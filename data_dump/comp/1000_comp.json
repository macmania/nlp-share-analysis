{"count": 24749, "results": [{"publisher": {"name": ""}, "description": "  We present an unsupervised framework for simultaneous appearance-based object\ndiscovery, detection, tracking and reconstruction using RGBD cameras and a\nrobot manipulator. The system performs dense 3D simultaneous localization and\nmapping concurrently with unsupervised object discovery. Putative objects that\nare spatially and visually coherent are manipulated by the robot to gain\nadditional motion-cues. The robot uses appearance alone, followed by structure\nand motion cues, to jointly discover, verify, learn and improve models of\nobjects. Induced motion segmentation reinforces learned models which are\nrepresented implicitly as 2D and 3D level sets to capture both shape and\nappearance. We compare three different approaches for appearance-based object\ndiscovery and find that a novel form of spatio-temporal super-pixels gives the\nhighest quality candidate object models in terms of precision and recall. Live\nexperiments with a Baxter robot demonstrate a holistic pipeline capable of\nautomatic discovery, verification, detection, tracking and reconstruction of\nunknown objects.\n", "contributors": [{"name": "Ma, Lu", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Lu", "email": ""}, {"name": "Ghafarianzadeh, Mahsa", "sameAs": [], "familyName": "Ghafarianzadeh", "additionalName": "", "givenName": "Mahsa", "email": ""}, {"name": "Coleman, Dave", "sameAs": [], "familyName": "Coleman", "additionalName": "", "givenName": "Dave", "email": ""}, {"name": "Correll, Nikolaus", "sameAs": [], "familyName": "Correll", "additionalName": "", "givenName": "Nikolaus", "email": ""}, {"name": "Sibley, Gabe", "sameAs": [], "familyName": "Sibley", "additionalName": "", "givenName": "Gabe", "email": ""}], "title": "Simultaneous Localization, Mapping, and Manipulation for Unsupervised\n  Object Discovery", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0802", "oai:arXiv.org:1411.0802"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We present an unsupervised framework for simultaneous appearance-based object\ndiscovery, detection, tracking and reconstruction using RGBD cameras and a\nrobot manipulator. The system performs dense 3D simultaneous localization and\nmapping concurrently with unsupervised object discovery. Putative objects that\nare spatially and visually coherent are manipulated by the robot to gain\nadditional motion-cues. The robot uses appearance alone, followed by structure\nand motion cues, to jointly discover, verify, learn and improve models of\nobjects. Induced motion segmentation reinforces learned models which are\nrepresented implicitly as 2D and 3D level sets to capture both shape and\nappearance. We compare three different approaches for appearance-based object\ndiscovery and find that a novel form of spatio-temporal super-pixels gives the\nhighest quality candidate object models in terms of precision and recall. Live\nexperiments with a Baxter robot demonstrate a holistic pipeline capable of\nautomatic discovery, verification, detection, tracking and reconstruction of\nunknown objects.\n"}}], "languages": [null], "subjects": ["computer science - robotics", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0802"}}, {"publisher": {"name": ""}, "description": "  In contrast to today's IP-based host-oriented Internet architecture,\nInformation-Centric Networking (ICN) emphasizes content by making it directly\naddressable and routable. Named Data Networking (NDN) architecture is an\ninstance of ICN that is being developed as a candidate next-generation Internet\narchitecture. By opportunistically caching content within the network (in\nrouters), NDN appears to be well-suited for large-scale content distribution\nand for meeting the needs of increasingly mobile and bandwidth-hungry\napplications that dominate today's Internet.\n  One key feature of NDN is the requirement for each content object to be\ndigitally signed by its producer. Thus, NDN should be, in principle, immune to\ndistributing fake (aka \"poisoned\") content. However, in practice, this poses\ntwo challenges for detecting fake content in NDN routers: (1) overhead due to\nsignature verification and certificate chain traversal, and (2) lack of trust\ncontext, i.e., determining which public keys are trusted to verify which\ncontent. Because of these issues, NDN does not force routers to verify content\nsignatures, which makes the architecture susceptible to content poisoning\nattacks.\n  This paper explores root causes of, and some cures for, content poisoning\nattacks in NDN. In the process, it becomes apparent that meaningful mitigation\nof content poisoning is contingent upon a network-layer trust management\narchitecture, elements of which we construct while carefully justifying\nspecific design choices. This work represents the initial effort towards\ncomprehensive trust management for NDN.\n", "contributors": [{"name": "Ghali, Cesar", "sameAs": [], "familyName": "Ghali", "additionalName": "", "givenName": "Cesar", "email": ""}, {"name": "Tsudik, Gene", "sameAs": [], "familyName": "Tsudik", "additionalName": "", "givenName": "Gene", "email": ""}, {"name": "Uzun, Ersin", "sameAs": [], "familyName": "Uzun", "additionalName": "", "givenName": "Ersin", "email": ""}], "title": "Elements of Trust in Named-Data Networking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-13", "2014-10-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.3332", "ACM SIGCOMM Computer Communication Review, Volume 44 Issue 5,\n  October 2014", "doi:10.1145/2677046.2677049", "oai:arXiv.org:1402.3332"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In contrast to today's IP-based host-oriented Internet architecture,\nInformation-Centric Networking (ICN) emphasizes content by making it directly\naddressable and routable. Named Data Networking (NDN) architecture is an\ninstance of ICN that is being developed as a candidate next-generation Internet\narchitecture. By opportunistically caching content within the network (in\nrouters), NDN appears to be well-suited for large-scale content distribution\nand for meeting the needs of increasingly mobile and bandwidth-hungry\napplications that dominate today's Internet.\n  One key feature of NDN is the requirement for each content object to be\ndigitally signed by its producer. Thus, NDN should be, in principle, immune to\ndistributing fake (aka \"poisoned\") content. However, in practice, this poses\ntwo challenges for detecting fake content in NDN routers: (1) overhead due to\nsignature verification and certificate chain traversal, and (2) lack of trust\ncontext, i.e., determining which public keys are trusted to verify which\ncontent. Because of these issues, NDN does not force routers to verify content\nsignatures, which makes the architecture susceptible to content poisoning\nattacks.\n  This paper explores root causes of, and some cures for, content poisoning\nattacks in NDN. In the process, it becomes apparent that meaningful mitigation\nof content poisoning is contingent upon a network-layer trust management\narchitecture, elements of which we construct while carefully justifying\nspecific design choices. This work represents the initial effort towards\ncomprehensive trust management for NDN.\n", "Comment: 9 pages, 2 figures"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-10-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.3332"}}, {"publisher": {"name": ""}, "description": "  We consider channel/subspace tracking systems for temporally correlated\nmillimeter wave (e.g., E-band) multiple-input multiple-output (MIMO) channels.\nOur focus is given to the tracking algorithm in the non-line-of-sight (NLoS)\nenvironment, where the transmitter and the receiver are equipped with hybrid\nanalog/digital precoder and combiner, respectively. In the absence of\nstraightforward time-correlated channel model in the millimeter wave MIMO\nliterature, we present a temporal MIMO channel evolution model for NLoS\nmillimeter wave scenarios. Considering that conventional MIMO channel tracking\nalgorithms in microwave bands are not directly applicable, we propose a new\nchannel tracking technique based on sequentially updating the precoder and\ncombiner. Numerical results demonstrate the superior channel tracking ability\nof the proposed technique over independent sounding approach in the presented\nchannel model and the spatial channel model (SCM) adopted in 3GPP\nspecification.\n", "contributors": [{"name": "He, Jiguang", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Jiguang", "email": ""}, {"name": "Kim, Taejoon", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Taejoon", "email": ""}, {"name": "Ghauch, Hadi", "sameAs": [], "familyName": "Ghauch", "additionalName": "", "givenName": "Hadi", "email": ""}, {"name": "Liu, Kunpeng", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Kunpeng", "email": ""}, {"name": "Wang, Guangjian", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Guangjian", "email": ""}], "title": "Millimeter Wave MIMO Channel Tracking Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4224", "oai:arXiv.org:1412.4224"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider channel/subspace tracking systems for temporally correlated\nmillimeter wave (e.g., E-band) multiple-input multiple-output (MIMO) channels.\nOur focus is given to the tracking algorithm in the non-line-of-sight (NLoS)\nenvironment, where the transmitter and the receiver are equipped with hybrid\nanalog/digital precoder and combiner, respectively. In the absence of\nstraightforward time-correlated channel model in the millimeter wave MIMO\nliterature, we present a temporal MIMO channel evolution model for NLoS\nmillimeter wave scenarios. Considering that conventional MIMO channel tracking\nalgorithms in microwave bands are not directly applicable, we propose a new\nchannel tracking technique based on sequentially updating the precoder and\ncombiner. Numerical results demonstrate the superior channel tracking ability\nof the proposed technique over independent sounding approach in the presented\nchannel model and the spatial channel model (SCM) adopted in 3GPP\nspecification.\n", "Comment: 6 pages, 3 figures, conference"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4224"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "One of the primary problems in constructing risk-stratification models for medical applications is that the data are often noisy, incomplete, and suffer from high class-imbalance. This problem becomes more severe when the total amount of data relevant to the task of interest is small. We address this problem in the context of risk-stratifying patients receiving isolated surgical aortic valve replacements (isolated AVR) for the adverse outcomes of operative mortality and stroke. We work with data from two hospitals (Hospital 1 and Hospital 2) in the Society of Thoracic Surgeons (STS) Adult Cardiac Surgery Database. Because the data available for our application of interest (target data) are limited, developing an accurate model using only these data is infeasible. Instead, we investigate transfer learning approaches to utilize data from other cardiac surgery procedures as well as from other institutions (source data). We first evaluate the effectiveness of leveraging information across procedures within a single hospital. We achieve significant improvements over baseline: at Hospital 1, the average AUC for operative mortality increased from 0.58 to 0.70. However, not all source examples are equally useful. Next, we evaluate the effectiveness of leveraging data across hospitals. We show that leveraging information across hospitals has variable utility; although it can result in worse performance (average AUC for stroke at Hospital 1 dropped from 0.61 to 0.56), it can also lead to significant improvements (average AUC for operative mortality at Hospital 1 increased from 0.70 to 0.72). Finally, we present an automated approach to leveraging the available source data. We investigate how removing source data based on how far they are from the mean of the target data affects performance. We propose an instance-weighting scheme based on these distances. This automated instance-weighting approach can achieve small, but significant improvements over using all of the data without weights (average AUC for operative mortality at Hospital 1 increased from 0.72 to 0.73). Research on these methods can have an important impact on the development of clinical risk-stratification tools targeted towards specific patient populations.", "contributors": [{"name": "Gong, Jen J. (Jen Jian)", "sameAs": [], "familyName": "Gong", "additionalName": "J.", "givenName": "Jen", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Electrical Engineering and Computer Science.", "sameAs": [], "familyName": "Science.", "additionalName": "Institute of Technology. Department of Electrical Engineering and Computer", "givenName": "Massachusetts", "email": ""}, {"name": "John V. Guttag.", "sameAs": [], "familyName": "Guttag.", "additionalName": "V.", "givenName": "John", "email": ""}], "title": "Improving clinical risk-stratification tools : instance-transfer for selecting relevant training data", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "71 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/91090", "892724540", "oai:dspace.mit.edu:1721.1/91090"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2014-10-21T17:25:32Z", "2014-10-21T17:25:32Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["One of the primary problems in constructing risk-stratification models for medical applications is that the data are often noisy, incomplete, and suffer from high class-imbalance. This problem becomes more severe when the total amount of data relevant to the task of interest is small. We address this problem in the context of risk-stratifying patients receiving isolated surgical aortic valve replacements (isolated AVR) for the adverse outcomes of operative mortality and stroke. We work with data from two hospitals (Hospital 1 and Hospital 2) in the Society of Thoracic Surgeons (STS) Adult Cardiac Surgery Database. Because the data available for our application of interest (target data) are limited, developing an accurate model using only these data is infeasible. Instead, we investigate transfer learning approaches to utilize data from other cardiac surgery procedures as well as from other institutions (source data). We first evaluate the effectiveness of leveraging information across procedures within a single hospital. We achieve significant improvements over baseline: at Hospital 1, the average AUC for operative mortality increased from 0.58 to 0.70. However, not all source examples are equally useful. Next, we evaluate the effectiveness of leveraging data across hospitals. We show that leveraging information across hospitals has variable utility; although it can result in worse performance (average AUC for stroke at Hospital 1 dropped from 0.61 to 0.56), it can also lead to significant improvements (average AUC for operative mortality at Hospital 1 increased from 0.70 to 0.72). Finally, we present an automated approach to leveraging the available source data. We investigate how removing source data based on how far they are from the mean of the target data affects performance. We propose an instance-weighting scheme based on these distances. This automated instance-weighting approach can achieve small, but significant improvements over using all of the data without weights (average AUC for operative mortality at Hospital 1 increased from 0.72 to 0.73). Research on these methods can have an important impact on the development of clinical risk-stratification tools targeted towards specific patient populations.", "by Jen J. Gong.", "Thesis: S.M. in Computer Science and Engineering, Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2014.", "52", "Cataloged from PDF version of thesis.", "Includes bibliographical references (pages 66-71)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7817", "hdl_1721.1_7663"]}}], "languages": [null], "subjects": ["electrical engineering and computer science."], "providerUpdatedDateTime": "2015-04-09T06:21:41", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/91090"}}, {"publisher": {"name": ""}, "description": "  TCP and its variants have suffered from surprisingly poor performance for\ndecades. We argue the TCP family has little hope to achieve consistent high\nperformance due to a fundamental architectural deficiency: hardwiring\npacket-level events to control responses without understanding the real\nperformance result of its actions. We propose Performance-oriented Congestion\nControl (PCC), a new congestion control architecture in which each sender\ncontinuously observes the connection between its actions and empirically\nexperienced performance, enabling it to consistently adopt actions that result\nin high performance. We prove that PCC converges to a stable and fair\nequilibrium. Across many real-world and challenging environments, PCC shows\nconsistent and often 10x performance improvement, with better fairness and\nstability than TCP. PCC requires no router hardware support or new packet\nformat.\n", "contributors": [{"name": "Dong, Mo", "sameAs": [], "familyName": "Dong", "additionalName": "", "givenName": "Mo", "email": ""}, {"name": "Li, Qingxi", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Qingxi", "email": ""}, {"name": "Zarchy, Doron", "sameAs": [], "familyName": "Zarchy", "additionalName": "", "givenName": "Doron", "email": ""}, {"name": "Godfrey, Brighten", "sameAs": [], "familyName": "Godfrey", "additionalName": "", "givenName": "Brighten", "email": ""}, {"name": "Schapira, Michael", "sameAs": [], "familyName": "Schapira", "additionalName": "", "givenName": "Michael", "email": ""}], "title": "PCC: Re-architecting Congestion Control for Consistent High Performance", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-24", "2014-09-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.7092", "oai:arXiv.org:1409.7092"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  TCP and its variants have suffered from surprisingly poor performance for\ndecades. We argue the TCP family has little hope to achieve consistent high\nperformance due to a fundamental architectural deficiency: hardwiring\npacket-level events to control responses without understanding the real\nperformance result of its actions. We propose Performance-oriented Congestion\nControl (PCC), a new congestion control architecture in which each sender\ncontinuously observes the connection between its actions and empirically\nexperienced performance, enabling it to consistently adopt actions that result\nin high performance. We prove that PCC converges to a stable and fair\nequilibrium. Across many real-world and challenging environments, PCC shows\nconsistent and often 10x performance improvement, with better fairness and\nstability than TCP. PCC requires no router hardware support or new packet\nformat.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.7092"}}, {"publisher": {"name": ""}, "description": "  Mean Field Variational Bayes (MFVB) is a popular posterior approximation\nmethod due to its fast runtime on large-scale data sets. However, it is well\nknown that a major failing of MFVB is its (sometimes severe) underestimates of\nthe uncertainty of model variables and lack of information about model variable\ncovariance. We develop a fast, general methodology for exponential families\nthat augments MFVB to deliver accurate uncertainty estimates for model\nvariables -- both for individual variables and coherently across variables.\nMFVB for exponential families defines a fixed-point equation in the means of\nthe approximating posterior, and our approach yields a covariance estimate by\nperturbing this fixed point. Inspired by linear response theory, we call our\nmethod linear response variational Bayes (LRVB). We demonstrate the accuracy of\nour method on simulated data sets.\n", "contributors": [{"name": "Giordano, Ryan", "sameAs": [], "familyName": "Giordano", "additionalName": "", "givenName": "Ryan", "email": ""}, {"name": "Broderick, Tamara", "sameAs": [], "familyName": "Broderick", "additionalName": "", "givenName": "Tamara", "email": ""}], "title": "Covariance Matrices for Mean Field Variational Bayes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6853", "oai:arXiv.org:1410.6853"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Mean Field Variational Bayes (MFVB) is a popular posterior approximation\nmethod due to its fast runtime on large-scale data sets. However, it is well\nknown that a major failing of MFVB is its (sometimes severe) underestimates of\nthe uncertainty of model variables and lack of information about model variable\ncovariance. We develop a fast, general methodology for exponential families\nthat augments MFVB to deliver accurate uncertainty estimates for model\nvariables -- both for individual variables and coherently across variables.\nMFVB for exponential families defines a fixed-point equation in the means of\nthe approximating posterior, and our approach yields a covariance estimate by\nperturbing this fixed point. Inspired by linear response theory, we call our\nmethod linear response variational Bayes (LRVB). We demonstrate the accuracy of\nour method on simulated data sets.\n", "Comment: 12 pages, 2 figures"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning", "statistics - methodology"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6853"}}, {"publisher": {"name": ""}, "description": "  Based on the axiomatization of reversible computing RACP, we generalize it to\nquantum reversible computing which is called qRACP. By use of the framework of\nquantum configuration, we show that structural reversibility and quantum state\nreversibility must be satisfied simultaneously in quantum reversible\ncomputation. RACP and qRACP has the same axiomatization modulo the so-called\nquantum forward-reverse bisimularity, that is, classical reversible computing\nand quantum reversible computing are unified.\n", "contributors": [{"name": "Wang, Yong", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yong", "email": ""}], "title": "An Algebra of Reversible Quantum Computing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05260", "oai:arXiv.org:1501.05260"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Based on the axiomatization of reversible computing RACP, we generalize it to\nquantum reversible computing which is called qRACP. By use of the framework of\nquantum configuration, we show that structural reversibility and quantum state\nreversibility must be satisfied simultaneously in quantum reversible\ncomputation. RACP and qRACP has the same axiomatization modulo the so-called\nquantum forward-reverse bisimularity, that is, classical reversible computing\nand quantum reversible computing are unified.\n", "Comment: arXiv admin note: substantial text overlap with arXiv:1311.2960,\n  arXiv:1410.5131, arXiv:1312.0686, arXiv:1404.0665"]}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2015-01-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05260"}}, {"publisher": {"name": ""}, "description": "  Distributed Opportunistic Scheduling (DOS) is inherently harder than\nconventional opportunistic scheduling due to the absence of a central entity\nthat has knowledge of all the channel states. With DOS, stations contend for\nthe channel using random access; after a successful contention, they measure\nthe channel conditions and only transmit in case of a good channel, while\ngiving up the transmission opportunity when the channel conditions are poor.\nThe distributed nature of DOS systems makes them vulnerable to selfish users:\nby deviating from the protocol and using more transmission opportunities, a\nselfish user can gain a greater share of the wireless resources at the expense\nof the well-behaved users. In this paper, we address the selfishness problem in\nDOS from a game theoretic standpoint. We propose an algorithm that satisfies\nthe following properties: (i) when all stations implement the algorithm, the\nwireless network is driven to the optimal point of operation, and (ii) one or\nmore selfish stations cannot gain any profit by deviating from the algorithm.\nThe key idea of the algorithm is to react to a selfish station by using a more\naggressive configuration that (indirectly) punishes this station. We build on\nmultivariable control theory to design a mechanism for punishment that on the\none hand is sufficiently severe to prevent selfish behavior while on the other\nhand is light enough to guarantee that, in the absence of selfish behavior, the\nsystem is stable and converges to the optimum point of operation. We conduct a\ngame theoretic analysis based on repeated games to show the algorithm's\neffectiveness against selfish stations. These results are confirmed by\nextensive simulations.\n", "contributors": [{"name": "Banchs, Albert", "sameAs": [], "familyName": "Banchs", "additionalName": "", "givenName": "Albert", "email": ""}, {"name": "Garcia-Saavedra, Andres", "sameAs": [], "familyName": "Garcia-Saavedra", "additionalName": "", "givenName": "Andres", "email": ""}, {"name": "Serrano, Pablo", "sameAs": [], "familyName": "Serrano", "additionalName": "", "givenName": "Pablo", "email": ""}, {"name": "Widmer, Joerg", "sameAs": [], "familyName": "Widmer", "additionalName": "", "givenName": "Joerg", "email": ""}], "title": "A Game Theoretic Approach to Distributed Opportunistic Scheduling", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-07-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1107.4452", "oai:arXiv.org:1107.4452"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Distributed Opportunistic Scheduling (DOS) is inherently harder than\nconventional opportunistic scheduling due to the absence of a central entity\nthat has knowledge of all the channel states. With DOS, stations contend for\nthe channel using random access; after a successful contention, they measure\nthe channel conditions and only transmit in case of a good channel, while\ngiving up the transmission opportunity when the channel conditions are poor.\nThe distributed nature of DOS systems makes them vulnerable to selfish users:\nby deviating from the protocol and using more transmission opportunities, a\nselfish user can gain a greater share of the wireless resources at the expense\nof the well-behaved users. In this paper, we address the selfishness problem in\nDOS from a game theoretic standpoint. We propose an algorithm that satisfies\nthe following properties: (i) when all stations implement the algorithm, the\nwireless network is driven to the optimal point of operation, and (ii) one or\nmore selfish stations cannot gain any profit by deviating from the algorithm.\nThe key idea of the algorithm is to react to a selfish station by using a more\naggressive configuration that (indirectly) punishes this station. We build on\nmultivariable control theory to design a mechanism for punishment that on the\none hand is sufficiently severe to prevent selfish behavior while on the other\nhand is light enough to guarantee that, in the absence of selfish behavior, the\nsystem is stable and converges to the optimum point of operation. We conduct a\ngame theoretic analysis based on repeated games to show the algorithm's\neffectiveness against selfish stations. These results are confirmed by\nextensive simulations.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1107.4452"}}, {"publisher": {"name": ""}, "description": "  Security metrics serve as a powerful tool for organizations to understand the\neffectiveness of protecting computer networks. However majority of these\nmeasurement techniques don't adequately help corporations to make informed risk\nmanagement decisions. In this paper we present a stochastic security framework\nfor obtaining quantitative measures of security by taking into account the\ndynamic attributes associated with vulnerabilities that can change over time.\nOur model is novel as existing research in attack graph analysis do not\nconsider the temporal aspects associated with the vulnerabilities, such as the\navailability of exploits and patches which can affect the overall network\nsecurity based on how the vulnerabilities are interconnected and leveraged to\ncompromise the system. In order to have a more realistic representation of how\nthe security state of the network would vary over time, a nonhomogeneous model\nis developed which incorporates a time dependent covariate, namely the\nvulnerability age. The daily transition-probability matrices are estimated\nusing Frei's Vulnerability Lifecycle model. We also leverage the trusted CVSS\nmetric domain to analyze how the total exploitability and impact measures\nevolve over a time period for a given network.\n", "contributors": [{"name": "Abraham, Subil", "sameAs": [], "familyName": "Abraham", "additionalName": "", "givenName": "Subil", "email": ""}, {"name": "Nair, Suku", "sameAs": [], "familyName": "Nair", "additionalName": "", "givenName": "Suku", "email": ""}], "title": "A Predictive Framework for Cyber Security Analytics using Attack Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01240", "oai:arXiv.org:1502.01240"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Security metrics serve as a powerful tool for organizations to understand the\neffectiveness of protecting computer networks. However majority of these\nmeasurement techniques don't adequately help corporations to make informed risk\nmanagement decisions. In this paper we present a stochastic security framework\nfor obtaining quantitative measures of security by taking into account the\ndynamic attributes associated with vulnerabilities that can change over time.\nOur model is novel as existing research in attack graph analysis do not\nconsider the temporal aspects associated with the vulnerabilities, such as the\navailability of exploits and patches which can affect the overall network\nsecurity based on how the vulnerabilities are interconnected and leveraged to\ncompromise the system. In order to have a more realistic representation of how\nthe security state of the network would vary over time, a nonhomogeneous model\nis developed which incorporates a time dependent covariate, namely the\nvulnerability age. The daily transition-probability matrices are estimated\nusing Frei's Vulnerability Lifecycle model. We also leverage the trusted CVSS\nmetric domain to analyze how the total exploitability and impact measures\nevolve over a time period for a given network.\n", "Comment: 17 pages, 8 figures in International Journal of Computer Networks &\n  Communications (IJCNC) January 2015. ISSN:0974-9322 [Online]; 0975-2293\n  [Print]"]}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-02-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01240"}}, {"publisher": {"name": ""}, "description": "  Network control refers to a very large and diverse set of problems including\ncontrollability of linear time-invariant dynamical systems evolving over time\nthat have inputs and outputs. The network control problem in this setting is to\nselect the appropriate input to steer the network into a desired output state.\nExamples of the output state include the throughput of a communications\nnetwork, transcription factor concentration in a gene regulatory network,\ncustomer purchases in a marketing context subject to social influences and the\namount of flux flowing through a biochemical network.\n  We focus on control of linear dynamical systems under the notion of\nstructural controllability which is intimately connected to finding maximum\nmatchings. Hence, a natural objective is studying scalable and fast algorithms\nfor this task. We first show the convergence of matching algorithms for\ndifferent random networks and then analyze a popular, fast and practical\nheuristic due to Karp and Sipser. We establish the optimality of both the\nKarp-Sipser Algorithm as well as a simplification of it, and provide results\nconcerning the asymptotic size of maximum matchings for an extensive class of\nrandom networks.\n", "contributors": [{"name": "Faradonbeh, Mohamad Kazem Shirani", "sameAs": [], "familyName": "Faradonbeh", "additionalName": "Kazem Shirani", "givenName": "Mohamad", "email": ""}, {"name": "Tewari, Ambuj", "sameAs": [], "familyName": "Tewari", "additionalName": "", "givenName": "Ambuj", "email": ""}, {"name": "Michailidis, George", "sameAs": [], "familyName": "Michailidis", "additionalName": "", "givenName": "George", "email": ""}], "title": "Optimality of Fast Matching Algorithms for Random Networks with\n  Applications to Structural Controllability", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08019", "oai:arXiv.org:1503.08019"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  Network control refers to a very large and diverse set of problems including\ncontrollability of linear time-invariant dynamical systems evolving over time\nthat have inputs and outputs. The network control problem in this setting is to\nselect the appropriate input to steer the network into a desired output state.\nExamples of the output state include the throughput of a communications\nnetwork, transcription factor concentration in a gene regulatory network,\ncustomer purchases in a marketing context subject to social influences and the\namount of flux flowing through a biochemical network.\n  We focus on control of linear dynamical systems under the notion of\nstructural controllability which is intimately connected to finding maximum\nmatchings. Hence, a natural objective is studying scalable and fast algorithms\nfor this task. We first show the convergence of matching algorithms for\ndifferent random networks and then analyze a popular, fast and practical\nheuristic due to Karp and Sipser. We establish the optimality of both the\nKarp-Sipser Algorithm as well as a simplification of it, and provide results\nconcerning the asymptotic size of maximum matchings for an extensive class of\nrandom networks.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - systems and control", "statistics - other statistics"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08019"}}, {"publisher": {"name": "American Diabetes Association"}, "description": "", "contributors": [{"name": "D\u2019Addio, Francesca", "sameAs": [], "familyName": "D\u2019Addio", "additionalName": "", "givenName": "Francesca", "email": ""}, {"name": "Maffi, Paola", "sameAs": [], "familyName": "Maffi", "additionalName": "", "givenName": "Paola", "email": ""}, {"name": "Vezzulli, Paolo", "sameAs": [], "familyName": "Vezzulli", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Vergani, Andrea", "sameAs": [], "familyName": "Vergani", "additionalName": "", "givenName": "Andrea", "email": ""}, {"name": "Mello, Alessandra", "sameAs": [], "familyName": "Mello", "additionalName": "", "givenName": "Alessandra", "email": ""}, {"name": "Bassi, Roberto", "sameAs": [], "familyName": "Bassi", "additionalName": "", "givenName": "Roberto", "email": ""}, {"name": "Nano, Rita", "sameAs": [], "familyName": "Nano", "additionalName": "", "givenName": "Rita", "email": ""}, {"name": "Falautano, Monica", "sameAs": [], "familyName": "Falautano", "additionalName": "", "givenName": "Monica", "email": ""}, {"name": "Coppi, Elisabetta", "sameAs": [], "familyName": "Coppi", "additionalName": "", "givenName": "Elisabetta", "email": ""}, {"name": "Finzi, Giovanna", "sameAs": [], "familyName": "Finzi", "additionalName": "", "givenName": "Giovanna", "email": ""}, {"name": "D\u2019Angelo, Armando", "sameAs": [], "familyName": "D\u2019Angelo", "additionalName": "", "givenName": "Armando", "email": ""}, {"name": "Fermo, Isabella", "sameAs": [], "familyName": "Fermo", "additionalName": "", "givenName": "Isabella", "email": ""}, {"name": "Pellegatta, Fabio", "sameAs": [], "familyName": "Pellegatta", "additionalName": "", "givenName": "Fabio", "email": ""}, {"name": "La Rosa, Stefano", "sameAs": [], "familyName": "La Rosa", "additionalName": "", "givenName": "Stefano", "email": ""}, {"name": "Magnani, Giuseppe", "sameAs": [], "familyName": "Magnani", "additionalName": "", "givenName": "Giuseppe", "email": ""}, {"name": "Piemonti, Lorenzo", "sameAs": [], "familyName": "Piemonti", "additionalName": "", "givenName": "Lorenzo", "email": ""}, {"name": "Falini, Andrea", "sameAs": [], "familyName": "Falini", "additionalName": "", "givenName": "Andrea", "email": ""}, {"name": "Folli, Franco", "sameAs": [], "familyName": "Folli", "additionalName": "", "givenName": "Franco", "email": ""}, {"name": "Secchi, Antonio", "sameAs": [], "familyName": "Secchi", "additionalName": "", "givenName": "Antonio", "email": ""}, {"name": "Fiorina, Paolo", "sameAs": [], "familyName": "Fiorina", "additionalName": "", "givenName": "Paolo", "email": ""}], "title": "Islet Transplantation Stabilizes Hemostatic Abnormalities and Cerebral Metabolism in Individuals With Type 1 Diabetes", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["pathophysiology/complications"], "providerUpdatedDateTime": "2015-01-01T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3867995"}}, {"publisher": {"name": ""}, "description": "  The goal of this survey is to present various results concerning the\ncohomology of pseudoeffective line bundles on compact K{\\\"a}hler manifolds, and\nrelated properties of their multiplier ideal sheaves. In case the curvature is\nstrictly positive, the prototype is the well known Nadel vanishing theorem,\nwhich is itself a generalized analytic version of the fundamental\nKawamata-Viehweg vanishing theorem of algebraic geometry. We are interested\nhere in the case where the curvature is merely semipositive in the sense of\ncurrents, and the base manifold is not necessarily projective. In this\nsituation, one can still obtain interesting information on cohomology, e.g. a\nHard Lefschetz theorem with pseudoeffective coefficients, in the form of a\nsurjectivity statement for the Lefschetz map. More recently, Junyan Cao, in his\nPhD thesis defended in Grenoble, obtained a general K{\\\"a}hler vanishing\ntheorem that depends on the concept of numerical dimension of a given\npseudoeffective line bundle. The proof of these results depends in a crucial\nway on a general approximation result for closed (1,1)-currents, based on the\nuse of Bergman kernels, and the related intersection theory of currents.\nAnother important ingredient is the recent proof by Guan and Zhou of the strong\nopenness conjecture. As an application, we discuss a structure theorem for\ncompact K{\\\"a}hler threefolds without nontrivial subvarieties, following a\njoint work with F.Campana and M.Verbitsky. We hope that these notes will serve\nas a useful guide to the more detailed and more technical papers in the\nliterature; in some cases, we provide here substantially simplified proofs and\nunifying viewpoints.\n", "contributors": [{"name": "Demailly, Jean-Pierre", "sameAs": [], "familyName": "Demailly", "additionalName": "", "givenName": "Jean-Pierre", "email": ""}], "title": "On the cohomology of pseudoeffective line bundles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-01-21", "2015-01-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1401.5432", "oai:arXiv.org:1401.5432"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The goal of this survey is to present various results concerning the\ncohomology of pseudoeffective line bundles on compact K{\\\"a}hler manifolds, and\nrelated properties of their multiplier ideal sheaves. In case the curvature is\nstrictly positive, the prototype is the well known Nadel vanishing theorem,\nwhich is itself a generalized analytic version of the fundamental\nKawamata-Viehweg vanishing theorem of algebraic geometry. We are interested\nhere in the case where the curvature is merely semipositive in the sense of\ncurrents, and the base manifold is not necessarily projective. In this\nsituation, one can still obtain interesting information on cohomology, e.g. a\nHard Lefschetz theorem with pseudoeffective coefficients, in the form of a\nsurjectivity statement for the Lefschetz map. More recently, Junyan Cao, in his\nPhD thesis defended in Grenoble, obtained a general K{\\\"a}hler vanishing\ntheorem that depends on the concept of numerical dimension of a given\npseudoeffective line bundle. The proof of these results depends in a crucial\nway on a general approximation result for closed (1,1)-currents, based on the\nuse of Bergman kernels, and the related intersection theory of currents.\nAnother important ingredient is the recent proof by Guan and Zhou of the strong\nopenness conjecture. As an application, we discuss a structure theorem for\ncompact K{\\\"a}hler threefolds without nontrivial subvarieties, following a\njoint work with F.Campana and M.Verbitsky. We hope that these notes will serve\nas a useful guide to the more detailed and more technical papers in the\nliterature; in some cases, we provide here substantially simplified proofs and\nunifying viewpoints.\n", "Comment: 39 pages. This survey is a written account of a lecture given at the\n  Abel Symposium, Trondheim, July 2013"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1401.5432"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "It is important for companies to manage their revenues and -reduce their costs efficiently. These goals can be achieved through effective pricing and inventory control strategies. This thesis studies a joint multi-period pricing and inventory control problem for a make-to-stock manufacturing system. Multiple products are produced under shared production capacity over a finite time horizon. The demand for each product is a function of the prices and no back orders are allowed. Inventory and production costs are linear functions of the levels of inventory and production, respectively. In this thesis, we introduce an iterative gradient-based algorithm. A key idea is that given a demand realization, the cost minimization part of the problem becomes a linear transportation problem. Given this idea, if we knew the optimal demand, we could solve the production problem efficiently. At each iteration of the algorithm, given a demand vector we solve a linear transportation problem and use its dual variables in order to solve a quadratic optimization problem that optimizes the revenue part and generates a new pricing policy. We illustrate computationally that this algorithm obtains the optimal production and pricing policy over the finite time horizon efficiently. The computational experiments in this thesis use a wide range of simulated data. The results show that the algorithm we study in this thesis indeed computes the optimal solution for the joint pricing and inventory control problem and is efficient as compared to solving a reformulation of the problem directly using commercial software. The algorithm proposed in this thesis solves large scale problems and can handle a wide range of nonlinear demand functions.", "contributors": [{"name": "Rao, Tingting", "sameAs": [], "familyName": "Rao", "additionalName": "", "givenName": "Tingting", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "Retsef Levi and Georgia Perakis.", "sameAs": [], "familyName": "Perakis.", "additionalName": "Levi and Georgia", "givenName": "Retsef", "email": ""}], "title": "LP-based subgradient algorithm for joint pricing and inventory control problems", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "94 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/45282", "311815436", "oai:dspace.mit.edu:1721.1/45282"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2009-04-29T17:20:09Z", "2009-04-29T17:20:09Z", "2008", "2008"]}}, {"name": "description", "properties": {"description": ["It is important for companies to manage their revenues and -reduce their costs efficiently. These goals can be achieved through effective pricing and inventory control strategies. This thesis studies a joint multi-period pricing and inventory control problem for a make-to-stock manufacturing system. Multiple products are produced under shared production capacity over a finite time horizon. The demand for each product is a function of the prices and no back orders are allowed. Inventory and production costs are linear functions of the levels of inventory and production, respectively. In this thesis, we introduce an iterative gradient-based algorithm. A key idea is that given a demand realization, the cost minimization part of the problem becomes a linear transportation problem. Given this idea, if we knew the optimal demand, we could solve the production problem efficiently. At each iteration of the algorithm, given a demand vector we solve a linear transportation problem and use its dual variables in order to solve a quadratic optimization problem that optimizes the revenue part and generates a new pricing policy. We illustrate computationally that this algorithm obtains the optimal production and pricing policy over the finite time horizon efficiently. The computational experiments in this thesis use a wide range of simulated data. The results show that the algorithm we study in this thesis indeed computes the optimal solution for the joint pricing and inventory control problem and is efficient as compared to solving a reformulation of the problem directly using commercial software. The algorithm proposed in this thesis solves large scale problems and can handle a wide range of nonlinear demand functions.", "by Tingting Rao.", "Thesis (S.M.)--Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2008.", "Includes bibliographical references (p. 93-94)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39115", "hdl_1721.1_39117"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:17", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/45282"}}, {"publisher": {"name": ""}, "description": "  We study the fundamental algorithmic rigidity problems for generic frameworks\nperiodic with respect to a fixed lattice or a finite-order rotation in the\nplane. For fixed-lattice frameworks we give an $O(n^2)$ algorithm for deciding\ngeneric rigidity and an O(n^3) algorithm for computing rigid components. If the\norder of rotation is part of the input, we give an O(n^4) algorithm for\ndeciding rigidity; in the case where the rotation's order is 3, a more\nspecialized algorithm solves all the fundamental algorithmic rigidity problems\nin O(n^2) time.\n", "contributors": [{"name": "Berardi, Matthew", "sameAs": [], "familyName": "Berardi", "additionalName": "", "givenName": "Matthew", "email": ""}, {"name": "Heeringa, Brent", "sameAs": [], "familyName": "Heeringa", "additionalName": "", "givenName": "Brent", "email": ""}, {"name": "Malestein, Justin", "sameAs": [], "familyName": "Malestein", "additionalName": "", "givenName": "Justin", "email": ""}, {"name": "Theran, Louis", "sameAs": [], "familyName": "Theran", "additionalName": "", "givenName": "Louis", "email": ""}], "title": "Rigid components in fixed-lattice and cone frameworks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.3234", "oai:arXiv.org:1105.3234"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We study the fundamental algorithmic rigidity problems for generic frameworks\nperiodic with respect to a fixed lattice or a finite-order rotation in the\nplane. For fixed-lattice frameworks we give an $O(n^2)$ algorithm for deciding\ngeneric rigidity and an O(n^3) algorithm for computing rigid components. If the\norder of rotation is part of the input, we give an O(n^4) algorithm for\ndeciding rigidity; in the case where the rotation's order is 3, a more\nspecialized algorithm solves all the fundamental algorithmic rigidity problems\nin O(n^2) time.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.3234"}}, {"publisher": {"name": ""}, "description": "  Spreadsheets are widely used within companies and often form the basis for\nbusiness decisions. Numerous cases are known where incorrect information in\nspreadsheets has lead to incorrect decisions. Such cases underline the\nrelevance of research on the professional use of spreadsheets.\n  Recently a new dataset became available for research, containing over 15.000\nbusiness spreadsheets that were extracted from the Enron E-mail Archive. With\nthis dataset, we 1) aim to obtain a thorough understanding of the\ncharacteristics of spreadsheets used within companies, and 2) compare the\ncharacteristics of the Enron spreadsheets with the EUSES corpus which is the\nexisting state of the art set of spreadsheets that is frequently used in\nspreadsheet studies.\n  Our analysis shows that 1) the majority of spreadsheets are not large in\nterms of worksheets and formulas, do not have a high degree of coupling, and\ntheir formulas are relatively simple; 2) the spreadsheets from the EUSES corpus\nare, with respect to the measured characteristics, quite similar to the Enron\nspreadsheets.\n", "contributors": [{"name": "Jansen, Bas", "sameAs": [], "familyName": "Jansen", "additionalName": "", "givenName": "Bas", "email": ""}], "title": "Enron versus EUSES: A Comparison of Two Spreadsheet Corpora", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04055", "oai:arXiv.org:1503.04055"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Spreadsheets are widely used within companies and often form the basis for\nbusiness decisions. Numerous cases are known where incorrect information in\nspreadsheets has lead to incorrect decisions. Such cases underline the\nrelevance of research on the professional use of spreadsheets.\n  Recently a new dataset became available for research, containing over 15.000\nbusiness spreadsheets that were extracted from the Enron E-mail Archive. With\nthis dataset, we 1) aim to obtain a thorough understanding of the\ncharacteristics of spreadsheets used within companies, and 2) compare the\ncharacteristics of the Enron spreadsheets with the EUSES corpus which is the\nexisting state of the art set of spreadsheets that is frequently used in\nspreadsheet studies.\n  Our analysis shows that 1) the majority of spreadsheets are not large in\nterms of worksheets and formulas, do not have a high degree of coupling, and\ntheir formulas are relatively simple; 2) the spreadsheets from the EUSES corpus\nare, with respect to the measured characteristics, quite similar to the Enron\nspreadsheets.\n", "Comment: In Proceedings of the 2nd Workshop on Software Engineering Methods in\n  Spreadsheets"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-03-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04055"}}, {"publisher": {"name": ""}, "description": "  In this paper we study the automorphism groups of real curves admitting a\nregular meromorphic function $f$ of degree $p$, so called real cyclic $p$-gonal\ncurves. When $p=2$ the automorphism groups of real hyperelliptic curves where\ngiven by Bujalance et al. in \\cite{BCGG}.\n", "contributors": [{"name": "Izquierdo, Milagros", "sameAs": [], "familyName": "Izquierdo", "additionalName": "", "givenName": "Milagros", "email": ""}, {"name": "Shaska, Tony", "sameAs": [], "familyName": "Shaska", "additionalName": "", "givenName": "Tony", "email": ""}], "title": "Cyclic curves over the reals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.01559", "oai:arXiv.org:1501.01559"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  In this paper we study the automorphism groups of real curves admitting a\nregular meromorphic function $f$ of degree $p$, so called real cyclic $p$-gonal\ncurves. When $p=2$ the automorphism groups of real hyperelliptic curves where\ngiven by Bujalance et al. in \\cite{BCGG}.\n", "Comment: NATO Advanced Study Institute, 2014, Ohrid, Macedonia"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.01559"}}, {"publisher": {"name": ""}, "description": "  The wiretap channel models secure communication of two users in the presence\nof a non-legitimate eavesdropper who must be kept ignorant of transmitted\nmessages. The performance of such a system is usually characterized by its\nsecrecy capacity determining the maximum transmission rate of secure\ncommunication. In this paper, the issue of whether the secrecy capacity is a\ncontinuous function of the system parameters or not is examined. In particular,\nthis is done for channel uncertainty modeled via compound channels and\narbitrarily varying channels, in which the legitimate users know only that the\ntrue channel realization is from a pre-specified uncertainty set. In the former\nmodel, this realization remains constant for the whole duration of\ntransmission, while in the latter the realization varies from channel use to\nchannel use in an unknown and arbitrary manner. These models not only capture\nthe case of channel uncertainty, but are also suitable to model scenarios in\nwhich a malicious adversary influences or jams the legitimate transmission. The\nsecrecy capacity of the compound wiretap channel is shown to be robust in the\nsense that it is a continuous function of the uncertainty set. Thus, small\nvariations in the uncertainty set lead to small variations in secrecy capacity.\nOn the other hand, the deterministic secrecy capacity of the arbitrarily\nvarying wiretap channel is shown to be discontinuous in the uncertainty set\nmeaning that small variations can lead to dramatic losses in capacity.\n", "contributors": [{"name": "Boche, Holger", "sameAs": [], "familyName": "Boche", "additionalName": "", "givenName": "Holger", "email": ""}, {"name": "Schaefer, Rafael F.", "sameAs": [], "familyName": "Schaefer", "additionalName": "F.", "givenName": "Rafael", "email": ""}, {"name": "Poor, H. Vincent", "sameAs": [], "familyName": "Poor", "additionalName": "Vincent", "givenName": "H.", "email": ""}], "title": "On the Continuity of the Secrecy Capacity of Compound and Arbitrarily\n  Varying Wiretap Channels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-16", "2015-03-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.4752", "oai:arXiv.org:1409.4752"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The wiretap channel models secure communication of two users in the presence\nof a non-legitimate eavesdropper who must be kept ignorant of transmitted\nmessages. The performance of such a system is usually characterized by its\nsecrecy capacity determining the maximum transmission rate of secure\ncommunication. In this paper, the issue of whether the secrecy capacity is a\ncontinuous function of the system parameters or not is examined. In particular,\nthis is done for channel uncertainty modeled via compound channels and\narbitrarily varying channels, in which the legitimate users know only that the\ntrue channel realization is from a pre-specified uncertainty set. In the former\nmodel, this realization remains constant for the whole duration of\ntransmission, while in the latter the realization varies from channel use to\nchannel use in an unknown and arbitrary manner. These models not only capture\nthe case of channel uncertainty, but are also suitable to model scenarios in\nwhich a malicious adversary influences or jams the legitimate transmission. The\nsecrecy capacity of the compound wiretap channel is shown to be robust in the\nsense that it is a continuous function of the uncertainty set. Thus, small\nvariations in the uncertainty set lead to small variations in secrecy capacity.\nOn the other hand, the deterministic secrecy capacity of the arbitrarily\nvarying wiretap channel is shown to be discontinuous in the uncertainty set\nmeaning that small variations can lead to dramatic losses in capacity.\n", "Comment: revised. Section VI added"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.4752"}}, {"publisher": {"name": ""}, "description": "  The water uptake by roots of plants is examined for an ideal situation, with\nan approximation that resembles plants growing in pots, meaning that the total\nsoil volume is fixed. We propose a coupled water uptake-root growth model. A\none-dimensional model for water flux and water uptake by a root system growing\nuniformly distributed in the soil is presented, and the Van Genuchten model for\nthe transport of water in soil is used. The governing equations are represented\nby a moving boundary model for which the root length, as a function of time, is\nprescribed. The solution of the model is obtained by front-fixing and finite\nelement methods. Model predictions for water uptake by a same plant growing in\nloam, silt and clay soils are obtained and compared. A sensitivity analysis to\ndetermine relative effects on water uptake when system parameters are changed\nis also presented and shows that the model and numerical method proposed are\nmore sensitive to the root growth rate than to the rest of the parameters. This\nsensitivity decreases along time, reaching its maximum at thirty days. A\ncomparison of this model with a fixed boundary model with and without root\ngrowth is also made. The results show qualitative differences from the\nbeginning of the simulations, and quantitative differences after ten days of\nsimulations.\n", "contributors": [{"name": "Albrieu, J. L. Blengino", "sameAs": [], "familyName": "Albrieu", "additionalName": "L. Blengino", "givenName": "J.", "email": ""}, {"name": "Reginato, J. C.", "sameAs": [], "familyName": "Reginato", "additionalName": "C.", "givenName": "J.", "email": ""}, {"name": "Tarzia, D. A.", "sameAs": [], "familyName": "Tarzia", "additionalName": "A.", "givenName": "D.", "email": ""}], "title": "Modeling water uptake by a root system growing in a fixed soil volume", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03331", "doi:10.1016/j.apm.2014.11.042", "oai:arXiv.org:1503.03331"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:physics", "q-bio"]}}, {"name": "description", "properties": {"description": ["  The water uptake by roots of plants is examined for an ideal situation, with\nan approximation that resembles plants growing in pots, meaning that the total\nsoil volume is fixed. We propose a coupled water uptake-root growth model. A\none-dimensional model for water flux and water uptake by a root system growing\nuniformly distributed in the soil is presented, and the Van Genuchten model for\nthe transport of water in soil is used. The governing equations are represented\nby a moving boundary model for which the root length, as a function of time, is\nprescribed. The solution of the model is obtained by front-fixing and finite\nelement methods. Model predictions for water uptake by a same plant growing in\nloam, silt and clay soils are obtained and compared. A sensitivity analysis to\ndetermine relative effects on water uptake when system parameters are changed\nis also presented and shows that the model and numerical method proposed are\nmore sensitive to the root growth rate than to the rest of the parameters. This\nsensitivity decreases along time, reaching its maximum at thirty days. A\ncomparison of this model with a fixed boundary model with and without root\ngrowth is also made. The results show qualitative differences from the\nbeginning of the simulations, and quantitative differences after ten days of\nsimulations.\n", "Comment: To Appear in Applied mathematical modelling 23 pages, 10 figures"]}}], "languages": [null], "subjects": ["35r37", "35q92", "physics - biological physics", "76505", "quantitative biology - tissues and organs", "physics - computational physics", "65m60"], "providerUpdatedDateTime": "2015-03-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03331"}}, {"publisher": {"name": ""}, "description": "  This paper investigates the role of factorial speech processing models in\nnoise-robust automatic speech recognition tasks. Factorial models can embed\nnon-stationary noise models using Markov chains as one of its source chain. The\npaper proposes a modeling scheme for modeling state-conditional observation\ndistribution of factorial models based on weighted stereo samples. This scheme\nis an extension to previous single pass retraining for ideal model compensation\nand here we used it to construct ideal state-conditional observation\ndistributions. Experiments of this paper over the set A of the Aurora 2 dataset\nshows that by considering noise models with multiple states, system performance\ncan be improved especially in low SNR conditions up to 4% absolute word\nrecognition performance. In addition to its power in accurate representation of\nstate-conditional observation distribution, it has an important advantage over\nprevious methods by providing the opportunity to independently select feature\nspaces for both source and corrupted features. This opens a new window for\nseeking better feature spaces appropriate for noise-robust tasks independent\nfrom clean speech feature space.\n", "contributors": [{"name": "Khademian, Mahdi", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Khademian", "email": ""}, {"name": "Homayounpour, Mohammad Mehdi", "sameAs": [], "familyName": "Homayounpour", "additionalName": "Mehdi", "givenName": "Mohammad", "email": ""}], "title": "Modeling State-Conditional Observation Distribution using Weighted\n  Stereo Samples for Factorial Speech Processing Models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02578", "oai:arXiv.org:1503.02578"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper investigates the role of factorial speech processing models in\nnoise-robust automatic speech recognition tasks. Factorial models can embed\nnon-stationary noise models using Markov chains as one of its source chain. The\npaper proposes a modeling scheme for modeling state-conditional observation\ndistribution of factorial models based on weighted stereo samples. This scheme\nis an extension to previous single pass retraining for ideal model compensation\nand here we used it to construct ideal state-conditional observation\ndistributions. Experiments of this paper over the set A of the Aurora 2 dataset\nshows that by considering noise models with multiple states, system performance\ncan be improved especially in low SNR conditions up to 4% absolute word\nrecognition performance. In addition to its power in accurate representation of\nstate-conditional observation distribution, it has an important advantage over\nprevious methods by providing the opportunity to independently select feature\nspaces for both source and corrupted features. This opens a new window for\nseeking better feature spaces appropriate for noise-robust tasks independent\nfrom clean speech feature space.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - learning", "computer science - sound"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02578"}}, {"publisher": {"name": ""}, "description": "  The flow field and the heat transfer around six in-line iso-thermal circular\ncylinders has been studied by mean of numerical simulations. Two values of the\ncenter to center spacing ($s=3.6d$ and $4d$, where $d$ is the cylinder\ndiameter) at Reynolds number of $100$ and Prandtl number of $0.7$ has been\ninvestigated. Similarly to the in-line two cylinder configuration, in this\nrange a transition in the flow and in the heat transfer occurs. Two different\nflow patterns have been identified: the stable shear layer (SSL) mode and the\nshear layer secondary vortices (SLSV) mode, at $3.6$ and $4$ spacing ratio\n($s/d$), respectively. At $s/d=3.6$ the flow pattern causes the entrainment of\ncold fluid on the downstream cylinders enhancing the heat transfer. On the\nother hand at $s/d=4$ two stable opposite shear layer prevent the cold fluid\nentrainment over the downstream cylinders reducing their heat exchange. The\noverall time average heat transfer of the array is enhanced up to 25%\ndecreasing the spacing ratio from $4$ to $3.6$. Furthermore, it is found that\nthe increased heat transfer is related to the phase shift between the Nusselt\ntime series of successive cylinders.\n", "contributors": [{"name": "Fornarelli, Francesco", "sameAs": [], "familyName": "Fornarelli", "additionalName": "", "givenName": "Francesco", "email": ""}, {"name": "Oresta, Paolo", "sameAs": [], "familyName": "Oresta", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Lippolis, Antonio", "sameAs": [], "familyName": "Lippolis", "additionalName": "", "givenName": "Antonio", "email": ""}], "title": "Flow patterns and heat transfer around six in-line circular cylinders at\n  low Reynolds number", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5836", "oai:arXiv.org:1410.5836"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": ["  The flow field and the heat transfer around six in-line iso-thermal circular\ncylinders has been studied by mean of numerical simulations. Two values of the\ncenter to center spacing ($s=3.6d$ and $4d$, where $d$ is the cylinder\ndiameter) at Reynolds number of $100$ and Prandtl number of $0.7$ has been\ninvestigated. Similarly to the in-line two cylinder configuration, in this\nrange a transition in the flow and in the heat transfer occurs. Two different\nflow patterns have been identified: the stable shear layer (SSL) mode and the\nshear layer secondary vortices (SLSV) mode, at $3.6$ and $4$ spacing ratio\n($s/d$), respectively. At $s/d=3.6$ the flow pattern causes the entrainment of\ncold fluid on the downstream cylinders enhancing the heat transfer. On the\nother hand at $s/d=4$ two stable opposite shear layer prevent the cold fluid\nentrainment over the downstream cylinders reducing their heat exchange. The\noverall time average heat transfer of the array is enhanced up to 25%\ndecreasing the spacing ratio from $4$ to $3.6$. Furthermore, it is found that\nthe increased heat transfer is related to the phase shift between the Nusselt\ntime series of successive cylinders.\n", "Comment: Accepted by JP Journal of Heat and Mass Transfer (2015)"]}}], "languages": [null], "subjects": ["physics - computational physics", "physics - fluid dynamics"], "providerUpdatedDateTime": "2014-10-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5836"}}, {"publisher": {"name": ""}, "description": "  This paper looks into the problem of pedestrian tracking using a monocular,\npotentially moving, uncalibrated camera. The pedestrians are located in each\nframe using a standard human detector, which are then tracked in subsequent\nframes. This is a challenging problem as one has to deal with complex\nsituations like changing background, partial or full occlusion and camera\nmotion. In order to carry out successful tracking, it is necessary to resolve\nassociations between the detected windows in the current frame with those\nobtained from the previous frame. Compared to methods that use temporal windows\nincorporating past as well as future information, we attempt to make decision\non a frame-by-frame basis. An occlusion reasoning scheme is proposed to resolve\nthe association problem between a pair of consecutive frames by using an\naffinity matrix that defines the closeness between a pair of windows and then,\nuses a binary integer programming to obtain unique association between them. A\nsecond stage of verification based on SURF matching is used to deal with those\ncases where the above optimization scheme might yield wrong associations. The\nefficacy of the approach is demonstrated through experiments on several\nstandard pedestrian datasets.\n", "contributors": [{"name": "Garg, Sourav", "sameAs": [], "familyName": "Garg", "additionalName": "", "givenName": "Sourav", "email": ""}, {"name": "Kumar, Swagat", "sameAs": [], "familyName": "Kumar", "additionalName": "", "givenName": "Swagat", "email": ""}, {"name": "Ratnakaram, Rajesh", "sameAs": [], "familyName": "Ratnakaram", "additionalName": "", "givenName": "Rajesh", "email": ""}, {"name": "Guha, Prithwijit", "sameAs": [], "familyName": "Guha", "additionalName": "", "givenName": "Prithwijit", "email": ""}], "title": "An Occlusion Reasoning Scheme for Monocular Pedestrian Tracking in\n  Dynamic Scenes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06129", "oai:arXiv.org:1501.06129"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper looks into the problem of pedestrian tracking using a monocular,\npotentially moving, uncalibrated camera. The pedestrians are located in each\nframe using a standard human detector, which are then tracked in subsequent\nframes. This is a challenging problem as one has to deal with complex\nsituations like changing background, partial or full occlusion and camera\nmotion. In order to carry out successful tracking, it is necessary to resolve\nassociations between the detected windows in the current frame with those\nobtained from the previous frame. Compared to methods that use temporal windows\nincorporating past as well as future information, we attempt to make decision\non a frame-by-frame basis. An occlusion reasoning scheme is proposed to resolve\nthe association problem between a pair of consecutive frames by using an\naffinity matrix that defines the closeness between a pair of windows and then,\nuses a binary integer programming to obtain unique association between them. A\nsecond stage of verification based on SURF matching is used to deal with those\ncases where the above optimization scheme might yield wrong associations. The\nefficacy of the approach is demonstrated through experiments on several\nstandard pedestrian datasets.\n", "Comment: 8 pages"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06129"}}, {"publisher": {"name": ""}, "description": "  We study the problem of distributed coverage control in a network of mobile\nagents arranged on a line. The goal is to design distributed dynamics for the\nagents to achieve optimal coverage positions with respect to a scalar density\nfield that measures the relative importance of each point on the line. Unlike\nprevious work, which has implicitly assumed the agents know this density field,\nwe only assume that each agent can access noisy samples of the field at points\nclose to its current location. We provide a simple randomized protocol wherein\nevery agent samples the scalar field at three nearby points at each step and\nwhich guarantees convergence to the optimal positions. We further analyze the\nconvergence time of this protocol and show that, under suitable assumptions,\nthe squared distance to the optimal coverage configuration decays as $O(1/t)$\nwith the number of iterations $t$, where the constant scales polynomially with\nthe number of agents $n$. We illustrate these results with simulations.\n", "contributors": [{"name": "Davison, P.", "sameAs": [], "familyName": "Davison", "additionalName": "", "givenName": "P.", "email": ""}, {"name": "Leonard, N. E.", "sameAs": [], "familyName": "Leonard", "additionalName": "E.", "givenName": "N.", "email": ""}, {"name": "Olshevsky, A.", "sameAs": [], "familyName": "Olshevsky", "additionalName": "", "givenName": "A.", "email": ""}, {"name": "Schwemmer, M.", "sameAs": [], "familyName": "Schwemmer", "additionalName": "", "givenName": "M.", "email": ""}], "title": "Nonuniform Line Coverage from Noisy Scalar Measurements", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-15", "2014-11-21"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.4188", "oai:arXiv.org:1310.4188"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We study the problem of distributed coverage control in a network of mobile\nagents arranged on a line. The goal is to design distributed dynamics for the\nagents to achieve optimal coverage positions with respect to a scalar density\nfield that measures the relative importance of each point on the line. Unlike\nprevious work, which has implicitly assumed the agents know this density field,\nwe only assume that each agent can access noisy samples of the field at points\nclose to its current location. We provide a simple randomized protocol wherein\nevery agent samples the scalar field at three nearby points at each step and\nwhich guarantees convergence to the optimal positions. We further analyze the\nconvergence time of this protocol and show that, under suitable assumptions,\nthe squared distance to the optimal coverage configuration decays as $O(1/t)$\nwith the number of iterations $t$, where the constant scales polynomially with\nthe number of agents $n$. We illustrate these results with simulations.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - systems and control"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.4188"}}, {"publisher": {"name": ""}, "description": "  Generic matrix multiplication (GEMM) and one-dimensional\nconvolution/cross-correlation (CONV) kernels often constitute the bulk of the\ncompute- and memory-intensive processing within image/audio recognition and\nmatching systems. We propose a novel method to scale the energy and processing\nthroughput of GEMM and CONV kernels for such error-tolerant multimedia\napplications by adjusting the precision of computation. Our technique employs\nlinear projections to the input matrix or signal data during the top-level GEMM\nand CONV blocking and reordering. The GEMM and CONV kernel processing then uses\nthe projected inputs and the results are accumulated to form the final outputs.\nThroughput and energy scaling takes place by changing the number of projections\ncomputed by each kernel, which in turn produces approximate results, i.e.\nchanges the precision of the performed computation. Results derived from a\nvoltage- and frequency-scaled ARM Cortex A15 processor running face recognition\nand music matching algorithms demonstrate that the proposed approach allows for\n280%~440% increase of processing throughput and 75%~80% decrease of energy\nconsumption against optimized GEMM and CONV kernels without any impact in the\nobtained recognition or matching accuracy. Even higher gains can be obtained if\none is willing to tolerate some reduction in the accuracy of the recognition\nand matching applications.\n", "contributors": [{"name": "Anam, Mohammad Ashraful", "sameAs": [], "familyName": "Anam", "additionalName": "Ashraful", "givenName": "Mohammad", "email": ""}, {"name": "Whatmough, Paul N.", "sameAs": [], "familyName": "Whatmough", "additionalName": "N.", "givenName": "Paul", "email": ""}, {"name": "Andreopoulos, Yiannis", "sameAs": [], "familyName": "Andreopoulos", "additionalName": "", "givenName": "Yiannis", "email": ""}], "title": "Precision-Energy-Throughput Scaling Of Generic Matrix Multiplication and\n  Convolution Kernels Via Linear Projections", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2860", "IEEE Transactions on Circuits and Systems for Video Technology,\n  vol. 24, no. 11, pp. 1860-1873, Nov. 2014", "oai:arXiv.org:1411.2860"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Generic matrix multiplication (GEMM) and one-dimensional\nconvolution/cross-correlation (CONV) kernels often constitute the bulk of the\ncompute- and memory-intensive processing within image/audio recognition and\nmatching systems. We propose a novel method to scale the energy and processing\nthroughput of GEMM and CONV kernels for such error-tolerant multimedia\napplications by adjusting the precision of computation. Our technique employs\nlinear projections to the input matrix or signal data during the top-level GEMM\nand CONV blocking and reordering. The GEMM and CONV kernel processing then uses\nthe projected inputs and the results are accumulated to form the final outputs.\nThroughput and energy scaling takes place by changing the number of projections\ncomputed by each kernel, which in turn produces approximate results, i.e.\nchanges the precision of the performed computation. Results derived from a\nvoltage- and frequency-scaled ARM Cortex A15 processor running face recognition\nand music matching algorithms demonstrate that the proposed approach allows for\n280%~440% increase of processing throughput and 75%~80% decrease of energy\nconsumption against optimized GEMM and CONV kernels without any impact in the\nobtained recognition or matching accuracy. Even higher gains can be obtained if\none is willing to tolerate some reduction in the accuracy of the recognition\nand matching applications.\n"}}], "languages": [null], "subjects": ["computer science - mathematical software", "computer science - multimedia"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2860"}}, {"publisher": {"name": ""}, "description": "  We focus on designing combinatorial algorithms for the Capacitated Network\nDesign problem (Cap-SNDP). The Cap-SNDP is the problem of satisfying\nconnectivity requirements when edges have costs and hard capacities. We begin\nby showing that the Group Steiner tree problem (GST) is a special case of\nCap-SNDP even when there is connectivity requirement between only one\nsource-sink pair. This implies the first poly-logarithmic lower bound for the\nCap-SNDP. We next provide combinatorial algorithms for several special cases of\nthis problem. The Cap-SNDP is equivalent to its special case when every edge\nhas either zero cost or infinite capacity. We consider a special case, called\nConnected Cap-SNDP, where all infinite-capacity edges in the solution are\nrequired to form a connected component containing the sinks. This problem is\nmotivated by its similarity to the Connected Facility Location problem\n[G+01,SW04]. We solve this problem by reducing it to Submodular tree cover\nproblem, which is a common generalization of Connected Cap-SNDP and Group\nSteiner tree problem. We generalize the recursive greedy algorithm [CEK]\nachieving a poly-logarithmic approximation algorithm for Submodular tree cover\nproblem. This result is interesting in its own right and gives the first\npoly-logarithmic approximation algorithms for Connected hard capacities set\nmulti-cover and Connected source location.\n  We then study another special case of Cap-SNDP called Unbalanced\npoint-to-point connection problem. Besides its practical applications to shift\ndesign problems [EKS], it generalizes many problems such as k-MST, Steiner\nForest and Point-to-Point Connection. We give a combinatorial logarithmic\napproximation algorithm for this problem by reducing it to degree-bounded SNDP.\n", "contributors": [{"name": "Hajiaghayi, MohammadTaghi", "sameAs": [], "familyName": "Hajiaghayi", "additionalName": "", "givenName": "MohammadTaghi", "email": ""}, {"name": "Khandekar, Rohit", "sameAs": [], "familyName": "Khandekar", "additionalName": "", "givenName": "Rohit", "email": ""}, {"name": "Kortsarz, Guy", "sameAs": [], "familyName": "Kortsarz", "additionalName": "", "givenName": "Guy", "email": ""}, {"name": "Nutov, Zeev", "sameAs": [], "familyName": "Nutov", "additionalName": "", "givenName": "Zeev", "email": ""}], "title": "Combinatorial Algorithms for Capacitated Network Design", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-08-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1108.1176", "oai:arXiv.org:1108.1176"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We focus on designing combinatorial algorithms for the Capacitated Network\nDesign problem (Cap-SNDP). The Cap-SNDP is the problem of satisfying\nconnectivity requirements when edges have costs and hard capacities. We begin\nby showing that the Group Steiner tree problem (GST) is a special case of\nCap-SNDP even when there is connectivity requirement between only one\nsource-sink pair. This implies the first poly-logarithmic lower bound for the\nCap-SNDP. We next provide combinatorial algorithms for several special cases of\nthis problem. The Cap-SNDP is equivalent to its special case when every edge\nhas either zero cost or infinite capacity. We consider a special case, called\nConnected Cap-SNDP, where all infinite-capacity edges in the solution are\nrequired to form a connected component containing the sinks. This problem is\nmotivated by its similarity to the Connected Facility Location problem\n[G+01,SW04]. We solve this problem by reducing it to Submodular tree cover\nproblem, which is a common generalization of Connected Cap-SNDP and Group\nSteiner tree problem. We generalize the recursive greedy algorithm [CEK]\nachieving a poly-logarithmic approximation algorithm for Submodular tree cover\nproblem. This result is interesting in its own right and gives the first\npoly-logarithmic approximation algorithms for Connected hard capacities set\nmulti-cover and Connected source location.\n  We then study another special case of Cap-SNDP called Unbalanced\npoint-to-point connection problem. Besides its practical applications to shift\ndesign problems [EKS], it generalizes many problems such as k-MST, Steiner\nForest and Point-to-Point Connection. We give a combinatorial logarithmic\napproximation algorithm for this problem by reducing it to degree-bounded SNDP.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1108.1176"}}, {"publisher": {"name": ""}, "description": "  Subspace clustering is the problem of clustering data points into a union of\nlow-dimensional linear or affine subspaces. It is the mathematical abstraction\nof many important problems in computer vision, image processing and has been\ndrawing avid attention in machine learning and statistics recently. In\nparticular, a line of recent work (Elhamifar and Vidal, 2013; Soltanolkotabi et\nal., 2012; Wang and Xu, 2013; Soltanolkotabi et al., 2014) provided strong\ntheoretical guarantee for the seminal algorithm: Sparse Subspace Clustering\n(SSC) (Elhamifar and Vidal, 2013) under various settings, and to some extent,\njustified its state-of-the-art performance in applications such as motion\nsegmentation and face clustering. The focus of these work has been getting\nmilder conditions under which SSC obeys \"self-expressiveness property\", which\nensures that no two points from different subspaces can be clustered together.\nSuch guarantee however is not sufficient for the clustering to be correct,\nthanks to the notorious \"graph connectivity problem\" (Nasihatkon and Hartley,\n2011). In this paper, we show that this issue can be resolved by a very simple\npost-processing procedure under only a mild \"general position\" assumption. In\naddition, we show that the approach is robust to arbitrary bounded perturbation\nof the data whenever the \"general position\" assumption holds with a margin.\nThese results provide the first exact clustering guarantee of SSC for subspaces\nof dimension greater than 3.\n", "contributors": [{"name": "Wang, Yining", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yining", "email": ""}, {"name": "Wang, Yu-Xiang", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yu-Xiang", "email": ""}, {"name": "Singh, Aarti", "sameAs": [], "familyName": "Singh", "additionalName": "", "givenName": "Aarti", "email": ""}], "title": "Clustering Consistent Sparse Subspace Clustering", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01046", "oai:arXiv.org:1504.01046"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Subspace clustering is the problem of clustering data points into a union of\nlow-dimensional linear or affine subspaces. It is the mathematical abstraction\nof many important problems in computer vision, image processing and has been\ndrawing avid attention in machine learning and statistics recently. In\nparticular, a line of recent work (Elhamifar and Vidal, 2013; Soltanolkotabi et\nal., 2012; Wang and Xu, 2013; Soltanolkotabi et al., 2014) provided strong\ntheoretical guarantee for the seminal algorithm: Sparse Subspace Clustering\n(SSC) (Elhamifar and Vidal, 2013) under various settings, and to some extent,\njustified its state-of-the-art performance in applications such as motion\nsegmentation and face clustering. The focus of these work has been getting\nmilder conditions under which SSC obeys \"self-expressiveness property\", which\nensures that no two points from different subspaces can be clustered together.\nSuch guarantee however is not sufficient for the clustering to be correct,\nthanks to the notorious \"graph connectivity problem\" (Nasihatkon and Hartley,\n2011). In this paper, we show that this issue can be resolved by a very simple\npost-processing procedure under only a mild \"general position\" assumption. In\naddition, we show that the approach is robust to arbitrary bounded perturbation\nof the data whenever the \"general position\" assumption holds with a margin.\nThese results provide the first exact clustering guarantee of SSC for subspaces\nof dimension greater than 3.\n", "Comment: 14 pages"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01046"}}, {"publisher": {"name": ""}, "description": "  More and more scientific research shows that there is a close correlation\nbetween the Internet and brain science. This paper presents the idea of\nestablishing the Internet neurology, which means to make a cross-contrast\nbetween the two in terms of physiology and psychology, so that a complete\ninfrastructure system of the Internet is established, predicting the\ndevelopment trend of the Internet in the future as well as the brain structure\nand operation mechanism, and providing theoretical support for the generation\nprinciple of intelligence, cognition and emotion. It also proposes the\nviewpoint that the Internet can be divided into Internet neurophysiology,\nInternet neuropsychology, Brain Internet physiology, Brain Internet psychology\nand the Internet in cognitive science.\n", "contributors": [{"name": "Liu, Feng", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Feng", "email": ""}], "title": "Definition and Research of Internet Neurology", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.02842", "oai:arXiv.org:1504.02842"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  More and more scientific research shows that there is a close correlation\nbetween the Internet and brain science. This paper presents the idea of\nestablishing the Internet neurology, which means to make a cross-contrast\nbetween the two in terms of physiology and psychology, so that a complete\ninfrastructure system of the Internet is established, predicting the\ndevelopment trend of the Internet in the future as well as the brain structure\nand operation mechanism, and providing theoretical support for the generation\nprinciple of intelligence, cognition and emotion. It also proposes the\nviewpoint that the Internet can be divided into Internet neurophysiology,\nInternet neuropsychology, Brain Internet physiology, Brain Internet psychology\nand the Internet in cognitive science.\n"}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.02842"}}, {"publisher": {"name": ""}, "description": "  This paper considers the controllability analysis problem for a class of\nmultirotor systems subject to rotor failure/wear. It is shown that classical\ncontrollability theories of linear systems are not sufficient to test the\ncontrollability of the considered multirotors. Owing to this, an easy-to-use\nmeasurement index is introduced to assess the available control authority.\nBased on it, a new necessary and sufficient condition for the controllability\nof multirotors is derived. Furthermore, a controllability test procedure is\napproached. The proposed controllability test method is applied to a class of\nhexacopters with different rotor configurations and different rotor efficiency\nparameters to show its effectiveness. The analysis results show that\nhexacopters with different rotor configurations have different fault-tolerant\ncapabilities. It is therefore necessary to test the controllability of the\nmultirotors before any fault-tolerant control strategies are employed.\n", "contributors": [{"name": "Du, Guang-Xun", "sameAs": [], "familyName": "Du", "additionalName": "", "givenName": "Guang-Xun", "email": ""}, {"name": "Quan, Quan", "sameAs": [], "familyName": "Quan", "additionalName": "", "givenName": "Quan", "email": ""}, {"name": "Yang, Binxian", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Binxian", "email": ""}, {"name": "Cai, Kai-Yuan", "sameAs": [], "familyName": "Cai", "additionalName": "", "givenName": "Kai-Yuan", "email": ""}], "title": "Controllability Analysis for Multirotor Helicopter Rotor Degradation and\n  Failure", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-24", "2015-02-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.5986", "oai:arXiv.org:1403.5986"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper considers the controllability analysis problem for a class of\nmultirotor systems subject to rotor failure/wear. It is shown that classical\ncontrollability theories of linear systems are not sufficient to test the\ncontrollability of the considered multirotors. Owing to this, an easy-to-use\nmeasurement index is introduced to assess the available control authority.\nBased on it, a new necessary and sufficient condition for the controllability\nof multirotors is derived. Furthermore, a controllability test procedure is\napproached. The proposed controllability test method is applied to a class of\nhexacopters with different rotor configurations and different rotor efficiency\nparameters to show its effectiveness. The analysis results show that\nhexacopters with different rotor configurations have different fault-tolerant\ncapabilities. It is therefore necessary to test the controllability of the\nmultirotors before any fault-tolerant control strategies are employed.\n", "Comment: 21 pages, 4 figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - robotics"], "providerUpdatedDateTime": "2015-02-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.5986"}}, {"publisher": {"name": ""}, "description": "  We describe four algorithms for neural network training, each adapted to\ndifferent scalability constraints. These algorithms are mathematically\nprincipled and invariant under a number of transformations in data and network\nrepresentation, from which performance is thus independent. These algorithms\nare obtained from the setting of differential geometry, and are based on either\nthe natural gradient using the Fisher information matrix, or on Hessian\nmethods, scaled down in a specific way to allow for scalability while keeping\nsome of their key mathematical properties.\n", "contributors": [{"name": "Ollivier, Yann", "sameAs": [], "familyName": "Ollivier", "additionalName": "", "givenName": "Yann", "email": ""}], "title": "Riemannian metrics for neural networks I: feedforward networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-03-04", "2015-02-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1303.0818", "oai:arXiv.org:1303.0818"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We describe four algorithms for neural network training, each adapted to\ndifferent scalability constraints. These algorithms are mathematically\nprincipled and invariant under a number of transformations in data and network\nrepresentation, from which performance is thus independent. These algorithms\nare obtained from the setting of differential geometry, and are based on either\nthe natural gradient using the Fisher information matrix, or on Hessian\nmethods, scaled down in a specific way to allow for scalability while keeping\nsome of their key mathematical properties.\n", "Comment: (5th version, minor changes)"]}}], "languages": [null], "subjects": ["mathematics - differential geometry", "68t05", "computer science - neural and evolutionary computing", "computer science - information theory", "computer science - learning"], "providerUpdatedDateTime": "2015-02-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1303.0818"}}, {"publisher": {"name": ""}, "description": "  In this work, we propose and study optimal proactive resource allocation and\ndemand shaping for data networks. Motivated by the recent findings on the\npredictability of human behavior patterns in data networks, and the emergence\nof highly capable handheld devices, our design aims to smooth out the network\ntraffic over time and minimize the data delivery costs.\n  Our framework utilizes proactive data services as well as smart content\nrecommendation schemes for shaping the demand. Proactive data services take\nplace during the off-peak hours based on a statistical prediction of a demand\nprofile for each user, whereas smart content recommendation assigns modified\nvaluations to data items so as to render the users' demand less uncertain.\nHence, our recommendation scheme aims to boost the performance of proactive\nservices within the allowed flexibility of user requirements. We conduct\ntheoretical performance analysis that quantifies the leveraged cost reduction\nthrough the proposed framework. We show that the cost reduction scales at the\nsame rate as the cost function scales with the number of users. Further, we\nprove that \\emph{demand shaping} through smart recommendation strictly reduces\nthe incurred cost even below that of proactive downloads without\nrecommendation.\n", "contributors": [{"name": "Tadrous, John", "sameAs": [], "familyName": "Tadrous", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Eryilmaz, Atilla", "sameAs": [], "familyName": "Eryilmaz", "additionalName": "", "givenName": "Atilla", "email": ""}, {"name": "Gamal, Hesham El", "sameAs": [], "familyName": "Gamal", "additionalName": "El", "givenName": "Hesham", "email": ""}], "title": "Proactive Data Download and User Demand Shaping for Data Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-04-21", "2014-12-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1304.5745", "oai:arXiv.org:1304.5745"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this work, we propose and study optimal proactive resource allocation and\ndemand shaping for data networks. Motivated by the recent findings on the\npredictability of human behavior patterns in data networks, and the emergence\nof highly capable handheld devices, our design aims to smooth out the network\ntraffic over time and minimize the data delivery costs.\n  Our framework utilizes proactive data services as well as smart content\nrecommendation schemes for shaping the demand. Proactive data services take\nplace during the off-peak hours based on a statistical prediction of a demand\nprofile for each user, whereas smart content recommendation assigns modified\nvaluations to data items so as to render the users' demand less uncertain.\nHence, our recommendation scheme aims to boost the performance of proactive\nservices within the allowed flexibility of user requirements. We conduct\ntheoretical performance analysis that quantifies the leveraged cost reduction\nthrough the proposed framework. We show that the cost reduction scales at the\nsame rate as the cost function scales with the number of users. Further, we\nprove that \\emph{demand shaping} through smart recommendation strictly reduces\nthe incurred cost even below that of proactive downloads without\nrecommendation.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1304.5745"}}, {"publisher": {"name": ""}, "description": "  We provide a comprehensive view of various phase transitions in random\n$K$-satisfiability problems solved by stochastic-local-search algorithms. In\nparticular, we focus on the finite-size scaling (FSS) exponent, which is\nmathematically important and practically useful in analyzing finite systems.\nUsing the FSS theory of nonequilibrium absorbing phase transitions, we show\nthat the density of unsatisfied clauses clearly indicates the transition from\nthe solvable (absorbing) phase to the unsolvable (active) phase as varying the\nnoise parameter and the density of constraints. Based on the solution\nclustering (percolation-type) argument, we conjecture two possible values of\nthe FSS exponent, which are confirmed reasonably well in numerical simulations\nfor $2\\le K \\le 3$.\n", "contributors": [{"name": "Lee, Sang Hoon", "sameAs": [], "familyName": "Lee", "additionalName": "Hoon", "givenName": "Sang", "email": ""}, {"name": "Ha, Meesoon", "sameAs": [], "familyName": "Ha", "additionalName": "", "givenName": "Meesoon", "email": ""}, {"name": "Jeon, Chanil", "sameAs": [], "familyName": "Jeon", "additionalName": "", "givenName": "Chanil", "email": ""}, {"name": "Jeong, Hawoong", "sameAs": [], "familyName": "Jeong", "additionalName": "", "givenName": "Hawoong", "email": ""}], "title": "Finite-size scaling in random $K$-satisfiability problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-05-03", "2010-12-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.0251", "PRE v82, 061109 (2010)", "doi:10.1103/PhysRevE.82.061109", "oai:arXiv.org:1005.0251"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We provide a comprehensive view of various phase transitions in random\n$K$-satisfiability problems solved by stochastic-local-search algorithms. In\nparticular, we focus on the finite-size scaling (FSS) exponent, which is\nmathematically important and practically useful in analyzing finite systems.\nUsing the FSS theory of nonequilibrium absorbing phase transitions, we show\nthat the density of unsatisfied clauses clearly indicates the transition from\nthe solvable (absorbing) phase to the unsolvable (active) phase as varying the\nnoise parameter and the density of constraints. Based on the solution\nclustering (percolation-type) argument, we conjecture two possible values of\nthe FSS exponent, which are confirmed reasonably well in numerical simulations\nfor $2\\le K \\le 3$.\n", "Comment: 5 pages, 3 figures (6 eps files), 1 table; published version"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "physics - computational physics", "condensed matter - statistical mechanics"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.0251"}}, {"publisher": {"name": ""}, "description": "  Novel energy-aware cloud management methods dynamically reallocate\ncomputation across geographically distributed data centers to leverage regional\nelectricity price and temperature differences. As a result, a managed VM may\nsuffer occasional downtimes. Current cloud providers only offer high\navailability VMs, without enough flexibility to apply such energy-aware\nmanagement. In this paper we show how to analyse past traces of dynamic cloud\nmanagement actions based on electricity prices and temperatures to estimate VM\navailability and price values. We propose a novel SLA specification approach\nfor offering VMs with different availability and price values guaranteed over\nmultiple SLAs to enable flexible energy-aware cloud management. We determine\nthe optimal number of such SLAs as well as their availability and price\nguaranteed values. We evaluate our approach in a user SLA selection simulation\nusing Wikipedia and Grid'5000 workloads. The results show higher customer\nconversion and 39% average energy savings per VM.\n", "contributors": [{"name": "Lu\u010danin, Dra\u017een", "sameAs": [], "familyName": "Lu\u010danin", "additionalName": "", "givenName": "Dra\u017een", "email": ""}, {"name": "Jrad, Foued", "sameAs": [], "familyName": "Jrad", "additionalName": "", "givenName": "Foued", "email": ""}, {"name": "Brandic, Ivona", "sameAs": [], "familyName": "Brandic", "additionalName": "", "givenName": "Ivona", "email": ""}, {"name": "Streit, Achim", "sameAs": [], "familyName": "Streit", "additionalName": "", "givenName": "Achim", "email": ""}], "title": "Energy-Aware Cloud Management through Progressive SLA Specification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-09-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.0325", "doi:10.1007/978-3-319-14609-6", "oai:arXiv.org:1409.0325"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Novel energy-aware cloud management methods dynamically reallocate\ncomputation across geographically distributed data centers to leverage regional\nelectricity price and temperature differences. As a result, a managed VM may\nsuffer occasional downtimes. Current cloud providers only offer high\navailability VMs, without enough flexibility to apply such energy-aware\nmanagement. In this paper we show how to analyse past traces of dynamic cloud\nmanagement actions based on electricity prices and temperatures to estimate VM\navailability and price values. We propose a novel SLA specification approach\nfor offering VMs with different availability and price values guaranteed over\nmultiple SLAs to enable flexible energy-aware cloud management. We determine\nthe optimal number of such SLAs as well as their availability and price\nguaranteed values. We evaluate our approach in a user SLA selection simulation\nusing Wikipedia and Grid'5000 workloads. The results show higher customer\nconversion and 39% average energy savings per VM.\n", "Comment: 14 pages, conference"]}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.0325"}}, {"publisher": {"name": ""}, "description": "  The essential variables in a finite function $f$ are defined as variables\nwhich occur in $f$ and weigh with the values of that function.\n  The number of essential variables is an important measure of complexity for\ndiscrete functions.\n  When replacing some variables in a function with constants the resulting\nfunctions are called subfunctions, and when replacing all essential variables\nin a function with constants we obtain an implementation of this function.\n  Such an implementation corresponds with a path in an ordered decision diagram\n(ODD) of the function which connects the root with a leaf of the diagram. The\nsets of essential variables in subfunctions of $f$ are called separable in $f$.\nIn this paper we study several properties of separable sets of variables in\nfunctions which directly impact on the number of implementations and\nsubfunctions in these functions.\n  We define equivalence relations which classify the functions of $k$-valued\nlogic into classes with same number of implementations, subfunctions or\nseparable sets. These relations induce three transformation groups which are\ncompared with the lattice of all subgroups of restricted affine group (RAG).\nThis allows us to solve several important computational and combinatorial\nproblems.\n", "contributors": [{"name": "Shtrakov, Sl.", "sameAs": [], "familyName": "Shtrakov", "additionalName": "", "givenName": "Sl.", "email": ""}, {"name": "Damyanov, I.", "sameAs": [], "familyName": "Damyanov", "additionalName": "", "givenName": "I.", "email": ""}], "title": "On the complexity of finite valued functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00265", "oai:arXiv.org:1501.00265"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The essential variables in a finite function $f$ are defined as variables\nwhich occur in $f$ and weigh with the values of that function.\n  The number of essential variables is an important measure of complexity for\ndiscrete functions.\n  When replacing some variables in a function with constants the resulting\nfunctions are called subfunctions, and when replacing all essential variables\nin a function with constants we obtain an implementation of this function.\n  Such an implementation corresponds with a path in an ordered decision diagram\n(ODD) of the function which connects the root with a leaf of the diagram. The\nsets of essential variables in subfunctions of $f$ are called separable in $f$.\nIn this paper we study several properties of separable sets of variables in\nfunctions which directly impact on the number of implementations and\nsubfunctions in these functions.\n  We define equivalence relations which classify the functions of $k$-valued\nlogic into classes with same number of implementations, subfunctions or\nseparable sets. These relations induce three transformation groups which are\ncompared with the lattice of all subgroups of restricted affine group (RAG).\nThis allows us to solve several important computational and combinatorial\nproblems.\n", "Comment: 23 pages, 4 figures, 6 tables, Preprint of the article is submitted\n  for consideration in [WSPC (2015)]\n  [http://www.worldscientific.com/worldscinet/ijfcs]"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "03d15", "f.1.3"], "providerUpdatedDateTime": "2015-01-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00265"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Thesis. 1975. Ph.D.--Massachusetts Institute of Technology. Dept. of Chemistry.", "contributors": [{"name": "McDermott, Joseph Xavier", "sameAs": [], "familyName": "McDermott", "additionalName": "Xavier", "givenName": "Joseph", "email": ""}, {"name": "G.M. Whitesides.", "sameAs": [], "familyName": "Whitesides.", "additionalName": "", "givenName": "G.M.", "email": ""}], "title": "Platinum and titanium metallocycles.", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "135 leaves"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/80423", "01331355", "oai:dspace.mit.edu:1721.1/80423"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2013-09-12T19:00:09Z", "2013-09-12T19:00:09Z", "1975"]}}, {"name": "description", "properties": {"description": ["Thesis. 1975. Ph.D.--Massachusetts Institute of Technology. Dept. of Chemistry.", "Vita.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7646", "hdl_1721.1_7794"]}}], "languages": [null], "subjects": ["organoplatinum compounds", "chemistry", "transition metal compounds", "organotitanium compounds", "decomposition (chemistry)"], "providerUpdatedDateTime": "2015-04-27T22:56:24", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/80423"}}, {"publisher": {"name": ""}, "description": "  We consider two CSP problems: the first CSP encodes 2D Sperner's lemma for\nthe standard triangulation of the right triangle on $n^2$ small triangles; the\nsecond CSP encodes the fact that it is impossible to match cells of $n \\times\nn$ square to arrows (two horizontal, two vertical and four diagonal) such that\narrows in two cells with a common edge differ by at most $45^\\circ$, and all\narrows on the boundary of the square do not look outside (this fact is a\ncorollary of the Brower's fixed point theorem). We prove that the tree-like\nresolution complexities of these CSPs are $2^{\\Theta(n)}$. For Sperner's lemma\nour result implies $\\Omega(n)$ lower bound on the number of request to colors\nof vertices that is enough to make in order to find a trichromatic triangle;\nthis lower bound was originally proved by Crescenzi and Silvestri.\n  CSP based on Sperner's lemma is related with the $\\rm PPAD$-complete problem.\nWe show that CSP corresponding to arrows is also related with a $\\rm\nPPAD$-complete problem.\n", "contributors": [{"name": "Itsykson, Dmitry", "sameAs": [], "familyName": "Itsykson", "additionalName": "", "givenName": "Dmitry", "email": ""}, {"name": "Malova, Anna", "sameAs": [], "familyName": "Malova", "additionalName": "", "givenName": "Anna", "email": ""}, {"name": "Oparin, Vsevolod", "sameAs": [], "familyName": "Oparin", "additionalName": "", "givenName": "Vsevolod", "email": ""}, {"name": "Sokolov, Dmitry", "sameAs": [], "familyName": "Sokolov", "additionalName": "", "givenName": "Dmitry", "email": ""}], "title": "Tree-like resolution complexity of two planar problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1124", "oai:arXiv.org:1412.1124"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We consider two CSP problems: the first CSP encodes 2D Sperner's lemma for\nthe standard triangulation of the right triangle on $n^2$ small triangles; the\nsecond CSP encodes the fact that it is impossible to match cells of $n \\times\nn$ square to arrows (two horizontal, two vertical and four diagonal) such that\narrows in two cells with a common edge differ by at most $45^\\circ$, and all\narrows on the boundary of the square do not look outside (this fact is a\ncorollary of the Brower's fixed point theorem). We prove that the tree-like\nresolution complexities of these CSPs are $2^{\\Theta(n)}$. For Sperner's lemma\nour result implies $\\Omega(n)$ lower bound on the number of request to colors\nof vertices that is enough to make in order to find a trichromatic triangle;\nthis lower bound was originally proved by Crescenzi and Silvestri.\n  CSP based on Sperner's lemma is related with the $\\rm PPAD$-complete problem.\nWe show that CSP corresponding to arrows is also related with a $\\rm\nPPAD$-complete problem.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "f.2.2", "68q25"], "providerUpdatedDateTime": "2014-12-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1124"}}, {"publisher": {"name": ""}, "description": "  Implicit electron-density solvation models based on joint density-functional\ntheory offer a computationally efficient solution to the problem of calculating\nthermodynamic quantities of solvated systems from firstprinciples quantum\nmechanics. However, despite much recent interest in such models, to date the\napplicability of such models in the plane-wave context to non-aqueous solvents\nhas been limited because the determination of the model parameters requires\nfitting to a large database of experimental solvation energies for each new\nsolvent considered. This work presents an alternate approach which allows\ndevelopment of new iso-density models for a large class of protic and aprotic\nsolvents from only simple, single-molecule ab initio calculations and readily\navailable bulk thermodynamic data.\n", "contributors": [{"name": "Gunceler, Deniz", "sameAs": [], "familyName": "Gunceler", "additionalName": "", "givenName": "Deniz", "email": ""}, {"name": "Arias, T. A.", "sameAs": [], "familyName": "Arias", "additionalName": "A.", "givenName": "T.", "email": ""}], "title": "Universal iso-density polarizable continuum model for molecular solvents", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-25", "2015-02-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.6465", "oai:arXiv.org:1403.6465"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Implicit electron-density solvation models based on joint density-functional\ntheory offer a computationally efficient solution to the problem of calculating\nthermodynamic quantities of solvated systems from firstprinciples quantum\nmechanics. However, despite much recent interest in such models, to date the\napplicability of such models in the plane-wave context to non-aqueous solvents\nhas been limited because the determination of the model parameters requires\nfitting to a large database of experimental solvation energies for each new\nsolvent considered. This work presents an alternate approach which allows\ndevelopment of new iso-density models for a large class of protic and aprotic\nsolvents from only simple, single-molecule ab initio calculations and readily\navailable bulk thermodynamic data.\n"}}], "languages": [null], "subjects": ["physics - computational physics", "physics - chemical physics", "condensed matter - materials science"], "providerUpdatedDateTime": "2015-02-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.6465"}}, {"publisher": {"name": ""}, "description": "  Cloud Data centers aim to provide reliable, sustainable and scalable services\nfor all kinds of applications. Resource scheduling is one of keys to cloud\nservices. To model and evaluate different scheduling policies and algorithms,\nwe propose FlexCloud, a flexible and scalable simulator that enables users to\nsimulate the process of initializing cloud data centers, allocating virtual\nmachine requests and providing performance evaluation for various scheduling\nalgorithms. FlexCloud can be run on a single computer with JVM to simulate\nlarge scale cloud environments with focus on infrastructure as a service;\nadopts agile design patterns to assure the flexibility and extensibility;\nmodels virtual machine migrations which is lack in the existing tools; provides\nuser-friendly interfaces for customized configurations and replaying. Comparing\nto existing simulators, FlexCloud has combining features for supporting public\ncloud providers, load-balance and energy-efficiency scheduling. FlexCloud has\nadvantage in computing time and memory consumption to support large-scale\nsimulations. The detailed design of FlexCloud is introduced and performance\nevaluation is provided.\n", "contributors": [{"name": "Xu, Minxian", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Minxian", "email": ""}, {"name": "Tian, Wenhong", "sameAs": [], "familyName": "Tian", "additionalName": "", "givenName": "Wenhong", "email": ""}, {"name": "Wang, Xinyang", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Xinyang", "email": ""}, {"name": "Xiong, Qin", "sameAs": [], "familyName": "Xiong", "additionalName": "", "givenName": "Qin", "email": ""}], "title": "FlexCloud: A Flexible and Extendible Simulator for Performance\n  Evaluation of Virtual Machine Allocation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05789", "oai:arXiv.org:1501.05789"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Cloud Data centers aim to provide reliable, sustainable and scalable services\nfor all kinds of applications. Resource scheduling is one of keys to cloud\nservices. To model and evaluate different scheduling policies and algorithms,\nwe propose FlexCloud, a flexible and scalable simulator that enables users to\nsimulate the process of initializing cloud data centers, allocating virtual\nmachine requests and providing performance evaluation for various scheduling\nalgorithms. FlexCloud can be run on a single computer with JVM to simulate\nlarge scale cloud environments with focus on infrastructure as a service;\nadopts agile design patterns to assure the flexibility and extensibility;\nmodels virtual machine migrations which is lack in the existing tools; provides\nuser-friendly interfaces for customized configurations and replaying. Comparing\nto existing simulators, FlexCloud has combining features for supporting public\ncloud providers, load-balance and energy-efficiency scheduling. FlexCloud has\nadvantage in computing time and memory consumption to support large-scale\nsimulations. The detailed design of FlexCloud is introduced and performance\nevaluation is provided.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05789"}}, {"publisher": {"name": ""}, "description": "  Location and mobility patterns of individuals are important to environmental\nplanning, societal resilience, public health, and a host of commercial\napplications. Mining telecommunication traffic and transactions data for such\npurposes is controversial, in particular raising issues of privacy. However,\nour hypothesis is that privacy-sensitive uses are possible and often beneficial\nenough to warrant considerable research and development efforts. Our work\ncontends that peoples behavior can yield patterns of both significant\ncommercial, and research, value. For such purposes, methods and algorithms for\nmining telecommunication data to extract commonly used routes and locations,\narticulated through time-geographical constructs, are described in a case study\nwithin the area of transportation planning and analysis. From the outset, these\nwere designed to balance the privacy of subscribers and the added value of\nmobility patterns derived from their mobile communication traffic and\ntransactions data. Our work directly contrasts the current, commonly held\nnotion that value can only be added to services by directly monitoring the\nbehavior of individuals, such as in current attempts at location-based\nservices. We position our work within relevant legal frameworks for privacy and\ndata protection, and show that our methods comply with such requirements and\nalso follow best-practices\n", "contributors": [{"name": "Sanches, Pedro", "sameAs": [], "familyName": "Sanches", "additionalName": "", "givenName": "Pedro", "email": ""}, {"name": "Svee, Eric-Oluf", "sameAs": [], "familyName": "Svee", "additionalName": "", "givenName": "Eric-Oluf", "email": ""}, {"name": "Bylund, Markus", "sameAs": [], "familyName": "Bylund", "additionalName": "", "givenName": "Markus", "email": ""}, {"name": "Hirsch, Benjamin", "sameAs": [], "familyName": "Hirsch", "additionalName": "", "givenName": "Benjamin", "email": ""}, {"name": "Boman, Magnus", "sameAs": [], "familyName": "Boman", "additionalName": "", "givenName": "Magnus", "email": ""}], "title": "Knowing Your Population: Privacy-Sensitive Mining of Massive Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2247", "Network and Communication Technologies 2, no. 1 (2013): p34", "doi:10.5539/nct.v2n1p34", "oai:arXiv.org:1412.2247"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Location and mobility patterns of individuals are important to environmental\nplanning, societal resilience, public health, and a host of commercial\napplications. Mining telecommunication traffic and transactions data for such\npurposes is controversial, in particular raising issues of privacy. However,\nour hypothesis is that privacy-sensitive uses are possible and often beneficial\nenough to warrant considerable research and development efforts. Our work\ncontends that peoples behavior can yield patterns of both significant\ncommercial, and research, value. For such purposes, methods and algorithms for\nmining telecommunication data to extract commonly used routes and locations,\narticulated through time-geographical constructs, are described in a case study\nwithin the area of transportation planning and analysis. From the outset, these\nwere designed to balance the privacy of subscribers and the added value of\nmobility patterns derived from their mobile communication traffic and\ntransactions data. Our work directly contrasts the current, commonly held\nnotion that value can only be added to services by directly monitoring the\nbehavior of individuals, such as in current attempts at location-based\nservices. We position our work within relevant legal frameworks for privacy and\ndata protection, and show that our methods comply with such requirements and\nalso follow best-practices\n"}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2247"}}, {"publisher": {"name": ""}, "description": "  The $\\beta$-skeleton $\\{G_{\\beta}(V)\\}$ for a point set V is a family of\ngeometric graphs, defined by the notion of neighborhoods parameterized by real\nnumber $0 < \\beta < \\infty$. By using the distance-based version definition of\n$\\beta$-skeletons we study those graphs for a set of points in $\\mathbb{R}^d$\nspace with $l_1$ and $l_{\\infty}$ metrics. We present algorithms for the entire\nspectrum of $\\beta$ values and we discuss properties of lens-based and\ncircle-based $\\beta$-skeletons in those metrics.\n  Let $V \\in \\mathbb{R}^d$ in $L_{\\infty}$ metric be a set of $n$ points in\ngeneral position. Then, for $\\beta<2$ lens-based $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$\nthere exists an $O(n \\log^{d-1} n)$ time algorithm that constructs\n$\\beta$-skeleton for the set $V$. We show that in $\\mathbb{R}^d$ with\n$L_{\\infty}$ metric, for $\\beta<2$ $\\beta$-skeleton $G_{\\beta}(V)$ for $n$\npoints can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$ there\nexists an $O(n \\log^{d-1} n)$ time algorithm. In $\\mathbb{R}^d$ with $L_1$\nmetric for a set of $n$ points in arbitrary position $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^{d+2} n)$ time.\n", "contributors": [{"name": "Kowaluk, Miros\u0142aw", "sameAs": [], "familyName": "Kowaluk", "additionalName": "", "givenName": "Miros\u0142aw", "email": ""}, {"name": "Majewska, Gabriela", "sameAs": [], "familyName": "Majewska", "additionalName": "", "givenName": "Gabriela", "email": ""}], "title": "Multidimensional $\\beta$-skeletons in $L_1$ and $L_{\\infty}$ metric", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5472", "oai:arXiv.org:1411.5472"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The $\\beta$-skeleton $\\{G_{\\beta}(V)\\}$ for a point set V is a family of\ngeometric graphs, defined by the notion of neighborhoods parameterized by real\nnumber $0 < \\beta < \\infty$. By using the distance-based version definition of\n$\\beta$-skeletons we study those graphs for a set of points in $\\mathbb{R}^d$\nspace with $l_1$ and $l_{\\infty}$ metrics. We present algorithms for the entire\nspectrum of $\\beta$ values and we discuss properties of lens-based and\ncircle-based $\\beta$-skeletons in those metrics.\n  Let $V \\in \\mathbb{R}^d$ in $L_{\\infty}$ metric be a set of $n$ points in\ngeneral position. Then, for $\\beta<2$ lens-based $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$\nthere exists an $O(n \\log^{d-1} n)$ time algorithm that constructs\n$\\beta$-skeleton for the set $V$. We show that in $\\mathbb{R}^d$ with\n$L_{\\infty}$ metric, for $\\beta<2$ $\\beta$-skeleton $G_{\\beta}(V)$ for $n$\npoints can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$ there\nexists an $O(n \\log^{d-1} n)$ time algorithm. In $\\mathbb{R}^d$ with $L_1$\nmetric for a set of $n$ points in arbitrary position $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^{d+2} n)$ time.\n"}}], "languages": [null], "subjects": ["computer science - computational geometry"], "providerUpdatedDateTime": "2014-11-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5472"}}, {"publisher": {"name": ""}, "description": "  We show that very simple algorithms based on local search are polynomial-time\napproximation schemes for Maximum Independent Set, Minimum Vertex Cover and\nMinimum Dominating Set, when the input graphs have a fixed forbidden minor.\n", "contributors": [{"name": "Cabello, Sergio", "sameAs": [], "familyName": "Cabello", "additionalName": "", "givenName": "Sergio", "email": ""}, {"name": "Gajser, David", "sameAs": [], "familyName": "Gajser", "additionalName": "", "givenName": "David", "email": ""}], "title": "Simple PTAS's for families of graphs excluding a minor", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-21", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5778", "oai:arXiv.org:1410.5778"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We show that very simple algorithms based on local search are polynomial-time\napproximation schemes for Maximum Independent Set, Minimum Vertex Cover and\nMinimum Dominating Set, when the input graphs have a fixed forbidden minor.\n", "Comment: To appear in Discrete Applied Mathematics"]}}], "languages": [null], "subjects": ["05c83", "computer science - discrete mathematics", "68w40", "computer science - data structures and algorithms", "05c85", "68w25"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5778"}}, {"publisher": {"name": ""}, "description": "  In the case of ordinary identification coding, a code is devised to identify\na single object among $N$ objects. But, in this paper, we consider an\nidentification coding problem to identify $K$ objects at once among $N$ objects\nin the both cases that $K$ objects are ranked or not ranked. By combining\nKurosawa-Yoshida scheme with Moulin-Koetter scheme, an efficient identification\ncoding scheme is proposed, which can attain high coding rate and error\nexponents compared with the case that an ordinary identification code is used\n$K$ times. Furthermore, the achievable triplet of rate and error exponents of\ntype I and type II decoding error probabilities are derived for the proposed\ncoding scheme.\n", "contributors": [{"name": "Yamamoto, Hirosuke", "sameAs": [], "familyName": "Yamamoto", "additionalName": "", "givenName": "Hirosuke", "email": ""}, {"name": "Ueda, Masashi", "sameAs": [], "familyName": "Ueda", "additionalName": "", "givenName": "Masashi", "email": ""}], "title": "Identification Codes to Identify Multiple Objects", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4612", "oai:arXiv.org:1410.4612"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In the case of ordinary identification coding, a code is devised to identify\na single object among $N$ objects. But, in this paper, we consider an\nidentification coding problem to identify $K$ objects at once among $N$ objects\nin the both cases that $K$ objects are ranked or not ranked. By combining\nKurosawa-Yoshida scheme with Moulin-Koetter scheme, an efficient identification\ncoding scheme is proposed, which can attain high coding rate and error\nexponents compared with the case that an ordinary identification code is used\n$K$ times. Furthermore, the achievable triplet of rate and error exponents of\ntype I and type II decoding error probabilities are derived for the proposed\ncoding scheme.\n", "Comment: 14 pages, submitted to IEEE Transactions on Information Theory"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4612"}}, {"publisher": {"name": ""}, "description": "  In the present article, a new system architecture for the next generation of\nsatellite communication (SatComs) is presented. The key concept lies in the\ncollaboration between multibeam satellites that share one orbital position.\nMulti-satellite constellations in unique orbital slots offer gradual deployment\nto cover unpredictable traffic patterns and redundancy to hardware failure\nadvantages. They are also of high relevance during the satellite replacement\nphases or necessitated by constraints in the maximum communications payload\nthat a single satellite can bear. In this context, the potential gains of\nadvanced architectures, that is architectures enabled by the general class of\ncooperative and cognitive techniques, are exhibited via a simple paradigm. More\nspecifically, the scenario presented herein, involves two co-existing multibeam\nsatellites which illuminate overlapping coverage areas. Based on this scenario,\nspecific types of cooperative and cognitive techniques are herein considered as\ncandidate technologies that can boost the performance of multibeam satellite\nconstellations. These techniques are compared to conventional frequency\nsplitting configurations in terms of three different criteria, namely the\nspectral efficiency, the power efficiency and the fairness. Consequently,\ninsightful guidelines for the design of future high throughput constellations\nof multibeam satellites are given.\n", "contributors": [{"name": "Christopoulos, Dimitrios", "sameAs": [], "familyName": "Christopoulos", "additionalName": "", "givenName": "Dimitrios", "email": ""}, {"name": "Sharma, Shree Krishna", "sameAs": [], "familyName": "Sharma", "additionalName": "Krishna", "givenName": "Shree", "email": ""}, {"name": "Chatzinotas, Symeon", "sameAs": [], "familyName": "Chatzinotas", "additionalName": "", "givenName": "Symeon", "email": ""}, {"name": "Ottersten, Jens Krauseand Bjorn", "sameAs": [], "familyName": "Ottersten", "additionalName": "Krauseand Bjorn", "givenName": "Jens", "email": ""}], "title": "Coordinated Multibeam Satellite Co-location: The Dual Satellite Paradigm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06981", "oai:arXiv.org:1503.06981"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In the present article, a new system architecture for the next generation of\nsatellite communication (SatComs) is presented. The key concept lies in the\ncollaboration between multibeam satellites that share one orbital position.\nMulti-satellite constellations in unique orbital slots offer gradual deployment\nto cover unpredictable traffic patterns and redundancy to hardware failure\nadvantages. They are also of high relevance during the satellite replacement\nphases or necessitated by constraints in the maximum communications payload\nthat a single satellite can bear. In this context, the potential gains of\nadvanced architectures, that is architectures enabled by the general class of\ncooperative and cognitive techniques, are exhibited via a simple paradigm. More\nspecifically, the scenario presented herein, involves two co-existing multibeam\nsatellites which illuminate overlapping coverage areas. Based on this scenario,\nspecific types of cooperative and cognitive techniques are herein considered as\ncandidate technologies that can boost the performance of multibeam satellite\nconstellations. These techniques are compared to conventional frequency\nsplitting configurations in terms of three different criteria, namely the\nspectral efficiency, the power efficiency and the fairness. Consequently,\ninsightful guidelines for the design of future high throughput constellations\nof multibeam satellites are given.\n", "Comment: Submitted to the IEEE wirless. Comms. Magazine"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06981"}}, {"publisher": {"name": ""}, "description": "  The proliferation of online social networks in the last decade has not\nstopped short of pets, and many different online platforms now exist catering\nto owners of various pets such as cats and dogs. These online pet social\nnetworks provide a unique opportunity to study an online social network in\nwhich a single user manages multiple user profiles, i.e. one for each pet they\nown. These types of multi-profile networks allow us to investigate two\nquestions: (1) What is the relationship between the pet-level and human-level\nnetwork, and (2) what is the relationship between friendship links and family\nties? Concretely, we study the online social pet networks Catster, Dogster and\nHamsterster, the first two of which are the two largest online pet networks in\nexistence. We show how the networks on the two levels interact, and perform\nexperiments to find out whether knowledge about friendships on a profile-level\nalone can be used to predict which users are behind which profile. In order to\ndo so, we introduce the concept of multi-profile social network, extend a\npreviously defined spectral test of diagonality to multi-profile networks,\ndefine two new homophily measures for multi-profile social networks, perform a\ntwo-level social network analysis, and present an algorithm for predicting\nwhether two profiles were created by the same user. As a result, we are able to\npredict with very high precision whether two profiles were created by a same\nuser. Our work is thus relevant for the analysis of other online communities in\nwhich users may use multiple profiles.\n", "contributors": [{"name": "D\u00fcnker, Daniel", "sameAs": [], "familyName": "D\u00fcnker", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Kunegis, J\u00e9r\u00f4me", "sameAs": [], "familyName": "Kunegis", "additionalName": "", "givenName": "J\u00e9r\u00f4me", "email": ""}], "title": "Social Networking by Proxy: A Case Study of Catster, Dogster and\n  Hamsterster", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04527", "oai:arXiv.org:1501.04527"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The proliferation of online social networks in the last decade has not\nstopped short of pets, and many different online platforms now exist catering\nto owners of various pets such as cats and dogs. These online pet social\nnetworks provide a unique opportunity to study an online social network in\nwhich a single user manages multiple user profiles, i.e. one for each pet they\nown. These types of multi-profile networks allow us to investigate two\nquestions: (1) What is the relationship between the pet-level and human-level\nnetwork, and (2) what is the relationship between friendship links and family\nties? Concretely, we study the online social pet networks Catster, Dogster and\nHamsterster, the first two of which are the two largest online pet networks in\nexistence. We show how the networks on the two levels interact, and perform\nexperiments to find out whether knowledge about friendships on a profile-level\nalone can be used to predict which users are behind which profile. In order to\ndo so, we introduce the concept of multi-profile social network, extend a\npreviously defined spectral test of diagonality to multi-profile networks,\ndefine two new homophily measures for multi-profile social networks, perform a\ntwo-level social network analysis, and present an algorithm for predicting\nwhether two profiles were created by the same user. As a result, we are able to\npredict with very high precision whether two profiles were created by a same\nuser. Our work is thus relevant for the analysis of other online communities in\nwhich users may use multiple profiles.\n", "Comment: 10 pages"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04527"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Understanding the microbial world is key to understanding global biogeochemistry, human health and disease, yet this world is largely inaccessible. Microbial genomes, an increasingly accessible data source, provide an ideal entry point. The genome sequences of different microbes may be compared using the tools of population genetics to infer important genetic changes allowing them to diversify ecologically and adapt to distinct ecological niches. Yet the toolkit of population genetics was developed largely with sexual eukaryotes in mind. In this work, I assess and develop tools for inferring natural selection in microbial genomes. Many tools rely on population genetics theory, and thus require defining distinct populations, or species, of bacteria. Because sex (recombination) is not required for reproduction, some bacteria recombine only rarely, while others are extremely promiscuous, exchanging genes across great genetic distances. This behavior poses a challenge for defining microbial population boundaries. This thesis begins with a discussion of how recombination and positive selection interact to promote ecological adaptation. I then describe a general pipeline for quantifying the impacts of mutation, recombination and selection on microbial genomes, and apply it to two closely related, yet ecologically distinct populations of Vibrio splendidus, each with its own microhabitat preference. I introduce a new tool, STARRInIGHTS, for inferring homologous recombination events. By assessing rates of recombination within and between ecological populations, I conclude that ecological differentiation is driven by small number of habitat-specific alleles, while most loci are shared freely across habitats. The remainder of the thesis focuses on lineage-specific changes in natural selection among anciently diverged species of gamma proteobacteria. I develop two new metrics, selective signatures and slow:fast, for detecting deviations from the expected rate of evolution in 'core' proteins (present in single copy in most species). Because they rely on empirical distributions of evolutionary rates across species, these methods should become increasingly powerful as more and more microbial genomes are sampled. Overall, the methods described here significantly expand the repertoire of tools available for microbial population genomics, both for investigating the process of ecological differentiation at the finest of time scales, and over billions of years of microbial evolution.", "contributors": [{"name": "Shapiro, B. Jesse (Benjamin Jesse)", "sameAs": [], "familyName": "Shapiro", "additionalName": "Jesse", "givenName": "B.", "email": ""}, {"name": "Massachusetts Institute of Technology. Computational and Systems Biology Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computational and Systems Biology", "givenName": "Massachusetts", "email": ""}, {"name": "Eric J. Alm.", "sameAs": [], "familyName": "Alm.", "additionalName": "J.", "givenName": "Eric", "email": ""}], "title": "Genomic signatures of sex, selection and speciation in the microbial world", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "228 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/61788", "706715014", "oai:dspace.mit.edu:1721.1/61788"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2011-03-24T18:52:25Z", "2011-03-24T18:52:25Z", "2010", "2010"]}}, {"name": "description", "properties": {"description": ["Understanding the microbial world is key to understanding global biogeochemistry, human health and disease, yet this world is largely inaccessible. Microbial genomes, an increasingly accessible data source, provide an ideal entry point. The genome sequences of different microbes may be compared using the tools of population genetics to infer important genetic changes allowing them to diversify ecologically and adapt to distinct ecological niches. Yet the toolkit of population genetics was developed largely with sexual eukaryotes in mind. In this work, I assess and develop tools for inferring natural selection in microbial genomes. Many tools rely on population genetics theory, and thus require defining distinct populations, or species, of bacteria. Because sex (recombination) is not required for reproduction, some bacteria recombine only rarely, while others are extremely promiscuous, exchanging genes across great genetic distances. This behavior poses a challenge for defining microbial population boundaries. This thesis begins with a discussion of how recombination and positive selection interact to promote ecological adaptation. I then describe a general pipeline for quantifying the impacts of mutation, recombination and selection on microbial genomes, and apply it to two closely related, yet ecologically distinct populations of Vibrio splendidus, each with its own microhabitat preference. I introduce a new tool, STARRInIGHTS, for inferring homologous recombination events. By assessing rates of recombination within and between ecological populations, I conclude that ecological differentiation is driven by small number of habitat-specific alleles, while most loci are shared freely across habitats. The remainder of the thesis focuses on lineage-specific changes in natural selection among anciently diverged species of gamma proteobacteria. I develop two new metrics, selective signatures and slow:fast, for detecting deviations from the expected rate of evolution in 'core' proteins (present in single copy in most species). Because they rely on empirical distributions of evolutionary rates across species, these methods should become increasingly powerful as more and more microbial genomes are sampled. Overall, the methods described here significantly expand the repertoire of tools available for microbial population genomics, both for investigating the process of ecological differentiation at the finest of time scales, and over billions of years of microbial evolution.", "by B. Jesse Shapiro.", "Thesis (Ph. D.)--Massachusetts Institute of Technology, Computational and Systems Biology Program, 2010.", "This electronic version was submitted by the student author.  The certified thesis is available in the Institute Archives and Special Collections.", "Cataloged from student-submitted PDF version of thesis.", "Includes bibliographical references (p. 218-228)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_54823", "hdl_1721.1_54828"]}}], "languages": [null], "subjects": ["computational and systems biology program."], "providerUpdatedDateTime": "2015-04-27T14:53:05", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/61788"}}, {"publisher": {"name": ""}, "description": "  We study the problem of selling $n$ items to a number of buyers with additive\nvaluation functions. We consider the items to be correlated, i.e.,\ndesirabilities of buyers for the items are not drawn independently. Ideally,\nthe goal is to design a mechanism to maximize the revenue. However, it has been\nshown that the optimum-revenue mechanism might be very complicated and as a\nresult inapplicable to real-world auctions. Therefore, our focus is on\ndesigning a simple mechanism that gets a constant fraction of the optimal\nrevenue. This problem was posed by Babaioff et al. in paper \"A Simple and\nApproximately Optimal Mechanism for an Additive Buyer\" (FOCS 2014) as an open\nquestion. In their paper they show a constant approximation of the optimal\nrevenue can be achieved by either selling the items separately or as a whole\nbundle in the independent setting. We show a similar result for the correlated\nsetting when the desirabilities of buyers are drawn from a common-base\ncorrelation. It is worth mentioning that the core decomposition lemma which is\nmainly the heart of the proofs for efficiency of the mechanisms does not hold\nfor correlated settings. Therefore we proposed a modified version of this lemma\nwhich plays a key role in proving bounds on the approximation of the mechanism.\nIn addition, we introduce a generalized form of correlation for items and show\nthe same mechanism can achieve an approximation of the optimal revenue in that\nsetting.\n", "contributors": [{"name": "Bateni, MohammadHossein", "sameAs": [], "familyName": "Bateni", "additionalName": "", "givenName": "MohammadHossein", "email": ""}, {"name": "Dehghani, Sina", "sameAs": [], "familyName": "Dehghani", "additionalName": "", "givenName": "Sina", "email": ""}, {"name": "Hajiaghayi, MohammadTaghi", "sameAs": [], "familyName": "Hajiaghayi", "additionalName": "", "givenName": "MohammadTaghi", "email": ""}, {"name": "Seddighin, Saeed", "sameAs": [], "familyName": "Seddighin", "additionalName": "", "givenName": "Saeed", "email": ""}], "title": "Revenue Maximization for Selling Multiple Correlated Items", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3187", "oai:arXiv.org:1412.3187"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We study the problem of selling $n$ items to a number of buyers with additive\nvaluation functions. We consider the items to be correlated, i.e.,\ndesirabilities of buyers for the items are not drawn independently. Ideally,\nthe goal is to design a mechanism to maximize the revenue. However, it has been\nshown that the optimum-revenue mechanism might be very complicated and as a\nresult inapplicable to real-world auctions. Therefore, our focus is on\ndesigning a simple mechanism that gets a constant fraction of the optimal\nrevenue. This problem was posed by Babaioff et al. in paper \"A Simple and\nApproximately Optimal Mechanism for an Additive Buyer\" (FOCS 2014) as an open\nquestion. In their paper they show a constant approximation of the optimal\nrevenue can be achieved by either selling the items separately or as a whole\nbundle in the independent setting. We show a similar result for the correlated\nsetting when the desirabilities of buyers are drawn from a common-base\ncorrelation. It is worth mentioning that the core decomposition lemma which is\nmainly the heart of the proofs for efficiency of the mechanisms does not hold\nfor correlated settings. Therefore we proposed a modified version of this lemma\nwhich plays a key role in proving bounds on the approximation of the mechanism.\nIn addition, we introduce a generalized form of correlation for items and show\nthe same mechanism can achieve an approximation of the optimal revenue in that\nsetting.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2014-12-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3187"}}, {"publisher": {"name": ""}, "description": "  A good deal of current research in complex networks involves the\ncharacterization and/or classification of the topological properties of given\nstructures, which has motivated several respective measurements. This letter\nproposes a framework for evaluating the quality of complex network measurements\nin terms of their effective resolution, degree of degeneracy and\ndiscriminability. The potential of the suggested approach is illustrated with\nrespect to comparing the characterization of several model and real-world\nnetworks by using concentric and symmetry measurements. The results indicate a\nmarkedly superior performance for the latter type of mapping.\n", "contributors": [{"name": "Comin, Cesar H.", "sameAs": [], "familyName": "Comin", "additionalName": "H.", "givenName": "Cesar", "email": ""}, {"name": "Silva, Filipi N.", "sameAs": [], "familyName": "Silva", "additionalName": "N.", "givenName": "Filipi", "email": ""}, {"name": "Costa, Luciano da F.", "sameAs": [], "familyName": "Costa", "additionalName": "da F.", "givenName": "Luciano", "email": ""}], "title": "A Framework for Evaluating Complex Networks Measurements", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-23", "2015-02-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7367", "oai:arXiv.org:1412.7367"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  A good deal of current research in complex networks involves the\ncharacterization and/or classification of the topological properties of given\nstructures, which has motivated several respective measurements. This letter\nproposes a framework for evaluating the quality of complex network measurements\nin terms of their effective resolution, degree of degeneracy and\ndiscriminability. The potential of the suggested approach is illustrated with\nrespect to comparing the characterization of several model and real-world\nnetworks by using concentric and symmetry measurements. The results indicate a\nmarkedly superior performance for the latter type of mapping.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "physics - data analysis", "statistics and probability", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7367"}}, {"publisher": {"name": ""}, "description": "  Google Scholar allows merging multiple article versions into one. This\nmerging affects the H-index computed by Google Scholar. We analyze the\nparameterized complexity of maximizing the H-index using article merges.\nHerein, multiple possible measures for computing the citation count of a merged\narticle are considered. Among others, for the measure used by Google Scholar,\nwe give an algorithm that maximizes the H-index in linear time if there is only\na constant number of versions of the same article. In contrast, if we are\nallowed to merge arbitrary articles, then already increasing the H-index by one\nis NP-hard.\n", "contributors": [{"name": "van Bevern, Ren\u00e9", "sameAs": [], "familyName": "van Bevern", "additionalName": "", "givenName": "Ren\u00e9", "email": ""}, {"name": "Komusiewicz, Christian", "sameAs": [], "familyName": "Komusiewicz", "additionalName": "", "givenName": "Christian", "email": ""}, {"name": "Niedermeier, Rolf", "sameAs": [], "familyName": "Niedermeier", "additionalName": "", "givenName": "Rolf", "email": ""}, {"name": "Sorge, Manuel", "sameAs": [], "familyName": "Sorge", "additionalName": "", "givenName": "Manuel", "email": ""}, {"name": "Walsh, Toby", "sameAs": [], "familyName": "Walsh", "additionalName": "", "givenName": "Toby", "email": ""}], "title": "On Google Scholar H-Index Manipulation by Merging Articles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5498", "oai:arXiv.org:1412.5498"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Google Scholar allows merging multiple article versions into one. This\nmerging affects the H-index computed by Google Scholar. We analyze the\nparameterized complexity of maximizing the H-index using article merges.\nHerein, multiple possible measures for computing the citation count of a merged\narticle are considered. Among others, for the measure used by Google Scholar,\nwe give an algorithm that maximizes the H-index in linear time if there is only\na constant number of versions of the same article. In contrast, if we are\nallowed to merge arbitrary articles, then already increasing the H-index by one\nis NP-hard.\n"}}], "languages": [null], "subjects": ["g.2.1", "g.2.2", "f.2.2", "computer science - discrete mathematics", "h.3.7", "computer science - digital libraries", "computer science - social and information networks", "91d30", "computer science - data structures and algorithms"], "providerUpdatedDateTime": "2014-12-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5498"}}, {"publisher": {"name": ""}, "description": "  Visual media has always been the most enjoyed way of communication. From the\nadvent of television to the modern day hand held computers, we have witnessed\nthe exponential growth of images around us. Undoubtedly it's a fact that they\ncarry a lot of information in them which needs be utilized in an effective\nmanner. Hence intense need has been felt to efficiently index and store large\nimage collections for effective and on- demand retrieval. For this purpose\nlow-level features extracted from the image contents like color, texture and\nshape has been used. Content based image retrieval systems employing these\nfeatures has proven very successful. Image retrieval has promising applications\nin numerous fields and hence has motivated researchers all over the world. New\nand improved ways to represent visual content are being developed each day.\nTremendous amount of research has been carried out in the last decade. In this\npaper we will present a detailed overview of some of the powerful color,\ntexture and shape descriptors for content based image retrieval. A comparative\nanalysis will also be carried out for providing an insight into outstanding\nchallenges in this field.\n", "contributors": [{"name": "Ahmad, Jamil", "sameAs": [], "familyName": "Ahmad", "additionalName": "", "givenName": "Jamil", "email": ""}, {"name": "Sajjad, Muhammad", "sameAs": [], "familyName": "Sajjad", "additionalName": "", "givenName": "Muhammad", "email": ""}, {"name": "Mehmood, Irfan", "sameAs": [], "familyName": "Mehmood", "additionalName": "", "givenName": "Irfan", "email": ""}, {"name": "Rho, Seungmin", "sameAs": [], "familyName": "Rho", "additionalName": "", "givenName": "Seungmin", "email": ""}, {"name": "Baik, Sung Wook", "sameAs": [], "familyName": "Baik", "additionalName": "Wook", "givenName": "Sung", "email": ""}], "title": "Describing Colors, Textures and Shapes for Content Based Image Retrieval\n  - A Survey", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07041", "(2014), Journal of Platform Technology 2(4): 34-48", "oai:arXiv.org:1502.07041"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Visual media has always been the most enjoyed way of communication. From the\nadvent of television to the modern day hand held computers, we have witnessed\nthe exponential growth of images around us. Undoubtedly it's a fact that they\ncarry a lot of information in them which needs be utilized in an effective\nmanner. Hence intense need has been felt to efficiently index and store large\nimage collections for effective and on- demand retrieval. For this purpose\nlow-level features extracted from the image contents like color, texture and\nshape has been used. Content based image retrieval systems employing these\nfeatures has proven very successful. Image retrieval has promising applications\nin numerous fields and hence has motivated researchers all over the world. New\nand improved ways to represent visual content are being developed each day.\nTremendous amount of research has been carried out in the last decade. In this\npaper we will present a detailed overview of some of the powerful color,\ntexture and shape descriptors for content based image retrieval. A comparative\nanalysis will also be carried out for providing an insight into outstanding\nchallenges in this field.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07041"}}, {"publisher": {"name": ""}, "description": "  The aim of this article is to use generalized complex structures in order to\nextend the definition of twistor spaces given by Penrose. We will adapt the\nintegrability result of Atiyah, Hitchin and Singer. We will deduce new\ncorrespondences betwenn differential geometry and (generalized) complex\ngeometry. In the last section we will show how these results generalized\nBredthauer's work.\n", "contributors": [{"name": "Deschamps, Guillaume", "sameAs": [], "familyName": "Deschamps", "additionalName": "", "givenName": "Guillaume", "email": ""}], "title": "Espaces de twisteurs des structures complexes g\\'en\\'eralis\\'ees", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-09-26", "2015-02-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1209.5870", "oai:arXiv.org:1209.5870"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The aim of this article is to use generalized complex structures in order to\nextend the definition of twistor spaces given by Penrose. We will adapt the\nintegrability result of Atiyah, Hitchin and Singer. We will deduce new\ncorrespondences betwenn differential geometry and (generalized) complex\ngeometry. In the last section we will show how these results generalized\nBredthauer's work.\n", "Comment: 19 pages, in French"]}}], "languages": [null], "subjects": ["mathematics - differential geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-02-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1209.5870"}}, {"publisher": {"name": ""}, "description": "  We are interested in characterising pairs $S,T$ of $F$-linear subspaces in a\nfield extension $L/F$ such that the linear span $ST$ of the set of products of\nelements of $S$ and of elements of $T$ has small dimension. Our central result\nis a linear analogue of Vosper's Theorem, which gives the structure of vector\nspaces $S,T$ in a prime extension $L$ of a finite field $F$ for which\n$\\dim_F(ST) =\\dim_F(S)+\\dim_F(T)-1$, when $\\dim_F(S), \\dim_F(T) >1$ and\n$\\dim_F(ST) < [L:F]-1$.\n", "contributors": [{"name": "Bachoc, Christine", "sameAs": [], "familyName": "Bachoc", "additionalName": "", "givenName": "Christine", "email": ""}, {"name": "Serra, Oriol", "sameAs": [], "familyName": "Serra", "additionalName": "", "givenName": "Oriol", "email": ""}, {"name": "Zemor, Gilles", "sameAs": [], "familyName": "Zemor", "additionalName": "", "givenName": "Gilles", "email": ""}], "title": "An analogue of Vosper's Theorem for Extension Fields", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00602", "oai:arXiv.org:1501.00602"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We are interested in characterising pairs $S,T$ of $F$-linear subspaces in a\nfield extension $L/F$ such that the linear span $ST$ of the set of products of\nelements of $S$ and of elements of $T$ has small dimension. Our central result\nis a linear analogue of Vosper's Theorem, which gives the structure of vector\nspaces $S,T$ in a prime extension $L$ of a finite field $F$ for which\n$\\dim_F(ST) =\\dim_F(S)+\\dim_F(T)-1$, when $\\dim_F(S), \\dim_F(T) >1$ and\n$\\dim_F(ST) < [L:F]-1$.\n"}}], "languages": [null], "subjects": ["mathematics - number theory", "computer science - information theory", "mathematics - combinatorics", "11p70 (primary) 94b65 12f99 (secondary)"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00602"}}, {"publisher": {"name": ""}, "description": "  Reconstructing complex networks from measurable data is a fundamental problem\nfor understanding and controlling collective dynamics of complex networked\nsystems. However, a significant challenge arises when we attempt to decode\nstructural information hidden in limited amounts of data accompanied by noise\nand in the presence of inaccessible nodes. Here, we develop a general framework\nfor robust reconstruction of complex networks from sparse and noisy data.\nSpecifically, we decompose the task of reconstructing the whole network into\nrecovering local structures centered at each node. Thus, the natural sparsity\nof complex networks ensures a conversion from the local structure\nreconstruction into a sparse signal reconstruction problem that can be\naddressed by using the lasso, a convex optimization method. We apply our method\nto evolutionary games, transportation and communication processes taking place\nin a variety of model and real complex networks, finding that universal high\nreconstruction accuracy can be achieved from sparse data in spite of noise in\ntime series and missing data of partial nodes. Our approach opens new routes to\nthe network reconstruction problem and has potential applications in a wide\nrange of fields.\n", "contributors": [{"name": "Han, Xiao", "sameAs": [], "familyName": "Han", "additionalName": "", "givenName": "Xiao", "email": ""}, {"name": "Shen, Zhesi", "sameAs": [], "familyName": "Shen", "additionalName": "", "givenName": "Zhesi", "email": ""}, {"name": "Wang, Wen-Xu", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Wen-Xu", "email": ""}, {"name": "Di, Zengru", "sameAs": [], "familyName": "Di", "additionalName": "", "givenName": "Zengru", "email": ""}], "title": "Robust Reconstruction of Complex Networks from Sparse Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04731", "doi:10.1103/PhysRevLett.114.028701", "oai:arXiv.org:1501.04731"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Reconstructing complex networks from measurable data is a fundamental problem\nfor understanding and controlling collective dynamics of complex networked\nsystems. However, a significant challenge arises when we attempt to decode\nstructural information hidden in limited amounts of data accompanied by noise\nand in the presence of inaccessible nodes. Here, we develop a general framework\nfor robust reconstruction of complex networks from sparse and noisy data.\nSpecifically, we decompose the task of reconstructing the whole network into\nrecovering local structures centered at each node. Thus, the natural sparsity\nof complex networks ensures a conversion from the local structure\nreconstruction into a sparse signal reconstruction problem that can be\naddressed by using the lasso, a convex optimization method. We apply our method\nto evolutionary games, transportation and communication processes taking place\nin a variety of model and real complex networks, finding that universal high\nreconstruction accuracy can be achieved from sparse data in spite of noise in\ntime series and missing data of partial nodes. Our approach opens new routes to\nthe network reconstruction problem and has potential applications in a wide\nrange of fields.\n", "Comment: 5 pages, 2 figures, 2 tables"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04731"}}, {"publisher": {"name": ""}, "description": "  The main aim of this paper is to document the performance of $p$-refinement\nwith respect to maximum principles and the non-negative constraint. The model\nproblem is (steady-state) anisotropic diffusion with decay (which is a\nsecond-order elliptic partial differential equation). We considered the\nstandard single-field formulation (which is based on the Galerkin formalism)\nand two least-squares-based mixed formulations. We have employed non-uniform\nLagrange polynomials for altering the polynomial order in each element, and we\nhave used $p = 1, ..., 10$.\n  It will be shown that the violation of the non-negative constraint will not\nvanish with $p$-refinement for anisotropic diffusion. We shall illustrate the\nperformance of $p$-refinement using several representative problems. The\nintended outcome of the paper is twofold. Firstly, this study will caution the\nusers of high-order approximations about its performance with respect to\nmaximum principles and the non-negative constraint. Secondly, this study will\nhelp researchers to develop new methodologies for enforcing maximum principles\nand the non-negative constraint under high-order approximations.\n", "contributors": [{"name": "Payette, G. S.", "sameAs": [], "familyName": "Payette", "additionalName": "S.", "givenName": "G.", "email": ""}, {"name": "Nakshatrala, K. B.", "sameAs": [], "familyName": "Nakshatrala", "additionalName": "B.", "givenName": "K.", "email": ""}, {"name": "Reddy, J. N.", "sameAs": [], "familyName": "Reddy", "additionalName": "N.", "givenName": "J.", "email": ""}], "title": "On the performance of high-order finite elements with respect to maximum\n  principles and the non-negative constraint for diffusion-type equations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-08-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1108.0952", "oai:arXiv.org:1108.0952"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  The main aim of this paper is to document the performance of $p$-refinement\nwith respect to maximum principles and the non-negative constraint. The model\nproblem is (steady-state) anisotropic diffusion with decay (which is a\nsecond-order elliptic partial differential equation). We considered the\nstandard single-field formulation (which is based on the Galerkin formalism)\nand two least-squares-based mixed formulations. We have employed non-uniform\nLagrange polynomials for altering the polynomial order in each element, and we\nhave used $p = 1, ..., 10$.\n  It will be shown that the violation of the non-negative constraint will not\nvanish with $p$-refinement for anisotropic diffusion. We shall illustrate the\nperformance of $p$-refinement using several representative problems. The\nintended outcome of the paper is twofold. Firstly, this study will caution the\nusers of high-order approximations about its performance with respect to\nmaximum principles and the non-negative constraint. Secondly, this study will\nhelp researchers to develop new methodologies for enforcing maximum principles\nand the non-negative constraint under high-order approximations.\n"}}], "languages": [null], "subjects": ["mathematics - numerical analysis", "computer science - numerical analysis"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1108.0952"}}, {"publisher": {"name": ""}, "description": "  The article revisits spatial interaction and distance decay from the\nperspective of human mobility patterns and spatially-embedded networks based on\nan empirical data set. We extract nationwide inter-urban movements in China\nfrom a check-in data set that covers half million individuals and 370 cities to\nanalyze the underlying patterns of trips and spatial interactions. By fitting\nthe gravity model, we find that the observed spatial interactions are governed\nby a power law distance decay effect. The obtained gravity model also well\nreproduces the exponential trip displacement distribution. However, due to the\necological fallacy issue, the movement of an individual may not obey the same\ndistance decay effect. We also construct a spatial network where the edge\nweights denote the interaction strengths. The communities detected from the\nnetwork are spatially connected and roughly consistent with province\nboundaries. We attribute this pattern to different distance decay parameters\nbetween intra-province and inter-province trips.\n", "contributors": [{"name": "Liu, Yu", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Yu", "email": ""}, {"name": "Sui, Zhengwei", "sameAs": [], "familyName": "Sui", "additionalName": "", "givenName": "Zhengwei", "email": ""}, {"name": "Kang, Chaogui", "sameAs": [], "familyName": "Kang", "additionalName": "", "givenName": "Chaogui", "email": ""}, {"name": "Gao, Yong", "sameAs": [], "familyName": "Gao", "additionalName": "", "givenName": "Yong", "email": ""}], "title": "Uncovering patterns of inter-urban trip and spatial interaction from\n  social media check-in data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-01", "2013-11-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.0282", "PLoS ONE 9(1): e86026", "doi:10.1371/journal.pone.0086026", "oai:arXiv.org:1310.0282"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The article revisits spatial interaction and distance decay from the\nperspective of human mobility patterns and spatially-embedded networks based on\nan empirical data set. We extract nationwide inter-urban movements in China\nfrom a check-in data set that covers half million individuals and 370 cities to\nanalyze the underlying patterns of trips and spatial interactions. By fitting\nthe gravity model, we find that the observed spatial interactions are governed\nby a power law distance decay effect. The obtained gravity model also well\nreproduces the exponential trip displacement distribution. However, due to the\necological fallacy issue, the movement of an individual may not obey the same\ndistance decay effect. We also construct a spatial network where the edge\nweights denote the interaction strengths. The communities detected from the\nnetwork are spatially connected and roughly consistent with province\nboundaries. We attribute this pattern to different distance decay parameters\nbetween intra-province and inter-province trips.\n", "Comment: 20 pages, 10 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.0282"}}, {"publisher": {"name": ""}, "description": "  In a recent series of papers a surprisingly strong connection was discovered\nbetween standard models of evolution in mathematical biology and Multiplicative\nWeights Updates Algorithm, a ubiquitous model of online learning and\noptimization. These papers establish that mathematical models of biological\nevolution are tantamount to applying discrete Multiplicative Weights Updates\nAlgorithm, a close variant of MWUA, on coordination games. This connection\nallows for introducing insights from the study of game theoretic dynamics into\nthe field of mathematical biology. Using these results as a stepping stone, we\nshow that mathematical models of haploid evolution imply the extinction of\ngenetic diversity in the long term limit, a widely believed conjecture in\ngenetics. In game theoretic terms we show that in the case of coordination\ngames, under minimal genericity assumptions, discrete MWUA converges to pure\nNash equilibria for all but a zero measure of initial conditions. This result\nholds despite the fact that mixed Nash equilibria can be exponentially (or even\nuncountably) many, completely dominating in number the set of pure Nash\nequilibria. Thus, in haploid organisms the long term preservation of genetic\ndiversity needs to be safeguarded by other evolutionary mechanisms such as\nmutations and speciation.\n", "contributors": [{"name": "Mehta, Ruta", "sameAs": [], "familyName": "Mehta", "additionalName": "", "givenName": "Ruta", "email": ""}, {"name": "Panageas, Ioannis", "sameAs": [], "familyName": "Panageas", "additionalName": "", "givenName": "Ioannis", "email": ""}, {"name": "Piliouras, Georgios", "sameAs": [], "familyName": "Piliouras", "additionalName": "", "givenName": "Georgios", "email": ""}], "title": "Natural Selection as an Inhibitor of Genetic Diversity: Multiplicative\n  Weights Updates Algorithm and a Conjecture of Haploid Genetics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-26", "2014-10-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6270", "oai:arXiv.org:1408.6270"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "q-bio"]}}, {"name": "description", "properties": {"description": ["  In a recent series of papers a surprisingly strong connection was discovered\nbetween standard models of evolution in mathematical biology and Multiplicative\nWeights Updates Algorithm, a ubiquitous model of online learning and\noptimization. These papers establish that mathematical models of biological\nevolution are tantamount to applying discrete Multiplicative Weights Updates\nAlgorithm, a close variant of MWUA, on coordination games. This connection\nallows for introducing insights from the study of game theoretic dynamics into\nthe field of mathematical biology. Using these results as a stepping stone, we\nshow that mathematical models of haploid evolution imply the extinction of\ngenetic diversity in the long term limit, a widely believed conjecture in\ngenetics. In game theoretic terms we show that in the case of coordination\ngames, under minimal genericity assumptions, discrete MWUA converges to pure\nNash equilibria for all but a zero measure of initial conditions. This result\nholds despite the fact that mixed Nash equilibria can be exponentially (or even\nuncountably) many, completely dominating in number the set of pure Nash\nequilibria. Thus, in haploid organisms the long term preservation of genetic\ndiversity needs to be safeguarded by other evolutionary mechanisms such as\nmutations and speciation.\n", "Comment: 18 pages, 1 figure"]}}], "languages": [null], "subjects": ["quantitative biology - quantitative methods", "computer science - computational engineering", "finance", "mathematics - dynamical systems", "and science"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6270"}}, {"publisher": {"name": ""}, "description": "  XML-based communication governs most of today's systems communication, due to\nits capability of representing complex structural and hierarchical data.\nHowever, XML document structure is considered a huge and bulky data that can be\nreduced to minimize bandwidth usage, transmission time, and maximize\nperformance. This contributes to a more efficient and utilized resource usage.\nIn cloud environments, this affects the amount of money the consumer pays.\nSeveral techniques are used to achieve this goal. This paper discusses these\ntechniques and proposes a new XML Schema-based Minification technique. The\nproposed technique works on XML Structure reduction using minification. The\nproposed technique provides a separation between the meaningful names and the\nunderlying minified names, which enhances software/code readability. This\ntechnique is applied to Intrusion Detection Message Exchange Format (IDMEF)\nmessages, as part of Security Information and Event Management (SIEM) system\ncommunication hosted on Microsoft Azure Cloud. Test results show message size\nreduction ranging from 8.15% to 50.34% in the raw message, without using\ntime-consuming compression techniques. Adding GZip compression to the proposed\ntechnique produces 66.1% shorter message size compared to original XML\nmessages.\n", "contributors": [{"name": "Moussa, Bishoy", "sameAs": [], "familyName": "Moussa", "additionalName": "", "givenName": "Bishoy", "email": ""}, {"name": "Mostafa, Mahmoud", "sameAs": [], "familyName": "Mostafa", "additionalName": "", "givenName": "Mahmoud", "email": ""}, {"name": "El-Khouly, Mahmoud", "sameAs": [], "familyName": "El-Khouly", "additionalName": "", "givenName": "Mahmoud", "email": ""}], "title": "XML Schema-based Minification for Communication of Security Information\n  and Event Management (SIEM) Systems in Cloud Environments", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2553", "International Journal of Advanced Computer Science and\n  Applications (IJACSA), 5(9), 2014", "doi:10.14569/IJACSA.2014.050912", "oai:arXiv.org:1410.2553"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  XML-based communication governs most of today's systems communication, due to\nits capability of representing complex structural and hierarchical data.\nHowever, XML document structure is considered a huge and bulky data that can be\nreduced to minimize bandwidth usage, transmission time, and maximize\nperformance. This contributes to a more efficient and utilized resource usage.\nIn cloud environments, this affects the amount of money the consumer pays.\nSeveral techniques are used to achieve this goal. This paper discusses these\ntechniques and proposes a new XML Schema-based Minification technique. The\nproposed technique works on XML Structure reduction using minification. The\nproposed technique provides a separation between the meaningful names and the\nunderlying minified names, which enhances software/code readability. This\ntechnique is applied to Intrusion Detection Message Exchange Format (IDMEF)\nmessages, as part of Security Information and Event Management (SIEM) system\ncommunication hosted on Microsoft Azure Cloud. Test results show message size\nreduction ranging from 8.15% to 50.34% in the raw message, without using\ntime-consuming compression techniques. Adding GZip compression to the proposed\ntechnique produces 66.1% shorter message size compared to original XML\nmessages.\n", "Comment: XML, JSON, Minification, XML Schema, Cloud, Log, Communication,\n  Compression, XMill, GZip, Code Generation, Code Readability, 9 pages, 12\n  figures, 5 tables, Journal Article"]}}], "languages": [null], "subjects": ["computer science - distributed", "computer science - networking and internet architecture", "parallel", "and cluster computing", "computer science - cryptography and security"], "providerUpdatedDateTime": "2014-10-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2553"}}, {"publisher": {"name": ""}, "description": "  We consider the problems of finding optimal identifying codes, (open)\nlocating-dominating sets and resolving sets (denoted IDENTIFYING CODE, (OPEN)\nLOCATING-DOMINATING SET and METRIC DIMENSION) of an interval or a permutation\ngraph. In these problems, one asks to distinguish all vertices of a graph by a\nsubset of the vertices, using either the neighbourhood within the solution set\nor the distances to the solution vertices. Using a general reduction for this\nclass of problems, we prove that the decision problems associated to these four\nnotions are NP-complete, even for graphs that are at the same time interval\ngraphs and permutation graphs and have diameter 2. While IDENTIFYING CODE and\n(OPEN) LOCATING-DOMINATING SET are trivially fixed-parameter-tractable when\nparameterized by solution size, it is known that in the same setting METRIC\nDIMENSION is W[2]-hard. We show that for interval graphs, this parameterization\nof METRIC DIMENSION is fixed-parameter-tractable.\n", "contributors": [{"name": "Foucaud, Florent", "sameAs": [], "familyName": "Foucaud", "additionalName": "", "givenName": "Florent", "email": ""}, {"name": "Mertzios, George B.", "sameAs": [], "familyName": "Mertzios", "additionalName": "B.", "givenName": "George", "email": ""}, {"name": "Naserasr, Reza", "sameAs": [], "familyName": "Naserasr", "additionalName": "", "givenName": "Reza", "email": ""}, {"name": "Parreau, Aline", "sameAs": [], "familyName": "Parreau", "additionalName": "", "givenName": "Aline", "email": ""}, {"name": "Valicov, Petru", "sameAs": [], "familyName": "Valicov", "additionalName": "", "givenName": "Petru", "email": ""}], "title": "Identification, location-domination and metric dimension on interval and\n  permutation graphs. II. Algorithms and complexity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-10", "2015-02-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.2424", "oai:arXiv.org:1405.2424"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider the problems of finding optimal identifying codes, (open)\nlocating-dominating sets and resolving sets (denoted IDENTIFYING CODE, (OPEN)\nLOCATING-DOMINATING SET and METRIC DIMENSION) of an interval or a permutation\ngraph. In these problems, one asks to distinguish all vertices of a graph by a\nsubset of the vertices, using either the neighbourhood within the solution set\nor the distances to the solution vertices. Using a general reduction for this\nclass of problems, we prove that the decision problems associated to these four\nnotions are NP-complete, even for graphs that are at the same time interval\ngraphs and permutation graphs and have diameter 2. While IDENTIFYING CODE and\n(OPEN) LOCATING-DOMINATING SET are trivially fixed-parameter-tractable when\nparameterized by solution size, it is known that in the same setting METRIC\nDIMENSION is W[2]-hard. We show that for interval graphs, this parameterization\nof METRIC DIMENSION is fixed-parameter-tractable.\n", "Comment: 22 pages, 8 figures. The new version contains a new algorithm. The\n  combinatorial bounds of the original version have been removed and will be\n  included in another paper"]}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.2424"}}, {"publisher": {"name": ""}, "description": "  The novel STEVE (i.e., Space-Time-Enclosing Volume Extraction) algorithm is\ndescribed here for the very first time. It generates iso-valued hypersurfaces\nthat may be implicitly contained in four-dimensional (4D) data sets, such as\ntemporal sequences of three-dimensional images from time-varying computed\ntomography. Any final hypersurface that will be generated by STEVE is\nguaranteed to be free from accidental rifts, i.e., it always fully encloses a\nregion in the 4D space under consideration. Furthermore, the information of the\ninterior/exterior of the enclosed regions is propagated to each one of the\ntetrahedrons, which are embedded into 4D and which in their union represent the\nfinal, iso-valued hypersurface(s). We argue that STEVE - while using a minimum\nof data redundancy in representing the final results - is faster than other\ntechniques that generate simplex-based manifolds of codimension 1.\n", "contributors": [{"name": "Schlei, B. R.", "sameAs": [], "familyName": "Schlei", "additionalName": "R.", "givenName": "B.", "email": ""}], "title": "STEVE - Space-Time-Enclosing Volume Extraction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-02-22", "2015-02-23"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1302.5683", "oai:arXiv.org:1302.5683"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The novel STEVE (i.e., Space-Time-Enclosing Volume Extraction) algorithm is\ndescribed here for the very first time. It generates iso-valued hypersurfaces\nthat may be implicitly contained in four-dimensional (4D) data sets, such as\ntemporal sequences of three-dimensional images from time-varying computed\ntomography. Any final hypersurface that will be generated by STEVE is\nguaranteed to be free from accidental rifts, i.e., it always fully encloses a\nregion in the 4D space under consideration. Furthermore, the information of the\ninterior/exterior of the enclosed regions is propagated to each one of the\ntetrahedrons, which are embedded into 4D and which in their union represent the\nfinal, iso-valued hypersurface(s). We argue that STEVE - while using a minimum\nof data redundancy in representing the final results - is faster than other\ntechniques that generate simplex-based manifolds of codimension 1.\n", "Comment: 16 pages, 26 figures, 1 table"]}}], "languages": [null], "subjects": ["computer science - graphics", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1302.5683"}}, {"publisher": {"name": ""}, "description": "  Random tilings are interesting as idealizations of atomistic models of\nquasicrystals and for their connection to problems in combinatorics and\nalgorithms. Of particular interest is the tiling entropy density, which\nmeasures the relation of the number of distinct tilings to the number of\nconstituent tiles. Tilings by squares and 45 degree rhombi receive special\nattention as presumably the simplest model that has not yet been solved exactly\nin the thermodynamic limit. However, an exact enumeration formula can be\nevaluated for tilings in finite regions with fixed boundaries. We implement\nthis algorithm in an efficient manner, enabling the investigation of larger\nregions of parameter space than previously were possible. Our new results\nappear to yield monotone increasing and decreasing lower and upper bounds on\nthe fixed boundary entropy density that converge toward S = 0.36021(3).\n", "contributors": [{"name": "Hutchinson, Maxwell", "sameAs": [], "familyName": "Hutchinson", "additionalName": "", "givenName": "Maxwell", "email": ""}, {"name": "Widom, Michael", "sameAs": [], "familyName": "Widom", "additionalName": "", "givenName": "Michael", "email": ""}], "title": "Enumeration of octagonal tilings", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-24", "2015-03-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.5977", "doi:10.1016/j.tcs.2015.03.019", "oai:arXiv.org:1306.5977"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:math-ph"]}}, {"name": "description", "properties": {"description": "  Random tilings are interesting as idealizations of atomistic models of\nquasicrystals and for their connection to problems in combinatorics and\nalgorithms. Of particular interest is the tiling entropy density, which\nmeasures the relation of the number of distinct tilings to the number of\nconstituent tiles. Tilings by squares and 45 degree rhombi receive special\nattention as presumably the simplest model that has not yet been solved exactly\nin the thermodynamic limit. However, an exact enumeration formula can be\nevaluated for tilings in finite regions with fixed boundaries. We implement\nthis algorithm in an efficient manner, enabling the investigation of larger\nregions of parameter space than previously were possible. Our new results\nappear to yield monotone increasing and decreasing lower and upper bounds on\nthe fixed boundary entropy density that converge toward S = 0.36021(3).\n"}}], "languages": [null], "subjects": ["mathematical physics", "computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.5977"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose opportunistic interference alignment (OIA) schemes\nfor three-transmitter multiple-input multiple-output (MIMO) interference\nchannels (ICs). In the proposed OIA, each transmitter has its own user group\nand selects a single user who has the most aligned interference signals. The\nuser dimensions provided by multiple users are exploited to align interfering\nsignals. Contrary to conventional IA, perfect channel state information of all\nchannel links is not required at the transmitter, and each user just feeds back\none scalar value to indicate how well the interfering channels are aligned. We\nprove that each transmitter can achieve the same degrees of freedom (DoF) as\nthe interference free case via user selection in our system model that the\nnumber of receive antennas is twice of the number of transmit antennas. Using\nthe geometric interpretation, we find the required user scaling to obtain an\narbitrary non-zero DoF. Two OIA schemes are proposed and compared with various\nuser selection schemes in terms of achievable rate/DoF and complexity.\n", "contributors": [{"name": "Lee, Jung Hoon", "sameAs": [], "familyName": "Lee", "additionalName": "Hoon", "givenName": "Jung", "email": ""}, {"name": "Choi, Wan", "sameAs": [], "familyName": "Choi", "additionalName": "", "givenName": "Wan", "email": ""}], "title": "On the Achievable DoF and User Scaling Law of Opportunistic Interference\n  Alignment in 3-Transmitter MIMO Interference Channels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-09-29", "2013-03-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.6541", "doi:10.1109/TWC.2013.041713.120773", "oai:arXiv.org:1109.6541"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we propose opportunistic interference alignment (OIA) schemes\nfor three-transmitter multiple-input multiple-output (MIMO) interference\nchannels (ICs). In the proposed OIA, each transmitter has its own user group\nand selects a single user who has the most aligned interference signals. The\nuser dimensions provided by multiple users are exploited to align interfering\nsignals. Contrary to conventional IA, perfect channel state information of all\nchannel links is not required at the transmitter, and each user just feeds back\none scalar value to indicate how well the interfering channels are aligned. We\nprove that each transmitter can achieve the same degrees of freedom (DoF) as\nthe interference free case via user selection in our system model that the\nnumber of receive antennas is twice of the number of transmit antennas. Using\nthe geometric interpretation, we find the required user scaling to obtain an\narbitrary non-zero DoF. Two OIA schemes are proposed and compared with various\nuser selection schemes in terms of achievable rate/DoF and complexity.\n", "Comment: To appear in IEEE Transactions on Wireless Communications"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.6541"}}, {"publisher": {"name": ""}, "description": "  A self-organization of efficient and robust networks is important for a\nfuture design of communication or transportation systems, however both\ncharacteristics are incompatible in many real networks. Recently, it has been\nfound that the robustness of onion-like structure with positive degree-degree\ncorrelations is optimal against intentional attacks. We show that, by\nbiologically inspired copying, an onion-like network emerges in the incremental\ngrowth with functions of proxy access and reinforced connectivity on a space.\nThe proposed network consists of the backbone of tree-like structure by\ncopyings and the periphery by adding shortcut links between low degree nodes to\nenhance the connectivity. It has the fine properties of the statistically\nself-averaging unlike the conventional duplication-divergence model,\nexponential-like degree distribution without overloaded hubs, strong robustness\nagainst both malicious attacks and random failures, and the efficiency with\nshort paths counted by the number of hops as mediators and by the Euclidean\ndistances. The adaptivity to heal over and to recover the performance of\nnetworking is also discussed for a change of environment in such disasters or\nbattlefields on a geographical map. These properties will be useful for a\nresilient and scalable infrastructure of network systems even in emergent\nsituations or poor environments.\n", "contributors": [{"name": "Hayashi, Yukio", "sameAs": [], "familyName": "Hayashi", "additionalName": "", "givenName": "Yukio", "email": ""}], "title": "Growing Self-organized Design of Efficient and Robust Complex Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7719", "doi:10.1109/SASO.2014.17", "oai:arXiv.org:1411.7719"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:nlin", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  A self-organization of efficient and robust networks is important for a\nfuture design of communication or transportation systems, however both\ncharacteristics are incompatible in many real networks. Recently, it has been\nfound that the robustness of onion-like structure with positive degree-degree\ncorrelations is optimal against intentional attacks. We show that, by\nbiologically inspired copying, an onion-like network emerges in the incremental\ngrowth with functions of proxy access and reinforced connectivity on a space.\nThe proposed network consists of the backbone of tree-like structure by\ncopyings and the periphery by adding shortcut links between low degree nodes to\nenhance the connectivity. It has the fine properties of the statistically\nself-averaging unlike the conventional duplication-divergence model,\nexponential-like degree distribution without overloaded hubs, strong robustness\nagainst both malicious attacks and random failures, and the efficiency with\nshort paths counted by the number of hops as mediators and by the Euclidean\ndistances. The adaptivity to heal over and to recover the performance of\nnetworking is also discussed for a change of environment in such disasters or\nbattlefields on a geographical map. These properties will be useful for a\nresilient and scalable infrastructure of network systems even in emergent\nsituations or poor environments.\n", "Comment: 10 pages, 14 figures, 3 tables, Proc. of 2014 IEEE 8th Int. Conf. on\n  Self-Adaptive and Self-Organizing Systems, pp.50-59"]}}], "languages": [null], "subjects": ["physics - physics and society", "nonlinear sciences - adaptation and self-organizing systems", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-12-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7719"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Uncertainty in travel time is one of the key factors that could allow us to understand and manage congestion in transportation networks. Models that incorporate uncertainty in travel time need to specify two mechanisms: the mechanism through which travel time uncertainty is generated and the mechanism through which travel time uncertainty influences users' behavior. Existing traffic equilibrium models are not sufficient in capturing these two mechanisms in an integrated way. This thesis proposes a new stochastic traffic equilibrium model that incorporates travel time uncertainty in an integrated manner. We focus on how uncertainty in travel time induces uncertainty in the traffic flow and vice versa. Travelers independently make probabilistic path choice decisions, inducing stochastic traffic flows in the network, which in turn result in uncertain travel times. Our model, based on the distribution of the travel time, uses the mean-variance approach in order to evaluate travelers' travel times and subsequently induce a stochastic traffic equilibrium flow pattern. In this thesis, we also examine when the new model we present has a solution as well as when the solution is unique. We discuss algorithms for solving this new model, and compare the model with existing traffic equilibrium models in the literature. We find that existing models tend to overestimate traffic flows on links with high travel time variance-to-mean ratios. To benchmark the various traffic network equilibrium models in the literature relative to the model we introduce, we investigate the total system cost, namely the total travel time in the network, for all these models. We prove three bounds that allow us to compare the system cost for the new model relative to existing models. We discuss the tightness of these bounds but also test them through numerical experimentation on test networks.", "contributors": [{"name": "Chen, Daizhuo", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Daizhuo", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "Georgia Perakis.", "sameAs": [], "familyName": "Perakis.", "additionalName": "", "givenName": "Georgia", "email": ""}], "title": "Modeling travel time uncertainty in traffic networks", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "154 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/61889", "706802887", "oai:dspace.mit.edu:1721.1/61889"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2011-03-24T20:22:12Z", "2011-03-24T20:22:12Z", "2010", "2010"]}}, {"name": "description", "properties": {"description": ["Uncertainty in travel time is one of the key factors that could allow us to understand and manage congestion in transportation networks. Models that incorporate uncertainty in travel time need to specify two mechanisms: the mechanism through which travel time uncertainty is generated and the mechanism through which travel time uncertainty influences users' behavior. Existing traffic equilibrium models are not sufficient in capturing these two mechanisms in an integrated way. This thesis proposes a new stochastic traffic equilibrium model that incorporates travel time uncertainty in an integrated manner. We focus on how uncertainty in travel time induces uncertainty in the traffic flow and vice versa. Travelers independently make probabilistic path choice decisions, inducing stochastic traffic flows in the network, which in turn result in uncertain travel times. Our model, based on the distribution of the travel time, uses the mean-variance approach in order to evaluate travelers' travel times and subsequently induce a stochastic traffic equilibrium flow pattern. In this thesis, we also examine when the new model we present has a solution as well as when the solution is unique. We discuss algorithms for solving this new model, and compare the model with existing traffic equilibrium models in the literature. We find that existing models tend to overestimate traffic flows on links with high travel time variance-to-mean ratios. To benchmark the various traffic network equilibrium models in the literature relative to the model we introduce, we investigate the total system cost, namely the total travel time in the network, for all these models. We prove three bounds that allow us to compare the system cost for the new model relative to existing models. We discuss the tightness of these bounds but also test them through numerical experimentation on test networks.", "by Daizhuo Chen.", "Thesis (S.M.)--Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2010.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (p. 147-154)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39115", "hdl_1721.1_39117"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:18", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/61889"}}, {"publisher": {"name": ""}, "description": "  Multi-threading allows agents to pursue a heterogeneous collection of tasks\nin an orderly manner. The view of multi-threading that emerges from thread\nalgebra is applied to the case where a single agent, who may be human,\nmaintains a hierarchical multithread as an architecture of its own activities.\n", "contributors": [{"name": "Bergstra, Jan A.", "sameAs": [], "familyName": "Bergstra", "additionalName": "A.", "givenName": "Jan", "email": ""}], "title": "Personal Multi-threading", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3579", "oai:arXiv.org:1412.3579"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Multi-threading allows agents to pursue a heterogeneous collection of tasks\nin an orderly manner. The view of multi-threading that emerges from thread\nalgebra is applied to the case where a single agent, who may be human,\nmaintains a hierarchical multithread as an architecture of its own activities.\n"}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3579"}}, {"publisher": {"name": ""}, "description": "  In recent years the effectiveness of interactive theorem provers has\nincreased to an extent that the bottleneck in the interactive process shifted\nto efficiency: while in principle large and complex theorems are provable\n(effectiveness), it takes a lot of effort for the user interacting with the\nsystem (lack of efficiency). We conducted focus groups to evaluate the\nusability of Isabelle/HOL and the KeY system with two goals: (a) detect\nusability issues in the interaction between interactive theorem provers and\ntheir user, and (b) analyze how evaluation and survey methods commonly used in\nthe area of human-computer interaction, such as focus groups and co-operative\nevaluation, are applicable to the specific field of interactive theorem proving\n(ITP).\n  In this paper, we report on our experience using the evaluation method focus\ngroups and how we adapted this method to ITP. We describe our results and\nconclusions mainly on the \"meta-level,\" i.e., we focus on the impact that\nspecific characteristics of ITPs have on the setup and the results of focus\ngroups. On the concrete level, we briefly summarise insights into the usability\nof the ITPs used in our case study.\n", "contributors": [{"name": "Beckert, Bernhard", "sameAs": [], "familyName": "Beckert", "additionalName": "", "givenName": "Bernhard", "email": ""}, {"name": "Grebing, Sarah", "sameAs": [], "familyName": "Grebing", "additionalName": "", "givenName": "Sarah", "email": ""}, {"name": "B\u00f6hl, Florian", "sameAs": [], "familyName": "B\u00f6hl", "additionalName": "", "givenName": "Florian", "email": ""}], "title": "How to Put Usability into Focus: Using Focus Groups to Evaluate the\n  Usability of Interactive Theorem Provers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.8215", "EPTCS 167, 2014, pp. 4-13", "doi:10.4204/EPTCS.167.3", "oai:arXiv.org:1410.8215"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In recent years the effectiveness of interactive theorem provers has\nincreased to an extent that the bottleneck in the interactive process shifted\nto efficiency: while in principle large and complex theorems are provable\n(effectiveness), it takes a lot of effort for the user interacting with the\nsystem (lack of efficiency). We conducted focus groups to evaluate the\nusability of Isabelle/HOL and the KeY system with two goals: (a) detect\nusability issues in the interaction between interactive theorem provers and\ntheir user, and (b) analyze how evaluation and survey methods commonly used in\nthe area of human-computer interaction, such as focus groups and co-operative\nevaluation, are applicable to the specific field of interactive theorem proving\n(ITP).\n  In this paper, we report on our experience using the evaluation method focus\ngroups and how we adapted this method to ITP. We describe our results and\nconclusions mainly on the \"meta-level,\" i.e., we focus on the impact that\nspecific characteristics of ITPs have on the setup and the results of focus\ngroups. On the concrete level, we briefly summarise insights into the usability\nof the ITPs used in our case study.\n", "Comment: In Proceedings UITP 2014, arXiv:1410.7850"]}}], "languages": [null], "subjects": ["computer science - human-computer interaction", "computer science - logic in computer science"], "providerUpdatedDateTime": "2014-10-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.8215"}}, {"publisher": {"name": ""}, "description": "  WiMAX (Worldwide Interoperability for Microwave Access) technology has\nemerged in response to the increasing demand for multimedia services in the\ninternet broadband networks. WiMAX standard has defined five different\nscheduling services to meet the QoS (Quality of Service) requirement of\nmultimedia applications and this paper investigates one specific scheduling\nservice, i.e. UGS scheduling. In parallel, it was observed that in the\ndifference of the traditional quality assessment approaches, nowadays, current\nresearches are centered on the user perception of the quality, the existing\nscheduling approaches take into account the QoS, mobility and many other\nparameters, but do not consider the Quality of Experience (QoE). In order to\ncontrol the packet transmission rate so as to match with the minimum subjective\nrate requirements of each user and therefore reduce packet loss and delays, an\nefficient scheduling approach has been proposed in this paper. The solution has\nbeen implemented and evaluated in the WiMAX simulation platform developed based\non NS-2. Simulation results show that by applying various levels of MOS (Mean\nOpinion Score) the QoE provided to the users is enhanced in term of jitter,\npacket loss rate, throughput and delay.\n", "contributors": [{"name": "Anouari, Tarik", "sameAs": [], "familyName": "Anouari", "additionalName": "", "givenName": "Tarik", "email": ""}, {"name": "Haqiq, Abdelkrim", "sameAs": [], "familyName": "Haqiq", "additionalName": "", "givenName": "Abdelkrim", "email": ""}], "title": "An Improved UGS Scheduling with QoE Metrics in WiMAX Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5944", "(IJCSIS) International Journal of Computer Science and Information\n  Security, Vol. 12, No. 9, September 2014", "oai:arXiv.org:1410.5944"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  WiMAX (Worldwide Interoperability for Microwave Access) technology has\nemerged in response to the increasing demand for multimedia services in the\ninternet broadband networks. WiMAX standard has defined five different\nscheduling services to meet the QoS (Quality of Service) requirement of\nmultimedia applications and this paper investigates one specific scheduling\nservice, i.e. UGS scheduling. In parallel, it was observed that in the\ndifference of the traditional quality assessment approaches, nowadays, current\nresearches are centered on the user perception of the quality, the existing\nscheduling approaches take into account the QoS, mobility and many other\nparameters, but do not consider the Quality of Experience (QoE). In order to\ncontrol the packet transmission rate so as to match with the minimum subjective\nrate requirements of each user and therefore reduce packet loss and delays, an\nefficient scheduling approach has been proposed in this paper. The solution has\nbeen implemented and evaluated in the WiMAX simulation platform developed based\non NS-2. Simulation results show that by applying various levels of MOS (Mean\nOpinion Score) the QoE provided to the users is enhanced in term of jitter,\npacket loss rate, throughput and delay.\n", "Comment: 6 pages, 8 figures"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-10-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5944"}}, {"publisher": {"name": ""}, "description": "  This paper considers the distributed consensus problem of multi-agent systems\nwith general continuous-time linear dynamics. Two distributed adaptive dynamic\nconsensus protocols are proposed, based on the relative output information of\nneighboring agents. One protocol assigns an adaptive coupling weight to each\nedge in the communication graph while the other uses an adaptive coupling\nweight for each node. These two adaptive protocols are designed to ensure that\nconsensus is reached in a fully distributed fashion for any undirected\nconnected communication graphs without using any global information. A\nsufficient condition for the existence of these adaptive protocols is that each\nagent is stabilizable and detectable. The cases with leader-follower and\nswitching communication graphs are also studied.\n", "contributors": [{"name": "Li, Zhongkui", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Zhongkui", "email": ""}, {"name": "Liu, Xiangdong", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Xiangdong", "email": ""}, {"name": "Ren, Wei", "sameAs": [], "familyName": "Ren", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Xie, Lihua", "sameAs": [], "familyName": "Xie", "additionalName": "", "givenName": "Lihua", "email": ""}], "title": "Distributed Consensus of Linear Multi-Agent Systems with Adaptive\n  Dynamic Protocols", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-09-17", "2011-09-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.3838", "Automatica, 49: 1986-1995, 2013", "doi:10.1016/j.automatica.2013.03.015", "oai:arXiv.org:1109.3838"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper considers the distributed consensus problem of multi-agent systems\nwith general continuous-time linear dynamics. Two distributed adaptive dynamic\nconsensus protocols are proposed, based on the relative output information of\nneighboring agents. One protocol assigns an adaptive coupling weight to each\nedge in the communication graph while the other uses an adaptive coupling\nweight for each node. These two adaptive protocols are designed to ensure that\nconsensus is reached in a fully distributed fashion for any undirected\nconnected communication graphs without using any global information. A\nsufficient condition for the existence of these adaptive protocols is that each\nagent is stabilizable and detectable. The cases with leader-follower and\nswitching communication graphs are also studied.\n", "Comment: 17 pages, 5 figues"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.3838"}}, {"publisher": {"name": ""}, "description": "  This paper advocates the use of the emerging distributed compressed sensing\n(DCS) paradigm to deploy energy harvesting (EH) wireless sensor networks (WSN)\nwith practical network lifetime and data gathering rates that are substantially\nhigher than the state-of-the-art. The basis of our work is a centralized EH WSN\narchitecture where the sensors convey data to a fusion center, using stylized\nmodels that capture the fact that the signals collected by different nodes can\nexhibit correlation and that the energy harvested by different nodes can also\nexhibit some degree of correlation. Via the probability of incorrect data\nreconstruction, we characterize the performance of both a compressive sensing\n(CS) and a DCS based approach to data acquisition and reconstruction. Moreover,\nwe perform an in-depth comparison of the proposed DCS based approach against a\nstate-of-the-art distributed source coding (DSC) system in terms of decoded\ndata distortion versus harvested energy. These performance characterizations\nand comparisons embody the effect of various system phenomena and parameters\nsuch as signal correlation, EH correlation, network size, and energy\navailability level. Our results unveil that, for an EH WSN consisting of eight\nSNs with our simple signal correlation and EH models, a target probability of\nincorrect reconstruction of $10^{-2}$, and under the same EH capability as CS,\nthe proposed approach allows for a six-fold increase in data gathering\ncapability with respect to the baseline CS-based approach. Moreover, under the\nsame energy harvested level, the proposed solution offers a substantial\nreduction of the mean-squared error distortion (up to 66.67\\%) with respect to\nthe state-of-the-art DSC system.\n", "contributors": [{"name": "Chen, Wei", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Deligiannis, Nikos", "sameAs": [], "familyName": "Deligiannis", "additionalName": "", "givenName": "Nikos", "email": ""}, {"name": "Andreopoulos, Yiannis", "sameAs": [], "familyName": "Andreopoulos", "additionalName": "", "givenName": "Yiannis", "email": ""}, {"name": "Wassell, Ian J.", "sameAs": [], "familyName": "Wassell", "additionalName": "J.", "givenName": "Ian", "email": ""}, {"name": "Rodrigues, Miguel R. D.", "sameAs": [], "familyName": "Rodrigues", "additionalName": "R. D.", "givenName": "Miguel", "email": ""}], "title": "Unlocking Energy Neutrality in Energy Harvesting Wireless Sensor\n  Networks: An Approach Based on Distributed Compressed Sensing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-15", "2015-01-31"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.4207", "oai:arXiv.org:1312.4207"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  This paper advocates the use of the emerging distributed compressed sensing\n(DCS) paradigm to deploy energy harvesting (EH) wireless sensor networks (WSN)\nwith practical network lifetime and data gathering rates that are substantially\nhigher than the state-of-the-art. The basis of our work is a centralized EH WSN\narchitecture where the sensors convey data to a fusion center, using stylized\nmodels that capture the fact that the signals collected by different nodes can\nexhibit correlation and that the energy harvested by different nodes can also\nexhibit some degree of correlation. Via the probability of incorrect data\nreconstruction, we characterize the performance of both a compressive sensing\n(CS) and a DCS based approach to data acquisition and reconstruction. Moreover,\nwe perform an in-depth comparison of the proposed DCS based approach against a\nstate-of-the-art distributed source coding (DSC) system in terms of decoded\ndata distortion versus harvested energy. These performance characterizations\nand comparisons embody the effect of various system phenomena and parameters\nsuch as signal correlation, EH correlation, network size, and energy\navailability level. Our results unveil that, for an EH WSN consisting of eight\nSNs with our simple signal correlation and EH models, a target probability of\nincorrect reconstruction of $10^{-2}$, and under the same EH capability as CS,\nthe proposed approach allows for a six-fold increase in data gathering\ncapability with respect to the baseline CS-based approach. Moreover, under the\nsame energy harvested level, the proposed solution offers a substantial\nreduction of the mean-squared error distortion (up to 66.67\\%) with respect to\nthe state-of-the-art DSC system.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.4207"}}, {"publisher": {"name": ""}, "description": "  We present a linear-time algorithm for deciding first-order (FO) properties\nin classes of graphs with bounded expansion, a notion recently introduced by\nNesetril and Ossona de Mendez. This generalizes several results from the\nliterature, because many natural classes of graphs have bounded expansion:\ngraphs of bounded tree-width, all proper minor-closed classes of graphs, graphs\nof bounded degree, graphs with no subgraph isomorphic to a subdivision of a\nfixed graph, and graphs that can be drawn in a fixed surface in such a way that\neach edge crosses at most a constant number of other edges. We deduce that\nthere is an almost linear-time algorithm for deciding FO properties in classes\nof graphs with locally bounded expansion.\n  More generally, we design a dynamic data structure for graphs belonging to a\nfixed class of graphs of bounded expansion. After a linear-time initialization\nthe data structure allows us to test an FO property in constant time, and the\ndata structure can be updated in constant time after addition/deletion of an\nedge, provided the list of possible edges to be added is known in advance and\ntheir simultaneous addition results in a graph in the class. All our results\nalso hold for relational structures and are based on the seminal result of\nNesetril and Ossona de Mendez on the existence of low tree-depth colorings.\n", "contributors": [{"name": "Dvorak, Zdenek", "sameAs": [], "familyName": "Dvorak", "additionalName": "", "givenName": "Zdenek", "email": ""}, {"name": "Kral, Daniel", "sameAs": [], "familyName": "Kral", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Thomas, Robin", "sameAs": [], "familyName": "Thomas", "additionalName": "", "givenName": "Robin", "email": ""}], "title": "Testing first-order properties for subclasses of sparse graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-09-23", "2013-01-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.5036", "oai:arXiv.org:1109.5036"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We present a linear-time algorithm for deciding first-order (FO) properties\nin classes of graphs with bounded expansion, a notion recently introduced by\nNesetril and Ossona de Mendez. This generalizes several results from the\nliterature, because many natural classes of graphs have bounded expansion:\ngraphs of bounded tree-width, all proper minor-closed classes of graphs, graphs\nof bounded degree, graphs with no subgraph isomorphic to a subdivision of a\nfixed graph, and graphs that can be drawn in a fixed surface in such a way that\neach edge crosses at most a constant number of other edges. We deduce that\nthere is an almost linear-time algorithm for deciding FO properties in classes\nof graphs with locally bounded expansion.\n  More generally, we design a dynamic data structure for graphs belonging to a\nfixed class of graphs of bounded expansion. After a linear-time initialization\nthe data structure allows us to test an FO property in constant time, and the\ndata structure can be updated in constant time after addition/deletion of an\nedge, provided the list of possible edges to be added is known in advance and\ntheir simultaneous addition results in a graph in the class. All our results\nalso hold for relational structures and are based on the seminal result of\nNesetril and Ossona de Mendez on the existence of low tree-depth colorings.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - logic in computer science", "computer science - discrete mathematics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.5036"}}, {"publisher": {"name": ""}, "description": "  Paper-by-paper results make it easy to miss the forest for the trees.We\nanalyse the remarkable progress of the last decade by discussing the main ideas\nexplored in the 40+ detectors currently present in the Caltech pedestrian\ndetection benchmark. We observe that there exist three families of approaches,\nall currently reaching similar detection quality. Based on our analysis, we\nstudy the complementarity of the most promising ideas by combining multiple\npublished strategies. This new decision forest detector achieves the current\nbest known performance on the challenging Caltech-USA dataset.\n", "contributors": [{"name": "Benenson, Rodrigo", "sameAs": [], "familyName": "Benenson", "additionalName": "", "givenName": "Rodrigo", "email": ""}, {"name": "Omran, Mohamed", "sameAs": [], "familyName": "Omran", "additionalName": "", "givenName": "Mohamed", "email": ""}, {"name": "Hosang, Jan", "sameAs": [], "familyName": "Hosang", "additionalName": "", "givenName": "Jan", "email": ""}, {"name": "Schiele, Bernt", "sameAs": [], "familyName": "Schiele", "additionalName": "", "givenName": "Bernt", "email": ""}], "title": "Ten Years of Pedestrian Detection, What Have We Learned?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4304", "oai:arXiv.org:1411.4304"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Paper-by-paper results make it easy to miss the forest for the trees.We\nanalyse the remarkable progress of the last decade by discussing the main ideas\nexplored in the 40+ detectors currently present in the Caltech pedestrian\ndetection benchmark. We observe that there exist three families of approaches,\nall currently reaching similar detection quality. Based on our analysis, we\nstudy the complementarity of the most promising ideas by combining multiple\npublished strategies. This new decision forest detector achieves the current\nbest known performance on the challenging Caltech-USA dataset.\n", "Comment: To appear in ECCV 2014 CVRSUAD workshop proceedings"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4304"}}, {"publisher": {"name": ""}, "description": "  In this paper, we consider vector space interference alignment strategies\nover the $K$-user interference channel and derive an upper bound on the\nachievable degrees of freedom as a function of the channel diversity $L$. The\nchannel diversity $L$ is modeled by $L$ independently fading real-valued\nparallel channels. Existing results in the literature for $K=3$ show that the\noptimal $1/2$ degrees of freedom per user can be approached at the speed of\n$1/L$ (i.e., the gap to $1/2$ degrees of freedom per user decreases inversely\nproportional to $L$). In this paper, we show that when $K\\geq4$, the speed of\nconvergence is significantly slower. In particular, the gap to $1/2$ degrees of\nfreedom per user can decrease at most like $1/\\sqrt{L}$. Furthermore, when $K$\nis of the order of $\\sqrt{\\log L}$, we show that the speed of convergence is\nsmaller than $1/\\sqrt[4]{L}$ .\n", "contributors": [{"name": "Li, Cheuk Ting", "sameAs": [], "familyName": "Li", "additionalName": "Ting", "givenName": "Cheuk", "email": ""}, {"name": "\u00d6zg\u00fcr, Ayfer", "sameAs": [], "familyName": "\u00d6zg\u00fcr", "additionalName": "", "givenName": "Ayfer", "email": ""}], "title": "Channel Diversity needed for Vector Interference Alignment", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-21", "2014-11-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.5326", "oai:arXiv.org:1402.5326"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we consider vector space interference alignment strategies\nover the $K$-user interference channel and derive an upper bound on the\nachievable degrees of freedom as a function of the channel diversity $L$. The\nchannel diversity $L$ is modeled by $L$ independently fading real-valued\nparallel channels. Existing results in the literature for $K=3$ show that the\noptimal $1/2$ degrees of freedom per user can be approached at the speed of\n$1/L$ (i.e., the gap to $1/2$ degrees of freedom per user decreases inversely\nproportional to $L$). In this paper, we show that when $K\\geq4$, the speed of\nconvergence is significantly slower. In particular, the gap to $1/2$ degrees of\nfreedom per user can decrease at most like $1/\\sqrt{L}$. Furthermore, when $K$\nis of the order of $\\sqrt{\\log L}$, we show that the speed of convergence is\nsmaller than $1/\\sqrt[4]{L}$ .\n", "Comment: 19 pages, 4 figures, short version presented at the International\n  Symposium on Information Theory 2014"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.5326"}}, {"publisher": {"name": ""}, "description": "  From the moment astronomical observations are made the resulting data\nproducts begin to grow stale. Even if perfect binary copies are preserved\nthrough repeated timely migration to more robust storage media, data standards\nevolve and new tools are created that require different kinds of data or\nmetadata. The expectations of the astronomical community change even if the\ndata do not. We discuss data engineering to mitigate the ensuing risks with\nexamples from a recent project to refactor seven million archival images to new\nstandards of nomenclature, metadata, format, and compression.\n", "contributors": [{"name": "Seaman, Rob", "sameAs": [], "familyName": "Seaman", "additionalName": "", "givenName": "Rob", "email": ""}], "title": "Data engineering for archive evolution", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.3481", "oai:arXiv.org:1410.3481"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:astro-ph"]}}, {"name": "description", "properties": {"description": ["  From the moment astronomical observations are made the resulting data\nproducts begin to grow stale. Even if perfect binary copies are preserved\nthrough repeated timely migration to more robust storage media, data standards\nevolve and new tools are created that require different kinds of data or\nmetadata. The expectations of the astronomical community change even if the\ndata do not. We discuss data engineering to mitigate the ensuing risks with\nexamples from a recent project to refactor seven million archival images to new\nstandards of nomenclature, metadata, format, and compression.\n", "Comment: 11 pages, this is a longer version of a poster paper submitted to the\n  proceedings of ADASS XXIV"]}}], "languages": [null], "subjects": ["computer science - digital libraries", "astrophysics - instrumentation and methods for astrophysics"], "providerUpdatedDateTime": "2014-10-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.3481"}}, {"publisher": {"name": ""}, "description": "  Titanium dioxide (TiO2) memristors exhibit complex conduction mechanism.\nSeveral models of different complexity have been developed in order to mimic\nthe experimental results for physical behaviors observed in memristor devices.\nPickett's tunneling barrier model describes the TiO2 memristors, and utilizes\ncomplex derivative of tunnel barrier width. It attains a large error in the ON\nswitching region. Variety of research consider it as the reference model for\nthe TiO2 memristors. In this paper, we first analyze the theory of operation of\nthe memristor and discuss Pickett's model. Then, we propose a modification to\nits derivative functions to provide a lower error and closer agreement with\nphysical behavior. This modification is represented by two additional fitting\nparameters to damp or accelerate the tunnel width derivative. Also, we\nincorporate a hard limiter term to limit the tunnel width to its physical\nextremes 1 nm and 2 nm. We run simulations to test the model modifications and\nwe compare the results to the experimental and original Pickett's model\nresults. The modified model more closely resembles the experimental behavior of\nTiO2 memristors and potentially enables the memristor to be used as a\nmultilevel memory.\n", "contributors": [{"name": "Daoud, Ahmad", "sameAs": [], "familyName": "Daoud", "additionalName": "", "givenName": "Ahmad", "email": ""}, {"name": "Dessouki, Ahmed", "sameAs": [], "familyName": "Dessouki", "additionalName": "", "givenName": "Ahmed", "email": ""}, {"name": "Abuelenin, Sherif", "sameAs": [], "familyName": "Abuelenin", "additionalName": "", "givenName": "Sherif", "email": ""}], "title": "Accuracy Enhancement of Pickett Tunnelling Barrier Memristor Model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07267", "oai:arXiv.org:1502.07267"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Titanium dioxide (TiO2) memristors exhibit complex conduction mechanism.\nSeveral models of different complexity have been developed in order to mimic\nthe experimental results for physical behaviors observed in memristor devices.\nPickett's tunneling barrier model describes the TiO2 memristors, and utilizes\ncomplex derivative of tunnel barrier width. It attains a large error in the ON\nswitching region. Variety of research consider it as the reference model for\nthe TiO2 memristors. In this paper, we first analyze the theory of operation of\nthe memristor and discuss Pickett's model. Then, we propose a modification to\nits derivative functions to provide a lower error and closer agreement with\nphysical behavior. This modification is represented by two additional fitting\nparameters to damp or accelerate the tunnel width derivative. Also, we\nincorporate a hard limiter term to limit the tunnel width to its physical\nextremes 1 nm and 2 nm. We run simulations to test the model modifications and\nwe compare the results to the experimental and original Pickett's model\nresults. The modified model more closely resembles the experimental behavior of\nTiO2 memristors and potentially enables the memristor to be used as a\nmultilevel memory.\n", "Comment: 5 pages, 5 figures, presented at the ICITACEE 2014 conference;\n  http://icitacee.undip.ac.id/index.php/icitacee/2014/paper/view/89"]}}], "languages": [null], "subjects": ["computer science - emerging technologies"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07267"}}, {"publisher": {"name": ""}, "description": "  In this contribution, a Bayes Ying Yang(BYY) harmony based approach for\non-line signature verification is presented. In the proposed method, a simple\nbut effective Gaussian Mixture Models(GMMs) is used to represent for each\nuser's signature model based on the prior information collected. Different from\nthe early works, in this paper, we use the Bayes Ying Yang machine combined\nwith the harmony function to achieve Automatic Model Selection(AMS) during the\nparameter learning for the GMMs, so that a better approximation of the user\nmodel is assured. Experiments on a database from the First International\nSignature Verification Competition(SVC 2004) confirm that this combined\nalgorithm yields quite satisfactory results.\n", "contributors": [{"name": "Zhao, Xiaosha", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Xiaosha", "email": ""}, {"name": "Liu, Mandan", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Mandan", "email": ""}], "title": "The application of the Bayes Ying Yang harmony based GMMs in on-line\n  signature verification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4205", "oai:arXiv.org:1412.4205"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this contribution, a Bayes Ying Yang(BYY) harmony based approach for\non-line signature verification is presented. In the proposed method, a simple\nbut effective Gaussian Mixture Models(GMMs) is used to represent for each\nuser's signature model based on the prior information collected. Different from\nthe early works, in this paper, we use the Bayes Ying Yang machine combined\nwith the harmony function to achieve Automatic Model Selection(AMS) during the\nparameter learning for the GMMs, so that a better approximation of the user\nmodel is assured. Experiments on a database from the First International\nSignature Verification Competition(SVC 2004) confirm that this combined\nalgorithm yields quite satisfactory results.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4205"}}, {"publisher": {"name": ""}, "description": "  We establish the conditions under which several algorithmically exploitable\nstructural features hold for random intersection graphs, a natural model for\nmany real-world networks where edges correspond to shared attributes.\nSpecifically, we fully characterize the degeneracy of random intersection\ngraphs, and prove that the model asymptotically almost surely produces graphs\nwith hyperbolicity at least $\\log{n}$. Further, we prove that when degenerate,\nthe graphs generated by this model belong to a bounded-expansion graph class\nwith high probability.\n", "contributors": [{"name": "Farrell, Matthew", "sameAs": [], "familyName": "Farrell", "additionalName": "", "givenName": "Matthew", "email": ""}, {"name": "Goodrich, Timothy", "sameAs": [], "familyName": "Goodrich", "additionalName": "", "givenName": "Timothy", "email": ""}, {"name": "Lemons, Nathan", "sameAs": [], "familyName": "Lemons", "additionalName": "", "givenName": "Nathan", "email": ""}, {"name": "Reidl, Felix", "sameAs": [], "familyName": "Reidl", "additionalName": "", "givenName": "Felix", "email": ""}, {"name": "Villaamil, Fernando S\u00e1nchez", "sameAs": [], "familyName": "Villaamil", "additionalName": "S\u00e1nchez", "givenName": "Fernando", "email": ""}, {"name": "Sullivan, Blair D.", "sameAs": [], "familyName": "Sullivan", "additionalName": "D.", "givenName": "Blair", "email": ""}], "title": "Hyperbolicity, degeneracy, and expansion of random intersection graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-29", "2015-03-09"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.8196", "oai:arXiv.org:1409.8196"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We establish the conditions under which several algorithmically exploitable\nstructural features hold for random intersection graphs, a natural model for\nmany real-world networks where edges correspond to shared attributes.\nSpecifically, we fully characterize the degeneracy of random intersection\ngraphs, and prove that the model asymptotically almost surely produces graphs\nwith hyperbolicity at least $\\log{n}$. Further, we prove that when degenerate,\nthe graphs generated by this model belong to a bounded-expansion graph class\nwith high probability.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.8196"}}, {"publisher": {"name": ""}, "description": "  Next generation cellular networks will be heterogeneous with dense deployment\nof small cells in order to deliver high data rate per unit area. Traffic\nvariations are more pronounced in a small cell, which in turn lead to more\ndynamic interference to other cells. It is crucial to adapt radio resource\nmanagement to traffic conditions in such a heterogeneous network (HetNet). This\npaper studies the optimization of spectrum allocation in HetNets on a\nrelatively slow timescale based on average traffic and channel conditions\n(typically over seconds or minutes). Specifically, in a cluster with $n$ base\ntransceiver stations (BTSs), the optimal partition of the spectrum into $2^n$\nsegments is determined, corresponding to all possible spectrum reuse patterns\nin the downlink. Each BTS's traffic is modeled using a queue with Poisson\narrivals, the service rate of which is a linear function of the combined\nbandwidth of all assigned spectrum segments. With the system average packet\nsojourn time as the objective, a convex optimization problem is first\nformulated, where it is shown that the optimal allocation divides the spectrum\ninto at most $n$ segments. A second, refined model is then proposed to address\nqueue interactions due to interference, where the corresponding optimal\nallocation problem admits an efficient suboptimal solution. Both allocation\nschemes attain the entire throughput region of a given network. Simulation\nresults show the two schemes perform similarly in the heavy-traffic regime, in\nwhich case they significantly outperform both the orthogonal allocation and the\nfull-frequency-reuse allocation. The refined allocation shows the best\nperformance under all traffic conditions.\n", "contributors": [{"name": "Zhuang, Binnan", "sameAs": [], "familyName": "Zhuang", "additionalName": "", "givenName": "Binnan", "email": ""}, {"name": "Guo, Dongning", "sameAs": [], "familyName": "Guo", "additionalName": "", "givenName": "Dongning", "email": ""}, {"name": "Honig, Michael L.", "sameAs": [], "familyName": "Honig", "additionalName": "L.", "givenName": "Michael", "email": ""}], "title": "Traffic-Driven Spectrum Allocation in Heterogeneous Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-26", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6011", "oai:arXiv.org:1408.6011"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Next generation cellular networks will be heterogeneous with dense deployment\nof small cells in order to deliver high data rate per unit area. Traffic\nvariations are more pronounced in a small cell, which in turn lead to more\ndynamic interference to other cells. It is crucial to adapt radio resource\nmanagement to traffic conditions in such a heterogeneous network (HetNet). This\npaper studies the optimization of spectrum allocation in HetNets on a\nrelatively slow timescale based on average traffic and channel conditions\n(typically over seconds or minutes). Specifically, in a cluster with $n$ base\ntransceiver stations (BTSs), the optimal partition of the spectrum into $2^n$\nsegments is determined, corresponding to all possible spectrum reuse patterns\nin the downlink. Each BTS's traffic is modeled using a queue with Poisson\narrivals, the service rate of which is a linear function of the combined\nbandwidth of all assigned spectrum segments. With the system average packet\nsojourn time as the objective, a convex optimization problem is first\nformulated, where it is shown that the optimal allocation divides the spectrum\ninto at most $n$ segments. A second, refined model is then proposed to address\nqueue interactions due to interference, where the corresponding optimal\nallocation problem admits an efficient suboptimal solution. Both allocation\nschemes attain the entire throughput region of a given network. Simulation\nresults show the two schemes perform similarly in the heavy-traffic regime, in\nwhich case they significantly outperform both the orthogonal allocation and the\nfull-frequency-reuse allocation. The refined allocation shows the best\nperformance under all traffic conditions.\n", "Comment: 13 pages, 11 figures, accepted for publication by JSAC-HCN"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6011"}}, {"publisher": {"name": ""}, "description": "  This paper presents a novel approach to including non-instantaneous discrete\ncontrol transitions in the linear hybrid automaton approach to simulation and\nverification of hybrid control systems. In this paper we study the control of a\ncontinuously evolving analog plant using a controller programmed in a\nsynchronous programming language. We provide extensions to the synchronous\nsubset of the SystemJ programming language for modeling, implementation, and\nverification of such hybrid systems. We provide a sound rewrite semantics that\napproximate the evolution of the continuous variables in the discrete domain\ninspired from the classical supervisory control theory. The resultant discrete\ntime model can be verified using classical model-checking tools. Finally, we\nshow that systems designed using our approach have a higher fidelity than the\nones designed using the hybrid automaton approach.\n", "contributors": [{"name": "Malik, Avinash", "sameAs": [], "familyName": "Malik", "additionalName": "", "givenName": "Avinash", "email": ""}, {"name": "Roop, Partha", "sameAs": [], "familyName": "Roop", "additionalName": "", "givenName": "Partha", "email": ""}], "title": "A unified framework for modeling and implementation of hybrid systems\n  with synchronous controllers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05936", "oai:arXiv.org:1501.05936"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper presents a novel approach to including non-instantaneous discrete\ncontrol transitions in the linear hybrid automaton approach to simulation and\nverification of hybrid control systems. In this paper we study the control of a\ncontinuously evolving analog plant using a controller programmed in a\nsynchronous programming language. We provide extensions to the synchronous\nsubset of the SystemJ programming language for modeling, implementation, and\nverification of such hybrid systems. We provide a sound rewrite semantics that\napproximate the evolution of the continuous variables in the discrete domain\ninspired from the classical supervisory control theory. The resultant discrete\ntime model can be verified using classical model-checking tools. Finally, we\nshow that systems designed using our approach have a higher fidelity than the\nones designed using the hybrid automaton approach.\n", "Comment: 16 pages"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - programming languages"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05936"}}, {"publisher": {"name": ""}, "description": "  The annotation of the results of database transformations was shown to be\nvery effective for various applications. Until recently, most works in this\ncontext focused on positive query languages. The provenance semirings is a\nparticular approach that was proven effective for these languages, and it was\nshown that when propagating provenance with semirings, the expected equivalence\naxioms of the corresponding query languages are satisfied. There have been\nseveral attempts to extend the framework to account for relational algebra\nqueries with difference. We show here that these suggestions fail to satisfy\nsome expected equivalence axioms (that in particular hold for queries on\n\"standard\" set and bag databases). Interestingly, we show that this is not a\npitfall of these particular attempts, but rather every such attempt is bound to\nfail in satisfying these axioms, for some semirings. Finally, we show\nparticular semirings for which an extension for supporting difference is\n(im)possible.\n", "contributors": [{"name": "Amsterdamer, Yael", "sameAs": [], "familyName": "Amsterdamer", "additionalName": "", "givenName": "Yael", "email": ""}, {"name": "Deutch, Daniel", "sameAs": [], "familyName": "Deutch", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Tannen, Val", "sameAs": [], "familyName": "Tannen", "additionalName": "", "givenName": "Val", "email": ""}], "title": "On the Limitations of Provenance for Queries With Difference", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.2255", "oai:arXiv.org:1105.2255"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The annotation of the results of database transformations was shown to be\nvery effective for various applications. Until recently, most works in this\ncontext focused on positive query languages. The provenance semirings is a\nparticular approach that was proven effective for these languages, and it was\nshown that when propagating provenance with semirings, the expected equivalence\naxioms of the corresponding query languages are satisfied. There have been\nseveral attempts to extend the framework to account for relational algebra\nqueries with difference. We show here that these suggestions fail to satisfy\nsome expected equivalence axioms (that in particular hold for queries on\n\"standard\" set and bag databases). Interestingly, we show that this is not a\npitfall of these particular attempts, but rather every such attempt is bound to\nfail in satisfying these axioms, for some semirings. Finally, we show\nparticular semirings for which an extension for supporting difference is\n(im)possible.\n", "Comment: TAPP 2011"]}}], "languages": [null], "subjects": ["computer science - databases"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.2255"}}, {"publisher": {"name": "Department of Computer Science, Columbia University"}, "description": "Discovering code clones in a runtime environment helps software engineers identify hard to find logic-based bugs. Yet most research in the area of code clone discovery deals with source code due to the complexity of finding clones in a\ndynamic environment. KAMINO manipulates Java bytecode to track control and data flow dependencies at the methodlevel of Java programs during runtime. It then matches similar flows to find semantic code clones. With positive preliminary\nresults indicating code clones using KAMINO , future tests will compare the its robustness compared to existing code clones detection tools.", "contributors": [{"name": "Neubauer, Lindsay Anne", "sameAs": [], "familyName": "Neubauer", "additionalName": "Anne", "givenName": "Lindsay", "email": ""}], "title": "Kamino: Dynamic Approach to Semantic Code Clone Detection", "shareProperties": {"source": "columbia"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014"}}, {"name": "identifier", "properties": {"identifier": ["http://dx.doi.org/10.7916/D8542M79", "academiccommons.columbia.edu/ac:179003"]}}, {"name": "setSpec", "properties": {"setSpec": []}}], "languages": [null], "subjects": ["computer science"], "providerUpdatedDateTime": "2014-10-27T18:49:56", "uris": {"canonicalUri": "http://dx.doi.org/10.7916/D8542M79"}}, {"publisher": {"name": ""}, "description": "  We study the dynamics of majority automata networks when the vertices are\nupdated according to a block sequential updating scheme. In particular, we show\nthat the complexity of the problem of predicting an eventual state change in\nsome vertex, given an initial configuration, is PSPACE-complete.\n", "contributors": [{"name": "Goles, Eric", "sameAs": [], "familyName": "Goles", "additionalName": "", "givenName": "Eric", "email": ""}, {"name": "Montealegre, Pedro", "sameAs": [], "familyName": "Montealegre", "additionalName": "", "givenName": "Pedro", "email": ""}, {"name": "Salo, Ville", "sameAs": [], "familyName": "Salo", "additionalName": "", "givenName": "Ville", "email": ""}, {"name": "T\u00f6rm\u00e4, Ilkka", "sameAs": [], "familyName": "T\u00f6rm\u00e4", "additionalName": "", "givenName": "Ilkka", "email": ""}], "title": "PSPACE-Completeness of Majority Automata Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.03992", "oai:arXiv.org:1501.03992"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study the dynamics of majority automata networks when the vertices are\nupdated according to a block sequential updating scheme. In particular, we show\nthat the complexity of the problem of predicting an eventual state change in\nsome vertex, given an initial configuration, is PSPACE-complete.\n", "Comment: 14 pages, 8 figures"]}}], "languages": [null], "subjects": ["68r10", "f.2.2", "computer science - discrete mathematics", "g.2.2"], "providerUpdatedDateTime": "2015-01-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.03992"}}, {"publisher": {"name": ""}, "description": "  Due to the fact that quality of service requirements are not very strict for\nall traffic types, more calls of higher priority can be accommodated by\nreducing some bandwidth allocation for the bandwidth adaptive calls. The\nbandwidth adaptation to accept a higher priority call is more than that of a\nlower priority call. Therefore, the multi-level bandwidth adaptation technique\nimproves the overall forced call termination probability as well as provides\npriority of the traffic classes in terms of call blocking probability without\nreducing the bandwidth utilization. We propose a novel bandwidth adaptation\nmodel that releases multi-level of bandwidth from the existing multimedia\ntraffic calls. The amount of released bandwidth is decided based on the\npriority of the requesting traffic calls and the number of existing bandwidth\nadaptive calls. This prioritization of traffic classes does not reduce the\nbandwidth utilization. Moreover, our scheme reduces the overall forced call\ntermination probability significantly. The proposed scheme is modeled using the\nMarkov Chain. The numerical results show that the proposed scheme is able to\nprovide negligible handover call dropping probability as well as significantly\nreduced new call blocking probability of higher priority calls without\nincreasing the overall forced call termination probability.\n", "contributors": [{"name": "Chowdhury, Mostafa Zaman", "sameAs": [], "familyName": "Chowdhury", "additionalName": "Zaman", "givenName": "Mostafa", "email": ""}, {"name": "Jang, Yeong Min", "sameAs": [], "familyName": "Jang", "additionalName": "Min", "givenName": "Yeong", "email": ""}], "title": "Class-Based Service Connectivity using Multi-Level Bandwidth Adaptation\n  in Multimedia Wireless Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3625", "Wireless Personal Communications, vol. 77, no 4, pp. 2735-2745,\n  August 2014", "doi:10.1007/s11277-014-1665-7", "oai:arXiv.org:1412.3625"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Due to the fact that quality of service requirements are not very strict for\nall traffic types, more calls of higher priority can be accommodated by\nreducing some bandwidth allocation for the bandwidth adaptive calls. The\nbandwidth adaptation to accept a higher priority call is more than that of a\nlower priority call. Therefore, the multi-level bandwidth adaptation technique\nimproves the overall forced call termination probability as well as provides\npriority of the traffic classes in terms of call blocking probability without\nreducing the bandwidth utilization. We propose a novel bandwidth adaptation\nmodel that releases multi-level of bandwidth from the existing multimedia\ntraffic calls. The amount of released bandwidth is decided based on the\npriority of the requesting traffic calls and the number of existing bandwidth\nadaptive calls. This prioritization of traffic classes does not reduce the\nbandwidth utilization. Moreover, our scheme reduces the overall forced call\ntermination probability significantly. The proposed scheme is modeled using the\nMarkov Chain. The numerical results show that the proposed scheme is able to\nprovide negligible handover call dropping probability as well as significantly\nreduced new call blocking probability of higher priority calls without\nincreasing the overall forced call termination probability.\n", "Comment: Journal paper"]}}], "languages": [null], "subjects": ["computer science - performance", "computer science - networking and internet architecture", "computer science - multimedia"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3625"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "This thesis presents a new simple lightweight C++ thread based parallelization library, intended for use in numerical algorithms. It provides simple multitasking and task synchronization functions. The library hides all internal system calls from the developer and utilizes thread pooling to provide better performance and utilization of system time and resources. The library is lightweight and platform independent, and has been tested on Linux, and Windows. Experiments were conducted to verify the proper functionality of the library and to show that parallelized algorithms on a single machine are more efficient than using the Message Passing Interface (MPI) using shared memory. In the opinion of several researchers who have used this library, the parallelized code is more easily understood and debugged than MPI. The results of initial experiments show that algorithms are as efficient or better than those using MPI.", "contributors": [{"name": "Alhubail, Maitham Makki", "sameAs": [], "familyName": "Alhubail", "additionalName": "Makki", "givenName": "Maitham", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "John R. Williams.", "sameAs": [], "familyName": "Williams.", "additionalName": "R.", "givenName": "John", "email": ""}], "title": "A thread-based parallel programming library for numerical algorithms", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "47 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/90080", "890141986", "oai:dspace.mit.edu:1721.1/90080"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2014-09-19T21:38:32Z", "2014-09-19T21:38:32Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["This thesis presents a new simple lightweight C++ thread based parallelization library, intended for use in numerical algorithms. It provides simple multitasking and task synchronization functions. The library hides all internal system calls from the developer and utilizes thread pooling to provide better performance and utilization of system time and resources. The library is lightweight and platform independent, and has been tested on Linux, and Windows. Experiments were conducted to verify the proper functionality of the library and to show that parallelized algorithms on a single machine are more efficient than using the Message Passing Interface (MPI) using shared memory. In the opinion of several researchers who have used this library, the parallelized code is more easily understood and debugged than MPI. The results of initial experiments show that algorithms are as efficient or better than those using MPI.", "by Maitham Makki Alhubail.", "Thesis: S.M., Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2014.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (page 47)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39117", "hdl_1721.1_39115"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:20", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/90080"}}, {"publisher": {"name": ""}, "description": "  Orthogonal greedy learning (OGL) is a stepwise learning scheme that adds a\nnew atom from a dictionary via the steepest gradient descent and build the\nestimator via orthogonal projecting the target function to the space spanned by\nthe selected atoms in each greedy step. Here, \"greed\" means choosing a new atom\naccording to the steepest gradient descent principle. OGL then avoids the\noverfitting/underfitting by selecting an appropriate iteration number. In this\npaper, we point out that the overfitting/underfitting can also be avoided via\nredefining \"greed\" in OGL. To this end, we introduce a new greedy metric,\ncalled $\\delta$-greedy thresholds, to refine \"greed\" and theoretically verifies\nits feasibility. Furthermore, we reveals that such a greedy metric can bring an\nadaptive termination rule on the premise of maintaining the prominent learning\nperformance of OGL. Our results show that the steepest gradient descent is not\nthe unique greedy metric of OGL and some other more suitable metric may lessen\nthe hassle of model-selection of OGL.\n", "contributors": [{"name": "Xu, Lin", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Lin", "email": ""}, {"name": "Lin, Shaobo", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Shaobo", "email": ""}, {"name": "Zeng, Jinshan", "sameAs": [], "familyName": "Zeng", "additionalName": "", "givenName": "Jinshan", "email": ""}, {"name": "Xu, Zongben", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Zongben", "email": ""}], "title": "Greedy metrics in orthogonal greedy learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3553", "oai:arXiv.org:1411.3553"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Orthogonal greedy learning (OGL) is a stepwise learning scheme that adds a\nnew atom from a dictionary via the steepest gradient descent and build the\nestimator via orthogonal projecting the target function to the space spanned by\nthe selected atoms in each greedy step. Here, \"greed\" means choosing a new atom\naccording to the steepest gradient descent principle. OGL then avoids the\noverfitting/underfitting by selecting an appropriate iteration number. In this\npaper, we point out that the overfitting/underfitting can also be avoided via\nredefining \"greed\" in OGL. To this end, we introduce a new greedy metric,\ncalled $\\delta$-greedy thresholds, to refine \"greed\" and theoretically verifies\nits feasibility. Furthermore, we reveals that such a greedy metric can bring an\nadaptive termination rule on the premise of maintaining the prominent learning\nperformance of OGL. Our results show that the steepest gradient descent is not\nthe unique greedy metric of OGL and some other more suitable metric may lessen\nthe hassle of model-selection of OGL.\n", "Comment: 33 pages, 8 figures"]}}], "languages": [null], "subjects": ["f.2.2", "computer science - learning"], "providerUpdatedDateTime": "2014-11-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3553"}}, {"publisher": {"name": ""}, "description": "  Caching data files directly on mobile user devices combined with\ndevice-to-device (D2D) communications has recently been suggested to improve\nthe capacity of wireless net6works. We investigate the performance of\nregenerating codes in terms of the total energy consumption of a cellular\nnetwork. We show that regenerating codes can offer large performance gains. It\nturns out that using redundancy against storage node failures is only\nbeneficial if the popularity of the data is between certain thresholds. As our\nmajor contribution, we investigate under which circumstances regenerating codes\nwith multiple redundant data fragments outdo uncoded caching.\n", "contributors": [{"name": "P\u00e4\u00e4kk\u00f6nen, Joonas", "sameAs": [], "familyName": "P\u00e4\u00e4kk\u00f6nen", "additionalName": "", "givenName": "Joonas", "email": ""}, {"name": "Hollanti, Camilla", "sameAs": [], "familyName": "Hollanti", "additionalName": "", "givenName": "Camilla", "email": ""}, {"name": "Tirkkonen, Olav", "sameAs": [], "familyName": "Tirkkonen", "additionalName": "", "givenName": "Olav", "email": ""}], "title": "Device-to-Device Data Storage with Regenerating Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1608", "oai:arXiv.org:1411.1608"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Caching data files directly on mobile user devices combined with\ndevice-to-device (D2D) communications has recently been suggested to improve\nthe capacity of wireless net6works. We investigate the performance of\nregenerating codes in terms of the total energy consumption of a cellular\nnetwork. We show that regenerating codes can offer large performance gains. It\nturns out that using redundancy against storage node failures is only\nbeneficial if the popularity of the data is between certain thresholds. As our\nmajor contribution, we investigate under which circumstances regenerating codes\nwith multiple redundant data fragments outdo uncoded caching.\n", "Comment: 6 pages, 8 figures"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1608"}}, {"publisher": {"name": ""}, "description": "  The Locator/ID Separation Protocol (LISP) limits the growth of the\nDefault-Free Zone routing tables by creating a highly aggregatable and\nquasi-static Internet core. However, LISP pushes the forwarding state to edge\nrouters whose timely operation relies on caching of location to identity\nbindings. In this paper we develop an analytical model to study the asymptotic\nscalability of the LISP cache. Under the assumptions that (i) long-term\npopularity can be modeled as a constant Generalized Zipf distribution and (ii)\ntemporal locality is predominantly determined by long-term popularity, we find\nthat the scalability of the LISP cache is O(1) with respect to the amount of\nprefixes (Internet growth) and users (growth of the LISP site). We validate the\nmodel and discuss the accuracy of our assumptions using several one-day-long\npacket traces.\n", "contributors": [{"name": "Coras, Florin", "sameAs": [], "familyName": "Coras", "additionalName": "", "givenName": "Florin", "email": ""}, {"name": "Domingo-Pascual, Jordi", "sameAs": [], "familyName": "Domingo-Pascual", "additionalName": "", "givenName": "Jordi", "email": ""}, {"name": "Cabellos-Aparicio, Albert", "sameAs": [], "familyName": "Cabellos-Aparicio", "additionalName": "", "givenName": "Albert", "email": ""}], "title": "On the Scalability of LISP Mappings Caches", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-04-12", "2015-04-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03004", "oai:arXiv.org:1504.03004"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The Locator/ID Separation Protocol (LISP) limits the growth of the\nDefault-Free Zone routing tables by creating a highly aggregatable and\nquasi-static Internet core. However, LISP pushes the forwarding state to edge\nrouters whose timely operation relies on caching of location to identity\nbindings. In this paper we develop an analytical model to study the asymptotic\nscalability of the LISP cache. Under the assumptions that (i) long-term\npopularity can be modeled as a constant Generalized Zipf distribution and (ii)\ntemporal locality is predominantly determined by long-term popularity, we find\nthat the scalability of the LISP cache is O(1) with respect to the amount of\nprefixes (Internet growth) and users (growth of the LISP site). We validate the\nmodel and discuss the accuracy of our assumptions using several one-day-long\npacket traces.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03004"}}, {"publisher": {"name": ""}, "description": "  Traditionally, there are three species of classification: unsupervised,\nsupervised, and semi-supervised. Supervised and semi-supervised classification\ndiffer by whether or not weight is given to unlabelled observations in the\nclassification procedure. In unsupervised classification, or clustering, no\nlabels are known and hence full weight is given to unlabelled observations. A\npriori, it can be very difficult to choose the optimal level of supervision,\nand the consequences of a sub-optimal choice can be non-trivial. A flexible\nfractionally-supervised approach to classification is introduced, where any\nlevel of supervision --- ranging from unsupervised to supervised --- can be\nattained. Our approach uses a weighted likelihood, wherein weights control the\nlevel of supervision. This paper investigates several choices for the\nspecification of these weights. Gaussian mixture models are used as a vehicle\nto illustrate our fractionally-supervised classification approach; however, it\nis broadly applicable and variations on the postulated model can easily be\nmade. A comparison between our approach and the traditional species is\npresented using simulated and real data.\n", "contributors": [{"name": "Vrbik, Irene", "sameAs": [], "familyName": "Vrbik", "additionalName": "", "givenName": "Irene", "email": ""}, {"name": "McNicholas, Paul D.", "sameAs": [], "familyName": "McNicholas", "additionalName": "D.", "givenName": "Paul", "email": ""}], "title": "Fractionally-Supervised Classification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-07-12", "2015-01-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1307.3598", "oai:arXiv.org:1307.3598"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  Traditionally, there are three species of classification: unsupervised,\nsupervised, and semi-supervised. Supervised and semi-supervised classification\ndiffer by whether or not weight is given to unlabelled observations in the\nclassification procedure. In unsupervised classification, or clustering, no\nlabels are known and hence full weight is given to unlabelled observations. A\npriori, it can be very difficult to choose the optimal level of supervision,\nand the consequences of a sub-optimal choice can be non-trivial. A flexible\nfractionally-supervised approach to classification is introduced, where any\nlevel of supervision --- ranging from unsupervised to supervised --- can be\nattained. Our approach uses a weighted likelihood, wherein weights control the\nlevel of supervision. This paper investigates several choices for the\nspecification of these weights. Gaussian mixture models are used as a vehicle\nto illustrate our fractionally-supervised classification approach; however, it\nis broadly applicable and variations on the postulated model can easily be\nmade. A comparison between our approach and the traditional species is\npresented using simulated and real data.\n"}}], "languages": [null], "subjects": ["statistics - applications", "statistics - computation", "statistics - methodology", "statistics - machine learning"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1307.3598"}}, {"publisher": {"name": ""}, "description": "  In order to address the imprecision often introduced by widening operators,\npolicy iteration based on min-computations amounts to consider the\ncharacterization of reachable states of a program as an iterative computation\nof policies, starting from a post-fixpoint. Computing each policy and the\nassociated invariant relies on a sequence of numerical optimizations. While the\nearly papers rely on LP to address linear properties of linear programs, the\ncurrent state of the art is still limited to the analysis of linear programs\nwith at most quadratic invariant, relying on Semi-Definite Programming (SDP)\nsolvers to compute the next policy, and LP solvers to solve the selected\npolicy.\n  We propose here to extend the class of programs considered through the use of\nSums-of-Squares (SOS) optimizations. Our approach enables the precise analysis\nof switched systems with polynomial assigns and guards. The analysis presented\nhas been implemented in Matlab and applied on existing programs, improving both\nthe set of systems analyzable and the precision of analyzed ones.\n", "contributors": [{"name": "Adj\u00e9, Assal\u00e9", "sameAs": [], "familyName": "Adj\u00e9", "additionalName": "", "givenName": "Assal\u00e9", "email": ""}, {"name": "Garoche, Pierre-Lo\u00efc", "sameAs": [], "familyName": "Garoche", "additionalName": "", "givenName": "Pierre-Lo\u00efc", "email": ""}, {"name": "Magron, Victor", "sameAs": [], "familyName": "Magron", "additionalName": "", "givenName": "Victor", "email": ""}], "title": "A Sums-of-Squares Extension of Policy Iterations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08090", "oai:arXiv.org:1503.08090"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In order to address the imprecision often introduced by widening operators,\npolicy iteration based on min-computations amounts to consider the\ncharacterization of reachable states of a program as an iterative computation\nof policies, starting from a post-fixpoint. Computing each policy and the\nassociated invariant relies on a sequence of numerical optimizations. While the\nearly papers rely on LP to address linear properties of linear programs, the\ncurrent state of the art is still limited to the analysis of linear programs\nwith at most quadratic invariant, relying on Semi-Definite Programming (SDP)\nsolvers to compute the next policy, and LP solvers to solve the selected\npolicy.\n  We propose here to extend the class of programs considered through the use of\nSums-of-Squares (SOS) optimizations. Our approach enables the precise analysis\nof switched systems with polynomial assigns and guards. The analysis presented\nhas been implemented in Matlab and applied on existing programs, improving both\nthe set of systems analyzable and the precision of analyzed ones.\n", "Comment: 20 pages, 1 figure"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - logic in computer science"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08090"}}, {"publisher": {"name": ""}, "description": "  In this paper, analytic relations between the macroscopic variables and the\nmesoscopic variables are derived for lattice Boltzmann methods (LBM). The\nanalytic relations are achieved by two different methods for the exchange from\nvelocity fields of finite-type methods to the single particle distribution\nfunctions of LBM. The numerical errors of reconstructing the single particle\ndistribution functions and the non-equilibrium distribution function by\nmacroscopic fields are investigated. Results show that their accuracy is better\nthan the existing ones. The proposed reconstruction operator has been used to\nimplement the coupling computations of LBM and macro-numerical methods of FVM.\nThe lid-driven cavity flow is chosen to carry out the coupling computations\nbased on the numerical strategies of domain decomposition methods (DDM). The\nnumerical results show that the proposed lifting relations are accurate and\nrobust.\n", "contributors": [{"name": "Xu, Hui", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Hui", "email": ""}, {"name": "Luan, Huibao", "sameAs": [], "familyName": "Luan", "additionalName": "", "givenName": "Huibao", "email": ""}, {"name": "He, Yaling", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Yaling", "email": ""}, {"name": "Tao, Wenquan", "sameAs": [], "familyName": "Tao", "additionalName": "", "givenName": "Wenquan", "email": ""}], "title": "A Lifting Relation from Macroscopic Variables to Mesoscopic Variables in\n  Lattice Boltzmann Method: Derivation, Numerical Assessments and Coupling\n  Computations Validation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-20", "2011-10-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.3958", "Computers and Fluids 54 (2012): 92-104", "doi:10.1016/j.compfluid.2011.10.007", "oai:arXiv.org:1104.3958"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": "  In this paper, analytic relations between the macroscopic variables and the\nmesoscopic variables are derived for lattice Boltzmann methods (LBM). The\nanalytic relations are achieved by two different methods for the exchange from\nvelocity fields of finite-type methods to the single particle distribution\nfunctions of LBM. The numerical errors of reconstructing the single particle\ndistribution functions and the non-equilibrium distribution function by\nmacroscopic fields are investigated. Results show that their accuracy is better\nthan the existing ones. The proposed reconstruction operator has been used to\nimplement the coupling computations of LBM and macro-numerical methods of FVM.\nThe lid-driven cavity flow is chosen to carry out the coupling computations\nbased on the numerical strategies of domain decomposition methods (DDM). The\nnumerical results show that the proposed lifting relations are accurate and\nrobust.\n"}}], "languages": [null], "subjects": ["physics - computational physics", "physics - fluid dynamics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.3958"}}, {"publisher": {"name": ""}, "description": "  The equation in the title describes the number of bright images of a point\nsource under lensing by an elliptic object with isothermal density. We prove\nthat this equation has at most 6 solutions. Any number of solutions from 1 to 6\ncan actually occur.\n", "contributors": [{"name": "Bergweiler, Walter", "sameAs": [], "familyName": "Bergweiler", "additionalName": "", "givenName": "Walter", "email": ""}, {"name": "Eremenko, Alexandre", "sameAs": [], "familyName": "Eremenko", "additionalName": "", "givenName": "Alexandre", "email": ""}], "title": "On the number of solutions of a transcendental equation arising in the\n  theory of gravitational lensing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2009-08-31", "2010-01-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/0908.4595", "Comput.Meth.Funct.Theory 10:303-324,2010", "oai:arXiv.org:0908.4595"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "physics:astro-ph", "physics:math-ph"]}}, {"name": "description", "properties": {"description": ["  The equation in the title describes the number of bright images of a point\nsource under lensing by an elliptic object with isothermal density. We prove\nthat this equation has at most 6 solutions. Any number of solutions from 1 to 6\ncan actually occur.\n", "Comment: 26 pages, 12 figures"]}}], "languages": [null], "subjects": ["astrophysics - cosmology and nongalactic astrophysics", "mathematical physics", "30e99", "85a99", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/0908.4595"}}, {"publisher": {"name": ""}, "description": "  We present a fixed point theorem for a class of (potentially) non-monotonic\nfunctions over specially structured complete lattices. The theorem has as a\nspecial case the Knaster-Tarski fixed point theorem when restricted to the case\nof monotonic functions and Kleene's theorem when the functions are additionally\ncontinuous. From the practical side, the theorem has direct applications in the\nsemantics of negation in logic programming. In particular, it leads to a more\ndirect and elegant proof of the least fixed point result of [Rondogiannis and\nW.W.Wadge, ACM TOCL 6(2): 441-467 (2005)]. Moreover, the theorem appears to\nhave potential for possible applications outside the logic programming domain.\n", "contributors": [{"name": "\u00c9sik, Zolt\u00e1n", "sameAs": [], "familyName": "\u00c9sik", "additionalName": "", "givenName": "Zolt\u00e1n", "email": ""}, {"name": "Rondogiannis, Panos", "sameAs": [], "familyName": "Rondogiannis", "additionalName": "", "givenName": "Panos", "email": ""}], "title": "A Fixed Point Theorem for Non-Monotonic Functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-03", "2015-02-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.0299", "oai:arXiv.org:1402.0299"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We present a fixed point theorem for a class of (potentially) non-monotonic\nfunctions over specially structured complete lattices. The theorem has as a\nspecial case the Knaster-Tarski fixed point theorem when restricted to the case\nof monotonic functions and Kleene's theorem when the functions are additionally\ncontinuous. From the practical side, the theorem has direct applications in the\nsemantics of negation in logic programming. In particular, it leads to a more\ndirect and elegant proof of the least fixed point result of [Rondogiannis and\nW.W.Wadge, ACM TOCL 6(2): 441-467 (2005)]. Moreover, the theorem appears to\nhave potential for possible applications outside the logic programming domain.\n", "Comment: 34 pages. Accepted in: Theoretical Computer Science (to appear)"]}}], "languages": [null], "subjects": ["mathematics - logic", "computer science - logic in computer science"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.0299"}}, {"publisher": {"name": ""}, "description": "  The word2vec model and application by Mikolov et al. have attracted a great\namount of attention in recent two years. The vector representations of words\nlearned by word2vec models have been proven to be able to carry semantic\nmeanings and are useful in various NLP tasks. As an increasing number of\nresearchers would like to experiment with word2vec, I notice that there lacks a\nmaterial that comprehensively explains the parameter learning process of\nword2vec in details, thus preventing many people with less neural network\nexperience from understanding how exactly word2vec works.\n  This note provides detailed derivations and explanations of the parameter\nupdate equations for the word2vec models, including the original continuous\nbag-of-word (CBOW) and skip-gram models, as well as advanced tricks,\nhierarchical soft-max and negative sampling. In the appendix a review is given\non the basics of neuron network models and backpropagation.\n", "contributors": [{"name": "Rong, Xin", "sameAs": [], "familyName": "Rong", "additionalName": "", "givenName": "Xin", "email": ""}], "title": "word2vec Parameter Learning Explained", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2738", "oai:arXiv.org:1411.2738"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The word2vec model and application by Mikolov et al. have attracted a great\namount of attention in recent two years. The vector representations of words\nlearned by word2vec models have been proven to be able to carry semantic\nmeanings and are useful in various NLP tasks. As an increasing number of\nresearchers would like to experiment with word2vec, I notice that there lacks a\nmaterial that comprehensively explains the parameter learning process of\nword2vec in details, thus preventing many people with less neural network\nexperience from understanding how exactly word2vec works.\n  This note provides detailed derivations and explanations of the parameter\nupdate equations for the word2vec models, including the original continuous\nbag-of-word (CBOW) and skip-gram models, as well as advanced tricks,\nhierarchical soft-max and negative sampling. In the appendix a review is given\non the basics of neuron network models and backpropagation.\n"}}], "languages": [null], "subjects": ["computer science - computation and language"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2738"}}, {"publisher": {"name": ""}, "description": "  We propose a new data-augmentation strategy for fully Bayesian inference in\nmodels with binomial likelihoods. The approach appeals to a new class of\nPolya-Gamma distributions, which are constructed in detail. A variety of\nexamples are presented to show the versatility of the method, including\nlogistic regression, negative binomial regression, nonlinear mixed-effects\nmodels, and spatial models for count data. In each case, our data-augmentation\nstrategy leads to simple, effective methods for posterior inference that: (1)\ncircumvent the need for analytic approximations, numerical integration, or\nMetropolis-Hastings; and (2) outperform other known data-augmentation\nstrategies, both in ease of use and in computational efficiency. All methods,\nincluding an efficient sampler for the Polya-Gamma distribution, are\nimplemented in the R package BayesLogit.\n  In the technical supplement appended to the end of the paper, we provide\nfurther details regarding the generation of Polya-Gamma random variables; the\nempirical benchmarks reported in the main manuscript; and the extension of the\nbasic data-augmentation framework to contingency tables and multinomial\noutcomes.\n", "contributors": [{"name": "Polson, Nicholas G.", "sameAs": [], "familyName": "Polson", "additionalName": "G.", "givenName": "Nicholas", "email": ""}, {"name": "Scott, James G.", "sameAs": [], "familyName": "Scott", "additionalName": "G.", "givenName": "James", "email": ""}, {"name": "Windle, Jesse", "sameAs": [], "familyName": "Windle", "additionalName": "", "givenName": "Jesse", "email": ""}], "title": "Bayesian inference for logistic models using Polya-Gamma latent\n  variables", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-05-01", "2013-07-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.0310", "oai:arXiv.org:1205.0310"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  We propose a new data-augmentation strategy for fully Bayesian inference in\nmodels with binomial likelihoods. The approach appeals to a new class of\nPolya-Gamma distributions, which are constructed in detail. A variety of\nexamples are presented to show the versatility of the method, including\nlogistic regression, negative binomial regression, nonlinear mixed-effects\nmodels, and spatial models for count data. In each case, our data-augmentation\nstrategy leads to simple, effective methods for posterior inference that: (1)\ncircumvent the need for analytic approximations, numerical integration, or\nMetropolis-Hastings; and (2) outperform other known data-augmentation\nstrategies, both in ease of use and in computational efficiency. All methods,\nincluding an efficient sampler for the Polya-Gamma distribution, are\nimplemented in the R package BayesLogit.\n  In the technical supplement appended to the end of the paper, we provide\nfurther details regarding the generation of Polya-Gamma random variables; the\nempirical benchmarks reported in the main manuscript; and the extension of the\nbasic data-augmentation framework to contingency tables and multinomial\noutcomes.\n"}}], "languages": [null], "subjects": ["statistics - computation", "statistics - methodology", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.0310"}}, {"publisher": {"name": "Institute of Electrical and Electronics Engineers"}, "description": "Abbreviation Completion is a novel technique to improve the efficiency of code-writing by supporting code completion of multiple keywords based on non-predefined abbreviated input - a different approach from conventional code completion that finds one keyword at a time based on an exact character match. Abbreviated input is expanded into keywords by a Hidden Markov Model learned from a corpus of existing code. The technique does not require the user to memorize abbreviations and provides incremental feedback of the most likely completions. This paper presents the algorithm for abbreviation completion, integrated with a new user interface for multiple-keyword completion. We tested the system by sampling 3000 code lines from open source projects and found that more than 98% of the code lines could be resolved from acronym-like abbreviations. A user study found 30% reduction in time usage and 41% reduction of keystrokes over conventional code completion.", "contributors": [{"name": "Miller, Robert C.", "sameAs": [], "familyName": "Miller", "additionalName": "C.", "givenName": "Robert", "email": ""}, {"name": "Han, Sangmok", "sameAs": [], "familyName": "Han", "additionalName": "", "givenName": "Sangmok", "email": ""}, {"name": "Wallace, David Robert", "sameAs": [], "familyName": "Wallace", "additionalName": "Robert", "givenName": "David", "email": ""}], "title": "Code Completion From Abbreviated Input", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": ["Article", "http://purl.org/eprint/type/JournalArticle"]}}, {"name": "source", "properties": {"source": "IEEE"}}, {"name": "format", "properties": {"format": []}}, {"name": "rights", "properties": {"rights": "Article is made available in accordance with the publisher's policy and may be subject to US copyright law. Please refer to the publisher's site for terms of use."}}, {"name": "identifier", "properties": {"identifier": ["978-1-4244-5259-0", "1527-1366", "INSPEC Accession Number: 11205136", "http://hdl.handle.net/1721.1/59377", "Sangmok Han, D.R. Wallace, and R.C. Miller. \u201cCode Completion from Abbreviated Input.\u201d Automated Software Engineering, 2009. ASE '09. 24th IEEE/ACM International Conference on. 2009. 332-343. \u00a9 2010 Institute of Electrical and Electronics Engineers.", "PUBLISHER_POLICY", "oai:dspace.mit.edu:1721.1/59377"]}}, {"name": "relation", "properties": {"relation": ["http://dx.doi.org/10.1109/ase.2009.64", "24th IEEE/ACM International Conference on Automated Software Engineering"]}}, {"name": "date", "properties": {"date": ["2010-10-15T15:48:31Z", "2010-10-15T15:48:31Z", "2010-03", "2009-11"]}}, {"name": "description", "properties": {"description": ["Abbreviation Completion is a novel technique to improve the efficiency of code-writing by supporting code completion of multiple keywords based on non-predefined abbreviated input - a different approach from conventional code completion that finds one keyword at a time based on an exact character match. Abbreviated input is expanded into keywords by a Hidden Markov Model learned from a corpus of existing code. The technique does not require the user to memorize abbreviations and provides incremental feedback of the most likely completions. This paper presents the algorithm for abbreviation completion, integrated with a new user interface for multiple-keyword completion. We tested the system by sampling 3000 code lines from open source projects and found that more than 98% of the code lines could be resolved from acronym-like abbreviations. A user study found 30% reduction in time usage and 41% reduction of keystrokes over conventional code completion.", "Samsung Scholarship Foundation"]}}, {"name": "setSpec", "properties": {"setSpec": "hdl_1721.1_49433"}}], "languages": [null], "subjects": ["code assistants", "abbreviation", "code completion", "multiple keywords", "data mining", "hidden markov model"], "providerUpdatedDateTime": "2015-03-20T19:26:03", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/59377"}}, {"publisher": {"name": ""}, "description": "  We compare variants of Anderson Mixing with the Jacobian-Free Newton-Krylov\nand Broyden methods applied to an instance of the k-eigenvalue formulation of\nthe linear Boltzmann transport equation. We present evidence that one variant\nof Anderson Mixing finds solutions in the fewest number of iterations. We\nexamine and strengthen theoretical results of Anderson Mixing applied to linear\nproblems.\n", "contributors": [{"name": "Calef, Matthew T.", "sameAs": [], "familyName": "Calef", "additionalName": "T.", "givenName": "Matthew", "email": ""}, {"name": "Fichtl, Erin D.", "sameAs": [], "familyName": "Fichtl", "additionalName": "D.", "givenName": "Erin", "email": ""}, {"name": "Warsa, James S.", "sameAs": [], "familyName": "Warsa", "additionalName": "S.", "givenName": "James", "email": ""}, {"name": "Berndt, Markus", "sameAs": [], "familyName": "Berndt", "additionalName": "", "givenName": "Markus", "email": ""}, {"name": "Carlson, Neil N.", "sameAs": [], "familyName": "Carlson", "additionalName": "N.", "givenName": "Neil", "email": ""}], "title": "Nonlinear Krylov Acceleration Applied to a Discrete Ordinates\n  Formulation of the k-Eigenvalue Problem", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-12-15", "2013-01-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1112.3568", "doi:10.1016/j.jcp.2012.12.024", "oai:arXiv.org:1112.3568"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": ["  We compare variants of Anderson Mixing with the Jacobian-Free Newton-Krylov\nand Broyden methods applied to an instance of the k-eigenvalue formulation of\nthe linear Boltzmann transport equation. We present evidence that one variant\nof Anderson Mixing finds solutions in the fewest number of iterations. We\nexamine and strengthen theoretical results of Anderson Mixing applied to linear\nproblems.\n", "Comment: This final revision includes results of the C5G7-MOX problem;\n  Nonlinear Krylov Acceleration Applied to a Discrete Ordinates Formulation of\n  the k-Eigenvalue Problem, Accepted by the Journal of Computational Physics\n  December 2012"]}}], "languages": [null], "subjects": ["physics - computational physics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1112.3568"}}, {"publisher": {"name": ""}, "description": "  The spread of ideas across a social network can be studied using complex\ncontagion models, in which agents are activated by contact with multiple\nactivated neighbors. The investigation of complex contagions can provide\ncrucial insights into social influence and behavior-adoption cascades on\nnetworks. In this paper, we introduce a model of a multi-stage complex\ncontagion on networks. Agents at different stages --- which could, for example,\nrepresent differing levels of support for a social movement or differing levels\nof commitment to a certain product or idea --- exert different amounts of\ninfluence on their neighbors. We demonstrate that the presence of even one\nadditional stage introduces novel dynamical behavior, including interplay\nbetween multiple cascades, that cannot occur in single-stage contagion models.\nWe find that cascades --- and hence collective action --- can be driven not\nonly by high-stage influencers but also by low-stage influencers.\n", "contributors": [{"name": "Melnik, Sergey", "sameAs": [], "familyName": "Melnik", "additionalName": "", "givenName": "Sergey", "email": ""}, {"name": "Ward, Jonathan A.", "sameAs": [], "familyName": "Ward", "additionalName": "A.", "givenName": "Jonathan", "email": ""}, {"name": "Gleeson, James P.", "sameAs": [], "familyName": "Gleeson", "additionalName": "P.", "givenName": "James", "email": ""}, {"name": "Porter, Mason A.", "sameAs": [], "familyName": "Porter", "additionalName": "A.", "givenName": "Mason", "email": ""}], "title": "Multi-Stage Complex Contagions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-07", "2013-02-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.1596", "Chaos 23, 013124 (2013)", "doi:10.1063/1.4790836", "oai:arXiv.org:1111.1596"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:nlin", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The spread of ideas across a social network can be studied using complex\ncontagion models, in which agents are activated by contact with multiple\nactivated neighbors. The investigation of complex contagions can provide\ncrucial insights into social influence and behavior-adoption cascades on\nnetworks. In this paper, we introduce a model of a multi-stage complex\ncontagion on networks. Agents at different stages --- which could, for example,\nrepresent differing levels of support for a social movement or differing levels\nof commitment to a certain product or idea --- exert different amounts of\ninfluence on their neighbors. We demonstrate that the presence of even one\nadditional stage introduces novel dynamical behavior, including interplay\nbetween multiple cascades, that cannot occur in single-stage contagion models.\nWe find that cascades --- and hence collective action --- can be driven not\nonly by high-stage influencers but also by low-stage influencers.\n", "Comment: 12 pages, 10 figures. This version is accepted to appear in Chaos"]}}], "languages": [null], "subjects": ["physics - physics and society", "nonlinear sciences - adaptation and self-organizing systems", "mathematics - dynamical systems", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.1596"}}, {"publisher": {"name": ""}, "description": "abstract: As we migrate into an era of personalized medicine, understanding how bio-molecules interact with one another to form cellular systems is one of the key focus areas of systems biology. Several challenges such as the dynamic nature of cellular systems, uncertainty due to environmental influences, and the heterogeneity between individual patients render this a difficult task. In the last decade, several algorithms have been proposed to elucidate cellular systems from data, resulting in numerous data-driven hypotheses. However, due to the large number of variables involved in the process, many of which are unknown or not measurable, such computational approaches often lead to a high proportion of false positives. This renders interpretation of the data-driven hypotheses extremely difficult. Consequently, a dismal proportion of these hypotheses are subject to further experimental validation, eventually limiting their potential to augment existing biological knowledge. This dissertation develops a framework of computational methods for the analysis of such data-driven hypotheses leveraging existing biological knowledge. Specifically, I show how biological knowledge can be mapped onto these hypotheses and subsequently augmented through novel hypotheses. Biological hypotheses are learnt in three levels of abstraction -- individual interactions, functional modules and relationships between pathways, corresponding to three complementary aspects of biological systems. The computational methods developed in this dissertation are applied to high throughput cancer data, resulting in novel hypotheses with potentially significant biological impact.", "contributors": [{"name": "Ramesh, Archana  (Author)", "sameAs": [], "familyName": "Ramesh", "additionalName": "", "givenName": "Archana", "email": ""}, {"name": "Kim, Seungchan  (Advisor)", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Seungchan", "email": ""}, {"name": "Langley, Patrick W (Committee member)", "sameAs": [], "familyName": "Langley", "additionalName": "W", "givenName": "Patrick", "email": ""}, {"name": "Baral, Chitta  (Committee member)", "sameAs": [], "familyName": "Baral", "additionalName": "", "givenName": "Chitta", "email": ""}, {"name": "Kiefer, Jeffrey  (Committee member)", "sameAs": [], "familyName": "Kiefer", "additionalName": "", "givenName": "Jeffrey", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Computational Methods for Knowledge Integration in the Analysis of Large-scale Biological Networks", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "130 pages"}}, {"name": "date", "properties": {"date": "2012"}}, {"name": "description", "properties": {"description": ["abstract: As we migrate into an era of personalized medicine, understanding how bio-molecules interact with one another to form cellular systems is one of the key focus areas of systems biology. Several challenges such as the dynamic nature of cellular systems, uncertainty due to environmental influences, and the heterogeneity between individual patients render this a difficult task. In the last decade, several algorithms have been proposed to elucidate cellular systems from data, resulting in numerous data-driven hypotheses. However, due to the large number of variables involved in the process, many of which are unknown or not measurable, such computational approaches often lead to a high proportion of false positives. This renders interpretation of the data-driven hypotheses extremely difficult. Consequently, a dismal proportion of these hypotheses are subject to further experimental validation, eventually limiting their potential to augment existing biological knowledge. This dissertation develops a framework of computational methods for the analysis of such data-driven hypotheses leveraging existing biological knowledge. Specifically, I show how biological knowledge can be mapped onto these hypotheses and subsequently augmented through novel hypotheses. Biological hypotheses are learnt in three levels of abstraction -- individual interactions, functional modules and relationships between pathways, corresponding to three complementary aspects of biological systems. The computational methods developed in this dissertation are applied to high throughput cancer data, resulting in novel hypotheses with potentially significant biological impact.", "Dissertation/Thesis", "Ph.D. Computer Science 2012"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.15204", "item:15204"]}}], "languages": [null], "subjects": ["microarray data", "bioinformatics", "knowledge integration", "computer science", "data mining", "machine learning", "gene regulatory networks", "artificial intelligence"], "providerUpdatedDateTime": "2015-02-12T01:13:51", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.15204"}}, {"publisher": {"name": ""}, "description": "  Interdependent networks are ubiquitous in our society, ranging from\ninfrastructure to economics, and the study of their cascading behaviors using\npercolation theory has attracted much attention in the recent years. To analyze\nthe percolation phenomena of these systems, different mathematical frameworks\nhave been proposed including generating functions, eigenvalues among some\nothers. These different frameworks approach the phase transition behaviors from\ndifferent angles, and have been very successful in shaping the different\nquantities of interest including critical threshold, size of the giant\ncomponent, order of phase transition and the dynamics of cascading. These\nmethods also vary in their mathematical complexity in dealing with\ninterdependent networks that have additional complexity in terms of the\ncorrelation among different layers of networks or links. In this work, we\nreview a particular approach of simple self-consistent probability equations,\nand illustrate that it can greatly simplify the mathematical analysis for\nsystems ranging from single layer network to various different interdependent\nnetworks. We give an overview on the detailed framework to study the nature of\nthe critical phase transition, value of the critical threshold and size of the\ngiant component for these different systems.\n", "contributors": [{"name": "Feng, Ling", "sameAs": [], "familyName": "Feng", "additionalName": "", "givenName": "Ling", "email": ""}, {"name": "Monterola, Christopher Pineda", "sameAs": [], "familyName": "Monterola", "additionalName": "Pineda", "givenName": "Christopher", "email": ""}, {"name": "Hu, Yanqing", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Yanqing", "email": ""}], "title": "A Simplified Self-Consistent Probabilities Framework to Characterize\n  Percolation Phenomena on Interdependent Networks : An Overview", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01601", "oai:arXiv.org:1502.01601"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Interdependent networks are ubiquitous in our society, ranging from\ninfrastructure to economics, and the study of their cascading behaviors using\npercolation theory has attracted much attention in the recent years. To analyze\nthe percolation phenomena of these systems, different mathematical frameworks\nhave been proposed including generating functions, eigenvalues among some\nothers. These different frameworks approach the phase transition behaviors from\ndifferent angles, and have been very successful in shaping the different\nquantities of interest including critical threshold, size of the giant\ncomponent, order of phase transition and the dynamics of cascading. These\nmethods also vary in their mathematical complexity in dealing with\ninterdependent networks that have additional complexity in terms of the\ncorrelation among different layers of networks or links. In this work, we\nreview a particular approach of simple self-consistent probability equations,\nand illustrate that it can greatly simplify the mathematical analysis for\nsystems ranging from single layer network to various different interdependent\nnetworks. We give an overview on the detailed framework to study the nature of\nthe critical phase transition, value of the critical threshold and size of the\ngiant component for these different systems.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "condensed matter - statistical mechanics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01601"}}, {"publisher": {"name": ""}, "description": "  We propose adaptation strategies to modify the standard constrained model\npredictive controller scheme in order to guarantee a certain lower bound on the\ndegree of suboptimality. Within this analysis, the length of the optimization\nhorizon is the parameter we wish to adapt. We develop and prove several\nshortening and prolongation strategies which also allow for an effective\nimplementation. Moreover, extensions of stability results and suboptimality\nestimates to model predictive controllers with varying optimization horizon are\nshown.\n", "contributors": [{"name": "Pannek, J\u00fcrgen", "sameAs": [], "familyName": "Pannek", "additionalName": "", "givenName": "J\u00fcrgen", "email": ""}], "title": "Horizon Adaptation for Nonlinear Model Predictive Controllers with\n  guaranteed Degree of Suboptimality", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.3037", "oai:arXiv.org:1105.3037"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We propose adaptation strategies to modify the standard constrained model\npredictive controller scheme in order to guarantee a certain lower bound on the\ndegree of suboptimality. Within this analysis, the length of the optimization\nhorizon is the parameter we wish to adapt. We develop and prove several\nshortening and prolongation strategies which also allow for an effective\nimplementation. Moreover, extensions of stability results and suboptimality\nestimates to model predictive controllers with varying optimization horizon are\nshown.\n", "Comment: 20 pages, 3 figures"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - systems and control"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.3037"}}, {"publisher": {"name": ""}, "description": "  Background: Confirmation bias is the tendency to acquire or evaluate new\ninformation in a way that is consistent with one's preexisting beliefs. It is\nomnipresent in psychology, economics, and even scientific practices. Prior\ntheoretical research of this phenomenon has mainly focused on its economic\nimplications possibly missing its potential connections with broader notions of\ncognitive science. Methodology/Principal Findings: We formulate a\n(non-Bayesian) model for revising subjective probabilistic opinion of a\nconfirmationally-biased agent in the light of a persuasive opinion. The\nrevision rule ensures that the agent does not react to persuasion that is\neither far from his current opinion or coincides with it. We demonstrate that\nthe model accounts for the basic phenomenology of the social judgment theory,\nand allows to study various phenomena such as cognitive dissonance and\nboomerang effect. The model also displays the order of presentation effect|when\nconsecutively exposed to two opinions, the preference is given to the last\nopinion (recency) or the first opinion (primacy)|and relates recency to\nconfirmation bias. Finally, we study the model in the case of repeated\npersuasion and analyze its convergence properties. Conclusions: The standard\nBayesian approach to probabilistic opinion revision is inadequate for\ndescribing the observed phenomenology of persuasion process. The simple\nnon-Bayesian model proposed here does agree with this phenomenology and is\ncapable of reproducing a spectrum of effects observed in psychology:\nprimacy-recency phenomenon, boomerang effect and cognitive dissonance. We point\nout several limitations of the model that should motivate its future\ndevelopment.\n", "contributors": [{"name": "Allahverdyan, A. E.", "sameAs": [], "familyName": "Allahverdyan", "additionalName": "E.", "givenName": "A.", "email": ""}, {"name": "Galstyan, Aram", "sameAs": [], "familyName": "Galstyan", "additionalName": "", "givenName": "Aram", "email": ""}], "title": "Opinion Dynamics with Confirmation Bias", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4328", "PLoS ONE 9(7), e99557 (2014)", "doi:10.1371/journal.pone.0099557", "oai:arXiv.org:1411.4328"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Background: Confirmation bias is the tendency to acquire or evaluate new\ninformation in a way that is consistent with one's preexisting beliefs. It is\nomnipresent in psychology, economics, and even scientific practices. Prior\ntheoretical research of this phenomenon has mainly focused on its economic\nimplications possibly missing its potential connections with broader notions of\ncognitive science. Methodology/Principal Findings: We formulate a\n(non-Bayesian) model for revising subjective probabilistic opinion of a\nconfirmationally-biased agent in the light of a persuasive opinion. The\nrevision rule ensures that the agent does not react to persuasion that is\neither far from his current opinion or coincides with it. We demonstrate that\nthe model accounts for the basic phenomenology of the social judgment theory,\nand allows to study various phenomena such as cognitive dissonance and\nboomerang effect. The model also displays the order of presentation effect|when\nconsecutively exposed to two opinions, the preference is given to the last\nopinion (recency) or the first opinion (primacy)|and relates recency to\nconfirmation bias. Finally, we study the model in the case of repeated\npersuasion and analyze its convergence properties. Conclusions: The standard\nBayesian approach to probabilistic opinion revision is inadequate for\ndescribing the observed phenomenology of persuasion process. The simple\nnon-Bayesian model proposed here does agree with this phenomenology and is\ncapable of reproducing a spectrum of effects observed in psychology:\nprimacy-recency phenomenon, boomerang effect and cognitive dissonance. We point\nout several limitations of the model that should motivate its future\ndevelopment.\n", "Comment: 18 pages"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4328"}}, {"publisher": {"name": ""}, "description": "  We study the problem of maximizing constrained non-monotone submodular\nfunctions and provide approximation algorithms that improve existing algorithms\nin terms of either the approximation factor or simplicity. Our algorithms\ncombine existing local search and greedy based algorithms. Different\nconstraints that we study are exact cardinality and multiple knapsack\nconstraints. For the multiple-knapsack constraints we achieve a\n$(0.25-2\\epsilon)$-factor algorithm.\n  We also show, as our main contribution, how to use the continuous greedy\nprocess for non-monotone functions and, as a result, obtain a 0.13-factor\napproximation algorithm for maximization over any solvable down-monotone\npolytope. The continuous greedy process has been previously used for maximizing\nsmooth monotone submodular function over a down-monotone polytope\n\\cite{CCPV08}. This implies a 0.13-approximation for several discrete problems,\nsuch as maximizing a non-negative submodular function subject to a matroid\nconstraint and/or multiple knapsack constraints.\n", "contributors": [{"name": "Fadaei, Salman", "sameAs": [], "familyName": "Fadaei", "additionalName": "", "givenName": "Salman", "email": ""}, {"name": "Fazli, MohammadAmin", "sameAs": [], "familyName": "Fazli", "additionalName": "", "givenName": "MohammadAmin", "email": ""}, {"name": "Safari, MohammadAli", "sameAs": [], "familyName": "Safari", "additionalName": "", "givenName": "MohammadAli", "email": ""}], "title": "Maximizing Non-monotone Submodular Set Functions Subject to Different\n  Constraints: Combined Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-15", "2011-07-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.2973", "oai:arXiv.org:1101.2973"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We study the problem of maximizing constrained non-monotone submodular\nfunctions and provide approximation algorithms that improve existing algorithms\nin terms of either the approximation factor or simplicity. Our algorithms\ncombine existing local search and greedy based algorithms. Different\nconstraints that we study are exact cardinality and multiple knapsack\nconstraints. For the multiple-knapsack constraints we achieve a\n$(0.25-2\\epsilon)$-factor algorithm.\n  We also show, as our main contribution, how to use the continuous greedy\nprocess for non-monotone functions and, as a result, obtain a 0.13-factor\napproximation algorithm for maximization over any solvable down-monotone\npolytope. The continuous greedy process has been previously used for maximizing\nsmooth monotone submodular function over a down-monotone polytope\n\\cite{CCPV08}. This implies a 0.13-approximation for several discrete problems,\nsuch as maximizing a non-negative submodular function subject to a matroid\nconstraint and/or multiple knapsack constraints.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.2973"}}, {"publisher": {"name": ""}, "description": "  This paper aims to present the different aspects and characteristics of\nstrategic and operational information and propose a categorization pattern\nallowing to consider an information as strategic or operational. This\ncategorization is to be used in the two decision making processes to assist its\nmining, and usage by the two related decision support systems. This is\nconducted trough the results of an investigative study of information used as\nbasis for strategic decisions inside three different companies.\n", "contributors": [{"name": "Abahmane, Omar", "sameAs": [], "familyName": "Abahmane", "additionalName": "", "givenName": "Omar", "email": ""}, {"name": "Binkkour, Mohamed", "sameAs": [], "familyName": "Binkkour", "additionalName": "", "givenName": "Mohamed", "email": ""}], "title": "Strategic and Operational information support of decision making\n  processes and systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01803", "oai:arXiv.org:1502.01803"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper aims to present the different aspects and characteristics of\nstrategic and operational information and propose a categorization pattern\nallowing to consider an information as strategic or operational. This\ncategorization is to be used in the two decision making processes to assist its\nmining, and usage by the two related decision support systems. This is\nconducted trough the results of an investigative study of information used as\nbasis for strategic decisions inside three different companies.\n", "Comment: Proceedings of the Information Systems and Business Intelligence\n  Conference, (SIIE-2008) Hammamet, Tunisia, February, 2008"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01803"}}, {"publisher": {"name": ""}, "description": "  Inspired by the brain, deep neural networks (DNN) are thought to learn\nabstract representations through their hierarchical architecture. However, at\npresent, how this happens is not well understood. Here, we demonstrate that DNN\nlearn abstract representations by a process of demodulation. We introduce a\nbiased sigmoid activation function and use it to show that DNN learn and\nperform better when optimized for demodulation. Our findings constitute the\nfirst unambiguous evidence that DNN perform abstract learning in practical use.\nOur findings may also explain abstract learning in the human brain.\n", "contributors": [{"name": "Simpson, Andrew J. R.", "sameAs": [], "familyName": "Simpson", "additionalName": "J. R.", "givenName": "Andrew", "email": ""}], "title": "Abstract Learning via Demodulation in a Deep Neural Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04042", "oai:arXiv.org:1502.04042"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Inspired by the brain, deep neural networks (DNN) are thought to learn\nabstract representations through their hierarchical architecture. However, at\npresent, how this happens is not well understood. Here, we demonstrate that DNN\nlearn abstract representations by a process of demodulation. We introduce a\nbiased sigmoid activation function and use it to show that DNN learn and\nperform better when optimized for demodulation. Our findings constitute the\nfirst unambiguous evidence that DNN perform abstract learning in practical use.\nOur findings may also explain abstract learning in the human brain.\n"}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - learning", "68txx"], "providerUpdatedDateTime": "2015-02-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04042"}}, {"publisher": {"name": ""}, "description": "  Wikipedia is a community-created encyclopedia that contains information about\nnotable people from different countries, epochs and disciplines and aims to\ndocument the world's knowledge from a neutral point of view. However, the\nnarrow diversity of the Wikipedia editor community has the potential to\nintroduce systemic biases such as gender biases into the content of Wikipedia.\nIn this paper we aim to tackle a sub problem of this larger challenge by\npresenting and applying a computational method for assessing gender bias on\nWikipedia along multiple dimensions. We find that while women on Wikipedia are\ncovered and featured well in many Wikipedia language editions, the way women\nare portrayed starkly differs from the way men are portrayed. We hope our work\ncontributes to increasing awareness about gender biases online, and in\nparticular to raising attention to the different levels in which gender biases\ncan manifest themselves on the web.\n", "contributors": [{"name": "Wagner, Claudia", "sameAs": [], "familyName": "Wagner", "additionalName": "", "givenName": "Claudia", "email": ""}, {"name": "Garcia, David", "sameAs": [], "familyName": "Garcia", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Jadidi, Mohsen", "sameAs": [], "familyName": "Jadidi", "additionalName": "", "givenName": "Mohsen", "email": ""}, {"name": "Strohmaier, Markus", "sameAs": [], "familyName": "Strohmaier", "additionalName": "", "givenName": "Markus", "email": ""}], "title": "It's a Man's Wikipedia? Assessing Gender Inequality in an Online\n  Encyclopedia", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-26", "2015-03-23"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06307", "oai:arXiv.org:1501.06307"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Wikipedia is a community-created encyclopedia that contains information about\nnotable people from different countries, epochs and disciplines and aims to\ndocument the world's knowledge from a neutral point of view. However, the\nnarrow diversity of the Wikipedia editor community has the potential to\nintroduce systemic biases such as gender biases into the content of Wikipedia.\nIn this paper we aim to tackle a sub problem of this larger challenge by\npresenting and applying a computational method for assessing gender bias on\nWikipedia along multiple dimensions. We find that while women on Wikipedia are\ncovered and featured well in many Wikipedia language editions, the way women\nare portrayed starkly differs from the way men are portrayed. We hope our work\ncontributes to increasing awareness about gender biases online, and in\nparticular to raising attention to the different levels in which gender biases\ncan manifest themselves on the web.\n", "Comment: in The International AAAI Conference on Web and Social Media\n  (ICWSM2015), Oxford, May 2015"]}}], "languages": [null], "subjects": ["computer science - computers and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06307"}}, {"publisher": {"name": ""}, "description": "  Clustering analysis aims to discover the underlying clusters in the data\npoints according to their similarities. It has wide applications ranging from\nbioinformatics to astronomy. Here, we proposed a Generalized Affinity\nPropagation (G-AP) clustering algorithm. Data points are first organized in a\nsparsely connected in-tree (IT) structure by a physically inspired strategy.\nThen, additional edges are added to the IT structure for those reachable nodes.\nThis expanded structure is subsequently trimmed by affinity propagation method.\nConsequently, the underlying cluster structure, with separate clusters,\nemerges. In contrast to other IT-based methods, G-AP is fully automatic and\ntakes as input the pairs of similarities between data points only. Unlike\naffinity propagation, G-AP is capable of discovering nonspherical clusters.\n", "contributors": [{"name": "Qiu, Teng", "sameAs": [], "familyName": "Qiu", "additionalName": "", "givenName": "Teng", "email": ""}, {"name": "Li, Yongjie", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Yongjie", "email": ""}], "title": "A Generalized Affinity Propagation Clustering Algorithm for Nonspherical\n  Cluster Discovery", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04318", "oai:arXiv.org:1501.04318"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Clustering analysis aims to discover the underlying clusters in the data\npoints according to their similarities. It has wide applications ranging from\nbioinformatics to astronomy. Here, we proposed a Generalized Affinity\nPropagation (G-AP) clustering algorithm. Data points are first organized in a\nsparsely connected in-tree (IT) structure by a physically inspired strategy.\nThen, additional edges are added to the IT structure for those reachable nodes.\nThis expanded structure is subsequently trimmed by affinity propagation method.\nConsequently, the underlying cluster structure, with separate clusters,\nemerges. In contrast to other IT-based methods, G-AP is fully automatic and\ntakes as input the pairs of similarities between data points only. Unlike\naffinity propagation, G-AP is capable of discovering nonspherical clusters.\n", "Comment: G-AP: a new (7th) member of the in-tree clustering family. 11 pages:\n  1-7, texts and figures; 8-11, supplementary materials"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04318"}}, {"publisher": {"name": ""}, "description": "  This paper studies the problem of predicting the coding effort for a\nsubsequent year of development by analysing metrics extracted from project\nrepositories, with an emphasis on projects containing XML code. The study\nconsiders thirteen open source projects and applies machine learning algorithms\nto generate models to predict one-year coding effort, measured in terms of\nlines of code added, modified and deleted. Both organisational and code metrics\nassociated to revisions are taken into account. The results show that coding\neffort is highly determined by the expertise of developers while source code\nmetrics have little effect on improving the accuracy of estimations of coding\neffort. The study also shows that models trained on one project are unreliable\nat estimating effort in other projects.\n", "contributors": [{"name": "Karus, Siim", "sameAs": [], "familyName": "Karus", "additionalName": "", "givenName": "Siim", "email": ""}, {"name": "Dumas, Marlon", "sameAs": [], "familyName": "Dumas", "additionalName": "", "givenName": "Marlon", "email": ""}], "title": "Predicting Coding Effort in Projects Containing XML Code", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-10-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1010.2354", "oai:arXiv.org:1010.2354"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper studies the problem of predicting the coding effort for a\nsubsequent year of development by analysing metrics extracted from project\nrepositories, with an emphasis on projects containing XML code. The study\nconsiders thirteen open source projects and applies machine learning algorithms\nto generate models to predict one-year coding effort, measured in terms of\nlines of code added, modified and deleted. Both organisational and code metrics\nassociated to revisions are taken into account. The results show that coding\neffort is highly determined by the expertise of developers while source code\nmetrics have little effect on improving the accuracy of estimations of coding\neffort. The study also shows that models trained on one project are unreliable\nat estimating effort in other projects.\n"}}], "languages": [null], "subjects": ["d.2.9", "d.2.8", "d.2.7", "computer science - software engineering"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1010.2354"}}, {"publisher": {"name": ""}, "description": "  In a currently ongoing project, we investigate a new possibility for solving\nthe k-labelled spanning forest (kLSF) problem by an intelligent Variable\nNeighbourhood Search (Int-VNS) metaheuristic. In the kLSF problem we are given\nan undirected input graph G and an integer positive value k, and the aim is to\nfind a spanning forest of G having the minimum number of connected components\nand the upper bound k on the number of labels to use. The problem is related to\nthe minimum labelling spanning tree (MLST) problem, whose goal is to get the\nspanning tree of the input graph with the minimum number of labels, and has\nseveral applications in the real world, where one aims to ensure connectivity\nby means of homogeneous connections. The Int-VNS metaheuristic that we propose\nfor the kLSF problem is derived from the promising intelligent VNS strategy\nrecently proposed for the MLST problem, and integrates the basic VNS for the\nkLSF problem with other complementary approaches from machine learning,\nstatistics and experimental algorithmics, in order to produce high-quality\nperformance and to completely automate the resulting strategy.\n", "contributors": [{"name": "Consoli, Sergio", "sameAs": [], "familyName": "Consoli", "additionalName": "", "givenName": "Sergio", "email": ""}, {"name": "P\u00e8rez, Jos\u00e8 Andr\u00e8s Moreno", "sameAs": [], "familyName": "P\u00e8rez", "additionalName": "Andr\u00e8s Moreno", "givenName": "Jos\u00e8", "email": ""}, {"name": "Mladenovic, Nenad", "sameAs": [], "familyName": "Mladenovic", "additionalName": "", "givenName": "Nenad", "email": ""}], "title": "Towards an intelligent VNS heuristic for the k-labelled spanning forest\n  problem", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02009", "Computer Aided Systems Theory, pages 79-80 (2015)", "oai:arXiv.org:1503.02009"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In a currently ongoing project, we investigate a new possibility for solving\nthe k-labelled spanning forest (kLSF) problem by an intelligent Variable\nNeighbourhood Search (Int-VNS) metaheuristic. In the kLSF problem we are given\nan undirected input graph G and an integer positive value k, and the aim is to\nfind a spanning forest of G having the minimum number of connected components\nand the upper bound k on the number of labels to use. The problem is related to\nthe minimum labelling spanning tree (MLST) problem, whose goal is to get the\nspanning tree of the input graph with the minimum number of labels, and has\nseveral applications in the real world, where one aims to ensure connectivity\nby means of homogeneous connections. The Int-VNS metaheuristic that we propose\nfor the kLSF problem is derived from the promising intelligent VNS strategy\nrecently proposed for the MLST problem, and integrates the basic VNS for the\nkLSF problem with other complementary approaches from machine learning,\nstatistics and experimental algorithmics, in order to produce high-quality\nperformance and to completely automate the resulting strategy.\n", "Comment: 2 pages, Fifteenth International Conference on Computer Aided Systems\n  Theory (EUROCAST 2015), Las Palmas de Gran Canaria, Spain"]}}], "languages": [null], "subjects": ["computer science - other computer science", "computer science - artificial intelligence"], "providerUpdatedDateTime": "2015-03-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02009"}}, {"publisher": {"name": ""}, "description": "  Gibbs random fields play an important role in statistics, however, the\nresulting likelihood is typically unavailable due to an intractable normalizing\nconstant. Composite likelihoods offer a principled means to construct useful\napproximations. This paper provides a mean to calibrate the posterior\ndistribution resulting from using a composite likelihood and illustrate its\nperformance in several examples.\n", "contributors": [{"name": "Stoehr, Julien", "sameAs": [], "familyName": "Stoehr", "additionalName": "", "givenName": "Julien", "email": ""}, {"name": "Friel, Nial", "sameAs": [], "familyName": "Friel", "additionalName": "", "givenName": "Nial", "email": ""}], "title": "Calibration of conditional composite likelihood for Bayesian inference\n  on Gibbs random fields", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01997", "oai:arXiv.org:1502.01997"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "stat"]}}, {"name": "description", "properties": {"description": "  Gibbs random fields play an important role in statistics, however, the\nresulting likelihood is typically unavailable due to an intractable normalizing\nconstant. Composite likelihoods offer a principled means to construct useful\napproximations. This paper provides a mean to calibrate the posterior\ndistribution resulting from using a composite likelihood and illustrate its\nperformance in several examples.\n"}}], "languages": [null], "subjects": ["mathematics - statistics theory", "statistics - computation"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01997"}}, {"publisher": {"name": ""}, "description": "  Mean Shift today, is widely used for mode detection and clustering. The\ntechnique though, is challenged in practice due to assumptions of isotropicity\nand homoscedasticity. We present an adaptive Mean Shift methodology that allows\nfor full anisotropic clustering, through unsupervised local bandwidth\nselection. The bandwidth matrices evolve naturally, adapting locally through\nagglomeration, and in turn guiding further agglomeration. The online\nmethodology is practical and effecive for low-dimensional feature spaces,\npreserving better detail and clustering salience. Additionally, conventional\nMean Shift either critically depends on a per instance choice of bandwidth, or\nrelies on offline methods which are inflexible and/or again data instance\nspecific. The presented approach, due to its adaptive design, also alleviates\nthis issue - with a default form performing generally well. The methodology\nthough, allows for effective tuning of results.\n", "contributors": [{"name": "Sawhney, Rahul", "sameAs": [], "familyName": "Sawhney", "additionalName": "", "givenName": "Rahul", "email": ""}, {"name": "Christensen, Henrik I.", "sameAs": [], "familyName": "Christensen", "additionalName": "I.", "givenName": "Henrik", "email": ""}, {"name": "Bradski, Gary R.", "sameAs": [], "familyName": "Bradski", "additionalName": "R.", "givenName": "Gary", "email": ""}], "title": "Anisotropic Agglomerative Adaptive Mean-Shift", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4102", "oai:arXiv.org:1411.4102"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Mean Shift today, is widely used for mode detection and clustering. The\ntechnique though, is challenged in practice due to assumptions of isotropicity\nand homoscedasticity. We present an adaptive Mean Shift methodology that allows\nfor full anisotropic clustering, through unsupervised local bandwidth\nselection. The bandwidth matrices evolve naturally, adapting locally through\nagglomeration, and in turn guiding further agglomeration. The online\nmethodology is practical and effecive for low-dimensional feature spaces,\npreserving better detail and clustering salience. Additionally, conventional\nMean Shift either critically depends on a per instance choice of bandwidth, or\nrelies on offline methods which are inflexible and/or again data instance\nspecific. The presented approach, due to its adaptive design, also alleviates\nthis issue - with a default form performing generally well. The methodology\nthough, allows for effective tuning of results.\n", "Comment: British Machine Vision Conference, 2014"]}}], "languages": [null], "subjects": ["computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4102"}}, {"publisher": {"name": ""}, "description": "  Erasure coding is a storage-efficient alternative to replication for\nachieving reliable data backup in distributed storage systems. During the\nstorage process, traditional erasure codes require a unique source node to\ncreate and upload all the redundant data to the different storage nodes.\nHowever, such a source node may have limited communication and computation\ncapabilities, which constrain the storage process throughput. Moreover, the\nsource node and the different storage nodes might not be able to send and\nreceive data simultaneously -- e.g., nodes might be busy in a datacenter\nsetting, or simply be offline in a peer-to-peer setting -- which can further\nthreaten the efficacy of the overall storage process. In this paper we propose\nan \"in-network\" redundancy generation process which distributes the data\ninsertion load among the source and storage nodes by allowing the storage nodes\nto generate new redundant data by exchanging partial information among\nthemselves, improving the throughput of the storage process. The process is\ncarried out asynchronously, utilizing spare bandwidth and computing resources\nfrom the storage nodes. The proposed approach leverages on the local\nrepairability property of newly proposed erasure codes tailor made for the\nneeds of distributed storage systems. We analytically show that the performance\nof this technique relies on an efficient usage of the spare node resources, and\nwe derive a set of scheduling algorithms to maximize the same. We\nexperimentally show, using availability traces from real peer-to-peer\napplications as well as Google data center availability and workload traces,\nthat our algorithms can, depending on the environment characteristics, increase\nthe throughput of the storage process significantly (up to 90% in data centers,\nand 60% in peer-to-peer settings) with respect to the classical naive data\ninsertion approach.\n", "contributors": [{"name": "Pamies-Juarez, Lluis", "sameAs": [], "familyName": "Pamies-Juarez", "additionalName": "", "givenName": "Lluis", "email": ""}, {"name": "Datta, Anwitaman", "sameAs": [], "familyName": "Datta", "additionalName": "", "givenName": "Anwitaman", "email": ""}, {"name": "Oggier, Fr\u00e9d\u00e9rique", "sameAs": [], "familyName": "Oggier", "additionalName": "", "givenName": "Fr\u00e9d\u00e9rique", "email": ""}], "title": "In-Network Redundancy Generation for Opportunistic Speedup of Backup", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-18", "2013-02-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.4533", "Future Generation Computer Systems (Volume 29, Issue 6, August\n  2013, Pages 1353-1362)", "doi:10.1016/j.future.2013.02.009", "oai:arXiv.org:1111.4533"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Erasure coding is a storage-efficient alternative to replication for\nachieving reliable data backup in distributed storage systems. During the\nstorage process, traditional erasure codes require a unique source node to\ncreate and upload all the redundant data to the different storage nodes.\nHowever, such a source node may have limited communication and computation\ncapabilities, which constrain the storage process throughput. Moreover, the\nsource node and the different storage nodes might not be able to send and\nreceive data simultaneously -- e.g., nodes might be busy in a datacenter\nsetting, or simply be offline in a peer-to-peer setting -- which can further\nthreaten the efficacy of the overall storage process. In this paper we propose\nan \"in-network\" redundancy generation process which distributes the data\ninsertion load among the source and storage nodes by allowing the storage nodes\nto generate new redundant data by exchanging partial information among\nthemselves, improving the throughput of the storage process. The process is\ncarried out asynchronously, utilizing spare bandwidth and computing resources\nfrom the storage nodes. The proposed approach leverages on the local\nrepairability property of newly proposed erasure codes tailor made for the\nneeds of distributed storage systems. We analytically show that the performance\nof this technique relies on an efficient usage of the spare node resources, and\nwe derive a set of scheduling algorithms to maximize the same. We\nexperimentally show, using availability traces from real peer-to-peer\napplications as well as Google data center availability and workload traces,\nthat our algorithms can, depending on the environment characteristics, increase\nthe throughput of the storage process significantly (up to 90% in data centers,\nand 60% in peer-to-peer settings) with respect to the classical naive data\ninsertion approach.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "computer science - networking and internet architecture", "computer science - information theory", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.4533"}}, {"publisher": {"name": ""}, "description": "  The use of partial geometries to construct parity-check matrices for LDPC\ncodes has resulted in the design of successful codes with a probability of\nerror close to the Shannon capacity at bit error rates down to $10^{-15}$. Such\nconsiderations have motivated this further investigation. A new and simple\nconstruction of a type of partial geometries with quasi-cyclic structure is\ngiven and their properties are investigated. The trapping sets of the partial\ngeometry codes were considered previously using the geometric aspects of the\nunderlying structure to derive information on the size of allowable trapping\nsets. This topic is further considered here. Finally, there is a natural\nrelationship between partial geometries and strongly regular graphs. The\neigenvalues of the adjacency matrices of such graphs are well known and it is\nof interest to determine if any of the Tanner graphs derived from the partial\ngeometries are good expanders for certain parameter sets, since it can be\nargued that codes with good geometric and expansion properties might perform\nwell under message-passing decoding.\n", "contributors": [{"name": "Diao, Qiuju", "sameAs": [], "familyName": "Diao", "additionalName": "", "givenName": "Qiuju", "email": ""}, {"name": "Li, Juane", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Juane", "email": ""}, {"name": "Lin, Shu", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Shu", "email": ""}, {"name": "Blake, Ian", "sameAs": [], "familyName": "Blake", "additionalName": "", "givenName": "Ian", "email": ""}], "title": "New Classes of Partial Geometries and Their Associated LDPC Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06900", "oai:arXiv.org:1503.06900"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The use of partial geometries to construct parity-check matrices for LDPC\ncodes has resulted in the design of successful codes with a probability of\nerror close to the Shannon capacity at bit error rates down to $10^{-15}$. Such\nconsiderations have motivated this further investigation. A new and simple\nconstruction of a type of partial geometries with quasi-cyclic structure is\ngiven and their properties are investigated. The trapping sets of the partial\ngeometry codes were considered previously using the geometric aspects of the\nunderlying structure to derive information on the size of allowable trapping\nsets. This topic is further considered here. Finally, there is a natural\nrelationship between partial geometries and strongly regular graphs. The\neigenvalues of the adjacency matrices of such graphs are well known and it is\nof interest to determine if any of the Tanner graphs derived from the partial\ngeometries are good expanders for certain parameter sets, since it can be\nargued that codes with good geometric and expansion properties might perform\nwell under message-passing decoding.\n", "Comment: 34 pages with single column, 6 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06900"}}, {"publisher": {"name": "Lippincott Williams & Wilkins"}, "description": "", "contributors": [{"name": "deKleijn, Miriam", "sameAs": [], "familyName": "deKleijn", "additionalName": "", "givenName": "Miriam", "email": ""}, {"name": "Lagro-Janssen, Antoine L.M.", "sameAs": [], "familyName": "Lagro-Janssen", "additionalName": "L.M.", "givenName": "Antoine", "email": ""}, {"name": "Canelo, Ismelda", "sameAs": [], "familyName": "Canelo", "additionalName": "", "givenName": "Ismelda", "email": ""}, {"name": "Yano, Elizabeth M.", "sameAs": [], "familyName": "Yano", "additionalName": "M.", "givenName": "Elizabeth", "email": ""}], "title": "Creating a Roadmap for Delivering Gender-sensitive Comprehensive Care for Women Veterans: Results of a National Expert Panel", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["transforming comprehensive care"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4379113"}}, {"publisher": {"name": ""}, "description": "  The problem of optimal switching between nonlinear autonomous subsystems is\ninvestigated in this study where the objective is not only bringing the states\nto close to the desired point, but also adjusting the switching pattern, in the\nsense of penalizing switching occurrences and assigning different preferences\nto utilization of different modes. The mode sequence is unspecified and a\nswitching cost term is used in the cost function for penalizing each switching.\nIt is shown that once a switching cost is incorporated, the optimal cost-to-go\nfunction depends on the already active subsystem, i.e., the subsystem which was\nengaged in the previous time step. Afterwards, an approximate dynamic\nprogramming based method is developed which provides an approximation of the\noptimal solution to the problem in a feedback form and for different initial\nconditions. Finally, the performance of the method is analyzed through\nnumerical examples.\n", "contributors": [{"name": "Heydari, Ali", "sameAs": [], "familyName": "Heydari", "additionalName": "", "givenName": "Ali", "email": ""}], "title": "Feedback Solution to Optimal Switching Problems with Switching Cost", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4695", "oai:arXiv.org:1411.4695"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  The problem of optimal switching between nonlinear autonomous subsystems is\ninvestigated in this study where the objective is not only bringing the states\nto close to the desired point, but also adjusting the switching pattern, in the\nsense of penalizing switching occurrences and assigning different preferences\nto utilization of different modes. The mode sequence is unspecified and a\nswitching cost term is used in the cost function for penalizing each switching.\nIt is shown that once a switching cost is incorporated, the optimal cost-to-go\nfunction depends on the already active subsystem, i.e., the subsystem which was\nengaged in the previous time step. Afterwards, an approximate dynamic\nprogramming based method is developed which provides an approximation of the\noptimal solution to the problem in a feedback form and for different initial\nconditions. Finally, the performance of the method is analyzed through\nnumerical examples.\n"}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "statistics - machine learning"], "providerUpdatedDateTime": "2014-11-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4695"}}, {"publisher": {"name": ""}, "description": "  We consider the question of defining interleaving metrics on generalized\npersistence modules over arbitrary preordered sets. Our constructions are\nfunctorial, which implies a form of stability for these metrics. We describe a\nlarge class of examples, inverse-image persistence modules, which occur\nwhenever a topological space is mapped to a metric space. Several standard\ntheories of persistence and their stability can be described in this framework.\nThis includes the classical case of sublevelset persistent homology. We\nintroduce a distinction between `soft' and `hard' stability theorems. While our\ntreatment is direct and elementary, the approach can be explained abstractly in\nterms of monoidal functors.\n", "contributors": [{"name": "Bubenik, Peter", "sameAs": [], "familyName": "Bubenik", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "de Silva, Vin", "sameAs": [], "familyName": "de Silva", "additionalName": "", "givenName": "Vin", "email": ""}, {"name": "Scott, Jonathan", "sameAs": [], "familyName": "Scott", "additionalName": "", "givenName": "Jonathan", "email": ""}], "title": "Metrics for generalized persistence modules", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-13", "2014-08-21"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.3829", "doi:10.1007/s10208-014-9229-5", "oai:arXiv.org:1312.3829"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider the question of defining interleaving metrics on generalized\npersistence modules over arbitrary preordered sets. Our constructions are\nfunctorial, which implies a form of stability for these metrics. We describe a\nlarge class of examples, inverse-image persistence modules, which occur\nwhenever a topological space is mapped to a metric space. Several standard\ntheories of persistence and their stability can be described in this framework.\nThis includes the classical case of sublevelset persistent homology. We\nintroduce a distinction between `soft' and `hard' stability theorems. While our\ntreatment is direct and elementary, the approach can be explained abstractly in\nterms of monoidal functors.\n", "Comment: 29 pages"]}}], "languages": [null], "subjects": ["68u05", "55u99", "mathematics - algebraic topology", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-01-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.3829"}}, {"publisher": {"name": ""}, "description": "  The success of many machine learning and pattern recognition methods relies\nheavily upon the identification of an appropriate distance metric on the input\ndata. It is often beneficial to learn such a metric from the input training\ndata, instead of using a default one such as the Euclidean distance. In this\nwork, we propose a boosting-based technique, termed BoostMetric, for learning a\nquadratic Mahalanobis distance metric. Learning a valid Mahalanobis distance\nmetric requires enforcing the constraint that the matrix parameter to the\nmetric remains positive definite. Semidefinite programming is often used to\nenforce this constraint, but does not scale well and easy to implement.\nBoostMetric is instead based on the observation that any positive semidefinite\nmatrix can be decomposed into a linear combination of trace-one rank-one\nmatrices. BoostMetric thus uses rank-one positive semidefinite matrices as weak\nlearners within an efficient and scalable boosting-based learning process. The\nresulting methods are easy to implement, efficient, and can accommodate various\ntypes of constraints. We extend traditional boosting algorithms in that its\nweak learner is a positive semidefinite matrix with trace and rank being one\nrather than a classifier or regressor. Experiments on various datasets\ndemonstrate that the proposed algorithms compare favorably to those\nstate-of-the-art methods in terms of classification accuracy and running time.\n", "contributors": [{"name": "Shen, Chunhua", "sameAs": [], "familyName": "Shen", "additionalName": "", "givenName": "Chunhua", "email": ""}, {"name": "Kim, Junae", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Junae", "email": ""}, {"name": "Wang, Lei", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Lei", "email": ""}, {"name": "Hengel, Anton van den", "sameAs": [], "familyName": "Hengel", "additionalName": "van den", "givenName": "Anton", "email": ""}], "title": "Positive Semidefinite Metric Learning Using Boosting-like Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-25", "2012-04-12"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.4704", "oai:arXiv.org:1104.4704"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The success of many machine learning and pattern recognition methods relies\nheavily upon the identification of an appropriate distance metric on the input\ndata. It is often beneficial to learn such a metric from the input training\ndata, instead of using a default one such as the Euclidean distance. In this\nwork, we propose a boosting-based technique, termed BoostMetric, for learning a\nquadratic Mahalanobis distance metric. Learning a valid Mahalanobis distance\nmetric requires enforcing the constraint that the matrix parameter to the\nmetric remains positive definite. Semidefinite programming is often used to\nenforce this constraint, but does not scale well and easy to implement.\nBoostMetric is instead based on the observation that any positive semidefinite\nmatrix can be decomposed into a linear combination of trace-one rank-one\nmatrices. BoostMetric thus uses rank-one positive semidefinite matrices as weak\nlearners within an efficient and scalable boosting-based learning process. The\nresulting methods are easy to implement, efficient, and can accommodate various\ntypes of constraints. We extend traditional boosting algorithms in that its\nweak learner is a positive semidefinite matrix with trace and rank being one\nrather than a classifier or regressor. Experiments on various datasets\ndemonstrate that the proposed algorithms compare favorably to those\nstate-of-the-art methods in terms of classification accuracy and running time.\n", "Comment: 30 pages, appearing in Journal of Machine Learning Research"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.4704"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "We give a comprehensive theoretical characterization of a nonparametric estimator for the L_2^2 divergence between two continuous distributions. We first bound the rate of convergence of our estimator, showing that it is \u221an-consistent provided the densities are sufficiently smooth. In this smooth regime, we then show that our estimator is asymptotically normal, construct asymptotic confidence intervals, and establish a Berry-Ess\\'{e}en style inequality characterizing the rate of convergence to normality. We also show that this estimator is minimax optimal.", "contributors": [{"name": "Krishnamurthy, Akshay", "sameAs": [], "familyName": "Krishnamurthy", "additionalName": "", "givenName": "Akshay", "email": ""}, {"name": "Kandasamy, Kirthevasan", "sameAs": [], "familyName": "Kandasamy", "additionalName": "", "givenName": "Kirthevasan", "email": ""}, {"name": "Poczos, Barnabas", "sameAs": [], "familyName": "Poczos", "additionalName": "", "givenName": "Barnabas", "email": ""}, {"name": "Wasserman, Larry", "sameAs": [], "familyName": "Wasserman", "additionalName": "", "givenName": "Larry", "email": ""}], "title": "On Estimating L_2^2 Divergence", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-10-31T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/84", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1076&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1076"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "We give a comprehensive theoretical characterization of a nonparametric estimator for the L_2^2 divergence between two continuous distributions. We first bound the rate of convergence of our estimator, showing that it is \u221an-consistent provided the densities are sufficiently smooth. In this smooth regime, we then show that our estimator is asymptotically normal, construct asymptotic confidence intervals, and establish a Berry-Ess\\'{e}en style inequality characterizing the rate of convergence to normality. We also show that this estimator is minimax optimal."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-13T21:23:49", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/84"}}, {"publisher": {"name": "DigitalCommons@CalPoly"}, "description": "This project includes the imagining, design, build, and test of a web application that creates and tracks a user\u2019s progress on completing tasks that an administrator has created for the user. The goal of this project is to have a functioning webpage that is robust and scalable to support many users and many tasks. The application will be developed for use on all modern web browsers, and will have a persistent server to access from any platform. This project was designed to be an exercise in building a modern web application, and as such is written using many different languages, APIs and libraries. The front-end is setup in HTML and CSS, with an approach that a web-designer might update the aesthetic of the application. MySQL is utilized for the server databasing implementation, and PHP, JavaScript and JQuery are used as the bridge between the database and the front-end of the application.", "contributors": [{"name": "Green, Ryan", "sameAs": [], "familyName": "Green", "additionalName": "", "givenName": "Ryan", "email": ""}], "title": "Badge Web Application", "shareProperties": {"source": "calpoly"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "source", "properties": {"source": "Computer Engineering"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-12-01T08:00:00Z"}}, {"name": "setSpec", "properties": {"setSpec": "publication:cpesp"}}], "languages": [null], "subjects": ["web application", "data storage systems", "other computer engineering", "software"], "providerUpdatedDateTime": "2014-12-17T20:09:38", "uris": {"canonicalUri": "http://digitalcommons.calpoly.edu/cpesp/143"}}, {"publisher": {"name": ""}, "description": "  We generalize a well-known algorithm for the generation of all subsets of a\nset in lexicographic order with respect to the sets as lists of elements\n(subset-lex order). We obtain algorithms for various combinatorial objects such\nas the subsets of a multiset, compositions and partitions represented as lists\nof parts, and for certain restricted growth strings. The algorithms are often\nloopless and require at most one extra variable for the computation of the next\nobject. The performance of the algorithms is very competitive even when not\nloopless. A Gray code corresponding to the subset-lex order and a Gray code for\ncompositions that was found during this work are described.\n", "contributors": [{"name": "Arndt, J\u00f6rg", "sameAs": [], "familyName": "Arndt", "additionalName": "", "givenName": "J\u00f6rg", "email": ""}], "title": "Subset-lex: did we miss an order?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-26", "2014-12-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.6503", "oai:arXiv.org:1405.6503"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We generalize a well-known algorithm for the generation of all subsets of a\nset in lexicographic order with respect to the sets as lists of elements\n(subset-lex order). We obtain algorithms for various combinatorial objects such\nas the subsets of a multiset, compositions and partitions represented as lists\nof parts, and for certain restricted growth strings. The algorithms are often\nloopless and require at most one extra variable for the computation of the next\nobject. The performance of the algorithms is very competitive even when not\nloopless. A Gray code corresponding to the subset-lex order and a Gray code for\ncompositions that was found during this work are described.\n", "Comment: Two obvious errors corrected (indicated by \"Correction:\" in the LaTeX\n  source)"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.6503"}}, {"publisher": {"name": ""}, "description": "  One of the most efficient ways of generating goal-directed walking motions is\nsynthesising the final motion based on footprints. Nevertheless, current\nimplementations have not examined the generation of continuous motion based on\nfootprints, where different behaviours can be generated automatically.\nTherefore, in this paper a flexible approach for footprint-driven locomotion\ncomposition is presented. The presented solution is based on the ability to\ngenerate footprint-driven locomotion, with flexible features like jumping,\nrunning, and stair stepping. In addition, the presented system examines the\nability of generating the desired motion of the character based on predefined\nfootprint patterns that determine which behaviour should be performed. Finally,\nit is examined the generation of transition patterns based on the velocity of\nthe root and the number of footsteps required to achieve the target behaviour\nsmoothly and naturally.\n", "contributors": [{"name": "Mousas, Christos", "sameAs": [], "familyName": "Mousas", "additionalName": "", "givenName": "Christos", "email": ""}, {"name": "Newbury, Paul", "sameAs": [], "familyName": "Newbury", "additionalName": "", "givenName": "Paul", "email": ""}, {"name": "Anagnostopoulos, Christos-Nikolaos", "sameAs": [], "familyName": "Anagnostopoulos", "additionalName": "", "givenName": "Christos-Nikolaos", "email": ""}], "title": "Footprint-Driven Locomotion Composition", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1906", "International Journal of Computer Graphics & Animation (IJCGA)\n  Vol.4, No.4, pp. 27-42, October 2014", "doi:10.5121/ijcga.2014.4403", "oai:arXiv.org:1411.1906"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  One of the most efficient ways of generating goal-directed walking motions is\nsynthesising the final motion based on footprints. Nevertheless, current\nimplementations have not examined the generation of continuous motion based on\nfootprints, where different behaviours can be generated automatically.\nTherefore, in this paper a flexible approach for footprint-driven locomotion\ncomposition is presented. The presented solution is based on the ability to\ngenerate footprint-driven locomotion, with flexible features like jumping,\nrunning, and stair stepping. In addition, the presented system examines the\nability of generating the desired motion of the character based on predefined\nfootprint patterns that determine which behaviour should be performed. Finally,\nit is examined the generation of transition patterns based on the velocity of\nthe root and the number of footsteps required to achieve the target behaviour\nsmoothly and naturally.\n"}}], "languages": [null], "subjects": ["computer science - graphics"], "providerUpdatedDateTime": "2014-11-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1906"}}, {"publisher": {"name": ""}, "description": "  A disk graph is the intersection graph of disks in the plane, a unit disk\ngraph is the intersection graph of same radius disks in the plane, and a\nsegment graph is an intersection graph of line segments in the plane. It can be\nseen that every disk graph can be realized by disks with centers on the integer\ngrid and with integer radii; and similarly every unit disk graph can be\nrealized by disks with centers on the integer grid and equal (integer) radius;\nand every segment graph can be realized by segments whose endpoints lie on the\ninteger grid. Here we show that there exist disk graphs on $n$ vertices such\nthat in every realization by integer disks at least one coordinate or radius is\n$2^{2^{\\Omega(n)}}$ and on the other hand every disk graph can be realized by\ndisks with integer coordinates and radii that are at most $2^{2^{O(n)}}$; and\nwe show the analogous results for unit disk graphs and segment graphs. For\n(unit) disk graphs this answers a question of Spinrad, and for segment graphs\nthis improves over a previous result by Kratochv\\'{\\i}l and Matou{\\v{s}}ek.\n", "contributors": [{"name": "McDiarmid, Colin", "sameAs": [], "familyName": "McDiarmid", "additionalName": "", "givenName": "Colin", "email": ""}, {"name": "Muller, Tobias", "sameAs": [], "familyName": "Muller", "additionalName": "", "givenName": "Tobias", "email": ""}], "title": "Integer realizations of disk and segment graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-12", "2011-11-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.2931", "oai:arXiv.org:1111.2931"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A disk graph is the intersection graph of disks in the plane, a unit disk\ngraph is the intersection graph of same radius disks in the plane, and a\nsegment graph is an intersection graph of line segments in the plane. It can be\nseen that every disk graph can be realized by disks with centers on the integer\ngrid and with integer radii; and similarly every unit disk graph can be\nrealized by disks with centers on the integer grid and equal (integer) radius;\nand every segment graph can be realized by segments whose endpoints lie on the\ninteger grid. Here we show that there exist disk graphs on $n$ vertices such\nthat in every realization by integer disks at least one coordinate or radius is\n$2^{2^{\\Omega(n)}}$ and on the other hand every disk graph can be realized by\ndisks with integer coordinates and radii that are at most $2^{2^{O(n)}}$; and\nwe show the analogous results for unit disk graphs and segment graphs. For\n(unit) disk graphs this answers a question of Spinrad, and for segment graphs\nthis improves over a previous result by Kratochv\\'{\\i}l and Matou{\\v{s}}ek.\n", "Comment: 35 pages, 14 figures, corrected a typo"]}}], "languages": [null], "subjects": ["mathematics - metric geometry", "mathematics - combinatorics", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.2931"}}, {"publisher": {"name": ""}, "description": "  In this paper, we generalize Huber's criterion to multichannel sparse\nrecovery problem of complex-valued measurements where the objective is to find\ngood recovery of jointly sparse unknown signal vectors from the given multiple\nmeasurement vectors which are different linear combinations of the same known\nelementary vectors. This requires careful characterization of robust\ncomplex-valued loss functions as well as Huber's criterion function for the\nmultivariate sparse regression problem. We devise a greedy algorithm based on\nsimultaneous normalized iterative hard thresholding (SNIHT) algorithm. Unlike\nthe conventional SNIHT method, our algorithm, referred to as HUB-SNIHT, is\nrobust under heavy-tailed non-Gaussian noise conditions, yet has a negligible\nperformance loss compared to SNIHT under Gaussian noise. Usefulness of the\nmethod is illustrated in source localization application with sensor arrays.\n", "contributors": [{"name": "Ollila, Esa", "sameAs": [], "familyName": "Ollila", "additionalName": "", "givenName": "Esa", "email": ""}], "title": "Multichannel sparse recovery of complex-valued signals using Huber's\n  criterion", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.04184", "oai:arXiv.org:1504.04184"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  In this paper, we generalize Huber's criterion to multichannel sparse\nrecovery problem of complex-valued measurements where the objective is to find\ngood recovery of jointly sparse unknown signal vectors from the given multiple\nmeasurement vectors which are different linear combinations of the same known\nelementary vectors. This requires careful characterization of robust\ncomplex-valued loss functions as well as Huber's criterion function for the\nmultivariate sparse regression problem. We devise a greedy algorithm based on\nsimultaneous normalized iterative hard thresholding (SNIHT) algorithm. Unlike\nthe conventional SNIHT method, our algorithm, referred to as HUB-SNIHT, is\nrobust under heavy-tailed non-Gaussian noise conditions, yet has a negligible\nperformance loss compared to SNIHT under Gaussian noise. Usefulness of the\nmethod is illustrated in source localization application with sensor arrays.\n", "Comment: To appear in CoSeRa'15 (Pisa, Italy, June 16-19, 2015). arXiv admin\n  note: text overlap with arXiv:1502.02441"]}}], "languages": [null], "subjects": ["statistics - computation", "computer science - information theory", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.04184"}}, {"publisher": {"name": ""}, "description": "  In this paper, we describe a new vector similarity measure associated with a\nconvex cost function. Given two vectors, we determine the surface normals of\nthe convex function at the vectors. The angle between the two surface normals\nis the similarity measure. Convex cost function can be the negative entropy\nfunction, total variation (TV) function and filtered variation function. The\nconvex cost function need not be differentiable everywhere. In general, we need\nto compute the gradient of the cost function to compute the surface normals. If\nthe gradient does not exist at a given vector, it is possible to use the\nsubgradients and the normal producing the smallest angle between the two\nvectors is used to compute the similarity measure.\n", "contributors": [{"name": "Gunay, Osman", "sameAs": [], "familyName": "Gunay", "additionalName": "", "givenName": "Osman", "email": ""}, {"name": "Akbas, Cem Emre", "sameAs": [], "familyName": "Akbas", "additionalName": "Emre", "givenName": "Cem", "email": ""}, {"name": "Cetin, A. Enis", "sameAs": [], "familyName": "Cetin", "additionalName": "Enis", "givenName": "A.", "email": ""}], "title": "Cosine Similarity Measure According to a Convex Cost Function", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6093", "oai:arXiv.org:1410.6093"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we describe a new vector similarity measure associated with a\nconvex cost function. Given two vectors, we determine the surface normals of\nthe convex function at the vectors. The angle between the two surface normals\nis the similarity measure. Convex cost function can be the negative entropy\nfunction, total variation (TV) function and filtered variation function. The\nconvex cost function need not be differentiable everywhere. In general, we need\nto compute the gradient of the cost function to compute the surface normals. If\nthe gradient does not exist at a given vector, it is possible to use the\nsubgradients and the normal producing the smallest angle between the two\nvectors is used to compute the similarity measure.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2014-10-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6093"}}, {"publisher": {"name": ""}, "description": "  Wireless sensor networks have profound effects on many application fields\nlike security management which need an immediate and fast system reaction.\nIndeed, the monitoring of a dangerous product warehouse is a major issue in\nchemical industry field. This paper describes the design of chemical warehouse\nsecurity system using the concept of active products and wireless sensor\nnetworks. A security application layer is developed to supervise and exchange\nmessages between nodes and the control center to prevent industrial accident.\nDifferent security rules are proposed on this layer to monitor the internal\nstate and incompatible products distance. If a critical event is detected, the\napplication generates alert message which need a short end to end delay and low\npacket loss rate constraints by network layer. Thus, a QoS routing protocol is\nalso developed in the network layer. The proposed solution is implemented in\nCastalia/OMNeT++ simulator. Simulation results show that the system reacts\nperfectly for critical event and can meet the QoS constraints of alert message.\n", "contributors": [{"name": "Zouinkhi, Ahmed", "sameAs": [], "familyName": "Zouinkhi", "additionalName": "", "givenName": "Ahmed", "email": ""}, {"name": "Mekki, Kais", "sameAs": [], "familyName": "Mekki", "additionalName": "", "givenName": "Kais", "email": ""}, {"name": "Abdelkrim, Mohamed Naceur", "sameAs": [], "familyName": "Abdelkrim", "additionalName": "Naceur", "givenName": "Mohamed", "email": ""}], "title": "Application and network layers design for wireless sensor network to\n  supervise chemical active product warehouse", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.01193", "doi:10.5121/ijcsea.2014.4605", "oai:arXiv.org:1501.01193"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Wireless sensor networks have profound effects on many application fields\nlike security management which need an immediate and fast system reaction.\nIndeed, the monitoring of a dangerous product warehouse is a major issue in\nchemical industry field. This paper describes the design of chemical warehouse\nsecurity system using the concept of active products and wireless sensor\nnetworks. A security application layer is developed to supervise and exchange\nmessages between nodes and the control center to prevent industrial accident.\nDifferent security rules are proposed on this layer to monitor the internal\nstate and incompatible products distance. If a critical event is detected, the\napplication generates alert message which need a short end to end delay and low\npacket loss rate constraints by network layer. Thus, a QoS routing protocol is\nalso developed in the network layer. The proposed solution is implemented in\nCastalia/OMNeT++ simulator. Simulation results show that the system reacts\nperfectly for critical event and can meet the QoS constraints of alert message.\n", "Comment: 20 pages in International Journal of Computer Science, Engineering\n  and Applications (IJCSEA), Vol.4, No.6, December 2014, pp. 53-72"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-01-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.01193"}}, {"publisher": {"name": ""}, "description": "  A K-quasiconformal selfmap of the unit disk with identity boundary values\nsatisfies the H\\\"older estimate $|f(z)-f(w)| \\leq 4^{1-1/K} |z-w|^{1/K}$. The\nconstant $4^{1-\\frac{1}{K}}$ is sharp.\n", "contributors": [{"name": "Prause, Istv\u00e1n", "sameAs": [], "familyName": "Prause", "additionalName": "", "givenName": "Istv\u00e1n", "email": ""}], "title": "On a H\\\"older constant in the theory of quasiconformal mappings", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-09-26", "2014-03-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1309.6748", "Comput. Methods. Funct. Theory 14 (2014) 483-486", "doi:10.1007/s40315-014-0060-4", "oai:arXiv.org:1309.6748"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  A K-quasiconformal selfmap of the unit disk with identity boundary values\nsatisfies the H\\\"older estimate $|f(z)-f(w)| \\leq 4^{1-1/K} |z-w|^{1/K}$. The\nconstant $4^{1-\\frac{1}{K}}$ is sharp.\n", "Comment: 3 pages, typos corrected, to appear in F.W. Gehring memorial volume\n  in CMFT"]}}], "languages": [null], "subjects": ["mathematics - complex variables"], "providerUpdatedDateTime": "2014-10-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1309.6748"}}, {"publisher": {"name": ""}, "description": "  In Social Science research, multimedia documents are often collected to\nanswer particular research questions like: \"Which of the aesthetic properties\nof a photo are considered important on the web\" or \"How has Street Art\ndeveloped over the past 50 years\". Therefore, a researcher generally issues\nmultiple queries to a number of search engines. This activity may span over\nlong time intervals and results in a collection which can be further analyzed.\nDocumenting the collection building process which includes the context of the\ncarried out searches is imperative for social scientists to reproduce their\nresearch. Such context documentation consists of several user actions and\nsearch attributes like: the issued queries; the results clicked and saved;\nduration a particular result was viewed for; the set of results that was\ndisplayed but neither clicked, nor saved; as well as user annotations like\ncomments or tags. In this work we will describe a search process tracking\nmodule and a search history visualization module. These modules can be\nintegrated into keyword based search systems through a REST API which was\ndeveloped to help capture, document and revisit past search contexts while\nbuilding a web corpora. Finally, we detail the implementation of how the module\nwas integrated into the LearnWeb2.0 platform - a multimedia web2.0 search and\nsharing application which can obtain resources from various web2.0 tools such\nas Youtube, Bing, Flickr, etc using keyword search.\n", "contributors": [{"name": "Fernando, Zeon Trevor", "sameAs": [], "familyName": "Fernando", "additionalName": "Trevor", "givenName": "Zeon", "email": ""}], "title": "Capturing, Documenting and Visualizing Search Contexts for building\n  Multimedia Corpora", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03660", "oai:arXiv.org:1503.03660"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In Social Science research, multimedia documents are often collected to\nanswer particular research questions like: \"Which of the aesthetic properties\nof a photo are considered important on the web\" or \"How has Street Art\ndeveloped over the past 50 years\". Therefore, a researcher generally issues\nmultiple queries to a number of search engines. This activity may span over\nlong time intervals and results in a collection which can be further analyzed.\nDocumenting the collection building process which includes the context of the\ncarried out searches is imperative for social scientists to reproduce their\nresearch. Such context documentation consists of several user actions and\nsearch attributes like: the issued queries; the results clicked and saved;\nduration a particular result was viewed for; the set of results that was\ndisplayed but neither clicked, nor saved; as well as user annotations like\ncomments or tags. In this work we will describe a search process tracking\nmodule and a search history visualization module. These modules can be\nintegrated into keyword based search systems through a REST API which was\ndeveloped to help capture, document and revisit past search contexts while\nbuilding a web corpora. Finally, we detail the implementation of how the module\nwas integrated into the LearnWeb2.0 platform - a multimedia web2.0 search and\nsharing application which can obtain resources from various web2.0 tools such\nas Youtube, Bing, Flickr, etc using keyword search.\n", "Comment: Undergraduate (B.Tech Hons, Computer Science) Thesis Report, 2014,\n  Vellore Institute of Technology, India"]}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - computers and society", "computer science - human-computer interaction", "computer science - software engineering"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03660"}}, {"publisher": {"name": ""}, "description": "  We give upper and lower bounds on the maximum and minimum number of geometric\nconfigurations of various kinds present (as subgraphs) in a triangulation of\n$n$ points in the plane. Configurations of interest include \\emph{convex\npolygons}, \\emph{star-shaped polygons} and \\emph{monotone paths}. We also\nconsider related problems for \\emph{directed} planar straight-line graphs.\n", "contributors": [{"name": "Dumitrescu, Adrian", "sameAs": [], "familyName": "Dumitrescu", "additionalName": "", "givenName": "Adrian", "email": ""}, {"name": "L\u00f6ffler, Maarten", "sameAs": [], "familyName": "L\u00f6ffler", "additionalName": "", "givenName": "Maarten", "email": ""}, {"name": "Schulz, Andr\u00e9", "sameAs": [], "familyName": "Schulz", "additionalName": "", "givenName": "Andr\u00e9", "email": ""}, {"name": "T\u00f3th, Csaba D.", "sameAs": [], "familyName": "T\u00f3th", "additionalName": "D.", "givenName": "Csaba", "email": ""}], "title": "Counting Carambolas", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1579", "oai:arXiv.org:1410.1579"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We give upper and lower bounds on the maximum and minimum number of geometric\nconfigurations of various kinds present (as subgraphs) in a triangulation of\n$n$ points in the plane. Configurations of interest include \\emph{convex\npolygons}, \\emph{star-shaped polygons} and \\emph{monotone paths}. We also\nconsider related problems for \\emph{directed} planar straight-line graphs.\n", "Comment: 16 pages, 13 figures"]}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-10-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1579"}}, {"publisher": {"name": ""}, "description": "  Polyhedral Omega is a new algorithm for solving linear Diophantine systems\n(LDS), i.e., for computing a multivariate rational function representation of\nthe set of all non-negative integer solutions to a system of linear equations\nand inequalities. Polyhedral Omega combines methods from partition analysis\nwith methods from polyhedral geometry. In particular, we combine MacMahon's\niterative approach based on the Omega operator and explicit formulas for its\nevaluation with geometric tools such as Brion decompositions and Barvinok's\nshort rational function representations. In this way, we connect two recent\nbranches of research that have so far remained separate, unified by the concept\nof symbolic cones which we introduce. The resulting LDS solver Polyhedral Omega\nis significantly faster than previous solvers based on partition analysis and\nit is competitive with state-of-the-art LDS solvers based on geometric methods.\nMost importantly, this synthesis of ideas makes Polyhedral Omega the simplest\nalgorithm for solving linear Diophantine systems available to date. Moreover,\nwe provide an illustrated geometric interpretation of partition analysis, with\nthe aim of making ideas from both areas accessible to readers from a wide range\nof backgrounds.\n", "contributors": [{"name": "Breuer, Felix", "sameAs": [], "familyName": "Breuer", "additionalName": "", "givenName": "Felix", "email": ""}, {"name": "Zafeirakopoulos, Zafeirakis", "sameAs": [], "familyName": "Zafeirakopoulos", "additionalName": "", "givenName": "Zafeirakis", "email": ""}], "title": "Polyhedral Omega: A New Algorithm for Solving Linear Diophantine Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.07773", "oai:arXiv.org:1501.07773"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Polyhedral Omega is a new algorithm for solving linear Diophantine systems\n(LDS), i.e., for computing a multivariate rational function representation of\nthe set of all non-negative integer solutions to a system of linear equations\nand inequalities. Polyhedral Omega combines methods from partition analysis\nwith methods from polyhedral geometry. In particular, we combine MacMahon's\niterative approach based on the Omega operator and explicit formulas for its\nevaluation with geometric tools such as Brion decompositions and Barvinok's\nshort rational function representations. In this way, we connect two recent\nbranches of research that have so far remained separate, unified by the concept\nof symbolic cones which we introduce. The resulting LDS solver Polyhedral Omega\nis significantly faster than previous solvers based on partition analysis and\nit is competitive with state-of-the-art LDS solvers based on geometric methods.\nMost importantly, this synthesis of ideas makes Polyhedral Omega the simplest\nalgorithm for solving linear Diophantine systems available to date. Moreover,\nwe provide an illustrated geometric interpretation of partition analysis, with\nthe aim of making ideas from both areas accessible to readers from a wide range\nof backgrounds.\n", "Comment: 49 pages, 17 figures"]}}], "languages": [null], "subjects": ["mathematics - number theory", "mathematics - combinatorics", "computer science - symbolic computation"], "providerUpdatedDateTime": "2015-02-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.07773"}}, {"publisher": {"name": ""}, "description": "  We solve a problem, stated in [CGP10], showing that Sticky Datalog, defined\nin the cited paper as an element of the Datalog\\pm project, has the finite\ncontrollability property. In order to do that, we develop a technique, which we\nbelieve can have further applications, of approximating Chase(D, T), for a\ndatabase instance D and some sets of tuple generating dependencies T, by an\ninfinite sequence of finite structures, all of them being models of T.\n", "contributors": [{"name": "Gogacz, T.", "sameAs": [], "familyName": "Gogacz", "additionalName": "", "givenName": "T.", "email": ""}, {"name": "Marcinkowski, J.", "sameAs": [], "familyName": "Marcinkowski", "additionalName": "", "givenName": "J.", "email": ""}], "title": "Converging to the Chase - a Tool for Finite Controllability", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-04-16", "2014-11-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1204.3432", "oai:arXiv.org:1204.3432"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We solve a problem, stated in [CGP10], showing that Sticky Datalog, defined\nin the cited paper as an element of the Datalog\\pm project, has the finite\ncontrollability property. In order to do that, we develop a technique, which we\nbelieve can have further applications, of approximating Chase(D, T), for a\ndatabase instance D and some sets of tuple generating dependencies T, by an\ninfinite sequence of finite structures, all of them being models of T.\n"}}], "languages": [null], "subjects": ["68p15", "computer science - databases"], "providerUpdatedDateTime": "2014-11-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1204.3432"}}, {"publisher": {"name": ""}, "description": "  With the advent of digital images the problem of keeping picture\nvisualization uniformity arises because each printing or scanning device has\nits own color chart. So, universal color profiles are made by ICC to bring\nuniformity in various types of devices. Keeping that color profile in mind\nvarious new color charts are created and calibrated with the help of standard\nIT8 test charts available in the market. The main objective to color\nreproduction is to produce the identical picture at device output. For that\nprinciples for gamut mapping has been designed\n", "contributors": [{"name": "Dilawari, Jaswinder Singh", "sameAs": [], "familyName": "Dilawari", "additionalName": "Singh", "givenName": "Jaswinder", "email": ""}, {"name": "Khanna, Ravinder", "sameAs": [], "familyName": "Khanna", "additionalName": "", "givenName": "Ravinder", "email": ""}], "title": "Reproduction of Images by Gamut Mapping and Creation of New Test Charts\n  in Prepress Process", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-09-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1209.6037", "oai:arXiv.org:1209.6037"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  With the advent of digital images the problem of keeping picture\nvisualization uniformity arises because each printing or scanning device has\nits own color chart. So, universal color profiles are made by ICC to bring\nuniformity in various types of devices. Keeping that color profile in mind\nvarious new color charts are created and calibrated with the help of standard\nIT8 test charts available in the market. The main objective to color\nreproduction is to produce the identical picture at device output. For that\nprinciples for gamut mapping has been designed\n", "Comment: 5 Pages,10 Figures; International Journal of Scientific and\n  Engineering Research,Volume 3, Issue 10, October 2012 Edition"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1209.6037"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose a new max-margin based discriminative feature\nlearning method. Specifically, we aim at learning a low-dimensional feature\nrepresentation, so as to maximize the global margin of the data and make the\nsamples from the same class as close as possible. In order to enhance the\nrobustness to noise, a $l_{2,1}$ norm constraint is introduced to make the\ntransformation matrix in group sparsity. In addition, for multi-class\nclassification tasks, we further intend to learn and leverage the correlation\nrelationships among multiple class tasks for assisting in learning\ndiscriminative features. The experimental results demonstrate the power of the\nproposed method against the related state-of-the-art methods.\n", "contributors": [{"name": "Li, Changsheng", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Changsheng", "email": ""}, {"name": "Liu, Qingshan", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Qingshan", "email": ""}, {"name": "Dong, Weishan", "sameAs": [], "familyName": "Dong", "additionalName": "", "givenName": "Weishan", "email": ""}, {"name": "Zhang, Xin", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Xin", "email": ""}, {"name": "Yang, Lin", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Lin", "email": ""}], "title": "Max-Margin based Discriminative Feature Learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4863", "oai:arXiv.org:1412.4863"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we propose a new max-margin based discriminative feature\nlearning method. Specifically, we aim at learning a low-dimensional feature\nrepresentation, so as to maximize the global margin of the data and make the\nsamples from the same class as close as possible. In order to enhance the\nrobustness to noise, a $l_{2,1}$ norm constraint is introduced to make the\ntransformation matrix in group sparsity. In addition, for multi-class\nclassification tasks, we further intend to learn and leverage the correlation\nrelationships among multiple class tasks for assisting in learning\ndiscriminative features. The experimental results demonstrate the power of the\nproposed method against the related state-of-the-art methods.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2014-12-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4863"}}, {"publisher": {"name": ""}, "description": "  We present new constructions of codes for asymmetric channels for both binary\nand nonbinary alphabets, based on methods of generalized code concatenation.\nFor the binary asymmetric channel, our methods construct nonlinear\nsingle-error-correcting codes from ternary outer codes. We show that some of\nthe Varshamov-Tenengol'ts-Constantin-Rao codes, a class of binary nonlinear\ncodes for this channel, have a nice structure when viewed as ternary codes. In\nmany cases, our ternary construction yields even better codes. For the\nnonbinary asymmetric channel, our methods construct linear codes for many\nlengths and distances which are superior to the linear codes of the same length\ncapable of correcting the same number of symmetric errors.\n  In the binary case, Varshamov has shown that almost all good linear codes for\nthe asymmetric channel are also good for the symmetric channel. Our results\nindicate that Varshamov's argument does not extend to the nonbinary case, i.e.,\none can find better linear codes for asymmetric channels than for symmetric\nones.\n", "contributors": [{"name": "Grassl, Markus", "sameAs": [], "familyName": "Grassl", "additionalName": "", "givenName": "Markus", "email": ""}, {"name": "Shor, Peter", "sameAs": [], "familyName": "Shor", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Smith, Graeme", "sameAs": [], "familyName": "Smith", "additionalName": "", "givenName": "Graeme", "email": ""}, {"name": "Smolin, John", "sameAs": [], "familyName": "Smolin", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Zeng, Bei", "sameAs": [], "familyName": "Zeng", "additionalName": "", "givenName": "Bei", "email": ""}], "title": "New Constructions of Codes for Asymmetric Channels via Concatenation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-10-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.7536", "IEEE Transactions on Information Theory, vol. 61, no. 4, pp.\n  1879-1886, 2015", "doi:10.1109/TIT.2015.2401567", "oai:arXiv.org:1310.7536"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We present new constructions of codes for asymmetric channels for both binary\nand nonbinary alphabets, based on methods of generalized code concatenation.\nFor the binary asymmetric channel, our methods construct nonlinear\nsingle-error-correcting codes from ternary outer codes. We show that some of\nthe Varshamov-Tenengol'ts-Constantin-Rao codes, a class of binary nonlinear\ncodes for this channel, have a nice structure when viewed as ternary codes. In\nmany cases, our ternary construction yields even better codes. For the\nnonbinary asymmetric channel, our methods construct linear codes for many\nlengths and distances which are superior to the linear codes of the same length\ncapable of correcting the same number of symmetric errors.\n  In the binary case, Varshamov has shown that almost all good linear codes for\nthe asymmetric channel are also good for the symmetric channel. Our results\nindicate that Varshamov's argument does not extend to the nonbinary case, i.e.,\none can find better linear codes for asymmetric channels than for symmetric\nones.\n", "Comment: 9 pages, 3 figures, 4 tables"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.7536"}}, {"publisher": {"name": ""}, "description": "  Feature selection with specific multivariate performance measures is the key\nto the success of many applications, such as image retrieval and text\nclassification. The existing feature selection methods are usually designed for\nclassification error. In this paper, we propose a generalized sparse\nregularizer. Based on the proposed regularizer, we present a unified feature\nselection framework for general loss functions. In particular, we study the\nnovel feature selection paradigm by optimizing multivariate performance\nmeasures. The resultant formulation is a challenging problem for\nhigh-dimensional data. Hence, a two-layer cutting plane algorithm is proposed\nto solve this problem, and the convergence is presented. In addition, we adapt\nthe proposed method to optimize multivariate measures for multiple instance\nlearning problems. The analyses by comparing with the state-of-the-art feature\nselection methods show that the proposed method is superior to others.\nExtensive experiments on large-scale and high-dimensional real world datasets\nshow that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a\nsmall subset of features, and achieves significantly improved performances over\nSVM$^{perf}$ in terms of $F_1$-score.\n", "contributors": [{"name": "Mao, Qi", "sameAs": [], "familyName": "Mao", "additionalName": "", "givenName": "Qi", "email": ""}, {"name": "Tsang, Ivor W.", "sameAs": [], "familyName": "Tsang", "additionalName": "W.", "givenName": "Ivor", "email": ""}], "title": "A Feature Selection Method for Multivariate Performance Measures", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-03-05", "2013-05-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1103.1013", "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2012", "doi:10.1109/TPAMI.2012.266", "oai:arXiv.org:1103.1013"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Feature selection with specific multivariate performance measures is the key\nto the success of many applications, such as image retrieval and text\nclassification. The existing feature selection methods are usually designed for\nclassification error. In this paper, we propose a generalized sparse\nregularizer. Based on the proposed regularizer, we present a unified feature\nselection framework for general loss functions. In particular, we study the\nnovel feature selection paradigm by optimizing multivariate performance\nmeasures. The resultant formulation is a challenging problem for\nhigh-dimensional data. Hence, a two-layer cutting plane algorithm is proposed\nto solve this problem, and the convergence is presented. In addition, we adapt\nthe proposed method to optimize multivariate measures for multiple instance\nlearning problems. The analyses by comparing with the state-of-the-art feature\nselection methods show that the proposed method is superior to others.\nExtensive experiments on large-scale and high-dimensional real world datasets\nshow that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a\nsmall subset of features, and achieves significantly improved performances over\nSVM$^{perf}$ in terms of $F_1$-score.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1103.1013"}}, {"publisher": {"name": ""}, "description": "  Feature selection is an essential problem in computer vision, important for\ncategory learning and recognition. Along with the rapid development of a wide\nvariety of visual features and classifiers, there is a growing need for\nefficient feature selection and combination methods, to construct powerful\nclassifiers for more complex and higher-level recognition tasks. We propose an\nalgorithm that efficiently discovers sparse, compact representations of input\nfeatures or classifiers, from a vast sea of candidates, with important\noptimality properties, low computational cost and excellent accuracy in\npractice. Different from boosting, we start with a discriminant linear\nclassification formulation that encourages sparse solutions. Then we obtain an\nequivalent unsupervised clustering problem that jointly discovers ensembles of\ndiverse features. They are independently valuable but even more powerful when\nunited in a cluster of classifiers. We evaluate our method on the task of\nlarge-scale recognition in video and show that it significantly outperforms\nclassical selection approaches, such as AdaBoost and greedy forward-backward\nselection, and powerful classifiers such as SVMs, in speed of training and\nperformance, especially in the case of limited training data.\n", "contributors": [{"name": "Leordeanu, Marius", "sameAs": [], "familyName": "Leordeanu", "additionalName": "", "givenName": "Marius", "email": ""}, {"name": "Radu, Alexandra", "sameAs": [], "familyName": "Radu", "additionalName": "", "givenName": "Alexandra", "email": ""}, {"name": "Sukthankar, Rahul", "sameAs": [], "familyName": "Sukthankar", "additionalName": "", "givenName": "Rahul", "email": ""}], "title": "Features in Concert: Discriminative Feature Selection meets Unsupervised\n  Clustering", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7714", "oai:arXiv.org:1411.7714"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Feature selection is an essential problem in computer vision, important for\ncategory learning and recognition. Along with the rapid development of a wide\nvariety of visual features and classifiers, there is a growing need for\nefficient feature selection and combination methods, to construct powerful\nclassifiers for more complex and higher-level recognition tasks. We propose an\nalgorithm that efficiently discovers sparse, compact representations of input\nfeatures or classifiers, from a vast sea of candidates, with important\noptimality properties, low computational cost and excellent accuracy in\npractice. Different from boosting, we start with a discriminant linear\nclassification formulation that encourages sparse solutions. Then we obtain an\nequivalent unsupervised clustering problem that jointly discovers ensembles of\ndiverse features. They are independently valuable but even more powerful when\nunited in a cluster of classifiers. We evaluate our method on the task of\nlarge-scale recognition in video and show that it significantly outperforms\nclassical selection approaches, such as AdaBoost and greedy forward-backward\nselection, and powerful classifiers such as SVMs, in speed of training and\nperformance, especially in the case of limited training data.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7714"}}, {"publisher": {"name": ""}, "description": "  Random Indexing is a simple implementation of Random Projections with a wide\nrange of applications. It can solve a variety of problems with good accuracy\nwithout introducing much complexity. Here we use it for identifying the\nlanguage of text samples. We present a novel method of generating language\nrepresentation vectors using letter blocks. Further, we show that the method is\neasily implemented and requires little computational power and space.\nExperiments on a number of model parameters illustrate certain properties about\nhigh dimensional sparse vector representations of data. Proof of statistically\nrelevant language vectors are shown through the extremely high success of\nvarious language recognition tasks. On a difficult data set of 21,000 short\nsentences from 21 different languages, our model performs a language\nrecognition task and achieves 97.8% accuracy, comparable to state-of-the-art\nmethods.\n", "contributors": [{"name": "Joshi, Aditya", "sameAs": [], "familyName": "Joshi", "additionalName": "", "givenName": "Aditya", "email": ""}, {"name": "Halseth, Johan", "sameAs": [], "familyName": "Halseth", "additionalName": "", "givenName": "Johan", "email": ""}, {"name": "Kanerva, Pentti", "sameAs": [], "familyName": "Kanerva", "additionalName": "", "givenName": "Pentti", "email": ""}], "title": "Language Recognition using Random Indexing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-22", "2015-02-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7026", "oai:arXiv.org:1412.7026"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Random Indexing is a simple implementation of Random Projections with a wide\nrange of applications. It can solve a variety of problems with good accuracy\nwithout introducing much complexity. Here we use it for identifying the\nlanguage of text samples. We present a novel method of generating language\nrepresentation vectors using letter blocks. Further, we show that the method is\neasily implemented and requires little computational power and space.\nExperiments on a number of model parameters illustrate certain properties about\nhigh dimensional sparse vector representations of data. Proof of statistically\nrelevant language vectors are shown through the extremely high success of\nvarious language recognition tasks. On a difficult data set of 21,000 short\nsentences from 21 different languages, our model performs a language\nrecognition task and achieves 97.8% accuracy, comparable to state-of-the-art\nmethods.\n", "Comment: 7 pages, 1 figures, 2 tables, ICLR 2015"]}}], "languages": [null], "subjects": ["computer science - computation and language", "computer science - learning"], "providerUpdatedDateTime": "2015-03-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7026"}}, {"publisher": {"name": ""}, "description": "  In Multi-Channel Multi-Radio Wireless Mesh Networks (MCMR-WMN), finding the\noptimal routing by satisfying the Quality of Service (QoS) constraints is an\nambitious task. Multiple paths are available from the source node to the\ngateway for reliability, and sometimes it is necessary to deal with failures of\nthe link in WMN. A major challenge in a MCMR-WMN is finding the routing with\nQoS satisfied and an interference free path from the redundant paths, in order\nto transmit the packets through this path. The Particle Swarm Optimization\n(PSO) is an optimization technique to find the candidate solution in the search\nspace optimally, and it applies artificial intelligence to solve the routing\nproblem. On the other hand, the Genetic Algorithm (GA) is a population based\nmeta-heuristic optimization algorithm inspired by the natural evolution, such\nas selection,mutation and crossover. PSO can easily fall into a local optimal\nsolution, at the same time GA is not suitable for dynamic data due to the\nunderlying dynamic network. In this paper we propose an optimal intelligent\nrouting, using a Hybrid PSO-GA, which also meets the QoS constraints. Moreover,\nit integrates the strength of PSO and GA. The QoS constraints, such as\nbandwidth, delay, jitter and interference are transformed into penalty\nfunctions. The simulation results show that the hybrid approach outperforms PSO\nand GA individually, and it takes less convergence time comparatively, keeping\naway from converging prematurely.\n  Keywords: Wireless mesh networks, Multi-radio, Multi-channel, Particle swarm\noptimization, Genetic algorithm, Quality of service.\n", "contributors": [{"name": "Sarasvathi, V.", "sameAs": [], "familyName": "Sarasvathi", "additionalName": "", "givenName": "V.", "email": ""}, {"name": "Iyengar, N. Ch. S. N.", "sameAs": [], "familyName": "Iyengar", "additionalName": "Ch. S. N.", "givenName": "N.", "email": ""}, {"name": "Saha, Snehanshu", "sameAs": [], "familyName": "Saha", "additionalName": "", "givenName": "Snehanshu", "email": ""}], "title": "QoS Guaranteed Intelligent Routing Using Hybrid PSO-GA in Wireless Mesh\n  Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03639", "doi:10.1515/cait-2015-0007", "oai:arXiv.org:1503.03639"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In Multi-Channel Multi-Radio Wireless Mesh Networks (MCMR-WMN), finding the\noptimal routing by satisfying the Quality of Service (QoS) constraints is an\nambitious task. Multiple paths are available from the source node to the\ngateway for reliability, and sometimes it is necessary to deal with failures of\nthe link in WMN. A major challenge in a MCMR-WMN is finding the routing with\nQoS satisfied and an interference free path from the redundant paths, in order\nto transmit the packets through this path. The Particle Swarm Optimization\n(PSO) is an optimization technique to find the candidate solution in the search\nspace optimally, and it applies artificial intelligence to solve the routing\nproblem. On the other hand, the Genetic Algorithm (GA) is a population based\nmeta-heuristic optimization algorithm inspired by the natural evolution, such\nas selection,mutation and crossover. PSO can easily fall into a local optimal\nsolution, at the same time GA is not suitable for dynamic data due to the\nunderlying dynamic network. In this paper we propose an optimal intelligent\nrouting, using a Hybrid PSO-GA, which also meets the QoS constraints. Moreover,\nit integrates the strength of PSO and GA. The QoS constraints, such as\nbandwidth, delay, jitter and interference are transformed into penalty\nfunctions. The simulation results show that the hybrid approach outperforms PSO\nand GA individually, and it takes less convergence time comparatively, keeping\naway from converging prematurely.\n  Keywords: Wireless mesh networks, Multi-radio, Multi-channel, Particle swarm\noptimization, Genetic algorithm, Quality of service.\n", "Comment: 15 pages in Cybernetics and Information Technologies,Volume 15, No 1,\n  2015"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03639"}}, {"publisher": {"name": ""}, "description": "  We discuss some results around the following question: Let $f$ be a\nnonconstant complex entire function and $a$, $b$ two distinct complex numbers.\nIf $f$ and its derivative $f'$ share their simple $a$-points and also share the\nvalue $b$, does this imply $f\\equiv f'$?\n", "contributors": [{"name": "Schweizer, Andreas", "sameAs": [], "familyName": "Schweizer", "additionalName": "", "givenName": "Andreas", "email": ""}], "title": "Entire functions sharing simple $a$-points with their first derivative\n  II", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2719", "oai:arXiv.org:1411.2719"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We discuss some results around the following question: Let $f$ be a\nnonconstant complex entire function and $a$, $b$ two distinct complex numbers.\nIf $f$ and its derivative $f'$ share their simple $a$-points and also share the\nvalue $b$, does this imply $f\\equiv f'$?\n", "Comment: 11 pages; comments welcome"]}}], "languages": [null], "subjects": ["secondary 30d45", "primary 30d35", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2719"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "This experience report builds on an earlier study in which we interviewed eight project teams that were using iterative incremental lifecycles. In the study, we captured the practices the teams felt contributed to rapid delivery. We identified a mix of Agile and architecture practices that teams apply to rapidly field software and minimize disruption and delay. In this paper, we elaborate one practice from the study, prototyping with quality attribute focus. We compared two experiences in prototyping focused on quality attribute considerations applied on Scrum projects. We observe through interviews that feature development and prototyping practice spans multiple levels: feature development/sprint, release planning, and portfolio planning. We also observe other factors including rapid trade-off analysis, flexible architecture, and adoption of a set of enabling prototyping guidelines. The analysis of the observations sheds light on several aspects of the practice that enable the team to respond quickly and efficiently when prototype feedback suggests architectural change.", "contributors": [{"name": "Bellomo, Stephany", "sameAs": [], "familyName": "Bellomo", "additionalName": "", "givenName": "Stephany", "email": ""}, {"name": "Nord, Robert", "sameAs": [], "familyName": "Nord", "additionalName": "", "givenName": "Robert", "email": ""}, {"name": "Ozkaya, Ipek", "sameAs": [], "familyName": "Ozkaya", "additionalName": "", "givenName": "Ipek", "email": ""}], "title": "Elaboration on an Integrated Architecture and Requirement Practice: Prototyping with Quality Attribute Focus", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2015-01-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/sei/824", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1821&amp;context=sei", "oai:repository.cmu.edu:sei-1821"]}}, {"name": "setSpec", "properties": {"setSpec": "publication:sei"}}, {"name": "description", "properties": {"description": "This experience report builds on an earlier study in which we interviewed eight project teams that were using iterative incremental lifecycles. In the study, we captured the practices the teams felt contributed to rapid delivery. We identified a mix of Agile and architecture practices that teams apply to rapidly field software and minimize disruption and delay. In this paper, we elaborate one practice from the study, prototyping with quality attribute focus. We compared two experiences in prototyping focused on quality attribute considerations applied on Scrum projects. We observe through interviews that feature development and prototyping practice spans multiple levels: feature development/sprint, release planning, and portfolio planning. We also observe other factors including rapid trade-off analysis, flexible architecture, and adoption of a set of enabling prototyping guidelines. The analysis of the observations sheds light on several aspects of the practice that enable the team to respond quickly and efficiently when prototype feedback suggests architectural change."}}], "languages": [null], "subjects": ["software development practices", "requirements", "software engineering", "architecture trade-off", "quality attribute", "computer sciences", "prototyping", "release planning", "architecture", "agile software development"], "providerUpdatedDateTime": "2015-03-13T15:31:07", "uris": {"canonicalUri": "http://repository.cmu.edu/sei/824"}}, {"publisher": {"name": ""}, "description": "  A new approach is proposed, namely CSSF MIMO radar, which applies the\ntechnique of step frequency (SF) to compressive sensing (CS) based multi-input\nmulti-output (MIMO) radar. The proposed approach enables high resolution range,\nangle and Doppler estimation, while transmitting narrowband pulses. The problem\nof joint angle-Doppler-range estimation is first formulated to fit the CS\nframework, i.e., as an L1 optimization problem. Direct solution of this problem\nentails high complexity as it employs a basis matrix whose construction\nrequires discretization of the angle-Doppler-range space. Since high resolution\nrequires fine space discretization, the complexity of joint range, angle and\nDoppler estimation can be prohibitively high. For the case of slowly moving\ntargets, a technique is proposed that achieves significant complexity reduction\nby successively estimating angle-range and Doppler in a decoupled fashion and\nby employing initial estimates obtained via matched filtering to further reduce\nthe space that needs to be digitized. Numerical results show that the\ncombination of CS and SF results in a MIMO radar system that has superior\nresolution and requires far less data as compared to a system that uses a\nmatched filter with SF.\n", "contributors": [{"name": "Yu, Yao", "sameAs": [], "familyName": "Yu", "additionalName": "", "givenName": "Yao", "email": ""}, {"name": "Petropulu, Athina P.", "sameAs": [], "familyName": "Petropulu", "additionalName": "P.", "givenName": "Athina", "email": ""}, {"name": "Poor, H. Vincent", "sameAs": [], "familyName": "Poor", "additionalName": "Vincent", "givenName": "H.", "email": ""}], "title": "CSSF MIMO RADAR: Low-Complexity Compressive Sensing Based MIMO Radar\n  That Uses Step Frequency", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-01-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.2719", "oai:arXiv.org:1101.2719"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  A new approach is proposed, namely CSSF MIMO radar, which applies the\ntechnique of step frequency (SF) to compressive sensing (CS) based multi-input\nmulti-output (MIMO) radar. The proposed approach enables high resolution range,\nangle and Doppler estimation, while transmitting narrowband pulses. The problem\nof joint angle-Doppler-range estimation is first formulated to fit the CS\nframework, i.e., as an L1 optimization problem. Direct solution of this problem\nentails high complexity as it employs a basis matrix whose construction\nrequires discretization of the angle-Doppler-range space. Since high resolution\nrequires fine space discretization, the complexity of joint range, angle and\nDoppler estimation can be prohibitively high. For the case of slowly moving\ntargets, a technique is proposed that achieves significant complexity reduction\nby successively estimating angle-range and Doppler in a decoupled fashion and\nby employing initial estimates obtained via matched filtering to further reduce\nthe space that needs to be digitized. Numerical results show that the\ncombination of CS and SF results in a MIMO radar system that has superior\nresolution and requires far less data as compared to a system that uses a\nmatched filter with SF.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.2719"}}, {"publisher": {"name": ""}, "description": "  In this essay the stance on robots is discussed. The attitude against robots\nin history, starting in Ancient Greek culture until the industrial revolution\nis described. The uncanny valley and some possible explanations are given. Some\ndifferences in Western and Asian understanding of robots are listed and finally\nwe answer the question raised with the title.\n", "contributors": [{"name": "Barthelmess, Ulrike", "sameAs": [], "familyName": "Barthelmess", "additionalName": "", "givenName": "Ulrike", "email": ""}, {"name": "Furbach, Ulrich", "sameAs": [], "familyName": "Furbach", "additionalName": "", "givenName": "Ulrich", "email": ""}], "title": "Do we need Asimov's Laws?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-04-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.0961", "oai:arXiv.org:1405.0961"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this essay the stance on robots is discussed. The attitude against robots\nin history, starting in Ancient Greek culture until the industrial revolution\nis described. The uncanny valley and some possible explanations are given. Some\ndifferences in Western and Asian understanding of robots are listed and finally\nwe answer the question raised with the title.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2014-11-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.0961"}}, {"publisher": {"name": ""}, "description": "  Two procedures to compute the output distribution phi_S of certain stack\nfilters S (so called erosion-dilation cascades) are given. One rests on the\ndisjunctive normal form of S and also yields the rank selection probabilities.\nThe other is based on inclusion-exclusion and e.g. yields phi_S for some\nimportant LULU-operators S. Properties of phi_S can be used to characterize\nsmoothing properties of S. One of the methods discussed also allows for the\ncalculation of the reliability polynomial of any positive Boolean function\n(e.g. one derived from a connected graph).\n", "contributors": [{"name": "Anguelov, R.", "sameAs": [], "familyName": "Anguelov", "additionalName": "", "givenName": "R.", "email": ""}, {"name": "Butler, P. W.", "sameAs": [], "familyName": "Butler", "additionalName": "W.", "givenName": "P.", "email": ""}, {"name": "Rohwer, C. H.", "sameAs": [], "familyName": "Rohwer", "additionalName": "H.", "givenName": "C.", "email": ""}, {"name": "Wild, M.", "sameAs": [], "familyName": "Wild", "additionalName": "", "givenName": "M.", "email": ""}], "title": "The output distribution of important LULU-operators", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-03-23", "2014-10-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1003.4406", "doi:10.2989/16073606.2014.981684", "oai:arXiv.org:1003.4406"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Two procedures to compute the output distribution phi_S of certain stack\nfilters S (so called erosion-dilation cascades) are given. One rests on the\ndisjunctive normal form of S and also yields the rank selection probabilities.\nThe other is based on inclusion-exclusion and e.g. yields phi_S for some\nimportant LULU-operators S. Properties of phi_S can be used to characterize\nsmoothing properties of S. One of the methods discussed also allows for the\ncalculation of the reliability polynomial of any positive Boolean function\n(e.g. one derived from a connected graph).\n", "Comment: 20 pages, up to trivial differences this is the final version to be\n  published in Quaestiones Mathematicae 2015"]}}], "languages": [null], "subjects": ["computer science - other computer science", "62e15", "mathematics - probability"], "providerUpdatedDateTime": "2014-10-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1003.4406"}}, {"publisher": {"name": ""}, "description": "  This paper has been withdrawn due to an incorrect proof.\n", "contributors": [{"name": "Jose, Jubin", "sameAs": [], "familyName": "Jose", "additionalName": "", "givenName": "Jubin", "email": ""}, {"name": "Mitliagkas, Ioannis", "sameAs": [], "familyName": "Mitliagkas", "additionalName": "", "givenName": "Ioannis", "email": ""}, {"name": "Vishwanath, Sriram", "sameAs": [], "familyName": "Vishwanath", "additionalName": "", "givenName": "Sriram", "email": ""}], "title": "Sum Capacity of Gaussian Interfering Multiple Access Channels in the Low\n  Interference Regime", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-05-10", "2011-05-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.2096", "oai:arXiv.org:1105.2096"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper has been withdrawn due to an incorrect proof.\n", "Comment: This paper has been withdrawn due to an incorrect proof"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.2096"}}, {"publisher": {"name": ""}, "description": "  We describe algorithm MINRES-QLP and its FORTRAN 90 implementation for\nsolving symmetric or Hermitian linear systems or least-squares problems. If the\nsystem is singular, MINRES-QLP computes the unique minimum-length solution\n(also known as the pseudoinverse solution), which generally eludes MINRES. In\nall cases, it overcomes a potential instability in the original MINRES\nalgorithm. A positive-definite preconditioner may be supplied. Our FORTRAN 90\nimplementation illustrates a design pattern that allows users to make problem\ndata known to the solver but hidden and secure from other program units. In\nparticular, we circumvent the need for reverse communication. While we focus\nhere on a FORTRAN 90 implementation, we also provide and maintain MATLAB\nversions of MINRES and MINRES-QLP.\n", "contributors": [{"name": "Choi, Sou-Cheng T.", "sameAs": [], "familyName": "Choi", "additionalName": "T.", "givenName": "Sou-Cheng", "email": ""}, {"name": "Saunders, Michael A.", "sameAs": [], "familyName": "Saunders", "additionalName": "A.", "givenName": "Michael", "email": ""}], "title": "ALGORITHM 937: MINRES-QLP for Singular Symmetric and Hermitian Linear\n  Equations and Least-Squares Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-01-12", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1301.2707", "doi:10.1145/2527267", "oai:arXiv.org:1301.2707"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We describe algorithm MINRES-QLP and its FORTRAN 90 implementation for\nsolving symmetric or Hermitian linear systems or least-squares problems. If the\nsystem is singular, MINRES-QLP computes the unique minimum-length solution\n(also known as the pseudoinverse solution), which generally eludes MINRES. In\nall cases, it overcomes a potential instability in the original MINRES\nalgorithm. A positive-definite preconditioner may be supplied. Our FORTRAN 90\nimplementation illustrates a design pattern that allows users to make problem\ndata known to the solver but hidden and secure from other program units. In\nparticular, we circumvent the need for reverse communication. While we focus\nhere on a FORTRAN 90 implementation, we also provide and maintain MATLAB\nversions of MINRES and MINRES-QLP.\n", "Comment: 14 pages and 1 figure"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - mathematical software", "computer science - numerical analysis"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1301.2707"}}, {"publisher": {"name": ""}, "description": "  Given a mixed Hodge module and a meromorphic function f on a complex\nmanifold, we associate to these data a filtration (the irregular Hodge\nfiltration) on the exponentially twisted holonomic module, which extends the\nconstruction of http://arxiv.org/abs/1302.4537. We show the strictness of the\npush-forward filtered D-module through any projective morphism, by using the\ntheory of mixed twistor D-modules of T. Mochizuki. We consider the example of\nthe rescaling of a regular function f, which leads to an expression of the\nirregular Hodge filtration of the Laplace transform of the Gauss-Manin systems\nof f in terms of the Harder-Narasimhan filtration of the Kontsevich bundles\nassociated with f.\n", "contributors": [{"name": "Sabbah, Claude", "sameAs": [], "familyName": "Sabbah", "additionalName": "", "givenName": "Claude", "email": ""}, {"name": "Yu, Jeng-Daw", "sameAs": [], "familyName": "Yu", "additionalName": "", "givenName": "Jeng-Daw", "email": ""}], "title": "On the irregular Hodge filtration of exponentially twisted mixed Hodge\n  modules", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-05", "2015-04-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.1339", "oai:arXiv.org:1406.1339"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Given a mixed Hodge module and a meromorphic function f on a complex\nmanifold, we associate to these data a filtration (the irregular Hodge\nfiltration) on the exponentially twisted holonomic module, which extends the\nconstruction of http://arxiv.org/abs/1302.4537. We show the strictness of the\npush-forward filtered D-module through any projective morphism, by using the\ntheory of mixed twistor D-modules of T. Mochizuki. We consider the example of\nthe rescaling of a regular function f, which leads to an expression of the\nirregular Hodge filtration of the Laplace transform of the Gauss-Manin systems\nof f in terms of the Harder-Narasimhan filtration of the Kontsevich bundles\nassociated with f.\n", "Comment: 53 pages. V2: 56 pages, Introduction partly rewritten. Final revised\n  version to appear in Forum of Mathematics Sigma"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "14f40", "32s35", "32s40", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-04-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.1339"}}, {"publisher": {"name": ""}, "description": "  Let $S(\\phi)= \\{z:\\;|\\arg(z)|\\geq \\phi\\}$ be a sector on the complex plane\n$\\CC$. If $\\phi\\geq \\pi/2$, then $S(\\phi)$ is a convex set and, according to\nthe Gauss-Lucas theorem, if a polynomial $p(z)$ has all its zeros on $S(\\phi)$,\nthen the same is true for the zeros of all its derivatives. In this paper is\nproved that if the polynomial $p(z)$ is with real and non negative\ncoefficients, then the same is true also for $\\phi < \\pi/2$, when the sector is\nnot a convex set on the complex plane.\n", "contributors": [{"name": "Sendov, Bl.", "sameAs": [], "familyName": "Sendov", "additionalName": "", "givenName": "Bl.", "email": ""}], "title": "Analogue of Gauss-Lucas theorem for non convex set on the complex plane", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-26", "2015-01-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.6425", "oai:arXiv.org:1402.6425"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  Let $S(\\phi)= \\{z:\\;|\\arg(z)|\\geq \\phi\\}$ be a sector on the complex plane\n$\\CC$. If $\\phi\\geq \\pi/2$, then $S(\\phi)$ is a convex set and, according to\nthe Gauss-Lucas theorem, if a polynomial $p(z)$ has all its zeros on $S(\\phi)$,\nthen the same is true for the zeros of all its derivatives. In this paper is\nproved that if the polynomial $p(z)$ is with real and non negative\ncoefficients, then the same is true also for $\\phi < \\pi/2$, when the sector is\nnot a convex set on the complex plane.\n"}}], "languages": [null], "subjects": ["30c15", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.6425"}}, {"publisher": {"name": ""}, "description": "  In this paper, we design a Collaborative-Hierarchical Sparse and Low-Rank\n(C-HiSLR) model that is natural for recognizing human emotion in visual data.\nPrevious attempts require explicit expression components, which are often\nunavailable and difficult to recover. Instead, our model exploits the lowrank\nproperty over expressive facial frames and rescue inexact sparse\nrepresentations by incorporating group sparsity. For the CK+ dataset, C-HiSLR\non raw expressive faces performs as competitive as the Sparse Representation\nbased Classification (SRC) applied on manually prepared emotions. C-HiSLR\nperforms even better than SRC in terms of true positive rate.\n", "contributors": [{"name": "Xiang, Xiang", "sameAs": [], "familyName": "Xiang", "additionalName": "", "givenName": "Xiang", "email": ""}, {"name": "Dao, Minh", "sameAs": [], "familyName": "Dao", "additionalName": "", "givenName": "Minh", "email": ""}, {"name": "Hager, Gregory D.", "sameAs": [], "familyName": "Hager", "additionalName": "D.", "givenName": "Gregory", "email": ""}, {"name": "Tran, Trac D.", "sameAs": [], "familyName": "Tran", "additionalName": "D.", "givenName": "Trac", "email": ""}], "title": "Hierarchical Sparse and Collaborative Low-Rank Representation for\n  Emotion Recognition", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-06", "2015-04-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1606", "oai:arXiv.org:1410.1606"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we design a Collaborative-Hierarchical Sparse and Low-Rank\n(C-HiSLR) model that is natural for recognizing human emotion in visual data.\nPrevious attempts require explicit expression components, which are often\nunavailable and difficult to recover. Instead, our model exploits the lowrank\nproperty over expressive facial frames and rescue inexact sparse\nrepresentations by incorporating group sparsity. For the CK+ dataset, C-HiSLR\non raw expressive faces performs as competitive as the Sparse Representation\nbased Classification (SRC) applied on manually prepared emotions. C-HiSLR\nperforms even better than SRC in terms of true positive rate.\n", "Comment: 5 pages, 5 figures; accepted to IEEE ICASSP 2015; programs available\n  at https://github.com/eglxiang/icassp15_emotion/"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1606"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "The Pitman-Yor process provides an elegant way to cluster data that exhibit power law behavior, where the number of clusters is unknown or unbounded. Unfortunately, inference in PitmanYor process-based models is typically slow and does not scale well with dataset size. In this paper we present new auxiliary-variable representations for the Pitman-Yor process and a special case of the hierarchical Pitman-Yor process that allows us to develop parallel inference algorithms that distribute inference both on the data space and the model space. We show that our method scales well with increasing data while avoiding any degradation in estimate quality", "contributors": [{"name": "Dubey, Avinava", "sameAs": [], "familyName": "Dubey", "additionalName": "", "givenName": "Avinava", "email": ""}, {"name": "Williamson, Sinead", "sameAs": [], "familyName": "Williamson", "additionalName": "", "givenName": "Sinead", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "Parallel Markov Chain Monte Carlo for Pitman-Yor Mixture Models", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-07-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/142", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1146&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1146"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "The Pitman-Yor process provides an elegant way to cluster data that exhibit power law behavior, where the number of clusters is unknown or unbounded. Unfortunately, inference in PitmanYor process-based models is typically slow and does not scale well with dataset size. In this paper we present new auxiliary-variable representations for the Pitman-Yor process and a special case of the hierarchical Pitman-Yor process that allows us to develop parallel inference algorithms that distribute inference both on the data space and the model space. We show that our method scales well with increasing data while avoiding any degradation in estimate quality"}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-30T21:01:46", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/142"}}, {"publisher": {"name": ""}, "description": "  This paper studies the problem of detecting the presence of a small dense\ncommunity planted in a large Erd\\H{o}s-R\\'enyi random graph $\\mathcal{G}(N,q)$,\nwhere the edge probability within the community exceeds $q$ by a constant\nfactor. Assuming the hardness of the planted clique detection problem, we show\nthat the computational complexity of detecting the community exhibits the\nfollowing phase transition phenomenon: As the graph size $N$ grows and the\ngraph becomes sparser according to $q=N^{-\\alpha}$, there exists a critical\nvalue of $\\alpha = \\frac{2}{3}$, below which there exists a computationally\nintensive procedure that can detect far smaller communities than any\ncomputationally efficient procedure, and above which a linear-time procedure is\nstatistically optimal. The results also lead to the average-case hardness\nresults for recovering the dense community and approximating the densest\n$K$-subgraph.\n", "contributors": [{"name": "Hajek, Bruce", "sameAs": [], "familyName": "Hajek", "additionalName": "", "givenName": "Bruce", "email": ""}, {"name": "Wu, Yihong", "sameAs": [], "familyName": "Wu", "additionalName": "", "givenName": "Yihong", "email": ""}, {"name": "Xu, Jiaming", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Jiaming", "email": ""}], "title": "Computational Lower Bounds for Community Detection on Random Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-25", "2015-03-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.6625", "oai:arXiv.org:1406.6625"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  This paper studies the problem of detecting the presence of a small dense\ncommunity planted in a large Erd\\H{o}s-R\\'enyi random graph $\\mathcal{G}(N,q)$,\nwhere the edge probability within the community exceeds $q$ by a constant\nfactor. Assuming the hardness of the planted clique detection problem, we show\nthat the computational complexity of detecting the community exhibits the\nfollowing phase transition phenomenon: As the graph size $N$ grows and the\ngraph becomes sparser according to $q=N^{-\\alpha}$, there exists a critical\nvalue of $\\alpha = \\frac{2}{3}$, below which there exists a computationally\nintensive procedure that can detect far smaller communities than any\ncomputationally efficient procedure, and above which a linear-time procedure is\nstatistically optimal. The results also lead to the average-case hardness\nresults for recovering the dense community and approximating the densest\n$K$-subgraph.\n", "Comment: 28 pages"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "computer science - computational complexity", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.6625"}}, {"publisher": {"name": ""}, "description": "  The idea to unite smartphones used as personal environmental sensors and\nhealth indicators into a scalable network for data collection and processing by\nthe internet-cloud is proposed. Access to the sensors, which are available in\nevery smartphone, will provide the appropriate software. Such a monitoring at\nthe global level would reveal the impact of the electromagnetic radiation,\nenvironmental pollution and weather factors on human health. Participation of\nstudents in these measurements increases their educational and social\nactivities.\n", "contributors": [{"name": "Shatalov, Vladimir", "sameAs": [], "familyName": "Shatalov", "additionalName": "", "givenName": "Vladimir", "email": ""}, {"name": "Martynyuk, Victor", "sameAs": [], "familyName": "Martynyuk", "additionalName": "", "givenName": "Victor", "email": ""}, {"name": "Saveliev, Maxim", "sameAs": [], "familyName": "Saveliev", "additionalName": "", "givenName": "Maxim", "email": ""}], "title": "Through Global Monitoring to School of the Future: Smartphone as a\n  Laboratory in Pocket of Each Student", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7949", "oai:arXiv.org:1412.7949"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The idea to unite smartphones used as personal environmental sensors and\nhealth indicators into a scalable network for data collection and processing by\nthe internet-cloud is proposed. Access to the sensors, which are available in\nevery smartphone, will provide the appropriate software. Such a monitoring at\nthe global level would reveal the impact of the electromagnetic radiation,\nenvironmental pollution and weather factors on human health. Participation of\nstudents in these measurements increases their educational and social\nactivities.\n", "Comment: Report on the on-line conference \"Cloud Technologies in\n  Education'2014 (December 26, 2014)\"\n  http://tmn.ccjournals.eu/index.php/cte/CTE2014/paper/view/81"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7949"}}, {"publisher": {"name": ""}, "description": "  Random walks are basic diffusion processes on networks and have applications\nin, for example, searching, navigation, ranking, and community detection.\nRecent recognition of the importance of temporal aspects on networks spurred\nstudies of random walks on temporal networks. Here we theoretically study two\ntypes of event-driven random walks on a stochastic temporal network model that\nproduces arbitrary distributions of interevent-times. In the so-called active\nrandom walk, the interevent-time is reinitialized on all links upon each\nmovement of the walker. In the so-called passive random walk, the\ninterevent-time is only reinitialized on the link that has been used last time,\nand it is a type of correlated random walk. We find that the steady state is\nalways the uniform density for the passive random walk. In contrast, for the\nactive random walk, it increases or decreases with the node's degree depending\non the distribution of interevent-times. The mean recurrence time of a node is\ninversely proportional to the degree for both active and passive random walks.\nFurthermore, the mean recurrence time does or does not depend on the\ndistribution of interevent-times for the active and passive random walks,\nrespectively.\n", "contributors": [{"name": "Speidel, Leo", "sameAs": [], "familyName": "Speidel", "additionalName": "", "givenName": "Leo", "email": ""}, {"name": "Lambiotte, Renaud", "sameAs": [], "familyName": "Lambiotte", "additionalName": "", "givenName": "Renaud", "email": ""}, {"name": "Aihara, Kazuyuki", "sameAs": [], "familyName": "Aihara", "additionalName": "", "givenName": "Kazuyuki", "email": ""}, {"name": "Masuda, Naoki", "sameAs": [], "familyName": "Masuda", "additionalName": "", "givenName": "Naoki", "email": ""}], "title": "Steady state and mean recurrence time for random walks on stochastic\n  temporal networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-17", "2015-01-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.4582", "Physical Review E, 91, 012806 (2015)", "doi:10.1103/PhysRevE.91.012806", "oai:arXiv.org:1407.4582"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Random walks are basic diffusion processes on networks and have applications\nin, for example, searching, navigation, ranking, and community detection.\nRecent recognition of the importance of temporal aspects on networks spurred\nstudies of random walks on temporal networks. Here we theoretically study two\ntypes of event-driven random walks on a stochastic temporal network model that\nproduces arbitrary distributions of interevent-times. In the so-called active\nrandom walk, the interevent-time is reinitialized on all links upon each\nmovement of the walker. In the so-called passive random walk, the\ninterevent-time is only reinitialized on the link that has been used last time,\nand it is a type of correlated random walk. We find that the steady state is\nalways the uniform density for the passive random walk. In contrast, for the\nactive random walk, it increases or decreases with the node's degree depending\non the distribution of interevent-times. The mean recurrence time of a node is\ninversely proportional to the degree for both active and passive random walks.\nFurthermore, the mean recurrence time does or does not depend on the\ndistribution of interevent-times for the active and passive random walks,\nrespectively.\n", "Comment: 5 figures"]}}], "languages": [null], "subjects": ["condensed matter - disordered systems and neural networks", "physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.4582"}}, {"publisher": {"name": ""}, "description": "  We describe extensive computational experiments on spectral properties of\nrandom objects - random cubic graphs, random planar triangulations, and Voronoi\nand Delaunay diagrams of random (uniformly distributed) point sets on the\nsphere). We look at bulk eigenvalue distribution, eigenvalue spacings, and\nlocality properties of eigenvectors. We also look at the statistics of\n\\emph{nodal domains} of eigenvectors on these graphs. In all cases we discover\ncompletely new (at least to this author) phenomena. The author has tried to\nrefrain from making specific conjectures, inviting the reader, instead, to\nmeditate on the data.\n", "contributors": [{"name": "Rivin, Igor", "sameAs": [], "familyName": "Rivin", "additionalName": "", "givenName": "Igor", "email": ""}], "title": "Spectral Experiments+", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-12", "2014-10-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6771", "oai:arXiv.org:1410.6771"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:cond-mat", "physics:hep-th", "physics:math-ph"]}}, {"name": "description", "properties": {"description": ["  We describe extensive computational experiments on spectral properties of\nrandom objects - random cubic graphs, random planar triangulations, and Voronoi\nand Delaunay diagrams of random (uniformly distributed) point sets on the\nsphere). We look at bulk eigenvalue distribution, eigenvalue spacings, and\nlocality properties of eigenvectors. We also look at the statistics of\n\\emph{nodal domains} of eigenvectors on these graphs. In all cases we discover\ncompletely new (at least to this author) phenomena. The author has tried to\nrefrain from making specific conjectures, inviting the reader, instead, to\nmeditate on the data.\n", "Comment: 24 pages"]}}], "languages": [null], "subjects": ["05c80", "60d05", "computer science - computational geometry", "high energy physics - theory", "60b20", "mathematical physics", "mathematics - spectral theory", "condensed matter - statistical mechanics", "mathematics - probability"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6771"}}, {"publisher": {"name": ""}, "description": "  Do different fields of knowledge require different research strategies? A\nnumerical model exploring different virtual knowledge landscapes, revealed two\ndiverging optimal search strategies. Trend following is maximized when the\npopularity of new discoveries determine the number of individuals researching\nit. This strategy works best when many researchers explore few large areas of\nknowledge. In contrast, individuals or small groups of researchers are better\nin discovering small bits of information in dispersed knowledge landscapes.\nBibliometric data of scientific publications showed a continuous bipolar\ndistribution of these strategies, ranging from natural sciences, with highly\ncited publications in journals containing a large number of articles, to the\nsocial sciences, with rarely cited publications in many journals containing a\nsmall number of articles. The natural sciences seem to adapt their research\nstrategies to landscapes with large concentrated knowledge clusters, whereas\nsocial sciences seem to have adapted to search in landscapes with many small\nisolated knowledge clusters. Similar bipolar distributions were obtained when\ncomparing levels of insularity estimated by indicators of international\ncollaboration and levels of country-self citations: researchers in academic\nareas with many journals such as social sciences, arts and humanities, were the\nmost isolated, and that was true in different regions of the world. The work\nshows that quantitative measures estimating differences between academic\ndisciplines improve our understanding of different research strategies,\neventually helping interdisciplinary research and may be also help improve\nscience policies worldwide.\n", "contributors": [{"name": "Jaffe, Klaus", "sameAs": [], "familyName": "Jaffe", "additionalName": "", "givenName": "Klaus", "email": ""}], "title": "Social and Natural Sciences Differ in Their Research Strategies, Adapted\n  to Work for Different Knowledge Landscapes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-20", "2015-04-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.5107", "PLoS ONE 9(11): e113901. (2014)", "doi:10.1371/journal.pone.0113901", "oai:arXiv.org:1403.5107"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Do different fields of knowledge require different research strategies? A\nnumerical model exploring different virtual knowledge landscapes, revealed two\ndiverging optimal search strategies. Trend following is maximized when the\npopularity of new discoveries determine the number of individuals researching\nit. This strategy works best when many researchers explore few large areas of\nknowledge. In contrast, individuals or small groups of researchers are better\nin discovering small bits of information in dispersed knowledge landscapes.\nBibliometric data of scientific publications showed a continuous bipolar\ndistribution of these strategies, ranging from natural sciences, with highly\ncited publications in journals containing a large number of articles, to the\nsocial sciences, with rarely cited publications in many journals containing a\nsmall number of articles. The natural sciences seem to adapt their research\nstrategies to landscapes with large concentrated knowledge clusters, whereas\nsocial sciences seem to have adapted to search in landscapes with many small\nisolated knowledge clusters. Similar bipolar distributions were obtained when\ncomparing levels of insularity estimated by indicators of international\ncollaboration and levels of country-self citations: researchers in academic\nareas with many journals such as social sciences, arts and humanities, were the\nmost isolated, and that was true in different regions of the world. The work\nshows that quantitative measures estimating differences between academic\ndisciplines improve our understanding of different research strategies,\neventually helping interdisciplinary research and may be also help improve\nscience policies worldwide.\n", "Comment: Formerly called: Simulations suggest that social and natural sciences\n  differ in their research strategies adapted to work for different knowledge\n  landscapes"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - digital libraries"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.5107"}}, {"publisher": {"name": ""}, "description": "  The theory of slice regular functions of a quaternionic variable, introduced\nin 2006 by Gentili and Struppa, extends the notion of holomorphic function to\nthe quaternionic setting. This fast growing theory is already rich of many\nresults and has interesting applications. In this setting, the present paper is\ndevoted to introduce and study the quaternionic counterparts of Hardy spaces of\nholomorphic functions of one complex variable. The basic properties of the\ntheory of quaternionic Hardy spaces are investigated, and in particular a\nPoisson-type representation formula, the notions of outer function, singular\nfunction and inner function are given. A quaternionic (partial) counterpart of\nthe classical $H^p$-factorization theorem is proved. This last result assumes a\nparticularly interesting formulation for a large subclass of slice regular\nfunctions, where it is obtained in terms of an outer function, a singular\nfunction and a quaternionic Blaschke product.\n", "contributors": [{"name": "de Fabritiis, Chiara", "sameAs": [], "familyName": "de Fabritiis", "additionalName": "", "givenName": "Chiara", "email": ""}, {"name": "Gentili, Graziano", "sameAs": [], "familyName": "Gentili", "additionalName": "", "givenName": "Graziano", "email": ""}, {"name": "Sarfatti, Giulia", "sameAs": [], "familyName": "Sarfatti", "additionalName": "", "givenName": "Giulia", "email": ""}], "title": "Quaternionic Hardy spaces", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-04", "2015-03-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.1234", "oai:arXiv.org:1404.1234"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The theory of slice regular functions of a quaternionic variable, introduced\nin 2006 by Gentili and Struppa, extends the notion of holomorphic function to\nthe quaternionic setting. This fast growing theory is already rich of many\nresults and has interesting applications. In this setting, the present paper is\ndevoted to introduce and study the quaternionic counterparts of Hardy spaces of\nholomorphic functions of one complex variable. The basic properties of the\ntheory of quaternionic Hardy spaces are investigated, and in particular a\nPoisson-type representation formula, the notions of outer function, singular\nfunction and inner function are given. A quaternionic (partial) counterpart of\nthe classical $H^p$-factorization theorem is proved. This last result assumes a\nparticularly interesting formulation for a large subclass of slice regular\nfunctions, where it is obtained in terms of an outer function, a singular\nfunction and a quaternionic Blaschke product.\n", "Comment: 31 pages, some proofs shortened, some references added"]}}], "languages": [null], "subjects": ["30h10", "30g35", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.1234"}}, {"publisher": {"name": ""}, "description": "  Identifying communities has always been a fundamental task in analysis of\ncomplex networks. Many methods have been devised over the last decade for\ndetection of communities. Amongst them, the label propagation algorithm brings\ngreat scalability together with high accuracy. However, it has one major flaw;\nwhen the community structure in the network is not clear enough, it will assign\nevery node the same label, thus detecting the whole graph as one giant\ncommunity. We have addressed this issue by setting a capacity for communities,\nstarting from a small value and gradually increasing it over time. Preliminary\nresults show that not only our extension improves the detection capability of\nclassic label propagation algorithm when communities are not clearly\ndetectable, but also improves the overall quality of the identified clusters in\ncomplex networks with a clear community structure.\n", "contributors": [{"name": "Rezaei, Aria", "sameAs": [], "familyName": "Rezaei", "additionalName": "", "givenName": "Aria", "email": ""}, {"name": "Far, Saeed Mahlouji", "sameAs": [], "familyName": "Far", "additionalName": "Mahlouji", "givenName": "Saeed", "email": ""}, {"name": "Soleymani, Mahdieh", "sameAs": [], "familyName": "Soleymani", "additionalName": "", "givenName": "Mahdieh", "email": ""}], "title": "Controlled Label Propagation: Preventing Over-Propagation through\n  Gradual Expansion", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04694", "oai:arXiv.org:1503.04694"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Identifying communities has always been a fundamental task in analysis of\ncomplex networks. Many methods have been devised over the last decade for\ndetection of communities. Amongst them, the label propagation algorithm brings\ngreat scalability together with high accuracy. However, it has one major flaw;\nwhen the community structure in the network is not clear enough, it will assign\nevery node the same label, thus detecting the whole graph as one giant\ncommunity. We have addressed this issue by setting a capacity for communities,\nstarting from a small value and gradually increasing it over time. Preliminary\nresults show that not only our extension improves the detection capability of\nclassic label propagation algorithm when communities are not clearly\ndetectable, but also improves the overall quality of the identified clusters in\ncomplex networks with a clear community structure.\n", "Comment: 8 pages, 5 figures, conference"]}}], "languages": [null], "subjects": ["computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04694"}}, {"publisher": {"name": ""}, "description": "  This article gives theoretical insights into the performance of K-SVD, a\ndictionary learning algorithm that has gained significant popularity in\npractical applications. The particular question studied here is when a\ndictionary $\\Phi\\in \\mathbb{R}^{d \\times K}$ can be recovered as local minimum\nof the minimisation criterion underlying K-SVD from a set of $N$ training\nsignals $y_n =\\Phi x_n$. A theoretical analysis of the problem leads to two\ntypes of identifiability results assuming the training signals are generated\nfrom a tight frame with coefficients drawn from a random symmetric\ndistribution. First, asymptotic results showing, that in expectation the\ngenerating dictionary can be recovered exactly as a local minimum of the K-SVD\ncriterion if the coefficient distribution exhibits sufficient decay. Second,\nbased on the asymptotic results it is demonstrated that given a finite number\nof training samples $N$, such that $N/\\log N = O(K^3d)$, except with\nprobability $O(N^{-Kd})$ there is a local minimum of the K-SVD criterion within\ndistance $O(KN^{-1/4})$ to the generating dictionary.\n", "contributors": [{"name": "Schnass, Karin", "sameAs": [], "familyName": "Schnass", "additionalName": "", "givenName": "Karin", "email": ""}], "title": "On the Identifiability of Overcomplete Dictionaries via the Minimisation\n  Principle Underlying K-SVD", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-01-15", "2015-04-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1301.3375", "Applied and Computational Harmonic Analysis, Volume 37, Issue 3,\n  November 2014, Pages 464-491", "doi:10.1016/j.acha.2014.01.005", "oai:arXiv.org:1301.3375"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This article gives theoretical insights into the performance of K-SVD, a\ndictionary learning algorithm that has gained significant popularity in\npractical applications. The particular question studied here is when a\ndictionary $\\Phi\\in \\mathbb{R}^{d \\times K}$ can be recovered as local minimum\nof the minimisation criterion underlying K-SVD from a set of $N$ training\nsignals $y_n =\\Phi x_n$. A theoretical analysis of the problem leads to two\ntypes of identifiability results assuming the training signals are generated\nfrom a tight frame with coefficients drawn from a random symmetric\ndistribution. First, asymptotic results showing, that in expectation the\ngenerating dictionary can be recovered exactly as a local minimum of the K-SVD\ncriterion if the coefficient distribution exhibits sufficient decay. Second,\nbased on the asymptotic results it is demonstrated that given a finite number\nof training samples $N$, such that $N/\\log N = O(K^3d)$, except with\nprobability $O(N^{-Kd})$ there is a local minimum of the K-SVD criterion within\ndistance $O(KN^{-1/4})$ to the generating dictionary.\n", "Comment: 36 pages (double spaced), 3 figures, equivalent to final accepted\n  version"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1301.3375"}}, {"publisher": {"name": ""}, "description": "  Todays students are encouraged to study and develop expertise in more than\none national academic environment. As a matter of fact, their educational\nactivities inevitably occur in a variety of academic settings and even span\nseveral years. Consequently students academic results and progress are expected\nto be easily monitored and accessed nationally. The authors of the present\npaper have devised a student gradebook information network to be nationally\nemployed by all public and private universities and colleges. The papers deals\nwith the architectural principles underlying the system and discusses aspects\nrelated to data collection, data analysis and data storage across multiple\nmachines while providing a seamless view of entire infrastructure and service\ndelivery system from a single Web access point. The utility of the\narchitectural system is discussed in relationship with its major advantages:\nuser-friendliness, security access, flexibility, transparency, distributional\npower, and scalability. The major beneficiary of the system is the Romanian\nhigher education system.\n", "contributors": [{"name": "Turcu, Cristina", "sameAs": [], "familyName": "Turcu", "additionalName": "", "givenName": "Cristina", "email": ""}, {"name": "Turcu, Cornel", "sameAs": [], "familyName": "Turcu", "additionalName": "", "givenName": "Cornel", "email": ""}, {"name": "Graur, Evelina", "sameAs": [], "familyName": "Graur", "additionalName": "", "givenName": "Evelina", "email": ""}], "title": "A Proposal for a Nationwide Student Gradebook Information Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04288", "oai:arXiv.org:1503.04288"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Todays students are encouraged to study and develop expertise in more than\none national academic environment. As a matter of fact, their educational\nactivities inevitably occur in a variety of academic settings and even span\nseveral years. Consequently students academic results and progress are expected\nto be easily monitored and accessed nationally. The authors of the present\npaper have devised a student gradebook information network to be nationally\nemployed by all public and private universities and colleges. The papers deals\nwith the architectural principles underlying the system and discusses aspects\nrelated to data collection, data analysis and data storage across multiple\nmachines while providing a seamless view of entire infrastructure and service\ndelivery system from a single Web access point. The utility of the\narchitectural system is discussed in relationship with its major advantages:\nuser-friendliness, security access, flexibility, transparency, distributional\npower, and scalability. The major beneficiary of the system is the Romanian\nhigher education system.\n"}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04288"}}, {"publisher": {"name": ""}, "description": "  For multiple-input multiple-output (MIMO) spatial-multiplexing transmission,\nzero-forcing detection (ZF) is appealing because of its low complexity. Our\nrecent MIMO ZF performance analysis for Rician--Rayleigh fading, which is\nrelevant in heterogeneous networks, has yielded for the ZF outage probability\nand ergodic capacity infinite-series expressions. Because they arose from\nexpanding the confluent hypergeometric function $ {_1\\! F_1} (\\cdot, \\cdot,\n\\sigma) $ around 0, they do not converge numerically at realistically-high\nRician $ K $-factor values. Therefore, herein, we seek to take advantage of the\nfact that $ {_1\\! F_1} (\\cdot, \\cdot, \\sigma) $ satisfies a differential\nequation, i.e., it is a \\textit{holonomic} function. Holonomic functions can be\ncomputed by the \\textit{holonomic gradient method} (HGM), i.e., by numerically\nsolving the satisfied differential equation. Thus, we first reveal that the\nmoment generating function (m.g.f.) and probability density function (p.d.f.)\nof the ZF signal-to-noise ratio (SNR) are holonomic. Then, from the\ndifferential equation for $ {_1\\! F_1} (\\cdot, \\cdot, \\sigma) $, we deduce\nthose satisfied by the SNR m.g.f. and p.d.f., and demonstrate that the HGM\nhelps compute the p.d.f. accurately at practically-relevant values of $ K $.\nFinally, numerical integration of the SNR p.d.f. produced by HGM yields\naccurate ZF outage probability and ergodic capacity results.\n", "contributors": [{"name": "Siriteanu, Constantin", "sameAs": [], "familyName": "Siriteanu", "additionalName": "", "givenName": "Constantin", "email": ""}, {"name": "Takemura, Akimichi", "sameAs": [], "familyName": "Takemura", "additionalName": "", "givenName": "Akimichi", "email": ""}, {"name": "Kuriki, Satoshi", "sameAs": [], "familyName": "Kuriki", "additionalName": "", "givenName": "Satoshi", "email": ""}, {"name": "Shin, Hyundong", "sameAs": [], "familyName": "Shin", "additionalName": "", "givenName": "Hyundong", "email": ""}, {"name": "Koutschan, Christoph", "sameAs": [], "familyName": "Koutschan", "additionalName": "", "givenName": "Christoph", "email": ""}], "title": "MIMO Zero-Forcing Performance Evaluation Using the Holonomic Gradient\n  Method", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-15", "2015-04-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.3788", "IEEE Transactions on Wireless Communications, vol. 14, no. 4,\n  April 2015, pp. 2322-2335", "doi:10.1109/TWC.2014.2385075", "oai:arXiv.org:1403.3788"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  For multiple-input multiple-output (MIMO) spatial-multiplexing transmission,\nzero-forcing detection (ZF) is appealing because of its low complexity. Our\nrecent MIMO ZF performance analysis for Rician--Rayleigh fading, which is\nrelevant in heterogeneous networks, has yielded for the ZF outage probability\nand ergodic capacity infinite-series expressions. Because they arose from\nexpanding the confluent hypergeometric function $ {_1\\! F_1} (\\cdot, \\cdot,\n\\sigma) $ around 0, they do not converge numerically at realistically-high\nRician $ K $-factor values. Therefore, herein, we seek to take advantage of the\nfact that $ {_1\\! F_1} (\\cdot, \\cdot, \\sigma) $ satisfies a differential\nequation, i.e., it is a \\textit{holonomic} function. Holonomic functions can be\ncomputed by the \\textit{holonomic gradient method} (HGM), i.e., by numerically\nsolving the satisfied differential equation. Thus, we first reveal that the\nmoment generating function (m.g.f.) and probability density function (p.d.f.)\nof the ZF signal-to-noise ratio (SNR) are holonomic. Then, from the\ndifferential equation for $ {_1\\! F_1} (\\cdot, \\cdot, \\sigma) $, we deduce\nthose satisfied by the SNR m.g.f. and p.d.f., and demonstrate that the HGM\nhelps compute the p.d.f. accurately at practically-relevant values of $ K $.\nFinally, numerical integration of the SNR p.d.f. produced by HGM yields\naccurate ZF outage probability and ergodic capacity results.\n", "Comment: This manuscript was accepted in December 2014"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.3788"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Advances in sensing technologies and the growth of the internet have resulted in an explosion in the size of modern datasets, while storage and processing power continue to lag behind. This motivates the need for algorithms that are efficient, both in terms of the number of measurements needed and running time. To combat the challenges associated with large datasets, we propose a general framework for active hierarchical clustering that repeatedly runs an off-the-shelf clustering algorithm on small subsets of the data and comes with guarantees on performance, measurement complexity and runtime complexity. We instantiate this framework with a simple spectral clustering algorithm and provide concrete results on its performance, showing that, under some assumptions, this algorithm recovers all clusters of size \u2126(log n) using O(n log2 n) similarities and runs in O(n log3 n) time for a dataset of n objects. Through extensive experimentation we also demonstrate that this framework is practically alluring.", "contributors": [{"name": "Krishnamurthy, Akshay", "sameAs": [], "familyName": "Krishnamurthy", "additionalName": "", "givenName": "Akshay", "email": ""}, {"name": "Balakrishnan, Sivaraman", "sameAs": [], "familyName": "Balakrishnan", "additionalName": "", "givenName": "Sivaraman", "email": ""}, {"name": "Xu, Min", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Min", "email": ""}, {"name": "Singh, Aarti", "sameAs": [], "familyName": "Singh", "additionalName": "", "givenName": "Aarti", "email": ""}], "title": "Efficient Active Algorithms for Hierarchical Clustering", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2012-06-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/125", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1122&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1122"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Advances in sensing technologies and the growth of the internet have resulted in an explosion in the size of modern datasets, while storage and processing power continue to lag behind. This motivates the need for algorithms that are efficient, both in terms of the number of measurements needed and running time. To combat the challenges associated with large datasets, we propose a general framework for active hierarchical clustering that repeatedly runs an off-the-shelf clustering algorithm on small subsets of the data and comes with guarantees on performance, measurement complexity and runtime complexity. We instantiate this framework with a simple spectral clustering algorithm and provide concrete results on its performance, showing that, under some assumptions, this algorithm recovers all clusters of size \u2126(log n) using O(n log2 n) similarities and runs in O(n log3 n) time for a dataset of n objects. Through extensive experimentation we also demonstrate that this framework is practically alluring."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-24T22:08:14", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/125"}}, {"publisher": {"name": ""}, "description": "  Error backpropagation is an extremely effective algorithm for assigning\ncredit in artificial neural networks. However, weight updates under Backprop\ndepend on lengthy recursive computations and require separate output and error\nmessages -- features not shared by biological neurons, that are perhaps\nunnecessary. In this paper, we revisit Backprop and the credit assignment\nproblem. We first decompose Backprop into a collection of interacting learning\nalgorithms; provide regret bounds on the performance of these sub-algorithms;\nand factorize Backprop's error signals. Using these results, we derive a new\ncredit assignment algorithm for nonparametric regression, Kickback, that is\nsignificantly simpler than Backprop. Finally, we provide a sufficient condition\nfor Kickback to follow error gradients, and show that Kickback matches\nBackprop's performance on real-world regression benchmarks.\n", "contributors": [{"name": "Balduzzi, David", "sameAs": [], "familyName": "Balduzzi", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Vanchinathan, Hastagiri", "sameAs": [], "familyName": "Vanchinathan", "additionalName": "", "givenName": "Hastagiri", "email": ""}, {"name": "Buhmann, Joachim", "sameAs": [], "familyName": "Buhmann", "additionalName": "", "givenName": "Joachim", "email": ""}], "title": "Kickback cuts Backprop's red-tape: Biologically plausible credit\n  assignment in neural networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.6191", "oai:arXiv.org:1411.6191"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": ["  Error backpropagation is an extremely effective algorithm for assigning\ncredit in artificial neural networks. However, weight updates under Backprop\ndepend on lengthy recursive computations and require separate output and error\nmessages -- features not shared by biological neurons, that are perhaps\nunnecessary. In this paper, we revisit Backprop and the credit assignment\nproblem. We first decompose Backprop into a collection of interacting learning\nalgorithms; provide regret bounds on the performance of these sub-algorithms;\nand factorize Backprop's error signals. Using these results, we derive a new\ncredit assignment algorithm for nonparametric regression, Kickback, that is\nsignificantly simpler than Backprop. Finally, we provide a sufficient condition\nfor Kickback to follow error gradients, and show that Kickback matches\nBackprop's performance on real-world regression benchmarks.\n", "Comment: 7 pages. To appear, AAAI-15"]}}], "languages": [null], "subjects": ["quantitative biology - neurons and cognition", "computer science - neural and evolutionary computing", "computer science - learning"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.6191"}}, {"publisher": {"name": ""}, "description": "  As it is known in the finance risk and macroeconomics literature,\nrisk-sharing in large portfolios may increase the probability of creation of\ndefault clusters and of systemic risk. We review recent developments on\nmathematical and computational tools for the quantification of such phenomena.\nLimiting analysis such as law of large numbers and central limit theorems allow\nto approximate the distribution in large systems and study quantities such as\nthe loss distribution in large portfolios. Large deviations analysis allow us\nto study the tail of the loss distribution and to identify pathways to default\nclustering. Sensitivity analysis allows to understand the most likely ways in\nwhich different effects, such as contagion and systematic risks, combine to\nlead to large default rates. Such results could give useful insights into how\nto optimally safeguard against such events.\n", "contributors": [{"name": "Spiliopoulos, Konstantinos", "sameAs": [], "familyName": "Spiliopoulos", "additionalName": "", "givenName": "Konstantinos", "email": ""}], "title": "Systemic Risk and Default Clustering for Large Financial Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-21", "2015-02-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.5352", "oai:arXiv.org:1402.5352"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "q-fin"]}}, {"name": "description", "properties": {"description": ["  As it is known in the finance risk and macroeconomics literature,\nrisk-sharing in large portfolios may increase the probability of creation of\ndefault clusters and of systemic risk. We review recent developments on\nmathematical and computational tools for the quantification of such phenomena.\nLimiting analysis such as law of large numbers and central limit theorems allow\nto approximate the distribution in large systems and study quantities such as\nthe loss distribution in large portfolios. Large deviations analysis allow us\nto study the tail of the loss distribution and to identify pathways to default\nclustering. Sensitivity analysis allows to understand the most likely ways in\nwhich different effects, such as contagion and systematic risks, combine to\nlead to large default rates. Such results could give useful insights into how\nto optimally safeguard against such events.\n", "Comment: in Large Deviations and Asymptotic Methods in Finance, (Editors: P.\n  Friz, J. Gatheral, A. Gulisashvili, A. Jacqier, J. Teichmann) , Springer\n  Proceedings in Mathematics and Statistics, Vol. 110 2015,"]}}], "languages": [null], "subjects": ["60g57", "60g55", "quantitative finance - risk management", "60f05", "60f10", "91g40", "91g80", "quantitative finance - computational finance", "mathematics - probability"], "providerUpdatedDateTime": "2015-02-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.5352"}}, {"publisher": {"name": ""}, "description": "  In this paper, we consider the problem of the recognition of various kinds of\norderings produced by graph searches. To this aim, we introduce a new\nframework, the Tie-Breaking Label Search (TBLS), in order to handle a broad\nvariety of searches. This new model is based on partial orders defined on the\nlabel set and it unifies the General Label Search (GLS) formalism of Krueger,\nSimonet and Berry (2011), and the \"pattern-conditions\" formalism of Corneil and\nKrueger (2008). It allows us to derive some general properties including new\npattern-conditions (yielding memory-efficient certificates) for many usual\nsearches, including BFS, DFS, LBFS and LDFS. Furthermore, the new model allows\neasy expression of multi-sweep uses of searches that depend on previous\n(search) orderings of the graph's vertex set.\n", "contributors": [{"name": "Corneil, Derek G.", "sameAs": [], "familyName": "Corneil", "additionalName": "G.", "givenName": "Derek", "email": ""}, {"name": "Dusart, Jeremie", "sameAs": [], "familyName": "Dusart", "additionalName": "", "givenName": "Jeremie", "email": ""}, {"name": "Habib, Michel", "sameAs": [], "familyName": "Habib", "additionalName": "", "givenName": "Michel", "email": ""}, {"name": "de Montgolfier, Fabien", "sameAs": [], "familyName": "de Montgolfier", "additionalName": "", "givenName": "Fabien", "email": ""}], "title": "A tie-break model for graph search", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06148", "oai:arXiv.org:1501.06148"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we consider the problem of the recognition of various kinds of\norderings produced by graph searches. To this aim, we introduce a new\nframework, the Tie-Breaking Label Search (TBLS), in order to handle a broad\nvariety of searches. This new model is based on partial orders defined on the\nlabel set and it unifies the General Label Search (GLS) formalism of Krueger,\nSimonet and Berry (2011), and the \"pattern-conditions\" formalism of Corneil and\nKrueger (2008). It allows us to derive some general properties including new\npattern-conditions (yielding memory-efficient certificates) for many usual\nsearches, including BFS, DFS, LBFS and LDFS. Furthermore, the new model allows\neasy expression of multi-sweep uses of searches that depend on previous\n(search) orderings of the graph's vertex set.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06148"}}, {"publisher": {"name": ""}, "description": "  We prove that for every $\\epsilon>0$ and predicate $P:\\{0,1\\}^k\\rightarrow\n\\{0,1\\}$ that supports a pairwise independent distribution, there exists an\ninstance $\\mathcal{I}$ of the $\\mathsf{Max}P$ constraint satisfaction problem\non $n$ variables such that no assignment can satisfy more than a\n$\\tfrac{|P^{-1}(1)|}{2^k}+\\epsilon$ fraction of $\\mathcal{I}$'s constraints but\nthe degree $\\Omega(n)$ Sum of Squares semidefinite programming hierarchy cannot\ncertify that $\\mathcal{I}$ is unsatisfiable. Similar results were previously\nonly known for weaker hierarchies.\n", "contributors": [{"name": "Barak, Boaz", "sameAs": [], "familyName": "Barak", "additionalName": "", "givenName": "Boaz", "email": ""}, {"name": "Chan, Siu On", "sameAs": [], "familyName": "Chan", "additionalName": "On", "givenName": "Siu", "email": ""}, {"name": "Kothari, Pravesh", "sameAs": [], "familyName": "Kothari", "additionalName": "", "givenName": "Pravesh", "email": ""}], "title": "Sum of Squares Lower Bounds from Pairwise Independence", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-04", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00734", "oai:arXiv.org:1501.00734"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We prove that for every $\\epsilon>0$ and predicate $P:\\{0,1\\}^k\\rightarrow\n\\{0,1\\}$ that supports a pairwise independent distribution, there exists an\ninstance $\\mathcal{I}$ of the $\\mathsf{Max}P$ constraint satisfaction problem\non $n$ variables such that no assignment can satisfy more than a\n$\\tfrac{|P^{-1}(1)|}{2^k}+\\epsilon$ fraction of $\\mathcal{I}$'s constraints but\nthe degree $\\Omega(n)$ Sum of Squares semidefinite programming hierarchy cannot\ncertify that $\\mathcal{I}$ is unsatisfiable. Similar results were previously\nonly known for weaker hierarchies.\n", "Comment: 27 Pages (including the title page) and 4 figures including appendix"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "f.2.0"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00734"}}, {"publisher": {"name": ""}, "description": "  We study the design of nearly-linear-time algorithms for approximately\nsolving positive linear programs. Both the parallel and the sequential\ndeterministic versions of these algorithms require\n$\\tilde{O}(\\varepsilon^{-4})$ iterations, a dependence that has not been\nimproved since the introduction of these methods in 1993 by Luby and Nisan.\nMoreover, previous algorithms and their analyses rely on update steps and\nconvergence arguments that are combinatorial in nature, and do not seem to\narise naturally from an optimization viewpoint. In this paper, we leverage\ninsights from optimization theory to construct a novel algorithm that breaks\nthe longstanding $\\tilde{O}(\\varepsilon^{-4})$ barrier. Our algorithm has a\nsimple analysis and a clear motivation. Our work introduces a number of novel\ntechniques, such as the combined application of gradient descent and mirror\ndescent, and a truncated, smoothed version of the standard multiplicative\nweight update, which may be of independent interest.\n", "contributors": [{"name": "Allen-Zhu, Zeyuan", "sameAs": [], "familyName": "Allen-Zhu", "additionalName": "", "givenName": "Zeyuan", "email": ""}, {"name": "Orecchia, Lorenzo", "sameAs": [], "familyName": "Orecchia", "additionalName": "", "givenName": "Lorenzo", "email": ""}], "title": "Using Optimization to Break the Epsilon Barrier: A Faster and Simpler\n  Width-Independent Algorithm for Solving Positive Linear Programs in Parallel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-07", "2014-11-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.1925", "oai:arXiv.org:1407.1925"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We study the design of nearly-linear-time algorithms for approximately\nsolving positive linear programs. Both the parallel and the sequential\ndeterministic versions of these algorithms require\n$\\tilde{O}(\\varepsilon^{-4})$ iterations, a dependence that has not been\nimproved since the introduction of these methods in 1993 by Luby and Nisan.\nMoreover, previous algorithms and their analyses rely on update steps and\nconvergence arguments that are combinatorial in nature, and do not seem to\narise naturally from an optimization viewpoint. In this paper, we leverage\ninsights from optimization theory to construct a novel algorithm that breaks\nthe longstanding $\\tilde{O}(\\varepsilon^{-4})$ barrier. Our algorithm has a\nsimple analysis and a clear motivation. Our work introduces a number of novel\ntechniques, such as the combined application of gradient descent and mirror\ndescent, and a truncated, smoothed version of the standard multiplicative\nweight update, which may be of independent interest.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "mathematics - numerical analysis", "computer science - numerical analysis", "and cluster computing", "computer science - data structures and algorithms", "computer science - distributed", "parallel"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.1925"}}, {"publisher": {"name": ""}, "description": "  Much has been said about observability in system theory and control; however,\nit has been recently that observability in complex networks has seriously\nattracted the attention of researchers. This paper examines the\nstate-of-the-art and discusses some issues raised due to \"complexity\" and\n\"stochasticity\". These unresolved issues call for a new practical methodology.\nFor stochastic systems, a degree of observability may be defined and the\nobservability problem is not a binary (i.e., yes-no) question anymore. Here, we\npropose to employ a goal-seeking system to play a supervisory role in the\nnetwork. Hence, improving the degree of observability would be a valid\nobjective for the supervisory system. Towards this goal, the supervisor\ndynamically optimizes the observation process by reconfiguring the sensory\nparts in the network. A cognitive dynamic system is suggested as a proper\nchoice for the supervisory system. In this framework, the network itself is\nviewed as the environment with which the cognitive dynamic system interacts.\nComputer experiments confirm the potential of the proposed approach for\naddressing some of the issues raised in networks due to complexity and\nstochasticity.\n", "contributors": [{"name": "Fatemi, Mehdi", "sameAs": [], "familyName": "Fatemi", "additionalName": "", "givenName": "Mehdi", "email": ""}, {"name": "Setoodeh, Peyman", "sameAs": [], "familyName": "Setoodeh", "additionalName": "", "givenName": "Peyman", "email": ""}, {"name": "Haykin, Simon", "sameAs": [], "familyName": "Haykin", "additionalName": "", "givenName": "Simon", "email": ""}], "title": "Improving Observability of Stochastic Complex Networks under the\n  Supervision of Cognitive Dynamic Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6162", "oai:arXiv.org:1412.6162"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Much has been said about observability in system theory and control; however,\nit has been recently that observability in complex networks has seriously\nattracted the attention of researchers. This paper examines the\nstate-of-the-art and discusses some issues raised due to \"complexity\" and\n\"stochasticity\". These unresolved issues call for a new practical methodology.\nFor stochastic systems, a degree of observability may be defined and the\nobservability problem is not a binary (i.e., yes-no) question anymore. Here, we\npropose to employ a goal-seeking system to play a supervisory role in the\nnetwork. Hence, improving the degree of observability would be a valid\nobjective for the supervisory system. Towards this goal, the supervisor\ndynamically optimizes the observation process by reconfiguring the sensory\nparts in the network. A cognitive dynamic system is suggested as a proper\nchoice for the supervisory system. In this framework, the network itself is\nviewed as the environment with which the cognitive dynamic system interacts.\nComputer experiments confirm the potential of the proposed approach for\naddressing some of the issues raised in networks due to complexity and\nstochasticity.\n", "Comment: Submitted to IEEE Trans. Network Science and Engineering on October\n  25, 2014"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6162"}}, {"publisher": {"name": ""}, "description": "  The hypercube 2-segmentation problem is a certain biclustering problem that\nwas previously claimed to be NP-hard, but for which there does not appear to be\na publicly available proof of NP-hardness. This manuscript provides such a\nproof.\n", "contributors": [{"name": "Feige, Uriel", "sameAs": [], "familyName": "Feige", "additionalName": "", "givenName": "Uriel", "email": ""}], "title": "NP-hardness of hypercube 2-segmentation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0821", "oai:arXiv.org:1411.0821"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The hypercube 2-segmentation problem is a certain biclustering problem that\nwas previously claimed to be NP-hard, but for which there does not appear to be\na publicly available proof of NP-hardness. This manuscript provides such a\nproof.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity"], "providerUpdatedDateTime": "2014-11-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0821"}}, {"publisher": {"name": ""}, "description": "  This document presents the business requirement of Unified University\nInventory System (UUIS) in Technology-independent manner. All attempts have\nbeen made in using mostly business terminology and business language while\ndescribing the requirements in this document. Very minimal and commonly\nunderstood Technical terminology is used. Use case approach is used in modeling\nthe business requirements in this document.\n", "contributors": [{"name": "Alhazmi, Ali", "sameAs": [], "familyName": "Alhazmi", "additionalName": "", "givenName": "Ali", "email": ""}, {"name": "Al-Sharawi, Abdulrahman", "sameAs": [], "familyName": "Al-Sharawi", "additionalName": "", "givenName": "Abdulrahman", "email": ""}, {"name": "Liu, Bing", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Bing", "email": ""}, {"name": "Oliveira, Deyvisson", "sameAs": [], "familyName": "Oliveira", "additionalName": "", "givenName": "Deyvisson", "email": ""}, {"name": "Sobh, Kanj", "sameAs": [], "familyName": "Sobh", "additionalName": "", "givenName": "Kanj", "email": ""}, {"name": "Mayantz, Max", "sameAs": [], "familyName": "Mayantz", "additionalName": "", "givenName": "Max", "email": ""}, {"name": "de Bled, Robin", "sameAs": [], "familyName": "de Bled", "additionalName": "", "givenName": "Robin", "email": ""}, {"name": "Zhang, Yu Ming", "sameAs": [], "familyName": "Zhang", "additionalName": "Ming", "givenName": "Yu", "email": ""}], "title": "Software Requirements Specification of the IUfA's UUIS -- a Team 4\n  COMP5541-W10 Project Approach", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-05-02", "2010-05-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.0162", "oai:arXiv.org:1005.0162"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This document presents the business requirement of Unified University\nInventory System (UUIS) in Technology-independent manner. All attempts have\nbeen made in using mostly business terminology and business language while\ndescribing the requirements in this document. Very minimal and commonly\nunderstood Technical terminology is used. Use case approach is used in modeling\nthe business requirements in this document.\n", "Comment: 30 pages, 13 figures"]}}], "languages": [null], "subjects": ["k.6", "computer science - software engineering", "h.5.2", "d.2"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.0162"}}, {"publisher": {"name": ""}, "description": "  Polynomial kernel regression is one of the standard and state-of-the-art\nlearning strategies. However, as is well known, the choices of the degree of\npolynomial kernel and the regularization parameter are still open in the realm\nof model selection. The first aim of this paper is to develop a strategy to\nselect these parameters. On one hand, based on the worst-case learning rate\nanalysis, we show that the regularization term in polynomial kernel regression\nis not necessary. In other words, the regularization parameter can decrease\narbitrarily fast when the degree of the polynomial kernel is suitable tuned. On\nthe other hand,taking account of the implementation of the algorithm, the\nregularization term is required. Summarily, the effect of the regularization\nterm in polynomial kernel regression is only to circumvent the \" ill-condition\"\nof the kernel matrix. Based on this, the second purpose of this paper is to\npropose a new model selection strategy, and then design an efficient learning\nalgorithm. Both theoretical and experimental analysis show that the new\nstrategy outperforms the previous one. Theoretically, we prove that the new\nlearning strategy is almost optimal if the regression function is smooth.\nExperimentally, it is shown that the new strategy can significantly reduce the\ncomputational burden without loss of generalization capability.\n", "contributors": [{"name": "Lin, Shaobo", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Shaobo", "email": ""}, {"name": "Sun, Xingping", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Xingping", "email": ""}, {"name": "Xu, Zongben", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Zongben", "email": ""}, {"name": "Zeng, Jinshan", "sameAs": [], "familyName": "Zeng", "additionalName": "", "givenName": "Jinshan", "email": ""}], "title": "Model selection of polynomial kernel regression", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02143", "oai:arXiv.org:1503.02143"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Polynomial kernel regression is one of the standard and state-of-the-art\nlearning strategies. However, as is well known, the choices of the degree of\npolynomial kernel and the regularization parameter are still open in the realm\nof model selection. The first aim of this paper is to develop a strategy to\nselect these parameters. On one hand, based on the worst-case learning rate\nanalysis, we show that the regularization term in polynomial kernel regression\nis not necessary. In other words, the regularization parameter can decrease\narbitrarily fast when the degree of the polynomial kernel is suitable tuned. On\nthe other hand,taking account of the implementation of the algorithm, the\nregularization term is required. Summarily, the effect of the regularization\nterm in polynomial kernel regression is only to circumvent the \" ill-condition\"\nof the kernel matrix. Based on this, the second purpose of this paper is to\npropose a new model selection strategy, and then design an efficient learning\nalgorithm. Both theoretical and experimental analysis show that the new\nstrategy outperforms the previous one. Theoretically, we prove that the new\nlearning strategy is almost optimal if the regression function is smooth.\nExperimentally, it is shown that the new strategy can significantly reduce the\ncomputational burden without loss of generalization capability.\n", "Comment: 29 pages, 4 figures"]}}], "languages": [null], "subjects": ["f.2.2", "computer science - learning"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02143"}}, {"publisher": {"name": ""}, "description": "  Topic models are probabilistic models for discovering topical themes in\ncollections of documents. In real world applications, these models provide us\nwith the means of organizing what would otherwise be unstructured collections.\nThey can help us cluster a huge collection into different topics or find a\nsubset of the collection that resembles the topical theme found in an article\nat hand.\n  The first wave of topic models developed were able to discover the prevailing\ntopics in a big collection of documents spanning a period of time. It was later\nrealized that these time-invariant models were not capable of modeling 1) the\ntime varying number of topics they discover and 2) the time changing structure\nof these topics. Few models were developed to address this two deficiencies.\nThe online-hierarchical Dirichlet process models the documents with a time\nvarying number of topics. It varies the structure of the topics over time as\nwell. However, it relies on document order, not timestamps to evolve the model\nover time. The continuous-time dynamic topic model evolves topic structure in\ncontinuous-time. However, it uses a fixed number of topics over time.\n  In this dissertation, I present a model, the continuous-time infinite dynamic\ntopic model, that combines the advantages of these two models 1) the\nonline-hierarchical Dirichlet process, and 2) the continuous-time dynamic topic\nmodel. More specifically, the model I present is a probabilistic topic model\nthat does the following: 1) it changes the number of topics over continuous\ntime, and 2) it changes the topic structure over continuous-time.\n  I compared the model I developed with the two other models with different\nsetting values. The results obtained were favorable to my model and showed the\nneed for having a model that has a continuous-time varying number of topics and\ntopic structure.\n", "contributors": [{"name": "Elshamy, Wesam", "sameAs": [], "familyName": "Elshamy", "additionalName": "", "givenName": "Wesam", "email": ""}], "title": "Continuous-time Infinite Dynamic Topic Models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-02-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1302.7088", "oai:arXiv.org:1302.7088"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Topic models are probabilistic models for discovering topical themes in\ncollections of documents. In real world applications, these models provide us\nwith the means of organizing what would otherwise be unstructured collections.\nThey can help us cluster a huge collection into different topics or find a\nsubset of the collection that resembles the topical theme found in an article\nat hand.\n  The first wave of topic models developed were able to discover the prevailing\ntopics in a big collection of documents spanning a period of time. It was later\nrealized that these time-invariant models were not capable of modeling 1) the\ntime varying number of topics they discover and 2) the time changing structure\nof these topics. Few models were developed to address this two deficiencies.\nThe online-hierarchical Dirichlet process models the documents with a time\nvarying number of topics. It varies the structure of the topics over time as\nwell. However, it relies on document order, not timestamps to evolve the model\nover time. The continuous-time dynamic topic model evolves topic structure in\ncontinuous-time. However, it uses a fixed number of topics over time.\n  In this dissertation, I present a model, the continuous-time infinite dynamic\ntopic model, that combines the advantages of these two models 1) the\nonline-hierarchical Dirichlet process, and 2) the continuous-time dynamic topic\nmodel. More specifically, the model I present is a probabilistic topic model\nthat does the following: 1) it changes the number of topics over continuous\ntime, and 2) it changes the topic structure over continuous-time.\n  I compared the model I developed with the two other models with different\nsetting values. The results obtained were favorable to my model and showed the\nneed for having a model that has a continuous-time varying number of topics and\ntopic structure.\n", "Comment: Ph.D. dissertation, Kansas State University, 2013"]}}], "languages": [null], "subjects": ["statistics - applications", "68t10", "computer science - information retrieval", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1302.7088"}}, {"publisher": {"name": ""}, "description": "  In this paper we present the first algorithm in the streaming model to\ncharacterize completely the biconnectivity properties of undirected networks:\narticulation points, bridges, and connected and biconnected components. The\nmotivation of our work was the development of a real-time algorithm to monitor\nthe connectivity of the Autonomous Systems (AS) Network, but the solution\nprovided is general enough to be applied to any network.\n  The network structure is represented by a graph, and the algorithm is\nanalyzed in the datastream framework. Here, as in the \\emph{on-line} model, the\ninput graph is revealed one item (i.e., graph edge) after the other, in an\non-line fashion; but, if compared to traditional on-line computation, there are\nstricter requirements for both memory occupation and per item processing time.\nOur algorithm works by properly updating a forest over the graph nodes. All the\ngraph (bi)connectivity properties are stored in this forest. We prove the\ncorrectness of the algorithm, together with its space ($O(n\\,\\log n)$, with $n$\nbeing the number of nodes in the graph) and time bounds.\n  We also present the results of a brief experimental evaluation against\nreal-world graphs, including many samples of the AS network, ranging from\nmedium to massive size. These preliminary experimental results confirm the\neffectiveness of our approach.\n", "contributors": [{"name": "Ausiello, Giorgio", "sameAs": [], "familyName": "Ausiello", "additionalName": "", "givenName": "Giorgio", "email": ""}, {"name": "Firmani, Donatella", "sameAs": [], "familyName": "Firmani", "additionalName": "", "givenName": "Donatella", "email": ""}, {"name": "Laura, Luigi", "sameAs": [], "familyName": "Laura", "additionalName": "", "givenName": "Luigi", "email": ""}], "title": "Real-Time Monitoring of Undirected Networks: Articulation Points,\n  Bridges, and Connected and Biconnected Components", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-02-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1202.0319", "oai:arXiv.org:1202.0319"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper we present the first algorithm in the streaming model to\ncharacterize completely the biconnectivity properties of undirected networks:\narticulation points, bridges, and connected and biconnected components. The\nmotivation of our work was the development of a real-time algorithm to monitor\nthe connectivity of the Autonomous Systems (AS) Network, but the solution\nprovided is general enough to be applied to any network.\n  The network structure is represented by a graph, and the algorithm is\nanalyzed in the datastream framework. Here, as in the \\emph{on-line} model, the\ninput graph is revealed one item (i.e., graph edge) after the other, in an\non-line fashion; but, if compared to traditional on-line computation, there are\nstricter requirements for both memory occupation and per item processing time.\nOur algorithm works by properly updating a forest over the graph nodes. All the\ngraph (bi)connectivity properties are stored in this forest. We prove the\ncorrectness of the algorithm, together with its space ($O(n\\,\\log n)$, with $n$\nbeing the number of nodes in the graph) and time bounds.\n  We also present the results of a brief experimental evaluation against\nreal-world graphs, including many samples of the AS network, ranging from\nmedium to massive size. These preliminary experimental results confirm the\neffectiveness of our approach.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1202.0319"}}, {"publisher": {"name": ""}, "description": "  The Art Gallery Problem (AGP) asks for placing a minimum number of stationary\nguards in a polygonal region P, such that all points in P are guarded. The\nproblem is known to be NP-hard, and its inherent continuous structure (with\nboth the set of points that need to be guarded and the set of points that can\nbe used for guarding being uncountably infinite) makes it difficult to apply a\nstraightforward formulation as an Integer Linear Program. We use an iterative\nprimal-dual relaxation approach for solving AGP instances to optimality. At\neach stage, a pair of LP relaxations for a finite candidate subset of primal\ncovering and dual packing constraints and variables is considered; these\ncorrespond to possible guard positions and points that are to be guarded.\n  Particularly useful are cutting planes for eliminating fractional solutions.\nWe identify two classes of facets, based on Edge Cover and Set Cover (SC)\ninequalities. Solving the separation problem for the latter is NP-complete, but\nexploiting the underlying geometric structure, we show that large subclasses of\nfractional SC solutions cannot occur for the AGP. This allows us to separate\nthe relevant subset of facets in polynomial time. We also characterize all\nfacets for finite AGP relaxations with coefficients in {0, 1, 2}.\n  Finally, we demonstrate the practical usefulness of our approach. Our cutting\nplane technique yields a significant improvement in terms of speed and solution\nquality due to considerably reduced integrality gaps as compared to the\napproach by Kr\\\"oller et al.\n", "contributors": [{"name": "Fekete, S\u00e1ndor P.", "sameAs": [], "familyName": "Fekete", "additionalName": "P.", "givenName": "S\u00e1ndor", "email": ""}, {"name": "Friedrichs, Stephan", "sameAs": [], "familyName": "Friedrichs", "additionalName": "", "givenName": "Stephan", "email": ""}, {"name": "Kr\u00f6ller, Alexander", "sameAs": [], "familyName": "Kr\u00f6ller", "additionalName": "", "givenName": "Alexander", "email": ""}, {"name": "Schmidt, Christiane", "sameAs": [], "familyName": "Schmidt", "additionalName": "", "givenName": "Christiane", "email": ""}], "title": "Facets for Art Gallery Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-08-21", "2014-12-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1308.4670", "oai:arXiv.org:1308.4670"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The Art Gallery Problem (AGP) asks for placing a minimum number of stationary\nguards in a polygonal region P, such that all points in P are guarded. The\nproblem is known to be NP-hard, and its inherent continuous structure (with\nboth the set of points that need to be guarded and the set of points that can\nbe used for guarding being uncountably infinite) makes it difficult to apply a\nstraightforward formulation as an Integer Linear Program. We use an iterative\nprimal-dual relaxation approach for solving AGP instances to optimality. At\neach stage, a pair of LP relaxations for a finite candidate subset of primal\ncovering and dual packing constraints and variables is considered; these\ncorrespond to possible guard positions and points that are to be guarded.\n  Particularly useful are cutting planes for eliminating fractional solutions.\nWe identify two classes of facets, based on Edge Cover and Set Cover (SC)\ninequalities. Solving the separation problem for the latter is NP-complete, but\nexploiting the underlying geometric structure, we show that large subclasses of\nfractional SC solutions cannot occur for the AGP. This allows us to separate\nthe relevant subset of facets in polynomial time. We also characterize all\nfacets for finite AGP relaxations with coefficients in {0, 1, 2}.\n  Finally, we demonstrate the practical usefulness of our approach. Our cutting\nplane technique yields a significant improvement in terms of speed and solution\nquality due to considerably reduced integrality gaps as compared to the\napproach by Kr\\\"oller et al.\n", "Comment: 29 pages, 18 figures, 1 table"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - optimization and control", "f.2.2", "computer science - computational geometry"], "providerUpdatedDateTime": "2014-12-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1308.4670"}}, {"publisher": {"name": ""}, "description": "  In this paper, we consider an $\\ell_{0}$-norm penalized formulation of the\ngeneralized eigenvalue problem (GEP), aimed at extracting the leading sparse\ngeneralized eigenvector of a matrix pair. The formulation involves maximization\nof a discontinuous nonconcave objective function over a nonconvex constraint\nset, and is therefore computationally intractable. To tackle the problem, we\nfirst approximate the $\\ell_{0}$-norm by a continuous surrogate function. Then\nan algorithm is developed via iteratively majorizing the surrogate function by\na quadratic separable function, which at each iteration reduces to a regular\ngeneralized eigenvalue problem. A preconditioned steepest ascent algorithm for\nfinding the leading generalized eigenvector is provided. A systematic way based\non smoothing is proposed to deal with the \"singularity issue\" that arises when\na quadratic function is used to majorize the nondifferentiable surrogate\nfunction. For sparse GEPs with special structure, algorithms that admit a\nclosed-form solution at every iteration are derived. Numerical experiments show\nthat the proposed algorithms match or outperform existing algorithms in terms\nof computational complexity and support recovery.\n", "contributors": [{"name": "Song, Junxiao", "sameAs": [], "familyName": "Song", "additionalName": "", "givenName": "Junxiao", "email": ""}, {"name": "Babu, Prabhu", "sameAs": [], "familyName": "Babu", "additionalName": "", "givenName": "Prabhu", "email": ""}, {"name": "Palomar, Daniel P.", "sameAs": [], "familyName": "Palomar", "additionalName": "P.", "givenName": "Daniel", "email": ""}], "title": "Sparse Generalized Eigenvalue Problem via Smooth Optimization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-28", "2014-11-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6686", "oai:arXiv.org:1408.6686"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  In this paper, we consider an $\\ell_{0}$-norm penalized formulation of the\ngeneralized eigenvalue problem (GEP), aimed at extracting the leading sparse\ngeneralized eigenvector of a matrix pair. The formulation involves maximization\nof a discontinuous nonconcave objective function over a nonconvex constraint\nset, and is therefore computationally intractable. To tackle the problem, we\nfirst approximate the $\\ell_{0}$-norm by a continuous surrogate function. Then\nan algorithm is developed via iteratively majorizing the surrogate function by\na quadratic separable function, which at each iteration reduces to a regular\ngeneralized eigenvalue problem. A preconditioned steepest ascent algorithm for\nfinding the leading generalized eigenvector is provided. A systematic way based\non smoothing is proposed to deal with the \"singularity issue\" that arises when\na quadratic function is used to majorize the nondifferentiable surrogate\nfunction. For sparse GEPs with special structure, algorithms that admit a\nclosed-form solution at every iteration are derived. Numerical experiments show\nthat the proposed algorithms match or outperform existing algorithms in terms\nof computational complexity and support recovery.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-11-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6686"}}, {"publisher": {"name": ""}, "description": "Multiple focus groups were conducted to elicit perspectives from members of the Earth science informatics community on the sustainability of scientific software. Recommendations that the participants offered for near-term community actions and activities are described.", "contributors": [{"name": "Downs, Robert R.", "sameAs": [], "familyName": "Downs", "additionalName": "R.", "givenName": "Robert", "email": ""}, {"name": "Lenhardt, W. Christopher", "sameAs": [], "familyName": "Lenhardt", "additionalName": "Christopher", "givenName": "W.", "email": ""}, {"name": "Robinson, Erin", "sameAs": [], "familyName": "Robinson", "additionalName": "", "givenName": "Erin", "email": ""}, {"name": "Davis, Ethan", "sameAs": [], "familyName": "Davis", "additionalName": "", "givenName": "Ethan", "email": ""}, {"name": "Weber, Nicholas", "sameAs": [], "familyName": "Weber", "additionalName": "", "givenName": "Nicholas", "email": ""}], "title": "Community Recommendations for Improving Sustainable Scientific Software Practices", "shareProperties": {"source": "columbia"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014"}}, {"name": "identifier", "properties": {"identifier": ["http://dx.doi.org/10.7916/D8Q52NBC", "academiccommons.columbia.edu/ac:179856"]}}, {"name": "setSpec", "properties": {"setSpec": []}}], "languages": [null], "subjects": ["information science", "computer science"], "providerUpdatedDateTime": "2014-11-21T15:28:28", "uris": {"canonicalUri": "http://dx.doi.org/10.7916/D8Q52NBC"}}, {"publisher": {"name": ""}, "description": "  The main challenge in on-line handwritten character recognition in Indian\nlan- guage is the large size of the character set, larger similarity between\ndifferent characters in the script and the huge variation in writing style. In\nthis paper we propose a framework for on-line handwitten script recognition\ntaking cues from speech signal processing literature. The framework is based on\nidentify- ing strokes, which in turn lead to recognition of handwritten on-line\ncharacters rather that the conventional character identification. Though the\nframework is described for Devanagari script, the framework is general and can\nbe applied to any language.\n  The proposed platform consists of pre-processing, feature extraction, recog-\nnition and post processing like the conventional character recognition but ap-\nplied to strokes. The on-line Devanagari character recognition reduces to one\nof recognizing one of 69 primitives and recognition of a character is performed\nby recognizing a sequence of such primitives. We further show the impact of\nnoise removal on on-line raw data which is usually noisy. The use of Fuzzy\nDirec- tional Features to enhance the accuracy of stroke recognition is also\ndescribed. The recognition results are compared with commonly used directional\nfeatures in literature using several classifiers.\n", "contributors": [{"name": "Kopparapu, Sunil Kumar", "sameAs": [], "familyName": "Kopparapu", "additionalName": "Kumar", "givenName": "Sunil", "email": ""}, {"name": "L, Lajish V.", "sameAs": [], "familyName": "L", "additionalName": "V.", "givenName": "Lajish", "email": ""}], "title": "A Framework for On-Line Devanagari Handwritten Character Recognition", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6909", "oai:arXiv.org:1410.6909"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The main challenge in on-line handwritten character recognition in Indian\nlan- guage is the large size of the character set, larger similarity between\ndifferent characters in the script and the huge variation in writing style. In\nthis paper we propose a framework for on-line handwitten script recognition\ntaking cues from speech signal processing literature. The framework is based on\nidentify- ing strokes, which in turn lead to recognition of handwritten on-line\ncharacters rather that the conventional character identification. Though the\nframework is described for Devanagari script, the framework is general and can\nbe applied to any language.\n  The proposed platform consists of pre-processing, feature extraction, recog-\nnition and post processing like the conventional character recognition but ap-\nplied to strokes. The on-line Devanagari character recognition reduces to one\nof recognizing one of 69 primitives and recognition of a character is performed\nby recognizing a sequence of such primitives. We further show the impact of\nnoise removal on on-line raw data which is usually noisy. The use of Fuzzy\nDirec- tional Features to enhance the accuracy of stroke recognition is also\ndescribed. The recognition results are compared with commonly used directional\nfeatures in literature using several classifiers.\n", "Comment: 29 pages"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6909"}}, {"publisher": {"name": ""}, "description": "  We consider waking up a single-hop radio network with multiple channels.\nThere are $n$ stations connected to $b$ channels without collision detection.\nSome $k$ stations may become active spontaneously at arbitrary times, where $k$\nis unknown, and the goal is for all the stations to hear a successful\ntransmission as soon as possible after the first spontaneous activation. We\npresent a deterministic algorithm for the general problem that wakes up the\nnetwork in $O(k\\log^{1/b} k\\log n)$ time. We prove a lower bound that any\ndeterministic algorithm requires $\\Omega((k/b)\\log (n/k))$ time. We give a\ndeterministic algorithm for the special case when $b>d \\log \\log n$, for some\nconstant $d>1$, which wakes up the network in $O((k/b)\\log n\\log(b\\log n))$\ntime. This algorithm misses time optimality by at most a factor of $\\log n\\log\nb$. We give a randomized algorithm that wakes up the network within\n$O(k^{1/b}\\ln (1/\\epsilon))$ rounds with the probability of at least\n$1-\\epsilon$, for any unknown $0<\\epsilon<1$. We also consider a model of\njamming, in which each channel in any round may be jammed to prevent a\nsuccessful transmission, which happens with some known parameter probability\n$p$, independently across all channels and rounds. For this model, we give a\ndeterministic algorithm that wakes up the network in $O(\\log^{-1}(1/p) k\\log\nn\\log^{1/b} k)$ time with the probability of at least $1-1/{poly}(n)$.\n", "contributors": [{"name": "Chlebus, Bogdan S.", "sameAs": [], "familyName": "Chlebus", "additionalName": "S.", "givenName": "Bogdan", "email": ""}, {"name": "De Marco, Gianluca", "sameAs": [], "familyName": "De Marco", "additionalName": "", "givenName": "Gianluca", "email": ""}, {"name": "Kowalski, Dariusz R.", "sameAs": [], "familyName": "Kowalski", "additionalName": "R.", "givenName": "Dariusz", "email": ""}], "title": "Scalable Wake-up of Multi-Channel Single-Hop Radio Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4498", "oai:arXiv.org:1411.4498"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We consider waking up a single-hop radio network with multiple channels.\nThere are $n$ stations connected to $b$ channels without collision detection.\nSome $k$ stations may become active spontaneously at arbitrary times, where $k$\nis unknown, and the goal is for all the stations to hear a successful\ntransmission as soon as possible after the first spontaneous activation. We\npresent a deterministic algorithm for the general problem that wakes up the\nnetwork in $O(k\\log^{1/b} k\\log n)$ time. We prove a lower bound that any\ndeterministic algorithm requires $\\Omega((k/b)\\log (n/k))$ time. We give a\ndeterministic algorithm for the special case when $b>d \\log \\log n$, for some\nconstant $d>1$, which wakes up the network in $O((k/b)\\log n\\log(b\\log n))$\ntime. This algorithm misses time optimality by at most a factor of $\\log n\\log\nb$. We give a randomized algorithm that wakes up the network within\n$O(k^{1/b}\\ln (1/\\epsilon))$ rounds with the probability of at least\n$1-\\epsilon$, for any unknown $0<\\epsilon<1$. We also consider a model of\njamming, in which each channel in any round may be jammed to prevent a\nsuccessful transmission, which happens with some known parameter probability\n$p$, independently across all channels and rounds. For this model, we give a\ndeterministic algorithm that wakes up the network in $O(\\log^{-1}(1/p) k\\log\nn\\log^{1/b} k)$ time with the probability of at least $1-1/{poly}(n)$.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4498"}}, {"publisher": {"name": ""}, "description": "  Armed groups of civilians known as \"self-defense forces\" have ousted the\npowerful Knights Templar drug cartel from several towns in Michoacan. This\nmilitia uprising has unfolded on social media, particularly in the \"VXM\"\n(\"Valor por Michoacan,\" Spanish for \"Courage for Michoacan\") Facebook page,\ngathering more than 170,000 fans. Previous work on the Drug War has documented\nthe use of social media for real-time reports of violent clashes. However, VXM\ngoes one step further by taking on a pro-militia propagandist role, engaging in\ntwo-way communication with its audience. This paper presents a descriptive\nanalysis of VXM and its audience. We examined nine months of posts, from VXM's\ninception until May 2014, totaling 6,000 posts by VXM administrators and more\nthan 108,000 comments from its audience. We describe the main conversation\nthemes, post frequency and relationships with offline events and public\nfigures. We also characterize the behavior of VXM's most active audience\nmembers. Our work illustrates VXM's online mobilization strategies, and how its\naudience takes part in defining the narrative of this armed conflict. We\nconclude by discussing possible applications of our findings for the design of\nfuture communication technologies.\n", "contributors": [{"name": "Savage, Saiph", "sameAs": [], "familyName": "Savage", "additionalName": "", "givenName": "Saiph", "email": ""}, {"name": "Monroy-Hern\u00e1ndez, Andr\u00e9s", "sameAs": [], "familyName": "Monroy-Hern\u00e1ndez", "additionalName": "", "givenName": "Andr\u00e9s", "email": ""}], "title": "Participatory Militias: An Analysis of an Armed Movement's Online\n  Audience", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02065", "doi:10.1145/2675133.2675295", "oai:arXiv.org:1502.02065"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Armed groups of civilians known as \"self-defense forces\" have ousted the\npowerful Knights Templar drug cartel from several towns in Michoacan. This\nmilitia uprising has unfolded on social media, particularly in the \"VXM\"\n(\"Valor por Michoacan,\" Spanish for \"Courage for Michoacan\") Facebook page,\ngathering more than 170,000 fans. Previous work on the Drug War has documented\nthe use of social media for real-time reports of violent clashes. However, VXM\ngoes one step further by taking on a pro-militia propagandist role, engaging in\ntwo-way communication with its audience. This paper presents a descriptive\nanalysis of VXM and its audience. We examined nine months of posts, from VXM's\ninception until May 2014, totaling 6,000 posts by VXM administrators and more\nthan 108,000 comments from its audience. We describe the main conversation\nthemes, post frequency and relationships with offline events and public\nfigures. We also characterize the behavior of VXM's most active audience\nmembers. Our work illustrates VXM's online mobilization strategies, and how its\naudience takes part in defining the narrative of this armed conflict. We\nconclude by discussing possible applications of our findings for the design of\nfuture communication technologies.\n", "Comment: Participatory Militias: An Analysis of an Armed Movement's Online\n  Audience. Saiph Savage, Andres Monroy-Hernandez. CSCW: ACM Conference on\n  Computer-Supported Cooperative Work 2015"]}}], "languages": [null], "subjects": ["h.5.3", "computer science - computers and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02065"}}, {"publisher": {"name": ""}, "description": "  In this text we develop the formalism of products and powers of linear codes\nunder componentwise multiplication. As an expanded version of the author's talk\nat AGCT-14, focus is put mostly on basic properties and descriptive statements\nthat could otherwise probably not fit in a regular research paper. On the other\nhand, more advanced results and applications are only quickly mentioned with\nreferences to the literature. We also point out a few open problems.\n  Our presentation alternates between two points of view, which the theory\nintertwines in an essential way: that of combinatorial coding, and that of\nalgebraic geometry.\n  In appendices that can be read independently, we investigate topics in\nmultilinear algebra over finite fields, notably we establish a criterion for a\nsymmetric multilinear map to admit a symmetric algorithm, or equivalently, for\na symmetric tensor to decompose as a sum of elementary symmetric tensors.\n", "contributors": [{"name": "Randriambololona, Hugues", "sameAs": [], "familyName": "Randriambololona", "additionalName": "", "givenName": "Hugues", "email": ""}], "title": "On products and powers of linear codes under componentwise\n  multiplication", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-11-29", "2014-10-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.0022", "oai:arXiv.org:1312.0022"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this text we develop the formalism of products and powers of linear codes\nunder componentwise multiplication. As an expanded version of the author's talk\nat AGCT-14, focus is put mostly on basic properties and descriptive statements\nthat could otherwise probably not fit in a regular research paper. On the other\nhand, more advanced results and applications are only quickly mentioned with\nreferences to the literature. We also point out a few open problems.\n  Our presentation alternates between two points of view, which the theory\nintertwines in an essential way: that of combinatorial coding, and that of\nalgebraic geometry.\n  In appendices that can be read independently, we investigate topics in\nmultilinear algebra over finite fields, notably we establish a criterion for a\nsymmetric multilinear map to admit a symmetric algorithm, or equivalently, for\na symmetric tensor to decompose as a sum of elementary symmetric tensors.\n", "Comment: 75 pages; expanded version of a talk at AGCT-14 (Luminy), to appear\n  in vol. 637 of Contemporary Math., AMS, Apr. 2015; v3: minor typos corrected\n  in the final \"open questions\" section"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "computer science - information theory"], "providerUpdatedDateTime": "2014-10-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.0022"}}, {"publisher": {"name": ""}, "description": "  A Hermitian metric $\\omega$ on a complex manifold is called SKT or\npluriclosed if $dd^c\\omega=0$. Let M be a twistor space of a compact,\nanti-selfdual Riemannian manifold, admitting a pluriclosed Hermitian metric. We\nprove that in this case M is K\\\"ahler, hence isomorphic to $\\C P^3$ or a flag\nspace. This result is obtained from rational connectedness of the twistor\nspace, due to F. Campana. As an aside, we prove that the moduli space of\nrational curves on the twistor space of a K3 surface is Stein.\n", "contributors": [{"name": "Verbitsky, Misha", "sameAs": [], "familyName": "Verbitsky", "additionalName": "", "givenName": "Misha", "email": ""}], "title": "Rational curves and special metrics on twistor spaces", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-10-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1210.6725", "Geom. Topol. 18 (2014) 897-909", "doi:10.2140/gt.2014.18.897", "oai:arXiv.org:1210.6725"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  A Hermitian metric $\\omega$ on a complex manifold is called SKT or\npluriclosed if $dd^c\\omega=0$. Let M be a twistor space of a compact,\nanti-selfdual Riemannian manifold, admitting a pluriclosed Hermitian metric. We\nprove that in this case M is K\\\"ahler, hence isomorphic to $\\C P^3$ or a flag\nspace. This result is obtained from rational connectedness of the twistor\nspace, due to F. Campana. As an aside, we prove that the moduli space of\nrational curves on the twistor space of a K3 surface is Stein.\n", "Comment: 12 pages"]}}], "languages": [null], "subjects": ["mathematics - differential geometry", "mathematics - complex variables", "mathematics - algebraic geometry"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1210.6725"}}, {"publisher": {"name": ""}, "description": "  We prove a continuity result for the fibers of the Berkovich analytification\nof a complex algebraic variety with respect to the the maximum of the\nArchimedean norm and the trivial norm. As a consequence, we obtain\ngeneralizations of a result of Mikhalkin and Rullgard about degenerations of\namoebae onto tropical varieties.\n", "contributors": [{"name": "Jonsson, Mattias", "sameAs": [], "familyName": "Jonsson", "additionalName": "", "givenName": "Mattias", "email": ""}], "title": "Degenerations of amoebae and Berkovich spaces", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-05", "2015-04-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.1430", "oai:arXiv.org:1406.1430"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We prove a continuity result for the fibers of the Berkovich analytification\nof a complex algebraic variety with respect to the the maximum of the\nArchimedean norm and the trivial norm. As a consequence, we obtain\ngeneralizations of a result of Mikhalkin and Rullgard about degenerations of\namoebae onto tropical varieties.\n", "Comment: To appear in Math. Ann"]}}], "languages": [null], "subjects": ["mathematics - complex variables", "primary: 14t05", "32p05", "mathematics - algebraic geometry", "secondary: 32a60", "14m25"], "providerUpdatedDateTime": "2015-04-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.1430"}}, {"publisher": {"name": ""}, "description": "  The nature of Systems of Systems (SoSs), large complex systems composed of\nindependent, geographically distributed and continuously evolving constituent\nsystems, means that faults are unavoidable. Previous work on defining\ncontractual specifications of the constituent systems of SoSs does not provide\nany explicit consideration for faults. In this paper we address that gap by\nextending an existing pattern for modelling contracts with fault modelling\nconcepts. The proposed extensions are introduced with respect to an Audio\nVisual SoS case study from Bang and Olufsen, before discussing how they relate\nto previous work on modelling faults in SoSs.\n", "contributors": [{"name": "Andrews, Zoe", "sameAs": [], "familyName": "Andrews", "additionalName": "", "givenName": "Zoe", "email": ""}, {"name": "Bryans, Jeremy", "sameAs": [], "familyName": "Bryans", "additionalName": "", "givenName": "Jeremy", "email": ""}, {"name": "Payne, Richard", "sameAs": [], "familyName": "Payne", "additionalName": "", "givenName": "Richard", "email": ""}, {"name": "Kristensen, Klaus", "sameAs": [], "familyName": "Kristensen", "additionalName": "", "givenName": "Klaus", "email": ""}], "title": "Fault Modelling in System-of-Systems Contracts", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-30", "2014-10-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.7775", "oai:arXiv.org:1404.7775"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The nature of Systems of Systems (SoSs), large complex systems composed of\nindependent, geographically distributed and continuously evolving constituent\nsystems, means that faults are unavoidable. Previous work on defining\ncontractual specifications of the constituent systems of SoSs does not provide\nany explicit consideration for faults. In this paper we address that gap by\nextending an existing pattern for modelling contracts with fault modelling\nconcepts. The proposed extensions are introduced with respect to an Audio\nVisual SoS case study from Bang and Olufsen, before discussing how they relate\nto previous work on modelling faults in SoSs.\n", "Comment: EDCC-2014, EDSoS-2014, systems of systems, modelling, architectural\n  frameworks, contracts, faults"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2014-10-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.7775"}}, {"publisher": {"name": ""}, "description": "  The goal of this work is to provide a fiber integration formula on the\nDemailly tower, that avoids step-by-step elimination of horizontal cohomology\nclasses, and that yields computational effectivity. A natural twist of the\nDemailly tower is introduced and a recursive formula for the total Segre class\nat k-th level is obtained. Then, by interpreting single Segre classes as\ncoefficients, an iterated residue formula is derived.\n", "contributors": [{"name": "Darondeau, Lionel", "sameAs": [], "familyName": "Darondeau", "additionalName": "", "givenName": "Lionel", "email": ""}], "title": "Fiber integration on the Demailly tower", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-11-30", "2015-03-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.0109", "oai:arXiv.org:1312.0109"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The goal of this work is to provide a fiber integration formula on the\nDemailly tower, that avoids step-by-step elimination of horizontal cohomology\nclasses, and that yields computational effectivity. A natural twist of the\nDemailly tower is introduced and a recursive formula for the total Segre class\nat k-th level is obtained. Then, by interpreting single Segre classes as\ncoefficients, an iterated residue formula is derived.\n", "Comment: 22 pages, to appear in Annales de l'Institut Fourier"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "14c17", "32q45", "14q20", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.0109"}}, {"publisher": {"name": ""}, "description": "  Statistical methods have been widely employed in many practical natural\nlanguage processing applications. More specifically, complex networks concepts\nand methods from dynamical systems theory have been successfully applied to\nrecognize stylistic patterns in written texts. Despite the large amount of\nstudies devoted to represent texts with physical models, only a few studies\nhave assessed the relevance of attributes derived from the analysis of\nstylistic fluctuations. Because fluctuations represent a pivotal factor for\ncharacterizing a myriad of real systems, this study focused on the analysis of\nthe properties of stylistic fluctuations in texts via topological analysis of\ncomplex networks and intermittency measurements. The results showed that\ndifferent authors display distinct fluctuation patterns. In particular, it was\nfound that it is possible to identify the authorship of books using the\nintermittency of specific words. Taken together, the results described here\nsuggest that the patterns found in stylistic fluctuations could be used to\nanalyze other related complex systems. Furthermore, the discovery of novel\npatterns related to textual stylistic fluctuations indicates that these\npatterns could be useful to improve the state of the art of many\nstylistic-based natural language processing tasks.\n", "contributors": [{"name": "Amancio, Diego R.", "sameAs": [], "familyName": "Amancio", "additionalName": "R.", "givenName": "Diego", "email": ""}], "title": "Authorship recognition via fluctuation analysis of network topology and\n  word intermittency", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01245", "oai:arXiv.org:1502.01245"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Statistical methods have been widely employed in many practical natural\nlanguage processing applications. More specifically, complex networks concepts\nand methods from dynamical systems theory have been successfully applied to\nrecognize stylistic patterns in written texts. Despite the large amount of\nstudies devoted to represent texts with physical models, only a few studies\nhave assessed the relevance of attributes derived from the analysis of\nstylistic fluctuations. Because fluctuations represent a pivotal factor for\ncharacterizing a myriad of real systems, this study focused on the analysis of\nthe properties of stylistic fluctuations in texts via topological analysis of\ncomplex networks and intermittency measurements. The results showed that\ndifferent authors display distinct fluctuation patterns. In particular, it was\nfound that it is possible to identify the authorship of books using the\nintermittency of specific words. Taken together, the results described here\nsuggest that the patterns found in stylistic fluctuations could be used to\nanalyze other related complex systems. Furthermore, the discovery of novel\npatterns related to textual stylistic fluctuations indicates that these\npatterns could be useful to improve the state of the art of many\nstylistic-based natural language processing tasks.\n"}}], "languages": [null], "subjects": ["computer science - computation and language"], "providerUpdatedDateTime": "2015-02-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01245"}}, {"publisher": {"name": ""}, "description": "  We consider supervised learning with random decision trees, where the tree\nconstruction is completely random. The method is popularly used and works well\nin practice despite the simplicity of the setting, but its statistical\nmechanism is not yet well-understood. In this paper we provide strong\ntheoretical guarantees regarding learning with random decision trees. We\nanalyze and compare three different variants of the algorithm that have minimal\nmemory requirements: majority voting, threshold averaging and probabilistic\naveraging. The random structure of the tree enables us to adapt these methods\nto a differentially-private setting thus we also propose differentially-private\nversions of all three schemes. We give upper-bounds on the generalization error\nand mathematically explain how the accuracy depends on the number of random\ndecision trees. Furthermore, we prove that only logarithmic (in the size of the\ndataset) number of independently selected random decision trees suffice to\ncorrectly classify most of the data, even when differential-privacy guarantees\nmust be maintained. We empirically show that majority voting and threshold\naveraging give the best accuracy, also for conservative users requiring high\nprivacy guarantees. Furthermore, we demonstrate that a simple majority voting\nrule is an especially good candidate for the differentially-private classifier\nsince it is much less sensitive to the choice of forest parameters than other\nmethods.\n", "contributors": [{"name": "Bojarski, Mariusz", "sameAs": [], "familyName": "Bojarski", "additionalName": "", "givenName": "Mariusz", "email": ""}, {"name": "Choromanska, Anna", "sameAs": [], "familyName": "Choromanska", "additionalName": "", "givenName": "Anna", "email": ""}, {"name": "Choromanski, Krzysztof", "sameAs": [], "familyName": "Choromanski", "additionalName": "", "givenName": "Krzysztof", "email": ""}, {"name": "LeCun, Yann", "sameAs": [], "familyName": "LeCun", "additionalName": "", "givenName": "Yann", "email": ""}], "title": "Differentially- and non-differentially-private random decision trees", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-25", "2015-02-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6973", "oai:arXiv.org:1410.6973"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We consider supervised learning with random decision trees, where the tree\nconstruction is completely random. The method is popularly used and works well\nin practice despite the simplicity of the setting, but its statistical\nmechanism is not yet well-understood. In this paper we provide strong\ntheoretical guarantees regarding learning with random decision trees. We\nanalyze and compare three different variants of the algorithm that have minimal\nmemory requirements: majority voting, threshold averaging and probabilistic\naveraging. The random structure of the tree enables us to adapt these methods\nto a differentially-private setting thus we also propose differentially-private\nversions of all three schemes. We give upper-bounds on the generalization error\nand mathematically explain how the accuracy depends on the number of random\ndecision trees. Furthermore, we prove that only logarithmic (in the size of the\ndataset) number of independently selected random decision trees suffice to\ncorrectly classify most of the data, even when differential-privacy guarantees\nmust be maintained. We empirically show that majority voting and threshold\naveraging give the best accuracy, also for conservative users requiring high\nprivacy guarantees. Furthermore, we demonstrate that a simple majority voting\nrule is an especially good candidate for the differentially-private classifier\nsince it is much less sensitive to the choice of forest parameters than other\nmethods.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6973"}}, {"publisher": {"name": ""}, "description": "  We develop a fast variational approximation scheme for Gaussian process (GP)\nregression, where the spectrum of the covariance function is subjected to a\nsparse approximation. Our approach enables uncertainty in covariance function\nhyperparameters to be treated without using Monte Carlo methods and is robust\nto overfitting. Our article makes three contributions. First, we present a\nvariational Bayes algorithm for fitting sparse spectrum GP regression models\nthat uses nonconjugate variational message passing to derive fast and efficient\nupdates. Second, we propose a novel adaptive neighbourhood technique for\nobtaining predictive inference that is effective in dealing with\nnonstationarity. Regression is performed locally at each point to be predicted\nand the neighbourhood is determined using a measure defined based on\nlengthscales estimated from an initial fit. Weighting dimensions according to\nlengthscales, this downweights variables of little relevance, leading to\nautomatic variable selection and improved prediction. Third, we introduce a\ntechnique for accelerating convergence in nonconjugate variational message\npassing by adapting step sizes in the direction of the natural gradient of the\nlower bound. Our adaptive strategy can be easily implemented and empirical\nresults indicate significant speedups.\n", "contributors": [{"name": "Tan, Linda S. L.", "sameAs": [], "familyName": "Tan", "additionalName": "S. L.", "givenName": "Linda", "email": ""}, {"name": "Ong, Victor M. H.", "sameAs": [], "familyName": "Ong", "additionalName": "M. H.", "givenName": "Victor", "email": ""}, {"name": "Nott, David J.", "sameAs": [], "familyName": "Nott", "additionalName": "J.", "givenName": "David", "email": ""}, {"name": "Jasra, Ajay", "sameAs": [], "familyName": "Jasra", "additionalName": "", "givenName": "Ajay", "email": ""}], "title": "Variational inference for sparse spectrum Gaussian process regression", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-09", "2015-01-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.1999", "oai:arXiv.org:1306.1999"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": ["  We develop a fast variational approximation scheme for Gaussian process (GP)\nregression, where the spectrum of the covariance function is subjected to a\nsparse approximation. Our approach enables uncertainty in covariance function\nhyperparameters to be treated without using Monte Carlo methods and is robust\nto overfitting. Our article makes three contributions. First, we present a\nvariational Bayes algorithm for fitting sparse spectrum GP regression models\nthat uses nonconjugate variational message passing to derive fast and efficient\nupdates. Second, we propose a novel adaptive neighbourhood technique for\nobtaining predictive inference that is effective in dealing with\nnonstationarity. Regression is performed locally at each point to be predicted\nand the neighbourhood is determined using a measure defined based on\nlengthscales estimated from an initial fit. Weighting dimensions according to\nlengthscales, this downweights variables of little relevance, leading to\nautomatic variable selection and improved prediction. Third, we introduce a\ntechnique for accelerating convergence in nonconjugate variational message\npassing by adapting step sizes in the direction of the natural gradient of the\nlower bound. Our adaptive strategy can be easily implemented and empirical\nresults indicate significant speedups.\n", "Comment: 20 pages, 11 figures, 1 table"]}}], "languages": [null], "subjects": ["statistics - computation"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.1999"}}, {"publisher": {"name": ""}, "description": "  We consider banded block Toeplitz matrices $T_n$ with $n$ block rows and\ncolumns. We show that under certain technical assumptions, the normalized\neigenvalue counting measure of $T_n$ for $n\\to\\infty$ weakly converges to one\ncomponent of the unique vector of measures that minimizes a certain energy\nfunctional. In this way we generalize a recent result of Duits and Kuijlaars\nfor the scalar case. Along the way we also obtain an equilibrium problem\nassociated to an arbitrary algebraic curve, not necessarily related to a block\nToeplitz matrix.\n  For banded block Toeplitz matrices, there are several new phenomena that do\nnot occur in the scalar case: (i) The total masses of the equilibrium measures\ndo not necessarily form a simple arithmetic series but in general are obtained\nthrough a combinatorial rule; (ii) The limiting eigenvalue distribution may\ncontain point masses, and there may be attracting point sources in the\nequilibrium problem; (iii) More seriously, there are examples where the\nconnection between the limiting eigenvalue distribution of $T_n$ and the\nsolution to the equilibrium problem breaks down. We provide sufficient\nconditions guaranteeing that no such breakdown occurs; in particular we show\nthis if $T_n$ is a Hessenberg matrix.\n", "contributors": [{"name": "Delvaux, Steven", "sameAs": [], "familyName": "Delvaux", "additionalName": "", "givenName": "Steven", "email": ""}], "title": "Equilibrium problem for the eigenvalues of banded block Toeplitz\n  matrices", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-13", "2012-12-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.2644", "Math. Nachr. 285 (2012), 1935-1962", "oai:arXiv.org:1101.2644"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We consider banded block Toeplitz matrices $T_n$ with $n$ block rows and\ncolumns. We show that under certain technical assumptions, the normalized\neigenvalue counting measure of $T_n$ for $n\\to\\infty$ weakly converges to one\ncomponent of the unique vector of measures that minimizes a certain energy\nfunctional. In this way we generalize a recent result of Duits and Kuijlaars\nfor the scalar case. Along the way we also obtain an equilibrium problem\nassociated to an arbitrary algebraic curve, not necessarily related to a block\nToeplitz matrix.\n  For banded block Toeplitz matrices, there are several new phenomena that do\nnot occur in the scalar case: (i) The total masses of the equilibrium measures\ndo not necessarily form a simple arithmetic series but in general are obtained\nthrough a combinatorial rule; (ii) The limiting eigenvalue distribution may\ncontain point masses, and there may be attracting point sources in the\nequilibrium problem; (iii) More seriously, there are examples where the\nconnection between the limiting eigenvalue distribution of $T_n$ and the\nsolution to the equilibrium problem breaks down. We provide sufficient\nconditions guaranteeing that no such breakdown occurs; in particular we show\nthis if $T_n$ is a Hessenberg matrix.\n", "Comment: 32 pages, 7 figures"]}}], "languages": [null], "subjects": ["mathematics - classical analysis and odes", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.2644"}}, {"publisher": {"name": ""}, "description": "  A Random SubMatrix method (RSM) is proposed to calculate the low-rank\ndecomposition of large-scale matrices with known entry percentage \\rho. RSM is\nvery fast as the floating-point operations (flops) required are compared\nfavorably with the state-of-the-art algorithms. Meanwhile RSM is very\nmemory-saving. With known entries homogeneously distributed in the given\nmatrix, sub-matrices formed by known entries are randomly selected. According\nto the just proved theorem that subspace related to smaller singular values is\nless perturbed by noise, the null vectors or the right singular vectors\nassociated with the minor singular values are calculated for each submatrix.\nThe vectors are the null vectors of the corresponding submatrix in the ground\ntruth of the given large-scale matrix. If enough sub-matrices are randomly\nchosen, the low-rank decomposition is estimated. The experimental results on\nrandom synthetical matrices with sizes such as 131072X1024 and on real data\nsets indicate that RSM is much faster and memory-saving, and, meanwhile, has\nconsiderable high precision achieving or approximating to the best.\n", "contributors": [{"name": "Liu, Yiguang", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Yiguang", "email": ""}], "title": "A random algorithm for low-rank decomposition of large-scale matrices\n  with missing entries", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0814", "oai:arXiv.org:1411.0814"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  A Random SubMatrix method (RSM) is proposed to calculate the low-rank\ndecomposition of large-scale matrices with known entry percentage \\rho. RSM is\nvery fast as the floating-point operations (flops) required are compared\nfavorably with the state-of-the-art algorithms. Meanwhile RSM is very\nmemory-saving. With known entries homogeneously distributed in the given\nmatrix, sub-matrices formed by known entries are randomly selected. According\nto the just proved theorem that subspace related to smaller singular values is\nless perturbed by noise, the null vectors or the right singular vectors\nassociated with the minor singular values are calculated for each submatrix.\nThe vectors are the null vectors of the corresponding submatrix in the ground\ntruth of the given large-scale matrix. If enough sub-matrices are randomly\nchosen, the low-rank decomposition is estimated. The experimental results on\nrandom synthetical matrices with sizes such as 131072X1024 and on real data\nsets indicate that RSM is much faster and memory-saving, and, meanwhile, has\nconsiderable high precision achieving or approximating to the best.\n"}}], "languages": [null], "subjects": ["computer science - numerical analysis", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0814"}}, {"publisher": {"name": ""}, "description": "  We give a $2^{n+o(n)}$-time and space randomized algorithm for solving the\nexact Closest Vector Problem (CVP) on $n$-dimensional Euclidean lattices. This\nimproves on the previous fastest algorithm, the deterministic\n$\\widetilde{O}(4^{n})$-time and $\\widetilde{O}(2^{n})$-space algorithm of\nMicciancio and Voulgaris.\n  We achieve our main result in two steps. First, we show how to modify the\nsampling algorithm from ADRS15 to solve the problem of discrete Gaussian\nsampling over lattice shifts, $L- \\vec{t}$, with very low parameters. While the\nactual algorithm is a natural generalization of ADRS15, the analysis uses\nsubstantial new ideas. This yields a $2^{n+o(n)}$-time algorithm for\napproximate CVP with the very good approximation factor $\\gamma =\n1+2^{-o(n/\\log n)}$. Second, we show that the near-closest vectors to a target\nvector $\\vec{t}$ can be grouped into \"lower-dimensional clusters,\" and we use\nthis to obtain a recursive algorithm based on our sampler that solves exact CVP\nin $2^{n + o(n)}$ time.\n  The analysis of both steps depends crucially on some new properties of the\ndiscrete Gaussian distribution, which might be of independent interest.\n", "contributors": [{"name": "Aggarwal, Divesh", "sameAs": [], "familyName": "Aggarwal", "additionalName": "", "givenName": "Divesh", "email": ""}, {"name": "Dadush, Daniel", "sameAs": [], "familyName": "Dadush", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Stephens-Davidowitz, Noah", "sameAs": [], "familyName": "Stephens-Davidowitz", "additionalName": "", "givenName": "Noah", "email": ""}], "title": "Solving the Closest Vector Problem in $2^n$ Time--- The Discrete\n  Gaussian Strikes Again!", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01995", "oai:arXiv.org:1504.01995"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We give a $2^{n+o(n)}$-time and space randomized algorithm for solving the\nexact Closest Vector Problem (CVP) on $n$-dimensional Euclidean lattices. This\nimproves on the previous fastest algorithm, the deterministic\n$\\widetilde{O}(4^{n})$-time and $\\widetilde{O}(2^{n})$-space algorithm of\nMicciancio and Voulgaris.\n  We achieve our main result in two steps. First, we show how to modify the\nsampling algorithm from ADRS15 to solve the problem of discrete Gaussian\nsampling over lattice shifts, $L- \\vec{t}$, with very low parameters. While the\nactual algorithm is a natural generalization of ADRS15, the analysis uses\nsubstantial new ideas. This yields a $2^{n+o(n)}$-time algorithm for\napproximate CVP with the very good approximation factor $\\gamma =\n1+2^{-o(n/\\log n)}$. Second, we show that the near-closest vectors to a target\nvector $\\vec{t}$ can be grouped into \"lower-dimensional clusters,\" and we use\nthis to obtain a recursive algorithm based on our sampler that solves exact CVP\nin $2^{n + o(n)}$ time.\n  The analysis of both steps depends crucially on some new properties of the\ndiscrete Gaussian distribution, which might be of independent interest.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-04-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01995"}}, {"publisher": {"name": ""}, "description": "abstract: The objective of this research is to understand how a set of systems, as defined by the business process, creates value. The three studies contained in this work develop the model of process-based automation. The model states that complementarities among systems are specified by handoffs in the business process. The model also provides theory to explain why entry systems, boundary spanning systems, and back-end control systems provide different impacts on process quality and cost. The first study includes 135 U. S. acute care hospitals. The study finds that hospitals which followed an organizational pattern of process automation have better financial outcomes. The second study looks in more depth at where synergies might be found. It includes 341 California acute care hospitals over 11 years. It finds that increased costs and increase adverse drug events are associated with increased automation discontinuity. Further, the study shows that automation in the front end of the process has a more desirable outcome on cost than automation in the back end of the process. The third study examines the assumption that the systems are actually used. It is a cross-sectional analysis of over 2000 U. S. hospitals. This study finds that system usage is a critical factor in realizing benefits from automating the business process. The model of process-based automation has implications for information technology decision makers, long-term automation planning, and for information systems research. The analyses have additional implications for the healthcare industry.", "contributors": [{"name": "Spaulding, Trent Joseph (Author)", "sameAs": [], "familyName": "Spaulding", "additionalName": "Joseph", "givenName": "Trent", "email": ""}, {"name": "Santanam, Raghu T (Advisor)", "sameAs": [], "familyName": "Santanam", "additionalName": "T", "givenName": "Raghu", "email": ""}, {"name": "Vinze, Ajay  (Committee member)", "sameAs": [], "familyName": "Vinze", "additionalName": "", "givenName": "Ajay", "email": ""}, {"name": "Furukawa, Michael F (Committee member)", "sameAs": [], "familyName": "Furukawa", "additionalName": "F", "givenName": "Michael", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "A Model of Process-Based Automation: Cost and Quality Implications in the Medication Management Process", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "147 pages"}}, {"name": "date", "properties": {"date": "2011"}}, {"name": "description", "properties": {"description": ["abstract: The objective of this research is to understand how a set of systems, as defined by the business process, creates value. The three studies contained in this work develop the model of process-based automation. The model states that complementarities among systems are specified by handoffs in the business process. The model also provides theory to explain why entry systems, boundary spanning systems, and back-end control systems provide different impacts on process quality and cost. The first study includes 135 U. S. acute care hospitals. The study finds that hospitals which followed an organizational pattern of process automation have better financial outcomes. The second study looks in more depth at where synergies might be found. It includes 341 California acute care hospitals over 11 years. It finds that increased costs and increase adverse drug events are associated with increased automation discontinuity. Further, the study shows that automation in the front end of the process has a more desirable outcome on cost than automation in the back end of the process. The third study examines the assumption that the systems are actually used. It is a cross-sectional analysis of over 2000 U. S. hospitals. This study finds that system usage is a critical factor in realizing benefits from automating the business process. The model of process-based automation has implications for information technology decision makers, long-term automation planning, and for information systems research. The analyses have additional implications for the healthcare industry.", "Dissertation/Thesis", "Ph.D. Information Management 2011"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.8931", "item:8931"]}}], "languages": [null], "subjects": ["information systems", "computerized physician order entry", "health care management", "business process", "medication management", "healthcare", "information technology"], "providerUpdatedDateTime": "2015-02-12T01:08:30", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.8931"}}, {"publisher": {"name": ""}, "description": "  The apsis toolkit presented in this paper provides a flexible framework for\nhyperparameter optimization and includes both random search and a bayesian\noptimizer. It is implemented in Python and its architecture features\nadaptability to any desired machine learning code. It can easily be used with\ncommon Python ML frameworks such as scikit-learn. Published under the MIT\nLicense other researchers are heavily encouraged to check out the code,\ncontribute or raise any suggestions. The code can be found at\ngithub.com/FrederikDiehl/apsis.\n", "contributors": [{"name": "Diehl, Frederik", "sameAs": [], "familyName": "Diehl", "additionalName": "", "givenName": "Frederik", "email": ""}, {"name": "Jauch, Andreas", "sameAs": [], "familyName": "Jauch", "additionalName": "", "givenName": "Andreas", "email": ""}], "title": "apsis - Framework for Automated Optimization of Machine Learning Hyper\n  Parameters", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-10", "2015-03-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02946", "oai:arXiv.org:1503.02946"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The apsis toolkit presented in this paper provides a flexible framework for\nhyperparameter optimization and includes both random search and a bayesian\noptimizer. It is implemented in Python and its architecture features\nadaptability to any desired machine learning code. It can easily be used with\ncommon Python ML frameworks such as scikit-learn. Published under the MIT\nLicense other researchers are heavily encouraged to check out the code,\ncontribute or raise any suggestions. The code can be found at\ngithub.com/FrederikDiehl/apsis.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02946"}}, {"publisher": {"name": ""}, "description": "  How do we know that a kitchen is a kitchen by looking? Relatively little is\nknown about how we conceptualize and categorize different visual environments.\nTraditional models of visual perception posit that scene categorization is\nachieved through the recognition of a scene's objects, yet these models cannot\naccount for the mounting evidence that human observers are relatively\ninsensitive to the local details in an image. Psychologists have long theorized\nthat the affordances, or actionable possibilities of a stimulus are pivotal to\nits perception. To what extent are scene categories created from similar\naffordances? Using a large-scale experiment using hundreds of scene categories,\nwe show that the activities afforded by a visual scene provide a fundamental\ncategorization principle. Affordance-based similarity explained the majority of\nthe structure in the human scene categorization patterns, outperforming\nalternative similarities based on objects or visual features. We all models\nwere combined, affordances provided the majority of the predictive power in the\ncombined model, and nearly half of the total explained variance is captured\nonly by affordances. These results challenge many existing models of high-level\nvisual perception, and provide immediately testable hypotheses for the\nfunctional organization of the human perceptual system.\n", "contributors": [{"name": "Greene, Michelle R.", "sameAs": [], "familyName": "Greene", "additionalName": "R.", "givenName": "Michelle", "email": ""}, {"name": "Baldassano, Christopher", "sameAs": [], "familyName": "Baldassano", "additionalName": "", "givenName": "Christopher", "email": ""}, {"name": "Esteva, Andre", "sameAs": [], "familyName": "Esteva", "additionalName": "", "givenName": "Andre", "email": ""}, {"name": "Beck, Diane M.", "sameAs": [], "familyName": "Beck", "additionalName": "M.", "givenName": "Diane", "email": ""}, {"name": "Fei-Fei, Li", "sameAs": [], "familyName": "Fei-Fei", "additionalName": "", "givenName": "Li", "email": ""}], "title": "Affordances Provide a Fundamental Categorization Principle for Visual\n  Scenes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5340", "oai:arXiv.org:1411.5340"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": "  How do we know that a kitchen is a kitchen by looking? Relatively little is\nknown about how we conceptualize and categorize different visual environments.\nTraditional models of visual perception posit that scene categorization is\nachieved through the recognition of a scene's objects, yet these models cannot\naccount for the mounting evidence that human observers are relatively\ninsensitive to the local details in an image. Psychologists have long theorized\nthat the affordances, or actionable possibilities of a stimulus are pivotal to\nits perception. To what extent are scene categories created from similar\naffordances? Using a large-scale experiment using hundreds of scene categories,\nwe show that the activities afforded by a visual scene provide a fundamental\ncategorization principle. Affordance-based similarity explained the majority of\nthe structure in the human scene categorization patterns, outperforming\nalternative similarities based on objects or visual features. We all models\nwere combined, affordances provided the majority of the predictive power in the\ncombined model, and nearly half of the total explained variance is captured\nonly by affordances. These results challenge many existing models of high-level\nvisual perception, and provide immediately testable hypotheses for the\nfunctional organization of the human perceptual system.\n"}}], "languages": [null], "subjects": ["quantitative biology - neurons and cognition", "computer science - human-computer interaction", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5340"}}, {"publisher": {"name": ""}, "description": "  Much research in the last two decades has focused on Virtual Topology\nReconfiguration (VTR) problem. However, most of the proposed methods either has\nlow controllability, or the analysis of a control parameter is limited to\nempirical analysis. In this paper, we present a highly tunable Virtual Topology\n(VT) controller. First, we analyze the controllability of two previously\nproposed VTR algorithms: a heuristic method and a neural networks based method.\nThen we present insights on how to transform these VTR methods to their tunable\nversions. To benefit from the controllability, an optimality analysis of the\ncontrol parameter is needed. In the second part of the paper, through a\nprobabilistic analysis we find an optimal parameter for the neural network\nbased method. We validated our analysis through simulations. We propose this\nhighly tunable method as a new VTR algorithm.\n", "contributors": [{"name": "Hanay, Y. Sinan", "sameAs": [], "familyName": "Hanay", "additionalName": "Sinan", "givenName": "Y.", "email": ""}, {"name": "Arakawa, Shinichi", "sameAs": [], "familyName": "Arakawa", "additionalName": "", "givenName": "Shinichi", "email": ""}, {"name": "Murata, Masayuki", "sameAs": [], "familyName": "Murata", "additionalName": "", "givenName": "Masayuki", "email": ""}], "title": "A Highly Tunable Virtual Topology Controller", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05710", "oai:arXiv.org:1501.05710"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Much research in the last two decades has focused on Virtual Topology\nReconfiguration (VTR) problem. However, most of the proposed methods either has\nlow controllability, or the analysis of a control parameter is limited to\nempirical analysis. In this paper, we present a highly tunable Virtual Topology\n(VT) controller. First, we analyze the controllability of two previously\nproposed VTR algorithms: a heuristic method and a neural networks based method.\nThen we present insights on how to transform these VTR methods to their tunable\nversions. To benefit from the controllability, an optimality analysis of the\ncontrol parameter is needed. In the second part of the paper, through a\nprobabilistic analysis we find an optimal parameter for the neural network\nbased method. We validated our analysis through simulations. We propose this\nhighly tunable method as a new VTR algorithm.\n", "Comment: 7 pages, 5 figures"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05710"}}, {"publisher": {"name": ""}, "description": "  Diabetes is considered a lifestyle disease and a well managed self-care plays\nan important role in the treatment. Clinicians often conduct surveys to\nunderstand the self-care behaviors in their patients. In this context, we\npropose to use Self-Organising Maps (SOM) to explore the survey data for\nassessing the self-care behaviors in Type-1 diabetic patients. Specifically,\nSOM is used to visualize high dimensional similar patient profiles, which is\nrarely discussed. Experiments demonstrate that our findings through SOM\nanalysis corresponds well to the expectations of the clinicians. In addition,\nour findings inspire the experts to improve their understanding of the\nself-care behaviors for their patients. The principle findings in our study\nshow: 1) patients who take correct dose of insulin, inject insulin at the right\ntime, 2) patients who take correct food portions undertake regular physical\nactivity and 3) patients who eat on time take correct food portions.\n", "contributors": [{"name": "Tirunagari, Santosh", "sameAs": [], "familyName": "Tirunagari", "additionalName": "", "givenName": "Santosh", "email": ""}, {"name": "Poh, Norman", "sameAs": [], "familyName": "Poh", "additionalName": "", "givenName": "Norman", "email": ""}, {"name": "Hu, Guosheng", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Guosheng", "email": ""}, {"name": "Windridge, David", "sameAs": [], "familyName": "Windridge", "additionalName": "", "givenName": "David", "email": ""}], "title": "Identifying Similar Patients Using Self-Organising Maps: A Case Study on\n  Type-1 Diabetes Self-care Survey Responses", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06316", "oai:arXiv.org:1503.06316"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Diabetes is considered a lifestyle disease and a well managed self-care plays\nan important role in the treatment. Clinicians often conduct surveys to\nunderstand the self-care behaviors in their patients. In this context, we\npropose to use Self-Organising Maps (SOM) to explore the survey data for\nassessing the self-care behaviors in Type-1 diabetic patients. Specifically,\nSOM is used to visualize high dimensional similar patient profiles, which is\nrarely discussed. Experiments demonstrate that our findings through SOM\nanalysis corresponds well to the expectations of the clinicians. In addition,\nour findings inspire the experts to improve their understanding of the\nself-care behaviors for their patients. The principle findings in our study\nshow: 1) patients who take correct dose of insulin, inject insulin at the right\ntime, 2) patients who take correct food portions undertake regular physical\nactivity and 3) patients who eat on time take correct food portions.\n", "Comment: 01-05 pages"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - computational engineering", "finance", "and science"], "providerUpdatedDateTime": "2015-03-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06316"}}, {"publisher": {"name": ""}, "description": "  We propose a sampling scheme that can perfectly reconstruct a collection of\nspikes on the sphere from samples of their lowpass-filtered observations.\nCentral to our algorithm is a generalization of the annihilating filter method,\na tool widely used in array signal processing and finite-rate-of-innovation\n(FRI) sampling. The proposed algorithm can reconstruct $K$ spikes from\n$(K+\\sqrt{K})^2$ spatial samples. This sampling requirement improves over\npreviously known FRI sampling schemes on the sphere by a factor of four for\nlarge $K$.\n  We showcase the versatility of the proposed algorithm by applying it to three\ndifferent problems: 1) sampling diffusion processes induced by localized\nsources on the sphere, 2) shot noise removal, and 3) sound source localization\n(SSL) by a spherical microphone array. In particular, we show how SSL can be\nreformulated as a spherical sparse sampling problem.\n", "contributors": [{"name": "Dokmanic, Ivan", "sameAs": [], "familyName": "Dokmanic", "additionalName": "", "givenName": "Ivan", "email": ""}, {"name": "Lu, Yue M.", "sameAs": [], "familyName": "Lu", "additionalName": "M.", "givenName": "Yue", "email": ""}], "title": "Sampling Sparse Signals on the Sphere: Algorithms and Applications", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07577", "oai:arXiv.org:1502.07577"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We propose a sampling scheme that can perfectly reconstruct a collection of\nspikes on the sphere from samples of their lowpass-filtered observations.\nCentral to our algorithm is a generalization of the annihilating filter method,\na tool widely used in array signal processing and finite-rate-of-innovation\n(FRI) sampling. The proposed algorithm can reconstruct $K$ spikes from\n$(K+\\sqrt{K})^2$ spatial samples. This sampling requirement improves over\npreviously known FRI sampling schemes on the sphere by a factor of four for\nlarge $K$.\n  We showcase the versatility of the proposed algorithm by applying it to three\ndifferent problems: 1) sampling diffusion processes induced by localized\nsources on the sphere, 2) shot noise removal, and 3) sound source localization\n(SSL) by a spherical microphone array. In particular, we show how SSL can be\nreformulated as a spherical sparse sampling problem.\n", "Comment: 14 pages, 8 figures, submitted to IEEE Transactions on Signal\n  Processing"]}}], "languages": [null], "subjects": ["computer science - information theory", "computer science - sound"], "providerUpdatedDateTime": "2015-02-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07577"}}, {"publisher": {"name": ""}, "description": "  We study here the relative cohomology and the Gauss-Manin connections\nassociated to an isolated singularity of a function on a manifold with\nboundary, i.e. with a fixed hyperplane section. We prove several relative\nanalogs of classical theorems obtained mainly by E. Brieskorn and B. Malgrange,\nconcerning the properties of the Gauss-Manin connection as well as its\nrelations with the Picard-Lefschetz monodromy and the asymptotics of integrals\nof holomorphic forms along the vanishing cycles. Finally, we give an\napplication in isochore deformation theory, i.e. the deformation theory of\nboundary singularities with respect to a volume form. In particular we prove\nthe relative analog of J. Vey's isochore Morse lemma, J. -P. Fran\\c{c}oise's\ngeneralisation on the local normal forms of volume forms with respect to the\nboundary singularity-preserving diffeomorphisms, as well as M. D. Garay's\ntheorem on the isochore version of Mather's versal unfolding theorem.\n", "contributors": [{"name": "Kourliouros, Konstantinos", "sameAs": [], "familyName": "Kourliouros", "additionalName": "", "givenName": "Konstantinos", "email": ""}], "title": "Gauss-Manin Connections for Boundary Singularities and Isochore\n  Deformations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08021", "oai:arXiv.org:1503.08021"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  We study here the relative cohomology and the Gauss-Manin connections\nassociated to an isolated singularity of a function on a manifold with\nboundary, i.e. with a fixed hyperplane section. We prove several relative\nanalogs of classical theorems obtained mainly by E. Brieskorn and B. Malgrange,\nconcerning the properties of the Gauss-Manin connection as well as its\nrelations with the Picard-Lefschetz monodromy and the asymptotics of integrals\nof holomorphic forms along the vanishing cycles. Finally, we give an\napplication in isochore deformation theory, i.e. the deformation theory of\nboundary singularities with respect to a volume form. In particular we prove\nthe relative analog of J. Vey's isochore Morse lemma, J. -P. Fran\\c{c}oise's\ngeneralisation on the local normal forms of volume forms with respect to the\nboundary singularity-preserving diffeomorphisms, as well as M. D. Garay's\ntheorem on the isochore version of Mather's versal unfolding theorem.\n"}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08021"}}, {"publisher": {"name": ""}, "description": "  Sampling-based algorithms are viewed as practical solutions for\nhigh-dimensional motion planning. Recent progress has taken advantage of random\ngeometric graph theory to show how asymptotic optimality can also be achieved\nwith these methods. Achieving this desirable property for systems with dynamics\nrequires solving a two-point boundary value problem (BVP) in the state space of\nthe underlying dynamical system. It is difficult, however, if not impractical,\nto generate a BVP solver for a variety of important dynamical models of robots\nor physically simulated ones. Thus, an open challenge was whether it was even\npossible to achieve optimality guarantees when planning for systems without\naccess to a BVP solver. This work resolves the above question and describes how\nto achieve asymptotic optimality for kinodynamic planning using incremental\nsampling-based planners by introducing a new rigorous framework. Two new\nmethods, Stable Sparse-RRT (SST) and SST*, result from this analysis, which are\nasymptotically near-optimal and optimal, respectively. The techniques are shown\nto converge fast to high-quality paths, while they maintain only a sparse set\nof samples, which makes them computationally efficient. The good performance of\nthe planners is confirmed by experimental results using dynamical systems\nbenchmarks, as well as physically simulated robots.\n", "contributors": [{"name": "Li, Yanbo", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Yanbo", "email": ""}, {"name": "Littlefield, Zakary", "sameAs": [], "familyName": "Littlefield", "additionalName": "", "givenName": "Zakary", "email": ""}, {"name": "Bekris, Kostas E.", "sameAs": [], "familyName": "Bekris", "additionalName": "E.", "givenName": "Kostas", "email": ""}], "title": "Asymptotically Optimal Sampling-based Kinodynamic Planning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-10", "2014-11-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.2896", "oai:arXiv.org:1407.2896"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Sampling-based algorithms are viewed as practical solutions for\nhigh-dimensional motion planning. Recent progress has taken advantage of random\ngeometric graph theory to show how asymptotic optimality can also be achieved\nwith these methods. Achieving this desirable property for systems with dynamics\nrequires solving a two-point boundary value problem (BVP) in the state space of\nthe underlying dynamical system. It is difficult, however, if not impractical,\nto generate a BVP solver for a variety of important dynamical models of robots\nor physically simulated ones. Thus, an open challenge was whether it was even\npossible to achieve optimality guarantees when planning for systems without\naccess to a BVP solver. This work resolves the above question and describes how\nto achieve asymptotic optimality for kinodynamic planning using incremental\nsampling-based planners by introducing a new rigorous framework. Two new\nmethods, Stable Sparse-RRT (SST) and SST*, result from this analysis, which are\nasymptotically near-optimal and optimal, respectively. The techniques are shown\nto converge fast to high-quality paths, while they maintain only a sparse set\nof samples, which makes them computationally efficient. The good performance of\nthe planners is confirmed by experimental results using dynamical systems\nbenchmarks, as well as physically simulated robots.\n"}}], "languages": [null], "subjects": ["computer science - robotics"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.2896"}}, {"publisher": {"name": ""}, "description": "  Biobjective mixed integer linear programs (BOMILP) are optimization problems\nwhere two linear objectives are optimized over a polyhedron while restricting\nsome of the variables to be integer. Since many of the techniques for solving\nBOMILP (or approximating its solution set) are iterative processes which\nutilize data discovered during early iterations to aid in the discovery of\nimproved data during later iterations, it is highly desirable to efficiently\nstore the nondominated subset of a given set of data. This problem has not\nreceived considerable attention in the context of BOMILP; only naive methods\nhave been implemented. We seek to bridge this gap by presenting a new data\nstructure in the form of a modified binary tree that stores, updates, searches\nand returns nondominated solutions. This structure takes points and line\nsegments in $\\mathbb{R}^2$ as input and stores the nondominated subset of this\ninput. We note that when used alongside an exact solution procedure, such as\nbranch-and-bound (BB), at termination the data stored by this structure is\nprecisely the set of Pareto optimal solutions. We perform two experiments. The\nfirst is designed to compare the utility of our structure for storing\nnondominated data to that of a dynamic list which updates via pairwise\ncomparison. In the second we use our data structure alongside the biobjective\nBB techniques available in the literature and solve specific instances of\nBOMILP. The results of our first experiment suggest that the data structure\nperforms reasonably well in handling input of up to $10^7$ points or segments\nand does so much more efficiently than a dynamic list. The results of the\nsecond experiment show that when our structure is utilized alongside BB\nfathoming is enhanced and running times improve slightly.\n", "contributors": [{"name": "Adelgren, Nathan", "sameAs": [], "familyName": "Adelgren", "additionalName": "", "givenName": "Nathan", "email": ""}, {"name": "Belotti, Pietro", "sameAs": [], "familyName": "Belotti", "additionalName": "", "givenName": "Pietro", "email": ""}, {"name": "Gupte, Akshay", "sameAs": [], "familyName": "Gupte", "additionalName": "", "givenName": "Akshay", "email": ""}], "title": "Efficient storage of Pareto points in biobjective mixed integer\n  programming", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.6538", "oai:arXiv.org:1411.6538"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Biobjective mixed integer linear programs (BOMILP) are optimization problems\nwhere two linear objectives are optimized over a polyhedron while restricting\nsome of the variables to be integer. Since many of the techniques for solving\nBOMILP (or approximating its solution set) are iterative processes which\nutilize data discovered during early iterations to aid in the discovery of\nimproved data during later iterations, it is highly desirable to efficiently\nstore the nondominated subset of a given set of data. This problem has not\nreceived considerable attention in the context of BOMILP; only naive methods\nhave been implemented. We seek to bridge this gap by presenting a new data\nstructure in the form of a modified binary tree that stores, updates, searches\nand returns nondominated solutions. This structure takes points and line\nsegments in $\\mathbb{R}^2$ as input and stores the nondominated subset of this\ninput. We note that when used alongside an exact solution procedure, such as\nbranch-and-bound (BB), at termination the data stored by this structure is\nprecisely the set of Pareto optimal solutions. We perform two experiments. The\nfirst is designed to compare the utility of our structure for storing\nnondominated data to that of a dynamic list which updates via pairwise\ncomparison. In the second we use our data structure alongside the biobjective\nBB techniques available in the literature and solve specific instances of\nBOMILP. The results of our first experiment suggest that the data structure\nperforms reasonably well in handling input of up to $10^7$ points or segments\nand does so much more efficiently than a dynamic list. The results of the\nsecond experiment show that when our structure is utilized alongside BB\nfathoming is enhanced and running times improve slightly.\n", "Comment: Shorter version accepted to Proceedings of the INFORMS Computing\n  Society Meeting 2015"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - optimization and control", "e.1.7", "90c29", "90c11"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.6538"}}, {"publisher": {"name": ""}, "description": "  In this work a rationalized algorithm for Dirac numbers multiplication is\npresented. This algorithm has a low computational complexity feature and is\nwell suited to FPGA implementation. The computation of two Dirac numbers\nproduct using the na\\\"ive method takes 256 real multiplications and 240 real\nadditions, while the proposed algorithm can compute the same result in only 88\nreal multiplications and 256 real additions. During synthesis of the discussed\nalgorithm we use the fact that Dirac numbers product may be represented as\nvector-matrix product. The matrix participating in the product has unique\nstructural properties that allow performing its advantageous decomposition.\nNamely this decomposition leads to significant reducing of the computational\ncomplexity.\n", "contributors": [{"name": "Cariow, Aleksandr", "sameAs": [], "familyName": "Cariow", "additionalName": "", "givenName": "Aleksandr", "email": ""}, {"name": "Cariowa, Galina", "sameAs": [], "familyName": "Cariowa", "additionalName": "", "givenName": "Galina", "email": ""}], "title": "A new algorithm for multiplying two Dirac numbers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00828", "oai:arXiv.org:1501.00828"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this work a rationalized algorithm for Dirac numbers multiplication is\npresented. This algorithm has a low computational complexity feature and is\nwell suited to FPGA implementation. The computation of two Dirac numbers\nproduct using the na\\\"ive method takes 256 real multiplications and 240 real\nadditions, while the proposed algorithm can compute the same result in only 88\nreal multiplications and 256 real additions. During synthesis of the discussed\nalgorithm we use the fact that Dirac numbers product may be represented as\nvector-matrix product. The matrix participating in the product has unique\nstructural properties that allow performing its advantageous decomposition.\nNamely this decomposition leads to significant reducing of the computational\ncomplexity.\n", "Comment: 14 pages, 1 figure"]}}], "languages": [null], "subjects": ["65y20", "11r52", "68w35", "computer science - numerical analysis", "computer science - data structures and algorithms", "65f30", "15b33"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00828"}}, {"publisher": {"name": ""}, "description": "  We establish the satisfiability threshold for random k-SAT for all k >= k_0.\nThat is, there exists a limiting density alpha_s(k) such that a random k-SAT\nformula of clause density alpha is with high probability satisfiable for alpha\n< alpha_s(k), and unsatisfiable for alpha > alpha_s(k). The satisfiability\nthreshold alpha_s(k) is given explicitly by the one-step replica symmetry\nbreaking prediction from statistical physics. We believe that our methods may\napply to a range of random CSPs in the 1RSB universality class.\n", "contributors": [{"name": "Ding, Jian", "sameAs": [], "familyName": "Ding", "additionalName": "", "givenName": "Jian", "email": ""}, {"name": "Sly, Allan", "sameAs": [], "familyName": "Sly", "additionalName": "", "givenName": "Allan", "email": ""}, {"name": "Sun, Nike", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Nike", "email": ""}], "title": "Proof of the satisfiability conjecture for large k", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0650", "oai:arXiv.org:1411.0650"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:math-ph"]}}, {"name": "description", "properties": {"description": "  We establish the satisfiability threshold for random k-SAT for all k >= k_0.\nThat is, there exists a limiting density alpha_s(k) such that a random k-SAT\nformula of clause density alpha is with high probability satisfiable for alpha\n< alpha_s(k), and unsatisfiable for alpha > alpha_s(k). The satisfiability\nthreshold alpha_s(k) is given explicitly by the one-step replica symmetry\nbreaking prediction from statistical physics. We believe that our methods may\napply to a range of random CSPs in the 1RSB universality class.\n"}}], "languages": [null], "subjects": ["mathematical physics", "computer science - discrete mathematics", "mathematics - probability"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0650"}}, {"publisher": {"name": ""}, "description": "  This paper introduces a model of environmental acoustic scenes which adopts a\nmorphological approach by ab-stracting temporal structures of acoustic scenes.\nTo demonstrate its potential, this model is employed to evaluate the\nperformance of a large set of acoustic events detection systems. This model\nallows us to explicitly control key morphological aspects of the acoustic scene\nand isolate their impact on the performance of the system under evaluation.\nThus, more information can be gained on the behavior of evaluated systems,\nproviding guidance for further improvements. The proposed model is validated\nusing submitted systems from the IEEE DCASE Challenge; results indicate that\nthe proposed scheme is able to successfully build datasets useful for\nevaluating some aspects the performance of event detection systems, more\nparticularly their robustness to new listening conditions and the increasing\nlevel of background sounds.\n", "contributors": [{"name": "Lagrange, Mathieu", "sameAs": [], "familyName": "Lagrange", "additionalName": "", "givenName": "Mathieu", "email": ""}, {"name": "Lafay, Gr\u00e9goire", "sameAs": [], "familyName": "Lafay", "additionalName": "", "givenName": "Gr\u00e9goire", "email": ""}, {"name": "Rossignol, Mathias", "sameAs": [], "familyName": "Rossignol", "additionalName": "", "givenName": "Mathias", "email": ""}, {"name": "Benetos, Emmanouil", "sameAs": [], "familyName": "Benetos", "additionalName": "", "givenName": "Emmanouil", "email": ""}, {"name": "Roebel, Axel", "sameAs": [], "familyName": "Roebel", "additionalName": "", "givenName": "Axel", "email": ""}], "title": "An evaluation framework for event detection using a morphological model\n  of acoustic scenes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.00141", "oai:arXiv.org:1502.00141"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  This paper introduces a model of environmental acoustic scenes which adopts a\nmorphological approach by ab-stracting temporal structures of acoustic scenes.\nTo demonstrate its potential, this model is employed to evaluate the\nperformance of a large set of acoustic events detection systems. This model\nallows us to explicitly control key morphological aspects of the acoustic scene\nand isolate their impact on the performance of the system under evaluation.\nThus, more information can be gained on the behavior of evaluated systems,\nproviding guidance for further improvements. The proposed model is validated\nusing submitted systems from the IEEE DCASE Challenge; results indicate that\nthe proposed scheme is able to successfully build datasets useful for\nevaluating some aspects the performance of event detection systems, more\nparticularly their robustness to new listening conditions and the increasing\nlevel of background sounds.\n"}}], "languages": [null], "subjects": ["computer science - sound", "statistics - machine learning"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.00141"}}, {"publisher": {"name": ""}, "description": "  It is shown that polar codes achieve the symmetric capacity of discrete\nmemoryless channels with arbitrary input alphabet sizes. It is shown that in\ngeneral, channel polarization happens in several, rather than only two levels\nso that the synthesized channels are either useless, perfect or \"partially\nperfect\". Any subset of the channel input alphabet which is closed under\naddition, induces a coset partition of the alphabet through its shifts. For any\nsuch partition of the input alphabet, there exists a corresponding partially\nperfect channel whose outputs uniquely determine the coset to which the channel\ninput belongs. By a slight modification of the encoding and decoding rules, it\nis shown that perfect transmission of certain information symbols over\npartially perfect channels is possible. Our result is general regarding both\nthe cardinality and the algebraic structure of the channel input alphabet; i.e\nwe show that for any channel input alphabet size and any Abelian group\nstructure on the alphabet, polar codes are optimal. It is also shown through an\nexample that polar codes when considered as group/coset codes, do not achieve\nthe capacity achievable using coset codes over arbitrary channels.\n", "contributors": [{"name": "Sahebi, Aria G.", "sameAs": [], "familyName": "Sahebi", "additionalName": "G.", "givenName": "Aria", "email": ""}, {"name": "Pradhan, S. Sandeep", "sameAs": [], "familyName": "Pradhan", "additionalName": "Sandeep", "givenName": "S.", "email": ""}], "title": "Multilevel Polarization of Polar Codes Over Arbitrary Discrete\n  Memoryless Channels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-07-07", "2012-06-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1107.1535", "oai:arXiv.org:1107.1535"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  It is shown that polar codes achieve the symmetric capacity of discrete\nmemoryless channels with arbitrary input alphabet sizes. It is shown that in\ngeneral, channel polarization happens in several, rather than only two levels\nso that the synthesized channels are either useless, perfect or \"partially\nperfect\". Any subset of the channel input alphabet which is closed under\naddition, induces a coset partition of the alphabet through its shifts. For any\nsuch partition of the input alphabet, there exists a corresponding partially\nperfect channel whose outputs uniquely determine the coset to which the channel\ninput belongs. By a slight modification of the encoding and decoding rules, it\nis shown that perfect transmission of certain information symbols over\npartially perfect channels is possible. Our result is general regarding both\nthe cardinality and the algebraic structure of the channel input alphabet; i.e\nwe show that for any channel input alphabet size and any Abelian group\nstructure on the alphabet, polar codes are optimal. It is also shown through an\nexample that polar codes when considered as group/coset codes, do not achieve\nthe capacity achievable using coset codes over arbitrary channels.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1107.1535"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "While the spectral graph partitioning method gives high quality segmentation, segmenting large graphs by the spectral method is computationally expensive. Numerous multilevel graph partitioning algorithms are proposed to reduce the segmentation time for the spectral partition of large graphs. However, the greedy local refinement used in these multilevel schemes has the tendency of trapping the partition in poor local minima. In this thesis, I develop a multilevel graph partitioning algorithm that incorporates the inverse powering method with greedy local refinement. The combination of the inverse powering method with greedy local refinement ensures that the partition quality of the multilevel method is as good as, if not better than, segmenting the large graph by the spectral method. In addition, I present a scheme to construct the adjacency matrix, W and degree matrix, D for the coarse graphs. The proposed multilevel graph partitioning algorithm is able to bisect a graph (k = 2) with significantly shorter time than segmenting the original graph without the multilevel implementation, and at the same time achieving the same normalized cut (Ncut) value. The starting eigenvector, obtained by solving a generalized eigenvalue problem on the coarsest graph, is close to the Fiedler vector of the original graph. Hence, the inverse iteration needs only a few iterations to converge the starting vector. In the k-way multilevel graph partition, the larger the graph, the greater the reduction in the time needed for segmenting the graph. For the multilevel image segmentation, the multilevel scheme is able to give better segmentation than segmenting the original image. The multilevel scheme has higher success of preserving the salient part of an object.", "contributors": [{"name": "Kong, Tian Fook", "sameAs": [], "familyName": "Kong", "additionalName": "Fook", "givenName": "Tian", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "Gilbert Strang.", "sameAs": [], "familyName": "Strang.", "additionalName": "", "givenName": "Gilbert", "email": ""}], "title": "Multilevel spectral clustering : graph partitions and image segmentation", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "146 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/45275", "310969204", "oai:dspace.mit.edu:1721.1/45275"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2009-04-29T17:19:04Z", "2009-04-29T17:19:04Z", "2008", "2008"]}}, {"name": "description", "properties": {"description": ["While the spectral graph partitioning method gives high quality segmentation, segmenting large graphs by the spectral method is computationally expensive. Numerous multilevel graph partitioning algorithms are proposed to reduce the segmentation time for the spectral partition of large graphs. However, the greedy local refinement used in these multilevel schemes has the tendency of trapping the partition in poor local minima. In this thesis, I develop a multilevel graph partitioning algorithm that incorporates the inverse powering method with greedy local refinement. The combination of the inverse powering method with greedy local refinement ensures that the partition quality of the multilevel method is as good as, if not better than, segmenting the large graph by the spectral method. In addition, I present a scheme to construct the adjacency matrix, W and degree matrix, D for the coarse graphs. The proposed multilevel graph partitioning algorithm is able to bisect a graph (k = 2) with significantly shorter time than segmenting the original graph without the multilevel implementation, and at the same time achieving the same normalized cut (Ncut) value. The starting eigenvector, obtained by solving a generalized eigenvalue problem on the coarsest graph, is close to the Fiedler vector of the original graph. Hence, the inverse iteration needs only a few iterations to converge the starting vector. In the k-way multilevel graph partition, the larger the graph, the greater the reduction in the time needed for segmenting the graph. For the multilevel image segmentation, the multilevel scheme is able to give better segmentation than segmenting the original image. The multilevel scheme has higher success of preserving the salient part of an object.", "(cont.) In this work, I also show that the Ncut value is not the ultimate yardstick for the segmentation quality of an image. Finding a partition that has lower Ncut value does not necessary means better segmentation quality. Segmenting large images by the multilevel method offers both speed and quality.", "by Tian Fook Kong.", "Thesis (S.M.)--Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2008.", "Includes bibliographical references (p. 145-146)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39115", "hdl_1721.1_39117"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:17", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/45275"}}, {"publisher": {"name": ""}, "description": "  In this paper we describe a new tool, SReach, which solves probabilistic\nbounded reachability problems for two classes of stochastic hybrid systems. The\nfirst one is (nonlinear) hybrid automata with parametric uncertainty. The\nsecond one is probabilistic hybrid automata with additional randomness for both\ntransition probabilities and variable resets. Standard approaches to\nreachability problems for linear hybrid systems require numerical solutions for\nlarge optimization problems, and become infeasible for systems involving both\nnonlinear dynamics over the reals and stochasticity. Our approach encodes\nstochastic information by using random variables, and combines the randomized\nsampling, a $\\delta$-complete decision procedure, and statistical tests. SReach\nutilizes the $\\delta$-complete decision procedure to solve reachability\nproblems in a sound manner, i.e., it always decides correctly if, for a given\nassignment to all random variables, the system actually reaches the unsafe\nregion. The statistical tests adapted guarantee arbitrary small error bounds\nbetween probabilities estimated by SReach and real ones. Compared to standard\nsimulation-based methods, our approach supports non-deterministic branching,\nincreases the coverage of simulation, and avoids the zero-crossing problem. We\ndemonstrate our method's feasibility by applying SReach to three representative\nbiological models and to additional benchmarks for nonlinear hybrid systems\nwith multiple probabilistic system parameters.\n", "contributors": [{"name": "Wang, Qinsi", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Qinsi", "email": ""}, {"name": "Zuliani, Paolo", "sameAs": [], "familyName": "Zuliani", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Kong, Soonho", "sameAs": [], "familyName": "Kong", "additionalName": "", "givenName": "Soonho", "email": ""}, {"name": "Gao, Sicun", "sameAs": [], "familyName": "Gao", "additionalName": "", "givenName": "Sicun", "email": ""}, {"name": "Clarke, Edmund M.", "sameAs": [], "familyName": "Clarke", "additionalName": "M.", "givenName": "Edmund", "email": ""}], "title": "SReach: A Bounded Model Checker for Stochastic Hybrid Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-28", "2014-10-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.7206", "oai:arXiv.org:1404.7206"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper we describe a new tool, SReach, which solves probabilistic\nbounded reachability problems for two classes of stochastic hybrid systems. The\nfirst one is (nonlinear) hybrid automata with parametric uncertainty. The\nsecond one is probabilistic hybrid automata with additional randomness for both\ntransition probabilities and variable resets. Standard approaches to\nreachability problems for linear hybrid systems require numerical solutions for\nlarge optimization problems, and become infeasible for systems involving both\nnonlinear dynamics over the reals and stochasticity. Our approach encodes\nstochastic information by using random variables, and combines the randomized\nsampling, a $\\delta$-complete decision procedure, and statistical tests. SReach\nutilizes the $\\delta$-complete decision procedure to solve reachability\nproblems in a sound manner, i.e., it always decides correctly if, for a given\nassignment to all random variables, the system actually reaches the unsafe\nregion. The statistical tests adapted guarantee arbitrary small error bounds\nbetween probabilities estimated by SReach and real ones. Compared to standard\nsimulation-based methods, our approach supports non-deterministic branching,\nincreases the coverage of simulation, and avoids the zero-crossing problem. We\ndemonstrate our method's feasibility by applying SReach to three representative\nbiological models and to additional benchmarks for nonlinear hybrid systems\nwith multiple probabilistic system parameters.\n"}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.7206"}}, {"publisher": {"name": ""}, "description": "  A number of ill-posed inverse problems in signal processing, like blind\ndeconvolution, matrix factorization, dictionary learning and blind source\nseparation share the common characteristic of being bilinear inverse problems\n(BIPs), i.e. the observation model is a function of two variables and\nconditioned on one variable being known, the observation is a linear function\nof the other variable. A key issue that arises for such inverse problems is\nthat of identifiability, i.e. whether the observation is sufficient to\nunambiguously determine the pair of inputs that generated the observation.\nIdentifiability is a key concern for applications like blind equalization in\nwireless communications and data mining in machine learning. Herein, a unifying\nand flexible approach to identifiability analysis for general conic prior\nconstrained BIPs is presented, exploiting a connection to low-rank matrix\nrecovery via lifting. We develop deterministic identifiability conditions on\nthe input signals and examine their satisfiability in practice for three\nclasses of signal distributions, viz. dependent but uncorrelated, independent\nGaussian, and independent Bernoulli. In each case, scaling laws are developed\nthat trade-off probability of robust identifiability with the complexity of the\nrank two null space. An added appeal of our approach is that the rank two null\nspace can be partly or fully characterized for many bilinear problems of\ninterest (e.g. blind deconvolution). We present numerical experiments involving\nvariations on the blind deconvolution problem that exploit a characterization\nof the rank two null space and demonstrate that the scaling laws offer good\nestimates of identifiability.\n", "contributors": [{"name": "Choudhary, Sunav", "sameAs": [], "familyName": "Choudhary", "additionalName": "", "givenName": "Sunav", "email": ""}, {"name": "Mitra, Urbashi", "sameAs": [], "familyName": "Mitra", "additionalName": "", "givenName": "Urbashi", "email": ""}], "title": "Identifiability Scaling Laws in Bilinear Inverse Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-11", "2014-11-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.2637", "oai:arXiv.org:1402.2637"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A number of ill-posed inverse problems in signal processing, like blind\ndeconvolution, matrix factorization, dictionary learning and blind source\nseparation share the common characteristic of being bilinear inverse problems\n(BIPs), i.e. the observation model is a function of two variables and\nconditioned on one variable being known, the observation is a linear function\nof the other variable. A key issue that arises for such inverse problems is\nthat of identifiability, i.e. whether the observation is sufficient to\nunambiguously determine the pair of inputs that generated the observation.\nIdentifiability is a key concern for applications like blind equalization in\nwireless communications and data mining in machine learning. Herein, a unifying\nand flexible approach to identifiability analysis for general conic prior\nconstrained BIPs is presented, exploiting a connection to low-rank matrix\nrecovery via lifting. We develop deterministic identifiability conditions on\nthe input signals and examine their satisfiability in practice for three\nclasses of signal distributions, viz. dependent but uncorrelated, independent\nGaussian, and independent Bernoulli. In each case, scaling laws are developed\nthat trade-off probability of robust identifiability with the complexity of the\nrank two null space. An added appeal of our approach is that the rank two null\nspace can be partly or fully characterized for many bilinear problems of\ninterest (e.g. blind deconvolution). We present numerical experiments involving\nvariations on the blind deconvolution problem that exploit a characterization\nof the rank two null space and demonstrate that the scaling laws offer good\nestimates of identifiability.\n", "Comment: 25 pages, 5 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.2637"}}, {"publisher": {"name": ""}, "description": "  We propose a method for estimating channel parameters from RSSI measurements\nand the lost packet count, which can work in the presence of losses due to both\ninterference and signal attenuation below the noise floor. This is especially\nimportant in the wireless networks, such as vehicular, where propagation model\nchanges with the density of nodes. The method is based on Stochastic\nExpectation Maximization, where the received data is modeled as a mixture of\ndistributions (no/low interference and strong interference), incomplete\n(censored) due to packet losses. The PDFs in the mixture are Gamma, according\nto the commonly accepted model for wireless signal and interference power. This\napproach leverages the loss count as additional information, hence\noutperforming maximum likelihood estimation, which does not use this\ninformation (ML-), for a small number of received RSSI samples. Hence, it\nallows inexpensive on-line channel estimation from ad-hoc collected data. The\nmethod also outperforms ML- on uncensored data mixtures, as ML- assumes that\nsamples are from a single-mode PDF.\n", "contributors": [{"name": "Kokalj-Filipovic, Silvija", "sameAs": [], "familyName": "Kokalj-Filipovic", "additionalName": "", "givenName": "Silvija", "email": ""}, {"name": "Greenstein, Larry", "sameAs": [], "familyName": "Greenstein", "additionalName": "", "givenName": "Larry", "email": ""}], "title": "EM-Based Channel Estimation from Crowd-Sourced RSSI Samples Corrupted by\n  Noise and Interference", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01072", "oai:arXiv.org:1504.01072"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We propose a method for estimating channel parameters from RSSI measurements\nand the lost packet count, which can work in the presence of losses due to both\ninterference and signal attenuation below the noise floor. This is especially\nimportant in the wireless networks, such as vehicular, where propagation model\nchanges with the density of nodes. The method is based on Stochastic\nExpectation Maximization, where the received data is modeled as a mixture of\ndistributions (no/low interference and strong interference), incomplete\n(censored) due to packet losses. The PDFs in the mixture are Gamma, according\nto the commonly accepted model for wireless signal and interference power. This\napproach leverages the loss count as additional information, hence\noutperforming maximum likelihood estimation, which does not use this\ninformation (ML-), for a small number of received RSSI samples. Hence, it\nallows inexpensive on-line channel estimation from ad-hoc collected data. The\nmethod also outperforms ML- on uncensored data mixtures, as ML- assumes that\nsamples are from a single-mode PDF.\n", "Comment: CISS 2015"]}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01072"}}, {"publisher": {"name": ""}, "description": "  The strong solutions of Nine Men's Morris and its variant, Lasker Morris are\nwell-known results (the starting positions are draws). We re-examined both of\nthese games, and calculated extended strong solutions for them. By this we mean\nthe game-theoretic values of all possible game states that could be reached\nfrom certain starting positions where the number of stones to be placed by the\nplayers is different from the standard rules. These were also calculated for a\npreviously unsolved third variant, Morabaraba, with interesting results: most\nof the starting positions where the players can place an equal number of stones\n(including the standard starting position) are wins for the first player (as\nopposed to the above games, where these are usually draws).\n  We also developed a multi-valued retrograde analysis, and used it as a basis\nfor an algorithm for solving these games ultra-strongly. This means that when\nour program is playing against a fallible opponent, it has a greater chance of\nachieving a better result than the game-theoretic value, compared to randomly\nselecting between \"just strongly\" optimal moves. Previous attempts on\nultra-strong solutions used local heuristics or learning during games, but we\nincorporated our algorithm into the retrograde analysis.\n", "contributors": [{"name": "G\u00e9vay, G\u00e1bor E.", "sameAs": [], "familyName": "G\u00e9vay", "additionalName": "E.", "givenName": "G\u00e1bor", "email": ""}, {"name": "Danner, G\u00e1bor", "sameAs": [], "familyName": "Danner", "additionalName": "", "givenName": "G\u00e1bor", "email": ""}], "title": "Calculating Ultra-Strong and Extended Solutions for Nine Men's Morris,\n  Morabaraba, and Lasker", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-31", "2015-03-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.0032", "oai:arXiv.org:1408.0032"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The strong solutions of Nine Men's Morris and its variant, Lasker Morris are\nwell-known results (the starting positions are draws). We re-examined both of\nthese games, and calculated extended strong solutions for them. By this we mean\nthe game-theoretic values of all possible game states that could be reached\nfrom certain starting positions where the number of stones to be placed by the\nplayers is different from the standard rules. These were also calculated for a\npreviously unsolved third variant, Morabaraba, with interesting results: most\nof the starting positions where the players can place an equal number of stones\n(including the standard starting position) are wins for the first player (as\nopposed to the above games, where these are usually draws).\n  We also developed a multi-valued retrograde analysis, and used it as a basis\nfor an algorithm for solving these games ultra-strongly. This means that when\nour program is playing against a fallible opponent, it has a greater chance of\nachieving a better result than the game-theoretic value, compared to randomly\nselecting between \"just strongly\" optimal moves. Previous attempts on\nultra-strong solutions used local heuristics or learning during games, but we\nincorporated our algorithm into the retrograde analysis.\n", "Comment: (c) 2015 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other users, including\n  reprinting/republishing this material for advertising or promotional\n  purposes, creating new collective works for resale or redistribution to\n  servers or lists, or reuse of any copyrighted components of this work in\n  other works"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "i.2.8"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.0032"}}, {"publisher": {"name": ""}, "description": "  In the restructured electricity industry, electricity pooling markets are an\noligopoly with strategic producers possessing private information (private\nproduction cost function). We focus on pooling markets where aggregate demand\nis represented by a non-strategic agent.\n  Inelasticity of demand is a main difficulty in electricity markets which can\npotentially result in market failure and high prices. We consider demand to be\ninelastic.\n  We propose a market mechanism that has the following features. (F1) It is\nindividually rational. (F2) It is budget balanced. (F3) It is price efficient,\nthat is, at equilibrium the price of electricity is equal to the marginal cost\nof production. (F4) The energy production profile corresponding to every\nnon-zero Nash equilibrium of the game induced by the mechanism is a solution of\nthe corresponding centralized problem where the objective is the maximization\nof the sum of the producers' and consumers' utilities.\n  We identify some open problems associated with our approach to electricity\npooling markets.\n", "contributors": [{"name": "Rasouli, Mohammad", "sameAs": [], "familyName": "Rasouli", "additionalName": "", "givenName": "Mohammad", "email": ""}, {"name": "Teneketzis, Demosthenis", "sameAs": [], "familyName": "Teneketzis", "additionalName": "", "givenName": "Demosthenis", "email": ""}], "title": "Electricity Pooling Markets with Strategic Producers Possessing\n  Asymmetric Information II: Inelastic Demand", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-21", "2014-10-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.5539", "oai:arXiv.org:1404.5539"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In the restructured electricity industry, electricity pooling markets are an\noligopoly with strategic producers possessing private information (private\nproduction cost function). We focus on pooling markets where aggregate demand\nis represented by a non-strategic agent.\n  Inelasticity of demand is a main difficulty in electricity markets which can\npotentially result in market failure and high prices. We consider demand to be\ninelastic.\n  We propose a market mechanism that has the following features. (F1) It is\nindividually rational. (F2) It is budget balanced. (F3) It is price efficient,\nthat is, at equilibrium the price of electricity is equal to the marginal cost\nof production. (F4) The energy production profile corresponding to every\nnon-zero Nash equilibrium of the game induced by the mechanism is a solution of\nthe corresponding centralized problem where the objective is the maximization\nof the sum of the producers' and consumers' utilities.\n  We identify some open problems associated with our approach to electricity\npooling markets.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.5539"}}, {"publisher": {"name": ""}, "description": "  It is an unfortunate convention of science that research should pretend to be\nreproducible; our top tips will help you mitigate this fussy conventionality,\nenabling you to enthusiastically showcase your irreproducible work.\n", "contributors": [{"name": "Hong, Neil P. Chue", "sameAs": [], "familyName": "Hong", "additionalName": "P. Chue", "givenName": "Neil", "email": ""}, {"name": "Crick, Tom", "sameAs": [], "familyName": "Crick", "additionalName": "", "givenName": "Tom", "email": ""}, {"name": "Gent, Ian P.", "sameAs": [], "familyName": "Gent", "additionalName": "P.", "givenName": "Ian", "email": ""}, {"name": "Kotthoff, Lars", "sameAs": [], "familyName": "Kotthoff", "additionalName": "", "givenName": "Lars", "email": ""}], "title": "Top Tips to Make Your Research Irreproducible", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.00062", "oai:arXiv.org:1504.00062"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  It is an unfortunate convention of science that research should pretend to be\nreproducible; our top tips will help you mitigate this fussy conventionality,\nenabling you to enthusiastically showcase your irreproducible work.\n", "Comment: 2 pages, LaTeX"]}}], "languages": [null], "subjects": ["computer science - computational engineering", "finance", "and science", "computer science - computers and society"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.00062"}}, {"publisher": {"name": ""}, "description": "  In the context of distributed estimation, we consider the problem of sensor\ncollaboration, which refers to the act of sharing measurements with neighboring\nsensors prior to transmission to a fusion center. While incorporating the cost\nof sensor collaboration, we aim to find optimal sparse collaboration schemes\nsubject to a certain information or energy constraint. Two types of sensor\ncollaboration problems are studied: minimum energy with an information\nconstraint; and maximum information with an energy constraint. To solve the\nresulting sensor collaboration problems, we present tractable optimization\nformulations and propose efficient methods which render near-optimal solutions\nin numerical experiments. We also explore the situation in which there is a\ncost associated with the involvement of each sensor in the estimation scheme.\nIn such situations, the participating sensors must be chosen judiciously. We\nintroduce a unified framework to jointly design the optimal sensor selection\nand collaboration schemes. For a given estimation performance, we show\nempirically that there exists a trade-off between sensor selection and sensor\ncollaboration.\n", "contributors": [{"name": "Liu, Sijia", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Sijia", "email": ""}, {"name": "Kar, Swarnendu", "sameAs": [], "familyName": "Kar", "additionalName": "", "givenName": "Swarnendu", "email": ""}, {"name": "Fardad, Makan", "sameAs": [], "familyName": "Fardad", "additionalName": "", "givenName": "Makan", "email": ""}, {"name": "Varshney, Pramod K.", "sameAs": [], "familyName": "Varshney", "additionalName": "K.", "givenName": "Pramod", "email": ""}], "title": "Sparsity-Aware Sensor Collaboration for Linear Coherent Estimation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-27", "2015-02-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6566", "oai:arXiv.org:1408.6566"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  In the context of distributed estimation, we consider the problem of sensor\ncollaboration, which refers to the act of sharing measurements with neighboring\nsensors prior to transmission to a fusion center. While incorporating the cost\nof sensor collaboration, we aim to find optimal sparse collaboration schemes\nsubject to a certain information or energy constraint. Two types of sensor\ncollaboration problems are studied: minimum energy with an information\nconstraint; and maximum information with an energy constraint. To solve the\nresulting sensor collaboration problems, we present tractable optimization\nformulations and propose efficient methods which render near-optimal solutions\nin numerical experiments. We also explore the situation in which there is a\ncost associated with the involvement of each sensor in the estimation scheme.\nIn such situations, the participating sensors must be chosen judiciously. We\nintroduce a unified framework to jointly design the optimal sensor selection\nand collaboration schemes. For a given estimation performance, we show\nempirically that there exists a trade-off between sensor selection and sensor\ncollaboration.\n", "Comment: IEEE Transactions on Signal Processing"]}}], "languages": [null], "subjects": ["computer science - information theory", "statistics - methodology"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6566"}}, {"publisher": {"name": ""}, "description": "  We present a study on connection errors in networks of linear features and\nmethods of error detection. We model networks with special connection\nspecifications as networks with hierarchically connected features and define\nerrors considering the spatial relationships and the functionality of the\nnetwork elements. A general definition of the problem of the detection of\nconnection errors which takes into account the functionality of the network\nelements is discussed. Then a series of spatial algorithms that solve different\naspects of the problem is presented. We also define and analyze the notion of\ngeometrical reduction as a method of achieving efficient performance. In the\nlast section the undecidability of algorithmic error correction is discussed.\n", "contributors": [{"name": "Rodis, Panteleimon", "sameAs": [], "familyName": "Rodis", "additionalName": "", "givenName": "Panteleimon", "email": ""}], "title": "Connection errors in networks of linear features and the application of\n  geometrical reduction in spatial data algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-27", "2015-04-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.5410", "oai:arXiv.org:1101.5410"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We present a study on connection errors in networks of linear features and\nmethods of error detection. We model networks with special connection\nspecifications as networks with hierarchically connected features and define\nerrors considering the spatial relationships and the functionality of the\nnetwork elements. A general definition of the problem of the detection of\nconnection errors which takes into account the functionality of the network\nelements is discussed. Then a series of spatial algorithms that solve different\naspects of the problem is presented. We also define and analyze the notion of\ngeometrical reduction as a method of achieving efficient performance. In the\nlast section the undecidability of algorithmic error correction is discussed.\n", "Comment: 14 pages, 4 spatial algorithms, 3 illustrations"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.5410"}}, {"publisher": {"name": "John Wiley & Sons Ltd"}, "description": "", "contributors": [{"name": "Rosa-Bray, M", "sameAs": [], "familyName": "Rosa-Bray", "additionalName": "", "givenName": "M", "email": ""}, {"name": "Wisdom, C", "sameAs": [], "familyName": "Wisdom", "additionalName": "", "givenName": "C", "email": ""}, {"name": "Marier, J F", "sameAs": [], "familyName": "Marier", "additionalName": "F", "givenName": "J", "email": ""}, {"name": "Mouksassi, M-S", "sameAs": [], "familyName": "Mouksassi", "additionalName": "", "givenName": "M-S", "email": ""}, {"name": "Wada, S", "sameAs": [], "familyName": "Wada", "additionalName": "", "givenName": "S", "email": ""}], "title": "The effect of plasmapheresis on blood pressure in voluntary plasma donors", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["blood component collection and production"], "providerUpdatedDateTime": "2015-01-30T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4302974"}}, {"publisher": {"name": ""}, "description": "  We propose, analyze and demonstrate an architecture for scalable cooperative\nreception. In a cluster of N + 1 receive nodes, one node is designated as the\nfinal receiver, and the N other nodes act as amplify-and-forward relays which\nadapt their phases such that the relayed signals add up constructively at the\ndesignated receiver. This yields received SNR scaling linearly with N, while\navoiding the linear increase in overhead incurred by a direct approach in which\nreceived signals are separately quantized and transmitted for centralized\nprocessing. By transforming the task of long-distance distributed receive\nbeamforming into one of local distributed transmit beamforming, we can leverage\na scalable one-bit feedback algorithm for phase synchronization. We show that\ntime division between the long-distance and local links eliminates the need for\nexplicit frequency synchronization. We provide an analytical framework, whose\nresults closely match Monte Carlo simulations, to evaluate the impact of phase\nnoise due to relaying delay on the performance of the one-bit feedback\nalgorithm. Experimental results from our prototype implementation on\nsoftware-defined radios demonstrate the expected gains in received signal\nstrength despite significant oscillator drift, and are consistent with results\nfrom our analytical framework.\n", "contributors": [{"name": "Quitin, Francois", "sameAs": [], "familyName": "Quitin", "additionalName": "", "givenName": "Francois", "email": ""}, {"name": "Irish, Andrew T.", "sameAs": [], "familyName": "Irish", "additionalName": "T.", "givenName": "Andrew", "email": ""}, {"name": "Madhow, Upamanyu", "sameAs": [], "familyName": "Madhow", "additionalName": "", "givenName": "Upamanyu", "email": ""}], "title": "A scalable architecture for distributed receive beamforming: analysis\n  and experimental demonstration", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05695", "oai:arXiv.org:1501.05695"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We propose, analyze and demonstrate an architecture for scalable cooperative\nreception. In a cluster of N + 1 receive nodes, one node is designated as the\nfinal receiver, and the N other nodes act as amplify-and-forward relays which\nadapt their phases such that the relayed signals add up constructively at the\ndesignated receiver. This yields received SNR scaling linearly with N, while\navoiding the linear increase in overhead incurred by a direct approach in which\nreceived signals are separately quantized and transmitted for centralized\nprocessing. By transforming the task of long-distance distributed receive\nbeamforming into one of local distributed transmit beamforming, we can leverage\na scalable one-bit feedback algorithm for phase synchronization. We show that\ntime division between the long-distance and local links eliminates the need for\nexplicit frequency synchronization. We provide an analytical framework, whose\nresults closely match Monte Carlo simulations, to evaluate the impact of phase\nnoise due to relaying delay on the performance of the one-bit feedback\nalgorithm. Experimental results from our prototype implementation on\nsoftware-defined radios demonstrate the expected gains in received signal\nstrength despite significant oscillator drift, and are consistent with results\nfrom our analytical framework.\n", "Comment: submitted to IEEE Transactions on Wireless Communications"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05695"}}, {"publisher": {"name": ""}, "description": "  Link failures in wide area networks are common. To recover from such\nfailures, a number of methods such as SONET rings, protection cycles, and\nsource rerouting have been investigated. Two important considerations in such\napproaches are the recovery time and the needed spare capacity to complete the\nrecovery. Usually, these techniques attempt to achieve a recovery time less\nthan 50 ms. In this paper we introduce an approach that provides link failure\nrecovery in a hitless manner, or without any appreciable delay. This is\nachieved by means of a method called diversity coding. We present an algorithm\nfor the design of an overlay network to achieve recovery from single link\nfailures in arbitrary networks via diversity coding. This algorithm is designed\nto minimize spare capacity for recovery. We compare the recovery time and spare\ncapacity performance of this algorithm against conventional techniques in terms\nof recovery time, spare capacity, and a joint metric called Quality of Recovery\n(QoR). QoR incorporates both the spare capacity percentages and worst case\nrecovery times. Based on these results, we conclude that the proposed technique\nprovides much shorter recovery times while achieving similar extra capacity, or\nbetter QoR performance overall.\n", "contributors": [{"name": "Avci, S. N.", "sameAs": [], "familyName": "Avci", "additionalName": "N.", "givenName": "S.", "email": ""}, {"name": "Hu, X.", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "X.", "email": ""}, {"name": "Ayanoglu, E.", "sameAs": [], "familyName": "Ayanoglu", "additionalName": "", "givenName": "E.", "email": ""}], "title": "Recovery from Link Failures in Networks with Arbitrary Topology via\n  Diversity Coding", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-06-02", "2011-06-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1106.0489", "oai:arXiv.org:1106.0489"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Link failures in wide area networks are common. To recover from such\nfailures, a number of methods such as SONET rings, protection cycles, and\nsource rerouting have been investigated. Two important considerations in such\napproaches are the recovery time and the needed spare capacity to complete the\nrecovery. Usually, these techniques attempt to achieve a recovery time less\nthan 50 ms. In this paper we introduce an approach that provides link failure\nrecovery in a hitless manner, or without any appreciable delay. This is\nachieved by means of a method called diversity coding. We present an algorithm\nfor the design of an overlay network to achieve recovery from single link\nfailures in arbitrary networks via diversity coding. This algorithm is designed\nto minimize spare capacity for recovery. We compare the recovery time and spare\ncapacity performance of this algorithm against conventional techniques in terms\nof recovery time, spare capacity, and a joint metric called Quality of Recovery\n(QoR). QoR incorporates both the spare capacity percentages and worst case\nrecovery times. Based on these results, we conclude that the proposed technique\nprovides much shorter recovery times while achieving similar extra capacity, or\nbetter QoR performance overall.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1106.0489"}}, {"publisher": {"name": ""}, "description": "  In contrast to its wired counterpart, wireless communication is highly\nsusceptible to eavesdropping due to the broadcast nature of the wireless\npropagation medium. Recent works have proposed the use of interference to\nreduce eavesdropping capabilities in wireless wiretap networks. However, the\nconcurrent effect of interference on both eavesdropping receivers (ERs) and\nlegitimate receivers (LRs) has not been thoroughly investigated, and carefully\nengineering the network interference is required to harness the full potential\nof interference for wireless secrecy. This two part paper addresses this issue\nby proposing a generalized interference alignment (GIA) technique, which\njointly designs the transceivers at the legitimate partners to impede the ERs\nwithout interfering with LRs. In Part I, we have established a theoretical\nframework for the GIA technique. In Part II, we will first propose an efficient\nGIA algorithm that is applicable to large-scale networks and then evaluate the\nperformance of this algorithm in stochastic wireless wiretap network via both\nanalysis and simulation. These results reveal insights into when and how GIA\ncontributes to wireless secrecy.\n", "contributors": [{"name": "Ruan, Liangzhong", "sameAs": [], "familyName": "Ruan", "additionalName": "", "givenName": "Liangzhong", "email": ""}, {"name": "Lau, Vincent K. N.", "sameAs": [], "familyName": "Lau", "additionalName": "K. N.", "givenName": "Vincent", "email": ""}, {"name": "Win, Moe Z.", "sameAs": [], "familyName": "Win", "additionalName": "Z.", "givenName": "Moe", "email": ""}], "title": "Generalized Interference Alignment --- Part II: Application to Wireless\n  Secrecy", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06361", "oai:arXiv.org:1503.06361"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In contrast to its wired counterpart, wireless communication is highly\nsusceptible to eavesdropping due to the broadcast nature of the wireless\npropagation medium. Recent works have proposed the use of interference to\nreduce eavesdropping capabilities in wireless wiretap networks. However, the\nconcurrent effect of interference on both eavesdropping receivers (ERs) and\nlegitimate receivers (LRs) has not been thoroughly investigated, and carefully\nengineering the network interference is required to harness the full potential\nof interference for wireless secrecy. This two part paper addresses this issue\nby proposing a generalized interference alignment (GIA) technique, which\njointly designs the transceivers at the legitimate partners to impede the ERs\nwithout interfering with LRs. In Part I, we have established a theoretical\nframework for the GIA technique. In Part II, we will first propose an efficient\nGIA algorithm that is applicable to large-scale networks and then evaluate the\nperformance of this algorithm in stochastic wireless wiretap network via both\nanalysis and simulation. These results reveal insights into when and how GIA\ncontributes to wireless secrecy.\n", "Comment: minor revision at IEEE Transactions on Signal Processing"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06361"}}, {"publisher": {"name": ""}, "description": "  It is known that the Bergman projection operator maps the space of\nessentially bounded functions in the unit ball in the d-dimensional complex\nvector space onto the Bloch space of the unit ball. This paper deals with the\nvarious semi-norms of the Bergman projection. We improve some recent results.\n", "contributors": [{"name": "Markovic, Marijan", "sameAs": [], "familyName": "Markovic", "additionalName": "", "givenName": "Marijan", "email": ""}], "title": "Semi-norms of the Bergman projection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-19", "2015-04-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.4688", "oai:arXiv.org:1402.4688"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  It is known that the Bergman projection operator maps the space of\nessentially bounded functions in the unit ball in the d-dimensional complex\nvector space onto the Bloch space of the unit ball. This paper deals with the\nvarious semi-norms of the Bergman projection. We improve some recent results.\n", "Comment: to appear in Computational Methods and Function Theory"]}}], "languages": [null], "subjects": ["mathematics - complex variables"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.4688"}}, {"publisher": {"name": ""}, "description": "  We prove that rational and 1-rational singularities of complex spaces are\nstable under taking quotients by holomorphic actions of reductive and compact\nLie groups. This extends a result of Boutot to the analytic category and yields\na refinement of his result in the algebraic category. As one of the main\ntechnical tools vanishing theorems for cohomology groups with support on fibres\nof resolutions are proven.\n", "contributors": [{"name": "Greb, Daniel", "sameAs": [], "familyName": "Greb", "additionalName": "", "givenName": "Daniel", "email": ""}], "title": "Rational singularities and quotients by holomorphic group actions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2009-06-25", "2010-04-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/0906.4623", "Ann. Scuola Norm. Sup. Pisa Cl. Sci. (5), Vol. X, issue 2 (2011),\n  413-426", "doi:10.2422/2036-2145.2011.2.07", "oai:arXiv.org:0906.4623"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We prove that rational and 1-rational singularities of complex spaces are\nstable under taking quotients by holomorphic actions of reductive and compact\nLie groups. This extends a result of Boutot to the analytic category and yields\na refinement of his result in the algebraic category. As one of the main\ntechnical tools vanishing theorems for cohomology groups with support on fibres\nof resolutions are proven.\n", "Comment: 13 pages; typos corrected, references added and updated; to appear in\n  Annali della Scuola Normale Superiore, Classe di Scienze."]}}], "languages": [null], "subjects": ["32s05", "32m05", "32c36", "mathematics - complex variables", "mathematics - algebraic geometry", "14l30"], "providerUpdatedDateTime": "2015-04-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/0906.4623"}}, {"publisher": {"name": ""}, "description": "  Marx and Strohh\\\"acker showed around in 1933 that $f(z)/z$ is subordinate to\n$1/(1-z)$ for a normalized convex function $f$ on the unit disk $|z|<1.$\nBrickman, Hallenbeck, MacGregor and Wilken proved in 1973 further that $f(z)/z$\nis subordinate to $k_\\alpha(z)/z$ if $f$ is convex of order $\\alpha$ for\n$1/2\\le\\alpha<1$ and conjectured that this is true also for $0<\\alpha<1/2.$\nHere, $k_\\alpha$ is the standard extremal function in the class of normalized\nconvex functions of order $\\alpha$ and $k_0(z)=z/(1-z).$ We prove the\nconjecture and study geometric properties of convex functions of order\n$\\alpha.$ In particular, we prove that $(f+g)/2$ is starlike whenever $f$ and\n$g$ both are convex of order $3/5.$\n", "contributors": [{"name": "Sugawa, Toshiyuki", "sameAs": [], "familyName": "Sugawa", "additionalName": "", "givenName": "Toshiyuki", "email": ""}, {"name": "Wang, Li-Mei", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Li-Mei", "email": ""}], "title": "Notes on convex functions of order $\\alpha$", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.05127", "oai:arXiv.org:1502.05127"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Marx and Strohh\\\"acker showed around in 1933 that $f(z)/z$ is subordinate to\n$1/(1-z)$ for a normalized convex function $f$ on the unit disk $|z|<1.$\nBrickman, Hallenbeck, MacGregor and Wilken proved in 1973 further that $f(z)/z$\nis subordinate to $k_\\alpha(z)/z$ if $f$ is convex of order $\\alpha$ for\n$1/2\\le\\alpha<1$ and conjectured that this is true also for $0<\\alpha<1/2.$\nHere, $k_\\alpha$ is the standard extremal function in the class of normalized\nconvex functions of order $\\alpha$ and $k_0(z)=z/(1-z).$ We prove the\nconjecture and study geometric properties of convex functions of order\n$\\alpha.$ In particular, we prove that $(f+g)/2$ is starlike whenever $f$ and\n$g$ both are convex of order $3/5.$\n", "Comment: 12 pages"]}}], "languages": [null], "subjects": ["secondary 30c75", "primary 30c45", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-02-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.05127"}}, {"publisher": {"name": ""}, "description": "  In this article, two closed and convex sets for blind deconvolution problem\nare proposed. Most blurring functions in microscopy are symmetric with respect\nto the origin. Therefore, they do not modify the phase of the Fourier transform\n(FT) of the original image. As a result blurred image and the original image\nhave the same FT phase. Therefore, the set of images with a prescribed FT phase\ncan be used as a constraint set in blind deconvolution problems. Another convex\nset that can be used during the image reconstruction process is the epigraph\nset of Total Variation (TV) function. This set does not need a prescribed upper\nbound on the total variation of the image. The upper bound is automatically\nadjusted according to the current image of the restoration process. Both of\nthese two closed and convex sets can be used as a part of any blind\ndeconvolution algorithm. Simulation examples are presented.\n", "contributors": [{"name": "Tofighi, Mohammad", "sameAs": [], "familyName": "Tofighi", "additionalName": "", "givenName": "Mohammad", "email": ""}, {"name": "Yorulmaz, Onur", "sameAs": [], "familyName": "Yorulmaz", "additionalName": "", "givenName": "Onur", "email": ""}, {"name": "Cetin, A. Enis", "sameAs": [], "familyName": "Cetin", "additionalName": "Enis", "givenName": "A.", "email": ""}], "title": "Phase and TV Based Convex Sets for Blind Deconvolution of Microscopic\n  Images", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04776", "oai:arXiv.org:1503.04776"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this article, two closed and convex sets for blind deconvolution problem\nare proposed. Most blurring functions in microscopy are symmetric with respect\nto the origin. Therefore, they do not modify the phase of the Fourier transform\n(FT) of the original image. As a result blurred image and the original image\nhave the same FT phase. Therefore, the set of images with a prescribed FT phase\ncan be used as a constraint set in blind deconvolution problems. Another convex\nset that can be used during the image reconstruction process is the epigraph\nset of Total Variation (TV) function. This set does not need a prescribed upper\nbound on the total variation of the image. The upper bound is automatically\nadjusted according to the current image of the restoration process. Both of\nthese two closed and convex sets can be used as a part of any blind\ndeconvolution algorithm. Simulation examples are presented.\n", "Comment: Submitted to IEEE Selected Topics in Signal Processing"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04776"}}, {"publisher": {"name": ""}, "description": "  The ordered weighted $\\ell_1$ norm (OWL) was recently proposed, with two\ndifferent motivations: its good statistical properties as a sparsity promoting\nregularizer; the fact that it generalizes the so-called {\\it octagonal\nshrinkage and clustering algorithm for regression} (OSCAR), which has the\nability to cluster/group regression variables that are highly correlated. This\npaper contains several contributions to the study and application of OWL\nregularization: the derivation of the atomic formulation of the OWL norm; the\nderivation of the dual of the OWL norm, based on its atomic formulation; a new\nand simpler derivation of the proximity operator of the OWL norm; an efficient\nscheme to compute the Euclidean projection onto an OWL ball; the instantiation\nof the conditional gradient (CG, also known as Frank-Wolfe) algorithm for\nlinear regression problems under OWL regularization; the instantiation of\naccelerated projected gradient algorithms for the same class of problems.\nFinally, a set of experiments give evidence that accelerated projected gradient\nalgorithms are considerably faster than CG, for the class of problems\nconsidered.\n", "contributors": [{"name": "Zeng, Xiangrong", "sameAs": [], "familyName": "Zeng", "additionalName": "", "givenName": "Xiangrong", "email": ""}, {"name": "Figueiredo, M\u00e1rio A. T.", "sameAs": [], "familyName": "Figueiredo", "additionalName": "A. T.", "givenName": "M\u00e1rio", "email": ""}], "title": "The Ordered Weighted $\\ell_1$ Norm: Atomic Formulation, Projections, and\n  Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-15", "2015-04-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.4271", "oai:arXiv.org:1409.4271"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The ordered weighted $\\ell_1$ norm (OWL) was recently proposed, with two\ndifferent motivations: its good statistical properties as a sparsity promoting\nregularizer; the fact that it generalizes the so-called {\\it octagonal\nshrinkage and clustering algorithm for regression} (OSCAR), which has the\nability to cluster/group regression variables that are highly correlated. This\npaper contains several contributions to the study and application of OWL\nregularization: the derivation of the atomic formulation of the OWL norm; the\nderivation of the dual of the OWL norm, based on its atomic formulation; a new\nand simpler derivation of the proximity operator of the OWL norm; an efficient\nscheme to compute the Euclidean projection onto an OWL ball; the instantiation\nof the conditional gradient (CG, also known as Frank-Wolfe) algorithm for\nlinear regression problems under OWL regularization; the instantiation of\naccelerated projected gradient algorithms for the same class of problems.\nFinally, a set of experiments give evidence that accelerated projected gradient\nalgorithms are considerably faster than CG, for the class of problems\nconsidered.\n", "Comment: 13 pages, 17 figures. The latest version of this paper was submitted\n  to a journal"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - information theory", "computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.4271"}}, {"publisher": {"name": ""}, "description": "  Relaying has been extensively studied during the last decades and has found\nnumerous applications in wireless communications. The simplest relaying method,\nnamely amplify and forward, has shown potential in MIMO multiple access\nsystems, when Gaussian fading channels are assumed for both hops. However, in\nsome cases ill conditioned channels may appear on the second hop. For example,\nthis impairment could affect cooperative BS systems with microwave link\nbackhauling, which involve strong line of sight channels with insufficient\nscattering. In this paper, we consider a large system analysis of such as model\nfocusing on both optimal joint decoding and joint MMSE filtering receivers.\nAnalytical methods based on free probability are presented for calculating the\nergodic throughput, the MMSE error and the average SINR. Furthermore, the\nperformance degradation of the system throughput is evaluated considering\nsecond hop impairments such as ill-conditioning and rank deficiency, while\nhigh- and low-SNR limits are calculated for the considered performance metrics.\nFinally, the cooperative BS system is compared to a conventional channel\nresource division strategy and suitable operating points are proposed.\n", "contributors": [{"name": "Chatzinotas, Symeon", "sameAs": [], "familyName": "Chatzinotas", "additionalName": "", "givenName": "Symeon", "email": ""}], "title": "Large System Analysis for Amplify & Forward SIMO Multiple Access Channel\n  with Ill-conditioned Second Hop", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1569", "oai:arXiv.org:1411.1569"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Relaying has been extensively studied during the last decades and has found\nnumerous applications in wireless communications. The simplest relaying method,\nnamely amplify and forward, has shown potential in MIMO multiple access\nsystems, when Gaussian fading channels are assumed for both hops. However, in\nsome cases ill conditioned channels may appear on the second hop. For example,\nthis impairment could affect cooperative BS systems with microwave link\nbackhauling, which involve strong line of sight channels with insufficient\nscattering. In this paper, we consider a large system analysis of such as model\nfocusing on both optimal joint decoding and joint MMSE filtering receivers.\nAnalytical methods based on free probability are presented for calculating the\nergodic throughput, the MMSE error and the average SINR. Furthermore, the\nperformance degradation of the system throughput is evaluated considering\nsecond hop impairments such as ill-conditioning and rank deficiency, while\nhigh- and low-SNR limits are calculated for the considered performance metrics.\nFinally, the cooperative BS system is compared to a conventional channel\nresource division strategy and suitable operating points are proposed.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1569"}}, {"publisher": {"name": ""}, "description": "  In wireless networks relay nodes can be used to assist the users'\ntransmissions to reach their destination. Work on relay cooperation, from a\nphysical layer perspective, has up to now yielded well-known results. This\npaper takes a different stance focusing on network-level cooperation. Extending\nprevious results for a single relay, we investigate here the benefits from the\ndeployment of a second one. We assume that the two relays do not generate\npackets of their own and the system employs random access to the medium; we\nfurther consider slotted time and that the users have saturated queues. We\nobtain analytical expressions for the arrival and service rates of the queues\nof the two relays and the stability conditions. We investigate a model of the\nsystem, in which the users are divided into clusters, each being served by one\nrelay, and show its advantages in terms of aggregate and throughput per user.\nWe quantify the above, analytically for the case of the collision channel and\nthrough simulations for the case of Multi-Packet Reception (MPR), and we\nprovide insight on when the deployment of a second relay in the system can\nyield significant advantages.\n", "contributors": [{"name": "Papadimitriou, Georgios", "sameAs": [], "familyName": "Papadimitriou", "additionalName": "", "givenName": "Georgios", "email": ""}, {"name": "Pappas, Nikolaos", "sameAs": [], "familyName": "Pappas", "additionalName": "", "givenName": "Nikolaos", "email": ""}, {"name": "Angelakis, Vangelis", "sameAs": [], "familyName": "Angelakis", "additionalName": "", "givenName": "Vangelis", "email": ""}, {"name": "Traganitis, Apostolos", "sameAs": [], "familyName": "Traganitis", "additionalName": "", "givenName": "Apostolos", "email": ""}], "title": "Network-Level Performance Evaluation of a Two-Relay Cooperative Random\n  Access Wireless System", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-23", "2014-12-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.5949", "oai:arXiv.org:1406.5949"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In wireless networks relay nodes can be used to assist the users'\ntransmissions to reach their destination. Work on relay cooperation, from a\nphysical layer perspective, has up to now yielded well-known results. This\npaper takes a different stance focusing on network-level cooperation. Extending\nprevious results for a single relay, we investigate here the benefits from the\ndeployment of a second one. We assume that the two relays do not generate\npackets of their own and the system employs random access to the medium; we\nfurther consider slotted time and that the users have saturated queues. We\nobtain analytical expressions for the arrival and service rates of the queues\nof the two relays and the stability conditions. We investigate a model of the\nsystem, in which the users are divided into clusters, each being served by one\nrelay, and show its advantages in terms of aggregate and throughput per user.\nWe quantify the above, analytically for the case of the collision channel and\nthrough simulations for the case of Multi-Packet Reception (MPR), and we\nprovide insight on when the deployment of a second relay in the system can\nyield significant advantages.\n", "Comment: Submitted for journal publication"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.5949"}}, {"publisher": {"name": ""}, "description": "  We consider apictorial edge-matching puzzles, in which the goal is to arrange\na collection of puzzle pieces with colored edges so that the colors match along\nthe edges of adjacent pieces. We devise an algebraic representation for this\nproblem and provide conditions under which it exactly characterizes a puzzle.\nUsing the new representation, we recast the combinatorial, discrete problem of\nsolving puzzles as a global, polynomial system of equations with continuous\nvariables. We further propose new algorithms for generating approximate\nsolutions to the continuous problem by solving a sequence of convex\nrelaxations.\n", "contributors": [{"name": "Kovalsky, Shahar Z.", "sameAs": [], "familyName": "Kovalsky", "additionalName": "Z.", "givenName": "Shahar", "email": ""}, {"name": "Glasner, Daniel", "sameAs": [], "familyName": "Glasner", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Basri, Ronen", "sameAs": [], "familyName": "Basri", "additionalName": "", "givenName": "Ronen", "email": ""}], "title": "A Global Approach for Solving Edge-Matching Puzzles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-21", "2015-02-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.5957", "oai:arXiv.org:1409.5957"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We consider apictorial edge-matching puzzles, in which the goal is to arrange\na collection of puzzle pieces with colored edges so that the colors match along\nthe edges of adjacent pieces. We devise an algebraic representation for this\nproblem and provide conditions under which it exactly characterizes a puzzle.\nUsing the new representation, we recast the combinatorial, discrete problem of\nsolving puzzles as a global, polynomial system of equations with continuous\nvariables. We further propose new algorithms for generating approximate\nsolutions to the continuous problem by solving a sequence of convex\nrelaxations.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.5957"}}, {"publisher": {"name": ""}, "description": "  The least-mean-squares (LMS) algorithm is the most popular algorithm in\nadaptive filtering. Several variable step-size strategies have been suggested\nto improve the performance of the LMS algorithm. These strategies enhance the\nperformance of the algorithm but a major drawback is the complexity in the\ntheoretical analysis of the resultant algorithms. Researchers use several\nassumptions to find closed-form analytical solutions. This work presents a\nunified approach for the analysis of variable step-size LMS algorithms. The\napproach is then applied to several variable step-size strategies and\ntheoretical and simulation results are compared.\n", "contributors": [{"name": "Saeed, Muhammad Omer Bin", "sameAs": [], "familyName": "Saeed", "additionalName": "Omer Bin", "givenName": "Muhammad", "email": ""}], "title": "A Unified Analysis Approach for LMS-based Variable Step-Size Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.02487", "oai:arXiv.org:1501.02487"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The least-mean-squares (LMS) algorithm is the most popular algorithm in\nadaptive filtering. Several variable step-size strategies have been suggested\nto improve the performance of the LMS algorithm. These strategies enhance the\nperformance of the algorithm but a major drawback is the complexity in the\ntheoretical analysis of the resultant algorithms. Researchers use several\nassumptions to find closed-form analytical solutions. This work presents a\nunified approach for the analysis of variable step-size LMS algorithms. The\napproach is then applied to several variable step-size strategies and\ntheoretical and simulation results are compared.\n", "Comment: 5 pages, 1 figure, 5 tables"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-01-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.02487"}}, {"publisher": {"name": ""}, "description": "  With increasing use of digital control it is natural to view control inputs\nand outputs as stochastic processes assuming values over finite alphabets\nrather than in a Euclidean space. As control over networks becomes increasingly\ncommon, data compression by reducing the size of the input and output alphabets\nwithout losing the fidelity of representation becomes relevant. This requires\nus to define a notion of distance between two stochastic processes assuming\nvalues in distinct sets, possibly of different cardinalities. If the two\nprocesses are i.i.d., then the problem becomes one of defining a metric between\ntwo probability distributions over distinct finite sets of possibly different\ncardinalities. This is the problem addressed in the present paper. A metric is\ndefined in terms of a joint distribution on the product of the two sets, which\nhas the two given distributions as its marginals, and has minimum entropy.\nComputing the metric exactly turns out to be NP-hard. Therefore an efficient\ngreedy algorithm is presented for finding an upper bound on the distance. This\nproblem also turns out to be NP-hard, so again a greedy algorithm is\nconstructed for finding a suboptimal reduced order approximation. Taken\ntogether, all the results presented here permit the approximation of an i.i.d.\nprocess over a set of large cardinality by another i.i.d. process over a set of\nsmaller cardinality. In future work, attempts will be made to extend this work\nto Markov processes over finite sets.\n", "contributors": [{"name": "Vidyasagar, Mathukumalli", "sameAs": [], "familyName": "Vidyasagar", "additionalName": "", "givenName": "Mathukumalli", "email": ""}], "title": "A Metric Between Probability Distributions on Finite Sets of Different\n  Cardinalities and Applications to Order Reduction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-22", "2011-09-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.4521", "oai:arXiv.org:1104.4521"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  With increasing use of digital control it is natural to view control inputs\nand outputs as stochastic processes assuming values over finite alphabets\nrather than in a Euclidean space. As control over networks becomes increasingly\ncommon, data compression by reducing the size of the input and output alphabets\nwithout losing the fidelity of representation becomes relevant. This requires\nus to define a notion of distance between two stochastic processes assuming\nvalues in distinct sets, possibly of different cardinalities. If the two\nprocesses are i.i.d., then the problem becomes one of defining a metric between\ntwo probability distributions over distinct finite sets of possibly different\ncardinalities. This is the problem addressed in the present paper. A metric is\ndefined in terms of a joint distribution on the product of the two sets, which\nhas the two given distributions as its marginals, and has minimum entropy.\nComputing the metric exactly turns out to be NP-hard. Therefore an efficient\ngreedy algorithm is presented for finding an upper bound on the distance. This\nproblem also turns out to be NP-hard, so again a greedy algorithm is\nconstructed for finding a suboptimal reduced order approximation. Taken\ntogether, all the results presented here permit the approximation of an i.i.d.\nprocess over a set of large cardinality by another i.i.d. process over a set of\nsmaller cardinality. In future work, attempts will be made to extend this work\nto Markov processes over finite sets.\n", "Comment: 32 pages, no figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "computer science - information theory", "93e99"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.4521"}}, {"publisher": {"name": ""}, "description": "  This paper was originally designed as a literature review for a doctoral\ndissertation focusing on Wikipedia. This exposition gives the structure of\nWikipedia and the latest trends in Wikipedia research.\n", "contributors": [{"name": "Martin, Owen S.", "sameAs": [], "familyName": "Martin", "additionalName": "S.", "givenName": "Owen", "email": ""}], "title": "A Wikipedia Literature Review", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-10-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1110.5863", "oai:arXiv.org:1110.5863"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper was originally designed as a literature review for a doctoral\ndissertation focusing on Wikipedia. This exposition gives the structure of\nWikipedia and the latest trends in Wikipedia research.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - digital libraries"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1110.5863"}}, {"publisher": {"name": ""}, "description": "  In this work we study on a 2-dimensional square lattice a recent version of\nthe Naming Game, an agent-based model used for describing the emergence of\nlinguistic structures. The system is open-ended and agents can invent new words\nall along the evolution of the game, picking them up from a pool characterised\nby a Gaussian distribution with standard deviation $\\sigma$. The model displays\na nonequilibrium phase transition at a critical point $\\sigma_{c}\\approx 25.6$,\nwhich separates an absorbing consensus state from an active fragmented state\nwhere agents continuously exchange different words. The finite-size scaling\nanalysis of our simulations strongly suggests that the phase transition is\ndiscontinuous.\n", "contributors": [{"name": "Crokidakis, Nuno", "sameAs": [], "familyName": "Crokidakis", "additionalName": "", "givenName": "Nuno", "email": ""}, {"name": "Brigatti, Edgardo", "sameAs": [], "familyName": "Brigatti", "additionalName": "", "givenName": "Edgardo", "email": ""}], "title": "Discontinuous phase transition in an open-ended Naming Game", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2994", "J. Stat. Mech. P01019 (2015)", "doi:10.1088/1742-5468/2015/01/P01019", "oai:arXiv.org:1412.2994"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  In this work we study on a 2-dimensional square lattice a recent version of\nthe Naming Game, an agent-based model used for describing the emergence of\nlinguistic structures. The system is open-ended and agents can invent new words\nall along the evolution of the game, picking them up from a pool characterised\nby a Gaussian distribution with standard deviation $\\sigma$. The model displays\na nonequilibrium phase transition at a critical point $\\sigma_{c}\\approx 25.6$,\nwhich separates an absorbing consensus state from an active fragmented state\nwhere agents continuously exchange different words. The finite-size scaling\nanalysis of our simulations strongly suggests that the phase transition is\ndiscontinuous.\n", "Comment: 13 pages, 6 figures, to appear in JSTAT"]}}], "languages": [null], "subjects": ["physics - physics and society", "condensed matter - statistical mechanics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2994"}}, {"publisher": {"name": ""}, "description": "  Generally, social network analysis has often focused on the topology of the\nnetwork without considering the characteristics of individuals involved in\nthem. Less attention is given to study the behavior of individuals, considering\nthey are the basic entity of a graph. Given a mobile social network graph, what\nare good features to extract key information from the nodes?How many distinct\nneighborhood patterns exist for ego nodes? What clues does such information\nprovide to study nodes over a long period of time?\n  In this report, we develop an automated system in order to discover the\noccurrences of prototypical ego-centric patterns from data. We aim to provide a\ndata-driven instrument to be used in behavioral sciences for graph\ninterpretations. We analyze social networks derived from real-world data\ncollected with smart-phones. We select 13 well-known network measures,\nespecially those concerned with ego graphs. We form eight feature subsets and\nthen assess their performance using unsupervised clustering techniques to\ndiscover distinguishing ego-centric patterns. From clustering analysis, we\ndiscover that eight distinct neighborhood patterns have emerged. This\ncategorization allows concise analysis of users' data as they change over time.\nThe results provide a fine-grained analysis for the contribution of different\nfeature sets to detect unique clustering patterns. Last, as a case study, two\ndatasets are studied over long periods to demonstrate the utility of this\nmethod. The study shows the effectiveness of the proposed approach in\ndiscovering important trends from data.\n", "contributors": [{"name": "Muhammad, Syed Agha", "sameAs": [], "familyName": "Muhammad", "additionalName": "Agha", "givenName": "Syed", "email": ""}, {"name": "Van Laerhoven, Kristof", "sameAs": [], "familyName": "Van Laerhoven", "additionalName": "", "givenName": "Kristof", "email": ""}], "title": "An Automated System for Discovering Neighborhood Patterns in Ego\n  Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04877", "oai:arXiv.org:1503.04877"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Generally, social network analysis has often focused on the topology of the\nnetwork without considering the characteristics of individuals involved in\nthem. Less attention is given to study the behavior of individuals, considering\nthey are the basic entity of a graph. Given a mobile social network graph, what\nare good features to extract key information from the nodes?How many distinct\nneighborhood patterns exist for ego nodes? What clues does such information\nprovide to study nodes over a long period of time?\n  In this report, we develop an automated system in order to discover the\noccurrences of prototypical ego-centric patterns from data. We aim to provide a\ndata-driven instrument to be used in behavioral sciences for graph\ninterpretations. We analyze social networks derived from real-world data\ncollected with smart-phones. We select 13 well-known network measures,\nespecially those concerned with ego graphs. We form eight feature subsets and\nthen assess their performance using unsupervised clustering techniques to\ndiscover distinguishing ego-centric patterns. From clustering analysis, we\ndiscover that eight distinct neighborhood patterns have emerged. This\ncategorization allows concise analysis of users' data as they change over time.\nThe results provide a fine-grained analysis for the contribution of different\nfeature sets to detect unique clustering patterns. Last, as a case study, two\ndatasets are studied over long periods to demonstrate the utility of this\nmethod. The study shows the effectiveness of the proposed approach in\ndiscovering important trends from data.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04877"}}, {"publisher": {"name": ""}, "description": "  When delegating computation to a service provider, as in cloud computing, we\nseek some reassurance that the output is correct and complete. Yet recomputing\nthe output as a check is inefficient and expensive, and it may not even be\nfeasible to store all the data locally. We are therefore interested in proof\nsystems which allow a service provider to prove the correctness of its output\nto a streaming (sublinear space) user, who cannot store the full input or\nperform the full computation herself.\n  Our approach is two-fold. First, we describe a carefully chosen instantiation\nof one of the most efficient general-purpose constructions for arbitrary\ncomputations (streaming or otherwise), due to Goldwasser, Kalai, and Rothblum.\nThis requires several new insights to make the methodology more practical. Our\nmain contribution is in achieving a prover who runs in time O(S(n) log S(n)),\nwhere S(n) is the size of an arithmetic circuit computing the function of\ninterest. Our experimental results demonstrate that a practical general-purpose\nprotocol for verifiable computation may be significantly closer to reality than\npreviously realized.\n  Second, we describe techniques that achieve genuine scalability for protocols\nfine-tuned for specific important problems in streaming and database\nprocessing. Focusing in particular on non-interactive protocols for problems\nranging from matrix-vector multiplication to bipartite perfect matching, we\nbuild on prior work to achieve a prover who runs in nearly linear-time, while\nobtaining optimal tradeoffs between communication cost and the user's working\nmemory. Existing techniques required (substantially) superlinear time for the\nprover. We argue that even if general-purpose methods improve, fine-tuned\nprotocols will remain valuable in real-world settings for key problems, and\nhence special attention to specific problems is warranted.\n", "contributors": [{"name": "Cormode, Graham", "sameAs": [], "familyName": "Cormode", "additionalName": "", "givenName": "Graham", "email": ""}, {"name": "Mitzenmacher, Michael", "sameAs": [], "familyName": "Mitzenmacher", "additionalName": "", "givenName": "Michael", "email": ""}, {"name": "Thaler, Justin", "sameAs": [], "familyName": "Thaler", "additionalName": "", "givenName": "Justin", "email": ""}], "title": "Practical Verified Computation with Streaming Interactive Proofs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-05-10", "2012-02-12"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.2003", "oai:arXiv.org:1105.2003"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  When delegating computation to a service provider, as in cloud computing, we\nseek some reassurance that the output is correct and complete. Yet recomputing\nthe output as a check is inefficient and expensive, and it may not even be\nfeasible to store all the data locally. We are therefore interested in proof\nsystems which allow a service provider to prove the correctness of its output\nto a streaming (sublinear space) user, who cannot store the full input or\nperform the full computation herself.\n  Our approach is two-fold. First, we describe a carefully chosen instantiation\nof one of the most efficient general-purpose constructions for arbitrary\ncomputations (streaming or otherwise), due to Goldwasser, Kalai, and Rothblum.\nThis requires several new insights to make the methodology more practical. Our\nmain contribution is in achieving a prover who runs in time O(S(n) log S(n)),\nwhere S(n) is the size of an arithmetic circuit computing the function of\ninterest. Our experimental results demonstrate that a practical general-purpose\nprotocol for verifiable computation may be significantly closer to reality than\npreviously realized.\n  Second, we describe techniques that achieve genuine scalability for protocols\nfine-tuned for specific important problems in streaming and database\nprocessing. Focusing in particular on non-interactive protocols for problems\nranging from matrix-vector multiplication to bipartite perfect matching, we\nbuild on prior work to achieve a prover who runs in nearly linear-time, while\nobtaining optimal tradeoffs between communication cost and the user's working\nmemory. Existing techniques required (substantially) superlinear time for the\nprover. We argue that even if general-purpose methods improve, fine-tuned\nprotocols will remain valuable in real-world settings for key problems, and\nhence special attention to specific problems is warranted.\n", "Comment: 39 pages, 12 figures, 2 tables. Accepted to ITCS 2012"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity", "computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.2003"}}, {"publisher": {"name": ""}, "description": "  The development of technologies of multimedia, linked to that of Internet and\ndemocratization of high outflow, has made henceforth E-learning possible for\nlearners being in virtual classes and geographically distributed. The quality\nand quantity of asynchronous and synchronous communications are the key\nelements for E-learning success. It is important to have a propitious\nsupervision to reduce the feeling of isolation in E-learning. This feeling of\nisolation is among the main causes of loss and high rates of stalling in\nE-learning. The researches to be conducted in this domain aim to bring\nsolutions of convergence coming from real time image for the capture and\nrecognition of hand gestures. These gestures will be analyzed by the system and\ntransformed as indicator of participation. This latter is displayed in the\ntable of performance of the tutor as a curve according to the time. In case of\nisolation of learner, the indicator of participation will become red and the\ntutor will be informed of learners with difficulties to participate during\nlearning session.\n", "contributors": [{"name": "Mourad, Bousaaid", "sameAs": [], "familyName": "Mourad", "additionalName": "", "givenName": "Bousaaid", "email": ""}, {"name": "Tarik, Ayaou", "sameAs": [], "familyName": "Tarik", "additionalName": "", "givenName": "Ayaou", "email": ""}, {"name": "Karim, Afdel", "sameAs": [], "familyName": "Karim", "additionalName": "", "givenName": "Afdel", "email": ""}, {"name": "Pascal, Estraillier", "sameAs": [], "familyName": "Pascal", "additionalName": "", "givenName": "Estraillier", "email": ""}], "title": "Real-Time System of Hand Detection And Gesture Recognition In Cyber\n  Presence Interactive System For E-Learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07243", "Journal of Engineering Research and Applications Vol. 4, Issue 9\n  (Version 1), September 2014, pp.1-5", "oai:arXiv.org:1502.07243"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The development of technologies of multimedia, linked to that of Internet and\ndemocratization of high outflow, has made henceforth E-learning possible for\nlearners being in virtual classes and geographically distributed. The quality\nand quantity of asynchronous and synchronous communications are the key\nelements for E-learning success. It is important to have a propitious\nsupervision to reduce the feeling of isolation in E-learning. This feeling of\nisolation is among the main causes of loss and high rates of stalling in\nE-learning. The researches to be conducted in this domain aim to bring\nsolutions of convergence coming from real time image for the capture and\nrecognition of hand gestures. These gestures will be analyzed by the system and\ntransformed as indicator of participation. This latter is displayed in the\ntable of performance of the tutor as a curve according to the time. In case of\nisolation of learner, the indicator of participation will become red and the\ntutor will be informed of learners with difficulties to participate during\nlearning session.\n", "Comment: 5 pages. arXiv admin note: substantial text overlap with\n  arXiv:1502.06641"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07243"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Our interactions with cities are increasingly mediated through a complex array of technologies, including location-aware mobile devices and a vast number of online platforms. However, we often also use these tools to create content about the places that we live in and travel through. My thesis examines what I define as \"place-based media,\" that is, user-generated content produced about place. This content - photos of street life, overheard quotes, and local reviews, for example - emerges out of daily routines, and has a reciprocal relationship with the urban environment, both contributing to, as well as reflecting the life of the city. In this thesis, I aim to explore the relationship between the technologies and practices involved in the production of place-based media. In my approach, I situate place-based media within relevant historical precedents, such as street photography. In addition, I examine content produced about a single neighborhood, Central Square, Cambridge, in order to better understand the social and affective qualities of content that is created in dialogue with place. Ultimately, this project examines the production of place-based media as an everyday urban practice, with an eye towards the potential implications these media could have for contemporary cities and city neighborhoods.", "contributors": [{"name": "Boghani, Amar K. (Amar Kapadia)", "sameAs": [], "familyName": "Boghani", "additionalName": "K.", "givenName": "Amar", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Comparative Media Studies.", "sameAs": [], "familyName": "Studies.", "additionalName": "Institute of Technology. Department of Comparative Media", "givenName": "Massachusetts", "email": ""}, {"name": "William Charles Uricchio.", "sameAs": [], "familyName": "Uricchio.", "additionalName": "Charles", "givenName": "William", "email": ""}], "title": "The city expressed : everyday media production and the urban environment", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "192 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/81077", "857829777", "oai:dspace.mit.edu:1721.1/81077"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2013-09-24T19:41:21Z", "2013-09-24T19:41:21Z", "2013", "2013"]}}, {"name": "description", "properties": {"description": ["Our interactions with cities are increasingly mediated through a complex array of technologies, including location-aware mobile devices and a vast number of online platforms. However, we often also use these tools to create content about the places that we live in and travel through. My thesis examines what I define as \"place-based media,\" that is, user-generated content produced about place. This content - photos of street life, overheard quotes, and local reviews, for example - emerges out of daily routines, and has a reciprocal relationship with the urban environment, both contributing to, as well as reflecting the life of the city. In this thesis, I aim to explore the relationship between the technologies and practices involved in the production of place-based media. In my approach, I situate place-based media within relevant historical precedents, such as street photography. In addition, I examine content produced about a single neighborhood, Central Square, Cambridge, in order to better understand the social and affective qualities of content that is created in dialogue with place. Ultimately, this project examines the production of place-based media as an everyday urban practice, with an eye towards the potential implications these media could have for contemporary cities and city neighborhoods.", "by Amar K. Boghani.", "Thesis (S.M.)--Massachusetts Institute of Technology, Dept. of Comparative Media Studies, 2013.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (p. 111-115)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39100", "hdl_1721.1_39097"]}}], "languages": [null], "subjects": ["comparative media studies."], "providerUpdatedDateTime": "2015-04-27T14:44:38", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/81077"}}, {"publisher": {"name": ""}, "description": "  We study the relations between a contract automata and an interaction model.\nIn the former model, distributed services are abstracted away as automata -\noblivious of their partners - that coordinate with each other through an\norchestrator. The interaction model relies on channel-based asynchronous\ncommunication and choreography to coordinate distributed services.\n  We define a notion of strong agreement on the contract model, exhibit a\nnatural mapping from the contract model to the interaction model, and give\nconditions to ensure that strong agreement corresponds to well-formed\nchoreography.\n", "contributors": [{"name": "Basile, Davide", "sameAs": [], "familyName": "Basile", "additionalName": "", "givenName": "Davide", "email": ""}, {"name": "Degano, Pierpaolo", "sameAs": [], "familyName": "Degano", "additionalName": "", "givenName": "Pierpaolo", "email": ""}, {"name": "Ferrari, Gian-Luigi", "sameAs": [], "familyName": "Ferrari", "additionalName": "", "givenName": "Gian-Luigi", "email": ""}, {"name": "Tuosto, Emilio", "sameAs": [], "familyName": "Tuosto", "additionalName": "", "givenName": "Emilio", "email": ""}], "title": "From Orchestration to Choreography through Contract Automata", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.7471", "EPTCS 166, 2014, pp. 67-85", "doi:10.4204/EPTCS.166.8", "oai:arXiv.org:1410.7471"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study the relations between a contract automata and an interaction model.\nIn the former model, distributed services are abstracted away as automata -\noblivious of their partners - that coordinate with each other through an\norchestrator. The interaction model relies on channel-based asynchronous\ncommunication and choreography to coordinate distributed services.\n  We define a notion of strong agreement on the contract model, exhibit a\nnatural mapping from the contract model to the interaction model, and give\nconditions to ensure that strong agreement corresponds to well-formed\nchoreography.\n", "Comment: In Proceedings ICE 2014, arXiv:1410.7013"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "computer science - logic in computer science"], "providerUpdatedDateTime": "2014-10-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.7471"}}, {"publisher": {"name": ""}, "description": "  Finding chordless cycles is an important theoretical problem in the Graph\nTheory area. It also can be applied to practical problems such as discover\nwhich predators compete for the same food in ecological networks. Motivated by\nthe problem of theoretical interest and also by its significant practical\nimportance, we present in this paper a parallel algorithm for enumerating all\nthe chordless cycles in undirected graphs, which was implemented in OpenCL.\n", "contributors": [{"name": "Dias, Elis\u00e2ngela Silva", "sameAs": [], "familyName": "Dias", "additionalName": "Silva", "givenName": "Elis\u00e2ngela", "email": ""}, {"name": "Castonguay, Diane", "sameAs": [], "familyName": "Castonguay", "additionalName": "", "givenName": "Diane", "email": ""}, {"name": "Longo, Humberto", "sameAs": [], "familyName": "Longo", "additionalName": "", "givenName": "Humberto", "email": ""}, {"name": "Jradi, Walid Abdala Rfaei", "sameAs": [], "familyName": "Jradi", "additionalName": "Abdala Rfaei", "givenName": "Walid", "email": ""}, {"name": "Nascimento, Hugo A. D. do", "sameAs": [], "familyName": "Nascimento", "additionalName": "A. D.", "givenName": "Hugo", "email": ""}], "title": "Fast Parallel Algorithm for Enumerating All Chordless Cycles in Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4876", "oai:arXiv.org:1410.4876"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Finding chordless cycles is an important theoretical problem in the Graph\nTheory area. It also can be applied to practical problems such as discover\nwhich predators compete for the same food in ecological networks. Motivated by\nthe problem of theoretical interest and also by its significant practical\nimportance, we present in this paper a parallel algorithm for enumerating all\nthe chordless cycles in undirected graphs, which was implemented in OpenCL.\n", "Comment: 9 pages"]}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-10-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4876"}}, {"publisher": {"name": ""}, "description": "  In this paper we study the consistency of an empirical minimum error entropy\n(MEE) algorithm in a regression setting. We introduce two types of consistency.\nThe error entropy consistency, which requires the error entropy of the learned\nfunction to approximate the minimum error entropy, is shown to be always true\nif the bandwidth parameter tends to 0 at an appropriate rate. The regression\nconsistency, which requires the learned function to approximate the regression\nfunction, however, is a complicated issue. We prove that the error entropy\nconsistency implies the regression consistency for homoskedastic models where\nthe noise is independent of the input variable. But for heteroskedastic models,\na counterexample is used to show that the two types of consistency do not\ncoincide. A surprising result is that the regression consistency is always\ntrue, provided that the bandwidth parameter tends to infinity at an appropriate\nrate. Regression consistency of two classes of special models is shown to hold\nwith fixed bandwidth parameter, which further illustrates the complexity of\nregression consistency of MEE. Fourier transform plays crucial roles in our\nanalysis.\n", "contributors": [{"name": "Fan, Jun", "sameAs": [], "familyName": "Fan", "additionalName": "", "givenName": "Jun", "email": ""}, {"name": "Hu, Ting", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Ting", "email": ""}, {"name": "Wu, Qiang", "sameAs": [], "familyName": "Wu", "additionalName": "", "givenName": "Qiang", "email": ""}, {"name": "Zhou, Ding-Xuan", "sameAs": [], "familyName": "Zhou", "additionalName": "", "givenName": "Ding-Xuan", "email": ""}], "title": "Consistency Analysis of an Empirical Minimum Error Entropy Algorithm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5272", "oai:arXiv.org:1412.5272"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  In this paper we study the consistency of an empirical minimum error entropy\n(MEE) algorithm in a regression setting. We introduce two types of consistency.\nThe error entropy consistency, which requires the error entropy of the learned\nfunction to approximate the minimum error entropy, is shown to be always true\nif the bandwidth parameter tends to 0 at an appropriate rate. The regression\nconsistency, which requires the learned function to approximate the regression\nfunction, however, is a complicated issue. We prove that the error entropy\nconsistency implies the regression consistency for homoskedastic models where\nthe noise is independent of the input variable. But for heteroskedastic models,\na counterexample is used to show that the two types of consistency do not\ncoincide. A surprising result is that the regression consistency is always\ntrue, provided that the bandwidth parameter tends to infinity at an appropriate\nrate. Regression consistency of two classes of special models is shown to hold\nwith fixed bandwidth parameter, which further illustrates the complexity of\nregression consistency of MEE. Fourier transform plays crucial roles in our\nanalysis.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-12-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5272"}}, {"publisher": {"name": ""}, "description": "  Two proper polynomial maps $f_1, \\,f_2 \\colon \\mC^n \\lr \\mC^n$ are said to be\n\\emph{equivalent} if there exist $\\Phi_1,\\, \\Phi_2 \\in \\textrm{Aut}(\\mC^n)$\nsuch that $f_2=\\Phi_2 \\circ f_1 \\circ \\Phi_1$. In this article we investigate\nproper polynomial maps of topological degree $d \\geq 2$ up to equivalence. In\nparticular we describe some of our recent results in the case $n=2$ and we\npartially extend them in higher dimension.\n", "contributors": [{"name": "Bisi, Cinzia", "sameAs": [], "familyName": "Bisi", "additionalName": "", "givenName": "Cinzia", "email": ""}, {"name": "Polizzi, Francesco", "sameAs": [], "familyName": "Polizzi", "additionalName": "", "givenName": "Francesco", "email": ""}], "title": "Proper polynomial self-maps of the affine space: state of the art and\n  new results", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-05-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.0078", "Contemporary Mathematics 553 (2011), 15-25", "oai:arXiv.org:1005.0078"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Two proper polynomial maps $f_1, \\,f_2 \\colon \\mC^n \\lr \\mC^n$ are said to be\n\\emph{equivalent} if there exist $\\Phi_1,\\, \\Phi_2 \\in \\textrm{Aut}(\\mC^n)$\nsuch that $f_2=\\Phi_2 \\circ f_1 \\circ \\Phi_1$. In this article we investigate\nproper polynomial maps of topological degree $d \\geq 2$ up to equivalence. In\nparticular we describe some of our recent results in the case $n=2$ and we\npartially extend them in higher dimension.\n", "Comment: Final version, as to appear in Contemporary Mathematics, Proceedings\n  of Complex Analysis and Dynamical Systems IV, held in Nahariya, Israel, May\n  2009."]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "20h15", "secondary: 14e05", "primary: 14r10", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.0078"}}, {"publisher": {"name": ""}, "description": "  The reliable detection of speed of moving vehicles is considered key to\ntraffic law enforcement in most countries, and is seen by many as an important\ntool to reduce the number of traffic accidents and fatalities. Many automatic\nsystems and different methods are employed in different countries, but as a\nrule they tend to be expensive and/or labor intensive, often employing outdated\ntechnology due to the long development time. Here we describe a speed detection\nsystem that relies on simple everyday equipment - a laptop and a consumer web\ncamera. Our method is based on tracking the license plates of cars, which gives\nthe relative movement of the cars in the image. This image displacement is\ntranslated to actual motion by using the method of projection to a reference\nplane, where the reference plane is the road itself. However, since license\nplates do not touch the road, we must compensate for the entailed distortion in\nspeed measurement. We show how to compute the compensation factor using\nknowledge of the license plate standard dimensions. Consequently our system\ncomputes the true speed of moving vehicles fast and accurately. We show\npromising results on videos obtained in a number of scenes and with different\ncar models.\n", "contributors": [{"name": "Ginzburg, Chaim", "sameAs": [], "familyName": "Ginzburg", "additionalName": "", "givenName": "Chaim", "email": ""}, {"name": "Raphael, Amit", "sameAs": [], "familyName": "Raphael", "additionalName": "", "givenName": "Amit", "email": ""}, {"name": "Weinshall, Daphna", "sameAs": [], "familyName": "Weinshall", "additionalName": "", "givenName": "Daphna", "email": ""}], "title": "A Cheap System for Vehicle Speed Detection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06751", "oai:arXiv.org:1501.06751"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The reliable detection of speed of moving vehicles is considered key to\ntraffic law enforcement in most countries, and is seen by many as an important\ntool to reduce the number of traffic accidents and fatalities. Many automatic\nsystems and different methods are employed in different countries, but as a\nrule they tend to be expensive and/or labor intensive, often employing outdated\ntechnology due to the long development time. Here we describe a speed detection\nsystem that relies on simple everyday equipment - a laptop and a consumer web\ncamera. Our method is based on tracking the license plates of cars, which gives\nthe relative movement of the cars in the image. This image displacement is\ntranslated to actual motion by using the method of projection to a reference\nplane, where the reference plane is the road itself. However, since license\nplates do not touch the road, we must compensate for the entailed distortion in\nspeed measurement. We show how to compute the compensation factor using\nknowledge of the license plate standard dimensions. Consequently our system\ncomputes the true speed of moving vehicles fast and accurately. We show\npromising results on videos obtained in a number of scenes and with different\ncar models.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06751"}}, {"publisher": {"name": ""}, "description": "  Network reconciliation is the problem of identifying nodes in separate\nnetworks that represent the same entity, for example matching nodes across\nsocial networks that correspond to the same user. We introduce a technique to\ncompute probably approximately correct (PAC) bounds on precision and recall for\nnetwork reconciliation algorithms. The bounds require some verified matches,\nbut those matches may be used to develop the algorithms. The bounds do not\nrequire knowledge of the network generation process, and they can supply\nconfidence levels for individual matches.\n", "contributors": [{"name": "Le, Ya", "sameAs": [], "familyName": "Le", "additionalName": "", "givenName": "Ya", "email": ""}, {"name": "Bax, Eric", "sameAs": [], "familyName": "Bax", "additionalName": "", "givenName": "Eric", "email": ""}, {"name": "Barbieri, Nicola", "sameAs": [], "familyName": "Barbieri", "additionalName": "", "givenName": "Nicola", "email": ""}, {"name": "Soriano, David Garcia", "sameAs": [], "familyName": "Soriano", "additionalName": "Garcia", "givenName": "David", "email": ""}, {"name": "Mehta, Jitesh", "sameAs": [], "familyName": "Mehta", "additionalName": "", "givenName": "Jitesh", "email": ""}, {"name": "Li, James", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "James", "email": ""}], "title": "Validation of Network Reconciliation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0023", "oai:arXiv.org:1411.0023"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Network reconciliation is the problem of identifying nodes in separate\nnetworks that represent the same entity, for example matching nodes across\nsocial networks that correspond to the same user. We introduce a technique to\ncompute probably approximately correct (PAC) bounds on precision and recall for\nnetwork reconciliation algorithms. The bounds require some verified matches,\nbut those matches may be used to develop the algorithms. The bounds do not\nrequire knowledge of the network generation process, and they can supply\nconfidence levels for individual matches.\n", "Comment: Short version will be submitted to NIPS workshop on networks, 2014"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0023"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "In distributed ML applications, shared parameters are usually replicated among computing nodes to minimize network overhead. Therefore, proper consistency model must be carefully chosen to ensure algorithm's correctness and provide high throughput. Existing consistency models used in general-purpose databases and modern distributed ML systems are either too loose to guarantee correctness of the ML algorithms or too strict and thus fail to fully exploit the computing power of the underlying distributed system. Many ML algorithms fall into the category of \\emph{iterative convergent algorithms} which start from a randomly chosen initial point and converge to optima by repeating iteratively a set of procedures. We've found that many such algorithms are to a bounded amount of inconsistency and still converge correctly. This property allows distributed ML to relax strict consistency models to improve system performance while theoretically guarantees algorithmic correctness. In this paper, we present several relaxed consistency models for asynchronous parallel computation and theoretically prove their algorithmic correctness. The proposed consistency models are implemented in a distributed parameter server and evaluated in the context of a popular ML application: topic modeling.", "contributors": [{"name": "Wei, Jinliang", "sameAs": [], "familyName": "Wei", "additionalName": "", "givenName": "Jinliang", "email": ""}, {"name": "Dai, Wei", "sameAs": [], "familyName": "Dai", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Kumar, Abhimanu", "sameAs": [], "familyName": "Kumar", "additionalName": "", "givenName": "Abhimanu", "email": ""}, {"name": "Zheng, Xun", "sameAs": [], "familyName": "Zheng", "additionalName": "", "givenName": "Xun", "email": ""}, {"name": "Ho, Qirong", "sameAs": [], "familyName": "Ho", "additionalName": "", "givenName": "Qirong", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "Consistent Bounded-Asynchronous Parameter Servers for Distributed ML", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-01-02T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/140", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1139&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1139"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "In distributed ML applications, shared parameters are usually replicated among computing nodes to minimize network overhead. Therefore, proper consistency model must be carefully chosen to ensure algorithm's correctness and provide high throughput. Existing consistency models used in general-purpose databases and modern distributed ML systems are either too loose to guarantee correctness of the ML algorithms or too strict and thus fail to fully exploit the computing power of the underlying distributed system. Many ML algorithms fall into the category of \\emph{iterative convergent algorithms} which start from a randomly chosen initial point and converge to optima by repeating iteratively a set of procedures. We've found that many such algorithms are to a bounded amount of inconsistency and still converge correctly. This property allows distributed ML to relax strict consistency models to improve system performance while theoretically guarantees algorithmic correctness. In this paper, we present several relaxed consistency models for asynchronous parallel computation and theoretically prove their algorithmic correctness. The proposed consistency models are implemented in a distributed parameter server and evaluated in the context of a popular ML application: topic modeling."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-27T21:01:09", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/140"}}, {"publisher": {"name": ""}, "description": "  We propose the object-oriented networking (OON) framework, for meeting the\ngeneralized interconnection, mobility and technology integration requirements\nunderlining the Internet. In OON, the various objects that need to be accessed\nthrough the Internet (content, smart things, services, people, etc.) are viewed\nas network layer resources, rather than as application layer resources as in\nthe IP communications model. By abstracting them as computing objects -with\nattributes and methods- they are identified by expressive, discoverable names,\nwhile data are exchanged between them in the context of their methods, based on\nsuitably defined system-specific names. An OON-enabled Internet is not only a\nglobal data delivery medium but also a universal object discovery and service\ndevelopment platform; service-level interactions can be realized through native\nnetwork means, without requiring standardized protocols. OON can be realized\nthrough existing software-defined networking or network functions\nvirtualization technologies and it can be deployed in an incremental fashion.\n", "contributors": [{"name": "Georgatsos, Panos", "sameAs": [], "familyName": "Georgatsos", "additionalName": "", "givenName": "Panos", "email": ""}, {"name": "Flegkas, Paris", "sameAs": [], "familyName": "Flegkas", "additionalName": "", "givenName": "Paris", "email": ""}, {"name": "Sourlas, Vasilis", "sameAs": [], "familyName": "Sourlas", "additionalName": "", "givenName": "Vasilis", "email": ""}, {"name": "Tassiulas, Leandros", "sameAs": [], "familyName": "Tassiulas", "additionalName": "", "givenName": "Leandros", "email": ""}], "title": "Object-Oriented Networking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07495", "oai:arXiv.org:1502.07495"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We propose the object-oriented networking (OON) framework, for meeting the\ngeneralized interconnection, mobility and technology integration requirements\nunderlining the Internet. In OON, the various objects that need to be accessed\nthrough the Internet (content, smart things, services, people, etc.) are viewed\nas network layer resources, rather than as application layer resources as in\nthe IP communications model. By abstracting them as computing objects -with\nattributes and methods- they are identified by expressive, discoverable names,\nwhile data are exchanged between them in the context of their methods, based on\nsuitably defined system-specific names. An OON-enabled Internet is not only a\nglobal data delivery medium but also a universal object discovery and service\ndevelopment platform; service-level interactions can be realized through native\nnetwork means, without requiring standardized protocols. OON can be realized\nthrough existing software-defined networking or network functions\nvirtualization technologies and it can be deployed in an incremental fashion.\n", "Comment: 7 pages, 1 figure"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-02-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07495"}}, {"publisher": {"name": ""}, "description": "  We study the computational complexity of exact minimisation of separable\nrational-valued discrete functions. Let $\\Gamma$ be a set of rational-valued\nfunctions on a fixed finite domain; such a set is called a finite-valued\nconstraint language. The valued constraint satisfaction problem,\n$\\operatorname{VCSP}(\\Gamma)$, is the problem of minimising a function given as\na sum of functions from $\\Gamma$. We establish a dichotomy theorem with respect\nto exact solvability for all finite-valued constraint languages defined on\ndomains of arbitrary finite size.\n  We show that every constraint language $\\Gamma$ either admits a binary\nsymmetric fractional polymorphism in which case the basic linear programming\nrelaxation solves any instance of $\\operatorname{VCSP}(\\Gamma)$ exactly, or\n$\\Gamma$ satisfies a simple hardness condition that allows for a\npolynomial-time reduction from Max-Cut to $\\operatorname{VCSP}(\\Gamma)$.\n", "contributors": [{"name": "Thapper, Johan", "sameAs": [], "familyName": "Thapper", "additionalName": "", "givenName": "Johan", "email": ""}, {"name": "Zivny, Stanislav", "sameAs": [], "familyName": "Zivny", "additionalName": "", "givenName": "Stanislav", "email": ""}], "title": "The complexity of finite-valued CSPs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-10-10", "2015-02-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1210.2987", "oai:arXiv.org:1210.2987"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study the computational complexity of exact minimisation of separable\nrational-valued discrete functions. Let $\\Gamma$ be a set of rational-valued\nfunctions on a fixed finite domain; such a set is called a finite-valued\nconstraint language. The valued constraint satisfaction problem,\n$\\operatorname{VCSP}(\\Gamma)$, is the problem of minimising a function given as\na sum of functions from $\\Gamma$. We establish a dichotomy theorem with respect\nto exact solvability for all finite-valued constraint languages defined on\ndomains of arbitrary finite size.\n  We show that every constraint language $\\Gamma$ either admits a binary\nsymmetric fractional polymorphism in which case the basic linear programming\nrelaxation solves any instance of $\\operatorname{VCSP}(\\Gamma)$ exactly, or\n$\\Gamma$ satisfies a simple hardness condition that allows for a\npolynomial-time reduction from Max-Cut to $\\operatorname{VCSP}(\\Gamma)$.\n", "Comment: A full version of a STOC'13 paper, submitted for journal publication"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "f.2.0"], "providerUpdatedDateTime": "2015-02-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1210.2987"}}, {"publisher": {"name": ""}, "description": "  In 1986, Spencer Bloch gave an abstract definition of a (regulator) map from\nhigher Chow groups to Deligne-Beilinson cohomology. This map can be defined on\nthe underlying complexes, and Kerr, Lewis and M\\\"uller-Stach gave an explicit\ndescription of this map in terms of currents. Using a multiplicative version of\nthe Deligne complex, we give a commutative version of this map.\n", "contributors": [{"name": "Wei\u00dfschuh, Thomas", "sameAs": [], "familyName": "Wei\u00dfschuh", "additionalName": "", "givenName": "Thomas", "email": ""}], "title": "A commutative regulator map into Deligne-Beilinson cohomology", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4686", "oai:arXiv.org:1410.4686"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  In 1986, Spencer Bloch gave an abstract definition of a (regulator) map from\nhigher Chow groups to Deligne-Beilinson cohomology. This map can be defined on\nthe underlying complexes, and Kerr, Lewis and M\\\"uller-Stach gave an explicit\ndescription of this map in terms of currents. Using a multiplicative version of\nthe Deligne complex, we give a commutative version of this map.\n"}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-10-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4686"}}, {"publisher": {"name": ""}, "description": "  The Hilbert space of probability mass functions (pmf) is introduced in this\nthesis. A factorization method for multivariate pmfs is proposed by using the\ntools provided by the Hilbert space of pmfs. The resulting factorization is\nspecial for two reasons. First, it reveals the algebraic relations between the\ninvolved random variables. Second, it determines the conditional independence\nrelations between the random variables. Due to the first property of the\nresulting factorization, it can be shown that channel decoders can be employed\nin the solution of probabilistic inference problems other than decoding. This\napproach might lead to new probabilistic inference algorithms and new hardware\noptions for the implementation of these algorithms. An example of new inference\nalgorithms inspired by the idea of using channel decoder for other inference\ntasks is a multiple-input multiple-output (MIMO) detection algorithm which has\na complexity of the square-root of the optimum MIMO detection algorithm.\n", "contributors": [{"name": "Bayramoglu, Muhammet Fatih", "sameAs": [], "familyName": "Bayramoglu", "additionalName": "Fatih", "givenName": "Muhammet", "email": ""}], "title": "The Hilbert Space of Probability Mass Functions and Applications on\n  Probabilistic Inference", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02940", "oai:arXiv.org:1502.02940"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The Hilbert space of probability mass functions (pmf) is introduced in this\nthesis. A factorization method for multivariate pmfs is proposed by using the\ntools provided by the Hilbert space of pmfs. The resulting factorization is\nspecial for two reasons. First, it reveals the algebraic relations between the\ninvolved random variables. Second, it determines the conditional independence\nrelations between the random variables. Due to the first property of the\nresulting factorization, it can be shown that channel decoders can be employed\nin the solution of probabilistic inference problems other than decoding. This\napproach might lead to new probabilistic inference algorithms and new hardware\noptions for the implementation of these algorithms. An example of new inference\nalgorithms inspired by the idea of using channel decoder for other inference\ntasks is a multiple-input multiple-output (MIMO) detection algorithm which has\na complexity of the square-root of the optimum MIMO detection algorithm.\n", "Comment: PhD Dissertation, 123 pages"]}}], "languages": [null], "subjects": ["computer science - information theory", "mathematics - probability"], "providerUpdatedDateTime": "2015-02-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02940"}}, {"publisher": {"name": ""}, "description": "  We present a method of solving the T-optimal design problem for nonlinear\ndynamical systems using dynamic programming. In contrast with previous dynamic\nprogramming formulations, we avoid adding an equation for the dispersion to the\nsystem state, allowing for more efficient solutions.\n", "contributors": [{"name": "Maidens, John", "sameAs": [], "familyName": "Maidens", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Arcak, Murat", "sameAs": [], "familyName": "Arcak", "additionalName": "", "givenName": "Murat", "email": ""}], "title": "A note on optimal experiment design for nonlinear systems using dynamic\n  programming", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07232", "oai:arXiv.org:1503.07232"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We present a method of solving the T-optimal design problem for nonlinear\ndynamical systems using dynamic programming. In contrast with previous dynamic\nprogramming formulations, we avoid adding an equation for the dispersion to the\nsystem state, allowing for more efficient solutions.\n", "Comment: 4 pages, 1 figure"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control"], "providerUpdatedDateTime": "2015-03-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07232"}}, {"publisher": {"name": ""}, "description": "  Given a context free language $L(G)$ over alphabet $\\Sigma$ and a string $s\n\\in \\Sigma^*$, the language edit distance (Lan-ED) problem seeks the minimum\nnumber of edits (insertions, deletions and substitutions) required to convert\n$s$ into a valid member of $L(G)$. The well-known dynamic programming algorithm\nsolves this problem in $O(n^3)$ time (ignoring grammar size) where $n$ is the\nstring length [Aho, Peterson 1972, Myers 1985]. Despite its vast number of\napplications, there is no algorithm known till date that computes or\napproximates Lan-ED in true sub-cubic time.\n  In this paper we give the first such algorithm that computes Lan-ED almost\noptimally. For any arbitrary $\\epsilon > 0$, our algorithm runs in\n$\\tilde{O}(\\frac{n^{\\omega}}{poly(\\epsilon)})$ time and returns an estimate\nwithin a multiplicative approximation factor of $(1+\\epsilon)$, where $\\omega$\nis the exponent of ordinary matrix multiplication of $n$ dimensional square\nmatrices. It also computes the edit script. Further, for all substrings of $s$,\nwe can estimate their Lan-ED within $(1\\pm \\epsilon)$ factor in\n$\\tilde{O}(\\frac{n^{\\omega}}{poly(\\epsilon)})$ time with high probability. We\nalso design the very first sub-cubic ($\\tilde{O}(n^\\omega)$) algorithm to\nhandle arbitrary stochastic context free grammar (SCFG) parsing. SCFGs lie the\nfoundation of statistical natural language processing, they generalize hidden\nMarkov models, and have found widespread applications.\n  To complement our upper bound result, we show that exact computation of\nLan-ED in true sub-cubic time will imply a truly sub-cubic algorithm for\nall-pairs shortest paths. This will result in a breakthrough for a large range\nof problems in graphs and matrices due to sub-cubic equivalence. By a known\nlower bound result [Lee 2002], improving upon our time bound of $O(n^\\omega)$\nfor any nontrivial multiplicative approximation is (almost) not possible.\n", "contributors": [{"name": "Saha, Barna", "sameAs": [], "familyName": "Saha", "additionalName": "", "givenName": "Barna", "email": ""}], "title": "Faster Language Edit Distance, Connection to All-pairs Shortest Paths\n  and Related Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7315", "oai:arXiv.org:1411.7315"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Given a context free language $L(G)$ over alphabet $\\Sigma$ and a string $s\n\\in \\Sigma^*$, the language edit distance (Lan-ED) problem seeks the minimum\nnumber of edits (insertions, deletions and substitutions) required to convert\n$s$ into a valid member of $L(G)$. The well-known dynamic programming algorithm\nsolves this problem in $O(n^3)$ time (ignoring grammar size) where $n$ is the\nstring length [Aho, Peterson 1972, Myers 1985]. Despite its vast number of\napplications, there is no algorithm known till date that computes or\napproximates Lan-ED in true sub-cubic time.\n  In this paper we give the first such algorithm that computes Lan-ED almost\noptimally. For any arbitrary $\\epsilon > 0$, our algorithm runs in\n$\\tilde{O}(\\frac{n^{\\omega}}{poly(\\epsilon)})$ time and returns an estimate\nwithin a multiplicative approximation factor of $(1+\\epsilon)$, where $\\omega$\nis the exponent of ordinary matrix multiplication of $n$ dimensional square\nmatrices. It also computes the edit script. Further, for all substrings of $s$,\nwe can estimate their Lan-ED within $(1\\pm \\epsilon)$ factor in\n$\\tilde{O}(\\frac{n^{\\omega}}{poly(\\epsilon)})$ time with high probability. We\nalso design the very first sub-cubic ($\\tilde{O}(n^\\omega)$) algorithm to\nhandle arbitrary stochastic context free grammar (SCFG) parsing. SCFGs lie the\nfoundation of statistical natural language processing, they generalize hidden\nMarkov models, and have found widespread applications.\n  To complement our upper bound result, we show that exact computation of\nLan-ED in true sub-cubic time will imply a truly sub-cubic algorithm for\nall-pairs shortest paths. This will result in a breakthrough for a large range\nof problems in graphs and matrices due to sub-cubic equivalence. By a known\nlower bound result [Lee 2002], improving upon our time bound of $O(n^\\omega)$\nfor any nontrivial multiplicative approximation is (almost) not possible.\n", "Comment: 39 pages"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2014-11-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7315"}}, {"publisher": {"name": ""}, "description": "  In this contribution, we develop an accurate and effective event detection\nmethod to detect events from a Twitter stream, which uses visual and textual\ninformation to improve the performance of the mining process. The method\nmonitors a Twitter stream to pick up tweets having texts and images and stores\nthem into a database. This is followed by applying a mining algorithm to detect\nan event. The procedure starts with detecting events based on text only by\nusing the feature of the bag-of-words which is calculated using the term\nfrequency-inverse document frequency (TF-IDF) method. Then it detects the event\nbased on image only by using visual features including histogram of oriented\ngradients (HOG) descriptors, grey-level cooccurrence matrix (GLCM), and color\nhistogram. K nearest neighbours (Knn) classification is used in the detection.\nThe final decision of the event detection is made based on the reliabilities of\ntext only detection and image only detection. The experiment result showed that\nthe proposed method achieved high accuracy of 0.94, comparing with 0.89 with\ntexts only, and 0.86 with images only.\n", "contributors": [{"name": "Alqhtani, Samar M.", "sameAs": [], "familyName": "Alqhtani", "additionalName": "M.", "givenName": "Samar", "email": ""}, {"name": "Luo, Suhuai", "sameAs": [], "familyName": "Luo", "additionalName": "", "givenName": "Suhuai", "email": ""}, {"name": "Regan, Brian", "sameAs": [], "familyName": "Regan", "additionalName": "", "givenName": "Brian", "email": ""}], "title": "Fusing Text and Image for Event Detection in Twitter", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03920", "doi:10.5121/ijma.2015.7103", "oai:arXiv.org:1503.03920"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this contribution, we develop an accurate and effective event detection\nmethod to detect events from a Twitter stream, which uses visual and textual\ninformation to improve the performance of the mining process. The method\nmonitors a Twitter stream to pick up tweets having texts and images and stores\nthem into a database. This is followed by applying a mining algorithm to detect\nan event. The procedure starts with detecting events based on text only by\nusing the feature of the bag-of-words which is calculated using the term\nfrequency-inverse document frequency (TF-IDF) method. Then it detects the event\nbased on image only by using visual features including histogram of oriented\ngradients (HOG) descriptors, grey-level cooccurrence matrix (GLCM), and color\nhistogram. K nearest neighbours (Knn) classification is used in the detection.\nThe final decision of the event detection is made based on the reliabilities of\ntext only detection and image only detection. The experiment result showed that\nthe proposed method achieved high accuracy of 0.94, comparing with 0.89 with\ntexts only, and 0.86 with images only.\n", "Comment: 9 Pages, 4 figuers"]}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - multimedia"], "providerUpdatedDateTime": "2015-03-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03920"}}, {"publisher": {"name": ""}, "description": "  Magnetic shape memory alloys are characterized by the coupling between a\nstructural phase transition and magnetic one. This permits to control the shape\nchange via an external magnetic field, at least in single crystals. Composite\nmaterials with single-crystalline particles embedded in a softer matrix have\nbeen proposed as a way to overcome the blocking of the transformation at grain\nboundaries. We investigate hysteresis phenomena for small NiMnGa single\ncrystals embedded in a polymer matrix for slowly varying magnetic fields. The\nevolution of the microstructure is studied within the rate-independent\nvariational framework proposed by Mielke and Theil (1999). The underlying\nvariational model incorporates linearized elasticity, micromagnetism, stray\nfield and a dissipation term proportional to the volume swept by the phase\nboundary. The time discretization is based on an incremental minimization of\nthe sum of energy and dissipation. A backtracking approach is employed to\napproximately ensure the global minimality condition. We illustrate and discuss\nthe influence of the particle geometry (volume fraction, shape, arrangement)\nand the polymer elastic parameters on the observed hysteresis and compare with\nrecent experimental results.\n", "contributors": [{"name": "Conti, Sergio", "sameAs": [], "familyName": "Conti", "additionalName": "", "givenName": "Sergio", "email": ""}, {"name": "Lenz, Martin", "sameAs": [], "familyName": "Lenz", "additionalName": "", "givenName": "Martin", "email": ""}, {"name": "Rumpf, Martin", "sameAs": [], "familyName": "Rumpf", "additionalName": "", "givenName": "Martin", "email": ""}], "title": "Hysteresis in Magnetic Shape Memory Composites: Modeling and Simulation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.05608", "oai:arXiv.org:1502.05608"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Magnetic shape memory alloys are characterized by the coupling between a\nstructural phase transition and magnetic one. This permits to control the shape\nchange via an external magnetic field, at least in single crystals. Composite\nmaterials with single-crystalline particles embedded in a softer matrix have\nbeen proposed as a way to overcome the blocking of the transformation at grain\nboundaries. We investigate hysteresis phenomena for small NiMnGa single\ncrystals embedded in a polymer matrix for slowly varying magnetic fields. The\nevolution of the microstructure is studied within the rate-independent\nvariational framework proposed by Mielke and Theil (1999). The underlying\nvariational model incorporates linearized elasticity, micromagnetism, stray\nfield and a dissipation term proportional to the volume swept by the phase\nboundary. The time discretization is based on an incremental minimization of\nthe sum of energy and dissipation. A backtracking approach is employed to\napproximately ensure the global minimality condition. We illustrate and discuss\nthe influence of the particle geometry (volume fraction, shape, arrangement)\nand the polymer elastic parameters on the observed hysteresis and compare with\nrecent experimental results.\n", "Comment: 18 pages, 11 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "mathematics - numerical analysis", "74f15", "74n30 (primary)", "74s15 (secondary)"], "providerUpdatedDateTime": "2015-02-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.05608"}}, {"publisher": {"name": ""}, "description": "  In contrast to the existing approaches to bisimulation for fuzzy systems, we\nintroduce a behavioral distance to measure the behavioral similarity of states\nin a nondeterministic fuzzy-transition system. This behavioral distance is\ndefined as the greatest fixed point of a suitable monotonic function and\nprovides a quantitative analogue of bisimilarity. The behavioral distance has\nthe important property that two states are at zero distance if and only if they\nare bisimilar. Moreover, for any given threshold, we find that states with\nbehavioral distances bounded by the threshold are equivalent. In addition, we\nshow that two system combinators---parallel composition and product---are\nnon-expansive with respect to our behavioral distance, which makes\ncompositional verification possible.\n", "contributors": [{"name": "Cao, Yongzhi", "sameAs": [], "familyName": "Cao", "additionalName": "", "givenName": "Yongzhi", "email": ""}, {"name": "Wang, Huaiqing", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Huaiqing", "email": ""}, {"name": "Sun, Sherry X.", "sameAs": [], "familyName": "Sun", "additionalName": "X.", "givenName": "Sherry", "email": ""}, {"name": "Chen, Guoqing", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Guoqing", "email": ""}], "title": "A Behavioral Distance for Fuzzy-Transition Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-10-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1110.0248", "oai:arXiv.org:1110.0248"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In contrast to the existing approaches to bisimulation for fuzzy systems, we\nintroduce a behavioral distance to measure the behavioral similarity of states\nin a nondeterministic fuzzy-transition system. This behavioral distance is\ndefined as the greatest fixed point of a suitable monotonic function and\nprovides a quantitative analogue of bisimilarity. The behavioral distance has\nthe important property that two states are at zero distance if and only if they\nare bisimilar. Moreover, for any given threshold, we find that states with\nbehavioral distances bounded by the threshold are equivalent. In addition, we\nshow that two system combinators---parallel composition and product---are\nnon-expansive with respect to our behavioral distance, which makes\ncompositional verification possible.\n", "Comment: 12 double column pages"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1110.0248"}}, {"publisher": {"name": ""}, "description": "  We present an approach for penalized tensor decomposition (PTD) that\nestimates smoothly varying latent factors in multi-way data. This generalizes\nexisting work on sparse tensor decomposition and penalized matrix\ndecompositions, in a manner parallel to the generalized lasso of Tibshirani and\nTaylor (2011) for regression and smoothing problems. Our approach presents many\nnontrivial challenges at the intersection of modeling and computation, which\nare studied in detail. An efficient coordinate-wise optimization algorithm for\n(PTD) is presented, and its convergence properties are characterized. The\nmethod is applied both to simulated data and real data on flu hospitalizations\nin Texas. These results show that our penalized tensor decomposition can offer\nmajor improvements on existing methods for analyzing multi-way data that\nexhibit smooth spatial or temporal features.\n", "contributors": [{"name": "Padilla, Oscar Hernan Madrid", "sameAs": [], "familyName": "Padilla", "additionalName": "Hernan Madrid", "givenName": "Oscar", "email": ""}, {"name": "Scott, James G.", "sameAs": [], "familyName": "Scott", "additionalName": "G.", "givenName": "James", "email": ""}], "title": "Tensor decomposition with generalized lasso penalties", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06930", "oai:arXiv.org:1502.06930"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  We present an approach for penalized tensor decomposition (PTD) that\nestimates smoothly varying latent factors in multi-way data. This generalizes\nexisting work on sparse tensor decomposition and penalized matrix\ndecompositions, in a manner parallel to the generalized lasso of Tibshirani and\nTaylor (2011) for regression and smoothing problems. Our approach presents many\nnontrivial challenges at the intersection of modeling and computation, which\nare studied in detail. An efficient coordinate-wise optimization algorithm for\n(PTD) is presented, and its convergence properties are characterized. The\nmethod is applied both to simulated data and real data on flu hospitalizations\nin Texas. These results show that our penalized tensor decomposition can offer\nmajor improvements on existing methods for analyzing multi-way data that\nexhibit smooth spatial or temporal features.\n"}}], "languages": [null], "subjects": ["statistics - computation", "statistics - methodology", "statistics - machine learning"], "providerUpdatedDateTime": "2015-02-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06930"}}, {"publisher": {"name": ""}, "description": "  Policy search methods based on reinforcement learning and optimal control can\nallow robots to automatically learn a wide range of tasks. However, practical\napplications of policy search tend to require the policy to be supported by\nhand-engineered components for perception, state estimation, and low-level\ncontrol. We propose a method for learning policies that map raw, low-level\nobservations, consisting of joint angles and camera images, directly to the\ntorques at the robot's joints. The policies are represented as deep\nconvolutional neural networks (CNNs) with 92,000 parameters. The high\ndimensionality of such policies poses a tremendous challenge for policy search.\nTo address this challenge, we develop a sensorimotor guided policy search\nmethod that can handle high-dimensional policies and partially observed tasks.\nWe use BADMM to decompose policy search into an optimal control phase and\nsupervised learning phase, allowing CNN policies to be trained with standard\nsupervised learning techniques. This method can learn a number of manipulation\ntasks that require close coordination between vision and control, including\ninserting a block into a shape sorting cube, screwing on a bottle cap, fitting\nthe claw of a toy hammer under a nail with various grasps, and placing a coat\nhanger on a clothes rack.\n", "contributors": [{"name": "Levine, Sergey", "sameAs": [], "familyName": "Levine", "additionalName": "", "givenName": "Sergey", "email": ""}, {"name": "Finn, Chelsea", "sameAs": [], "familyName": "Finn", "additionalName": "", "givenName": "Chelsea", "email": ""}, {"name": "Darrell, Trevor", "sameAs": [], "familyName": "Darrell", "additionalName": "", "givenName": "Trevor", "email": ""}, {"name": "Abbeel, Pieter", "sameAs": [], "familyName": "Abbeel", "additionalName": "", "givenName": "Pieter", "email": ""}], "title": "End-to-End Training of Deep Visuomotor Policies", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.00702", "oai:arXiv.org:1504.00702"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Policy search methods based on reinforcement learning and optimal control can\nallow robots to automatically learn a wide range of tasks. However, practical\napplications of policy search tend to require the policy to be supported by\nhand-engineered components for perception, state estimation, and low-level\ncontrol. We propose a method for learning policies that map raw, low-level\nobservations, consisting of joint angles and camera images, directly to the\ntorques at the robot's joints. The policies are represented as deep\nconvolutional neural networks (CNNs) with 92,000 parameters. The high\ndimensionality of such policies poses a tremendous challenge for policy search.\nTo address this challenge, we develop a sensorimotor guided policy search\nmethod that can handle high-dimensional policies and partially observed tasks.\nWe use BADMM to decompose policy search into an optimal control phase and\nsupervised learning phase, allowing CNN policies to be trained with standard\nsupervised learning techniques. This method can learn a number of manipulation\ntasks that require close coordination between vision and control, including\ninserting a block into a shape sorting cube, screwing on a bottle cap, fitting\nthe claw of a toy hammer under a nail with various grasps, and placing a coat\nhanger on a clothes rack.\n"}}], "languages": [null], "subjects": ["computer science - robotics", "computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.00702"}}, {"publisher": {"name": ""}, "description": "  We empirically analyze two versions of the well-known \"randomized rumor\nspreading\" protocol to disseminate a piece of information in networks. In the\nclassical model, in each round each informed node informs a random neighbor. In\nthe recently proposed quasirandom variant, each node has a (cyclic) list of its\nneighbors. Once informed, it starts at a random position of the list, but from\nthen on informs its neighbors in the order of the list. While for sparse random\ngraphs a better performance of the quasirandom model could be proven, all other\nresults show that, independent of the structure of the lists, the same\nasymptotic performance guarantees hold as for the classical model. In this\nwork, we compare the two models experimentally. This not only shows that the\nquasirandom model generally is faster, but also that the runtime is more\nconcentrated around the mean. This is surprising given that much fewer random\nbits are used in the quasirandom process. These advantages are also observed in\na lossy communication model, where each transmission does not reach its target\nwith a certain probability, and in an asynchronous model, where nodes send at\nrandom times drawn from an exponential distribution. We also show that\ntypically the particular structure of the lists has little influence on the\nefficiency.\n", "contributors": [{"name": "Doerr, Benjamin", "sameAs": [], "familyName": "Doerr", "additionalName": "", "givenName": "Benjamin", "email": ""}, {"name": "Friedrich, Tobias", "sameAs": [], "familyName": "Friedrich", "additionalName": "", "givenName": "Tobias", "email": ""}, {"name": "K\u00fcnnemann, Marvin", "sameAs": [], "familyName": "K\u00fcnnemann", "additionalName": "", "givenName": "Marvin", "email": ""}, {"name": "Sauerwald, Thomas", "sameAs": [], "familyName": "Sauerwald", "additionalName": "", "givenName": "Thomas", "email": ""}], "title": "Quasirandom Rumor Spreading: An Experimental Analysis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-12-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1012.5357", "oai:arXiv.org:1012.5357"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We empirically analyze two versions of the well-known \"randomized rumor\nspreading\" protocol to disseminate a piece of information in networks. In the\nclassical model, in each round each informed node informs a random neighbor. In\nthe recently proposed quasirandom variant, each node has a (cyclic) list of its\nneighbors. Once informed, it starts at a random position of the list, but from\nthen on informs its neighbors in the order of the list. While for sparse random\ngraphs a better performance of the quasirandom model could be proven, all other\nresults show that, independent of the structure of the lists, the same\nasymptotic performance guarantees hold as for the classical model. In this\nwork, we compare the two models experimentally. This not only shows that the\nquasirandom model generally is faster, but also that the runtime is more\nconcentrated around the mean. This is surprising given that much fewer random\nbits are used in the quasirandom process. These advantages are also observed in\na lossy communication model, where each transmission does not reach its target\nwith a certain probability, and in an asynchronous model, where nodes send at\nrandom times drawn from an exponential distribution. We also show that\ntypically the particular structure of the lists has little influence on the\nefficiency.\n", "Comment: 14 pages, appeared in ALENEX'09"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "f.2.2", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1012.5357"}}, {"publisher": {"name": ""}, "description": "  In this paper, we describe a new neuro-inspired, hardware-friendly readout\nstage for the liquid state machine (LSM), a popular model for reservoir\ncomputing. Compared to the parallel perceptron architecture trained by the\np-delta algorithm, which is the state of the art in terms of performance of\nreadout stages, our readout architecture and learning algorithm can attain\nbetter performance with significantly less synaptic resources making it\nattractive for VLSI implementation. Inspired by the nonlinear properties of\ndendrites in biological neurons, our readout stage incorporates neurons having\nmultiple dendrites with a lumped nonlinearity. The number of synaptic\nconnections on each branch is significantly lower than the total number of\nconnections from the liquid neurons and the learning algorithm tries to find\nthe best 'combination' of input connections on each branch to reduce the error.\nHence, the learning involves network rewiring (NRW) of the readout network\nsimilar to structural plasticity observed in its biological counterparts. We\nshow that compared to a single perceptron using analog weights, this\narchitecture for the readout can attain, even by using the same number of\nbinary valued synapses, up to 3.3 times less error for a two-class spike train\nclassification problem and 2.4 times less error for an input rate approximation\ntask. Even with 60 times larger synapses, a group of 60 parallel perceptrons\ncannot attain the performance of the proposed dendritically enhanced readout.\nAn additional advantage of this method for hardware implementations is that the\n'choice' of connectivity can be easily implemented exploiting address event\nrepresentation (AER) protocols commonly used in current neuromorphic systems\nwhere the connection matrix is stored in memory. Also, due to the use of binary\nsynapses, our proposed method is more robust against statistical variations.\n", "contributors": [{"name": "Roy, Subhrajit", "sameAs": [], "familyName": "Roy", "additionalName": "", "givenName": "Subhrajit", "email": ""}, {"name": "Banerjee, Amitava", "sameAs": [], "familyName": "Banerjee", "additionalName": "", "givenName": "Amitava", "email": ""}, {"name": "Basu, Arindam", "sameAs": [], "familyName": "Basu", "additionalName": "", "givenName": "Arindam", "email": ""}], "title": "Liquid State Machine with Dendritically Enhanced Readout for Low-power,\n  Neuromorphic VLSI Implementations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5458", "IEEE Transactions on Biomedical Circuits and Systems, vol.8, no.5,\n  pp.681,695, Oct. 2014", "doi:10.1109/TBCAS.2014.2362969", "oai:arXiv.org:1411.5458"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we describe a new neuro-inspired, hardware-friendly readout\nstage for the liquid state machine (LSM), a popular model for reservoir\ncomputing. Compared to the parallel perceptron architecture trained by the\np-delta algorithm, which is the state of the art in terms of performance of\nreadout stages, our readout architecture and learning algorithm can attain\nbetter performance with significantly less synaptic resources making it\nattractive for VLSI implementation. Inspired by the nonlinear properties of\ndendrites in biological neurons, our readout stage incorporates neurons having\nmultiple dendrites with a lumped nonlinearity. The number of synaptic\nconnections on each branch is significantly lower than the total number of\nconnections from the liquid neurons and the learning algorithm tries to find\nthe best 'combination' of input connections on each branch to reduce the error.\nHence, the learning involves network rewiring (NRW) of the readout network\nsimilar to structural plasticity observed in its biological counterparts. We\nshow that compared to a single perceptron using analog weights, this\narchitecture for the readout can attain, even by using the same number of\nbinary valued synapses, up to 3.3 times less error for a two-class spike train\nclassification problem and 2.4 times less error for an input rate approximation\ntask. Even with 60 times larger synapses, a group of 60 parallel perceptrons\ncannot attain the performance of the proposed dendritically enhanced readout.\nAn additional advantage of this method for hardware implementations is that the\n'choice' of connectivity can be easily implemented exploiting address event\nrepresentation (AER) protocols commonly used in current neuromorphic systems\nwhere the connection matrix is stored in memory. Also, due to the use of binary\nsynapses, our proposed method is more robust against statistical variations.\n", "Comment: 14 pages, 19 figures, Journal"]}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - emerging technologies"], "providerUpdatedDateTime": "2014-11-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5458"}}, {"publisher": {"name": ""}, "description": "  Most categorical models of meaning use a functor from the syntactic category\nto the semantic category. When semantic information is available, the problem\nof grammar induction can therefore be defined as finding preimages of the\nsemantic types under this forgetful functor, lifting the information flow from\nthe semantic level to a valid reduction at the syntactic level. We study the\ncomplexity of grammar induction, and show that for a variety of type systems,\nincluding pivotal and compact closed categories, the grammar induction problem\nis NP-complete. Our approach could be extended to linguistic type systems such\nas autonomous or bi-closed categories.\n", "contributors": [{"name": "Delpeuch, Antonin", "sameAs": [], "familyName": "Delpeuch", "additionalName": "", "givenName": "Antonin", "email": ""}], "title": "Complexity of Grammar Induction for Quantum Types", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-13", "2014-12-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.3925", "EPTCS 172, 2014, pp. 236-248", "doi:10.4204/EPTCS.172.16", "oai:arXiv.org:1404.3925"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Most categorical models of meaning use a functor from the syntactic category\nto the semantic category. When semantic information is available, the problem\nof grammar induction can therefore be defined as finding preimages of the\nsemantic types under this forgetful functor, lifting the information flow from\nthe semantic level to a valid reduction at the syntactic level. We study the\ncomplexity of grammar induction, and show that for a variety of type systems,\nincluding pivotal and compact closed categories, the grammar induction problem\nis NP-complete. Our approach could be extended to linguistic type systems such\nas autonomous or bi-closed categories.\n", "Comment: In Proceedings QPL 2014, arXiv:1412.8102"]}}], "languages": [null], "subjects": ["mathematics - category theory", "computer science - computation and language"], "providerUpdatedDateTime": "2014-12-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.3925"}}, {"publisher": {"name": ""}, "description": "  The universe of potentially interesting, searchable literature is expanding\ncontinuously. Besides the normal expansion, there is an additional influx of\nliterature because of interdisciplinary boundaries becoming more and more\ndiffuse. Hence, the need for accurate, efficient and intelligent search tools\nis bigger than ever. Even with a sophisticated search engine, looking for\ninformation can still result in overwhelming results. An overload of\ninformation has the intrinsic danger of scaring visitors away, and any\norganization, for-profit or not-for-profit, in the business of providing\nscholarly information wants to capture and keep the attention of its target\naudience. Publishers and search engine engineers alike will benefit from a\nservice that is able to provide visitors with recommendations that closely meet\ntheir interests. Providing visitors with special deals, new options and\nhighlights may be interesting to a certain degree, but what makes more sense\n(especially from a commercial point of view) than to let visitors do most of\nthe work by the mere action of making choices? Hiring psychics is not an\noption, so a technological solution is needed to recommend items that a visitor\nis likely to be looking for. In this presentation we will introduce such a\nsolution and argue that it is practically feasible to incorporate this approach\ninto a useful addition to any information retrieval system with enough usage.\n", "contributors": [{"name": "Henneken, Edwin A.", "sameAs": [], "familyName": "Henneken", "additionalName": "A.", "givenName": "Edwin", "email": ""}, {"name": "Kurtz, Michael J.", "sameAs": [], "familyName": "Kurtz", "additionalName": "J.", "givenName": "Michael", "email": ""}, {"name": "Accomazzi, Alberto", "sameAs": [], "familyName": "Accomazzi", "additionalName": "", "givenName": "Alberto", "email": ""}, {"name": "Grant, Carolyn", "sameAs": [], "familyName": "Grant", "additionalName": "", "givenName": "Carolyn", "email": ""}, {"name": "Thompson, Donna", "sameAs": [], "familyName": "Thompson", "additionalName": "", "givenName": "Donna", "email": ""}, {"name": "Bohlen, Elizabeth", "sameAs": [], "familyName": "Bohlen", "additionalName": "", "givenName": "Elizabeth", "email": ""}, {"name": "Di Milia, Giovanni", "sameAs": [], "familyName": "Di Milia", "additionalName": "", "givenName": "Giovanni", "email": ""}, {"name": "Luker, Jay", "sameAs": [], "familyName": "Luker", "additionalName": "", "givenName": "Jay", "email": ""}, {"name": "Murray, Stephen S.", "sameAs": [], "familyName": "Murray", "additionalName": "S.", "givenName": "Stephen", "email": ""}], "title": "Finding Your Literature Match -- A Recommender System", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-05-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.2308", "oai:arXiv.org:1005.2308"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The universe of potentially interesting, searchable literature is expanding\ncontinuously. Besides the normal expansion, there is an additional influx of\nliterature because of interdisciplinary boundaries becoming more and more\ndiffuse. Hence, the need for accurate, efficient and intelligent search tools\nis bigger than ever. Even with a sophisticated search engine, looking for\ninformation can still result in overwhelming results. An overload of\ninformation has the intrinsic danger of scaring visitors away, and any\norganization, for-profit or not-for-profit, in the business of providing\nscholarly information wants to capture and keep the attention of its target\naudience. Publishers and search engine engineers alike will benefit from a\nservice that is able to provide visitors with recommendations that closely meet\ntheir interests. Providing visitors with special deals, new options and\nhighlights may be interesting to a certain degree, but what makes more sense\n(especially from a commercial point of view) than to let visitors do most of\nthe work by the mere action of making choices? Hiring psychics is not an\noption, so a technological solution is needed to recommend items that a visitor\nis likely to be looking for. In this presentation we will introduce such a\nsolution and argue that it is practically feasible to incorporate this approach\ninto a useful addition to any information retrieval system with enough usage.\n", "Comment: Contribution to the proceedings of the colloquium Future Professional\n  Communication in Astronomy II, 13-14 April 2010, Cambridge, Massachusetts. 11\n  pages, 4 figures."]}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - digital libraries"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.2308"}}, {"publisher": {"name": ""}, "description": "  This paper present the mathematical fundaments and experimental study of an\nalgorithm used to find the optimal position for the camera lens to obtain a\nmaximum of details. This information can be further applied to a appropriate\nsystem to automatically correct this position. The algorithm is based on the\nevaluation of a so called resolution function who calculates the maximum of\ngradient in a certain zone of the image. The paper also presents alternative\nforms of the function, results of measurements and set up a set of practical\nrules for the right application of the algorithm.\n", "contributors": [{"name": "Arsinte, Radu", "sameAs": [], "familyName": "Arsinte", "additionalName": "", "givenName": "Radu", "email": ""}], "title": "Study of a Robust Algorithm Applied in the Optimal Position Tuning for\n  the Camera Lens in Automated Visual Inspection Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06081", "Proceedings of Fifth International Conference on Pattern\n  Recognition and Information Processing - PRIP'99 - May 18-20, 1999 Minsk,\n  Belarus - pag.237-242 - ISBN 83-87362-16-6", "oai:arXiv.org:1502.06081"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper present the mathematical fundaments and experimental study of an\nalgorithm used to find the optimal position for the camera lens to obtain a\nmaximum of details. This information can be further applied to a appropriate\nsystem to automatically correct this position. The algorithm is based on the\nevaluation of a so called resolution function who calculates the maximum of\ngradient in a certain zone of the image. The paper also presents alternative\nforms of the function, results of measurements and set up a set of practical\nrules for the right application of the algorithm.\n", "Comment: 5 pages, 2 figures"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06081"}}, {"publisher": {"name": ""}, "description": "  Detailed description of procedures around architecture reviews. In order to\nsucceed in building and deploying complex software solutions, an architecture\nis essential. For many in the industry structured reviews of these\narchitectures is also de rigor. Practices for such reviews have been developed\nand reported on for years. One aspect that does not receive as much attention\nbut is no less important is the relationship between these architectures and\nthe requirements for deploying them into production environments. At Wolters\nKluwer's Corporate Legal Services we first established a typical architecture\nreview process and then established a two phase production preparation review\nprocess. This paper describes in detail how these practices work and some of\nthe technical results of these reviews including the frequency and style of the\nreviews, the process automation around them, and the number and nature of some\nof the technical flaws eliminated by enforcing these reviews. This paper lays\nthe ground work for others who would be interested in following similar\npractices.\n", "contributors": [{"name": "Cusick, James", "sameAs": [], "familyName": "Cusick", "additionalName": "", "givenName": "James", "email": ""}], "title": "Architecture and Production Readiness Reviews in Practice", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-05-10", "2014-12-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1305.2402", "oai:arXiv.org:1305.2402"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Detailed description of procedures around architecture reviews. In order to\nsucceed in building and deploying complex software solutions, an architecture\nis essential. For many in the industry structured reviews of these\narchitectures is also de rigor. Practices for such reviews have been developed\nand reported on for years. One aspect that does not receive as much attention\nbut is no less important is the relationship between these architectures and\nthe requirements for deploying them into production environments. At Wolters\nKluwer's Corporate Legal Services we first established a typical architecture\nreview process and then established a two phase production preparation review\nprocess. This paper describes in detail how these practices work and some of\nthe technical results of these reviews including the frequency and style of the\nreviews, the process automation around them, and the number and nature of some\nof the technical flaws eliminated by enforcing these reviews. This paper lays\nthe ground work for others who would be interested in following similar\npractices.\n"}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-01-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1305.2402"}}, {"publisher": {"name": ""}, "description": "  Modern spreadsheet systems can be used to implement complex spreadsheet\napplications including data sheets, customized user forms and executable\nprocedures written in a scripting language. These applications are often\ndeveloped by practitioners that do not follow any software engineering practice\nand do not produce any design documentation. Thus, spreadsheet applications may\nbe very difficult to be maintained or restructured. In this position paper we\npresent in a nutshell two reverse engineering techniques and a tool that we are\ncurrently realizing for the abstraction of conceptual data models and business\nlogic models.\n", "contributors": [{"name": "Amalfitano, Domenico", "sameAs": [], "familyName": "Amalfitano", "additionalName": "", "givenName": "Domenico", "email": ""}, {"name": "Amatucci, Nicola", "sameAs": [], "familyName": "Amatucci", "additionalName": "", "givenName": "Nicola", "email": ""}, {"name": "De Simone, Vincenzo", "sameAs": [], "familyName": "De Simone", "additionalName": "", "givenName": "Vincenzo", "email": ""}, {"name": "Fasolino, Anna Rita", "sameAs": [], "familyName": "Fasolino", "additionalName": "Rita", "givenName": "Anna", "email": ""}, {"name": "Tramontana, Porfirio", "sameAs": [], "familyName": "Tramontana", "additionalName": "", "givenName": "Porfirio", "email": ""}], "title": "Toward Reverse Engineering of VBA Based Excel Spreadsheet Applications", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03401", "oai:arXiv.org:1503.03401"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Modern spreadsheet systems can be used to implement complex spreadsheet\napplications including data sheets, customized user forms and executable\nprocedures written in a scripting language. These applications are often\ndeveloped by practitioners that do not follow any software engineering practice\nand do not produce any design documentation. Thus, spreadsheet applications may\nbe very difficult to be maintained or restructured. In this position paper we\npresent in a nutshell two reverse engineering techniques and a tool that we are\ncurrently realizing for the abstraction of conceptual data models and business\nlogic models.\n", "Comment: In Proceedings of the 2nd Workshop on Software Engineering Methods in\n  Spreadsheets (http://spreadsheetlab.org/sems15/)"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-03-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03401"}}, {"publisher": {"name": ""}, "description": "  We propose to augment rating based recommender systems by providing the user\nwith additional information which might help him in his choice or in the\nunderstanding of the recommendation. We consider here as a new task, the\ngeneration of personalized reviews associated to items. We use an extractive\nsummary formulation for generating these reviews. We also show that the two\ninformation sources, ratings and items could be used both for estimating\nratings and for generating summaries, leading to improved performance for each\nsystem compared to the use of a single source. Besides these two contributions,\nwe show how a personalized polarity classifier can integrate the rating and\ntextual aspects. Overall, the proposed system offers the user three\npersonalized hints for a recommendation: rating, text and polarity. We evaluate\nthese three components on two datasets using appropriate measures for each\ntask.\n", "contributors": [{"name": "Poussevin, Micka\u00ebl", "sameAs": [], "familyName": "Poussevin", "additionalName": "", "givenName": "Micka\u00ebl", "email": ""}, {"name": "Guigue, Vincent", "sameAs": [], "familyName": "Guigue", "additionalName": "", "givenName": "Vincent", "email": ""}, {"name": "Gallinari, Patrick", "sameAs": [], "familyName": "Gallinari", "additionalName": "", "givenName": "Patrick", "email": ""}], "title": "Extended Recommendation Framework: Generating the Text of a User Review\n  as a Personalized Summary", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5448", "oai:arXiv.org:1412.5448"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We propose to augment rating based recommender systems by providing the user\nwith additional information which might help him in his choice or in the\nunderstanding of the recommendation. We consider here as a new task, the\ngeneration of personalized reviews associated to items. We use an extractive\nsummary formulation for generating these reviews. We also show that the two\ninformation sources, ratings and items could be used both for estimating\nratings and for generating summaries, leading to improved performance for each\nsystem compared to the use of a single source. Besides these two contributions,\nwe show how a personalized polarity classifier can integrate the rating and\ntextual aspects. Overall, the proposed system offers the user three\npersonalized hints for a recommendation: rating, text and polarity. We evaluate\nthese three components on two datasets using appropriate measures for each\ntask.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - computation and language"], "providerUpdatedDateTime": "2014-12-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5448"}}, {"publisher": {"name": "eScholarship, University of California"}, "description": "", "contributors": [{"name": "McCubbins, Colin H", "sameAs": [], "familyName": "McCubbins", "additionalName": "H", "givenName": "Colin", "email": ""}, {"name": "McCubbins, Mathew D", "sameAs": [], "familyName": "McCubbins", "additionalName": "D", "givenName": "Mathew", "email": ""}], "title": "Proposition 13 and The California Fiscal Shell Game", "shareProperties": {"source": "ucescholarship"}, "otherProperties": [{"name": "type", "properties": {"type": "article"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2010-02-03"}}, {"name": "identifier", "properties": {"identifier": ["qt400320ph", "http://www.escholarship.org/uc/item/400320ph", "qt400320ph"]}}, {"name": "setSpec", "properties": {"setSpec": []}}, {"name": "source", "properties": {"source": "McCubbins, Colin H; & McCubbins, Mathew D. (2010). Proposition 13 and The California Fiscal Shell Game. California Journal of Politics and Policy, 2(2). doi: 10.5070/P2P881. Retrieved from: http://www.escholarship.org/uc/item/400320ph"}}, {"name": "coverage", "properties": {"coverage": []}}, {"name": "relation", "properties": {"relation": []}}, {"name": "rights", "properties": {"rights": "public"}}], "languages": [null], "subjects": ["debt", "proposition 13", "revenue", "tax", "comparative series", "initiative", "synthetic controls"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://www.escholarship.org/uc/item/400320ph"}}, {"publisher": {"name": ""}, "description": "  Transcription of broadcast news is an interesting and challenging application\nfor large-vocabulary continuous speech recognition (LVCSR). We present in\ndetail the structure of a manually segmented and annotated corpus including\nover 160 hours of German broadcast news, and propose it as an evaluation\nframework of LVCSR systems. We show our own experimental results on the corpus,\nachieved with a state-of-the-art LVCSR decoder, measuring the effect of\ndifferent feature sets and decoding parameters, and thereby demonstrate that\nreal-time decoding of our test set is feasible on a desktop PC at 9.2% word\nerror rate.\n", "contributors": [{"name": "Weninger, Felix", "sameAs": [], "familyName": "Weninger", "additionalName": "", "givenName": "Felix", "email": ""}, {"name": "Schuller, Bj\u00f6rn", "sameAs": [], "familyName": "Schuller", "additionalName": "", "givenName": "Bj\u00f6rn", "email": ""}, {"name": "Eyben, Florian", "sameAs": [], "familyName": "Eyben", "additionalName": "", "givenName": "Florian", "email": ""}, {"name": "W\u00f6llmer, Martin", "sameAs": [], "familyName": "W\u00f6llmer", "additionalName": "", "givenName": "Martin", "email": ""}, {"name": "Rigoll, Gerhard", "sameAs": [], "familyName": "Rigoll", "additionalName": "", "givenName": "Gerhard", "email": ""}], "title": "A Broadcast News Corpus for Evaluation and Tuning of German LVCSR\n  Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4616", "oai:arXiv.org:1412.4616"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Transcription of broadcast news is an interesting and challenging application\nfor large-vocabulary continuous speech recognition (LVCSR). We present in\ndetail the structure of a manually segmented and annotated corpus including\nover 160 hours of German broadcast news, and propose it as an evaluation\nframework of LVCSR systems. We show our own experimental results on the corpus,\nachieved with a state-of-the-art LVCSR decoder, measuring the effect of\ndifferent feature sets and decoding parameters, and thereby demonstrate that\nreal-time decoding of our test set is feasible on a desktop PC at 9.2% word\nerror rate.\n", "Comment: submitted to INTERSPEECH 2010 on May 3, 2010"]}}], "languages": [null], "subjects": ["computer science - computation and language", "computer science - sound"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4616"}}, {"publisher": {"name": ""}, "description": "abstract: This dissertation illuminates overlaps in Mormonism and the New Spirituality in North America, showing their shared history and epistemologies. As example of these connections, it introduces ethnographic data from women who are members of the Church of Jesus Christ of Latter-day Saints in order to show (a) how living LDS women adapt and integrate elements from the New Spirituality with Mormon ideas about the nature of reality into hybrid spiritualities; and (b) how they negotiate their blended religious identities both in relation to the current American New Spirituality milieu and the highly centralized, hierarchical, and patriarchal Church of Jesus Christ of Latter-day Saints. The study focuses on religious hybridity with an emphasis on gender and the negotiation of power deriving from patriarchal religious authority, highlighting the dance between institutional power structures and individual authority. It illuminates processes and discourses of religious adaptation and synthesis through which these LDS women creatively and provocatively challenge LDS Church formal power structures.", "contributors": [{"name": "Daughtrey, Doe  (Author)", "sameAs": [], "familyName": "Daughtrey", "additionalName": "", "givenName": "Doe", "email": ""}, {"name": "Cady, Linell  (Advisor)", "sameAs": [], "familyName": "Cady", "additionalName": "", "givenName": "Linell", "email": ""}, {"name": "Mcdannell, Colleen  (Committee member)", "sameAs": [], "familyName": "Mcdannell", "additionalName": "", "givenName": "Colleen", "email": ""}, {"name": "Wenger, Tisa  (Committee member)", "sameAs": [], "familyName": "Wenger", "additionalName": "", "givenName": "Tisa", "email": ""}, {"name": "Fessenden, Tracy  (Committee member)", "sameAs": [], "familyName": "Fessenden", "additionalName": "", "givenName": "Tracy", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Mormonism and the New Spirituality: LDS Women's Hybrid Spiritualities", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "431 pages"}}, {"name": "date", "properties": {"date": "2012"}}, {"name": "description", "properties": {"description": ["abstract: This dissertation illuminates overlaps in Mormonism and the New Spirituality in North America, showing their shared history and epistemologies. As example of these connections, it introduces ethnographic data from women who are members of the Church of Jesus Christ of Latter-day Saints in order to show (a) how living LDS women adapt and integrate elements from the New Spirituality with Mormon ideas about the nature of reality into hybrid spiritualities; and (b) how they negotiate their blended religious identities both in relation to the current American New Spirituality milieu and the highly centralized, hierarchical, and patriarchal Church of Jesus Christ of Latter-day Saints. The study focuses on religious hybridity with an emphasis on gender and the negotiation of power deriving from patriarchal religious authority, highlighting the dance between institutional power structures and individual authority. It illuminates processes and discourses of religious adaptation and synthesis through which these LDS women creatively and provocatively challenge LDS Church formal power structures.", "Dissertation/Thesis", "Ph.D. Religious Studies 2012"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.14737", "item:14737"]}}], "languages": [null], "subjects": ["contemporary paganism", "new age", "religion and popular culture", "comparative religion", "gender studies", "american studies", "religion and gender", "mormonism", "new spirituality"], "providerUpdatedDateTime": "2015-02-12T01:13:25", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.14737"}}, {"publisher": {"name": ""}, "description": "  We revisit the implementation of iterative solvers on discrete graphics\nprocessing units and demonstrate the benefit of implementations using extensive\nkernel fusion for pipelined formulations over conventional implementations of\nclassical formulations. The proposed implementations with both CUDA and OpenCL\nare freely available in ViennaCL and achieve up to three-fold performance gains\nwhen compared to other solver packages for graphics processing units. Highest\nperformance gains are obtained for small to medium-sized systems, while our\nimplementations remain competitive with vendor-tuned implementations for very\nlarge systems. Our results are especially beneficial for transient problems,\nwhere many small to medium-sized systems instead of a single big system need to\nbe solved.\n", "contributors": [{"name": "Rupp, Karl", "sameAs": [], "familyName": "Rupp", "additionalName": "", "givenName": "Karl", "email": ""}, {"name": "Weinbub, Josef", "sameAs": [], "familyName": "Weinbub", "additionalName": "", "givenName": "Josef", "email": ""}, {"name": "J\u00fcngel, Ansgar", "sameAs": [], "familyName": "J\u00fcngel", "additionalName": "", "givenName": "Ansgar", "email": ""}, {"name": "Grasser, Tibor", "sameAs": [], "familyName": "Grasser", "additionalName": "", "givenName": "Tibor", "email": ""}], "title": "Pipelined Iterative Solvers with Kernel Fusion for Graphics Processing\n  Units", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4054", "oai:arXiv.org:1410.4054"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We revisit the implementation of iterative solvers on discrete graphics\nprocessing units and demonstrate the benefit of implementations using extensive\nkernel fusion for pipelined formulations over conventional implementations of\nclassical formulations. The proposed implementations with both CUDA and OpenCL\nare freely available in ViennaCL and achieve up to three-fold performance gains\nwhen compared to other solver packages for graphics processing units. Highest\nperformance gains are obtained for small to medium-sized systems, while our\nimplementations remain competitive with vendor-tuned implementations for very\nlarge systems. Our results are especially beneficial for transient problems,\nwhere many small to medium-sized systems instead of a single big system need to\nbe solved.\n", "Comment: 23 pages, 9 figures, 1 table"]}}], "languages": [null], "subjects": ["65f50", "65f10 (secondary)", "computer science - mathematical software", "computer science - performance", "65y05 (primary)", "and cluster computing", "computer science - distributed", "65y10", "parallel"], "providerUpdatedDateTime": "2014-10-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4054"}}, {"publisher": {"name": ""}, "description": "abstract: The purpose of this experimental study was to investigate the effects of textual and visual annotations on Spanish listening comprehension and vocabulary acquisition in the context of an online multimedia listening activity. 95 students who were enrolled in different sections of first year Spanish classes at a community college and a large southwestern university were randomly assigned to one of four versions of an online multimedia listening activity that contained textual and visual annotations of several key words. Students then took a comprehension and vocabulary posttest and a survey to measure cognitive load and general attitudes towards the program. Results indicated that textual annotations had a significant positive effect on listening comprehension and that visual annotations had a significant positive effect on how successful students felt. No statistically significant differences were found for other variables. Participants also reported positive attitudes towards vocabulary annotations and expressed a desire to see more annotations during multimedia listening activities of this type. These findings provide further evidence of the impact that multimedia may have on language acquisition. These findings have implications for multimedia design and for future research. Language listening activities should include a variety of vocabulary annotations that may help students to understand what they hear and to help them learn new vocabulary. Further research is needed outside of the laboratory, in the online and increasingly-mobile language learning environment in order to align the research with the environment in which many students currently study. The incorporation of motivation into multimedia learning theory and cognitive load should be explored, as well as new measures of cognitive load.", "contributors": [{"name": "Cottam, Michael Evan (Author)", "sameAs": [], "familyName": "Cottam", "additionalName": "Evan", "givenName": "Michael", "email": ""}, {"name": "Savenye, Wilhelmina  (Advisor)", "sameAs": [], "familyName": "Savenye", "additionalName": "", "givenName": "Wilhelmina", "email": ""}, {"name": "Klein, James D. (Committee member)", "sameAs": [], "familyName": "Klein", "additionalName": "D.", "givenName": "James", "email": ""}, {"name": "Atkinson, Robert  (Committee member)", "sameAs": [], "familyName": "Atkinson", "additionalName": "", "givenName": "Robert", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "The Effects of Visual and Textual Annotations on Spanish Listening Comprehension, Vocabulary Acquisition and Cognitive Load", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "148 pages"}}, {"name": "date", "properties": {"date": "2010"}}, {"name": "description", "properties": {"description": ["abstract: The purpose of this experimental study was to investigate the effects of textual and visual annotations on Spanish listening comprehension and vocabulary acquisition in the context of an online multimedia listening activity. 95 students who were enrolled in different sections of first year Spanish classes at a community college and a large southwestern university were randomly assigned to one of four versions of an online multimedia listening activity that contained textual and visual annotations of several key words. Students then took a comprehension and vocabulary posttest and a survey to measure cognitive load and general attitudes towards the program. Results indicated that textual annotations had a significant positive effect on listening comprehension and that visual annotations had a significant positive effect on how successful students felt. No statistically significant differences were found for other variables. Participants also reported positive attitudes towards vocabulary annotations and expressed a desire to see more annotations during multimedia listening activities of this type. These findings provide further evidence of the impact that multimedia may have on language acquisition. These findings have implications for multimedia design and for future research. Language listening activities should include a variety of vocabulary annotations that may help students to understand what they hear and to help them learn new vocabulary. Further research is needed outside of the laboratory, in the online and increasingly-mobile language learning environment in order to align the research with the environment in which many students currently study. The incorporation of motivation into multimedia learning theory and cognitive load should be explored, as well as new measures of cognitive load.", "Dissertation/Thesis", "Ph.D. Educational Technology 2010"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.8633", "item:8633"]}}], "languages": [null], "subjects": ["linguistics", "language", "educational psychology", "multimedia", "listening comprehension", "cognitive load", "vocabulary acquisition", "education", "technology"], "providerUpdatedDateTime": "2015-02-12T01:08:01", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.8633"}}, {"publisher": {"name": ""}, "description": "  Let $X$ be a compact quotient of a bounded domain in $\\mathbb C^n$. Let $K_X$\nbe the canonical line bundle of $X$. In this paper, we shall introduce the\nnotion of $S$ very ampleness for the pluri-canonical line bundles $mK_X$ by\nusing the Poincar\\'e series. The main result is an effective Seshadri constant\ncriterion of $S$ very ampleness for $mK_X$. An elementary proof of surjectivity\nof the Poincar\\'e map is also given.\n", "contributors": [{"name": "Wu, Jujie", "sameAs": [], "familyName": "Wu", "additionalName": "", "givenName": "Jujie", "email": ""}, {"name": "Wang, Xu", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Xu", "email": ""}], "title": "Poincare Series And Very Ampleness Criterion For Pluri-canonical Bundles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.00081", "oai:arXiv.org:1504.00081"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  Let $X$ be a compact quotient of a bounded domain in $\\mathbb C^n$. Let $K_X$\nbe the canonical line bundle of $X$. In this paper, we shall introduce the\nnotion of $S$ very ampleness for the pluri-canonical line bundles $mK_X$ by\nusing the Poincar\\'e series. The main result is an effective Seshadri constant\ncriterion of $S$ very ampleness for $mK_X$. An elementary proof of surjectivity\nof the Poincar\\'e map is also given.\n"}}], "languages": [null], "subjects": ["mathematics - complex variables"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.00081"}}, {"publisher": {"name": ""}, "description": "  The estimation of the time- and frequency-dependent coherent-to-diffuse power\nratio (CDR) from the measured spatial coherence between two omnidirectional\nmicrophones is investigated. Known CDR estimators are formulated in a common\nframework, illustrated using a geometric interpretation in the complex plane,\nand investigated with respect to bias and robustness towards model errors.\nSeveral novel unbiased CDR estimators are proposed, and it is shown that\nknowledge of either the direction of arrival (DOA) of the target source or the\ncoherence of the noise field is sufficient for unbiased CDR estimation. The\nvalidity of the model for the application of CDR estimates to dereverberation\nis investigated using measured and simulated impulse responses. A CDR-based\ndereverberation system is presented and evaluated using signal-based quality\nmeasures as well as automatic speech recognition accuracy. The results show\nthat the proposed unbiased estimators have a practical advantage over existing\nestimators, and that the proposed DOA-independent estimator can be used for\neffective blind dereverberation.\n", "contributors": [{"name": "Schwarz, Andreas", "sameAs": [], "familyName": "Schwarz", "additionalName": "", "givenName": "Andreas", "email": ""}, {"name": "Kellermann, Walter", "sameAs": [], "familyName": "Kellermann", "additionalName": "", "givenName": "Walter", "email": ""}], "title": "Coherent-to-Diffuse Power Ratio Estimation for Dereverberation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-02-12", "2015-02-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03784", "doi:10.1109/TASLP.2015.2418571", "oai:arXiv.org:1502.03784"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The estimation of the time- and frequency-dependent coherent-to-diffuse power\nratio (CDR) from the measured spatial coherence between two omnidirectional\nmicrophones is investigated. Known CDR estimators are formulated in a common\nframework, illustrated using a geometric interpretation in the complex plane,\nand investigated with respect to bias and robustness towards model errors.\nSeveral novel unbiased CDR estimators are proposed, and it is shown that\nknowledge of either the direction of arrival (DOA) of the target source or the\ncoherence of the noise field is sufficient for unbiased CDR estimation. The\nvalidity of the model for the application of CDR estimates to dereverberation\nis investigated using measured and simulated impulse responses. A CDR-based\ndereverberation system is presented and evaluated using signal-based quality\nmeasures as well as automatic speech recognition accuracy. The results show\nthat the proposed unbiased estimators have a practical advantage over existing\nestimators, and that the proposed DOA-independent estimator can be used for\neffective blind dereverberation.\n", "Comment: submitted to IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing, 2015"]}}], "languages": [null], "subjects": ["computer science - sound"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03784"}}, {"publisher": {"name": ""}, "description": "  We consider the problem of recovering the sparsest vector in a subspace\n$\\mathcal{S} \\subseteq \\mathbb{R}^p$ with $\\mathrm{dim}(\\mathcal{S}) = n < p$.\nThis problem can be considered a homogeneous variant of the sparse recovery\nproblem, and finds applications in sparse dictionary learning, sparse PCA, and\nother problems in signal processing and machine learning. Simple convex\nheuristics for this problem provably break down when the fraction of nonzero\nentries in the target sparse vector substantially exceeds $1/\\sqrt{n}$. In\ncontrast, we exhibit a relatively simple nonconvex approach based on\nalternating directions, which provably succeeds even when the fraction of\nnonzero entries is $\\Omega(1)$. To our knowledge, this is the first practical\nalgorithm to achieve this linear scaling. This result assumes a planted sparse\nmodel, in which the target sparse vector is embedded in an otherwise random\nsubspace. Empirically, our proposed algorithm also succeeds in more challenging\ndata models arising, e.g., from sparse dictionary learning.\n", "contributors": [{"name": "Qu, Qing", "sameAs": [], "familyName": "Qu", "additionalName": "", "givenName": "Qing", "email": ""}, {"name": "Sun, Ju", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Ju", "email": ""}, {"name": "Wright, John", "sameAs": [], "familyName": "Wright", "additionalName": "", "givenName": "John", "email": ""}], "title": "Finding a sparse vector in a subspace: Linear sparsity using alternating\n  directions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4659", "oai:arXiv.org:1412.4659"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  We consider the problem of recovering the sparsest vector in a subspace\n$\\mathcal{S} \\subseteq \\mathbb{R}^p$ with $\\mathrm{dim}(\\mathcal{S}) = n < p$.\nThis problem can be considered a homogeneous variant of the sparse recovery\nproblem, and finds applications in sparse dictionary learning, sparse PCA, and\nother problems in signal processing and machine learning. Simple convex\nheuristics for this problem provably break down when the fraction of nonzero\nentries in the target sparse vector substantially exceeds $1/\\sqrt{n}$. In\ncontrast, we exhibit a relatively simple nonconvex approach based on\nalternating directions, which provably succeeds even when the fraction of\nnonzero entries is $\\Omega(1)$. To our knowledge, this is the first practical\nalgorithm to achieve this linear scaling. This result assumes a planted sparse\nmodel, in which the target sparse vector is embedded in an otherwise random\nsubspace. Empirically, our proposed algorithm also succeeds in more challenging\ndata models arising, e.g., from sparse dictionary learning.\n", "Comment: 38 pages, 4 figures. Extended abstract appears in Advances in Neural\n  Information Processing Systems (NIPS), 2014"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - information theory", "computer science - learning", "statistics - machine learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4659"}}, {"publisher": {"name": "ScholarlyCommons"}, "description": "This policy brief examines the evolution of the educational leadership development system in England to see what ideas American leaders and policymakers might take from looking transnationally. The brief is based on a more in-depth examination of that leadership development system described in a CPRE research report entitled Building a Lattice for School Leadership: The Top-to-Bottom Rethinking of Leadership Development in England and What It Might Mean for American Education. The research report was based upon a year of research on school leadership in England that included extensive background research, site visits to schools and leadership programs, and over 20 interviews with government officials, teachers and school leaders, university researchers, union officials, and both forprofit and non-profit school leadership providers.", "contributors": [{"name": "Supovitz, Jonathan A", "sameAs": [], "familyName": "Supovitz", "additionalName": "A", "givenName": "Jonathan", "email": ""}], "title": "Building a Lattice for School Leadership: Lessons From England", "shareProperties": {"source": "upennsylvania"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2015-03-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.upenn.edu/cpre_policybriefs/7", "http://repository.upenn.edu/cgi/viewcontent.cgi?article=1000&amp;context=cpre_policybriefs", "oai:repository.upenn.edu:cpre_policybriefs-1000"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:cpre", "publication:cpre_policybriefs"]}}, {"name": "source", "properties": {"source": "CPRE Policy Briefs"}}, {"name": "rights", "properties": {"rights": []}}], "languages": [null], "subjects": ["educational leadership", "leadership studies", "education policy", "international and comparative education"], "providerUpdatedDateTime": "2015-03-26T19:16:08", "uris": {"canonicalUri": "http://repository.upenn.edu/cpre_policybriefs/7"}}, {"publisher": {"name": ""}, "description": "  An analytical framework for performance analysis and optimization of coded\nV-BLAST is developed. Average power and/or rate allocations to minimize the\noutage probability as well as their robustness and dual problems are\ninvestigated. Compact, closed-form expressions for the optimum allocations and\ncorresponding system performance are given. The uniform power allocation is\nshown to be near optimum in the low outage regime in combination with the\noptimum rate allocation. The average rate allocation provides the largest\nperformance improvement (extra diversity gain), and the average power\nallocation offers a modest SNR gain limited by the number of transmit antennas\nbut does not increase the diversity gain. The dual problems are shown to have\nthe same solutions as the primal ones. All these allocation strategies are\nshown to be robust. The reported results also apply to coded multiuser\ndetection and channel equalization systems relying on successive interference\ncancelation.\n", "contributors": [{"name": "Kostina, Victoria", "sameAs": [], "familyName": "Kostina", "additionalName": "", "givenName": "Victoria", "email": ""}, {"name": "Loyka, Sergey", "sameAs": [], "familyName": "Loyka", "additionalName": "", "givenName": "Sergey", "email": ""}], "title": "Optimum Power and Rate Allocation for Coded V-BLAST: Average\n  Optimization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-10-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1010.2789", "oai:arXiv.org:1010.2789"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  An analytical framework for performance analysis and optimization of coded\nV-BLAST is developed. Average power and/or rate allocations to minimize the\noutage probability as well as their robustness and dual problems are\ninvestigated. Compact, closed-form expressions for the optimum allocations and\ncorresponding system performance are given. The uniform power allocation is\nshown to be near optimum in the low outage regime in combination with the\noptimum rate allocation. The average rate allocation provides the largest\nperformance improvement (extra diversity gain), and the average power\nallocation offers a modest SNR gain limited by the number of transmit antennas\nbut does not increase the diversity gain. The dual problems are shown to have\nthe same solutions as the primal ones. All these allocation strategies are\nshown to be robust. The reported results also apply to coded multiuser\ndetection and channel equalization systems relying on successive interference\ncancelation.\n", "Comment: accepted by IEEE Transactions on Communications"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1010.2789"}}, {"publisher": {"name": ""}, "description": "  Four quantum code constructions generating several new families of good\nnonbinary quantum nonprimitive non-narrow-sense Bose-Chaudhuri-Hocquenghem\n(BCH) codes are presented in this paper. The first two ones are based on\nCalderbank-Shor-Steane (CSS) construction derived from two nonprimitive BCH\ncodes, not necessarily self-orthogonal. The third one is based on nonbinary\nSteane's enlargement of CSS codes applied to suitable sub-families of\nnonprimitive non-narrow-sense BCH codes. The fourth construction is derived\nfrom suitable sub-families of Hermitian self-orthogonal nonprimitive\nnon-narrow-sense BCH codes. These constructions generate new families of\nquantum BCH codes whose parameters are better than the ones available in the\nliterature.\n", "contributors": [{"name": "La Guardia, Giuliano G.", "sameAs": [], "familyName": "La Guardia", "additionalName": "G.", "givenName": "Giuliano", "email": ""}], "title": "On the Construction of Nonbinary Quantum BCH Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-12-22", "2013-12-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1212.5687", "IEEE Transactions on Information Theory 60(3), 2014", "oai:arXiv.org:1212.5687"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": "  Four quantum code constructions generating several new families of good\nnonbinary quantum nonprimitive non-narrow-sense Bose-Chaudhuri-Hocquenghem\n(BCH) codes are presented in this paper. The first two ones are based on\nCalderbank-Shor-Steane (CSS) construction derived from two nonprimitive BCH\ncodes, not necessarily self-orthogonal. The third one is based on nonbinary\nSteane's enlargement of CSS codes applied to suitable sub-families of\nnonprimitive non-narrow-sense BCH codes. The fourth construction is derived\nfrom suitable sub-families of Hermitian self-orthogonal nonprimitive\nnon-narrow-sense BCH codes. These constructions generate new families of\nquantum BCH codes whose parameters are better than the ones available in the\nliterature.\n"}}], "languages": [null], "subjects": ["quantum physics", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1212.5687"}}, {"publisher": {"name": ""}, "description": "  Subset selection from massive data with noised information is increasingly\npopular for various applications. This problem is still highly challenging as\ncurrent methods are generally slow in speed and sensitive to outliers. To\naddress the above two issues, we propose an accelerated robust subset selection\n(ARSS) method. Specifically in the subset selection area, this is the first\nattempt to employ the $\\ell_{p}(0<p\\leq1)$-norm based measure for the\nrepresentation loss, preventing large errors from dominating our objective. As\na result, the robustness against outlier elements is greatly enhanced.\nActually, data size is generally much larger than feature length, i.e. $N\\gg\nL$. Based on this observation, we propose a speedup solver (via ALM and\nequivalent derivations) to highly reduce the computational cost, theoretically\nfrom $O(N^{4})$ to $O(N{}^{2}L)$. Extensive experiments on ten benchmark\ndatasets verify that our method not only outperforms state of the art methods,\nbut also runs 10,000+ times faster than the most related method.\n", "contributors": [{"name": "Zhu, Feiyun", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "Feiyun", "email": ""}, {"name": "Fan, Bin", "sameAs": [], "familyName": "Fan", "additionalName": "", "givenName": "Bin", "email": ""}, {"name": "Zhu, Xinliang", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "Xinliang", "email": ""}, {"name": "Wang, Ying", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Ying", "email": ""}, {"name": "Xiang, Shiming", "sameAs": [], "familyName": "Xiang", "additionalName": "", "givenName": "Shiming", "email": ""}, {"name": "Pan, Chunhong", "sameAs": [], "familyName": "Pan", "additionalName": "", "givenName": "Chunhong", "email": ""}], "title": "10,000+ Times Accelerated Robust Subset Selection (ARSS)", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-12", "2014-11-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.3660", "oai:arXiv.org:1409.3660"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  Subset selection from massive data with noised information is increasingly\npopular for various applications. This problem is still highly challenging as\ncurrent methods are generally slow in speed and sensitive to outliers. To\naddress the above two issues, we propose an accelerated robust subset selection\n(ARSS) method. Specifically in the subset selection area, this is the first\nattempt to employ the $\\ell_{p}(0<p\\leq1)$-norm based measure for the\nrepresentation loss, preventing large errors from dominating our objective. As\na result, the robustness against outlier elements is greatly enhanced.\nActually, data size is generally much larger than feature length, i.e. $N\\gg\nL$. Based on this observation, we propose a speedup solver (via ALM and\nequivalent derivations) to highly reduce the computational cost, theoretically\nfrom $O(N^{4})$ to $O(N{}^{2}L)$. Extensive experiments on ten benchmark\ndatasets verify that our method not only outperforms state of the art methods,\nbut also runs 10,000+ times faster than the most related method.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.3660"}}, {"publisher": {"name": ""}, "description": "  Complete Pick algebras - these are, roughly, the multiplier algebras in which\nPick's interpolation theorem holds true - have been the focus of much research\nin the last twenty years or so. All (irreducible) complete Pick algebras may be\nrealized concretely as the algebras obtained by restricting multipliers on\nDrury-Arveson space to a subvariety of the unit ball; to be precise: every\nirreducible complete Pick algebra has the form $M_V = \\{f|_V : f \\in M_d\\}$,\nwhere $M_d$ denotes the multiplier algebra of the Drury-Arveson space $H^2_d$,\nand $V$ is the joint zero set of some functions in $M_d$. In recent years\nseveral works were devoted to the classification of complete Pick algebras in\nterms of the complex geometry of the varieties with which they are associated.\nThe purpose of this survey is to give an account of this research in a\ncomprehensive and unified way. We describe the array of tools and methods that\nwere developed for this program, and take the opportunity to clarify, improve,\nand correct some parts of the literature.\n", "contributors": [{"name": "Salomon, Guy", "sameAs": [], "familyName": "Salomon", "additionalName": "", "givenName": "Guy", "email": ""}, {"name": "Shalit, Orr", "sameAs": [], "familyName": "Shalit", "additionalName": "", "givenName": "Orr", "email": ""}], "title": "The isomorphism problem for complete Pick algebras: a survey", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7817", "oai:arXiv.org:1412.7817"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Complete Pick algebras - these are, roughly, the multiplier algebras in which\nPick's interpolation theorem holds true - have been the focus of much research\nin the last twenty years or so. All (irreducible) complete Pick algebras may be\nrealized concretely as the algebras obtained by restricting multipliers on\nDrury-Arveson space to a subvariety of the unit ball; to be precise: every\nirreducible complete Pick algebra has the form $M_V = \\{f|_V : f \\in M_d\\}$,\nwhere $M_d$ denotes the multiplier algebra of the Drury-Arveson space $H^2_d$,\nand $V$ is the joint zero set of some functions in $M_d$. In recent years\nseveral works were devoted to the classification of complete Pick algebras in\nterms of the complex geometry of the varieties with which they are associated.\nThe purpose of this survey is to give an account of this research in a\ncomprehensive and unified way. We describe the array of tools and methods that\nwere developed for this program, and take the opportunity to clarify, improve,\nand correct some parts of the literature.\n", "Comment: 28 pages. Prepared for Proceedings of IWOTA 2014"]}}], "languages": [null], "subjects": ["47a13", "47l30", "mathematics - functional analysis", "mathematics - complex variables", "mathematics - operator algebras", "46e22"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7817"}}, {"publisher": {"name": ""}, "description": "  We study the expression complexity of two basic problems involving the\ncomparison of primitive positive formulas: equivalence and containment. In\nparticular, we study the complexity of these problems relative to finite\nrelational structures. We present two generic hardness results for the studied\nproblems, and discuss evidence that they are optimal and yield, for each of the\nproblems, a complexity trichotomy.\n", "contributors": [{"name": "Bova, Simone", "sameAs": [], "familyName": "Bova", "additionalName": "", "givenName": "Simone", "email": ""}, {"name": "Chen, Hubie", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Hubie", "email": ""}, {"name": "Valeriote, Matthew", "sameAs": [], "familyName": "Valeriote", "additionalName": "", "givenName": "Matthew", "email": ""}], "title": "Generic Expression Hardness Results for Primitive Positive Formula\n  Comparison", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-05-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.5745", "oai:arXiv.org:1205.5745"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We study the expression complexity of two basic problems involving the\ncomparison of primitive positive formulas: equivalence and containment. In\nparticular, we study the complexity of these problems relative to finite\nrelational structures. We present two generic hardness results for the studied\nproblems, and discuss evidence that they are optimal and yield, for each of the\nproblems, a complexity trichotomy.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "computer science - databases", "computer science - logic in computer science"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.5745"}}, {"publisher": {"name": ""}, "description": "  Bourgain recently constructed $O(1)$-monotone bipartite expanders. By\ncombining this result with a generalisation of the unraveling method of Kannan,\nwe construct 3-monotone bipartite expanders, which is best possible. Similarly,\nwe construct bipartite expanders that have 3-page book embeddings, 2-queue\nlayouts, and 4-track layouts. All these results are best possible.\n", "contributors": [{"name": "Dujmovi\u0107, Vida", "sameAs": [], "familyName": "Dujmovi\u0107", "additionalName": "", "givenName": "Vida", "email": ""}, {"name": "Sidiropoulos, Anastasios", "sameAs": [], "familyName": "Sidiropoulos", "additionalName": "", "givenName": "Anastasios", "email": ""}, {"name": "Wood, David R.", "sameAs": [], "familyName": "Wood", "additionalName": "R.", "givenName": "David", "email": ""}], "title": "3-Monotone Expanders", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05020", "oai:arXiv.org:1501.05020"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Bourgain recently constructed $O(1)$-monotone bipartite expanders. By\ncombining this result with a generalisation of the unraveling method of Kannan,\nwe construct 3-monotone bipartite expanders, which is best possible. Similarly,\nwe construct bipartite expanders that have 3-page book embeddings, 2-queue\nlayouts, and 4-track layouts. All these results are best possible.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-01-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05020"}}, {"publisher": {"name": ""}, "description": "  We develop a worst-case analysis of aggregation of classifier ensembles for\nbinary classification. The task of predicting to minimize error is formulated\nas a game played over a given set of unlabeled data (a transductive setting),\nwhere prior label information is encoded as constraints on the game. The\nminimax solution of this game identifies cases where a weighted combination of\nthe classifiers can perform significantly better than any single classifier.\n", "contributors": [{"name": "Balsubramani, Akshay", "sameAs": [], "familyName": "Balsubramani", "additionalName": "", "givenName": "Akshay", "email": ""}, {"name": "Freund, Yoav", "sameAs": [], "familyName": "Freund", "additionalName": "", "givenName": "Yoav", "email": ""}], "title": "Optimally Combining Classifiers Using Unlabeled Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-05", "2015-03-09"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01811", "oai:arXiv.org:1503.01811"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  We develop a worst-case analysis of aggregation of classifier ensembles for\nbinary classification. The task of predicting to minimize error is formulated\nas a game played over a given set of unlabeled data (a transductive setting),\nwhere prior label information is encoded as constraints on the game. The\nminimax solution of this game identifies cases where a weighted combination of\nthe classifiers can perform significantly better than any single classifier.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01811"}}, {"publisher": {"name": ""}, "description": "  Errors in data are usually unwelcome and so some means to correct them is\nuseful. However, it is difficult to define, detect or correct errors in an\nunsupervised way. Here, we train a deep neural network to re-synthesize its\ninputs at its output layer for a given class of data. We then exploit the fact\nthat this abstract transformation, which we call a deep transform (DT),\ninherently rejects information (errors) existing outside of the abstract\nfeature space. Using the DT to perform probabilistic re-synthesis, we\ndemonstrate the recovery of data that has been subject to extreme degradation.\n", "contributors": [{"name": "Simpson, Andrew J. R.", "sameAs": [], "familyName": "Simpson", "additionalName": "J. R.", "givenName": "Andrew", "email": ""}], "title": "Deep Transform: Error Correction via Probabilistic Re-Synthesis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04617", "oai:arXiv.org:1502.04617"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Errors in data are usually unwelcome and so some means to correct them is\nuseful. However, it is difficult to define, detect or correct errors in an\nunsupervised way. Here, we train a deep neural network to re-synthesize its\ninputs at its output layer for a given class of data. We then exploit the fact\nthat this abstract transformation, which we call a deep transform (DT),\ninherently rejects information (errors) existing outside of the abstract\nfeature space. Using the DT to perform probabilistic re-synthesis, we\ndemonstrate the recovery of data that has been subject to extreme degradation.\n"}}], "languages": [null], "subjects": ["computer science - learning", "68txx"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04617"}}, {"publisher": {"name": ""}, "description": "  Recently, XACML is a popular access control policy language that is used\nwidely in many applications. Policies in XACML are built based on many\ncomponents over distributed resources. Due to the expressiveness of XACML, it\nis not trivial for policy administrators to understand the overall effect and\nconsequences of XACML policies they have written. In this paper we show a\nmechanism and a tool how to analyses big access control policies sets such as\n(i) incompleteness policies, (ii) conflicting policies, and (iii) unreachable\npolicies. To detect these problems we present a method using Answer Set\nProgramming (ASP) in the context of XACML 3.0.\n", "contributors": [{"name": "Ramli, Carroline Dewi Puspa Kencana", "sameAs": [], "familyName": "Ramli", "additionalName": "Dewi Puspa Kencana", "givenName": "Carroline", "email": ""}], "title": "Detecting Incompleteness, Conflicting and Unreachability XACML Policies\n  using Answer Set Programming", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02732", "oai:arXiv.org:1503.02732"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Recently, XACML is a popular access control policy language that is used\nwidely in many applications. Policies in XACML are built based on many\ncomponents over distributed resources. Due to the expressiveness of XACML, it\nis not trivial for policy administrators to understand the overall effect and\nconsequences of XACML policies they have written. In this paper we show a\nmechanism and a tool how to analyses big access control policies sets such as\n(i) incompleteness policies, (ii) conflicting policies, and (iii) unreachable\npolicies. To detect these problems we present a method using Answer Set\nProgramming (ASP) in the context of XACML 3.0.\n", "Comment: arXiv admin note: text overlap with arXiv:1206.5327"]}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02732"}}, {"publisher": {"name": ""}, "description": "  The word position automaton was introduced by Glushkov and McNaughton in the\nearly 1960. This automaton is homogeneous and has (||\\E||+1) states for a word\nexpression of alphabetic width ||\\E||. This kind of automata is extended to\nregular tree expressions.\n  In this paper, we give an efficient algorithm that computes the \\Follow sets,\nwhich are used in different algorithms of conversion of a regular expression\ninto tree automata. In the following, we consider the k-position tree automaton\nconstruction. We prove that for a regular expression \\E of a size |\\E| and\nalphabetic width ||\\E||, the \\Follow sets can be computed in O(||\\E||\\cdot\n|\\E|) time complexity.\n", "contributors": [{"name": "Sebti, Nadia Ouali", "sameAs": [], "familyName": "Sebti", "additionalName": "Ouali", "givenName": "Nadia", "email": ""}, {"name": "Ziadi, Djelloul", "sameAs": [], "familyName": "Ziadi", "additionalName": "", "givenName": "Djelloul", "email": ""}], "title": "Algorithm for the k-Position Tree Automaton Construction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06194", "oai:arXiv.org:1502.06194"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The word position automaton was introduced by Glushkov and McNaughton in the\nearly 1960. This automaton is homogeneous and has (||\\E||+1) states for a word\nexpression of alphabetic width ||\\E||. This kind of automata is extended to\nregular tree expressions.\n  In this paper, we give an efficient algorithm that computes the \\Follow sets,\nwhich are used in different algorithms of conversion of a regular expression\ninto tree automata. In the following, we consider the k-position tree automaton\nconstruction. We prove that for a regular expression \\E of a size |\\E| and\nalphabetic width ||\\E||, the \\Follow sets can be computed in O(||\\E||\\cdot\n|\\E|) time complexity.\n", "Comment: arXiv admin note: text overlap with arXiv:1403.6251, arXiv:1401.5951"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06194"}}, {"publisher": {"name": "Elsevier/North-Holland Biomedical Press"}, "description": "\u2022We use a normative (Bayes optimal) model of oculomotor pursuit.\u2022We average the empirical responses of subjects performing a pursuit paradigm.\u2022We invert these responses using the pursuit model and dynamic causal modelling.\u2022We thereby estimate the precision of subjects\u2019 Bayesian beliefs from their pursuit.\u2022This could be used to quantify abnormal precision encoding in schizophrenia.", "contributors": [{"name": "Adams, Rick A.", "sameAs": [], "familyName": "Adams", "additionalName": "A.", "givenName": "Rick", "email": ""}, {"name": "Aponte, Eduardo", "sameAs": [], "familyName": "Aponte", "additionalName": "", "givenName": "Eduardo", "email": ""}, {"name": "Marshall, Louise", "sameAs": [], "familyName": "Marshall", "additionalName": "", "givenName": "Louise", "email": ""}, {"name": "Friston, Karl J.", "sameAs": [], "familyName": "Friston", "additionalName": "J.", "givenName": "Karl", "email": ""}], "title": "Active inference and oculomotor pursuit: The dynamic causal modelling of eye movements", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["computational neuroscience"], "providerUpdatedDateTime": "2015-03-15T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4346275"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "This research investigates the distortion on the electrical distribution system for a high voltage DC Integrated Power System (IPS). The analysis was concentrated on the power supplied to a propulsion motor driven by an inverter with simulated silicon carbide switches. Theoretically, silicon carbide switches have the advantage of being able to withstand a very large blocking voltage and carry very large forward currents. Silicon carbide switches are also very efficient due to their quick rise and fall times. Since silicon carbide switches can withstand high voltage differentials and switch faster than silicon switches, the switching effects on the electrical distribution system were investigated. The current state of silicon carbide power electronics was also investigated. This research quantifies the current and voltage distortion over various operating conditions. A system model was developed using Matlab, Simulink, and SimPowerSystems. The model consisted of a synchronous generator supplying a rectifier and inverter set driving an induction motor. This induction motor simulates the propulsion motor for a Navy ship. This model had a DC link voltage of 10 kV in order to simulate future Navy IPS systems. The current and voltage distortion were compared to MIL STD 1399 and IEEE STD 519 and 45.", "contributors": [{"name": "Fallier, William F. (William Frederick)", "sameAs": [], "familyName": "Fallier", "additionalName": "F.", "givenName": "William", "email": ""}, {"name": "Massachusetts Institute of Technology. Dept. of Electrical Engineering and Computer Science.", "sameAs": [], "familyName": "Science.", "additionalName": "Institute of Technology. Dept. of Electrical Engineering and Computer", "givenName": "Massachusetts", "email": ""}, {"name": "James L. Kirtley.", "sameAs": [], "familyName": "Kirtley.", "additionalName": "L.", "givenName": "James", "email": ""}], "title": "Analysis of system wide distortion in an integrated power system utilizing a high voltage DC bus and silicon carbide power devices", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "172 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/39730", "181006289", "oai:dspace.mit.edu:1721.1/39730"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2007-12-07T16:14:45Z", "2007-12-07T16:14:45Z", "2007", "2007"]}}, {"name": "description", "properties": {"description": ["This research investigates the distortion on the electrical distribution system for a high voltage DC Integrated Power System (IPS). The analysis was concentrated on the power supplied to a propulsion motor driven by an inverter with simulated silicon carbide switches. Theoretically, silicon carbide switches have the advantage of being able to withstand a very large blocking voltage and carry very large forward currents. Silicon carbide switches are also very efficient due to their quick rise and fall times. Since silicon carbide switches can withstand high voltage differentials and switch faster than silicon switches, the switching effects on the electrical distribution system were investigated. The current state of silicon carbide power electronics was also investigated. This research quantifies the current and voltage distortion over various operating conditions. A system model was developed using Matlab, Simulink, and SimPowerSystems. The model consisted of a synchronous generator supplying a rectifier and inverter set driving an induction motor. This induction motor simulates the propulsion motor for a Navy ship. This model had a DC link voltage of 10 kV in order to simulate future Navy IPS systems. The current and voltage distortion were compared to MIL STD 1399 and IEEE STD 519 and 45.", "by William F. Fallier.", "Thesis (Nav. E.)--Massachusetts Institute of Technology, Dept. of Mechanical Engineering; and, (S.M.)--Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2007.", "Includes bibliographical references (p. 81-82)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7685", "hdl_1721.1_7851", "hdl_1721.1_7663", "hdl_1721.1_7817"]}}], "languages": [null], "subjects": ["mechanical engineering.", "electrical engineering and computer science."], "providerUpdatedDateTime": "2014-11-06T07:21:00", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/39730"}}, {"publisher": {"name": ""}, "description": "  Consider the continuum of points on the edges of a network, i.e., a\nconnected, undirected graph with positive edge weights. We measure the distance\nbetween these points in terms of the weighted shortest path distance, called\nthe network distance. Within this metric space, we study farthest points and\nfarthest distances. We introduce optimal data structures supporting queries for\nthe farthest distance and the farthest points on trees, cycles, uni-cyclic\nnetworks, and cactus networks.\n", "contributors": [{"name": "Bose, Prosenjit", "sameAs": [], "familyName": "Bose", "additionalName": "", "givenName": "Prosenjit", "email": ""}, {"name": "De Carufel, Jean-Lou", "sameAs": [], "familyName": "De Carufel", "additionalName": "", "givenName": "Jean-Lou", "email": ""}, {"name": "Grimm, Carsten", "sameAs": [], "familyName": "Grimm", "additionalName": "", "givenName": "Carsten", "email": ""}, {"name": "Maheshwari, Anil", "sameAs": [], "familyName": "Maheshwari", "additionalName": "", "givenName": "Anil", "email": ""}, {"name": "Smid, Michiel", "sameAs": [], "familyName": "Smid", "additionalName": "", "givenName": "Michiel", "email": ""}], "title": "Optimal Data Structures for Farthest-Point Queries in Cactus Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1879", "doi:10.7155/jgaa.00345", "oai:arXiv.org:1411.1879"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Consider the continuum of points on the edges of a network, i.e., a\nconnected, undirected graph with positive edge weights. We measure the distance\nbetween these points in terms of the weighted shortest path distance, called\nthe network distance. Within this metric space, we study farthest points and\nfarthest distances. We introduce optimal data structures supporting queries for\nthe farthest distance and the farthest points on trees, cycles, uni-cyclic\nnetworks, and cactus networks.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1879"}}, {"publisher": {"name": ""}, "description": "  In this paper, we pioneer the study of physical-layer security in\nheterogeneous networks (HetNets). We investigate secure communications in a\ntwo-tier downlink HetNet, which comprises one macrocell and several femtocells.\nEach cell has multiple users and an eavesdropper attempts to wiretap the\nintended macrocell user. Firstly, we consider an orthogonal spectrum allocation\nstrategy to eliminate co-channel interference, and propose the secrecy transmit\nbeamforming only operating in the macrocell (STB-OM) as a partial solution for\nsecure communication in HetNet. Next, we consider a secrecy-oriented\nnon-orthogonal spectrum allocation strategy and propose two cooperative STBs\nwhich rely on the collaboration amongst the macrocell base station (MBS) and\nthe adjacent femtocell base stations (FBSs). Our first cooperative STB is the\nSTB sequentially operating in the macrocell and femtocells (STB-SMF), where the\ncooperative FBSs individually design their STB matrices and then feed their\nperformance metrics to the MBS for guiding the STB in the macrocell. Aiming to\nimprove the performance of STB-SMF, we further propose the STB jointly designed\nin the macrocell and femtocells (STB-JMF), where all cooperative FBSs feed\nchannel state information to the MBS for designing the joint STB. Unlike\nconventional STBs conceived for broadcasting or interference channels, the\nthree proposed STB schemes all entail relatively sophisticated optimizations\ndue to QoS constraints of the legitimate users. In order to efficiently use\nthese STB schemes, the original optimization problems are reformulated and\nconvex optimization techniques, such as second-order cone programming and\nsemidefinite programming, are invoked to obtain the optimal solutions.\nNumerical results demonstrate that the proposed STB schemes are highly\neffective in improving the secrecy rate performance of HetNet.\n", "contributors": [{"name": "Lv, Tiejun", "sameAs": [], "familyName": "Lv", "additionalName": "", "givenName": "Tiejun", "email": ""}, {"name": "Gao, Hui", "sameAs": [], "familyName": "Gao", "additionalName": "", "givenName": "Hui", "email": ""}, {"name": "Yang, Shaoshi", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Shaoshi", "email": ""}], "title": "Secrecy Transmit Beamforming for Heterogeneous Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01056", "doi:10.1109/JSAC.2015.2416984", "oai:arXiv.org:1503.01056"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we pioneer the study of physical-layer security in\nheterogeneous networks (HetNets). We investigate secure communications in a\ntwo-tier downlink HetNet, which comprises one macrocell and several femtocells.\nEach cell has multiple users and an eavesdropper attempts to wiretap the\nintended macrocell user. Firstly, we consider an orthogonal spectrum allocation\nstrategy to eliminate co-channel interference, and propose the secrecy transmit\nbeamforming only operating in the macrocell (STB-OM) as a partial solution for\nsecure communication in HetNet. Next, we consider a secrecy-oriented\nnon-orthogonal spectrum allocation strategy and propose two cooperative STBs\nwhich rely on the collaboration amongst the macrocell base station (MBS) and\nthe adjacent femtocell base stations (FBSs). Our first cooperative STB is the\nSTB sequentially operating in the macrocell and femtocells (STB-SMF), where the\ncooperative FBSs individually design their STB matrices and then feed their\nperformance metrics to the MBS for guiding the STB in the macrocell. Aiming to\nimprove the performance of STB-SMF, we further propose the STB jointly designed\nin the macrocell and femtocells (STB-JMF), where all cooperative FBSs feed\nchannel state information to the MBS for designing the joint STB. Unlike\nconventional STBs conceived for broadcasting or interference channels, the\nthree proposed STB schemes all entail relatively sophisticated optimizations\ndue to QoS constraints of the legitimate users. In order to efficiently use\nthese STB schemes, the original optimization problems are reformulated and\nconvex optimization techniques, such as second-order cone programming and\nsemidefinite programming, are invoked to obtain the optimal solutions.\nNumerical results demonstrate that the proposed STB schemes are highly\neffective in improving the secrecy rate performance of HetNet.\n", "Comment: 17 pages, 14 figures, 3 algorithms and 1 table, to appear in IEEE\n  Journal on Selected Areas in Communications, 2015"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01056"}}, {"publisher": {"name": ""}, "description": "  The modern engineering landscape increasingly requires a range of skills to\nsuccessfully integrate complex systems. Project-based learning is used to help\nstudents build professional skills. However, it is typically applied to small\nteams and small efforts. This paper describes an experience in engaging a large\nnumber of students in research projects within a multi-year interdisciplinary\nresearch effort. The projects expose the students to various disciplines in\nComputer Science (embedded systems, algorithm design, networking), Electrical\nEngineering (circuit design, wireless communications, hardware prototyping),\nand Applied Physics (thin-film battery design, solar cell fabrication). While a\nstudent project is usually focused on one discipline area, it requires\ninteraction with at least two other areas. Over 5 years, 180 semester-long\nprojects have been completed. The students were a diverse group of high school,\nundergraduate, and M.S. Computer Science, Computer Engineering, and Electrical\nEngineering students. Some of the approaches that were taken to facilitate\nstudent learning are real-world system development constraints, regular\ncross-group meetings, and extensive involvement of Ph.D. students in student\nmentorship and knowledge transfer. To assess the approaches, a survey was\nconducted among the participating students. The results demonstrate the\neffectiveness of the approaches. For example, 70% of the students surveyed\nindicated that working on their research project improved their ability to\nfunction on multidisciplinary teams more than coursework, internships, or any\nother activity.\n", "contributors": [{"name": "Margolies, Robert", "sameAs": [], "familyName": "Margolies", "additionalName": "", "givenName": "Robert", "email": ""}, {"name": "Gorlatova, Maria", "sameAs": [], "familyName": "Gorlatova", "additionalName": "", "givenName": "Maria", "email": ""}, {"name": "Sarik, John", "sameAs": [], "familyName": "Sarik", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Kinget, Peter", "sameAs": [], "familyName": "Kinget", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Kymissis, Ioannis", "sameAs": [], "familyName": "Kymissis", "additionalName": "", "givenName": "Ioannis", "email": ""}, {"name": "Zussman, Gil", "sameAs": [], "familyName": "Zussman", "additionalName": "", "givenName": "Gil", "email": ""}], "title": "Project-based Learning within a Large-Scale Interdisciplinary Research\n  Effort", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6935", "oai:arXiv.org:1410.6935"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The modern engineering landscape increasingly requires a range of skills to\nsuccessfully integrate complex systems. Project-based learning is used to help\nstudents build professional skills. However, it is typically applied to small\nteams and small efforts. This paper describes an experience in engaging a large\nnumber of students in research projects within a multi-year interdisciplinary\nresearch effort. The projects expose the students to various disciplines in\nComputer Science (embedded systems, algorithm design, networking), Electrical\nEngineering (circuit design, wireless communications, hardware prototyping),\nand Applied Physics (thin-film battery design, solar cell fabrication). While a\nstudent project is usually focused on one discipline area, it requires\ninteraction with at least two other areas. Over 5 years, 180 semester-long\nprojects have been completed. The students were a diverse group of high school,\nundergraduate, and M.S. Computer Science, Computer Engineering, and Electrical\nEngineering students. Some of the approaches that were taken to facilitate\nstudent learning are real-world system development constraints, regular\ncross-group meetings, and extensive involvement of Ph.D. students in student\nmentorship and knowledge transfer. To assess the approaches, a survey was\nconducted among the participating students. The results demonstrate the\neffectiveness of the approaches. For example, 70% of the students surveyed\nindicated that working on their research project improved their ability to\nfunction on multidisciplinary teams more than coursework, internships, or any\nother activity.\n"}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6935"}}, {"publisher": {"name": ""}, "description": "  Recently, utilizing renewable energy for wireless system has attracted\nextensive attention. However, due to the instable energy supply and the limited\nbattery capacity, renewable energy cannot guarantee to provide the perpetual\noperation for wireless sensor networks (WSN). The coexistence of renewable\nenergy and electricity grid is expected as a promising energy supply manner to\nremain function for a potentially infinite lifetime. In this paper, we propose\na new system model suitable for WSN, taking into account multiple energy\nconsumptions due to sensing, transmission and reception, heterogeneous energy\nsupplies from renewable energy, electricity grid and mixed energy, and\nmultidimension stochastic natures due to energy harvesting profile, electricity\nprice and channel condition. A discrete-time stochastic cross-layer\noptimization problem is formulated to achieve the optimal trade-off between the\ntime-average rate utility and electricity cost subject to the data and energy\nqueuing stability constraints. The Lyapunov drift-plus-penalty with\nperturbation technique and block coordinate descent method is applied to obtain\na fully distributed and low-complexity cross-layer algorithm only requiring\nknowledge of the instantaneous system state. The explicit trade-off between the\noptimization objective and queue backlog is theoretically proven. Finally, the\nextensive simulations verify the theoretic claims.\n", "contributors": [{"name": "Xu, Weiqiang", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Weiqiang", "email": ""}, {"name": "Zhang, Yushu", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Yushu", "email": ""}, {"name": "Shi, Qingjiang", "sameAs": [], "familyName": "Shi", "additionalName": "", "givenName": "Qingjiang", "email": ""}, {"name": "Wang, Xiaodong", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Xiaodong", "email": ""}], "title": "Energy Management and Cross Layer Optimization for Wireless Sensor\n  Network Powered by Heterogeneous Energy Sources", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-07", "2014-11-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1973", "oai:arXiv.org:1410.1973"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Recently, utilizing renewable energy for wireless system has attracted\nextensive attention. However, due to the instable energy supply and the limited\nbattery capacity, renewable energy cannot guarantee to provide the perpetual\noperation for wireless sensor networks (WSN). The coexistence of renewable\nenergy and electricity grid is expected as a promising energy supply manner to\nremain function for a potentially infinite lifetime. In this paper, we propose\na new system model suitable for WSN, taking into account multiple energy\nconsumptions due to sensing, transmission and reception, heterogeneous energy\nsupplies from renewable energy, electricity grid and mixed energy, and\nmultidimension stochastic natures due to energy harvesting profile, electricity\nprice and channel condition. A discrete-time stochastic cross-layer\noptimization problem is formulated to achieve the optimal trade-off between the\ntime-average rate utility and electricity cost subject to the data and energy\nqueuing stability constraints. The Lyapunov drift-plus-penalty with\nperturbation technique and block coordinate descent method is applied to obtain\na fully distributed and low-complexity cross-layer algorithm only requiring\nknowledge of the instantaneous system state. The explicit trade-off between the\noptimization objective and queue backlog is theoretically proven. Finally, the\nextensive simulations verify the theoretic claims.\n", "Comment: submitted to IEEE Transactions on Wireless Communications, Under\n  Second Round Review after Major Revision"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1973"}}, {"publisher": {"name": ""}, "description": "  This paper considers a problem of distributed hypothesis testing and social\nlearning. Individual nodes in a network receive noisy local (private)\nobservations whose distribution is parameterized by a discrete parameter\n(hypotheses). The conditional distributions are known locally at the nodes, but\nthe true parameter/hypothesis is not known. An update rule is analyzed in which\nnodes first perform a Bayesian update of their belief (distribution estimate)\nof the parameter based on their local observation, communicate these updates to\ntheir neighbors, and then perform a \"non-Bayesian\" linear consensus using the\nlog-beliefs of their neighbors. In this paper we show that under mild\nassumptions, the belief of any node in any incorrect hypothesis converges to\nzero exponentially fast, and we characterize the exponential rate of learning\nwhich is given in terms of the network structure and the divergences between\nthe observations' distributions. Our main result is the large deviation\nproperty established on the rate of convergence with an explicit\ncharacterization of the probability of convergence.\n", "contributors": [{"name": "Lalitha, Anusha", "sameAs": [], "familyName": "Lalitha", "additionalName": "", "givenName": "Anusha", "email": ""}, {"name": "Javidi, Tara", "sameAs": [], "familyName": "Javidi", "additionalName": "", "givenName": "Tara", "email": ""}, {"name": "Sarwate, Anand", "sameAs": [], "familyName": "Sarwate", "additionalName": "", "givenName": "Anand", "email": ""}], "title": "Social Learning and Distributed Hypothesis Testing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-16", "2014-10-21"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4307", "oai:arXiv.org:1410.4307"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  This paper considers a problem of distributed hypothesis testing and social\nlearning. Individual nodes in a network receive noisy local (private)\nobservations whose distribution is parameterized by a discrete parameter\n(hypotheses). The conditional distributions are known locally at the nodes, but\nthe true parameter/hypothesis is not known. An update rule is analyzed in which\nnodes first perform a Bayesian update of their belief (distribution estimate)\nof the parameter based on their local observation, communicate these updates to\ntheir neighbors, and then perform a \"non-Bayesian\" linear consensus using the\nlog-beliefs of their neighbors. In this paper we show that under mild\nassumptions, the belief of any node in any incorrect hypothesis converges to\nzero exponentially fast, and we characterize the exponential rate of learning\nwhich is given in terms of the network structure and the divergences between\nthe observations' distributions. Our main result is the large deviation\nproperty established on the rate of convergence with an explicit\ncharacterization of the probability of convergence.\n"}}], "languages": [null], "subjects": ["mathematics - statistics theory", "mathematics - optimization and control", "computer science - information theory"], "providerUpdatedDateTime": "2014-10-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4307"}}, {"publisher": {"name": ""}, "description": "  Mathematical model for hit phenomena presented by A Ishii et al in 2012 has\nbeen extended to analyze and predict a lot of hit subject using social network\nsystem. The equation for each individual consumers is assumed and the equation\nof social response to each hit subject is derived as stochastic process of\nstatistical physics. The advertisement effect is included as external force and\nthe communication effects are included as two-body and three-body interaction.\nThe applications of this model are demonstrated for analyzing population of\nweekly TV drama. Including both the realtime view data and the playback view\ndata, we found that the indirect communication correlate strongly to the TV\nviewing rate data for recent Japanese 20 TV drama.\n", "contributors": [{"name": "Ishii, Akira", "sameAs": [], "familyName": "Ishii", "additionalName": "", "givenName": "Akira", "email": ""}, {"name": "Kitao, Akiko", "sameAs": [], "familyName": "Kitao", "additionalName": "", "givenName": "Akiko", "email": ""}, {"name": "Usui, Tsukasa", "sameAs": [], "familyName": "Usui", "additionalName": "", "givenName": "Tsukasa", "email": ""}, {"name": "Uchiyama, Koki", "sameAs": [], "familyName": "Uchiyama", "additionalName": "", "givenName": "Koki", "email": ""}], "title": "Mathematical model for hit phenomena and its application to analyze\n  popularity of weekly tv drama", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00758", "oai:arXiv.org:1501.00758"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Mathematical model for hit phenomena presented by A Ishii et al in 2012 has\nbeen extended to analyze and predict a lot of hit subject using social network\nsystem. The equation for each individual consumers is assumed and the equation\nof social response to each hit subject is derived as stochastic process of\nstatistical physics. The advertisement effect is included as external force and\nthe communication effects are included as two-body and three-body interaction.\nThe applications of this model are demonstrated for analyzing population of\nweekly TV drama. Including both the realtime view data and the playback view\ndata, we found that the indirect communication correlate strongly to the TV\nviewing rate data for recent Japanese 20 TV drama.\n", "Comment: 18 pages, 12 figures, submitted to International Journal of Modern\n  Physics B: Special issue: Advances on Statistical Physics of Complex Systems\n  as a conference paper of International Conference on Statisitical Physics,\n  Rhodes, Greece, 7-11 July 2014"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00758"}}, {"publisher": {"name": ""}, "description": "  For information transmission a discrete time channel with independent\nadditive Gaussian noise is used. There is also another channel with independent\nadditive Gaussian noise (the feedback channel), and the transmitter observes\nwithout delay all outputs of the forward channel via that channel. Transmission\nof nonexponential number of messages is considered (i.e. transmission rate\nequals zero) and the achievable decoding error exponent for such a combination\nof channels is investigated. The transmission method strengthens the method\nused by authors earlier for BSC and Gaussian channels. In particular, for small\nfeedback noise, it allows to gain 33.3\\% (instead of 23.6\\% earlier in the\nsimilar case of Gaussian channel).\n", "contributors": [{"name": "Burnashev, Marat V.", "sameAs": [], "familyName": "Burnashev", "additionalName": "V.", "givenName": "Marat", "email": ""}, {"name": "Yamamoto, Hirosuke", "sameAs": [], "familyName": "Yamamoto", "additionalName": "", "givenName": "Hirosuke", "email": ""}], "title": "On Using Feedback in a Gaussian Channel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04887", "Problems of Information Transmission, vol. 50, no. 3, pp. 19--34,\n  2014", "oai:arXiv.org:1501.04887"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  For information transmission a discrete time channel with independent\nadditive Gaussian noise is used. There is also another channel with independent\nadditive Gaussian noise (the feedback channel), and the transmitter observes\nwithout delay all outputs of the forward channel via that channel. Transmission\nof nonexponential number of messages is considered (i.e. transmission rate\nequals zero) and the achievable decoding error exponent for such a combination\nof channels is investigated. The transmission method strengthens the method\nused by authors earlier for BSC and Gaussian channels. In particular, for small\nfeedback noise, it allows to gain 33.3\\% (instead of 23.6\\% earlier in the\nsimilar case of Gaussian channel).\n", "Comment: arXiv admin note: text overlap with arXiv:1208.2786"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04887"}}, {"publisher": {"name": ""}, "description": "  Collisions are a main cause of throughput degradation in WLANs. The current\ncontention mechanism used in IEEE 802.11 networks is called Carrier Sense\nMultiple Access with Collision Avoidance (CSMA/CA). It uses a Binary\nExponential Backoff (BEB) technique to randomise each contender attempt of\ntransmitting, effectively reducing the collision probability. Nevertheless,\nCSMA/CA relies on a random backoff that while effective and totally\ndistributed, in principle is unable to completely eliminate collisions,\ntherefore degrading the network throughput as more contenders attempt to share\nthe channel. Carrier Sense Multiple Access with Enhanced Collision Avoidance\n(CSMA/ECA) is able to create a collision-free schedule in a totally distributed\nmanner using a deterministic backoff after successful transmissions. Hysteresis\nand Fair Share are two extensions of CSMA/ECA to support a large number of\ncontenders in a collision-free schedule. CSMA/ECA offers better throughput than\nCSMA/CA and short-term throughput fairness.\n  This work describes CSMA/ECA and its extensions. Additionally, it provides\nthe first evaluation results of CSMA/ECA in non-saturated traffic conditions as\nwell as its performance when coexisting with CSMA/CA nodes. Furthermore, the\neffects of imperfect clocks over CSMA/ECA's deterministic backoff mechanism and\nits consequences when attempting to implement the protocol in real hardware are\nalso analysed.\n", "contributors": [{"name": "Sanabria-Russo, Luis", "sameAs": [], "familyName": "Sanabria-Russo", "additionalName": "", "givenName": "Luis", "email": ""}, {"name": "Barcelo, Jaume", "sameAs": [], "familyName": "Barcelo", "additionalName": "", "givenName": "Jaume", "email": ""}, {"name": "Bellalta, Boris", "sameAs": [], "familyName": "Bellalta", "additionalName": "", "givenName": "Boris", "email": ""}], "title": "A High Efficiency MAC Protocol for WLANs: Providing Fairness in Dense\n  Scenarios", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1395", "oai:arXiv.org:1412.1395"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Collisions are a main cause of throughput degradation in WLANs. The current\ncontention mechanism used in IEEE 802.11 networks is called Carrier Sense\nMultiple Access with Collision Avoidance (CSMA/CA). It uses a Binary\nExponential Backoff (BEB) technique to randomise each contender attempt of\ntransmitting, effectively reducing the collision probability. Nevertheless,\nCSMA/CA relies on a random backoff that while effective and totally\ndistributed, in principle is unable to completely eliminate collisions,\ntherefore degrading the network throughput as more contenders attempt to share\nthe channel. Carrier Sense Multiple Access with Enhanced Collision Avoidance\n(CSMA/ECA) is able to create a collision-free schedule in a totally distributed\nmanner using a deterministic backoff after successful transmissions. Hysteresis\nand Fair Share are two extensions of CSMA/ECA to support a large number of\ncontenders in a collision-free schedule. CSMA/ECA offers better throughput than\nCSMA/CA and short-term throughput fairness.\n  This work describes CSMA/ECA and its extensions. Additionally, it provides\nthe first evaluation results of CSMA/ECA in non-saturated traffic conditions as\nwell as its performance when coexisting with CSMA/CA nodes. Furthermore, the\neffects of imperfect clocks over CSMA/ECA's deterministic backoff mechanism and\nits consequences when attempting to implement the protocol in real hardware are\nalso analysed.\n", "Comment: This work has been submitted to the IEEE/ACM Transactions on\n  Networking journal"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-12-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1395"}}, {"publisher": {"name": ""}, "description": "  The ring and polynomial learning with errors problems (Ring-LWE and Poly-LWE)\nhave been proposed as hard problems to form the basis for cryptosystems, and\nvarious security reductions to hard lattice problems have been presented. So\nfar these problems have been stated for general (number) rings but have only\nbeen closely examined for cyclotomic number rings. In this paper, we state and\nexamine the Ring-LWE problem for general number rings and demonstrate provably\nweak instances of Ring-LWE. We construct an explicit family of number fields\nfor which we have an efficient attack. We demonstrate the attack in both theory\nand practice, providing code and running times for the attack. The attack runs\nin time linear in q, where q is the modulus.\n  Our attack is based on the attack on Poly-LWE which was presented in\n[Eisentr\\\"ager-Hallgren-Lauter]. We extend the EHL-attack to apply to a larger\nclass of number fields, and show how it applies to attack Ring-LWE for a\nheuristically large class of fields. Certain Ring-LWE instances can be\ntransformed into Poly-LWE instances without distorting the error too much, and\nthus provide the first weak instances of the Ring-LWE problem. We also provide\nadditional examples of fields which are vulnerable to our attacks on Poly-LWE,\nincluding power-of-$2$ cyclotomic fields, presented using the minimal\npolynomial of $\\zeta_{2^n} \\pm 1$.\n", "contributors": [{"name": "Elias, Yara", "sameAs": [], "familyName": "Elias", "additionalName": "", "givenName": "Yara", "email": ""}, {"name": "Lauter, Kristin E.", "sameAs": [], "familyName": "Lauter", "additionalName": "E.", "givenName": "Kristin", "email": ""}, {"name": "Ozman, Ekin", "sameAs": [], "familyName": "Ozman", "additionalName": "", "givenName": "Ekin", "email": ""}, {"name": "Stange, Katherine E.", "sameAs": [], "familyName": "Stange", "additionalName": "E.", "givenName": "Katherine", "email": ""}], "title": "Provably weak instances of Ring-LWE", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03708", "oai:arXiv.org:1502.03708"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The ring and polynomial learning with errors problems (Ring-LWE and Poly-LWE)\nhave been proposed as hard problems to form the basis for cryptosystems, and\nvarious security reductions to hard lattice problems have been presented. So\nfar these problems have been stated for general (number) rings but have only\nbeen closely examined for cyclotomic number rings. In this paper, we state and\nexamine the Ring-LWE problem for general number rings and demonstrate provably\nweak instances of Ring-LWE. We construct an explicit family of number fields\nfor which we have an efficient attack. We demonstrate the attack in both theory\nand practice, providing code and running times for the attack. The attack runs\nin time linear in q, where q is the modulus.\n  Our attack is based on the attack on Poly-LWE which was presented in\n[Eisentr\\\"ager-Hallgren-Lauter]. We extend the EHL-attack to apply to a larger\nclass of number fields, and show how it applies to attack Ring-LWE for a\nheuristically large class of fields. Certain Ring-LWE instances can be\ntransformed into Poly-LWE instances without distorting the error too much, and\nthus provide the first weak instances of the Ring-LWE problem. We also provide\nadditional examples of fields which are vulnerable to our attacks on Poly-LWE,\nincluding power-of-$2$ cyclotomic fields, presented using the minimal\npolynomial of $\\zeta_{2^n} \\pm 1$.\n", "Comment: 24 pages including computer code"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "mathematics - number theory", "94a60", "11t71"], "providerUpdatedDateTime": "2015-02-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03708"}}, {"publisher": {"name": ""}, "description": "  Establishing secret common randomness between two or multiple devices in a\nnetwork resides at the root of communication security. The problem is\ntraditionally decomposed into a randomness generation stage (randomness purity\nis subject to employing often costly true random number generators) and a\nkey-agreement information exchange stage, which can rely on public-key\ninfrastructure or on key wrapping. In this paper, we propose KERMAN, an\nalternative key establishment algorithm for ad-hoc networks which works by\nharvesting randomness directly from the network routing metadata, thus\nachieving both pure randomness generation and (implicitly) secret-key\nagreement. Our algorithm relies on the route discovery phase of an ad-hoc\nnetwork employing the Dynamic Source Routing protocol, is lightweight, and\nrequires minimal communication overhead.\n", "contributors": [{"name": "Shoja, Mohammad Reza Khalili", "sameAs": [], "familyName": "Shoja", "additionalName": "Reza Khalili", "givenName": "Mohammad", "email": ""}, {"name": "Amariucai, George Traian", "sameAs": [], "familyName": "Amariucai", "additionalName": "Traian", "givenName": "George", "email": ""}, {"name": "Wei, Shuangqing", "sameAs": [], "familyName": "Wei", "additionalName": "", "givenName": "Shuangqing", "email": ""}, {"name": "Deng, Jing", "sameAs": [], "familyName": "Deng", "additionalName": "", "givenName": "Jing", "email": ""}], "title": "KERMAN: A Key Establishment Algorithm based on Harvesting Randomness in\n  MANETs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03744", "oai:arXiv.org:1504.03744"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Establishing secret common randomness between two or multiple devices in a\nnetwork resides at the root of communication security. The problem is\ntraditionally decomposed into a randomness generation stage (randomness purity\nis subject to employing often costly true random number generators) and a\nkey-agreement information exchange stage, which can rely on public-key\ninfrastructure or on key wrapping. In this paper, we propose KERMAN, an\nalternative key establishment algorithm for ad-hoc networks which works by\nharvesting randomness directly from the network routing metadata, thus\nachieving both pure randomness generation and (implicitly) secret-key\nagreement. Our algorithm relies on the route discovery phase of an ad-hoc\nnetwork employing the Dynamic Source Routing protocol, is lightweight, and\nrequires minimal communication overhead.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-04-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03744"}}, {"publisher": {"name": ""}, "description": "  The girth of a matrix is the least number of linearly dependent columns, in\ncontrast to the rank which is the largest number of linearly independent\ncolumns. This paper considers the construction of {\\it high-girth} matrices,\nwhose probabilistic girth is close to its rank. Random matrices can be used to\nshow the existence of high-girth matrices with constant relative rank, but the\nconstruction is non-explicit. This paper uses a polar-like construction to\nobtain a deterministic and efficient construction of high-girth matrices for\narbitrary fields and relative ranks. Applications to coding and sparse recovery\nare discussed.\n", "contributors": [{"name": "Abbe, Emmanuel", "sameAs": [], "familyName": "Abbe", "additionalName": "", "givenName": "Emmanuel", "email": ""}, {"name": "Wigderson, Yuval", "sameAs": [], "familyName": "Wigderson", "additionalName": "", "givenName": "Yuval", "email": ""}], "title": "High-Girth Matrices and Polarization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06528", "oai:arXiv.org:1501.06528"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  The girth of a matrix is the least number of linearly dependent columns, in\ncontrast to the rank which is the largest number of linearly independent\ncolumns. This paper considers the construction of {\\it high-girth} matrices,\nwhose probabilistic girth is close to its rank. Random matrices can be used to\nshow the existence of high-girth matrices with constant relative rank, but the\nconstruction is non-explicit. This paper uses a polar-like construction to\nobtain a deterministic and efficient construction of high-girth matrices for\narbitrary fields and relative ranks. Applications to coding and sparse recovery\nare discussed.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06528"}}, {"publisher": {"name": ""}, "description": "  Sentiment analysis of microblogs such as Twitter has recently gained a fair\namount of attention. One of the simplest sentiment analysis approaches compares\nthe words of a posting against a labeled word list, where each word has been\nscored for valence, -- a 'sentiment lexicon' or 'affective word lists'. There\nexist several affective word lists, e.g., ANEW (Affective Norms for English\nWords) developed before the advent of microblogging and sentiment analysis. I\nwanted to examine how well ANEW and other word lists performs for the detection\nof sentiment strength in microblog posts in comparison with a new word list\nspecifically constructed for microblogs. I used manually labeled postings from\nTwitter scored for sentiment. Using a simple word matching I show that the new\nword list may perform better than ANEW, though not as good as the more\nelaborate approach found in SentiStrength.\n", "contributors": [{"name": "Nielsen, Finn \u00c5rup", "sameAs": [], "familyName": "Nielsen", "additionalName": "\u00c5rup", "givenName": "Finn", "email": ""}], "title": "A new ANEW: Evaluation of a word list for sentiment analysis in\n  microblogs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-03-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1103.2903", "oai:arXiv.org:1103.2903"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Sentiment analysis of microblogs such as Twitter has recently gained a fair\namount of attention. One of the simplest sentiment analysis approaches compares\nthe words of a posting against a labeled word list, where each word has been\nscored for valence, -- a 'sentiment lexicon' or 'affective word lists'. There\nexist several affective word lists, e.g., ANEW (Affective Norms for English\nWords) developed before the advent of microblogging and sentiment analysis. I\nwanted to examine how well ANEW and other word lists performs for the detection\nof sentiment strength in microblog posts in comparison with a new word list\nspecifically constructed for microblogs. I used manually labeled postings from\nTwitter scored for sentiment. Using a simple word matching I show that the new\nword list may perform better than ANEW, though not as good as the more\nelaborate approach found in SentiStrength.\n", "Comment: 6 pages, 4 figures, 1 table, Submitted to \"Making Sense of Microposts\n  (#MSM2011)\""]}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - computation and language", "68m11", "h.4.3", "j.4"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1103.2903"}}, {"publisher": {"name": ""}, "description": "  We introduce and solve the problem of Byzantine fault tolerant distributed\nquickest change detection in both continuous and discrete time setups. In this\nproblem, multiple sensors sequentially observe random signals from the\nenvironment and send their observations to a control center that will determine\nwhether there is a change in the statistical behavior of the observations. We\nassume that the signals are independent and identically distributed across\nsensors. An unknown subset of sensors are compromised and will send arbitrarily\nmodified and even artificially generated signals to the control center. It is\nshown that the performance of the the so-called CUSUM statistic, which is\noptimal when all sensors are honest, will be significantly degraded in the\npresence of even a single dishonest sensor. In particular, instead of in a\nlogarithmically the detection delay grows linearly with the average run length\n(ARL) to false alarm. To mitigate such a performance degradation, we propose a\nfully distributed low complexity detection scheme. We show that the proposed\nscheme can recover the log scaling. We also propose a centralized group-wise\nscheme that can further reduce the detection delay.\n", "contributors": [{"name": "Bayraktar, Erhan", "sameAs": [], "familyName": "Bayraktar", "additionalName": "", "givenName": "Erhan", "email": ""}, {"name": "Lai, Lifeng", "sameAs": [], "familyName": "Lai", "additionalName": "", "givenName": "Lifeng", "email": ""}], "title": "Byzantine Fault Tolerant Distributed Quickest Change Detection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-09", "2014-12-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.2086", "oai:arXiv.org:1306.2086"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We introduce and solve the problem of Byzantine fault tolerant distributed\nquickest change detection in both continuous and discrete time setups. In this\nproblem, multiple sensors sequentially observe random signals from the\nenvironment and send their observations to a control center that will determine\nwhether there is a change in the statistical behavior of the observations. We\nassume that the signals are independent and identically distributed across\nsensors. An unknown subset of sensors are compromised and will send arbitrarily\nmodified and even artificially generated signals to the control center. It is\nshown that the performance of the the so-called CUSUM statistic, which is\noptimal when all sensors are honest, will be significantly degraded in the\npresence of even a single dishonest sensor. In particular, instead of in a\nlogarithmically the detection delay grows linearly with the average run length\n(ARL) to false alarm. To mitigate such a performance degradation, we propose a\nfully distributed low complexity detection scheme. We show that the proposed\nscheme can recover the log scaling. We also propose a centralized group-wise\nscheme that can further reduce the detection delay.\n", "Comment: Final version. To appear in the SIAM Journal on Control and\n  Optimization. Keywords: (Non-Bayesian) quickest change detection, Byzantine\n  fault tolerance, distributed sensor network, robust optimal stopping in\n  continuous and discrete time"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "computer science - information theory", "mathematics - probability"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.2086"}}, {"publisher": {"name": ""}, "description": "  Algorithms to find communities in networks rely just on structural\ninformation and search for cohesive subsets of nodes. On the other hand, most\nscholars implicitly or explicitly assume that structural communities represent\ngroups of nodes with similar (non-topological) properties or functions. This\nhypothesis could not be verified, so far, because of the lack of network\ndatasets with information on the classification of the nodes. We show that\ntraditional community detection methods fail to find the metadata groups in\nmany large networks. Our results show that there is a marked separation between\nstructural communities and metadata groups, in line with recent findings. That\nmeans that either our current modeling of community structure has to be\nsubstantially modified, or that metadata groups may not be recoverable from\ntopology alone.\n", "contributors": [{"name": "Hric, Darko", "sameAs": [], "familyName": "Hric", "additionalName": "", "givenName": "Darko", "email": ""}, {"name": "Darst, Richard K.", "sameAs": [], "familyName": "Darst", "additionalName": "K.", "givenName": "Richard", "email": ""}, {"name": "Fortunato, Santo", "sameAs": [], "familyName": "Fortunato", "additionalName": "", "givenName": "Santo", "email": ""}], "title": "Community detection in networks: Structural communities versus ground\n  truth", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-01", "2014-12-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.0146", "Phys. Rev. E 90, 062805 (2014)", "doi:10.1103/PhysRevE.90.062805", "oai:arXiv.org:1406.0146"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics", "q-bio"]}}, {"name": "description", "properties": {"description": ["  Algorithms to find communities in networks rely just on structural\ninformation and search for cohesive subsets of nodes. On the other hand, most\nscholars implicitly or explicitly assume that structural communities represent\ngroups of nodes with similar (non-topological) properties or functions. This\nhypothesis could not be verified, so far, because of the lack of network\ndatasets with information on the classification of the nodes. We show that\ntraditional community detection methods fail to find the metadata groups in\nmany large networks. Our results show that there is a marked separation between\nstructural communities and metadata groups, in line with recent findings. That\nmeans that either our current modeling of community structure has to be\nsubstantially modified, or that metadata groups may not be recoverable from\ntopology alone.\n", "Comment: 21 pages, 19 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - information retrieval", "quantitative biology - quantitative methods", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.0146"}}, {"publisher": {"name": ""}, "description": "  In this paper, we consider a distributed detection problem for a censoring\nsensor network where each sensor's communication rate is significantly reduced\nby transmitting only \"informative\" observations to the Fusion Center (FC), and\ncensoring those deemed \"uninformative\". While the independence of data from\ncensoring sensors is often assumed in previous research, we explore spatial\ndependence among observations. Our focus is on designing the fusion rule under\nthe Neyman-Pearson (NP) framework that takes into account the spatial\ndependence among observations. Two transmission scenarios are considered, one\nwhere uncensored observations are transmitted directly to the FC and second\nwhere they are first quantized and then transmitted to further improve\ntransmission efficiency. Copula-based Generalized Likelihood Ratio Test (GLRT)\nfor censored data is proposed with both continuous and discrete messages\nreceived at the FC corresponding to different transmission strategies. We\naddress the computational issues of the copula-based GLRTs involving\nmultidimensional integrals by presenting more efficient fusion rules, based on\nthe key idea of injecting controlled noise at the FC before fusion. Although,\nthe signal-to-noise ratio (SNR) is reduced by introducing controlled noise at\nthe receiver, simulation results demonstrate that the resulting noise-aided\nfusion approach based on adding artificial noise performs very closely to the\nexact copula-based GLRTs. Copula-based GLRTs and their noise-aided counterparts\nby exploiting the spatial dependence greatly improve detection performance\ncompared with the fusion rule under independence assumption.\n", "contributors": [{"name": "He, Hao", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Hao", "email": ""}, {"name": "Varshney, Pramod K.", "sameAs": [], "familyName": "Varshney", "additionalName": "K.", "givenName": "Pramod", "email": ""}], "title": "Fusing Censored Dependent Data for Distributed Detection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07826", "oai:arXiv.org:1503.07826"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  In this paper, we consider a distributed detection problem for a censoring\nsensor network where each sensor's communication rate is significantly reduced\nby transmitting only \"informative\" observations to the Fusion Center (FC), and\ncensoring those deemed \"uninformative\". While the independence of data from\ncensoring sensors is often assumed in previous research, we explore spatial\ndependence among observations. Our focus is on designing the fusion rule under\nthe Neyman-Pearson (NP) framework that takes into account the spatial\ndependence among observations. Two transmission scenarios are considered, one\nwhere uncensored observations are transmitted directly to the FC and second\nwhere they are first quantized and then transmitted to further improve\ntransmission efficiency. Copula-based Generalized Likelihood Ratio Test (GLRT)\nfor censored data is proposed with both continuous and discrete messages\nreceived at the FC corresponding to different transmission strategies. We\naddress the computational issues of the copula-based GLRTs involving\nmultidimensional integrals by presenting more efficient fusion rules, based on\nthe key idea of injecting controlled noise at the FC before fusion. Although,\nthe signal-to-noise ratio (SNR) is reduced by introducing controlled noise at\nthe receiver, simulation results demonstrate that the resulting noise-aided\nfusion approach based on adding artificial noise performs very closely to the\nexact copula-based GLRTs. Copula-based GLRTs and their noise-aided counterparts\nby exploiting the spatial dependence greatly improve detection performance\ncompared with the fusion rule under independence assumption.\n"}}], "languages": [null], "subjects": ["statistics - applications", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07826"}}, {"publisher": {"name": "ScholarlyCommons"}, "description": "Epidermal growth factor receptor (EGFR) mutation and overexpression promote tumorigenesis in multiple cancers. Understanding the complex EGFR regulatory network is critical for developing effective therapeutic interventions. To this end, this work investigated the functions of two incompletely characterized regulators of EGFR trafficking and signaling, mitogen-inducible gene 6 (MIG6) and Sprouty2 (SPRY2), in two cancer settings where EGFR mutation is common, non-small cell lung cancer (NSCLC) and glioblastoma multiforme (GBM). In NSCLC cells, results indicate that MIG6, an endogenous inhibitor of EGFR activity and endocytic adaptor, is surprisingly responsible for at least half of EGFR endocytosis, suggesting that a substantial fraction of internalized EGFR may not be competent to drive signaling. Computational modeling further suggested that in cells expressing kinase-activated, endocytosis-impaired EGFR mutants, the importance of MIG6 relative to other endocytic pathways is increased, but that MIG6 internalization capacity is reduced compared to cells expressing wild-type EGFR. Additional data indicate that SPRY2 expression reduces EGFR endocytosis rate primarily by promoting EGFR expression, which overwhelms the saturable EGFR endocytic pathway, but that SPRY2 also promotes ERK phosphorylation and resistance to EGFR inhibition independent of EGFR expression level. In GBM cell lines, our data demonstrate that SPRY2 expression promotes proliferation, anchorage-independent growth, resistance to EGFR and c-MET co-inhibition, and growth as mouse tumor xenografts. Additional studies identified SPRY2-mediated regulation of the strength and effects of JNK and p38 MAP kinase pathways as important for controlling GBM cell behaviors. Through analysis of public datasets and a collaborative analysis of human and rat tumors, we further found that elevated SPRY2 expression is associated with reduced patient survival and expression of EGFR variant III, an EGFR mutant linked to aggressive GBM. Thus, while SPRY2 is a candidate tumor suppressor in other contexts, our results support a tumor promoter role for SPRY2 in GBM and identify SPRY2 and the pathways it regulates as potential therapeutic targets or biomarkers for therapeutic response. Overall, these findings add new qualitative and quantitative understanding of the complexities of EGFR trafficking and signaling regulation and the functions of SPRY2 and MIG6 that may be leveraged to develop improved cancer therapies.", "contributors": [{"name": "Walsh, Alice Macdonald", "sameAs": [], "familyName": "Walsh", "additionalName": "Macdonald", "givenName": "Alice", "email": ""}], "title": "Regulation of cell signaling by MIG6 and Sprouty2 in cancers with EGFR mutations", "shareProperties": {"source": "upennsylvania"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-01-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.upenn.edu/edissertations/1302", "http://repository.upenn.edu/cgi/viewcontent.cgi?article=2426&amp;context=edissertations", "oai:repository.upenn.edu:edissertations-2426"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:be", "publication:edissertations", "publication:seas"]}}, {"name": "source", "properties": {"source": "Publicly Accessible Penn Dissertations"}}, {"name": "rights", "properties": {"rights": []}}], "languages": [null], "subjects": ["cancer", "drug resistance", "feedback", "cell biology", "biomedical", "computational modeling", "signaling"], "providerUpdatedDateTime": "2015-03-16T19:01:32", "uris": {"canonicalUri": "http://repository.upenn.edu/edissertations/1302"}}, {"publisher": {"name": ""}, "description": "  \\noindent We present an algorithm to $3$-colour a graph $G$ without triangles\nor induced paths on seven vertices in $O(|V(G)|^7)$ time. In fact, our\nalgorithm solves the list $3$-colouring problem, where each vertex is assigned\na subset of $\\{1,2,3\\}$ as its admissible colours.\n", "contributors": [{"name": "Bonomo, Flavia", "sameAs": [], "familyName": "Bonomo", "additionalName": "", "givenName": "Flavia", "email": ""}, {"name": "Schaudt, Oliver", "sameAs": [], "familyName": "Schaudt", "additionalName": "", "givenName": "Oliver", "email": ""}, {"name": "Stein, Maya", "sameAs": [], "familyName": "Stein", "additionalName": "", "givenName": "Maya", "email": ""}], "title": "3-Colouring graphs without triangles or induced paths on seven vertices", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-30", "2014-10-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.0040", "oai:arXiv.org:1410.0040"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  \\noindent We present an algorithm to $3$-colour a graph $G$ without triangles\nor induced paths on seven vertices in $O(|V(G)|^7)$ time. In fact, our\nalgorithm solves the list $3$-colouring problem, where each vertex is assigned\na subset of $\\{1,2,3\\}$ as its admissible colours.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-10-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.0040"}}, {"publisher": {"name": ""}, "description": "  Over the past few years, symmetric positive definite (SPD) matrices have been\nreceiving considerable attention from computer vision community. Though various\ndistance measures have been proposed in the past for comparing SPD matrices,\nthe two most widely-used measures are affine-invariant distance and\nlog-Euclidean distance. This is because these two measures are true geodesic\ndistances induced by Riemannian geometry. In this work, we focus on the\nlog-Euclidean Riemannian geometry and propose a data-driven approach for\nlearning Riemannian metrics/geodesic distances for SPD matrices. We show that\nthe geodesic distance learned using the proposed approach performs better than\nvarious existing distance measures when evaluated on face matching and\nclustering tasks.\n", "contributors": [{"name": "Vemulapalli, Raviteja", "sameAs": [], "familyName": "Vemulapalli", "additionalName": "", "givenName": "Raviteja", "email": ""}, {"name": "Jacobs, David W.", "sameAs": [], "familyName": "Jacobs", "additionalName": "W.", "givenName": "David", "email": ""}], "title": "Riemannian Metric Learning for Symmetric Positive Definite Matrices", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.02393", "oai:arXiv.org:1501.02393"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Over the past few years, symmetric positive definite (SPD) matrices have been\nreceiving considerable attention from computer vision community. Though various\ndistance measures have been proposed in the past for comparing SPD matrices,\nthe two most widely-used measures are affine-invariant distance and\nlog-Euclidean distance. This is because these two measures are true geodesic\ndistances induced by Riemannian geometry. In this work, we focus on the\nlog-Euclidean Riemannian geometry and propose a data-driven approach for\nlearning Riemannian metrics/geodesic distances for SPD matrices. We show that\nthe geodesic distance learned using the proposed approach performs better than\nvarious existing distance measures when evaluated on face matching and\nclustering tasks.\n"}}], "languages": [null], "subjects": ["computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.02393"}}, {"publisher": {"name": ""}, "description": "  We present a user-friendly, but powerful interface for the data mining of\nscientific repositories. We present the tool in use with actual astronomy data\nand show how it may be used to achieve many different types of powerful\nsemantic queries. The tool itself hides the gory details of query formulation,\nand data retrieval from the user, and allows the user to create workflows which\nmay be used to transform the data into a convenient form.\n", "contributors": [{"name": "Thomas, Brian", "sameAs": [], "familyName": "Thomas", "additionalName": "", "givenName": "Brian", "email": ""}, {"name": "Shaya, Edward", "sameAs": [], "familyName": "Shaya", "additionalName": "", "givenName": "Edward", "email": ""}], "title": "A User Interface for Semantically Oriented Data Mining of Astronomy\n  Repositories", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06492", "oai:arXiv.org:1502.06492"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:astro-ph"]}}, {"name": "description", "properties": {"description": ["  We present a user-friendly, but powerful interface for the data mining of\nscientific repositories. We present the tool in use with actual astronomy data\nand show how it may be used to achieve many different types of powerful\nsemantic queries. The tool itself hides the gory details of query formulation,\nand data retrieval from the user, and allows the user to create workflows which\nmay be used to transform the data into a convenient form.\n", "Comment: ADASS ASP Conference Series, Vol. 394, Proceedings of the conference\n  held 23-26 September, 2007, in Kensington Town Hall, London, United Kingdom.\n  Edited by Robert W. Argyle, Peter S. Bunclark, and James R. Lewis., p.361"]}}], "languages": [null], "subjects": ["computer science - human-computer interaction", "astrophysics - instrumentation and methods for astrophysics"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06492"}}, {"publisher": {"name": ""}, "description": "  In this work, we consider linear-feedback schemes for the two-user Gaussian\nbroadcast channel with noiseless feedback. We extend the transmission scheme of\n[Ozarow and Leung, 1984] by applying estimators with memory instead of the\nmemoryless estimators used by Ozarow and Leung (OL) in their original work. A\nrecursive formulation of the mean square errors achieved by the proposed\nestimators is provided, along with a proof for the existence of a fixed point.\nThis enables characterizing the achievable rates of the extended scheme.\nFinally, via numerical simulations it is shown that the extended scheme can\nimprove upon the original OL scheme in terms of achievable rates, as well as\nachieve a low probability of error after a finite number of channel uses.\n", "contributors": [{"name": "Murin, Yonathan", "sameAs": [], "familyName": "Murin", "additionalName": "", "givenName": "Yonathan", "email": ""}, {"name": "Kaspi, Yonatan", "sameAs": [], "familyName": "Kaspi", "additionalName": "", "givenName": "Yonatan", "email": ""}, {"name": "Dabora, Ron", "sameAs": [], "familyName": "Dabora", "additionalName": "", "givenName": "Ron", "email": ""}], "title": "On the Ozarow-Leung Scheme for the Gaussian Broadcast Channel with\n  Feedback", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6782", "doi:10.1109/LSP.2014.2375893", "oai:arXiv.org:1412.6782"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this work, we consider linear-feedback schemes for the two-user Gaussian\nbroadcast channel with noiseless feedback. We extend the transmission scheme of\n[Ozarow and Leung, 1984] by applying estimators with memory instead of the\nmemoryless estimators used by Ozarow and Leung (OL) in their original work. A\nrecursive formulation of the mean square errors achieved by the proposed\nestimators is provided, along with a proof for the existence of a fixed point.\nThis enables characterizing the achievable rates of the extended scheme.\nFinally, via numerical simulations it is shown that the extended scheme can\nimprove upon the original OL scheme in terms of achievable rates, as well as\nachieve a low probability of error after a finite number of channel uses.\n", "Comment: Accepted to IEEE Signal Processing Letters"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6782"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "by William Q. Hubbard, Jr.", "contributors": [{"name": "Hubbard, Bill, 1947-", "sameAs": [], "familyName": "Hubbard", "additionalName": "", "givenName": "Bill", "email": ""}, {"name": "Stanford Anderson.", "sameAs": [], "familyName": "Anderson.", "additionalName": "", "givenName": "Stanford", "email": ""}], "title": "A system of formal analysis for architectural composition", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "193 leaves"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/67370", "02660500", "oai:dspace.mit.edu:1721.1/67370"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2011-12-05T19:45:42Z", "2011-12-05T19:45:42Z", "1976"]}}, {"name": "description", "properties": {"description": ["by William Q. Hubbard, Jr.", "Thesis. 1976. M.ArchAS--Massachusetts Institute of Technology. Dept. of Architecture.", "Microfiche copy available in Archives and Rotch.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7635", "hdl_1721.1_7772"]}}], "languages": [null], "subjects": ["architecture conservation and restoration designs and plans", "proportion", "etc", "architecture", "architecture composition", "architectural design", "architecture history"], "providerUpdatedDateTime": "2015-04-27T15:30:03", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/67370"}}, {"publisher": {"name": ""}, "description": "  We propose a multicast scheduling scheme to exploit content reuse when there\nis asynchronicity in user requests. A unicast transmission setup is used for\ncontent delivery, while multicast transmission is employed opportunistically to\nreduce wireless resource usage. We then develop a multicast scheduling scheme\nfor the downlink multiple-input multiple output orthogonal-frequency division\nmultiplexing system in IEEE 802.11 wireless local area network (WLAN). At each\ntime slot, the scheduler serves the users by either unicast or multicast\ntransmission. Out-sequence data received by a user is stored in user's cache\nfor future use.Multicast precoding and user selection for multicast grouping\nare also considered and compliance with the IEEE 802.11 WLAN transmission\nprotocol. The scheduling scheme is based on the Lyapunov optimization\ntechnique, which aims to maximize system rate. The resulting scheme has low\ncomplexity and requires no prior statistical information on the channels and\nqueues. Furthermore, in the absence of channel error, the proposed scheme\nrestricts the worst case of frame dropping deadline, which is useful for\ndelivering real-time traffic. Simulation results show that our proposed\nalgorithm outperforms existing techniques by 17 % to 35 % in term of user\ncapacity.\n", "contributors": [{"name": "Tan, Peng Hui", "sameAs": [], "familyName": "Tan", "additionalName": "Hui", "givenName": "Peng", "email": ""}, {"name": "Joung, Jingon", "sameAs": [], "familyName": "Joung", "additionalName": "", "givenName": "Jingon", "email": ""}, {"name": "Sun, Sumei", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Sumei", "email": ""}], "title": "Opportunistic Multicast Scheduling for Unicast Transmission in MIMO-OFDM\n  System", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2714", "oai:arXiv.org:1411.2714"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We propose a multicast scheduling scheme to exploit content reuse when there\nis asynchronicity in user requests. A unicast transmission setup is used for\ncontent delivery, while multicast transmission is employed opportunistically to\nreduce wireless resource usage. We then develop a multicast scheduling scheme\nfor the downlink multiple-input multiple output orthogonal-frequency division\nmultiplexing system in IEEE 802.11 wireless local area network (WLAN). At each\ntime slot, the scheduler serves the users by either unicast or multicast\ntransmission. Out-sequence data received by a user is stored in user's cache\nfor future use.Multicast precoding and user selection for multicast grouping\nare also considered and compliance with the IEEE 802.11 WLAN transmission\nprotocol. The scheduling scheme is based on the Lyapunov optimization\ntechnique, which aims to maximize system rate. The resulting scheme has low\ncomplexity and requires no prior statistical information on the channels and\nqueues. Furthermore, in the absence of channel error, the proposed scheme\nrestricts the worst case of frame dropping deadline, which is useful for\ndelivering real-time traffic. Simulation results show that our proposed\nalgorithm outperforms existing techniques by 17 % to 35 % in term of user\ncapacity.\n", "Comment: 6 pages, conference"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2714"}}, {"publisher": {"name": ""}, "description": "  A network supporting deep unsupervised learning is presented. The network is\nan autoencoder with lateral shortcut connections from the encoder to decoder at\neach level of the hierarchy. The lateral shortcut connections allow the higher\nlevels of the hierarchy to focus on abstract invariant features. While standard\nautoencoders are analogous to latent variable models with a single layer of\nstochastic variables, the proposed network is analogous to hierarchical latent\nvariables models. Learning combines denoising autoencoder and denoising sources\nseparation frameworks. Each layer of the network contributes to the cost\nfunction a term which measures the distance of the representations produced by\nthe encoder and the decoder. Since training signals originate from all levels\nof the network, all layers can learn efficiently even in deep networks. The\nspeedup offered by cost terms from higher levels of the hierarchy and the\nability to learn invariant features are demonstrated in experiments.\n", "contributors": [{"name": "Valpola, Harri", "sameAs": [], "familyName": "Valpola", "additionalName": "", "givenName": "Harri", "email": ""}], "title": "From neural PCA to deep unsupervised learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-28", "2015-02-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7783", "oai:arXiv.org:1411.7783"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  A network supporting deep unsupervised learning is presented. The network is\nan autoencoder with lateral shortcut connections from the encoder to decoder at\neach level of the hierarchy. The lateral shortcut connections allow the higher\nlevels of the hierarchy to focus on abstract invariant features. While standard\nautoencoders are analogous to latent variable models with a single layer of\nstochastic variables, the proposed network is analogous to hierarchical latent\nvariables models. Learning combines denoising autoencoder and denoising sources\nseparation frameworks. Each layer of the network contributes to the cost\nfunction a term which measures the distance of the representations produced by\nthe encoder and the decoder. Since training signals originate from all levels\nof the network, all layers can learn efficiently even in deep networks. The\nspeedup offered by cost terms from higher levels of the hierarchy and the\nability to learn invariant features are demonstrated in experiments.\n", "Comment: A revised version of an article that has been accepted for\n  publication in Advances in Independent Component Analysis and Learning\n  Machines (2015), edited by Ella Bingham, Samuel Kaski, Jorma Laaksonen and\n  Jouko Lampinen"]}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7783"}}, {"publisher": {"name": ""}, "description": "  In the classical cop and robber game, two players, the cop C and the robber\nR, move alternatively along edges of a finite graph G. The cop captures the\nrobber if both players are on the same vertex at the same moment of time. A\ngraph G is called cop win if the cop always captures the robber after a finite\nnumber of steps. Nowakowski, Winkler (1983) and Quilliot (1983) characterized\nthe cop-win graphs as graphs admitting a dismantling scheme. In this paper, we\ncharacterize in a similar way the class CW(s,s') of cop-win graphs in the game\nin which the cop and the robber move at different speeds s' and s, s'<= s. We\nalso establish some connections between cop-win graphs for this game with s'<s\nand Gromov's hyperbolicity. In the particular case s'=1 and s=2, we prove that\nthe class of cop-win graphs is exactly the well-known class of dually chordal\ngraphs. We show that all classes CW(s,1), s>=3, coincide and we provide a\nstructural characterization of these graphs. We also investigate several\ndismantling schemes necessary or sufficient for the cop-win graphs in the game\nin which the robber is visible only every k moves for a fixed integer k>1. We\ncharacterize the graphs which are cop-win for any value of k. Finally, we\nconsider the game where the cop wins if he is at distance at most 1 from the\nrobber and we characterize via a specific dismantling scheme the bipartite\ngraphs where a single cop wins in this game.\n", "contributors": [{"name": "Chalopin, J\u00e9r\u00e9mie", "sameAs": [], "familyName": "Chalopin", "additionalName": "", "givenName": "J\u00e9r\u00e9mie", "email": ""}, {"name": "Chepoi, Victor", "sameAs": [], "familyName": "Chepoi", "additionalName": "", "givenName": "Victor", "email": ""}, {"name": "Nisse, Nicolas", "sameAs": [], "familyName": "Nisse", "additionalName": "", "givenName": "Nicolas", "email": ""}, {"name": "Vax\u00e8s, Yann", "sameAs": [], "familyName": "Vax\u00e8s", "additionalName": "", "givenName": "Yann", "email": ""}], "title": "Cop and robber games when the robber can hide and ride", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-01-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1001.4457", "SIAM J. Discrete Math. 25(2011) 333-359", "oai:arXiv.org:1001.4457"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In the classical cop and robber game, two players, the cop C and the robber\nR, move alternatively along edges of a finite graph G. The cop captures the\nrobber if both players are on the same vertex at the same moment of time. A\ngraph G is called cop win if the cop always captures the robber after a finite\nnumber of steps. Nowakowski, Winkler (1983) and Quilliot (1983) characterized\nthe cop-win graphs as graphs admitting a dismantling scheme. In this paper, we\ncharacterize in a similar way the class CW(s,s') of cop-win graphs in the game\nin which the cop and the robber move at different speeds s' and s, s'<= s. We\nalso establish some connections between cop-win graphs for this game with s'<s\nand Gromov's hyperbolicity. In the particular case s'=1 and s=2, we prove that\nthe class of cop-win graphs is exactly the well-known class of dually chordal\ngraphs. We show that all classes CW(s,1), s>=3, coincide and we provide a\nstructural characterization of these graphs. We also investigate several\ndismantling schemes necessary or sufficient for the cop-win graphs in the game\nin which the robber is visible only every k moves for a fixed integer k>1. We\ncharacterize the graphs which are cop-win for any value of k. Finally, we\nconsider the game where the cop wins if he is at distance at most 1 from the\nrobber and we characterize via a specific dismantling scheme the bipartite\ngraphs where a single cop wins in this game.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1001.4457"}}, {"publisher": {"name": ""}, "description": "  Decision support system in Requirements engineering plays an important role\nin software development life cycle. The relationship between functional and\nnon-functional requirements often plays a crucial role in resolving conflicts\nor arriving at decisions in requirements engineering phase. Goal-Oriented\nRequirements Engineering (GORE) methods make a good attempt of addressing these\naspects which are helpful in decision support. We propose a GORE method -\nIntegrating goals after prioritization and evaluation (IGAPE). The method is\nsemi-formal in nature thereby ensuring active stakeholder participation. In\nthis paper we elaborate the various steps of IGAPE method. The output of IGAPE\nis then given as input to a decision support system which makes use of Analytic\nHierarchy Process (AHP) and Technique for Order of Preference by Similarity to\nIdeal Solution (TOPSIS). Integration of IGAPE with AHP and TOPSIS will clearly\nprovide a rationale for various decisions which are arrived at during the\nrequirements engineering phase. The method is illustrated for an e-commerce\napplication and is validated by expert analysis approach.\n", "contributors": [{"name": "Vinay, S", "sameAs": [], "familyName": "Vinay", "additionalName": "", "givenName": "S", "email": ""}, {"name": "Aithal, Shridhar", "sameAs": [], "familyName": "Aithal", "additionalName": "", "givenName": "Shridhar", "email": ""}, {"name": "Adiga, Sudhakara", "sameAs": [], "familyName": "Adiga", "additionalName": "", "givenName": "Sudhakara", "email": ""}], "title": "Integrating goals after prioritization and evaluation-A Goal-oriented\n  requirements engineering method", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2588", "doi:10.5121/ijsea.2014.5604", "oai:arXiv.org:1412.2588"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Decision support system in Requirements engineering plays an important role\nin software development life cycle. The relationship between functional and\nnon-functional requirements often plays a crucial role in resolving conflicts\nor arriving at decisions in requirements engineering phase. Goal-Oriented\nRequirements Engineering (GORE) methods make a good attempt of addressing these\naspects which are helpful in decision support. We propose a GORE method -\nIntegrating goals after prioritization and evaluation (IGAPE). The method is\nsemi-formal in nature thereby ensuring active stakeholder participation. In\nthis paper we elaborate the various steps of IGAPE method. The output of IGAPE\nis then given as input to a decision support system which makes use of Analytic\nHierarchy Process (AHP) and Technique for Order of Preference by Similarity to\nIdeal Solution (TOPSIS). Integration of IGAPE with AHP and TOPSIS will clearly\nprovide a rationale for various decisions which are arrived at during the\nrequirements engineering phase. The method is illustrated for an e-commerce\napplication and is validated by expert analysis approach.\n", "Comment: IJSEA 2014"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2588"}}, {"publisher": {"name": ""}, "description": "  We investigate compressibility of the dimension of positive semidefinite\nmatrices while approximately preserving their pairwise inner products. This can\neither be regarded as compression of positive semidefinite factorizations of\nnonnegative matrices or (if the matrices are subject to additional\nnormalization constraints) as compression of quantum models. We derive both\nlower and upper bounds on compressibility. Applications are broad and range\nfrom the statistical analysis of experimental data to bounding the one-way\nquantum communication complexity of Boolean functions.\n", "contributors": [{"name": "Stark, Cyril J.", "sameAs": [], "familyName": "Stark", "additionalName": "J.", "givenName": "Cyril", "email": ""}, {"name": "Harrow, Aram W.", "sameAs": [], "familyName": "Harrow", "additionalName": "W.", "givenName": "Aram", "email": ""}], "title": "Compressibility of positive semidefinite factorizations and quantum\n  models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7437", "oai:arXiv.org:1412.7437"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": ["  We investigate compressibility of the dimension of positive semidefinite\nmatrices while approximately preserving their pairwise inner products. This can\neither be regarded as compression of positive semidefinite factorizations of\nnonnegative matrices or (if the matrices are subject to additional\nnormalization constraints) as compression of quantum models. We derive both\nlower and upper bounds on compressibility. Applications are broad and range\nfrom the statistical analysis of experimental data to bounding the one-way\nquantum communication complexity of Boolean functions.\n", "Comment: 13 pages"]}}], "languages": [null], "subjects": ["quantum physics", "computer science - information theory"], "providerUpdatedDateTime": "2014-12-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7437"}}, {"publisher": {"name": ""}, "description": "  In this paper, we study top-$k$ aggregate (or group) nearest neighbor queries\nusing the weighted SUM operator under the $L_1$ metric in the plane. Given a\nset $P$ of $n$ points, for any query consisting of a set $Q$ of $m$ weighted\npoints and an integer $k$, $ 1 \\le k \\le n$, the top-$k$ aggregate nearest\nneighbor query asks for the $k$ points of $P$ whose aggregate distances to $Q$\nare the smallest, where the aggregate distance of each point $p$ of $P$ to $Q$\nis the sum of the weighted distances from $p$ to all points of $Q$. We build an\n$O(n\\log n\\log\\log n)$-size data structure in $O(n\\log n \\log\\log n)$ time,\nsuch that each top-$k$ query can be answered in $O(m\\log m+(k+m)\\log^2 n)$\ntime. We also obtain other results with trade-off between preprocessing and\nquery. Even for the special case where $k=1$, our results are better than the\npreviously best method (in PODS 2012), which requires $O(n\\log^2 n)$\npreprocessing time, $O(n\\log^2 n)$ space, and $O(m^2\\log^3 n)$ query time. In\naddition, for the one-dimensional version of this problem, our approach can\nbuild an $O(n)$-size data structure in $O(n\\log n)$ time that can support\n$O(\\min\\{k,\\log m\\}\\cdot m+k+\\log n)$ time queries. Further, we extend our\ntechniques to the top-$k$ aggregate farthest neighbor queries, with the same\nbounds.\n", "contributors": [{"name": "Wang, Haitao", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Haitao", "email": ""}, {"name": "Zhang, Wuzhou", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Wuzhou", "email": ""}], "title": "On Top-$k$ Weighted SUM Aggregate Nearest and Farthest Neighbors in the\n  $L_1$ Plane", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-11-21", "2014-11-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1211.5084", "oai:arXiv.org:1211.5084"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we study top-$k$ aggregate (or group) nearest neighbor queries\nusing the weighted SUM operator under the $L_1$ metric in the plane. Given a\nset $P$ of $n$ points, for any query consisting of a set $Q$ of $m$ weighted\npoints and an integer $k$, $ 1 \\le k \\le n$, the top-$k$ aggregate nearest\nneighbor query asks for the $k$ points of $P$ whose aggregate distances to $Q$\nare the smallest, where the aggregate distance of each point $p$ of $P$ to $Q$\nis the sum of the weighted distances from $p$ to all points of $Q$. We build an\n$O(n\\log n\\log\\log n)$-size data structure in $O(n\\log n \\log\\log n)$ time,\nsuch that each top-$k$ query can be answered in $O(m\\log m+(k+m)\\log^2 n)$\ntime. We also obtain other results with trade-off between preprocessing and\nquery. Even for the special case where $k=1$, our results are better than the\npreviously best method (in PODS 2012), which requires $O(n\\log^2 n)$\npreprocessing time, $O(n\\log^2 n)$ space, and $O(m^2\\log^3 n)$ query time. In\naddition, for the one-dimensional version of this problem, our approach can\nbuild an $O(n)$-size data structure in $O(n\\log n)$ time that can support\n$O(\\min\\{k,\\log m\\}\\cdot m+k+\\log n)$ time queries. Further, we extend our\ntechniques to the top-$k$ aggregate farthest neighbor queries, with the same\nbounds.\n", "Comment: 24 pages; this version extends our results in the previous version to\n  more general problem settings, and the title has been changed accordingly"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - databases", "computer science - computational geometry"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1211.5084"}}, {"publisher": {"name": ""}, "description": "  Approximating non-linear kernels using feature maps has gained a lot of\ninterest in recent years due to applications in reducing training and testing\ntimes of SVM classifiers and other kernel based learning algorithms. We extend\nthis line of work and present low distortion embeddings for dot product kernels\ninto linear Euclidean spaces. We base our results on a classical result in\nharmonic analysis characterizing all dot product kernels and use it to define\nrandomized feature maps into explicit low dimensional Euclidean spaces in which\nthe native dot product provides an approximation to the dot product kernel with\nhigh confidence.\n", "contributors": [{"name": "Kar, Purushottam", "sameAs": [], "familyName": "Kar", "additionalName": "", "givenName": "Purushottam", "email": ""}, {"name": "Karnick, Harish", "sameAs": [], "familyName": "Karnick", "additionalName": "", "givenName": "Harish", "email": ""}], "title": "Random Feature Maps for Dot Product Kernels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-01-31", "2012-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1201.6530", "Journal of Machine Learning Research, W&CP 22 (2012) 583-591", "oai:arXiv.org:1201.6530"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  Approximating non-linear kernels using feature maps has gained a lot of\ninterest in recent years due to applications in reducing training and testing\ntimes of SVM classifiers and other kernel based learning algorithms. We extend\nthis line of work and present low distortion embeddings for dot product kernels\ninto linear Euclidean spaces. We base our results on a classical result in\nharmonic analysis characterizing all dot product kernels and use it to define\nrandomized feature maps into explicit low dimensional Euclidean spaces in which\nthe native dot product provides an approximation to the dot product kernel with\nhigh confidence.\n", "Comment: To appear in the proceedings of the 15th International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2012). This version corrects\n  a minor error with Lemma 10. Acknowledgements : Devanshu Bhimwal"]}}], "languages": [null], "subjects": ["statistics - machine learning", "computer science - learning", "mathematics - functional analysis", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1201.6530"}}, {"publisher": {"name": ""}, "description": "  We introduce a learning-based approach to detect repeatable keypoints under\ndrastic imaging changes of weather and lighting conditions to which\nstate-of-the-art keypoint detectors are surprisingly sensitive. We first\nidentify good keypoint candidates in multiple training images taken from the\nsame viewpoint. We then train a regressor to predict a score map whose maxima\nare those points so that they can be found by simple non-maximum suppression.\nAs there are no standard datasets to test the influence of these kinds of\nchanges, we created our own, which we will make publicly available. We will\nshow that our method significantly outperforms the state-of-the-art methods in\nsuch challenging conditions, while still achieving state-of-the-art performance\non the untrained standard Oxford dataset.\n", "contributors": [{"name": "Verdie, Yannick", "sameAs": [], "familyName": "Verdie", "additionalName": "", "givenName": "Yannick", "email": ""}, {"name": "Yi, Kwang Moo", "sameAs": [], "familyName": "Yi", "additionalName": "Moo", "givenName": "Kwang", "email": ""}, {"name": "Fua, Pascal", "sameAs": [], "familyName": "Fua", "additionalName": "", "givenName": "Pascal", "email": ""}, {"name": "Lepetit, Vincent", "sameAs": [], "familyName": "Lepetit", "additionalName": "", "givenName": "Vincent", "email": ""}], "title": "TILDE: A Temporally Invariant Learned DEtector", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-17", "2015-03-12"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4568", "oai:arXiv.org:1411.4568"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We introduce a learning-based approach to detect repeatable keypoints under\ndrastic imaging changes of weather and lighting conditions to which\nstate-of-the-art keypoint detectors are surprisingly sensitive. We first\nidentify good keypoint candidates in multiple training images taken from the\nsame viewpoint. We then train a regressor to predict a score map whose maxima\nare those points so that they can be found by simple non-maximum suppression.\nAs there are no standard datasets to test the influence of these kinds of\nchanges, we created our own, which we will make publicly available. We will\nshow that our method significantly outperforms the state-of-the-art methods in\nsuch challenging conditions, while still achieving state-of-the-art performance\non the untrained standard Oxford dataset.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4568"}}, {"publisher": {"name": ""}, "description": "  We develop a framework for extracting a concise representation of the shape\ninformation available from diffuse shading in a small image patch. This\nproduces a mid-level scene descriptor, comprised of local shape distributions\nthat are inferred separately at every image patch across multiple scales. The\nframework is based on a quadratic representation of local shape that, in the\nabsence of noise, has guarantees on recovering accurate local shape and\nlighting. And when noise is present, the inferred local shape distributions\nprovide useful shape information without over-committing to any particular\nimage explanation. These local shape distributions naturally encode the fact\nthat some smooth diffuse regions are more informative than others, and they\nenable efficient and robust reconstruction of object-scale shape. Experimental\nresults show that this approach to surface reconstruction compares well against\nthe state-of-art on both synthetic images and captured photographs.\n", "contributors": [{"name": "Xiong, Ying", "sameAs": [], "familyName": "Xiong", "additionalName": "", "givenName": "Ying", "email": ""}, {"name": "Chakrabarti, Ayan", "sameAs": [], "familyName": "Chakrabarti", "additionalName": "", "givenName": "Ayan", "email": ""}, {"name": "Basri, Ronen", "sameAs": [], "familyName": "Basri", "additionalName": "", "givenName": "Ronen", "email": ""}, {"name": "Gortler, Steven J.", "sameAs": [], "familyName": "Gortler", "additionalName": "J.", "givenName": "Steven", "email": ""}, {"name": "Jacobs, David W.", "sameAs": [], "familyName": "Jacobs", "additionalName": "W.", "givenName": "David", "email": ""}, {"name": "Zickler, Todd", "sameAs": [], "familyName": "Zickler", "additionalName": "", "givenName": "Todd", "email": ""}], "title": "From Shading to Local Shape", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-10", "2014-04-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.2916", "IEEE Trans. PAMI 37 (2015) 67-79", "doi:10.1109/TPAMI.2014.2343211", "oai:arXiv.org:1310.2916"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We develop a framework for extracting a concise representation of the shape\ninformation available from diffuse shading in a small image patch. This\nproduces a mid-level scene descriptor, comprised of local shape distributions\nthat are inferred separately at every image patch across multiple scales. The\nframework is based on a quadratic representation of local shape that, in the\nabsence of noise, has guarantees on recovering accurate local shape and\nlighting. And when noise is present, the inferred local shape distributions\nprovide useful shape information without over-committing to any particular\nimage explanation. These local shape distributions naturally encode the fact\nthat some smooth diffuse regions are more informative than others, and they\nenable efficient and robust reconstruction of object-scale shape. Experimental\nresults show that this approach to surface reconstruction compares well against\nthe state-of-art on both synthetic images and captured photographs.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-04-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.2916"}}, {"publisher": {"name": ""}, "description": "  In this letter, we present the first characterization for the achievable\nDegrees-of-Freedom (DoF) by Blind Interference Alignment (BIA) using staggered\nantenna switching in the $K$-user Gaussian Interference Channel. In such\nscheme, each transmitter is equipped with one conventional antenna and each\nreceiver is equipped with one reconfigurable (multi-mode) antenna. Assuming\nthat the channel is known to the receivers only, we show that BIA can achieve\n$\\frac{2K}{K+2}$ DoF, which surpasses the sum DoF achieved by previously known\ninterference alignment schemes with delayed channel state information at\ntransmitters (CSIT). This result implies that the sum DoF is upper bounded by\n2, which means that the best we can do with BIA is to double the DoF achieved\nby orthogonal multiple access schemes. Moreover, we propose an algorithm to\ngenerate the transmit beamforming vectors and the reconfigurable antenna\nswitching patterns, and apply this algorithm to the 4-user SISO Interference\nChannel, showing that $\\frac{4}{3}$ sum DoF is achievable.\n", "contributors": [{"name": "Alaa, Ahmed M.", "sameAs": [], "familyName": "Alaa", "additionalName": "M.", "givenName": "Ahmed", "email": ""}, {"name": "Ismail, Mahmoud H.", "sameAs": [], "familyName": "Ismail", "additionalName": "H.", "givenName": "Mahmoud", "email": ""}], "title": "Degrees-of-Freedom of the K-user SISO Interference Channel with Blind\n  Interference Alignment using Staggered Antenna Switching", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-27", "2014-12-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6427", "oai:arXiv.org:1408.6427"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this letter, we present the first characterization for the achievable\nDegrees-of-Freedom (DoF) by Blind Interference Alignment (BIA) using staggered\nantenna switching in the $K$-user Gaussian Interference Channel. In such\nscheme, each transmitter is equipped with one conventional antenna and each\nreceiver is equipped with one reconfigurable (multi-mode) antenna. Assuming\nthat the channel is known to the receivers only, we show that BIA can achieve\n$\\frac{2K}{K+2}$ DoF, which surpasses the sum DoF achieved by previously known\ninterference alignment schemes with delayed channel state information at\ntransmitters (CSIT). This result implies that the sum DoF is upper bounded by\n2, which means that the best we can do with BIA is to double the DoF achieved\nby orthogonal multiple access schemes. Moreover, we propose an algorithm to\ngenerate the transmit beamforming vectors and the reconfigurable antenna\nswitching patterns, and apply this algorithm to the 4-user SISO Interference\nChannel, showing that $\\frac{4}{3}$ sum DoF is achievable.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6427"}}, {"publisher": {"name": ""}, "description": "  One of the frustrating things in the digital fabrication era is that its\nmedia are neither affordable nor easily accessible and usable.\nThree-dimensional (3D) fabrication media (DFM) such as 3D Printers and 3D\nScanners have experienced an upsurge in popularity, while the latter remain\nexpensive and hard to function. With this paper, we aim to present you the\nRhoScanner Project - a an affordable and efficient Three-dimensional Projective\nScanner for Smart-phones, hence shedding light on the extended capabilities of\ndigital fabrication media on popular use.\n", "contributors": [{"name": "Papachristou, Marios", "sameAs": [], "familyName": "Papachristou", "additionalName": "", "givenName": "Marios", "email": ""}], "title": "Designing and Building a Three-dimensional Projective Scanner for\n  Smartphones", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04315", "oai:arXiv.org:1503.04315"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  One of the frustrating things in the digital fabrication era is that its\nmedia are neither affordable nor easily accessible and usable.\nThree-dimensional (3D) fabrication media (DFM) such as 3D Printers and 3D\nScanners have experienced an upsurge in popularity, while the latter remain\nexpensive and hard to function. With this paper, we aim to present you the\nRhoScanner Project - a an affordable and efficient Three-dimensional Projective\nScanner for Smart-phones, hence shedding light on the extended capabilities of\ndigital fabrication media on popular use.\n"}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04315"}}, {"publisher": {"name": ""}, "description": "  Distributed Denial of Service (DDoS) attacks have become more prominent\nrecently, both in frequency of occurrence, as well as magnitude. Such attacks\nrender key Internet resources unavailable and disrupt its normal operation. It\nis therefore of paramount importance to quickly identify malicious Internet\nactivity. The DDoS threat model includes characteristics such as: (i)\nheavy-hitters that transmit large volumes of traffic towards \"victims\", (ii)\npersistent-hitters that send traffic, not necessarily large, to specific\ndestinations to be used as attack facilitators, (iii) host and port scanning\nfor compiling lists of un-secure servers to be used as attack amplifiers, etc.\nThis conglomeration of problems motivates the development of space/time\nefficient summaries of data traffic streams that can be used to identify\nheavy-hitters associated with the above attack vectors. This paper presents a\nhashing-based framework and fast algorithms that take into account the\nlarge-dimensionality of the incoming network stream and can be employed to\nquickly identify the culprits. The algorithms and data structures proposed\nprovide a synopsis of the network stream that is not taxing to fast-memory, and\ncan be efficiently implemented in hardware due to simple bit-wise operations.\nThe methods are evaluated using real-world Internet data from a large academic\nnetwork.\n", "contributors": [{"name": "Kallitsis, Michael", "sameAs": [], "familyName": "Kallitsis", "additionalName": "", "givenName": "Michael", "email": ""}, {"name": "Stoev, Stilian", "sameAs": [], "familyName": "Stoev", "additionalName": "", "givenName": "Stilian", "email": ""}, {"name": "Michailidis, George", "sameAs": [], "familyName": "Michailidis", "additionalName": "", "givenName": "George", "email": ""}], "title": "Hashing Pursuit for Online Identification of Heavy-Hitters in High-Speed\n  Network Streams", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6148", "oai:arXiv.org:1412.6148"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Distributed Denial of Service (DDoS) attacks have become more prominent\nrecently, both in frequency of occurrence, as well as magnitude. Such attacks\nrender key Internet resources unavailable and disrupt its normal operation. It\nis therefore of paramount importance to quickly identify malicious Internet\nactivity. The DDoS threat model includes characteristics such as: (i)\nheavy-hitters that transmit large volumes of traffic towards \"victims\", (ii)\npersistent-hitters that send traffic, not necessarily large, to specific\ndestinations to be used as attack facilitators, (iii) host and port scanning\nfor compiling lists of un-secure servers to be used as attack amplifiers, etc.\nThis conglomeration of problems motivates the development of space/time\nefficient summaries of data traffic streams that can be used to identify\nheavy-hitters associated with the above attack vectors. This paper presents a\nhashing-based framework and fast algorithms that take into account the\nlarge-dimensionality of the incoming network stream and can be employed to\nquickly identify the culprits. The algorithms and data structures proposed\nprovide a synopsis of the network stream that is not taxing to fast-memory, and\ncan be efficiently implemented in hardware due to simple bit-wise operations.\nThe methods are evaluated using real-world Internet data from a large academic\nnetwork.\n", "Comment: 14 pages"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - cryptography and security", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6148"}}, {"publisher": {"name": ""}, "description": "  We study two fundamental problems related to finding subgraphs: (1) given\ngraphs G and H, Subgraph Test asks if H is isomorphic to a subgraph of G, (2)\ngiven graphs G, H, and an integer t, Packing asks if G contains t\nvertex-disjoint subgraphs isomorphic to H. For every graph class F, let\nF-Subgraph Test and F-Packing be the special cases of the two problems where H\nis restricted to be in F. Our goal is to study which classes F make the two\nproblems tractable in one of the following senses:\n  * (randomized) polynomial-time solvable,\n  * admits a polynomial (many-one) kernel, or\n  * admits a polynomial Turing kernel (that is, has an adaptive polynomial-time\nprocedure that reduces the problem to a polynomial number of instances, each of\nwhich has size bounded polynomially by the size of the solution).\n  We identify a simple combinatorial property such that if a hereditary class F\nhas this property, then F-Packing admits a polynomial kernel, and has no\npolynomial (many-one) kernel otherwise, unless the polynomial hierarchy\ncollapses. Furthermore, if F does not have this property, then F-Packing is\neither WK[1]-hard, W[1]-hard, or Long Path-hard, giving evidence that it does\nnot admit polynomial Turing kernels either.\n  For F-Subgraph Test, we show that if every graph of a hereditary class F\nsatisfies the property that it is possible to delete a bounded number of\nvertices such that every remaining component has size at most two, then\nF-Subgraph Test is solvable in randomized polynomial time and it is NP-hard\notherwise. We introduce a combinatorial property called (a,b,c,d)-splittability\nand show that if every graph in a hereditary class F has this property, then\nF-Subgraph Test admits a polynomial Turing kernel and it is WK[1]-hard,\nW[1]-hard, or Long Path-hard, otherwise.\n", "contributors": [{"name": "Jansen, Bart M. P.", "sameAs": [], "familyName": "Jansen", "additionalName": "M. P.", "givenName": "Bart", "email": ""}, {"name": "Marx, D\u00e1niel", "sameAs": [], "familyName": "Marx", "additionalName": "", "givenName": "D\u00e1niel", "email": ""}], "title": "Characterizing the easy-to-find subgraphs from the viewpoint of\n  polynomial-time algorithms, kernels, and Turing kernels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.0855", "oai:arXiv.org:1410.0855"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study two fundamental problems related to finding subgraphs: (1) given\ngraphs G and H, Subgraph Test asks if H is isomorphic to a subgraph of G, (2)\ngiven graphs G, H, and an integer t, Packing asks if G contains t\nvertex-disjoint subgraphs isomorphic to H. For every graph class F, let\nF-Subgraph Test and F-Packing be the special cases of the two problems where H\nis restricted to be in F. Our goal is to study which classes F make the two\nproblems tractable in one of the following senses:\n  * (randomized) polynomial-time solvable,\n  * admits a polynomial (many-one) kernel, or\n  * admits a polynomial Turing kernel (that is, has an adaptive polynomial-time\nprocedure that reduces the problem to a polynomial number of instances, each of\nwhich has size bounded polynomially by the size of the solution).\n  We identify a simple combinatorial property such that if a hereditary class F\nhas this property, then F-Packing admits a polynomial kernel, and has no\npolynomial (many-one) kernel otherwise, unless the polynomial hierarchy\ncollapses. Furthermore, if F does not have this property, then F-Packing is\neither WK[1]-hard, W[1]-hard, or Long Path-hard, giving evidence that it does\nnot admit polynomial Turing kernels either.\n  For F-Subgraph Test, we show that if every graph of a hereditary class F\nsatisfies the property that it is possible to delete a bounded number of\nvertices such that every remaining component has size at most two, then\nF-Subgraph Test is solvable in randomized polynomial time and it is NP-hard\notherwise. We introduce a combinatorial property called (a,b,c,d)-splittability\nand show that if every graph in a hereditary class F has this property, then\nF-Subgraph Test admits a polynomial Turing kernel and it is WK[1]-hard,\nW[1]-hard, or Long Path-hard, otherwise.\n", "Comment: 69 pages, extended abstract to appear in the proceedings of SODA 2015"]}}], "languages": [null], "subjects": ["g.2.2", "f.2.2", "computer science - computational complexity", "68q17", "computer science - data structures and algorithms", "68r10"], "providerUpdatedDateTime": "2014-10-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.0855"}}, {"publisher": {"name": ""}, "description": "  In this paper, we introduce a new class of transform method --- the\narithmetic cosine transform (ACT). We provide the central mathematical\nproperties of the ACT, necessary in designing efficient and accurate\nimplementations of the new transform method. The key mathematical tools used in\nthe paper come from analytic number theory, in particular the properties of the\nRiemann zeta function. Additionally, we demonstrate that an exact signal\ninterpolation is achievable for any block-length. Approximate calculations were\nalso considered. The numerical examples provided show the potential of the ACT\nfor various digital signal processing applications.\n", "contributors": [{"name": "Cintra, R. J.", "sameAs": [], "familyName": "Cintra", "additionalName": "J.", "givenName": "R.", "email": ""}, {"name": "Dimitrov, V. S.", "sameAs": [], "familyName": "Dimitrov", "additionalName": "S.", "givenName": "V.", "email": ""}], "title": "The Arithmetic Cosine Transform: Exact and Approximate Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01377", "IEEE Transactions on Signal Processing, vol. 58, no. 6, pp.\n  3076-3085, June 2010", "doi:10.1109/TSP.2010.2045781", "oai:arXiv.org:1502.01377"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  In this paper, we introduce a new class of transform method --- the\narithmetic cosine transform (ACT). We provide the central mathematical\nproperties of the ACT, necessary in designing efficient and accurate\nimplementations of the new transform method. The key mathematical tools used in\nthe paper come from analytic number theory, in particular the properties of the\nRiemann zeta function. Additionally, we demonstrate that an exact signal\ninterpolation is achievable for any block-length. Approximate calculations were\nalso considered. The numerical examples provided show the potential of the ACT\nfor various digital signal processing applications.\n", "Comment: 17 pages, 3 figures"]}}], "languages": [null], "subjects": ["statistics - applications", "mathematics - numerical analysis", "statistics - methodology", "computer science - numerical analysis", "statistics - computation"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01377"}}, {"publisher": {"name": "American Diabetes Association"}, "description": "Differences in susceptibility to diabetic nephropathy (DN) between mouse strains with identical levels of hyperglycemia correlate with renal levels of oxidative stress, shown previously to play a central role in the pathogenesis of DN. Susceptibility to DN appears to be genetically determined, but the critical genes have not yet been identified. Overexpression of the enzyme glyoxalase 1 (Glo1), which prevents posttranslational modification of proteins by the glycolysis-derived \u03b1-oxoaldehyde, methylglyoxal (MG), prevents hyperglycemia-induced oxidative stress in cultured cells and model organisms. In this study, we show that in nondiabetic mice, knockdown of Glo1 increases to diabetic levels both MG modification of glomerular proteins and oxidative stress, causing alterations in kidney morphology indistinguishable from those caused by diabetes. We also show that in diabetic mice, Glo1 overexpression completely prevents diabetes-induced increases in MG modification of glomerular proteins, increased oxidative stress, and the development of diabetic kidney pathology, despite unchanged levels of diabetic hyperglycemia. Together, these data indicate that Glo1 activity regulates the sensitivity of the kidney to hyperglycemic-induced renal pathology and that alterations in the rate of MG detoxification are sufficient to determine the glycemic set point at which DN occurs.", "contributors": [{"name": "Giacco, Ferdinando", "sameAs": [], "familyName": "Giacco", "additionalName": "", "givenName": "Ferdinando", "email": ""}, {"name": "Du, Xueliang", "sameAs": [], "familyName": "Du", "additionalName": "", "givenName": "Xueliang", "email": ""}, {"name": "D\u2019Agati, Vivette D.", "sameAs": [], "familyName": "D\u2019Agati", "additionalName": "D.", "givenName": "Vivette", "email": ""}, {"name": "Milne, Ross", "sameAs": [], "familyName": "Milne", "additionalName": "", "givenName": "Ross", "email": ""}, {"name": "Sui, Guangzhi", "sameAs": [], "familyName": "Sui", "additionalName": "", "givenName": "Guangzhi", "email": ""}, {"name": "Geoffrion, Michele", "sameAs": [], "familyName": "Geoffrion", "additionalName": "", "givenName": "Michele", "email": ""}, {"name": "Brownlee, Michael", "sameAs": [], "familyName": "Brownlee", "additionalName": "", "givenName": "Michael", "email": ""}], "title": "Knockdown of Glyoxalase 1 Mimics Diabetic Nephropathy in Nondiabetic Mice", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["complications"], "providerUpdatedDateTime": "2015-01-01T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3868051"}}, {"publisher": {"name": ""}, "description": "  We present a new similarity measure based on information theoretic measures\nwhich is superior than Normalized Compression Distance for clustering problems\nand inherits the useful properties of conditional Kolmogorov complexity. We\nshow that Normalized Compression Dictionary Size and Normalized Compression\nDictionary Entropy are computationally more efficient, as the need to perform\nthe compression itself is eliminated. Also they scale linearly with exponential\nvector size growth and are content independent. We show that normalized\ncompression dictionary distance is compressor independent, if limited to\nlossless compressors, which gives space for optimizations and implementation\nspeed improvement for real-time and big data applications. The introduced\nmeasure is applicable for machine learning tasks of parameter-free unsupervised\nclustering, supervised learning such as classification and regression, feature\nselection, and is applicable for big data problems with order of magnitude\nspeed increase.\n", "contributors": [{"name": "Bogomolov, Andrey", "sameAs": [], "familyName": "Bogomolov", "additionalName": "", "givenName": "Andrey", "email": ""}, {"name": "Lepri, Bruno", "sameAs": [], "familyName": "Lepri", "additionalName": "", "givenName": "Bruno", "email": ""}, {"name": "Pianesi, Fabio", "sameAs": [], "familyName": "Pianesi", "additionalName": "", "givenName": "Fabio", "email": ""}], "title": "Generalized Compression Dictionary Distance as Universal Similarity\n  Measure", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5792", "oai:arXiv.org:1410.5792"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  We present a new similarity measure based on information theoretic measures\nwhich is superior than Normalized Compression Distance for clustering problems\nand inherits the useful properties of conditional Kolmogorov complexity. We\nshow that Normalized Compression Dictionary Size and Normalized Compression\nDictionary Entropy are computationally more efficient, as the need to perform\nthe compression itself is eliminated. Also they scale linearly with exponential\nvector size growth and are content independent. We show that normalized\ncompression dictionary distance is compressor independent, if limited to\nlossless compressors, which gives space for optimizations and implementation\nspeed improvement for real-time and big data applications. The introduced\nmeasure is applicable for machine learning tasks of parameter-free unsupervised\nclustering, supervised learning such as classification and regression, feature\nselection, and is applicable for big data problems with order of magnitude\nspeed increase.\n", "Comment: 2014 Conference on Big Data from Space (BiDS 14)"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "computer science - artificial intelligence", "computer science - information theory", "statistics - machine learning"], "providerUpdatedDateTime": "2014-10-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5792"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Distributed machine learning has typically been approached from a data parallel perspective, where big data are partitioned to multiple workers and an algorithm is executed concurrently over different data subsets under various synchronization schemes to ensure speed-up and/or correctness. A sibling problem that has received relatively less attention is how to ensure efficient and correct model parallel execution of ML algorithms, where parameters of an ML program are partitioned to different workers and undergone concurrent iterative updates. We argue that model and data parallelisms impose rather different challenges for system design, algorithmic adjustment, and theoretical analysis. In this paper, we develop a system for model-parallelism, STRADS, that provides a programming abstraction for scheduling parameter updates by discovering and leveraging changing structural properties of ML programs. STRADS enables a flexible tradeoff between scheduling efficiency and fidelity to intrinsic dependencies within the models, and improves memory efficiency of distributed ML. We demonstrate the efficacy of model-parallel algorithms implemented on STRADS versus popular implementations for topic modeling, matrix factorization, and Lasso.", "contributors": [{"name": "Lee, Seunghak", "sameAs": [], "familyName": "Lee", "additionalName": "", "givenName": "Seunghak", "email": ""}, {"name": "Kim, Jin Kyu", "sameAs": [], "familyName": "Kim", "additionalName": "Kyu", "givenName": "Jin", "email": ""}, {"name": "Zheng, Xun", "sameAs": [], "familyName": "Zheng", "additionalName": "", "givenName": "Xun", "email": ""}, {"name": "Ho, Qirong", "sameAs": [], "familyName": "Ho", "additionalName": "", "givenName": "Qirong", "email": ""}, {"name": "Gibson, Garth", "sameAs": [], "familyName": "Gibson", "additionalName": "", "givenName": "Garth", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "On Model Parallelization and Scheduling Strategies for Distributed Machine Learning", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-12-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/147", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1141&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1141"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Distributed machine learning has typically been approached from a data parallel perspective, where big data are partitioned to multiple workers and an algorithm is executed concurrently over different data subsets under various synchronization schemes to ensure speed-up and/or correctness. A sibling problem that has received relatively less attention is how to ensure efficient and correct model parallel execution of ML algorithms, where parameters of an ML program are partitioned to different workers and undergone concurrent iterative updates. We argue that model and data parallelisms impose rather different challenges for system design, algorithmic adjustment, and theoretical analysis. In this paper, we develop a system for model-parallelism, STRADS, that provides a programming abstraction for scheduling parameter updates by discovering and leveraging changing structural properties of ML programs. STRADS enables a flexible tradeoff between scheduling efficiency and fidelity to intrinsic dependencies within the models, and improves memory efficiency of distributed ML. We demonstrate the efficacy of model-parallel algorithms implemented on STRADS versus popular implementations for topic modeling, matrix factorization, and Lasso."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-30T21:01:59", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/147"}}, {"publisher": {"name": ""}, "description": "  In this report, a novel variation of Particle Swarm Optimization (PSO)\nalgorithm, called Multiagent Coordination Optimization (MCO), is implemented in\na parallel computing way for practical use by introducing MATLAB built-in\nfunction \"parfor\" into MCO. Then we rigorously analyze the global convergence\nof MCO by means of semistability theory. Besides sharing global optimal\nsolutions with the PSO algorithm, the MCO algorithm integrates cooperative\nswarm behavior of multiple agents into the update formula by sharing velocity\nand position information between neighbors to improve its performance.\nNumerical evaluation of the parallel MCO algorithm is provided in the report by\nrunning the proposed algorithm on supercomputers in the High Performance\nComputing Center at Texas Tech University. In particular, the optimal value and\nconsuming time are compared with PSO and serial MCO by solving several\nbenchmark functions in the literature, respectively. Based on the simulation\nresults, the performance of the parallel MCO is not only superb compared with\nPSO for solving many nonlinear, noncovex optimization problems, but also is of\nhigh efficiency by saving the computational time.\n", "contributors": [{"name": "Hui, Qing", "sameAs": [], "familyName": "Hui", "additionalName": "", "givenName": "Qing", "email": ""}, {"name": "Zhang, Haopeng", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Haopeng", "email": ""}], "title": "Convergence Analysis and Parallel Computing Implementation for the\n  Multiagent Coordination Optimization Algorithm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-02", "2014-11-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.0225", "oai:arXiv.org:1306.0225"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this report, a novel variation of Particle Swarm Optimization (PSO)\nalgorithm, called Multiagent Coordination Optimization (MCO), is implemented in\na parallel computing way for practical use by introducing MATLAB built-in\nfunction \"parfor\" into MCO. Then we rigorously analyze the global convergence\nof MCO by means of semistability theory. Besides sharing global optimal\nsolutions with the PSO algorithm, the MCO algorithm integrates cooperative\nswarm behavior of multiple agents into the update formula by sharing velocity\nand position information between neighbors to improve its performance.\nNumerical evaluation of the parallel MCO algorithm is provided in the report by\nrunning the proposed algorithm on supercomputers in the High Performance\nComputing Center at Texas Tech University. In particular, the optimal value and\nconsuming time are compared with PSO and serial MCO by solving several\nbenchmark functions in the literature, respectively. Based on the simulation\nresults, the performance of the parallel MCO is not only superb compared with\nPSO for solving many nonlinear, noncovex optimization problems, but also is of\nhigh efficiency by saving the computational time.\n", "Comment: 51 pages, 34 figures"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "49j45", "i.2.8", "93d99", "90c59", "mathematics - dynamical systems", "g.1.6", "computer science - neural and evolutionary computing", "65y05", "g.1.0"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.0225"}}, {"publisher": {"name": ""}, "description": "  Most existing content-based filtering approaches learn user profiles\nindependently without capturing the similarity among users. Bayesian\nhierarchical models \\cite{Zhang:Efficient} learn user profiles jointly and have\nthe advantage of being able to borrow discriminative information from other\nusers through a Bayesian prior. However, the standard Bayesian hierarchical\nmodels assume all user profiles are generated from the same prior. Considering\nthe diversity of user interests, this assumption could be improved by\nintroducing more flexibility. Besides, most existing content-based filtering\napproaches implicitly assume that each user profile corresponds to exactly one\nuser interest and fail to capture a user's multiple interests (information\nneeds).\n  In this paper, we present a flexible Bayesian hierarchical modeling approach\nto model both commonality and diversity among users as well as individual\nusers' multiple interests. We propose two models each with different\nassumptions, and the proposed models are called Discriminative Factored Prior\nModels (DFPM). In our models, each user profile is modeled as a discriminative\nclassifier with a factored model as its prior, and different factors contribute\nin different levels to each user profile. Compared with existing content-based\nfiltering models, DFPM are interesting because they can 1) borrow\ndiscriminative criteria of other users while learning a particular user profile\nthrough the factored prior; 2) trade off well between diversity and commonality\namong users; and 3) handle the challenging classification situation where each\nclass contains multiple concepts. The experimental results on a dataset\ncollected from real users on digg.com show that our models significantly\noutperform the baseline models of L-2 regularized logistic regression and\ntraditional Bayesian hierarchical model with logistic regression.\n", "contributors": [{"name": "Zhang, Lanbo", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Lanbo", "email": ""}, {"name": "Zhang, Yi", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Yi", "email": ""}], "title": "Hierarchical Bayesian Models with Factorization for Content-Based\n  Recommendation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.8118", "oai:arXiv.org:1412.8118"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Most existing content-based filtering approaches learn user profiles\nindependently without capturing the similarity among users. Bayesian\nhierarchical models \\cite{Zhang:Efficient} learn user profiles jointly and have\nthe advantage of being able to borrow discriminative information from other\nusers through a Bayesian prior. However, the standard Bayesian hierarchical\nmodels assume all user profiles are generated from the same prior. Considering\nthe diversity of user interests, this assumption could be improved by\nintroducing more flexibility. Besides, most existing content-based filtering\napproaches implicitly assume that each user profile corresponds to exactly one\nuser interest and fail to capture a user's multiple interests (information\nneeds).\n  In this paper, we present a flexible Bayesian hierarchical modeling approach\nto model both commonality and diversity among users as well as individual\nusers' multiple interests. We propose two models each with different\nassumptions, and the proposed models are called Discriminative Factored Prior\nModels (DFPM). In our models, each user profile is modeled as a discriminative\nclassifier with a factored model as its prior, and different factors contribute\nin different levels to each user profile. Compared with existing content-based\nfiltering models, DFPM are interesting because they can 1) borrow\ndiscriminative criteria of other users while learning a particular user profile\nthrough the factored prior; 2) trade off well between diversity and commonality\namong users; and 3) handle the challenging classification situation where each\nclass contains multiple concepts. The experimental results on a dataset\ncollected from real users on digg.com show that our models significantly\noutperform the baseline models of L-2 regularized logistic regression and\ntraditional Bayesian hierarchical model with logistic regression.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.8118"}}, {"publisher": {"name": ""}, "description": "  Given an initial placement of a set of rectangles in the plane, we consider\nthe problem of finding a disjoint placement of the rectangles that minimizes\nthe area of the bounding box and preserves the orthogonal order i.e.\\ maintains\nthe sorted ordering of the rectangle centers along both $x$-axis and $y$-axis\nwith respect to the initial placement. This problem is known as Layout\nAdjustment for Disjoint Rectangles(LADR). It was known that LADR is\n$\\mathbb{NP}$-hard, but only heuristics were known for it. We show that a\ncertain decision version of LADR is $\\mathbb{APX}$-hard, and give a constant\nfactor approximation for LADR.\n", "contributors": [{"name": "Bandyapadhyay, Sayan", "sameAs": [], "familyName": "Bandyapadhyay", "additionalName": "", "givenName": "Sayan", "email": ""}, {"name": "Bhowmick, Santanu", "sameAs": [], "familyName": "Bhowmick", "additionalName": "", "givenName": "Santanu", "email": ""}, {"name": "Varadarajan, Kasturi", "sameAs": [], "familyName": "Varadarajan", "additionalName": "", "givenName": "Kasturi", "email": ""}], "title": "A Constant Factor Approximation for Orthogonal Order Preserving Layout\n  Adjustment", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03847", "oai:arXiv.org:1502.03847"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Given an initial placement of a set of rectangles in the plane, we consider\nthe problem of finding a disjoint placement of the rectangles that minimizes\nthe area of the bounding box and preserves the orthogonal order i.e.\\ maintains\nthe sorted ordering of the rectangle centers along both $x$-axis and $y$-axis\nwith respect to the initial placement. This problem is known as Layout\nAdjustment for Disjoint Rectangles(LADR). It was known that LADR is\n$\\mathbb{NP}$-hard, but only heuristics were known for it. We show that a\ncertain decision version of LADR is $\\mathbb{APX}$-hard, and give a constant\nfactor approximation for LADR.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "computer science - discrete mathematics", "i.3.5", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-02-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03847"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Low-dimensional embedding, manifold learning, clustering, classification, and anomaly detection are among the most important problems in machine learning. Here we consider the setting where each instance of the inputs corresponds to a continuous probability distribution. These distributions are unknown to us, but we are given some i.i.d. samples from each of them. While most of the existing machine learning methods operate on points, i.e. finite-dimensional feature vectors, in our setting we study algorithms that operate on groups, i.e. sets of feature vectors. For this purpose, we propose new nonparametric, consistent estimators for a large family of divergences and describe how to apply them for machine learning problems. As important special cases, the estimators can be used to estimate R\u00b4enyi, Tsallis, Kullback-Leibler, Hellinger, Bhattacharyya distance, L2 divergences, and mutual information. We present empirical results on synthetic data, real word images, and astronomical data sets.", "contributors": [{"name": "Poczos, Barnabas", "sameAs": [], "familyName": "Poczos", "additionalName": "", "givenName": "Barnabas", "email": ""}, {"name": "Xiong, Liang", "sameAs": [], "familyName": "Xiong", "additionalName": "", "givenName": "Liang", "email": ""}, {"name": "Schneider, Jeff", "sameAs": [], "familyName": "Schneider", "additionalName": "", "givenName": "Jeff", "email": ""}], "title": "Nonparametric Divergence Estimation and its Applications to Machine Learning", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2011-01-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/88", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1095&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1095"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Low-dimensional embedding, manifold learning, clustering, classification, and anomaly detection are among the most important problems in machine learning. Here we consider the setting where each instance of the inputs corresponds to a continuous probability distribution. These distributions are unknown to us, but we are given some i.i.d. samples from each of them. While most of the existing machine learning methods operate on points, i.e. finite-dimensional feature vectors, in our setting we study algorithms that operate on groups, i.e. sets of feature vectors. For this purpose, we propose new nonparametric, consistent estimators for a large family of divergences and describe how to apply them for machine learning problems. As important special cases, the estimators can be used to estimate R\u00b4enyi, Tsallis, Kullback-Leibler, Hellinger, Bhattacharyya distance, L2 divergences, and mutual information. We present empirical results on synthetic data, real word images, and astronomical data sets."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-17T21:24:06", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/88"}}, {"publisher": {"name": ""}, "description": "  Given a non-deterministic timed automaton with silent transitions (eNTA), we\nshow that after an initial stage it becomes time-periodic. After computing the\nperiodic parameters, we construct a finite almost periodic augmented region\nautomaton, which includes a clock measuring the global time. In the next step\nwe construct the timestamp of the automaton: the union of all its observable\ntimed traces, which contains all the dates on which events occur - a\ngeneralization of the reachability problem. The timestamp of each event is an\nalmost periodic subset of the non-negative reals. We also construct a simple\ndeterministic timed automaton with the same timestamp as the given timed\nautomaton, in contrast to the fact that the timed automaton itself may be\nnon-determinizable. One application is the decidability of the $1$-bounded\nlanguage inclusion problem for eNTA. Another is a partial method, which is not\nbounded by time or number of steps, for showing the non-inclusion of languages\nof timed automata.\n", "contributors": [{"name": "Rosenmann, Amnon", "sameAs": [], "familyName": "Rosenmann", "additionalName": "", "givenName": "Amnon", "email": ""}], "title": "Almost Periodicity and the Timestamp of Timed Automata", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-17", "2014-12-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5669", "oai:arXiv.org:1412.5669"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Given a non-deterministic timed automaton with silent transitions (eNTA), we\nshow that after an initial stage it becomes time-periodic. After computing the\nperiodic parameters, we construct a finite almost periodic augmented region\nautomaton, which includes a clock measuring the global time. In the next step\nwe construct the timestamp of the automaton: the union of all its observable\ntimed traces, which contains all the dates on which events occur - a\ngeneralization of the reachability problem. The timestamp of each event is an\nalmost periodic subset of the non-negative reals. We also construct a simple\ndeterministic timed automaton with the same timestamp as the given timed\nautomaton, in contrast to the fact that the timed automaton itself may be\nnon-determinizable. One application is the decidability of the $1$-bounded\nlanguage inclusion problem for eNTA. Another is a partial method, which is not\nbounded by time or number of steps, for showing the non-inclusion of languages\nof timed automata.\n", "Comment: 25 pages, 10 figures; Typo in Title of first submission"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "d.2.4", "f.1.1"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5669"}}, {"publisher": {"name": ""}, "description": "  The main problem in colour management in prepress department is lack of\navailability of literature on colour management and knowledge gap between\nprepress department and press department. So a digital test from has been\ncreated by Adobe Photoshop to analyse the ICC profile and to create a new\nprofile and this analysed data is used to study about various grey scale of RGB\nand CMYK images. That helps in conversion of image from RGB to CMYK in prepress\ndepartment.\n", "contributors": [{"name": "Dilawari, Jaswinder Singh", "sameAs": [], "familyName": "Dilawari", "additionalName": "Singh", "givenName": "Jaswinder", "email": ""}, {"name": "Khanna, Ravinder", "sameAs": [], "familyName": "Khanna", "additionalName": "", "givenName": "Ravinder", "email": ""}], "title": "Creation of Digital Test Form for Prepress Department", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-09-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1209.5039", "(IJCSIS) International Journal of Computer Science and Information\n  Security, Vol. 10, No. 9, September 2012 (IJCSIS) International Journal of\n  Computer Science and Information Security, Vol. 10, No. 9, September 2012", "oai:arXiv.org:1209.5039"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The main problem in colour management in prepress department is lack of\navailability of literature on colour management and knowledge gap between\nprepress department and press department. So a digital test from has been\ncreated by Adobe Photoshop to analyse the ICC profile and to create a new\nprofile and this analysed data is used to study about various grey scale of RGB\nand CMYK images. That helps in conversion of image from RGB to CMYK in prepress\ndepartment.\n", "Comment: 5 Pages,4 Figures"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1209.5039"}}, {"publisher": {"name": ""}, "description": "  We consider the recovery of sparse signals that share a common support from\nmultiple measurement vectors. The performance of several algorithms developed\nfor this task depends on parameters like dimension of the sparse signal,\ndimension of measurement vector, sparsity level, measurement noise. We propose\na fusion framework, where several multiple measurement vector reconstruction\nalgorithms participate and the final signal estimate is obtained by combining\nthe signal estimates of the participating algorithms. We present the conditions\nfor achieving a better reconstruction performance than the participating\nalgorithms. Numerical simulations demonstrate that the proposed fusion\nalgorithm often performs better than the participating algorithms.\n", "contributors": [{"name": "G., Deepa K.", "sameAs": [], "familyName": "G.", "additionalName": "K.", "givenName": "Deepa", "email": ""}, {"name": "Ambat, Sooraj K.", "sameAs": [], "familyName": "Ambat", "additionalName": "K.", "givenName": "Sooraj", "email": ""}, {"name": "Hari, K. V. S.", "sameAs": [], "familyName": "Hari", "additionalName": "V. S.", "givenName": "K.", "email": ""}], "title": "Fusion of Sparse Reconstruction Algorithms for Multiple Measurement\n  Vectors", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01705", "oai:arXiv.org:1504.01705"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  We consider the recovery of sparse signals that share a common support from\nmultiple measurement vectors. The performance of several algorithms developed\nfor this task depends on parameters like dimension of the sparse signal,\ndimension of measurement vector, sparsity level, measurement noise. We propose\na fusion framework, where several multiple measurement vector reconstruction\nalgorithms participate and the final signal estimate is obtained by combining\nthe signal estimates of the participating algorithms. We present the conditions\nfor achieving a better reconstruction performance than the participating\nalgorithms. Numerical simulations demonstrate that the proposed fusion\nalgorithm often performs better than the participating algorithms.\n"}}], "languages": [null], "subjects": ["computer science - information theory", "statistics - methodology"], "providerUpdatedDateTime": "2015-04-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01705"}}, {"publisher": {"name": ""}, "description": "  Let $A$ be an algebra of bounded smooth functions on the interior of a\ncompact set in the plane. We study the following problem: if\n$f,f_1,\\dots,f_n\\in A$ satisfy $|f|\\leq \\sum_{j=1}^n |f_j|$, does there exist\n$g_j\\in A$ and a constant $N\\in\\N$ such that $f^N=\\sum_{j=1}^n g_j f_j$? A\nprominent role in our proofs is played by a new space, $C_{\\dbar, 1}(K)$, which\nwe call the algebra of $\\dbar$-smooth functions.\n  In the case $n=1$, a complete solution is given for the algebras $A^m(K)$ of\nfunctions holomorphic in $K^\\circ$ and whose first $m$-derivatives extend\ncontinuously to $\\ov{K^\\circ}$. This necessitates the introduction of a special\nclass of compacta, the so-called locally L-connected sets.\n  We also present another constructive proof of the Nullstellensatz for $A(K)$,\nthat is only based on elementary $\\dbar$-calculus and Wolff's method.\n", "contributors": [{"name": "Mortini, Raymond", "sameAs": [], "familyName": "Mortini", "additionalName": "", "givenName": "Raymond", "email": ""}, {"name": "Rupp, Rudolf", "sameAs": [], "familyName": "Rupp", "additionalName": "", "givenName": "Rudolf", "email": ""}], "title": "Corona-type theorems and division in some function algebras on planar\n  domains", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-01-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1301.7668", "The Corona Problem, Connections Between Operator Theory, Function\n  Theory, and Geometry Series: Fields Institute Communications, Vol. 72\n  Douglas, R.G., Krantz, S.G., Sawyer, E.T., Treil, S., Wick, B.D. (Eds.),\n  (2014) pp. 127-151", "oai:arXiv.org:1301.7668"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Let $A$ be an algebra of bounded smooth functions on the interior of a\ncompact set in the plane. We study the following problem: if\n$f,f_1,\\dots,f_n\\in A$ satisfy $|f|\\leq \\sum_{j=1}^n |f_j|$, does there exist\n$g_j\\in A$ and a constant $N\\in\\N$ such that $f^N=\\sum_{j=1}^n g_j f_j$? A\nprominent role in our proofs is played by a new space, $C_{\\dbar, 1}(K)$, which\nwe call the algebra of $\\dbar$-smooth functions.\n  In the case $n=1$, a complete solution is given for the algebras $A^m(K)$ of\nfunctions holomorphic in $K^\\circ$ and whose first $m$-derivatives extend\ncontinuously to $\\ov{K^\\circ}$. This necessitates the introduction of a special\nclass of compacta, the so-called locally L-connected sets.\n  We also present another constructive proof of the Nullstellensatz for $A(K)$,\nthat is only based on elementary $\\dbar$-calculus and Wolff's method.\n", "Comment: 23 pages, 6 figures"]}}], "languages": [null], "subjects": ["30h50", "46j10", "46j15", "46j20", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-10-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1301.7668"}}, {"publisher": {"name": ""}, "description": "  A model checker can produce a trace of counterexample, for an erroneous\nprogram, which is often long and difficult to understand. In general, the part\nabout the loops is the largest among the instructions in this trace. This makes\nthe location of errors in loops critical, to analyze errors in the overall\nprogram. In this paper, we explore the scala-bility capabilities of LocFaults,\nour error localization approach exploiting paths of CFG(Control Flow Graph)\nfrom a counterexample to calculate the MCDs (Minimal Correction Deviations),\nand MCSs (Minimal Correction Subsets) from each found MCD. We present the times\nof our approach on programs with While-loops unfolded b times, and a number of\ndeviated conditions ranging from 0 to n. Our preliminary results show that the\ntimes of our approach, constraint-based and flow-driven, are better compared to\nBugAssist which is based on SAT and transforms the entire program to a Boolean\nformula, and further the information provided by LocFaults is more expressive\nfor the user.\n", "contributors": [{"name": "Bekkouche, Mohammed", "sameAs": [], "familyName": "Bekkouche", "additionalName": "", "givenName": "Mohammed", "email": ""}], "title": "Exploration of the scalability of LocFaults approach for error\n  localization with While-loops programs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.05508", "oai:arXiv.org:1503.05508"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  A model checker can produce a trace of counterexample, for an erroneous\nprogram, which is often long and difficult to understand. In general, the part\nabout the loops is the largest among the instructions in this trace. This makes\nthe location of errors in loops critical, to analyze errors in the overall\nprogram. In this paper, we explore the scala-bility capabilities of LocFaults,\nour error localization approach exploiting paths of CFG(Control Flow Graph)\nfrom a counterexample to calculate the MCDs (Minimal Correction Deviations),\nand MCSs (Minimal Correction Subsets) from each found MCD. We present the times\nof our approach on programs with While-loops unfolded b times, and a number of\ndeviated conditions ranging from 0 to n. Our preliminary results show that the\ntimes of our approach, constraint-based and flow-driven, are better compared to\nBugAssist which is based on SAT and transforms the entire program to a Boolean\nformula, and further the information provided by LocFaults is more expressive\nfor the user.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - software engineering"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.05508"}}, {"publisher": {"name": ""}, "description": "Thesis (Ph.D.)--University of Washington, 2014", "contributors": [{"name": "Dickerson, John F.", "sameAs": [], "familyName": "Dickerson", "additionalName": "F.", "givenName": "John", "email": ""}, {"name": "Basu, Anirban", "sameAs": [], "familyName": "Basu", "additionalName": "", "givenName": "Anirban", "email": ""}], "title": "Role of Patient Adherence in the Treatment and Prevention of Depression", "shareProperties": {"source": "uwashington"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": ["2015-02-24T17:35:36Z", "2014"]}}, {"name": "identifier", "properties": {"identifier": ["Dickerson_washington_0250E_14006.pdf", "http://hdl.handle.net/1773/27498", "oai:digital.lib.washington.edu:1773/27498"]}}, {"name": "setSpec", "properties": {"setSpec": ["com_1773_4888", "col_1773_4928"]}}, {"name": "rights", "properties": {"rights": []}}], "languages": [null], "subjects": ["statistics", "public health", "economics", "health services", "adherence; bias; comparative effectiveness; cost effectiveness; instrumental variable; mental health"], "providerUpdatedDateTime": "2015-02-25T11:04:44", "uris": {"canonicalUri": "http://hdl.handle.net/1773/27498"}}, {"publisher": {"name": ""}, "description": "  In this paper, we defined the viseme (visual speech element) and described\nabout the method of extracting visual feature vector. We defined the 10 visemes\nbased on vowel by analyzing of Korean utterance and proposed the method of\nextracting the 20-dimensional visual feature vector, combination of static\nfeatures and dynamic features. Lastly, we took an experiment in recognizing\nwords based on 3-viseme HMM and evaluated the efficiency.\n", "contributors": [{"name": "Won, Ha Jong", "sameAs": [], "familyName": "Won", "additionalName": "Jong", "givenName": "Ha", "email": ""}, {"name": "Chol, Li Gwang", "sameAs": [], "familyName": "Chol", "additionalName": "Gwang", "givenName": "Li", "email": ""}, {"name": "Chol, Kim Hyok", "sameAs": [], "familyName": "Chol", "additionalName": "Hyok", "givenName": "Kim", "email": ""}, {"name": "Song, Li Kum", "sameAs": [], "familyName": "Song", "additionalName": "Kum", "givenName": "Li", "email": ""}], "title": "Definition of Visual Speech Element and Research on a Method of\n  Extracting Feature Vector for Korean Lip-Reading", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4114", "oai:arXiv.org:1411.4114"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we defined the viseme (visual speech element) and described\nabout the method of extracting visual feature vector. We defined the 10 visemes\nbased on vowel by analyzing of Korean utterance and proposed the method of\nextracting the 20-dimensional visual feature vector, combination of static\nfeatures and dynamic features. Lastly, we took an experiment in recognizing\nwords based on 3-viseme HMM and evaluated the efficiency.\n"}}], "languages": [null], "subjects": ["computer science - computation and language", "computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4114"}}, {"publisher": {"name": ""}, "description": "  We propose a new approach to sequential testing which is an adaptive\n(on-line) extension of the (off-line) framework developed in [10]. It relies\nupon testing of pairs of hypotheses in the case where each hypothesis states\nthat the vector of parameters underlying the dis- tribution of observations\nbelongs to a convex set. The nearly optimal under appropriate conditions test\nis yielded by a solution to an efficiently solvable convex optimization prob-\nlem. The proposed methodology can be seen as a computationally friendly\nreformulation of the classical sequential testing.\n", "contributors": [{"name": "Juditsky, Anatoli", "sameAs": [], "familyName": "Juditsky", "additionalName": "", "givenName": "Anatoli", "email": ""}, {"name": "Nemirovski, Arkadi", "sameAs": [], "familyName": "Nemirovski", "additionalName": "", "givenName": "Arkadi", "email": ""}], "title": "On sequential hypotheses testing via convex optimization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1605", "oai:arXiv.org:1412.1605"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "stat"]}}, {"name": "description", "properties": {"description": "  We propose a new approach to sequential testing which is an adaptive\n(on-line) extension of the (off-line) framework developed in [10]. It relies\nupon testing of pairs of hypotheses in the case where each hypothesis states\nthat the vector of parameters underlying the dis- tribution of observations\nbelongs to a convex set. The nearly optimal under appropriate conditions test\nis yielded by a solution to an efficiently solvable convex optimization prob-\nlem. The proposed methodology can be seen as a computationally friendly\nreformulation of the classical sequential testing.\n"}}], "languages": [null], "subjects": ["mathematics - statistics theory", "statistics - computation"], "providerUpdatedDateTime": "2014-12-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1605"}}, {"publisher": {"name": ""}, "description": "  The immediate snapshot complexes were introduced as combinatorial models for\nthe protocol complexes in the context of theoretical distributed computing. In\nthe previous work we have developed a formal language of witness structures in\norder to define and to analyze these complexes.\n  In this paper, we study topology of immediate snapshot complexes. It was\nknown that these complexes are always pure and that they are pseudomanifolds.\nHere we prove two further independent topological properties. First, we show\nthat immediate snapshot complexes are collapsible. Second, we show that these\ncomplexes are homeomorphic to closed balls. Specifically, given any immediate\nsnapshot complex $P(\\tr)$, we show that there exists a homeomorphism\n$\\varphi:\\da^{|\\supp\\tr|-1}\\ra P(\\tr)$, such that $\\varphi(\\sigma)$ is a\nsubcomplex of $P(\\tr)$, whenever $\\sigma$ is a simplex in the simplicial\ncomplex $\\da^{|\\supp\\tr|-1}$.\n", "contributors": [{"name": "Kozlov, Dmitry N.", "sameAs": [], "familyName": "Kozlov", "additionalName": "N.", "givenName": "Dmitry", "email": ""}], "title": "Topology of the immediate snapshot complexes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-23", "2014-11-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.5813", "oai:arXiv.org:1404.5813"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The immediate snapshot complexes were introduced as combinatorial models for\nthe protocol complexes in the context of theoretical distributed computing. In\nthe previous work we have developed a formal language of witness structures in\norder to define and to analyze these complexes.\n  In this paper, we study topology of immediate snapshot complexes. It was\nknown that these complexes are always pure and that they are pseudomanifolds.\nHere we prove two further independent topological properties. First, we show\nthat immediate snapshot complexes are collapsible. Second, we show that these\ncomplexes are homeomorphic to closed balls. Specifically, given any immediate\nsnapshot complex $P(\\tr)$, we show that there exists a homeomorphism\n$\\varphi:\\da^{|\\supp\\tr|-1}\\ra P(\\tr)$, such that $\\varphi(\\sigma)$ is a\nsubcomplex of $P(\\tr)$, whenever $\\sigma$ is a simplex in the simplicial\ncomplex $\\da^{|\\supp\\tr|-1}$.\n", "Comment: final version as it appears in Topology and it Applications, Article\n  number 5275. arXiv admin note: substantial text overlap with arXiv:1402.4707"]}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.5813"}}, {"publisher": {"name": ""}, "description": "  The Abel differential equation $y'=p(x)y^3 + q(x) y^2$ with polynomial\ncoefficients $p,q$ is said to have a center on $[a,b]$ if all its solutions,\nwith the initial value $y(a)$ small enough, satisfy the condition $y(a)=y(b)$.\nThe problem of giving conditions on $(p,q,a,b)$ implying a center for the Abel\nequation is analogous to the classical Poincar\\'e Center-Focus problem for\nplane vector fields. Center conditions are provided by an infinite system of\n\"Center Equations\". An important new information on these equations has been\nobtained via a detailed analysis of two related structures: Composition Algebra\nand Moment Equations (first order approximation of the Center ones). Recently\none of the basic open questions in this direction - the \"Polynomial moments\nproblem\" - has been completely settled in \\cite{mp1,pak}.\n  In this paper we present a progress in the following two main directions:\nFirst, we translate the results of \\cite{mp1,pak} into the language of\nAlgebraic Geometry of the Center Equations. On this base we obtain new\ninformation on the center conditions, significantly extending, in particular,\nthe results of \\cite{broy}. Second, we study the \"second Melnikov coefficients\"\n(second order approximation of the Center equations) showing that in many cases\nvanishing of the moments and of these coefficients is sufficient in order to\ncompletely characterize centers.\n", "contributors": [{"name": "Briskin, M.", "sameAs": [], "familyName": "Briskin", "additionalName": "", "givenName": "M.", "email": ""}, {"name": "Pakovich, F.", "sameAs": [], "familyName": "Pakovich", "additionalName": "", "givenName": "F.", "email": ""}, {"name": "Yomdin, Y.", "sameAs": [], "familyName": "Yomdin", "additionalName": "", "givenName": "Y.", "email": ""}], "title": "Algebraic Geometry of the Center-Focus problem for Abel Differential\n  Equation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-11-06", "2014-07-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1211.1296", "doi:10.1017/etds.2014.94", "oai:arXiv.org:1211.1296"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  The Abel differential equation $y'=p(x)y^3 + q(x) y^2$ with polynomial\ncoefficients $p,q$ is said to have a center on $[a,b]$ if all its solutions,\nwith the initial value $y(a)$ small enough, satisfy the condition $y(a)=y(b)$.\nThe problem of giving conditions on $(p,q,a,b)$ implying a center for the Abel\nequation is analogous to the classical Poincar\\'e Center-Focus problem for\nplane vector fields. Center conditions are provided by an infinite system of\n\"Center Equations\". An important new information on these equations has been\nobtained via a detailed analysis of two related structures: Composition Algebra\nand Moment Equations (first order approximation of the Center ones). Recently\none of the basic open questions in this direction - the \"Polynomial moments\nproblem\" - has been completely settled in \\cite{mp1,pak}.\n  In this paper we present a progress in the following two main directions:\nFirst, we translate the results of \\cite{mp1,pak} into the language of\nAlgebraic Geometry of the Center Equations. On this base we obtain new\ninformation on the center conditions, significantly extending, in particular,\nthe results of \\cite{broy}. Second, we study the \"second Melnikov coefficients\"\n(second order approximation of the Center equations) showing that in many cases\nvanishing of the moments and of these coefficients is sufficient in order to\ncompletely characterize centers.\n"}}], "languages": [null], "subjects": ["34c08", "mathematics - complex variables", "34c07", "mathematics - dynamical systems", "mathematics - classical analysis and odes"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1211.1296"}}, {"publisher": {"name": ""}, "description": "  Godel's theory T can be understood as a theory of the simply-typed lambda\ncalculus that is extended to include the constant 0, the successor function S,\nand the operator R_tau for primitive recursion on objects of type tau. It is\nknown that the functions from non-negative integers to non-negative integers\nthat can be defined in this theory are exactly the <epsilon_0-recursive\nfunctions of non-negative integers. As an extension of this result, we show\nthat when the domain and codomain are restricted to pure closed normal forms,\nthe functionals of arbitrary type that are definable in T can be encoded as\n<epsilon_0-recursive functions.\n", "contributors": [{"name": "Szudzik, Matthew P.", "sameAs": [], "familyName": "Szudzik", "additionalName": "P.", "givenName": "Matthew", "email": ""}], "title": "On the definability of functionals in G\\\"odel's theory T", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-11-29", "2014-10-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1011.6353", "oai:arXiv.org:1011.6353"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Godel's theory T can be understood as a theory of the simply-typed lambda\ncalculus that is extended to include the constant 0, the successor function S,\nand the operator R_tau for primitive recursion on objects of type tau. It is\nknown that the functions from non-negative integers to non-negative integers\nthat can be defined in this theory are exactly the <epsilon_0-recursive\nfunctions of non-negative integers. As an extension of this result, we show\nthat when the domain and codomain are restricted to pure closed normal forms,\nthe functionals of arbitrary type that are definable in T can be encoded as\n<epsilon_0-recursive functions.\n", "Comment: 13 pages, 0 figures; metadata updated, other minor changes"]}}], "languages": [null], "subjects": ["mathematics - logic", "03d65", "computer science - logic in computer science", "03f10 (secondary)", "03b40 (primary)"], "providerUpdatedDateTime": "2014-10-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1011.6353"}}, {"publisher": {"name": ""}, "description": "  This paper attempts to explain consequences of the relational calculus not\nallowing relations to be domains of relations, and to suggest a solution for\nthe issue. On the example of SQL we describe the consequent problem of the\nmultitude of different representations for relations; analyze in detail the\ndisadvantages of the notions \"TABLE\" and \"FOREIGN KEY\"; and propose a complex\nsolution which includes brand new data language, abandonment of tables as a\nrepresentation for relations, and relatively small yet very significant\nalteration of the data storage concept, called \"multitable index\".\n", "contributors": [{"name": "Panferov, Eugene", "sameAs": [], "familyName": "Panferov", "additionalName": "", "givenName": "Eugene", "email": ""}], "title": "A Next-Generation Data Language Proposal", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-02", "2015-03-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.00503", "oai:arXiv.org:1503.00503"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper attempts to explain consequences of the relational calculus not\nallowing relations to be domains of relations, and to suggest a solution for\nthe issue. On the example of SQL we describe the consequent problem of the\nmultitude of different representations for relations; analyze in detail the\ndisadvantages of the notions \"TABLE\" and \"FOREIGN KEY\"; and propose a complex\nsolution which includes brand new data language, abandonment of tables as a\nrepresentation for relations, and relatively small yet very significant\nalteration of the data storage concept, called \"multitable index\".\n", "Comment: 19 pages"]}}], "languages": [null], "subjects": ["computer science - databases", "computer science - programming languages"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.00503"}}, {"publisher": {"name": ""}, "description": "  Since its introduction by Valiant in 1984, PAC learning of DNF expressions\nremains one of the central problems in learning theory. We consider this\nproblem in the setting where the underlying distribution is uniform, or more\ngenerally, a product distribution. Kalai, Samorodnitsky and Teng (2009) showed\nthat in this setting a DNF expression can be efficiently approximated from its\n\"heavy\" low-degree Fourier coefficients alone. This is in contrast to previous\napproaches where boosting was used and thus Fourier coefficients of the target\nfunction modified by various distributions were needed. This property is\ncrucial for learning of DNF expressions over smoothed product distributions, a\nlearning model introduced by Kalai et al. (2009) and inspired by the seminal\nsmoothed analysis model of Spielman and Teng (2001).\n  We introduce a new approach to learning (or approximating) a polynomial\nthreshold functions which is based on creating a function with range [-1,1]\nthat approximately agrees with the unknown function on low-degree Fourier\ncoefficients. We then describe conditions under which this is sufficient for\nlearning polynomial threshold functions. Our approach yields a new, simple\nalgorithm for approximating any polynomial-size DNF expression from its \"heavy\"\nlow-degree Fourier coefficients alone. Our algorithm greatly simplifies the\nproof of learnability of DNF expressions over smoothed product distributions.\nWe also describe an application of our algorithm to learning monotone DNF\nexpressions over product distributions. Building on the work of Servedio\n(2001), we give an algorithm that runs in time $\\poly((s \\cdot\n\\log{(s/\\eps)})^{\\log{(s/\\eps)}}, n)$, where $s$ is the size of the target DNF\nexpression and $\\eps$ is the accuracy. This improves on $\\poly((s \\cdot\n\\log{(ns/\\eps)})^{\\log{(s/\\eps)} \\cdot \\log{(1/\\eps)}}, n)$ bound of Servedio\n(2001).\n", "contributors": [{"name": "Feldman, Vitaly", "sameAs": [], "familyName": "Feldman", "additionalName": "", "givenName": "Vitaly", "email": ""}], "title": "Learning DNF Expressions from Fourier Spectrum", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-03-02", "2013-04-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1203.0594", "oai:arXiv.org:1203.0594"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Since its introduction by Valiant in 1984, PAC learning of DNF expressions\nremains one of the central problems in learning theory. We consider this\nproblem in the setting where the underlying distribution is uniform, or more\ngenerally, a product distribution. Kalai, Samorodnitsky and Teng (2009) showed\nthat in this setting a DNF expression can be efficiently approximated from its\n\"heavy\" low-degree Fourier coefficients alone. This is in contrast to previous\napproaches where boosting was used and thus Fourier coefficients of the target\nfunction modified by various distributions were needed. This property is\ncrucial for learning of DNF expressions over smoothed product distributions, a\nlearning model introduced by Kalai et al. (2009) and inspired by the seminal\nsmoothed analysis model of Spielman and Teng (2001).\n  We introduce a new approach to learning (or approximating) a polynomial\nthreshold functions which is based on creating a function with range [-1,1]\nthat approximately agrees with the unknown function on low-degree Fourier\ncoefficients. We then describe conditions under which this is sufficient for\nlearning polynomial threshold functions. Our approach yields a new, simple\nalgorithm for approximating any polynomial-size DNF expression from its \"heavy\"\nlow-degree Fourier coefficients alone. Our algorithm greatly simplifies the\nproof of learnability of DNF expressions over smoothed product distributions.\nWe also describe an application of our algorithm to learning monotone DNF\nexpressions over product distributions. Building on the work of Servedio\n(2001), we give an algorithm that runs in time $\\poly((s \\cdot\n\\log{(s/\\eps)})^{\\log{(s/\\eps)}}, n)$, where $s$ is the size of the target DNF\nexpression and $\\eps$ is the accuracy. This improves on $\\poly((s \\cdot\n\\log{(ns/\\eps)})^{\\log{(s/\\eps)} \\cdot \\log{(1/\\eps)}}, n)$ bound of Servedio\n(2001).\n", "Comment: Appears in Conference on Learning Theory (COLT) 2012"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity", "computer science - learning"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1203.0594"}}, {"publisher": {"name": ""}, "description": "Thesis (Ph.D.)--University of Washington, 2014", "contributors": [{"name": "Christensen, Janara Maria", "sameAs": [], "familyName": "Christensen", "additionalName": "Maria", "givenName": "Janara", "email": ""}, {"name": "Mausam, .", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Mausam", "email": ""}], "title": "Towards Large Scale Summarization", "shareProperties": {"source": "uwashington"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": ["2015-02-24T17:33:20Z", "2015-02-24T17:33:20Z", "2014"]}}, {"name": "identifier", "properties": {"identifier": ["Christensen_washington_0250E_13808.pdf", "http://hdl.handle.net/1773/27448", "oai:digital.lib.washington.edu:1773/27448"]}}, {"name": "setSpec", "properties": {"setSpec": ["com_1773_4888", "col_1773_4909"]}}, {"name": "rights", "properties": {"rights": []}}], "languages": [null], "subjects": ["computer science and engineering", "computer science"], "providerUpdatedDateTime": "2015-02-25T11:02:32", "uris": {"canonicalUri": "http://hdl.handle.net/1773/27448"}}, {"publisher": {"name": ""}, "description": "  The purpose of this paper is to prove an interpolation formula involving\nderivatives for entire functions of exponential type. We extend the\ninterpolation formula derived by J. Vaaler in [37, Theorem 9] to general $L^p$\nde Branges spaces. We extensively use techniques from de Branges' theory of\nHilbert spaces of entire functions as developed in [6], but a crucial passage\ninvolves the Hilbert-type inequalities as derived in [15]. We give applications\nto homogeneous spaces of entire functions that involve Bessel functions and we\nprove a uniqueness result for extremal one-sided band-limited approximations of\nradial functions in Euclidean spaces.\n", "contributors": [{"name": "Gon\u00e7alves, Felipe", "sameAs": [], "familyName": "Gon\u00e7alves", "additionalName": "", "givenName": "Felipe", "email": ""}], "title": "Interpolation Formulas With Derivatives in De Branges Spaces", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.05178", "oai:arXiv.org:1503.05178"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The purpose of this paper is to prove an interpolation formula involving\nderivatives for entire functions of exponential type. We extend the\ninterpolation formula derived by J. Vaaler in [37, Theorem 9] to general $L^p$\nde Branges spaces. We extensively use techniques from de Branges' theory of\nHilbert spaces of entire functions as developed in [6], but a crucial passage\ninvolves the Hilbert-type inequalities as derived in [15]. We give applications\nto homogeneous spaces of entire functions that involve Bessel functions and we\nprove a uniqueness result for extremal one-sided band-limited approximations of\nradial functions in Euclidean spaces.\n", "Comment: 25 pages"]}}], "languages": [null], "subjects": ["41a05", "33c10", "30d10", "41a30", "mathematics - complex variables", "46e22"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.05178"}}, {"publisher": {"name": "Institute of Electrical and Electronics Engineers"}, "description": "As the demand for higher data rates increases, commercial analog-to-digital converters (ADCs) are more commonly being implemented with multiple on-chip converters whose outputs are time-interleaved. The distortion generated by time-interleaved ADCs is now not only a function of the nonlinear behavior of the constituent circuitry, but also mismatches associated with interleaving multiple output streams. To mitigate distortion generated by time-interleaved ADCs, we have developed a polyphase NonLinear EQualizer (pNLEQ) which is capable of simultaneously mitigating distortion generated by both the on-chip circuitry and mismatches due to time interleaving. In this paper, we describe the pNLEQ architecture and present measurements of its performance.", "contributors": [{"name": "Goodman, Joel I.", "sameAs": [], "familyName": "Goodman", "additionalName": "I.", "givenName": "Joel", "email": ""}, {"name": "Miller, Benjamin A.", "sameAs": [], "familyName": "Miller", "additionalName": "A.", "givenName": "Benjamin", "email": ""}, {"name": "Herman, Matthew", "sameAs": [], "familyName": "Herman", "additionalName": "", "givenName": "Matthew", "email": ""}, {"name": "Raz, Gil", "sameAs": [], "familyName": "Raz", "additionalName": "", "givenName": "Gil", "email": ""}, {"name": "Jackson, Jeffrey", "sameAs": [], "familyName": "Jackson", "additionalName": "", "givenName": "Jeffrey", "email": ""}], "title": "Polyphase Nonlinear Equalization of Time-Interleaved Analog-to-Digital Converters", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": ["Article", "http://purl.org/eprint/type/JournalArticle"]}}, {"name": "source", "properties": {"source": "IEEE"}}, {"name": "format", "properties": {"format": []}}, {"name": "rights", "properties": {"rights": "Article is made available in accordance with the publisher\u2019s policy and may be subject to US copyright law. Please refer to the publisher\u2019s site for terms of use."}}, {"name": "identifier", "properties": {"identifier": ["1932-4553", "INSPEC Accession Number: 10664321", "http://hdl.handle.net/1721.1/52371", "Goodman, J. et al. \u201cPolyphase Nonlinear Equalization of Time-Interleaved Analog-to-Digital Converters.\u201d Selected Topics in Signal Processing, IEEE Journal of 3.3 (2009): 362-373. \u00a9 2009 Institute of Electrical and Electronics Engineers", "PUBLISHER_POLICY", "oai:dspace.mit.edu:1721.1/52371"]}}, {"name": "relation", "properties": {"relation": ["http://dx.doi.org/10.1109/JSTSP.2009.2020243", "IEEE Journal of Selected Topics in Signal Processing"]}}, {"name": "date", "properties": {"date": ["2010-03-08T16:24:36Z", "2010-03-08T16:24:36Z", "2009-05", "2009-03"]}}, {"name": "description", "properties": {"description": ["As the demand for higher data rates increases, commercial analog-to-digital converters (ADCs) are more commonly being implemented with multiple on-chip converters whose outputs are time-interleaved. The distortion generated by time-interleaved ADCs is now not only a function of the nonlinear behavior of the constituent circuitry, but also mismatches associated with interleaving multiple output streams. To mitigate distortion generated by time-interleaved ADCs, we have developed a polyphase NonLinear EQualizer (pNLEQ) which is capable of simultaneously mitigating distortion generated by both the on-chip circuitry and mismatches due to time interleaving. In this paper, we describe the pNLEQ architecture and present measurements of its performance.", "Defense Advanced Research Projects Agency (Air Force Contract FA8721-05-C-0002)"]}}, {"name": "setSpec", "properties": {"setSpec": "hdl_1721.1_49433"}}], "languages": [null], "subjects": ["volterra", "mismatch distortions", "compressed sensing", "time-interleaved analog-to-digital converter (adc)", "nonlinear compensation", "nonlinear equalization", "polynomial filter", "multidimensional filter"], "providerUpdatedDateTime": "2015-03-20T19:04:51", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/52371"}}, {"publisher": {"name": ""}, "description": "  Assume that a multi-user multiple-input multiple-output (MIMO) system is\ndesigned from scratch to uniformly cover a given area with maximal energy\nefficiency (EE). What are the optimal number of antennas, active users, and\ntransmit power? The aim of this paper is to answer this fundamental question.\nWe consider jointly the uplink and downlink with different processing schemes\nat the base station and propose a new realistic power consumption model that\nreveals how the above parameters affect the EE. Closed-form expressions for the\nEE-optimal value of each parameter, when the other two are fixed, are provided\nfor zero-forcing (ZF) processing in single-cell scenarios. These expressions\nprove how the parameters interact. For example, in sharp contrast to common\nbelief, the transmit power is found to increase (not to decrease) with the\nnumber of antennas. This implies that energy-efficient systems can operate in\nhigh signal-to-noise ratio regimes in which interference-suppressing signal\nprocessing is mandatory. Numerical and analytical results show that the maximal\nEE is achieved by a massive MIMO setup wherein hundreds of antennas are\ndeployed to serve a relatively large number of users using ZF processing. The\nnumerical results show the same behavior under imperfect channel state\ninformation and in symmetric multi-cell scenarios.\n", "contributors": [{"name": "Bj\u00f6rnson, Emil", "sameAs": [], "familyName": "Bj\u00f6rnson", "additionalName": "", "givenName": "Emil", "email": ""}, {"name": "Sanguinetti, Luca", "sameAs": [], "familyName": "Sanguinetti", "additionalName": "", "givenName": "Luca", "email": ""}, {"name": "Hoydis, Jakob", "sameAs": [], "familyName": "Hoydis", "additionalName": "", "givenName": "Jakob", "email": ""}, {"name": "Debbah, M\u00e9rouane", "sameAs": [], "familyName": "Debbah", "additionalName": "", "givenName": "M\u00e9rouane", "email": ""}], "title": "Optimal Design of Energy-Efficient Multi-User MIMO Systems: Is Massive\n  MIMO the Answer?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-24", "2015-03-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.6150", "oai:arXiv.org:1403.6150"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Assume that a multi-user multiple-input multiple-output (MIMO) system is\ndesigned from scratch to uniformly cover a given area with maximal energy\nefficiency (EE). What are the optimal number of antennas, active users, and\ntransmit power? The aim of this paper is to answer this fundamental question.\nWe consider jointly the uplink and downlink with different processing schemes\nat the base station and propose a new realistic power consumption model that\nreveals how the above parameters affect the EE. Closed-form expressions for the\nEE-optimal value of each parameter, when the other two are fixed, are provided\nfor zero-forcing (ZF) processing in single-cell scenarios. These expressions\nprove how the parameters interact. For example, in sharp contrast to common\nbelief, the transmit power is found to increase (not to decrease) with the\nnumber of antennas. This implies that energy-efficient systems can operate in\nhigh signal-to-noise ratio regimes in which interference-suppressing signal\nprocessing is mandatory. Numerical and analytical results show that the maximal\nEE is achieved by a massive MIMO setup wherein hundreds of antennas are\ndeployed to serve a relatively large number of users using ZF processing. The\nnumerical results show the same behavior under imperfect channel state\ninformation and in symmetric multi-cell scenarios.\n", "Comment: To appear in IEEE Transactions on Wireless Communications, 16 pages,\n  14 figures, 2 tables. The results can be reproduced using the following\n  Matlab code: https://github.com/emilbjornson/is-massive-MIMO-the-answer"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.6150"}}, {"publisher": {"name": ""}, "description": "  We prove the Shepp--Olkin conjecture, which states that the entropy of the\nsum of independent Bernoulli random variables is concave in the parameters of\nthe individual random variables. Our proof is a refinement of an argument\npreviously presented by the same authors, which resolved the conjecture in the\nmonotonic case (where all the parameters are simultaneously increasing). In\nfact, we show that the monotonic case is the worst case, using a careful\nanalysis of concavity properties of the derivatives of the probability mass\nfunction. We propose a generalization of Shepp and Olkin's original conjecture,\nto consider Renyi and Tsallis entropies.\n", "contributors": [{"name": "Hillion, Erwan", "sameAs": [], "familyName": "Hillion", "additionalName": "", "givenName": "Erwan", "email": ""}, {"name": "Johnson, Oliver", "sameAs": [], "familyName": "Johnson", "additionalName": "", "givenName": "Oliver", "email": ""}], "title": "A proof of the Shepp-Olkin entropy concavity conjecture", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01570", "oai:arXiv.org:1503.01570"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We prove the Shepp--Olkin conjecture, which states that the entropy of the\nsum of independent Bernoulli random variables is concave in the parameters of\nthe individual random variables. Our proof is a refinement of an argument\npreviously presented by the same authors, which resolved the conjecture in the\nmonotonic case (where all the parameters are simultaneously increasing). In\nfact, we show that the monotonic case is the worst case, using a careful\nanalysis of concavity properties of the derivatives of the probability mass\nfunction. We propose a generalization of Shepp and Olkin's original conjecture,\nto consider Renyi and Tsallis entropies.\n"}}], "languages": [null], "subjects": ["computer science - information theory", "mathematics - probability"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01570"}}, {"publisher": {"name": ""}, "description": "  The problem of sending two correlated vector Gaussian sources over a\nbandwidth-matched two-user scalar Gaussian broadcast channel is studied in this\nwork, where each receiver wishes to reconstruct its target source under a\ncovariance distortion constraint. We derive a lower bound on the optimal\ntradeoff between the transmit power and the achievable reconstruction\ndistortion pair. Our derivation is based on a new bounding technique which\ninvolves the introduction of appropriate remote sources. Furthermore, it is\nshown that this lower bound is achievable by a class of hybrid schemes for the\nspecial case where the weak receiver wishes to reconstruct a scalar source\nunder the mean squared error distortion constraint.\n", "contributors": [{"name": "Song, Lin", "sameAs": [], "familyName": "Song", "additionalName": "", "givenName": "Lin", "email": ""}, {"name": "Chen, Jun", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Jun", "email": ""}, {"name": "Tian, Chao", "sameAs": [], "familyName": "Tian", "additionalName": "", "givenName": "Chao", "email": ""}], "title": "Broadcasting Correlated Vector Gaussians", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02927", "oai:arXiv.org:1503.02927"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The problem of sending two correlated vector Gaussian sources over a\nbandwidth-matched two-user scalar Gaussian broadcast channel is studied in this\nwork, where each receiver wishes to reconstruct its target source under a\ncovariance distortion constraint. We derive a lower bound on the optimal\ntradeoff between the transmit power and the achievable reconstruction\ndistortion pair. Our derivation is based on a new bounding technique which\ninvolves the introduction of appropriate remote sources. Furthermore, it is\nshown that this lower bound is achievable by a class of hybrid schemes for the\nspecial case where the weak receiver wishes to reconstruct a scalar source\nunder the mean squared error distortion constraint.\n", "Comment: 13 pages"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02927"}}, {"publisher": {"name": ""}, "description": "  This article presents novel results concerning the recovery of signals from\nundersampled data in the common situation where such signals are not sparse in\nan orthonormal basis or incoherent dictionary, but in a truly redundant\ndictionary. This work thus bridges a gap in the literature and shows not only\nthat compressed sensing is viable in this context, but also that accurate\nrecovery is possible via an L1-analysis optimization problem. We introduce a\ncondition on the measurement/sensing matrix, which is a natural generalization\nof the now well-known restricted isometry property, and which guarantees\naccurate recovery of signals that are nearly sparse in (possibly) highly\novercomplete and coherent dictionaries. This condition imposes no incoherence\nrestriction on the dictionary and our results may be the first of this kind. We\ndiscuss practical examples and the implications of our results on those\napplications, and complement our study by demonstrating the potential of\nL1-analysis for such problems.\n", "contributors": [{"name": "Candes, Emmanuel J.", "sameAs": [], "familyName": "Candes", "additionalName": "J.", "givenName": "Emmanuel", "email": ""}, {"name": "Eldar, Yonina C.", "sameAs": [], "familyName": "Eldar", "additionalName": "C.", "givenName": "Yonina", "email": ""}, {"name": "Needell, Deanna", "sameAs": [], "familyName": "Needell", "additionalName": "", "givenName": "Deanna", "email": ""}, {"name": "Randall, Paige", "sameAs": [], "familyName": "Randall", "additionalName": "", "givenName": "Paige", "email": ""}], "title": "Compressed Sensing with Coherent and Redundant Dictionaries", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-05-14", "2010-12-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.2613", "oai:arXiv.org:1005.2613"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  This article presents novel results concerning the recovery of signals from\nundersampled data in the common situation where such signals are not sparse in\nan orthonormal basis or incoherent dictionary, but in a truly redundant\ndictionary. This work thus bridges a gap in the literature and shows not only\nthat compressed sensing is viable in this context, but also that accurate\nrecovery is possible via an L1-analysis optimization problem. We introduce a\ncondition on the measurement/sensing matrix, which is a natural generalization\nof the now well-known restricted isometry property, and which guarantees\naccurate recovery of signals that are nearly sparse in (possibly) highly\novercomplete and coherent dictionaries. This condition imposes no incoherence\nrestriction on the dictionary and our results may be the first of this kind. We\ndiscuss practical examples and the implications of our results on those\napplications, and complement our study by demonstrating the potential of\nL1-analysis for such problems.\n"}}], "languages": [null], "subjects": ["94a12", "mathematics - numerical analysis", "41a45", "computer science - information theory", "42a10"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.2613"}}, {"publisher": {"name": "eScholarship, University of California"}, "description": "", "contributors": [{"name": "Povey, S", "sameAs": [], "familyName": "Povey", "additionalName": "", "givenName": "S", "email": ""}, {"name": "Smith, M", "sameAs": [], "familyName": "Smith", "additionalName": "", "givenName": "M", "email": ""}, {"name": "Haines, J", "sameAs": [], "familyName": "Haines", "additionalName": "", "givenName": "J", "email": ""}, {"name": "Kwiatkowski, D", "sameAs": [], "familyName": "Kwiatkowski", "additionalName": "", "givenName": "D", "email": ""}, {"name": "Fountain, J", "sameAs": [], "familyName": "Fountain", "additionalName": "", "givenName": "J", "email": ""}, {"name": "Bale, A", "sameAs": [], "familyName": "Bale", "additionalName": "", "givenName": "A", "email": ""}, {"name": "Abbott, C", "sameAs": [], "familyName": "Abbott", "additionalName": "", "givenName": "C", "email": ""}, {"name": "Jackson, I", "sameAs": [], "familyName": "Jackson", "additionalName": "", "givenName": "I", "email": ""}, {"name": "Lawrie, M", "sameAs": [], "familyName": "Lawrie", "additionalName": "", "givenName": "M", "email": ""}, {"name": "Hult\u00e9n, M", "sameAs": [], "familyName": "Hult\u00e9n", "additionalName": "", "givenName": "M", "email": ""}], "title": "Report and abstracts of the First International Workshop on Chromosome 9. Held at Girton College Cambridge, UK, 22-24 March, 1992.", "shareProperties": {"source": "ucescholarship"}, "otherProperties": [{"name": "type", "properties": {"type": "article"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "1992-01-01"}}, {"name": "identifier", "properties": {"identifier": ["qt9ps8n973", "http://www.escholarship.org/uc/item/9ps8n973", "qt9ps8n973"]}}, {"name": "setSpec", "properties": {"setSpec": []}}, {"name": "source", "properties": {"source": "Povey, S; Smith, M; Haines, J; Kwiatkowski, D; Fountain, J; Bale, A; \u00a0et al.(1992). Report and abstracts of the First International Workshop on Chromosome 9. Held at Girton College Cambridge, UK, 22-24 March, 1992.. Annals of Human Genetics, 56, Pt - 3/. UC Irvine: Retrieved from: http://www.escholarship.org/uc/item/9ps8n973"}}, {"name": "coverage", "properties": {"coverage": "Pt - 3/"}}, {"name": "relation", "properties": {"relation": []}}, {"name": "rights", "properties": {"rights": "Attribution (CC BY): http://creativecommons.org/licenses/by/3.0/"}}], "languages": [null], "subjects": ["conference paper", "nucleotide sequence", "human", "p.h.s.", "chromosomes", "mouse", "pair 9", "dna", "non-u.s. gov't", "single stranded", "support", "single-stranded", "genetics", "animal", "non-p.h.s.", "comparative study", "chromosome mapping", "single stranded dna", "molecular genetics", "tuberous sclerosis", "mice", "base sequence", "molecular sequence data", "linkage (genetics)", "genetic linkage", "chromosome map", "chromosome 9", "u.s. gov't"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://www.escholarship.org/uc/item/9ps8n973"}}, {"publisher": {"name": ""}, "description": "  We present the first high order one-step ADER-WENO finite volume scheme with\nAdaptive Mesh Refinement (AMR) in multiple space dimensions. High order spatial\naccuracy is obtained through a WENO reconstruction, while a high order one-step\ntime discretization is achieved using a local space-time discontinuous Galerkin\npredictor method. Due to the one-step nature of the underlying scheme, the\nresulting algorithm is particularly well suited for an AMR strategy on\nspace-time adaptive meshes, i.e.with time-accurate local time stepping. The AMR\nproperty has been implemented 'cell-by-cell', with a standard tree-type\nalgorithm, while the scheme has been parallelized via the Message Passing\nInterface (MPI) paradigm. The new scheme has been tested over a wide range of\nexamples for nonlinear systems of hyperbolic conservation laws, including the\nclassical Euler equations of compressible gas dynamics and the equations of\nmagnetohydrodynamics (MHD). High order in space and time have been confirmed\nvia a numerical convergence study and a detailed analysis of the computational\nspeed-up with respect to highly refined uniform meshes is also presented. We\nalso show test problems where the presented high order AMR scheme behaves\nclearly better than traditional second order AMR methods. The proposed scheme\nthat combines for the first time high order ADER methods with space--time\nadaptive grids in two and three space dimensions is likely to become a useful\ntool in several fields of computational physics, applied mathematics and\nmechanics.\n", "contributors": [{"name": "Dumbser, Michael", "sameAs": [], "familyName": "Dumbser", "additionalName": "", "givenName": "Michael", "email": ""}, {"name": "Zanotti, Olindo", "sameAs": [], "familyName": "Zanotti", "additionalName": "", "givenName": "Olindo", "email": ""}, {"name": "Hidalgo, Arturo", "sameAs": [], "familyName": "Hidalgo", "additionalName": "", "givenName": "Arturo", "email": ""}, {"name": "Balsara, Dinshaw S.", "sameAs": [], "familyName": "Balsara", "additionalName": "S.", "givenName": "Dinshaw", "email": ""}], "title": "ADER-WENO Finite Volume Schemes with Space-Time Adaptive Mesh Refinement", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-12-14", "2015-03-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1212.3585", "Journal of Computational Physics, Volume 248, p. 257-286 (2013)", "doi:10.1016/j.jcp.2013.04.017", "oai:arXiv.org:1212.3585"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:astro-ph", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We present the first high order one-step ADER-WENO finite volume scheme with\nAdaptive Mesh Refinement (AMR) in multiple space dimensions. High order spatial\naccuracy is obtained through a WENO reconstruction, while a high order one-step\ntime discretization is achieved using a local space-time discontinuous Galerkin\npredictor method. Due to the one-step nature of the underlying scheme, the\nresulting algorithm is particularly well suited for an AMR strategy on\nspace-time adaptive meshes, i.e.with time-accurate local time stepping. The AMR\nproperty has been implemented 'cell-by-cell', with a standard tree-type\nalgorithm, while the scheme has been parallelized via the Message Passing\nInterface (MPI) paradigm. The new scheme has been tested over a wide range of\nexamples for nonlinear systems of hyperbolic conservation laws, including the\nclassical Euler equations of compressible gas dynamics and the equations of\nmagnetohydrodynamics (MHD). High order in space and time have been confirmed\nvia a numerical convergence study and a detailed analysis of the computational\nspeed-up with respect to highly refined uniform meshes is also presented. We\nalso show test problems where the presented high order AMR scheme behaves\nclearly better than traditional second order AMR methods. The proposed scheme\nthat combines for the first time high order ADER methods with space--time\nadaptive grids in two and three space dimensions is likely to become a useful\ntool in several fields of computational physics, applied mathematics and\nmechanics.\n", "Comment: With updated bibliography information"]}}], "languages": [null], "subjects": ["physics - computational physics", "mathematics - numerical analysis", "computer science - numerical analysis", "astrophysics - instrumentation and methods for astrophysics"], "providerUpdatedDateTime": "2015-03-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1212.3585"}}, {"publisher": {"name": ""}, "description": "  Discourse markers are universal linguistic events subject to language\nvariation. Although an extensive literature has already reported language\nspecific traits of these events, little has been said on their cross-language\nbehavior and on building an inventory of multilingual lexica of discourse\nmarkers. This work describes new methods and approaches for the description,\nclassification, and annotation of discourse markers in the specific domain of\nthe Europarl corpus. The study of discourse markers in the context of\ntranslation is crucial due to the idiomatic nature of these structures.\nMultilingual lexica together with the functional analysis of such structures\nare useful tools for the hard task of translating discourse markers into\npossible equivalents from one language to another. Using Daniel Marcu's\nvalidated discourse markers for English, extracted from the Brown Corpus, our\npurpose is to build multilingual lexica of discourse markers for other\nlanguages, based on machine translation techniques. The major assumption in\nthis study is that the usage of a discourse marker is independent of the\nlanguage, i.e., the rhetorical function of a discourse marker in a sentence in\none language is equivalent to the rhetorical function of the same discourse\nmarker in another language.\n", "contributors": [{"name": "Lopes, Ant\u00f3nio", "sameAs": [], "familyName": "Lopes", "additionalName": "", "givenName": "Ant\u00f3nio", "email": ""}, {"name": "de Matos, David Martins", "sameAs": [], "familyName": "de Matos", "additionalName": "Martins", "givenName": "David", "email": ""}, {"name": "Cabarr\u00e3o, Vera", "sameAs": [], "familyName": "Cabarr\u00e3o", "additionalName": "", "givenName": "Vera", "email": ""}, {"name": "Ribeiro, Ricardo", "sameAs": [], "familyName": "Ribeiro", "additionalName": "", "givenName": "Ricardo", "email": ""}, {"name": "Moniz, Helena", "sameAs": [], "familyName": "Moniz", "additionalName": "", "givenName": "Helena", "email": ""}, {"name": "Trancoso, Isabel", "sameAs": [], "familyName": "Trancoso", "additionalName": "", "givenName": "Isabel", "email": ""}, {"name": "Mata, Ana Isabel", "sameAs": [], "familyName": "Mata", "additionalName": "Isabel", "givenName": "Ana", "email": ""}], "title": "Towards Using Machine Translation Techniques to Induce Multilingual\n  Lexica of Discourse Markers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.09144", "oai:arXiv.org:1503.09144"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Discourse markers are universal linguistic events subject to language\nvariation. Although an extensive literature has already reported language\nspecific traits of these events, little has been said on their cross-language\nbehavior and on building an inventory of multilingual lexica of discourse\nmarkers. This work describes new methods and approaches for the description,\nclassification, and annotation of discourse markers in the specific domain of\nthe Europarl corpus. The study of discourse markers in the context of\ntranslation is crucial due to the idiomatic nature of these structures.\nMultilingual lexica together with the functional analysis of such structures\nare useful tools for the hard task of translating discourse markers into\npossible equivalents from one language to another. Using Daniel Marcu's\nvalidated discourse markers for English, extracted from the Brown Corpus, our\npurpose is to build multilingual lexica of discourse markers for other\nlanguages, based on machine translation techniques. The major assumption in\nthis study is that the usage of a discourse marker is independent of the\nlanguage, i.e., the rhetorical function of a discourse marker in a sentence in\none language is equivalent to the rhetorical function of the same discourse\nmarker in another language.\n", "Comment: 6 pages"]}}], "languages": [null], "subjects": ["i.2.7", "computer science - computation and language"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.09144"}}, {"publisher": {"name": ""}, "description": "  Attosecond streaking is one of the most fundamental processes in attosecond\nscience allowing for a mapping of temporal (i.e. phase) information on the\nenergy domain. We show that on the single-particle level attosecond streaking\ntime shifts contain spectral phase information associated with the\nEisenbud-Wigner-Smith (EWS) time delay, provided the influence of the streaking\ninfrared field is properly accounted for. While the streaking phase shifts for\nshort-ranged potentials agree with the associated EWS delays, Coulomb\npotentials require special care. We show that the interaction between the\noutgoing electron and the combined Coulomb and IR laser fields lead to a\nstreaking phase shift that can be described classically.\n", "contributors": [{"name": "Pazourek, Renate", "sameAs": [], "familyName": "Pazourek", "additionalName": "", "givenName": "Renate", "email": ""}, {"name": "Nagele, Stefan", "sameAs": [], "familyName": "Nagele", "additionalName": "", "givenName": "Stefan", "email": ""}, {"name": "Doblhoff-Dier, Katharina", "sameAs": [], "familyName": "Doblhoff-Dier", "additionalName": "", "givenName": "Katharina", "email": ""}, {"name": "Feist, Johannes", "sameAs": [], "familyName": "Feist", "additionalName": "", "givenName": "Johannes", "email": ""}, {"name": "Lemell, Christoph", "sameAs": [], "familyName": "Lemell", "additionalName": "", "givenName": "Christoph", "email": ""}, {"name": "T\u00f6k\u00e9si, Karoly", "sameAs": [], "familyName": "T\u00f6k\u00e9si", "additionalName": "", "givenName": "Karoly", "email": ""}, {"name": "Burgd\u00f6rfer, Joachim", "sameAs": [], "familyName": "Burgd\u00f6rfer", "additionalName": "", "givenName": "Joachim", "email": ""}], "title": "Probing scattering phase shifts by attosecond streaking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-11-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.4172", "J. Phys.: Conf. Ser. 388, 012029 (2012)", "doi:10.1088/1742-6596/388/1/012029", "oai:arXiv.org:1111.4172"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": "  Attosecond streaking is one of the most fundamental processes in attosecond\nscience allowing for a mapping of temporal (i.e. phase) information on the\nenergy domain. We show that on the single-particle level attosecond streaking\ntime shifts contain spectral phase information associated with the\nEisenbud-Wigner-Smith (EWS) time delay, provided the influence of the streaking\ninfrared field is properly accounted for. While the streaking phase shifts for\nshort-ranged potentials agree with the associated EWS delays, Coulomb\npotentials require special care. We show that the interaction between the\noutgoing electron and the combined Coulomb and IR laser fields lead to a\nstreaking phase shift that can be described classically.\n"}}], "languages": [null], "subjects": ["physics - computational physics", "physics - atomic physics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.4172"}}, {"publisher": {"name": ""}, "description": "  In this work, we present the problem of rash driving detection algorithm\nusing a single wide angle camera sensor, particularly useful in the Indian\ncontext. To our knowledge this rash driving problem has not been addressed\nusing Image processing techniques (existing works use other sensors such as\naccelerometer). Car Image processing literature, though rich and mature, does\nnot address the rash driving problem. In this work-in-progress paper, we\npresent the need to address this problem, our approach and our future plans to\nbuild a rash driving detector.\n", "contributors": [{"name": "Haloi, Mrinal", "sameAs": [], "familyName": "Haloi", "additionalName": "", "givenName": "Mrinal", "email": ""}, {"name": "Jayagopi, Dinesh Babu", "sameAs": [], "familyName": "Jayagopi", "additionalName": "Babu", "givenName": "Dinesh", "email": ""}], "title": "Characterizing driving behavior using automatic visual analysis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04036", "doi:10.1145/2662117.2662126", "oai:arXiv.org:1503.04036"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this work, we present the problem of rash driving detection algorithm\nusing a single wide angle camera sensor, particularly useful in the Indian\ncontext. To our knowledge this rash driving problem has not been addressed\nusing Image processing techniques (existing works use other sensors such as\naccelerometer). Car Image processing literature, though rich and mature, does\nnot address the rash driving problem. In this work-in-progress paper, we\npresent the need to address this problem, our approach and our future plans to\nbuild a rash driving detector.\n", "Comment: 4 pages,7 figures, IBM-ICARE2014"]}}], "languages": [null], "subjects": ["h.4.3", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04036"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Many organisms have evolved DNA damage response mechanisms to deal with the constant damage to DNA caused by endogenous and exogenous agents. These mechanisms activate cell cycle checkpoints to allow time for DNA repair or, in the case of severely damaged DNA, initiate cell death mechanisms to maintain genomic integrity. The cell's response to DNA damaging agents includes wide spread changes in the transcriptional state of the cell that have been implicated in cell death or survival decisions. However, we do not fully understand how the multiple and sometimes opposing transcriptional signals are interpreted to make these critical decisions. A computational and systems biology approach was taken to study the wide-spread transcriptional changes induced in human cell lines after exposure to a DNA damaging and chemotherapeutic agent, 1,3-bis-(2-chloroethyl)- 1 -nitrosourea (BCNU or carmustine). Cell lines with extreme sensitivity or resistance to BCNU were identified from a set of twenty four genetically diverse human lymphoblastoid cell lines using a high-throughput method that was developed as part of this thesis. This assay has broad applications and can be used to simultaneously screen multiple cell lines and drugs for accurate measurements of cell proliferation and survival after drug treatment. The assay has the advantage of having a large dynamic range that allows sensitivity measurements on a multi-log scale allowing better resolution of comparative sensitivities. Temporal transcription profiles were measured in cell lines with extreme BCNU sensitivity or resistance to generate a large transcription data set amenable to bioinformatics analysis. A transcriptional signature of 706 genes, differentially expressed between BCNU sensitive and resistant cell lines, was identified. Network and gene ontology enrichment identified these differentially expressed genes as being involved in key DNA damage response processes like apoptosis and mitosis. Experimental evidence showed that the transcription signature correlated with observed cellular phenotypes. Furthermore, the NF-Y transcription factor binding motif was enriched in the promoter region of 62 mitosis-related genes downregulated in BCNU sensitive but not resistant cell lines. Chromatin immunoprecipitation followed by sequencing (ChIP-seq) confirmed NF-Y occupancy in 54 of the 62 genes, thus implicating NF-Y as a possible regulator of the observed stalling of entry into mitosis. Using experimental and computational techniques we deciphered the functional importance of differential transcription between BCNU sensitive and resistant cell lines and identified NF-Y as an important factor in the transcriptional and phenotypic cell response to BCNU such as the control of entry into mitosis.", "contributors": [{"name": "Valiathan, Chandni Rajan", "sameAs": [], "familyName": "Valiathan", "additionalName": "Rajan", "givenName": "Chandni", "email": ""}, {"name": "Massachusetts Institute of Technology. Computational and Systems Biology Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computational and Systems Biology", "givenName": "Massachusetts", "email": ""}, {"name": "Leona Samson.", "sameAs": [], "familyName": "Samson.", "additionalName": "", "givenName": "Leona", "email": ""}], "title": "Identifying a transcriptional signature for cell sensitivity to the cancer chemotherapy agent, BCNU", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "195 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/65773", "749453776", "oai:dspace.mit.edu:1721.1/65773"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2011-09-13T17:50:49Z", "2011-09-13T17:50:49Z", "2011", "2011"]}}, {"name": "description", "properties": {"description": ["Many organisms have evolved DNA damage response mechanisms to deal with the constant damage to DNA caused by endogenous and exogenous agents. These mechanisms activate cell cycle checkpoints to allow time for DNA repair or, in the case of severely damaged DNA, initiate cell death mechanisms to maintain genomic integrity. The cell's response to DNA damaging agents includes wide spread changes in the transcriptional state of the cell that have been implicated in cell death or survival decisions. However, we do not fully understand how the multiple and sometimes opposing transcriptional signals are interpreted to make these critical decisions. A computational and systems biology approach was taken to study the wide-spread transcriptional changes induced in human cell lines after exposure to a DNA damaging and chemotherapeutic agent, 1,3-bis-(2-chloroethyl)- 1 -nitrosourea (BCNU or carmustine). Cell lines with extreme sensitivity or resistance to BCNU were identified from a set of twenty four genetically diverse human lymphoblastoid cell lines using a high-throughput method that was developed as part of this thesis. This assay has broad applications and can be used to simultaneously screen multiple cell lines and drugs for accurate measurements of cell proliferation and survival after drug treatment. The assay has the advantage of having a large dynamic range that allows sensitivity measurements on a multi-log scale allowing better resolution of comparative sensitivities. Temporal transcription profiles were measured in cell lines with extreme BCNU sensitivity or resistance to generate a large transcription data set amenable to bioinformatics analysis. A transcriptional signature of 706 genes, differentially expressed between BCNU sensitive and resistant cell lines, was identified. Network and gene ontology enrichment identified these differentially expressed genes as being involved in key DNA damage response processes like apoptosis and mitosis. Experimental evidence showed that the transcription signature correlated with observed cellular phenotypes. Furthermore, the NF-Y transcription factor binding motif was enriched in the promoter region of 62 mitosis-related genes downregulated in BCNU sensitive but not resistant cell lines. Chromatin immunoprecipitation followed by sequencing (ChIP-seq) confirmed NF-Y occupancy in 54 of the 62 genes, thus implicating NF-Y as a possible regulator of the observed stalling of entry into mitosis. Using experimental and computational techniques we deciphered the functional importance of differential transcription between BCNU sensitive and resistant cell lines and identified NF-Y as an important factor in the transcriptional and phenotypic cell response to BCNU such as the control of entry into mitosis.", "by Chandni Rajan Valiathan.", "Thesis (Ph. D.)--Massachusetts Institute of Technology, Computational and Systems Biology Program, 2011.", "Cataloged from PDF version of thesis.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_54823", "hdl_1721.1_54828"]}}], "languages": [null], "subjects": ["computational and systems biology program."], "providerUpdatedDateTime": "2015-04-27T14:53:06", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/65773"}}, {"publisher": {"name": ""}, "description": "  Bounded-rate multi-mode systems are hybrid systems that can switch among a\nfinite set of modes. Its dynamics is specified by a finite number of\nreal-valued variables with mode-dependent rates that can vary within given\nbounded sets. Given an arbitrary piecewise linear trajectory, we study the\nproblem of following the trajectory with arbitrary precision, using motion\nprimitives given as bounded-rate multi-mode systems. We give an algorithm to\nsolve the problem and show that the problem is co-NP complete. We further prove\nthat the problem can be solved in polynomial time for multi-mode systems with\nfixed dimension. We study the problem with dwell-time requirement and show the\ndecidability of the problem under certain positivity restriction on the rate\nvectors. Finally, we show that introducing structure to the multi-mode systems\nleads to undecidability, even when using only a single clock variable.\n", "contributors": [{"name": "Bhave, Devendra", "sameAs": [], "familyName": "Bhave", "additionalName": "", "givenName": "Devendra", "email": ""}, {"name": "Jha, Sagar", "sameAs": [], "familyName": "Jha", "additionalName": "", "givenName": "Sagar", "email": ""}, {"name": "Krishna, Shankara Narayanan", "sameAs": [], "familyName": "Krishna", "additionalName": "Narayanan", "givenName": "Shankara", "email": ""}, {"name": "Schewe, Sven", "sameAs": [], "familyName": "Schewe", "additionalName": "", "givenName": "Sven", "email": ""}, {"name": "Trivedi, Ashutosh", "sameAs": [], "familyName": "Trivedi", "additionalName": "", "givenName": "Ashutosh", "email": ""}], "title": "Bounded-Rate Multi-Mode Systems Based Motion Planning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3670", "oai:arXiv.org:1412.3670"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Bounded-rate multi-mode systems are hybrid systems that can switch among a\nfinite set of modes. Its dynamics is specified by a finite number of\nreal-valued variables with mode-dependent rates that can vary within given\nbounded sets. Given an arbitrary piecewise linear trajectory, we study the\nproblem of following the trajectory with arbitrary precision, using motion\nprimitives given as bounded-rate multi-mode systems. We give an algorithm to\nsolve the problem and show that the problem is co-NP complete. We further prove\nthat the problem can be solved in polynomial time for multi-mode systems with\nfixed dimension. We study the problem with dwell-time requirement and show the\ndecidability of the problem under certain positivity restriction on the rate\nvectors. Finally, we show that introducing structure to the multi-mode systems\nleads to undecidability, even when using only a single clock variable.\n", "Comment: 14 pages, 12 figures, HSCC - 2015"]}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3670"}}, {"publisher": {"name": ""}, "description": "  We construct random point processes in the complex plane that are\nasymptotically close to a given doubling measure. The processes we construct\nare the zero sets of random entire functions that are constructed through\ngeneralised Fock spaces. We offer two alternative constructions, one via bases\nfor these spaces and another via frames, and we show that for both\nconstructions the average distribution of the zero set is close to the given\ndoubling measure, and that the variance is much less than the variance of the\ncorresponding Poisson point process. We prove some asymptotic large deviation\nestimates for these processes, which in particular allow us to estimate the\n`hole probability', the probability that there are no zeroes in a given open\nbounded subset of the plane. We also show that the `smooth linear statistics'\nare asymptotically normal, under an additional regularity hypothesis on the\nmeasure. These generalise previous results by Sodin and Tsirelson for the\nLebesgue measure.\n", "contributors": [{"name": "Buckley, Jeremiah", "sameAs": [], "familyName": "Buckley", "additionalName": "", "givenName": "Jeremiah", "email": ""}, {"name": "Massaneda, Xavier", "sameAs": [], "familyName": "Massaneda", "additionalName": "", "givenName": "Xavier", "email": ""}, {"name": "Ortega-Cerd\u00e0, Joaquim", "sameAs": [], "familyName": "Ortega-Cerd\u00e0", "additionalName": "", "givenName": "Joaquim", "email": ""}], "title": "Inhomogenous random zero sets", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-12-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1212.5548", "Indiana Univ. Math. J. 63 (2014), no. 3, 739-781", "doi:10.1512/iumj.2014.63.5260", "oai:arXiv.org:1212.5548"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We construct random point processes in the complex plane that are\nasymptotically close to a given doubling measure. The processes we construct\nare the zero sets of random entire functions that are constructed through\ngeneralised Fock spaces. We offer two alternative constructions, one via bases\nfor these spaces and another via frames, and we show that for both\nconstructions the average distribution of the zero set is close to the given\ndoubling measure, and that the variance is much less than the variance of the\ncorresponding Poisson point process. We prove some asymptotic large deviation\nestimates for these processes, which in particular allow us to estimate the\n`hole probability', the probability that there are no zeroes in a given open\nbounded subset of the plane. We also show that the `smooth linear statistics'\nare asymptotically normal, under an additional regularity hypothesis on the\nmeasure. These generalise previous results by Sodin and Tsirelson for the\nLebesgue measure.\n", "Comment: 39 paqes"]}}], "languages": [null], "subjects": ["mathematics - probability", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1212.5548"}}, {"publisher": {"name": ""}, "description": "  In this note we improve our upper bound given earlier by showing that every\n9-fold covering of a point set in the space by finitely many translates of an\noctant decomposes into two coverings, and our lower bound by a construction for\na 4-fold covering that does not decompose into two coverings. We also prove\nthat certain dynamic interval coloring problems are equivalent to the above\nquestion. The same bounds also hold for coverings of points in $\\R^2$ by\nfinitely many homothets or translates of a triangle.\n", "contributors": [{"name": "Keszegh, Bal\u00e1zs", "sameAs": [], "familyName": "Keszegh", "additionalName": "", "givenName": "Bal\u00e1zs", "email": ""}, {"name": "P\u00e1lv\u00f6lgyi, D\u00f6m\u00f6t\u00f6r", "sameAs": [], "familyName": "P\u00e1lv\u00f6lgyi", "additionalName": "", "givenName": "D\u00f6m\u00f6t\u00f6r", "email": ""}], "title": "More on Decomposing Coverings by Octants", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01669", "oai:arXiv.org:1503.01669"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this note we improve our upper bound given earlier by showing that every\n9-fold covering of a point set in the space by finitely many translates of an\noctant decomposes into two coverings, and our lower bound by a construction for\na 4-fold covering that does not decompose into two coverings. We also prove\nthat certain dynamic interval coloring problems are equivalent to the above\nquestion. The same bounds also hold for coverings of points in $\\R^2$ by\nfinitely many homothets or translates of a triangle.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01669"}}, {"publisher": {"name": ""}, "description": "  In blind hyperspectral unmixing (HU), the pure-pixel assumption is well-known\nto be powerful in enabling simple and effective blind HU solutions. However,\nthe pure-pixel assumption is not always satisfied in an exact sense, especially\nfor scenarios where pixels are heavily mixed. In the no pure-pixel case, a good\nblind HU approach to consider is the minimum volume enclosing simplex (MVES).\nEmpirical experience has suggested that MVES algorithms can perform well\nwithout pure pixels, although it was not totally clear why this is true from a\ntheoretical viewpoint. This paper aims to address the latter issue. We develop\nan analysis framework wherein the perfect endmember identifiability of MVES is\nstudied under the noiseless case. We prove that MVES is indeed robust against\nlack of pure pixels, as long as the pixels do not get too heavily mixed and too\nasymmetrically spread. The theoretical results are verified by numerical\nsimulations.\n", "contributors": [{"name": "Lin, Chia-Hsiang", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Chia-Hsiang", "email": ""}, {"name": "Ma, Wing-Kin", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Wing-Kin", "email": ""}, {"name": "Li, Wei-Chiang", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Wei-Chiang", "email": ""}, {"name": "Chi, Chong-Yung", "sameAs": [], "familyName": "Chi", "additionalName": "", "givenName": "Chong-Yung", "email": ""}, {"name": "Ambikapathi, ArulMurugan", "sameAs": [], "familyName": "Ambikapathi", "additionalName": "", "givenName": "ArulMurugan", "email": ""}], "title": "Identifiability of the Simplex Volume Minimization Criterion for Blind\n  Hyperspectral Unmixing: The No Pure-Pixel Case", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-19", "2015-02-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.5273", "oai:arXiv.org:1406.5273"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  In blind hyperspectral unmixing (HU), the pure-pixel assumption is well-known\nto be powerful in enabling simple and effective blind HU solutions. However,\nthe pure-pixel assumption is not always satisfied in an exact sense, especially\nfor scenarios where pixels are heavily mixed. In the no pure-pixel case, a good\nblind HU approach to consider is the minimum volume enclosing simplex (MVES).\nEmpirical experience has suggested that MVES algorithms can perform well\nwithout pure pixels, although it was not totally clear why this is true from a\ntheoretical viewpoint. This paper aims to address the latter issue. We develop\nan analysis framework wherein the perfect endmember identifiability of MVES is\nstudied under the noiseless case. We prove that MVES is indeed robust against\nlack of pure pixels, as long as the pixels do not get too heavily mixed and too\nasymmetrically spread. The theoretical results are verified by numerical\nsimulations.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - information theory", "statistics - machine learning"], "providerUpdatedDateTime": "2015-02-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.5273"}}, {"publisher": {"name": ""}, "description": "  Optical coherence tomography (OCT) is an important interferometric diagnostic\ntechnique which provides cross-sectional views of the subsurface microstructure\nof biological tissues. However, the imaging quality of high-speed OCT is\nlimited due to the large speckle noise. To address this problem, this paper\nproposes a multi-frame algorithmic method to denoise OCT volume.\nMathematically, we build an optimization model which forces the temporally\nregistered frames to be low rank, and the gradient in each frame to be sparse,\nunder logarithmic image formation and noise variance constraints. Besides, a\nconvex optimization algorithm based on the augmented Lagrangian method is\nderived to solve the above model. The results reveal that our approach\noutperforms the other methods in terms of both speckle noise suppression and\ncrucial detail preservation.\n", "contributors": [{"name": "Bian, Liheng", "sameAs": [], "familyName": "Bian", "additionalName": "", "givenName": "Liheng", "email": ""}, {"name": "Suo, Jinli", "sameAs": [], "familyName": "Suo", "additionalName": "", "givenName": "Jinli", "email": ""}, {"name": "Chen, Feng", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Feng", "email": ""}, {"name": "Dai, Qionghai", "sameAs": [], "familyName": "Dai", "additionalName": "", "givenName": "Qionghai", "email": ""}], "title": "Multi-frame denoising of high speed optical coherence tomography data\n  using inter-frame and intra-frame priors", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-06", "2014-11-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.1931", "doi:10.1117/1.JBO.20.3.036006", "oai:arXiv.org:1312.1931"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Optical coherence tomography (OCT) is an important interferometric diagnostic\ntechnique which provides cross-sectional views of the subsurface microstructure\nof biological tissues. However, the imaging quality of high-speed OCT is\nlimited due to the large speckle noise. To address this problem, this paper\nproposes a multi-frame algorithmic method to denoise OCT volume.\nMathematically, we build an optimization model which forces the temporally\nregistered frames to be low rank, and the gradient in each frame to be sparse,\nunder logarithmic image formation and noise variance constraints. Besides, a\nconvex optimization algorithm based on the augmented Lagrangian method is\nderived to solve the above model. The results reveal that our approach\noutperforms the other methods in terms of both speckle noise suppression and\ncrucial detail preservation.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.1931"}}, {"publisher": {"name": ""}, "description": "  Non-intrusive load monitoring (NILM) or energy disaggregation, aims to\ndisaggregate a household's electricity consumption into constituent appliances.\nMore than three decades of work in NILM has resulted in the development of\nseveral novel algorithmic approaches. However, despite these advancements, two\ncore challenges still exist: i) disaggregating low power consumption appliances\nand ii) distinguishing between multiple instances of similar appliances. These\nchallenges are becoming increasingly important due to an increasing number of\nappliances and increased usage of electronics in homes. Previous approaches\nhave attempted to solve these problems using expensive hardware involving high\nsampling rates better suited to laboratory settings, or using additional number\nof sensors, limiting the ease of deployment. In this work, we explore using\ncommercial-off-the-shelf (COTS) power line communication (PLC) modems as an\ninexpensive and easy to deploy alternative solution to these problems. We use\nthe reduction in bandwidth between two PLC modems, caused due to the change in\nPLC modulation scheme when different appliances are operated as a signature for\nan appliance. Since the noise generated in the powerline is dependent both on\ntype and location of an appliance, we believe that our technique based on PLC\nmodems can be a promising addition for solving NILM.\n", "contributors": [{"name": "Batra, Nipun", "sameAs": [], "familyName": "Batra", "additionalName": "", "givenName": "Nipun", "email": ""}, {"name": "Gulati, Manoj", "sameAs": [], "familyName": "Gulati", "additionalName": "", "givenName": "Manoj", "email": ""}, {"name": "Jain, Puneet", "sameAs": [], "familyName": "Jain", "additionalName": "", "givenName": "Puneet", "email": ""}, {"name": "Whitehouse, Kamin", "sameAs": [], "familyName": "Whitehouse", "additionalName": "", "givenName": "Kamin", "email": ""}, {"name": "Singh, Amarjeet", "sameAs": [], "familyName": "Singh", "additionalName": "", "givenName": "Amarjeet", "email": ""}], "title": "Poster Abstract: Bits and Watts: Improving energy disaggregation\n  performance using power line communication modems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-20", "2014-10-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.5907", "doi:10.1145/2674061.2675039", "oai:arXiv.org:1409.5907"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Non-intrusive load monitoring (NILM) or energy disaggregation, aims to\ndisaggregate a household's electricity consumption into constituent appliances.\nMore than three decades of work in NILM has resulted in the development of\nseveral novel algorithmic approaches. However, despite these advancements, two\ncore challenges still exist: i) disaggregating low power consumption appliances\nand ii) distinguishing between multiple instances of similar appliances. These\nchallenges are becoming increasingly important due to an increasing number of\nappliances and increased usage of electronics in homes. Previous approaches\nhave attempted to solve these problems using expensive hardware involving high\nsampling rates better suited to laboratory settings, or using additional number\nof sensors, limiting the ease of deployment. In this work, we explore using\ncommercial-off-the-shelf (COTS) power line communication (PLC) modems as an\ninexpensive and easy to deploy alternative solution to these problems. We use\nthe reduction in bandwidth between two PLC modems, caused due to the change in\nPLC modulation scheme when different appliances are operated as a signature for\nan appliance. Since the noise generated in the powerline is dependent both on\ntype and location of an appliance, we believe that our technique based on PLC\nmodems can be a promising addition for solving NILM.\n"}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.5907"}}, {"publisher": {"name": ""}, "description": "  We introduce the study of forcing sets in mathematical origami. The origami\nmaterial folds flat along straight line segments called creases, each of which\nis assigned a folding direction of mountain or valley. A subset $F$ of creases\nis forcing if the global folding mountain/valley assignment can be deduced from\nits restriction to $F$. In this paper we focus on one particular class of\nfoldable patterns called Miura-ori, which divide the plane into congruent\nparallelograms using horizontal lines and zig-zag vertical lines. We develop\nefficient algorithms for constructing a minimum forcing set of a Miura-ori map,\nand for deciding whether a given set of creases is forcing or not. We also\nprovide tight bounds on the size of a forcing set, establishing that the\nstandard mountain-valley assignment for the Miura-ori is the one that requires\nthe most creases in its forcing sets. Additionally, given a partial\nmountain/valley assignment to a subset of creases of a Miura-ori map, we\ndetermine whether the assignment domain can be extended to a locally\nflat-foldable pattern on all the creases. At the heart of our results is a\nnovel correspondence between flat-foldable Miura-ori maps and $3$-colorings of\ngrid graphs.\n", "contributors": [{"name": "Ballinger, Brad", "sameAs": [], "familyName": "Ballinger", "additionalName": "", "givenName": "Brad", "email": ""}, {"name": "Damian, Mirela", "sameAs": [], "familyName": "Damian", "additionalName": "", "givenName": "Mirela", "email": ""}, {"name": "Eppstein, David", "sameAs": [], "familyName": "Eppstein", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Flatland, Robin", "sameAs": [], "familyName": "Flatland", "additionalName": "", "givenName": "Robin", "email": ""}, {"name": "Ginepro, Jessica", "sameAs": [], "familyName": "Ginepro", "additionalName": "", "givenName": "Jessica", "email": ""}, {"name": "Hull, Thomas", "sameAs": [], "familyName": "Hull", "additionalName": "", "givenName": "Thomas", "email": ""}], "title": "Minimum Forcing Sets for Miura Folding Patterns", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2231", "oai:arXiv.org:1410.2231"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We introduce the study of forcing sets in mathematical origami. The origami\nmaterial folds flat along straight line segments called creases, each of which\nis assigned a folding direction of mountain or valley. A subset $F$ of creases\nis forcing if the global folding mountain/valley assignment can be deduced from\nits restriction to $F$. In this paper we focus on one particular class of\nfoldable patterns called Miura-ori, which divide the plane into congruent\nparallelograms using horizontal lines and zig-zag vertical lines. We develop\nefficient algorithms for constructing a minimum forcing set of a Miura-ori map,\nand for deciding whether a given set of creases is forcing or not. We also\nprovide tight bounds on the size of a forcing set, establishing that the\nstandard mountain-valley assignment for the Miura-ori is the one that requires\nthe most creases in its forcing sets. Additionally, given a partial\nmountain/valley assignment to a subset of creases of a Miura-ori map, we\ndetermine whether the assignment domain can be extended to a locally\nflat-foldable pattern on all the creases. At the heart of our results is a\nnovel correspondence between flat-foldable Miura-ori maps and $3$-colorings of\ngrid graphs.\n", "Comment: 20 pages, 16 figures. To appear at the ACM/SIAM Symp. on Discrete\n  Algorithms (SODA 2015)"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "f.2.2", "computer science - discrete mathematics"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2231"}}, {"publisher": {"name": ""}, "description": "  Scientometrics is the study of the quantitative aspects of the process of\nscience as a communication system. It is centrally, but not only, concerned\nwith the analysis of citations in the academic literature. In recent years it\nhas come to play a major role in the measurement and evaluation of research\nperformance. In this review we consider: the historical development of\nscientometrics, sources of citation data, citation metrics and the \"laws\" of\nscientometrics, normalisation, journal impact factors and other journal\nmetrics, visualising and mapping science, evaluation and policy, and future\ndevelopments.\n", "contributors": [{"name": "Mingers, John", "sameAs": [], "familyName": "Mingers", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Leydesdorff, Loet", "sameAs": [], "familyName": "Leydesdorff", "additionalName": "", "givenName": "Loet", "email": ""}], "title": "A Review of Theory and Practice in Scientometrics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-22", "2015-04-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05462", "oai:arXiv.org:1501.05462"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Scientometrics is the study of the quantitative aspects of the process of\nscience as a communication system. It is centrally, but not only, concerned\nwith the analysis of citations in the academic literature. In recent years it\nhas come to play a major role in the measurement and evaluation of research\nperformance. In this review we consider: the historical development of\nscientometrics, sources of citation data, citation metrics and the \"laws\" of\nscientometrics, normalisation, journal impact factors and other journal\nmetrics, visualising and mapping science, evaluation and policy, and future\ndevelopments.\n", "Comment: accepted for publication in the European Journal of Operational\n  Research"]}}], "languages": [null], "subjects": ["computer science - digital libraries"], "providerUpdatedDateTime": "2015-04-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05462"}}, {"publisher": {"name": ""}, "description": "  Bit-interleaved coded modulation (BICM) using (bi-)orthogonal signals is\nespecially well suited for the application in impulse-radio ultra-wideband\ntransmission systems, which typically operate in the power-limited regime and\nrequire a very low-complexity transmitter and receiver design. In this paper we\nanalyze the capacity of BICM using (bi-)orthogonal signals with coherent and\nnoncoherent detection and put particular focus on the power-limited or wideband\nregime. We give analytical expressions for the ratio energy per bit vs. noise\npower spectral density in the limit of infinite bandwidth and the respective\nwideband slope, and thus, are able to quantify the loss incurred by the\nrestriction to BICM in contrast to coded modulation. The gained theoretical\ninsights allow to derive design rules for impulse-radio ultra-wideband\ntransmission systems.\n", "contributors": [{"name": "Schenk, Andreas", "sameAs": [], "familyName": "Schenk", "additionalName": "", "givenName": "Andreas", "email": ""}, {"name": "Fischer, Robert F. H.", "sameAs": [], "familyName": "Fischer", "additionalName": "F. H.", "givenName": "Robert", "email": ""}], "title": "Capacity of BICM Using (Bi-)Orthogonal Signal Constellations in\n  Impulse-Radio Ultra-Wideband Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-02-14", "2011-04-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1102.2761", "oai:arXiv.org:1102.2761"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Bit-interleaved coded modulation (BICM) using (bi-)orthogonal signals is\nespecially well suited for the application in impulse-radio ultra-wideband\ntransmission systems, which typically operate in the power-limited regime and\nrequire a very low-complexity transmitter and receiver design. In this paper we\nanalyze the capacity of BICM using (bi-)orthogonal signals with coherent and\nnoncoherent detection and put particular focus on the power-limited or wideband\nregime. We give analytical expressions for the ratio energy per bit vs. noise\npower spectral density in the limit of infinite bandwidth and the respective\nwideband slope, and thus, are able to quantify the loss incurred by the\nrestriction to BICM in contrast to coded modulation. The gained theoretical\ninsights allow to derive design rules for impulse-radio ultra-wideband\ntransmission systems.\n", "Comment: Draft-version of a manuscript submitted to ICUWB'11"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1102.2761"}}, {"publisher": {"name": ""}, "description": "  Taking full advantages of both heterogeneous networks (HetNets) and cloud\naccess radio access networks (CRANs), heterogeneous cloud radio access networks\n(H-CRANs) are presented to enhance both the spectral and energy efficiencies,\nwhere remote radio heads (RRHs) are mainly used to provide high data rates for\nusers with high quality of service (QoS) requirements, while the high power\nnode (HPN) is deployed to guarantee the seamless coverage and serve users with\nlow QoS requirements. To mitigate the inter-tier interference and improve EE\nperformances in H-CRANs, characterizing user association with RRH/HPN is\nconsidered in this paper, and the traditional soft fractional frequency reuse\n(S-FFR) is enhanced. Based on the RRH/HPN association constraint and the\nenhanced S-FFR, an energy-efficient optimization problem with the resource\nassignment and power allocation for the orthogonal frequency division multiple\naccess (OFDMA) based H-CRANs is formulated as a non-convex objective function.\nTo deal with the non-convexity, an equivalent convex feasibility problem is\nreformulated, and closedform expressions for the energy-efficient resource\nallocation solution to jointly allocate the resource block and transmit power\nare derived by the Lagrange dual decomposition method. Simulation results\nconfirm that the H-CRAN architecture and the corresponding resource allocation\nsolution can enhance the energy efficiency significantly.\n", "contributors": [{"name": "Peng, Mugen", "sameAs": [], "familyName": "Peng", "additionalName": "", "givenName": "Mugen", "email": ""}, {"name": "Zhang, Kecheng", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Kecheng", "email": ""}, {"name": "Jiang, Jiamo", "sameAs": [], "familyName": "Jiang", "additionalName": "", "givenName": "Jiamo", "email": ""}, {"name": "Wang, Jiaheng", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Jiaheng", "email": ""}, {"name": "Wang, Wenbo", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Wenbo", "email": ""}], "title": "Energy-Efficient Resource Assignment and Power Allocation in\n  Heterogeneous Cloud Radio Access Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3788", "oai:arXiv.org:1412.3788"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Taking full advantages of both heterogeneous networks (HetNets) and cloud\naccess radio access networks (CRANs), heterogeneous cloud radio access networks\n(H-CRANs) are presented to enhance both the spectral and energy efficiencies,\nwhere remote radio heads (RRHs) are mainly used to provide high data rates for\nusers with high quality of service (QoS) requirements, while the high power\nnode (HPN) is deployed to guarantee the seamless coverage and serve users with\nlow QoS requirements. To mitigate the inter-tier interference and improve EE\nperformances in H-CRANs, characterizing user association with RRH/HPN is\nconsidered in this paper, and the traditional soft fractional frequency reuse\n(S-FFR) is enhanced. Based on the RRH/HPN association constraint and the\nenhanced S-FFR, an energy-efficient optimization problem with the resource\nassignment and power allocation for the orthogonal frequency division multiple\naccess (OFDMA) based H-CRANs is formulated as a non-convex objective function.\nTo deal with the non-convexity, an equivalent convex feasibility problem is\nreformulated, and closedform expressions for the energy-efficient resource\nallocation solution to jointly allocate the resource block and transmit power\nare derived by the Lagrange dual decomposition method. Simulation results\nconfirm that the H-CRAN architecture and the corresponding resource allocation\nsolution can enhance the energy efficiency significantly.\n", "Comment: 13 pages, 7 figures, accepted by IEEE TVT"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3788"}}, {"publisher": {"name": ""}, "description": "  In this paper, we show $O(1.415^n)$-time and $O(1.190^n)$-space exact\nalgorithms for 0-1 integer programs where constraints are linear equalities and\ncoefficients are arbitrary real numbers. Our algorithms are quadratically\nfaster than exhaustive search and almost quadratically faster than an algorithm\nfor an inequality version of the problem by Impagliazzo, Lovett, Paturi and\nSchneider (arXiv:1401.5512), which motivated our work. Rather than improving\nthe time and space complexity, we advance to a simple direction as inclusion of\nmany NP-hard problems in terms of exact exponential algorithms. Specifically,\nwe extend our algorithms to linear optimization problems.\n", "contributors": [{"name": "Ueno, Kenya", "sameAs": [], "familyName": "Ueno", "additionalName": "", "givenName": "Kenya", "email": ""}], "title": "Exact Algorithms for 0-1 Integer Programs with Linear Equality\n  Constraints", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-27", "2014-11-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.6851", "oai:arXiv.org:1405.6851"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we show $O(1.415^n)$-time and $O(1.190^n)$-space exact\nalgorithms for 0-1 integer programs where constraints are linear equalities and\ncoefficients are arbitrary real numbers. Our algorithms are quadratically\nfaster than exhaustive search and almost quadratically faster than an algorithm\nfor an inequality version of the problem by Impagliazzo, Lovett, Paturi and\nSchneider (arXiv:1401.5512), which motivated our work. Rather than improving\nthe time and space complexity, we advance to a simple direction as inclusion of\nmany NP-hard problems in terms of exact exponential algorithms. Specifically,\nwe extend our algorithms to linear optimization problems.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.6851"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Training structured predictors often requires a considerable time selecting features or tweaking the kernel. Multiple kernel learning (MKL) sidesteps this issue by embedding the kernel learning into the training procedure. Despite the recent progress towards efficiency of MKL algorithms, the structured output case remains an open research front. We propose a family of online algorithms able to tackle variants of MKL and group-LASSO, for which we show regret, convergence, and generalization bounds. Experiments on handwriting recognition and dependency parsing attest the success of the approach.", "contributors": [{"name": "Martins, Andre F.T.", "sameAs": [], "familyName": "Martins", "additionalName": "F.T.", "givenName": "Andre", "email": ""}, {"name": "Smith, Noah A.", "sameAs": [], "familyName": "Smith", "additionalName": "A.", "givenName": "Noah", "email": ""}, {"name": "Xing, Eric P.", "sameAs": [], "familyName": "Xing", "additionalName": "P.", "givenName": "Eric", "email": ""}, {"name": "Aguiar, Pedro M.Q.", "sameAs": [], "familyName": "Aguiar", "additionalName": "M.Q.", "givenName": "Pedro", "email": ""}, {"name": "Figeuiredo, Mario A. T.", "sameAs": [], "familyName": "Figeuiredo", "additionalName": "A. T.", "givenName": "Mario", "email": ""}], "title": "Online Learning of Structured Predictors with Multiple Kernels", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2011-04-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/220", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1216&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1216"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:scs", "publication:machine_learning"]}}, {"name": "description", "properties": {"description": "Training structured predictors often requires a considerable time selecting features or tweaking the kernel. Multiple kernel learning (MKL) sidesteps this issue by embedding the kernel learning into the training procedure. Despite the recent progress towards efficiency of MKL algorithms, the structured output case remains an open research front. We propose a family of online algorithms able to tackle variants of MKL and group-LASSO, for which we show regret, convergence, and generalization bounds. Experiments on handwriting recognition and dependency parsing attest the success of the approach."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-04-09T20:51:32", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/220"}}, {"publisher": {"name": ""}, "description": "  The objective of Content-Based Image Retrieval (CBIR) methods is essentially\nto extract, from large (image) databases, a specified number of images similar\nin visual and semantic content to a so-called query image. To bridge the\nsemantic gap that exists between the representation of an image by low-level\nfeatures (namely, colour, shape, texture) and its high-level semantic content\nas perceived by humans, CBIR systems typically make use of the relevance\nfeedback (RF) mechanism. RF iteratively incorporates user-given inputs\nregarding the relevance of retrieved images, to improve retrieval efficiency.\nOne approach is to vary the weights of the features dynamically via feature\nreweighting. In this work, an attempt has been made to improve retrieval\naccuracy by enhancing a CBIR system based on color features alone, through\nimplicit incorporation of shape information obtained through prior segmentation\nof the images. Novel schemes for feature reweighting as well as for\ninitialization of the relevant set for improved relevance feedback, have also\nbeen proposed for boosting performance of RF- based CBIR. At the same time, new\nmeasures for evaluation of retrieval accuracy have been suggested, to overcome\nthe limitations of existing measures in the RF context. Results of extensive\nexperiments have been presented to illustrate the effectiveness of the proposed\napproaches.\n", "contributors": [{"name": "Bose, Smarajit", "sameAs": [], "familyName": "Bose", "additionalName": "", "givenName": "Smarajit", "email": ""}, {"name": "Pal, Amita", "sameAs": [], "familyName": "Pal", "additionalName": "", "givenName": "Amita", "email": ""}, {"name": "Mallick, Jhimli", "sameAs": [], "familyName": "Mallick", "additionalName": "", "givenName": "Jhimli", "email": ""}, {"name": "Kumar, Sunil", "sameAs": [], "familyName": "Kumar", "additionalName": "", "givenName": "Sunil", "email": ""}, {"name": "Rudra, Pratyaydipta", "sameAs": [], "familyName": "Rudra", "additionalName": "", "givenName": "Pratyaydipta", "email": ""}], "title": "A Hybrid Approach for Improved Content-based Image Retrieval using\n  Segmentation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03215", "oai:arXiv.org:1502.03215"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  The objective of Content-Based Image Retrieval (CBIR) methods is essentially\nto extract, from large (image) databases, a specified number of images similar\nin visual and semantic content to a so-called query image. To bridge the\nsemantic gap that exists between the representation of an image by low-level\nfeatures (namely, colour, shape, texture) and its high-level semantic content\nas perceived by humans, CBIR systems typically make use of the relevance\nfeedback (RF) mechanism. RF iteratively incorporates user-given inputs\nregarding the relevance of retrieved images, to improve retrieval efficiency.\nOne approach is to vary the weights of the features dynamically via feature\nreweighting. In this work, an attempt has been made to improve retrieval\naccuracy by enhancing a CBIR system based on color features alone, through\nimplicit incorporation of shape information obtained through prior segmentation\nof the images. Novel schemes for feature reweighting as well as for\ninitialization of the relevant set for improved relevance feedback, have also\nbeen proposed for boosting performance of RF- based CBIR. At the same time, new\nmeasures for evaluation of retrieval accuracy have been suggested, to overcome\nthe limitations of existing measures in the RF context. Results of extensive\nexperiments have been presented to illustrate the effectiveness of the proposed\napproaches.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval", "statistics - methodology", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03215"}}, {"publisher": {"name": ""}, "description": "  Oscillations between swing modes of electric machines is an important\nlimitation in achieving a high level of transient performance and reliability\nin power grids. Based on the new advances in measurement and transmission of\nwide-area information, this work proposes a distributed networked control\nscheme by considering the communication delays. The results are applied to\nreduce the inter-area swing oscillations in a power grid. In comparison with\nthe previous works, we provide a more realistic modeling of the resulting\nnetworked control system with data sampling and delays. The exactness of the\nproposed modeling allows for precise evaluation and comparison between the\ndistributed and decentralized schema. A symmetric a dual machine power system\nis highly oscillatory and we focus on this case to evaluate the ability of the\nproposed control design in dampening of the oscillations. The design can be\ndone either based on optimization of a quadratic cost function or a disturbance\nattenuation level\n", "contributors": [{"name": "Tavassoli, Babak", "sameAs": [], "familyName": "Tavassoli", "additionalName": "", "givenName": "Babak", "email": ""}], "title": "Design and Evaluation of Distributed Networked Control for a\n  Dual-Machine Power System", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01887", "oai:arXiv.org:1504.01887"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Oscillations between swing modes of electric machines is an important\nlimitation in achieving a high level of transient performance and reliability\nin power grids. Based on the new advances in measurement and transmission of\nwide-area information, this work proposes a distributed networked control\nscheme by considering the communication delays. The results are applied to\nreduce the inter-area swing oscillations in a power grid. In comparison with\nthe previous works, we provide a more realistic modeling of the resulting\nnetworked control system with data sampling and delays. The exactness of the\nproposed modeling allows for precise evaluation and comparison between the\ndistributed and decentralized schema. A symmetric a dual machine power system\nis highly oscillatory and we focus on this case to evaluate the ability of the\nproposed control design in dampening of the oscillations. The design can be\ndone either based on optimization of a quadratic cost function or a disturbance\nattenuation level\n"}}], "languages": [null], "subjects": ["computer science - systems and control"], "providerUpdatedDateTime": "2015-04-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01887"}}, {"publisher": {"name": ""}, "description": "  This article is about twofold arithmetic. Here I introduce algorithms and\nexperimental code for twofold variant of C/C++ standard functions exp() and\nlog(), and expm1() and log1p(). Twofold function $y_0+y_1 \\approx f(x_0+x_1)$\nis nearly 2x-precise so can assess accuracy of standard one. Performance allows\nassessing on-fly: twofold texp() over double is ~10x times faster than expq()\nby GNU quadmath.\n", "contributors": [{"name": "Latkin, Evgeny", "sameAs": [], "familyName": "Latkin", "additionalName": "", "givenName": "Evgeny", "email": ""}], "title": "Twofold exp and log", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.05216", "oai:arXiv.org:1502.05216"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This article is about twofold arithmetic. Here I introduce algorithms and\nexperimental code for twofold variant of C/C++ standard functions exp() and\nlog(), and expm1() and log1p(). Twofold function $y_0+y_1 \\approx f(x_0+x_1)$\nis nearly 2x-precise so can assess accuracy of standard one. Performance allows\nassessing on-fly: twofold texp() over double is ~10x times faster than expq()\nby GNU quadmath.\n", "Comment: Experimental code and tests at \"twofolds\" project Web site:\n  https://sites.google.com/site/yevgenylatkin/"]}}], "languages": [null], "subjects": ["computer science - mathematical software"], "providerUpdatedDateTime": "2015-02-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.05216"}}, {"publisher": {"name": ""}, "description": "  Motivated by the fact that transfer functions do not contain structural\ninformation about networks, dynamical structure functions were introduced to\ncapture causal relationships between measured nodes in networks. From the\ndynamical structure functions, a) we show that the actual number of hidden\nstates can be larger than the number of hidden states estimated from the\ncorresponding transfer function; b) we can obtain partial information about the\ntrue state-space equation, which cannot in general be obtained from the\ntransfer function. Based on these properties, this paper proposes algorithms to\nfind minimal realisations for a given dynamical structure function. This helps\nto estimate the minimal number of hidden states, to better understand the\ncomplexity of the network, and to identify potential targets for new\nmeasurements.\n", "contributors": [{"name": "Yuan, Ye", "sameAs": [], "familyName": "Yuan", "additionalName": "", "givenName": "Ye", "email": ""}, {"name": "Glover, Keith", "sameAs": [], "familyName": "Glover", "additionalName": "", "givenName": "Keith", "email": ""}, {"name": "Goncalvees, Jorge", "sameAs": [], "familyName": "Goncalvees", "additionalName": "", "givenName": "Jorge", "email": ""}], "title": "On minimal realisations of dynamical structure functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-29", "2014-12-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.0072", "oai:arXiv.org:1409.0072"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Motivated by the fact that transfer functions do not contain structural\ninformation about networks, dynamical structure functions were introduced to\ncapture causal relationships between measured nodes in networks. From the\ndynamical structure functions, a) we show that the actual number of hidden\nstates can be larger than the number of hidden states estimated from the\ncorresponding transfer function; b) we can obtain partial information about the\ntrue state-space equation, which cannot in general be obtained from the\ntransfer function. Based on these properties, this paper proposes algorithms to\nfind minimal realisations for a given dynamical structure function. This helps\nto estimate the minimal number of hidden states, to better understand the\ncomplexity of the network, and to identify potential targets for new\nmeasurements.\n"}}], "languages": [null], "subjects": ["computer science - systems and control"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.0072"}}, {"publisher": {"name": ""}, "description": "  This paper presents results on the typical number of simultaneous\npoint-to-point transmissions above a minimum rate that can be sustained in a\nnetwork with $n$ transmitter-receiver node pairs when all transmitting nodes\ncan potentially interfere with all receivers. In particular we obtain a scaling\nlaw when the fading gains are independent Rayleigh distributed random variables\nand the transmitters over different realizations are located at the points of a\nstationary Poisson field in the plane. We show that asymptotically with\nprobability approaching 1, the number of simultaneous transmissions (links that\ncan transmit at greater than a minimum rate) is of the order of\n$O(n^{\\frac{1}{4}})$. These asymptotic results are confirmed from simulations.\n", "contributors": [{"name": "Keshavarz, Hengameh", "sameAs": [], "familyName": "Keshavarz", "additionalName": "", "givenName": "Hengameh", "email": ""}, {"name": "Mazumdar, Ravi R.", "sameAs": [], "familyName": "Mazumdar", "additionalName": "R.", "givenName": "Ravi", "email": ""}, {"name": "Roy, Rahul", "sameAs": [], "familyName": "Roy", "additionalName": "", "givenName": "Rahul", "email": ""}, {"name": "Zoghalchi, Farshid", "sameAs": [], "familyName": "Zoghalchi", "additionalName": "", "givenName": "Farshid", "email": ""}], "title": "On the number of active links in random wireless networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3098", "oai:arXiv.org:1412.3098"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  This paper presents results on the typical number of simultaneous\npoint-to-point transmissions above a minimum rate that can be sustained in a\nnetwork with $n$ transmitter-receiver node pairs when all transmitting nodes\ncan potentially interfere with all receivers. In particular we obtain a scaling\nlaw when the fading gains are independent Rayleigh distributed random variables\nand the transmitters over different realizations are located at the points of a\nstationary Poisson field in the plane. We show that asymptotically with\nprobability approaching 1, the number of simultaneous transmissions (links that\ncan transmit at greater than a minimum rate) is of the order of\n$O(n^{\\frac{1}{4}})$. These asymptotic results are confirmed from simulations.\n"}}], "languages": [null], "subjects": ["computer science - information theory", "94a17", "secondary 60g60", "primary 94a40"], "providerUpdatedDateTime": "2014-12-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3098"}}, {"publisher": {"name": ""}, "description": "  Mobile network operators are facing the difficult task of significantly\nincreasing capacity to meet projected demand while keeping CAPEX and OPEX down.\nWe argue that infrastructure sharing is a key consideration in operators'\nplanning of the evolution of their networks, and that such planning can be\nviewed as a stage in the cognitive cycle. In this paper, we present a framework\nto model this planning process while taking into account both the ability to\nshare resources and the constraints imposed by competition regulation (the\nlatter quantified using the Herfindahl index). Using real-world demand and\ndeployment data, we find that the ability to share infrastructure essentially\nmoves capacity from rural, sparsely populated areas (where some of the current\ninfrastructure can be decommissioned) to urban ones (where most of the\nnext-generation base stations would be deployed), with significant increases in\nresource efficiency. Tight competition regulation somewhat limits the ability\nto share but does not entirely jeopardize those gains, while having the\nsecondary effect of encouraging the wider deployment of next-generation\ntechnologies.\n", "contributors": [{"name": "Di Francesco, Paolo", "sameAs": [], "familyName": "Di Francesco", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Malandrino, Francesco", "sameAs": [], "familyName": "Malandrino", "additionalName": "", "givenName": "Francesco", "email": ""}, {"name": "Forde, Tim K.", "sameAs": [], "familyName": "Forde", "additionalName": "K.", "givenName": "Tim", "email": ""}, {"name": "DaSilva, Luiz A.", "sameAs": [], "familyName": "DaSilva", "additionalName": "A.", "givenName": "Luiz", "email": ""}], "title": "A Sharing- and Competition-Aware Framework for Cellular Network\n  Evolution Planning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03213", "oai:arXiv.org:1504.03213"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Mobile network operators are facing the difficult task of significantly\nincreasing capacity to meet projected demand while keeping CAPEX and OPEX down.\nWe argue that infrastructure sharing is a key consideration in operators'\nplanning of the evolution of their networks, and that such planning can be\nviewed as a stage in the cognitive cycle. In this paper, we present a framework\nto model this planning process while taking into account both the ability to\nshare resources and the constraints imposed by competition regulation (the\nlatter quantified using the Herfindahl index). Using real-world demand and\ndeployment data, we find that the ability to share infrastructure essentially\nmoves capacity from rural, sparsely populated areas (where some of the current\ninfrastructure can be decommissioned) to urban ones (where most of the\nnext-generation base stations would be deployed), with significant increases in\nresource efficiency. Tight competition regulation somewhat limits the ability\nto share but does not entirely jeopardize those gains, while having the\nsecondary effect of encouraging the wider deployment of next-generation\ntechnologies.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03213"}}, {"publisher": {"name": ""}, "description": "  We propose a nonparametric procedure to achieve fast inference in generative\ngraphical models when the number of latent states is very large. The approach\nis based on iterative latent variable preselection, where we alternate between\nlearning a 'selection function' to reveal the relevant latent variables, and\nuse this to obtain a compact approximation of the posterior distribution for\nEM; this can make inference possible where the number of possible latent states\nis e.g. exponential in the number of latent variables, whereas an exact\napproach would be computationally unfeasible. We learn the selection function\nentirely from the observed data and current EM state via Gaussian process\nregression: this is by contrast with earlier approaches, where selections were\nhand-designed for each problem setting. We show our approach to perform as well\nas these bespoke selection functions on a wide variety of inference problems:\nin particular, for the challenging case of a hierarchical model for object\nlocalization with occlusion, we achieve results that match a customized\nstate-of-the-art selection method, at a far lower computational cost.\n", "contributors": [{"name": "Shelton, Jacquelyn A.", "sameAs": [], "familyName": "Shelton", "additionalName": "A.", "givenName": "Jacquelyn", "email": ""}, {"name": "Gasthaus, Jan", "sameAs": [], "familyName": "Gasthaus", "additionalName": "", "givenName": "Jan", "email": ""}, {"name": "Dai, Zhenwen", "sameAs": [], "familyName": "Dai", "additionalName": "", "givenName": "Zhenwen", "email": ""}, {"name": "Luecke, Joerg", "sameAs": [], "familyName": "Luecke", "additionalName": "", "givenName": "Joerg", "email": ""}, {"name": "Gretton, Arthur", "sameAs": [], "familyName": "Gretton", "additionalName": "", "givenName": "Arthur", "email": ""}], "title": "GP-select: Accelerating EM using adaptive subspace preselection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3411", "oai:arXiv.org:1412.3411"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  We propose a nonparametric procedure to achieve fast inference in generative\ngraphical models when the number of latent states is very large. The approach\nis based on iterative latent variable preselection, where we alternate between\nlearning a 'selection function' to reveal the relevant latent variables, and\nuse this to obtain a compact approximation of the posterior distribution for\nEM; this can make inference possible where the number of possible latent states\nis e.g. exponential in the number of latent variables, whereas an exact\napproach would be computationally unfeasible. We learn the selection function\nentirely from the observed data and current EM state via Gaussian process\nregression: this is by contrast with earlier approaches, where selections were\nhand-designed for each problem setting. We show our approach to perform as well\nas these bespoke selection functions on a wide variety of inference problems:\nin particular, for the challenging case of a hierarchical model for object\nlocalization with occlusion, we achieve results that match a customized\nstate-of-the-art selection method, at a far lower computational cost.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-12-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3411"}}, {"publisher": {"name": ""}, "description": "  This paper considers the problem of distributed estimation in an incremental\nnetwork when the measurements taken by the node follow a widely linear model.\nThe proposed algorithm which we refer to it as incremental augmented affine\nprojection algorithm (incAAPA) utilizes the full second order statistical\ninformation in the complex domain. Moreover, it exploits spatio-temporal\ndiversity to improve the estimation performance. We derive steady-state\nperformance metric of the incAAPA in terms of the mean-square deviation (MSD).\nWe further derive sufficient conditions to ensure mean-square convergence. Our\nanalysis illustrate that the proposed algorithm is able to process both second\norder circular (proper) and noncircular (improper) signals. The validity of the\ntheoretical results and the good performance of the proposed algorithm are\ndemonstrated by several computer simulations.\n", "contributors": [{"name": "Khalili, Azam", "sameAs": [], "familyName": "Khalili", "additionalName": "", "givenName": "Azam", "email": ""}, {"name": "Bazzi, Wael M.", "sameAs": [], "familyName": "Bazzi", "additionalName": "M.", "givenName": "Wael", "email": ""}, {"name": "Rastegarnia, Amir", "sameAs": [], "familyName": "Rastegarnia", "additionalName": "", "givenName": "Amir", "email": ""}], "title": "Analysis of incremental augmented affine projection algorithm for\n  distributed estimation of complex signals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4477", "oai:arXiv.org:1410.4477"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper considers the problem of distributed estimation in an incremental\nnetwork when the measurements taken by the node follow a widely linear model.\nThe proposed algorithm which we refer to it as incremental augmented affine\nprojection algorithm (incAAPA) utilizes the full second order statistical\ninformation in the complex domain. Moreover, it exploits spatio-temporal\ndiversity to improve the estimation performance. We derive steady-state\nperformance metric of the incAAPA in terms of the mean-square deviation (MSD).\nWe further derive sufficient conditions to ensure mean-square convergence. Our\nanalysis illustrate that the proposed algorithm is able to process both second\norder circular (proper) and noncircular (improper) signals. The validity of the\ntheoretical results and the good performance of the proposed algorithm are\ndemonstrated by several computer simulations.\n", "Comment: 23 pages, 6 figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4477"}}, {"publisher": {"name": ""}, "description": "  This paper presents a generalization of the $\\kappa$-$\\mu$ shadowed model\nwhen multiple antennas are present at both the transmitter and receiver sides,\ni.e, for a multiple-input multiple-output (MIMO) scenario. Using multivariate\nstatistical theory, the MIMO $\\kappa$-$\\mu$ shadowed model is defined. Its\nprobability density function (pdf) can be expressed in terms of the well-known\ngamma-Wishart distribution and the moment generating function is carried out\nfrom it. Closed-form expressions for the cumulative distribution function (cdf)\nand the pdf of the maximum eigenvalue are derived. Like the single-input\nsingle-output (SISO) model present in the literature, the MIMO $\\kappa$-$\\mu$\nshadowed model allows the unification of some MIMO stochastic channels. In\nfact, the MIMO Rayleigh, MIMO Nakagami-$m$, MIMO Rician, MIMO $\\kappa$-$\\mu$\nand MIMO Rician-Shadowed models can be derived from it, and so their SISO\ncounterparts, i.e, the Rayleigh, Nakagami-$m$, Rician, $\\kappa$-$\\mu$ and\nRician-Shadowed, respectively.\n", "contributors": [{"name": "Moreno-Pozas, Laureano", "sameAs": [], "familyName": "Moreno-Pozas", "additionalName": "", "givenName": "Laureano", "email": ""}, {"name": "Martos-Naya, Eduardo", "sameAs": [], "familyName": "Martos-Naya", "additionalName": "", "givenName": "Eduardo", "email": ""}], "title": "A Random Matrix Model for $\\kappa$-$\\mu$ Shadowed Fading", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-15", "2015-03-23"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.3998", "oai:arXiv.org:1410.3998"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper presents a generalization of the $\\kappa$-$\\mu$ shadowed model\nwhen multiple antennas are present at both the transmitter and receiver sides,\ni.e, for a multiple-input multiple-output (MIMO) scenario. Using multivariate\nstatistical theory, the MIMO $\\kappa$-$\\mu$ shadowed model is defined. Its\nprobability density function (pdf) can be expressed in terms of the well-known\ngamma-Wishart distribution and the moment generating function is carried out\nfrom it. Closed-form expressions for the cumulative distribution function (cdf)\nand the pdf of the maximum eigenvalue are derived. Like the single-input\nsingle-output (SISO) model present in the literature, the MIMO $\\kappa$-$\\mu$\nshadowed model allows the unification of some MIMO stochastic channels. In\nfact, the MIMO Rayleigh, MIMO Nakagami-$m$, MIMO Rician, MIMO $\\kappa$-$\\mu$\nand MIMO Rician-Shadowed models can be derived from it, and so their SISO\ncounterparts, i.e, the Rayleigh, Nakagami-$m$, Rician, $\\kappa$-$\\mu$ and\nRician-Shadowed, respectively.\n", "Comment: This work has been submitted to an international for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.3998"}}, {"publisher": {"name": ""}, "description": "  This paper presents a digital signal processing tool developed using\nMatlabTM, which provides a very low-cost and effective strategy for\nanalog-to-digital conversion of legated paper biomedical maps without requiring\ndedicated hardware. This software-based approach is particularly helpful for\ndigitalizing biomedical signals acquired from analogical devices equipped with\na plottingter. Albeit signals used in biomedical diagnosis are the primary\nconcern, this imaging processing tool is suitable to modernize facilities in a\nnon-expensive way. Legated paper ECG and EEG charts can be fast and efficiently\ndigitalized in order to be added in existing up-to-date medical data banks,\nimproving the follow-up of patients.\n", "contributors": [{"name": "Silva, A. R. Gomes e", "sameAs": [], "familyName": "Silva", "additionalName": "R. Gomes e", "givenName": "A.", "email": ""}, {"name": "de Oliveira, H. M.", "sameAs": [], "familyName": "de Oliveira", "additionalName": "M.", "givenName": "H.", "email": ""}, {"name": "Lins, R. D.", "sameAs": [], "familyName": "Lins", "additionalName": "D.", "givenName": "R.", "email": ""}], "title": "Converting ECG and other paper legated biomedical maps into digital\n  signals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.05906", "oai:arXiv.org:1502.05906"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper presents a digital signal processing tool developed using\nMatlabTM, which provides a very low-cost and effective strategy for\nanalog-to-digital conversion of legated paper biomedical maps without requiring\ndedicated hardware. This software-based approach is particularly helpful for\ndigitalizing biomedical signals acquired from analogical devices equipped with\na plottingter. Albeit signals used in biomedical diagnosis are the primary\nconcern, this imaging processing tool is suitable to modernize facilities in a\nnon-expensive way. Legated paper ECG and EEG charts can be fast and efficiently\ndigitalized in order to be added in existing up-to-date medical data banks,\nimproving the follow-up of patients.\n", "Comment: 5 pages, 8 figures. XXV Simposio Brasileiro de Telecomunicacoes, 2007"]}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2015-02-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.05906"}}, {"publisher": {"name": ""}, "description": "  Working in a three-dimensional variant of Winfree's abstract Tile Assembly\nModel, we show that, for all $N \\in \\mathbb{N}$, there is a tile set that\nuniquely self-assembles into an $N \\times N$ square shape at temperature 1 with\noptimal program-size complexity of $O(\\log N / \\log \\log N)$ (the program-size\ncomplexity, also known as tile complexity, of a shape is the minimum number of\nunique tile types required to uniquely self-assemble it). Moreover, our\nconstruction is \"just barely\" 3D in the sense that it works even when the\nplacement of tiles is restricted to the $z = 0$ and $z = 1$ planes. This result\naffirmatively answers an open question from Cook, Fu, Schweller (SODA 2011). To\nachieve this result, we develop a general 3D temperature 1 optimal encoding\nconstruction, reminiscent of the 2D temperature 2 optimal encoding construction\nof Soloveichik and Winfree (SICOMP 2007), and perhaps of independent interest.\n", "contributors": [{"name": "Furcy, David", "sameAs": [], "familyName": "Furcy", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Micka, Samuel", "sameAs": [], "familyName": "Micka", "additionalName": "", "givenName": "Samuel", "email": ""}, {"name": "Summers, Scott M.", "sameAs": [], "familyName": "Summers", "additionalName": "M.", "givenName": "Scott", "email": ""}], "title": "Optimal program-size complexity for self-assembly at temperature 1 in 3D", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1122", "oai:arXiv.org:1411.1122"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Working in a three-dimensional variant of Winfree's abstract Tile Assembly\nModel, we show that, for all $N \\in \\mathbb{N}$, there is a tile set that\nuniquely self-assembles into an $N \\times N$ square shape at temperature 1 with\noptimal program-size complexity of $O(\\log N / \\log \\log N)$ (the program-size\ncomplexity, also known as tile complexity, of a shape is the minimum number of\nunique tile types required to uniquely self-assemble it). Moreover, our\nconstruction is \"just barely\" 3D in the sense that it works even when the\nplacement of tiles is restricted to the $z = 0$ and $z = 1$ planes. This result\naffirmatively answers an open question from Cook, Fu, Schweller (SODA 2011). To\nachieve this result, we develop a general 3D temperature 1 optimal encoding\nconstruction, reminiscent of the 2D temperature 2 optimal encoding construction\nof Soloveichik and Winfree (SICOMP 2007), and perhaps of independent interest.\n"}}], "languages": [null], "subjects": ["computer science - emerging technologies", "computer science - computational geometry"], "providerUpdatedDateTime": "2014-11-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1122"}}, {"publisher": {"name": ""}, "description": "  The R package sns implements Stochastic Newton Sampler (SNS), a\nMetropolis-Hastings Monte Carlo Markov Chain algorithm where the proposal\ndensity function is a multivariate Gaussian based on a local, second-order\nTaylor series expansion of log-density. The mean of the proposal function is\nthe full Newton step in Newton-Raphson optimization algorithm. Taking advantage\nof the local, multivariate geometry captured in log-density Hessian allows SNS\nto be more efficient than univariate samplers, approaching independent sampling\nas the density function increasingly resembles a multivariate Gaussian. SNS\nrequires the log-density Hessian to be negative-definite everywhere in order to\nconstruct a valid proposal function. This property holds, or can be easily\nchecked, for many GLM-like models. When initial point is far from density peak,\nrunning SNS in non-stochastic mode by taking the Newton step, augmented with\nwith line search, allows the MCMC chain to converge to high-density areas\nfaster. For high-dimensional problems, partitioning of state space into\nlower-dimensional subsets, and applying SNS to the subsets within a Gibbs\nsampling framework can significantly improve the mixing of SNS chains. In\naddition to the above strategies for improving convergence and mixing, sns\noffers diagnostics and visualization capabilities, as well as a function for\nsample-based calculation of Bayesian predictive posterior distributions.\n", "contributors": [{"name": "Mahani, Alireza S.", "sameAs": [], "familyName": "Mahani", "additionalName": "S.", "givenName": "Alireza", "email": ""}, {"name": "Hasan, Asad", "sameAs": [], "familyName": "Hasan", "additionalName": "", "givenName": "Asad", "email": ""}, {"name": "Jiang, Marshall", "sameAs": [], "familyName": "Jiang", "additionalName": "", "givenName": "Marshall", "email": ""}, {"name": "Sharabiani, Mansour T. A.", "sameAs": [], "familyName": "Sharabiani", "additionalName": "T. A.", "givenName": "Mansour", "email": ""}], "title": "Stochastic Newton Sampler: R Package sns", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02008", "oai:arXiv.org:1502.02008"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  The R package sns implements Stochastic Newton Sampler (SNS), a\nMetropolis-Hastings Monte Carlo Markov Chain algorithm where the proposal\ndensity function is a multivariate Gaussian based on a local, second-order\nTaylor series expansion of log-density. The mean of the proposal function is\nthe full Newton step in Newton-Raphson optimization algorithm. Taking advantage\nof the local, multivariate geometry captured in log-density Hessian allows SNS\nto be more efficient than univariate samplers, approaching independent sampling\nas the density function increasingly resembles a multivariate Gaussian. SNS\nrequires the log-density Hessian to be negative-definite everywhere in order to\nconstruct a valid proposal function. This property holds, or can be easily\nchecked, for many GLM-like models. When initial point is far from density peak,\nrunning SNS in non-stochastic mode by taking the Newton step, augmented with\nwith line search, allows the MCMC chain to converge to high-density areas\nfaster. For high-dimensional problems, partitioning of state space into\nlower-dimensional subsets, and applying SNS to the subsets within a Gibbs\nsampling framework can significantly improve the mixing of SNS chains. In\naddition to the above strategies for improving convergence and mixing, sns\noffers diagnostics and visualization capabilities, as well as a function for\nsample-based calculation of Bayesian predictive posterior distributions.\n"}}], "languages": [null], "subjects": ["statistics - computation", "statistics - methodology"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02008"}}, {"publisher": {"name": ""}, "description": "  This paper considers onboard control of a small-sized quadrotor using a\nstrapdown embedded optical flow sensor which is conventionally used for desktop\nmice. The vehicle considered in this paper can carry only few dozen grams of\npayload, therefore conventional camera-based optical flow methods are not\napplicable. We present hovering control of the small-sized quadrotor using a\nsingle-chip optical flow sensor, implemented on an 8-bit microprocessor without\nexternal sensors or communication with a ground control station. Detailed\ndescription of all the system components is provided along with evaluation of\nthe accuracy. Experimental results from flight tests are validated with the\nground-truth data provided by a high-accuracy reference system.\n", "contributors": [{"name": "Lim, Hyon", "sameAs": [], "familyName": "Lim", "additionalName": "", "givenName": "Hyon", "email": ""}, {"name": "Lee, Hyeonbeom", "sameAs": [], "familyName": "Lee", "additionalName": "", "givenName": "Hyeonbeom", "email": ""}, {"name": "Kim, H. Jin", "sameAs": [], "familyName": "Kim", "additionalName": "Jin", "givenName": "H.", "email": ""}], "title": "Onboard Flight Control of a Small Quadrotor Using Single Strapdown\n  Optical Flow Sensor", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-03-20", "2012-03-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1203.4349", "oai:arXiv.org:1203.4349"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper considers onboard control of a small-sized quadrotor using a\nstrapdown embedded optical flow sensor which is conventionally used for desktop\nmice. The vehicle considered in this paper can carry only few dozen grams of\npayload, therefore conventional camera-based optical flow methods are not\napplicable. We present hovering control of the small-sized quadrotor using a\nsingle-chip optical flow sensor, implemented on an 8-bit microprocessor without\nexternal sensors or communication with a ground control station. Detailed\ndescription of all the system components is provided along with evaluation of\nthe accuracy. Experimental results from flight tests are validated with the\nground-truth data provided by a high-accuracy reference system.\n", "Comment: I would like to remove this article due to copyright problem. Please\n  remove my article as soon as possible"]}}], "languages": [null], "subjects": ["computer science - robotics"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1203.4349"}}, {"publisher": {"name": ""}, "description": "  Werner's set-theoretical model is one of the most intuitive models of CC. It\ncombines a functional view of predicative universes with a collapsed view of\nimpredicative sort Prop. However this model of Prop is so coarse that the\nprinciple of excluded middle $P \\lor \\neg P$ holds. In this paper, we interpret\nProp into a Heyting algebra to make it more intuitionistic without sacrificing\nsimplicity.\n", "contributors": [{"name": "Sato, Masahiro", "sameAs": [], "familyName": "Sato", "additionalName": "", "givenName": "Masahiro", "email": ""}], "title": "An Intuitionistic Set-theoretical Model of the Extended Calculus of\n  Constructions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2235", "oai:arXiv.org:1412.2235"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Werner's set-theoretical model is one of the most intuitive models of CC. It\ncombines a functional view of predicative universes with a collapsed view of\nimpredicative sort Prop. However this model of Prop is so coarse that the\nprinciple of excluded middle $P \\lor \\neg P$ holds. In this paper, we interpret\nProp into a Heyting algebra to make it more intuitionistic without sacrificing\nsimplicity.\n"}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2235"}}, {"publisher": {"name": ""}, "description": "  The magnetic field integral equation for axially symmetric cavities with\nperfectly conducting surfaces is discretized according to a high-order\nconvergent Fourier--Nystr\\\"om scheme. The resulting solver is used to determine\neigenwavenumbers and normalized magnetic eigenfields to very high accuracy in\nthe entire computational domain.\n", "contributors": [{"name": "Helsing, Johan", "sameAs": [], "familyName": "Helsing", "additionalName": "", "givenName": "Johan", "email": ""}, {"name": "Karlsson, Anders", "sameAs": [], "familyName": "Karlsson", "additionalName": "", "givenName": "Anders", "email": ""}], "title": "Determination of normalized magnetic eigenfields in microwave cavities", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.0848", "oai:arXiv.org:1410.0848"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": ["  The magnetic field integral equation for axially symmetric cavities with\nperfectly conducting surfaces is discretized according to a high-order\nconvergent Fourier--Nystr\\\"om scheme. The resulting solver is used to determine\neigenwavenumbers and normalized magnetic eigenfields to very high accuracy in\nthe entire computational domain.\n", "Comment: 23 pages, 4 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "65n25", "31b10", "78m15", "35q61"], "providerUpdatedDateTime": "2014-10-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.0848"}}, {"publisher": {"name": ""}, "description": "  Lifted inference has been proposed for various probabilistic logical\nframeworks in order to compute the probability of queries in a time that\ndepends on the size of the domains of the random variables rather than the\nnumber of instances. Even if various authors have underlined its importance for\nprobabilistic logic programming (PLP), lifted inference has been applied up to\nnow only to relational languages outside of logic programming. In this paper we\nadapt Generalized Counting First Order Variable Elimination (GC-FOVE) to the\nproblem of computing the probability of queries to probabilistic logic programs\nunder the distribution semantics. In particular, we extend the Prolog Factor\nLanguage (PFL) to include two new types of factors that are needed for\nrepresenting ProbLog programs. These factors take into account the existing\ncausal independence relationships among random variables and are managed by the\nextension to variable elimination proposed by Zhang and Poole for dealing with\nconvergent variables and heterogeneous factors. Two new operators are added to\nGC-FOVE for treating heterogeneous factors. The resulting algorithm, called\nLP$^2$ for Lifted Probabilistic Logic Programming, has been implemented by\nmodifying the PFL implementation of GC-FOVE and tested on three benchmarks for\nlifted inference. A comparison with PITA and ProbLog2 shows the potential of\nthe approach.\n", "contributors": [{"name": "Bellodi, Elena", "sameAs": [], "familyName": "Bellodi", "additionalName": "", "givenName": "Elena", "email": ""}, {"name": "Lamma, Evelina", "sameAs": [], "familyName": "Lamma", "additionalName": "", "givenName": "Evelina", "email": ""}, {"name": "Riguzzi, Fabrizio", "sameAs": [], "familyName": "Riguzzi", "additionalName": "", "givenName": "Fabrizio", "email": ""}, {"name": "Costa, Vitor Santos", "sameAs": [], "familyName": "Costa", "additionalName": "Santos", "givenName": "Vitor", "email": ""}, {"name": "Zese, Riccardo", "sameAs": [], "familyName": "Zese", "additionalName": "", "givenName": "Riccardo", "email": ""}], "title": "Lifted Variable Elimination for Probabilistic Logic Programming", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-13", "2014-10-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.3218", "doi:10.1017/S1471068414000283", "oai:arXiv.org:1405.3218"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Lifted inference has been proposed for various probabilistic logical\nframeworks in order to compute the probability of queries in a time that\ndepends on the size of the domains of the random variables rather than the\nnumber of instances. Even if various authors have underlined its importance for\nprobabilistic logic programming (PLP), lifted inference has been applied up to\nnow only to relational languages outside of logic programming. In this paper we\nadapt Generalized Counting First Order Variable Elimination (GC-FOVE) to the\nproblem of computing the probability of queries to probabilistic logic programs\nunder the distribution semantics. In particular, we extend the Prolog Factor\nLanguage (PFL) to include two new types of factors that are needed for\nrepresenting ProbLog programs. These factors take into account the existing\ncausal independence relationships among random variables and are managed by the\nextension to variable elimination proposed by Zhang and Poole for dealing with\nconvergent variables and heterogeneous factors. Two new operators are added to\nGC-FOVE for treating heterogeneous factors. The resulting algorithm, called\nLP$^2$ for Lifted Probabilistic Logic Programming, has been implemented by\nmodifying the PFL implementation of GC-FOVE and tested on three benchmarks for\nlifted inference. A comparison with PITA and ProbLog2 shows the potential of\nthe approach.\n", "Comment: To appear in Theory and Practice of Logic Programming (TPLP). arXiv\n  admin note: text overlap with arXiv:1402.0565 by other authors"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2014-10-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.3218"}}, {"publisher": {"name": ""}, "description": "  There have been numerous works on network intrusion detection and prevention\nsystems, but work on application layer intrusion detection and prevention is\nrare and not very mature. Intrusion detection and prevention at both network\nand application layers are important for cyber-security and enterprise system\nsecurity. Since application layer intrusion is increasing day by day, it is\nimperative to give adequate attention to it and use state-of-the-art algorithms\nfor effective detection and prevention. This paper talks about current state of\napplication layer intrusion detection and prevention capabilities in commercial\nand open-source space and provides a path for evolution to more mature state\nthat will address not only enterprise system security, but also national\ncyber-defence. Scalability and cost-effectiveness were important factors which\nshaped the proposed solution.\n", "contributors": [{"name": "Saha, Amal", "sameAs": [], "familyName": "Saha", "additionalName": "", "givenName": "Amal", "email": ""}, {"name": "Sanyal, Sugata", "sameAs": [], "familyName": "Sanyal", "additionalName": "", "givenName": "Sugata", "email": ""}], "title": "Application Layer Intrusion Detection with Combination of Explicit-Rule-\n  Based and Machine Learning Algorithms and Deployment in Cyber- Defence\n  Program", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3089", "oai:arXiv.org:1411.3089"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  There have been numerous works on network intrusion detection and prevention\nsystems, but work on application layer intrusion detection and prevention is\nrare and not very mature. Intrusion detection and prevention at both network\nand application layers are important for cyber-security and enterprise system\nsecurity. Since application layer intrusion is increasing day by day, it is\nimperative to give adequate attention to it and use state-of-the-art algorithms\nfor effective detection and prevention. This paper talks about current state of\napplication layer intrusion detection and prevention capabilities in commercial\nand open-source space and provides a path for evolution to more mature state\nthat will address not only enterprise system security, but also national\ncyber-defence. Scalability and cost-effectiveness were important factors which\nshaped the proposed solution.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3089"}}, {"publisher": {"name": ""}, "description": "  Elliptic M\\\"obius transformations of the unit disk are those for which there\nis a fixed point in $\\mathbb{D}$. It is not hard to classify which M\\\"obius\ntransformations are elliptic in terms of the parameters. The set of parameters\ncan be identified with the solid torus $S^1 \\times \\mathbb{D}$, and the set of\nelliptic parameters is called the domain of ellipticity. In this paper, we\nstudy the domain of ellipticity for non-trivial unicritical Blaschke products.\nWe will also study the set corresponding to the Mandelbrot set for this family,\nand show how it can be obtained from the domain of ellipticity by adding one\npoint.\n", "contributors": [{"name": "Fletcher, Alastair", "sameAs": [], "familyName": "Fletcher", "additionalName": "", "givenName": "Alastair", "email": ""}], "title": "Unicritical Blaschke products and domains of ellipticity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-11", "2014-12-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.2418", "oai:arXiv.org:1408.2418"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Elliptic M\\\"obius transformations of the unit disk are those for which there\nis a fixed point in $\\mathbb{D}$. It is not hard to classify which M\\\"obius\ntransformations are elliptic in terms of the parameters. The set of parameters\ncan be identified with the solid torus $S^1 \\times \\mathbb{D}$, and the set of\nelliptic parameters is called the domain of ellipticity. In this paper, we\nstudy the domain of ellipticity for non-trivial unicritical Blaschke products.\nWe will also study the set corresponding to the Mandelbrot set for this family,\nand show how it can be obtained from the domain of ellipticity by adding one\npoint.\n", "Comment: 3 figures"]}}], "languages": [null], "subjects": ["mathematics - dynamical systems", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.2418"}}, {"publisher": {"name": ""}, "description": "  Can we move beyond simply networking creative individuals to establishing\ndiverse communities of practice for innovation through discursive methods.\nFurthermore, can we digitise their creativity activities within an integrative\nsocio-cultural collaborative technology platform that could then support\ndistributed innovation. First, we consider the complexity of creative cultures\nfrom the perspective of design innovation, including how to nurture creativity\nactivities in what we call Creative Gardens. Specifically, how they could grow,\ndiverge, and combine, be- ing cultivated to nurture emergent, disruptive,\ncollaborative innovation. Then, we consider the digitisation of Creative\nGardens from the perspective of digital culture. Specifically, the tenets of\nCreative Gardens as dynamic and innovative communities. This includes\nconsidering the challenges and opportunities around digitisation, the\ninfluences around the connectivity with knowledge cultivation, and the\npotential for distributed innovation as collective intelligence to utilise\ndiverse expertise. We conclude be considering the importance of the issues and\nquestions raised, and their potential for the future.\n", "contributors": [{"name": "Briscoe, Gerard", "sameAs": [], "familyName": "Briscoe", "additionalName": "", "givenName": "Gerard", "email": ""}, {"name": "Lockwood, Joseph", "sameAs": [], "familyName": "Lockwood", "additionalName": "", "givenName": "Joseph", "email": ""}], "title": "Creative Gardens", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-09-23", "2015-02-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1309.5769", "oai:arXiv.org:1309.5769"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Can we move beyond simply networking creative individuals to establishing\ndiverse communities of practice for innovation through discursive methods.\nFurthermore, can we digitise their creativity activities within an integrative\nsocio-cultural collaborative technology platform that could then support\ndistributed innovation. First, we consider the complexity of creative cultures\nfrom the perspective of design innovation, including how to nurture creativity\nactivities in what we call Creative Gardens. Specifically, how they could grow,\ndiverge, and combine, be- ing cultivated to nurture emergent, disruptive,\ncollaborative innovation. Then, we consider the digitisation of Creative\nGardens from the perspective of digital culture. Specifically, the tenets of\nCreative Gardens as dynamic and innovative communities. This includes\nconsidering the challenges and opportunities around digitisation, the\ninfluences around the connectivity with knowledge cultivation, and the\npotential for distributed innovation as collective intelligence to utilise\ndiverse expertise. We conclude be considering the importance of the issues and\nquestions raised, and their potential for the future.\n", "Comment: 4 pages, conference"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-02-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1309.5769"}}, {"publisher": {"name": ""}, "description": "  An increasing amount of geo-referenced mobile phone data enables the\nidentification of behavioral patterns, habits and movements of people. With\nthis data, we can extract the knowledge potentially useful for many\napplications including the one tackled in this study - understanding spatial\nvariation of epidemics. We explored the datasets collected by a cell phone\nservice provider and linked them to spatial HIV prevalence rates estimated from\npublicly available surveys. For that purpose, 224 features were extracted from\nmobility and connectivity traces and related to the level of HIV epidemic in 50\nIvory Coast departments. By means of regression models, we evaluated predictive\nability of extracted features. Several models predicted HIV prevalence that are\nhighly correlated (>0.7) with actual values. Through contribution analysis we\nidentified key elements that impact the rate of infections. Our findings\nindicate that night connectivity and activity, spatial area covered by users\nand overall migrations are strongly linked to HIV. By visualizing the\ncommunication and mobility flows, we strived to explain the spatial structure\nof epidemics. We discovered that strong ties and hubs in communication and\nmobility align with HIV hot spots.\n", "contributors": [{"name": "Brdar, Sanja", "sameAs": [], "familyName": "Brdar", "additionalName": "", "givenName": "Sanja", "email": ""}, {"name": "Gavric, Katarina", "sameAs": [], "familyName": "Gavric", "additionalName": "", "givenName": "Katarina", "email": ""}, {"name": "Culibrk, Dubravko", "sameAs": [], "familyName": "Culibrk", "additionalName": "", "givenName": "Dubravko", "email": ""}, {"name": "Crnojevic, Vladimir", "sameAs": [], "familyName": "Crnojevic", "additionalName": "", "givenName": "Vladimir", "email": ""}], "title": "Unveiling Spatial Epidemiology of HIV with Mobile Phone Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06575", "oai:arXiv.org:1503.06575"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  An increasing amount of geo-referenced mobile phone data enables the\nidentification of behavioral patterns, habits and movements of people. With\nthis data, we can extract the knowledge potentially useful for many\napplications including the one tackled in this study - understanding spatial\nvariation of epidemics. We explored the datasets collected by a cell phone\nservice provider and linked them to spatial HIV prevalence rates estimated from\npublicly available surveys. For that purpose, 224 features were extracted from\nmobility and connectivity traces and related to the level of HIV epidemic in 50\nIvory Coast departments. By means of regression models, we evaluated predictive\nability of extracted features. Several models predicted HIV prevalence that are\nhighly correlated (>0.7) with actual values. Through contribution analysis we\nidentified key elements that impact the rate of infections. Our findings\nindicate that night connectivity and activity, spatial area covered by users\nand overall migrations are strongly linked to HIV. By visualizing the\ncommunication and mobility flows, we strived to explain the spatial structure\nof epidemics. We discovered that strong ties and hubs in communication and\nmobility align with HIV hot spots.\n", "Comment: 13 pages, 4 figures, 2 tables"]}}], "languages": [null], "subjects": ["statistics - applications", "computer science - computers and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06575"}}, {"publisher": {"name": ""}, "description": "  A quantum-mechanical description of the magnetic shape anisotropy, that is\nusually ascribed to the classical magnetic dipole-dipole interaction, has been\ndeveloped. This is achieved by including the Breit-interaction, that can be\nseen as an electronic current-current interaction in addition to the\nconventional Coulomb interaction, within fully relativistic band structure\ncalculations. The major sources of the magnetic anisotropy, spin-orbit coupling\nand the Breit-interaction, are treated coherently this way. This seems to be\nespecially important for layered systems for which often both sources\ncontribute with opposite sign to the magnetic anisotropy energy. Applications\nto layered transition metal systems are presented to demonstrate the\nimplications of this new approach in treating the magnetic shape anisotropy.\n", "contributors": [{"name": "Bornemann, S.", "sameAs": [], "familyName": "Bornemann", "additionalName": "", "givenName": "S.", "email": ""}, {"name": "Minar, J.", "sameAs": [], "familyName": "Minar", "additionalName": "", "givenName": "J.", "email": ""}, {"name": "Braun, J.", "sameAs": [], "familyName": "Braun", "additionalName": "", "givenName": "J.", "email": ""}, {"name": "Koedderitzsch, D.", "sameAs": [], "familyName": "Koedderitzsch", "additionalName": "", "givenName": "D.", "email": ""}, {"name": "Ebert, H.", "sameAs": [], "familyName": "Ebert", "additionalName": "", "givenName": "H.", "email": ""}], "title": "Ab-initio description of the magnetic shape anisotropy due to the Breit\n  interaction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-12-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1012.1115", "oai:arXiv.org:1012.1115"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  A quantum-mechanical description of the magnetic shape anisotropy, that is\nusually ascribed to the classical magnetic dipole-dipole interaction, has been\ndeveloped. This is achieved by including the Breit-interaction, that can be\nseen as an electronic current-current interaction in addition to the\nconventional Coulomb interaction, within fully relativistic band structure\ncalculations. The major sources of the magnetic anisotropy, spin-orbit coupling\nand the Breit-interaction, are treated coherently this way. This seems to be\nespecially important for layered systems for which often both sources\ncontribute with opposite sign to the magnetic anisotropy energy. Applications\nto layered transition metal systems are presented to demonstrate the\nimplications of this new approach in treating the magnetic shape anisotropy.\n", "Comment: 4 pages, 4 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "condensed matter - strongly correlated electrons", "condensed matter - materials science"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1012.1115"}}, {"publisher": {"name": ""}, "description": "  In this report we describe a tool framework for certifying properties of\nPLCs: CERTPLC. CERTPLC can handle PLC descriptions provided in the Sequential\nFunction Chart (SFC) language of the IEC 61131-3 standard. It provides routines\nto certify properties of systems by delivering an independently checkable\nformal system description and proof (called certificate) for the desired\nproperties. We focus on properties that can be described as inductive\ninvariants. System descriptions and certificates are generated and handled\nusing the COQ proof assistant. Our tool framework is used to provide supporting\nevidence for the safety of embedded systems in the industrial automation domain\nto third-party authorities. In this document we describe the tool framework:\nusage scenarios, the archi-tecture, semantics of PLCs and their realization in\nCOQ, proof generation and the construction of certificates.\n", "contributors": [{"name": "Blech, Jan Olaf", "sameAs": [], "familyName": "Blech", "additionalName": "Olaf", "givenName": "Jan", "email": ""}], "title": "A Tool for the Certification of PLCs based on a Coq Semantics for\n  Sequential Function Charts", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-02-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1102.3529", "oai:arXiv.org:1102.3529"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this report we describe a tool framework for certifying properties of\nPLCs: CERTPLC. CERTPLC can handle PLC descriptions provided in the Sequential\nFunction Chart (SFC) language of the IEC 61131-3 standard. It provides routines\nto certify properties of systems by delivering an independently checkable\nformal system description and proof (called certificate) for the desired\nproperties. We focus on properties that can be described as inductive\ninvariants. System descriptions and certificates are generated and handled\nusing the COQ proof assistant. Our tool framework is used to provide supporting\nevidence for the safety of embedded systems in the industrial automation domain\nto third-party authorities. In this document we describe the tool framework:\nusage scenarios, the archi-tecture, semantics of PLCs and their realization in\nCOQ, proof generation and the construction of certificates.\n"}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1102.3529"}}, {"publisher": {"name": ""}, "description": "  Precise complexity results are derived for the model checking problems for\nMTL (metric temporal logic) and TPTL (timed propositional temporal logic) on\n(in)finite data words and deterministic one-counter machines. Depending on the\nnumber of register variables and the encoding of numbers in constraints (unary\nor binary), the complexity is either P-complete or PSPACE-complete.\n", "contributors": [{"name": "Feng, Shiguang", "sameAs": [], "familyName": "Feng", "additionalName": "", "givenName": "Shiguang", "email": ""}, {"name": "Lohrey, Markus", "sameAs": [], "familyName": "Lohrey", "additionalName": "", "givenName": "Markus", "email": ""}, {"name": "Quaas, Karin", "sameAs": [], "familyName": "Quaas", "additionalName": "", "givenName": "Karin", "email": ""}], "title": "Path-Checking for MTL and TPTL over Data Words", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-11", "2015-03-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3644", "oai:arXiv.org:1412.3644"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Precise complexity results are derived for the model checking problems for\nMTL (metric temporal logic) and TPTL (timed propositional temporal logic) on\n(in)finite data words and deterministic one-counter machines. Depending on the\nnumber of register variables and the encoding of numbers in constraints (unary\nor binary), the complexity is either P-complete or PSPACE-complete.\n"}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3644"}}, {"publisher": {"name": ""}, "description": "  Vector Symbolic Architectures (VSAs) are high-dimensional vector\nrepresentations of objects (eg., words, image parts), relations (eg., sentence\nstructures), and sequences for use with machine learning algorithms. They\nconsist of a vector addition operator for representing a collection of\nunordered objects, a Binding operator for associating groups of objects, and a\nmethodology for encoding complex structures.\n  We first develop Constraints that machine learning imposes upon VSAs: for\nexample, similar structures must be represented by similar vectors. The\nconstraints suggest that current VSAs should represent phrases (\"The smart\nBrazilian girl\") by binding sums of terms, in addition to simply binding the\nterms directly.\n  We show that matrix multiplication can be used as the binding operator for a\nVSA, and that matrix elements can be chosen at random. A consequence for living\nsystems is that binding is mathematically possible without the need to specify,\nin advance, precise neuron-to-neuron connection properties for large numbers of\nsynapses.\n  A VSA that incorporates these ideas, MBAT (Matrix Binding of Additive Terms),\nis described that satisfies all Constraints.\n  With respect to machine learning, for some types of problems appropriate VSA\nrepresentations permit us to prove learnability, rather than relying on\nsimulations. We also propose dividing machine (and neural) learning and\nrepresentation into three Stages, with differing roles for learning in each\nstage.\n  For neural modeling, we give \"representational reasons\" for nervous systems\nto have many recurrent connections, as well as for the importance of phrases in\nlanguage processing.\n  Sizing simulations and analyses suggest that VSAs in general, and MBAT in\nparticular, are ready for real-world applications.\n", "contributors": [{"name": "Gallant, Stephen I.", "sameAs": [], "familyName": "Gallant", "additionalName": "I.", "givenName": "Stephen", "email": ""}, {"name": "Okaywe, T. Wendy", "sameAs": [], "familyName": "Okaywe", "additionalName": "Wendy", "givenName": "T.", "email": ""}], "title": "Representing Objects, Relations, and Sequences", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.07627", "Neural Computation 25, 2038-2078 (August 2013)", "oai:arXiv.org:1501.07627"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Vector Symbolic Architectures (VSAs) are high-dimensional vector\nrepresentations of objects (eg., words, image parts), relations (eg., sentence\nstructures), and sequences for use with machine learning algorithms. They\nconsist of a vector addition operator for representing a collection of\nunordered objects, a Binding operator for associating groups of objects, and a\nmethodology for encoding complex structures.\n  We first develop Constraints that machine learning imposes upon VSAs: for\nexample, similar structures must be represented by similar vectors. The\nconstraints suggest that current VSAs should represent phrases (\"The smart\nBrazilian girl\") by binding sums of terms, in addition to simply binding the\nterms directly.\n  We show that matrix multiplication can be used as the binding operator for a\nVSA, and that matrix elements can be chosen at random. A consequence for living\nsystems is that binding is mathematically possible without the need to specify,\nin advance, precise neuron-to-neuron connection properties for large numbers of\nsynapses.\n  A VSA that incorporates these ideas, MBAT (Matrix Binding of Additive Terms),\nis described that satisfies all Constraints.\n  With respect to machine learning, for some types of problems appropriate VSA\nrepresentations permit us to prove learnability, rather than relying on\nsimulations. We also propose dividing machine (and neural) learning and\nrepresentation into three Stages, with differing roles for learning in each\nstage.\n  For neural modeling, we give \"representational reasons\" for nervous systems\nto have many recurrent connections, as well as for the importance of phrases in\nlanguage processing.\n  Sizing simulations and analyses suggest that VSAs in general, and MBAT in\nparticular, are ready for real-world applications.\n", "Comment: 41 pages"]}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-02-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.07627"}}, {"publisher": {"name": ""}, "description": "  The purpose of this paper is to study metrics suitable for assessing\nuncertainty of power spectra when these are based on finite second-order\nstatistics. The family of power spectra which is consistent with a given range\nof values for the estimated statistics represents the uncertainty set about the\n\"true\" power spectrum. Our aim is to quantify the size of this uncertainty set\nusing suitable notions of distance, and in particular, to compute the diameter\nof the set since this represents an upper bound on the distance between any\nchoice of a nominal element in the set and the \"true\" power spectrum. Since the\nuncertainty set may contain power spectra with lines and discontinuities, it is\nnatural to quantify distances in the weak topology---the topology defined by\ncontinuity of moments. We provide examples of such weakly-continuous metrics\nand focus on particular metrics for which we can explicitly quantify spectral\nuncertainty. We then consider certain high resolution techniques which utilize\nfilter-banks for pre-processing, and compute worst-case a priori uncertainty\nbounds solely on the basis of the filter dynamics. This allows the a priori\ntuning of the filter-banks for improved resolution over selected frequency\nbands.\n", "contributors": [{"name": "Karlsson, Johan", "sameAs": [], "familyName": "Karlsson", "additionalName": "", "givenName": "Johan", "email": ""}, {"name": "Georgiou, Tryphon T.", "sameAs": [], "familyName": "Georgiou", "additionalName": "T.", "givenName": "Tryphon", "email": ""}], "title": "Uncertainty Bounds for Spectral Estimation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-01-21", "2012-09-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1201.4469", "oai:arXiv.org:1201.4469"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  The purpose of this paper is to study metrics suitable for assessing\nuncertainty of power spectra when these are based on finite second-order\nstatistics. The family of power spectra which is consistent with a given range\nof values for the estimated statistics represents the uncertainty set about the\n\"true\" power spectrum. Our aim is to quantify the size of this uncertainty set\nusing suitable notions of distance, and in particular, to compute the diameter\nof the set since this represents an upper bound on the distance between any\nchoice of a nominal element in the set and the \"true\" power spectrum. Since the\nuncertainty set may contain power spectra with lines and discontinuities, it is\nnatural to quantify distances in the weak topology---the topology defined by\ncontinuity of moments. We provide examples of such weakly-continuous metrics\nand focus on particular metrics for which we can explicitly quantify spectral\nuncertainty. We then consider certain high resolution techniques which utilize\nfilter-banks for pre-processing, and compute worst-case a priori uncertainty\nbounds solely on the basis of the filter dynamics. This allows the a priori\ntuning of the filter-banks for improved resolution over selected frequency\nbands.\n", "Comment: 8 figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "g.3", "62g07", "mathematics - statistics theory", "93e10"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1201.4469"}}, {"publisher": {"name": ""}, "description": "  The need to estimate smooth probability distributions (a.k.a. probability\ndensities) from finite sampled data is ubiquitous in science. Many approaches\nto this problem have been described, but none is yet regarded as providing a\ndefinitive solution. Maximum entropy estimation and Bayesian field theory are\ntwo such approaches. Both have origins in statistical physics, but the\nrelationship between them has remained unclear. Here I unify these two methods\nby showing that every maximum entropy density estimate can be recovered in the\ninfinite smoothness limit of an appropriate Bayesian field theory. I also show\nthat Bayesian field theory estimation can be performed without imposing any\nboundary conditions on candidate densities, and that the infinite smoothness\nlimit of these theories recovers the most common types of maximum entropy\nestimates. Bayesian field theory is thus seen to provide a natural test of the\nvalidity of the maximum entropy null hypothesis. Bayesian field theory also\nreturns a lower entropy density estimate when the maximum entropy hypothesis is\nfalsified. The computations necessary for this approach can be performed\nrapidly for one-dimensional data, and software for doing this is provided.\nBased on these results, I argue that Bayesian field theory is poised to provide\na definitive solution to the density estimation problem in one dimension.\n", "contributors": [{"name": "Kinney, Justin B.", "sameAs": [], "familyName": "Kinney", "additionalName": "B.", "givenName": "Justin", "email": ""}], "title": "Unification of field theory and maximum entropy methods for learning\n  probability densities", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-19", "2015-03-21"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5371", "oai:arXiv.org:1411.5371"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics", "q-bio", "stat"]}}, {"name": "description", "properties": {"description": ["  The need to estimate smooth probability distributions (a.k.a. probability\ndensities) from finite sampled data is ubiquitous in science. Many approaches\nto this problem have been described, but none is yet regarded as providing a\ndefinitive solution. Maximum entropy estimation and Bayesian field theory are\ntwo such approaches. Both have origins in statistical physics, but the\nrelationship between them has remained unclear. Here I unify these two methods\nby showing that every maximum entropy density estimate can be recovered in the\ninfinite smoothness limit of an appropriate Bayesian field theory. I also show\nthat Bayesian field theory estimation can be performed without imposing any\nboundary conditions on candidate densities, and that the infinite smoothness\nlimit of these theories recovers the most common types of maximum entropy\nestimates. Bayesian field theory is thus seen to provide a natural test of the\nvalidity of the maximum entropy null hypothesis. Bayesian field theory also\nreturns a lower entropy density estimate when the maximum entropy hypothesis is\nfalsified. The computations necessary for this approach can be performed\nrapidly for one-dimensional data, and software for doing this is provided.\nBased on these results, I argue that Bayesian field theory is poised to provide\na definitive solution to the density estimation problem in one dimension.\n", "Comment: 16 pages, 4 figures. The text has been greatly expanded. Open source\n  software is available at https://github.com/jbkinney/14_maxent"]}}], "languages": [null], "subjects": ["statistics and probability", "quantitative biology - quantitative methods", "computer science - learning", "statistics - machine learning", "physics - data analysis"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5371"}}, {"publisher": {"name": ""}, "description": "  We consider a nonatomic congestion game on a graph, with several classes of\nplayers. Each player wants to go from its origin vertex to its destination\nvertex at the minimum cost and all players of a given class share the same\ncharacteristics: cost functions on each arc, and origin-destination pair. Under\nsome mild conditions, it is known that a Nash equilibrium exists, but the\ncomputation of an equilibrium in the multiclass case is an open problem for\ngeneral functions. We consider the specific case where the cost functions are\naffine. We show that this problem is polynomially solvable when the number of\nvertices and the number of classes are fixed. In particular, it shows that the\nparallel-link case with a fixed number of classes is polynomially solvable. On\na more practical side, we propose an extension of Lemke's algorithm able to\nsolve this problem.\n", "contributors": [{"name": "Meunier, Fr\u00e9d\u00e9ric", "sameAs": [], "familyName": "Meunier", "additionalName": "", "givenName": "Fr\u00e9d\u00e9ric", "email": ""}, {"name": "Pradeau, Thomas", "sameAs": [], "familyName": "Pradeau", "additionalName": "", "givenName": "Thomas", "email": ""}], "title": "Computing solutions of the multiclass network equilibrium problem with\n  affine cost functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6496", "oai:arXiv.org:1412.6496"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We consider a nonatomic congestion game on a graph, with several classes of\nplayers. Each player wants to go from its origin vertex to its destination\nvertex at the minimum cost and all players of a given class share the same\ncharacteristics: cost functions on each arc, and origin-destination pair. Under\nsome mild conditions, it is known that a Nash equilibrium exists, but the\ncomputation of an equilibrium in the multiclass case is an open problem for\ngeneral functions. We consider the specific case where the cost functions are\naffine. We show that this problem is polynomially solvable when the number of\nvertices and the number of classes are fixed. In particular, it shows that the\nparallel-link case with a fixed number of classes is polynomially solvable. On\na more practical side, we propose an extension of Lemke's algorithm able to\nsolve this problem.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory", "mathematics - optimization and control"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6496"}}, {"publisher": {"name": ""}, "description": "  Cloud computing systems, in which clients rent and share computing resources\nof third party platforms, have gained widespread use in recent years.\nFurthermore, cloud computing for mobile systems (i.e., systems in which the\nclients are mobile devices) have too been receiving considerable attention in\ntechnical literature. We propose a new method of delegating computations of\nresource-constrained mobile clients, in which multiple servers interact to\nconstruct an encrypted program known as garbled circuit. Next, using garbled\ninputs from a mobile client, another server executes this garbled circuit and\nreturns the resulting garbled outputs. Our system assures privacy of the mobile\nclient's data, even if the executing server chooses to collude with all but one\nof the other servers. We adapt the garbled circuit design of Beaver et al. and\nthe secure multiparty computation protocol of Goldreich et al. for the purpose\nof building a secure cloud computing for mobile systems. Our method\nincorporates the novel use of the cryptographically secure pseudo random number\ngenerator of Blum et al. that enables the mobile client to efficiently retrieve\nthe result of the computation, as well as to verify that the evaluator actually\nperformed the computation. We analyze the server-side and client-side\ncomplexity of our system. Using real-world data, we evaluate our system for a\nprivacy preserving search application that locates the nearest bank/ATM from\nthe mobile client. We also measure the time taken to construct and evaluate the\ngarbled circuit for varying number of servers, demonstrating the feasibility of\nour secure and verifiable cloud computing for mobile systems.\n", "contributors": [{"name": "Premnath, Sriram N.", "sameAs": [], "familyName": "Premnath", "additionalName": "N.", "givenName": "Sriram", "email": ""}, {"name": "Haas, Zygmunt J.", "sameAs": [], "familyName": "Haas", "additionalName": "J.", "givenName": "Zygmunt", "email": ""}], "title": "A Practical, Secure, and Verifiable Cloud Computing for Mobile Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1389", "oai:arXiv.org:1410.1389"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Cloud computing systems, in which clients rent and share computing resources\nof third party platforms, have gained widespread use in recent years.\nFurthermore, cloud computing for mobile systems (i.e., systems in which the\nclients are mobile devices) have too been receiving considerable attention in\ntechnical literature. We propose a new method of delegating computations of\nresource-constrained mobile clients, in which multiple servers interact to\nconstruct an encrypted program known as garbled circuit. Next, using garbled\ninputs from a mobile client, another server executes this garbled circuit and\nreturns the resulting garbled outputs. Our system assures privacy of the mobile\nclient's data, even if the executing server chooses to collude with all but one\nof the other servers. We adapt the garbled circuit design of Beaver et al. and\nthe secure multiparty computation protocol of Goldreich et al. for the purpose\nof building a secure cloud computing for mobile systems. Our method\nincorporates the novel use of the cryptographically secure pseudo random number\ngenerator of Blum et al. that enables the mobile client to efficiently retrieve\nthe result of the computation, as well as to verify that the evaluator actually\nperformed the computation. We analyze the server-side and client-side\ncomplexity of our system. Using real-world data, we evaluate our system for a\nprivacy preserving search application that locates the nearest bank/ATM from\nthe mobile client. We also measure the time taken to construct and evaluate the\ngarbled circuit for varying number of servers, demonstrating the feasibility of\nour secure and verifiable cloud computing for mobile systems.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1389"}}, {"publisher": {"name": ""}, "description": "  Mobile networks are vulnerable to signalling attacks and storms that are\ncaused by traffic patterns that overload the control plane, and differ from\ndistributed denial of service (DDoS) attacks in the Internet since they\ndirectly attack the control plane, and also reserve wireless bandwidth without\nactually using it. Such attacks can result from malware and mobile botnets, as\nwell as from poorly designed applications, and can cause service outages in 3G\nand 4G networks which have been experienced by mobile operators. Since the\nradio resource control (RRC) protocol in 3G and 4G networks is particularly\nsusceptible to such attacks, we analyze their effect with a mathematical model\nthat helps to predict the congestion that is caused by an attack. A detailed\nsimulation model of a mobile network is used to better understand the temporal\ndynamics of user behavior and signalling in the network and to show how RRC\nbased signalling attacks and storms cause significant problems in the control\nplane and the user plane of the network. Our analysis also serves to identify\nhow storms can be detected, and to propose how system parameters can be chosen\nto mitigate their effect.\n", "contributors": [{"name": "Gorbil, Gokce", "sameAs": [], "familyName": "Gorbil", "additionalName": "", "givenName": "Gokce", "email": ""}, {"name": "Abdelrahman, Omer H.", "sameAs": [], "familyName": "Abdelrahman", "additionalName": "H.", "givenName": "Omer", "email": ""}, {"name": "Pavloski, Mihajlo", "sameAs": [], "familyName": "Pavloski", "additionalName": "", "givenName": "Mihajlo", "email": ""}, {"name": "Gelenbe, Erol", "sameAs": [], "familyName": "Gelenbe", "additionalName": "", "givenName": "Erol", "email": ""}], "title": "Storms in Mobile Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1280", "oai:arXiv.org:1411.1280"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Mobile networks are vulnerable to signalling attacks and storms that are\ncaused by traffic patterns that overload the control plane, and differ from\ndistributed denial of service (DDoS) attacks in the Internet since they\ndirectly attack the control plane, and also reserve wireless bandwidth without\nactually using it. Such attacks can result from malware and mobile botnets, as\nwell as from poorly designed applications, and can cause service outages in 3G\nand 4G networks which have been experienced by mobile operators. Since the\nradio resource control (RRC) protocol in 3G and 4G networks is particularly\nsusceptible to such attacks, we analyze their effect with a mathematical model\nthat helps to predict the congestion that is caused by an attack. A detailed\nsimulation model of a mobile network is used to better understand the temporal\ndynamics of user behavior and signalling in the network and to show how RRC\nbased signalling attacks and storms cause significant problems in the control\nplane and the user plane of the network. Our analysis also serves to identify\nhow storms can be detected, and to propose how system parameters can be chosen\nto mitigate their effect.\n", "Comment: Submitted to the IEEE TETC special issue on \"Emerging topics in Cyber\n  Security\""]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1280"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose a novel low complexity scaling strategy of min-sum\ndecoding algorithm for irregular LDPC codes. In the proposed method, we\ngeneralize our previously proposed simplified Variable Scaled Min-Sum\n(SVS-min-sum) by replacing the sub-optimal starting value and heuristic update\nfor the scaling factor sequence by optimized values. Density evolution and\nNelder-Mead optimization are used offline, prior to the decoding, to obtain the\noptimal starting point and per iteration updating step size for the scaling\nfactor sequence of the proposed scaling strategy. The optimization of these\nparameters proves to be of noticeable positive impact on the decoding\nperformance. We used different DVB-T2 LDPC codes in our simulation. Simulation\nresults show the superior performance (in both WER and latency) of the proposed\nalgorithm to other Min-Sum based algorithms. In addition to that, generalized\nSVS-min-sum algorithm has very close performance to LLR-SPA with much lower\ncomplexity.\n", "contributors": [{"name": "Emran, Ahmed A.", "sameAs": [], "familyName": "Emran", "additionalName": "A.", "givenName": "Ahmed", "email": ""}, {"name": "Elsabrouty, Maha", "sameAs": [], "familyName": "Elsabrouty", "additionalName": "", "givenName": "Maha", "email": ""}], "title": "Generalized Simplified Variable-Scaled Min Sum LDPC decoder for\n  irregular LDPC Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.07336", "oai:arXiv.org:1501.07336"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this paper, we propose a novel low complexity scaling strategy of min-sum\ndecoding algorithm for irregular LDPC codes. In the proposed method, we\ngeneralize our previously proposed simplified Variable Scaled Min-Sum\n(SVS-min-sum) by replacing the sub-optimal starting value and heuristic update\nfor the scaling factor sequence by optimized values. Density evolution and\nNelder-Mead optimization are used offline, prior to the decoding, to obtain the\noptimal starting point and per iteration updating step size for the scaling\nfactor sequence of the proposed scaling strategy. The optimization of these\nparameters proves to be of noticeable positive impact on the decoding\nperformance. We used different DVB-T2 LDPC codes in our simulation. Simulation\nresults show the superior performance (in both WER and latency) of the proposed\nalgorithm to other Min-Sum based algorithms. In addition to that, generalized\nSVS-min-sum algorithm has very close performance to LLR-SPA with much lower\ncomplexity.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.07336"}}, {"publisher": {"name": ""}, "description": "  In this paper, we describe an algorithm for sensor network localization (SNL)\nthat proceeds by dividing the whole network into smaller subnetworks, then\nlocalizes them in parallel using some fast and accurate algorithm, and finally\nregisters the localized subnetworks in a global coordinate system. We\ndemonstrate that this divide-and-conquer algorithm can be used to leverage\nexisting high-precision SNL algorithms to large-scale networks, which could\notherwise only be applied to small-to-medium sized networks. The main\ncontribution of this paper concerns the final registration phase. In\nparticular, we consider a least-squares formulation of the registration problem\n(both with and without anchor constraints) and demonstrate how this otherwise\nnon-convex problem can be relaxed into a tractable convex program. We provide\nsome preliminary simulation results for large-scale SNL demonstrating that the\nproposed registration algorithm (together with an accurate localization scheme)\noffers a good tradeoff between run time and accuracy.\n", "contributors": [{"name": "Chaudhury, Kunal N.", "sameAs": [], "familyName": "Chaudhury", "additionalName": "N.", "givenName": "Kunal", "email": ""}, {"name": "Khoo, Yuehaw", "sameAs": [], "familyName": "Khoo", "additionalName": "", "givenName": "Yuehaw", "email": ""}, {"name": "Singer, Amit", "sameAs": [], "familyName": "Singer", "additionalName": "", "givenName": "Amit", "email": ""}], "title": "Large-Scale Sensor Network Localization via Rigid Subnetwork\n  Registration", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-29", "2015-01-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.8135", "oai:arXiv.org:1310.8135"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we describe an algorithm for sensor network localization (SNL)\nthat proceeds by dividing the whole network into smaller subnetworks, then\nlocalizes them in parallel using some fast and accurate algorithm, and finally\nregisters the localized subnetworks in a global coordinate system. We\ndemonstrate that this divide-and-conquer algorithm can be used to leverage\nexisting high-precision SNL algorithms to large-scale networks, which could\notherwise only be applied to small-to-medium sized networks. The main\ncontribution of this paper concerns the final registration phase. In\nparticular, we consider a least-squares formulation of the registration problem\n(both with and without anchor constraints) and demonstrate how this otherwise\nnon-convex problem can be relaxed into a tractable convex program. We provide\nsome preliminary simulation results for large-scale SNL demonstrating that the\nproposed registration algorithm (together with an accurate localization scheme)\noffers a good tradeoff between run time and accuracy.\n", "Comment: 5 pages, 8 figures, 1 table. To appear in Proc. IEEE International\n  Conference on Acoustics, Speech, and Signal Processing, April 19-24, 2015"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-01-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.8135"}}, {"publisher": {"name": ""}, "description": "  We compare tools for complementing nondeterministic B\\\"uchi automata with a\nrecent termination-analysis algorithm. Complementation of B\\\"uchi automata is a\nkey step in program verification. Early constructions using a Ramsey-based\nargument have been supplanted by rank-based constructions with exponentially\nbetter bounds. In 2001 Lee et al. presented the size-change termination (SCT)\nproblem, along with both a reduction to B\\\"uchi automata and a Ramsey-based\nalgorithm. The Ramsey-based algorithm was presented as a more practical\nalternative to the automata-theoretic approach, but strongly resembles the\ninitial complementation constructions for B\\\"uchi automata. We prove that the\nSCT algorithm is a specialized realization of the Ramsey-based complementation\nconstruction. To do so, we extend the Ramsey-based complementation construction\nto provide a containment-testing algorithm. Surprisingly, empirical analysis\nsuggests that despite the massive gap in worst-case complexity, Ramsey-based\napproaches are superior over the domain of SCT problems. Upon further analysis\nwe discover an interesting property of the problem space that both explains\nthis result and provides a chance to improve rank-based tools. With these\nimprovements, we show that theoretical gains in efficiency of the rank-based\napproach are mirrored in empirical performance.\n", "contributors": [{"name": "Fogarty, Seth", "sameAs": [], "familyName": "Fogarty", "additionalName": "", "givenName": "Seth", "email": ""}, {"name": "Vardi, Moshe Y.", "sameAs": [], "familyName": "Vardi", "additionalName": "Y.", "givenName": "Moshe", "email": ""}], "title": "B\\\"uchi Complementation and Size-Change Termination", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-10-27", "2012-02-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1110.6183", "LMCS 8 (1:13) 2012", "doi:10.2168/LMCS-8(1:13)2012", "oai:arXiv.org:1110.6183"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We compare tools for complementing nondeterministic B\\\"uchi automata with a\nrecent termination-analysis algorithm. Complementation of B\\\"uchi automata is a\nkey step in program verification. Early constructions using a Ramsey-based\nargument have been supplanted by rank-based constructions with exponentially\nbetter bounds. In 2001 Lee et al. presented the size-change termination (SCT)\nproblem, along with both a reduction to B\\\"uchi automata and a Ramsey-based\nalgorithm. The Ramsey-based algorithm was presented as a more practical\nalternative to the automata-theoretic approach, but strongly resembles the\ninitial complementation constructions for B\\\"uchi automata. We prove that the\nSCT algorithm is a specialized realization of the Ramsey-based complementation\nconstruction. To do so, we extend the Ramsey-based complementation construction\nto provide a containment-testing algorithm. Surprisingly, empirical analysis\nsuggests that despite the massive gap in worst-case complexity, Ramsey-based\napproaches are superior over the domain of SCT problems. Upon further analysis\nwe discover an interesting property of the problem space that both explains\nthis result and provides a chance to improve rank-based tools. With these\nimprovements, we show that theoretical gains in efficiency of the rank-based\napproach are mirrored in empirical performance.\n"}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "d.2.4"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1110.6183"}}, {"publisher": {"name": ""}, "description": "  We consider state and parameter estimation in multiple target tracking\nproblems with data association uncertainties and unknown number of targets. We\nshow how the problem can be recast into a conditionally linear Gaussian\nstate-space model with unknown parameters and present an algorithm for\ncomputationally efficient inference on the resulting model. The proposed\nalgorithm is based on combining the Rao-Blackwellized Monte Carlo data\nassociation algorithm with particle Markov chain Monte Carlo algorithms to\njointly estimate both parameters and data associations. Both particle marginal\nMetropolis-Hastings and particle Gibbs variants of particle MCMC are\nconsidered. We demonstrate the performance of the method both using simulated\ndata and in a real-data case study of using multiple target tracking to\nestimate the brown bear population in Finland.\n", "contributors": [{"name": "Kokkala, Juho", "sameAs": [], "familyName": "Kokkala", "additionalName": "", "givenName": "Juho", "email": ""}, {"name": "S\u00e4rkk\u00e4, Simo", "sameAs": [], "familyName": "S\u00e4rkk\u00e4", "additionalName": "", "givenName": "Simo", "email": ""}], "title": "Combining Particle MCMC with Rao-Blackwellized Monte Carlo Data\n  Association for Parameter Estimation in Multiple Target Tracking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-30", "2015-02-20"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.8502", "oai:arXiv.org:1409.8502"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "stat"]}}, {"name": "description", "properties": {"description": ["  We consider state and parameter estimation in multiple target tracking\nproblems with data association uncertainties and unknown number of targets. We\nshow how the problem can be recast into a conditionally linear Gaussian\nstate-space model with unknown parameters and present an algorithm for\ncomputationally efficient inference on the resulting model. The proposed\nalgorithm is based on combining the Rao-Blackwellized Monte Carlo data\nassociation algorithm with particle Markov chain Monte Carlo algorithms to\njointly estimate both parameters and data associations. Both particle marginal\nMetropolis-Hastings and particle Gibbs variants of particle MCMC are\nconsidered. We demonstrate the performance of the method both using simulated\ndata and in a real-data case study of using multiple target tracking to\nestimate the brown bear population in Finland.\n", "Comment: Revised version. 43 pages, 4 figures"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "statistics - applications", "statistics - methodology", "mathematics - dynamical systems", "statistics - computation"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.8502"}}, {"publisher": {"name": ""}, "description": "  Multiphase active contour based models are useful in identifying multiple\nregions with different characteristics such as the mean values of regions. This\nis relevant in brain magnetic resonance images (MRIs), allowing the\ndifferentiation of white matter against gray matter. We consider a well defined\nglobally convex formulation of Vese and Chan multiphase active contour model\nfor segmenting brain MRI images. A well-established theory and an efficient\ndual minimization scheme are thoroughly described which guarantees optimal\nsolutions and provides stable segmentations. Moreover, under the dual\nminimization implementation our model perfectly describes disjoint regions by\navoiding local minima solutions. Experimental results indicate that the\nproposed approach provides better accuracy than other related multiphase active\ncontour algorithms even under severe noise, intensity inhomogeneities, and\npartial volume effects.\n", "contributors": [{"name": "Moreno, Juan C.", "sameAs": [], "familyName": "Moreno", "additionalName": "C.", "givenName": "Juan", "email": ""}, {"name": "Prasath, V. B. S.", "sameAs": [], "familyName": "Prasath", "additionalName": "B. S.", "givenName": "V.", "email": ""}, {"name": "Proenca, Hugo", "sameAs": [], "familyName": "Proenca", "additionalName": "", "givenName": "Hugo", "email": ""}, {"name": "Palaniappan, K.", "sameAs": [], "familyName": "Palaniappan", "additionalName": "", "givenName": "K.", "email": ""}], "title": "Brain MRI Segmentation with Fast and Globally Convex Multiphase Active\n  Contours", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-08-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1308.6056", "Computer Vision and Image Understanding, 125, 237-250, 2014", "doi:10.1016/j.cviu.2014.04.010", "oai:arXiv.org:1308.6056"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Multiphase active contour based models are useful in identifying multiple\nregions with different characteristics such as the mean values of regions. This\nis relevant in brain magnetic resonance images (MRIs), allowing the\ndifferentiation of white matter against gray matter. We consider a well defined\nglobally convex formulation of Vese and Chan multiphase active contour model\nfor segmenting brain MRI images. A well-established theory and an efficient\ndual minimization scheme are thoroughly described which guarantees optimal\nsolutions and provides stable segmentations. Moreover, under the dual\nminimization implementation our model perfectly describes disjoint regions by\navoiding local minima solutions. Experimental results indicate that the\nproposed approach provides better accuracy than other related multiphase active\ncontour algorithms even under severe noise, intensity inhomogeneities, and\npartial volume effects.\n"}}], "languages": [null], "subjects": ["68u10", "i.4.6", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1308.6056"}}, {"publisher": {"name": ""}, "description": "  Let $k$ be a nonnegative integer. In the approximate $k$-flat nearest\nneighbor ($k$-ANN) problem, we are given a set $P \\subset \\mathbb{R}^d$ of $n$\npoints in $d$-dimensional space and a fixed approximation factor $c > 1$. Our\ngoal is to preprocess $P$ so that we can efficiently answer approximate\n$k$-flat nearest neighbor queries: given a $k$-flat $F$, find a point in $P$\nwhose distance to $F$ is within a factor $c$ of the distance between $F$ and\nthe closest point in $P$. The case $k = 0$ corresponds to the well-studied\napproximate nearest neighbor problem, for which a plethora of results are\nknown, both in low and high dimensions. The case $k = 1$ is called approximate\nline nearest neighbor. In this case, we are aware of only one provably\nefficient data structure, due to Andoni, Indyk, Krauthgamer, and Nguyen. For $k\n\\geq 2$, we know of no previous results.\n  We present the first efficient data structure that can handle approximate\nnearest neighbor queries for arbitrary $k$. We use a data structure for\n$0$-ANN-queries as a black box, and the performance depends on the parameters\nof the $0$-ANN solution: suppose we have an $0$-ANN structure with query time\n$O(n^{\\rho})$ and space requirement $O(n^{1+\\sigma})$, for $\\rho, \\sigma > 0$.\nThen we can answer $k$-ANN queries in time $O(n^{k/(k + 1 - \\rho) + t})$ and\nspace $O(n^{1+\\sigma k/(k + 1 - \\rho)} + n\\log^{O(1/t)} n)$. Here, $t > 0$ is\nan arbitrary constant and the $O$-notation hides exponential factors in $k$,\n$1/t$, and $c$ and polynomials in $d$. Our new data structures also give an\nimprovement in the space requirement over the previous result for $1$-ANN: we\ncan achieve near-linear space and sublinear query time, a further step towards\npractical applications where space constitutes the bottleneck.\n", "contributors": [{"name": "Mulzer, Wolfgang", "sameAs": [], "familyName": "Mulzer", "additionalName": "", "givenName": "Wolfgang", "email": ""}, {"name": "Nguyen, Huy L.", "sameAs": [], "familyName": "Nguyen", "additionalName": "L.", "givenName": "Huy", "email": ""}, {"name": "Seiferth, Paul", "sameAs": [], "familyName": "Seiferth", "additionalName": "", "givenName": "Paul", "email": ""}, {"name": "Stein, Yannik", "sameAs": [], "familyName": "Stein", "additionalName": "", "givenName": "Yannik", "email": ""}], "title": "Approximate k-flat Nearest Neighbor Search", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1519", "oai:arXiv.org:1411.1519"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Let $k$ be a nonnegative integer. In the approximate $k$-flat nearest\nneighbor ($k$-ANN) problem, we are given a set $P \\subset \\mathbb{R}^d$ of $n$\npoints in $d$-dimensional space and a fixed approximation factor $c > 1$. Our\ngoal is to preprocess $P$ so that we can efficiently answer approximate\n$k$-flat nearest neighbor queries: given a $k$-flat $F$, find a point in $P$\nwhose distance to $F$ is within a factor $c$ of the distance between $F$ and\nthe closest point in $P$. The case $k = 0$ corresponds to the well-studied\napproximate nearest neighbor problem, for which a plethora of results are\nknown, both in low and high dimensions. The case $k = 1$ is called approximate\nline nearest neighbor. In this case, we are aware of only one provably\nefficient data structure, due to Andoni, Indyk, Krauthgamer, and Nguyen. For $k\n\\geq 2$, we know of no previous results.\n  We present the first efficient data structure that can handle approximate\nnearest neighbor queries for arbitrary $k$. We use a data structure for\n$0$-ANN-queries as a black box, and the performance depends on the parameters\nof the $0$-ANN solution: suppose we have an $0$-ANN structure with query time\n$O(n^{\\rho})$ and space requirement $O(n^{1+\\sigma})$, for $\\rho, \\sigma > 0$.\nThen we can answer $k$-ANN queries in time $O(n^{k/(k + 1 - \\rho) + t})$ and\nspace $O(n^{1+\\sigma k/(k + 1 - \\rho)} + n\\log^{O(1/t)} n)$. Here, $t > 0$ is\nan arbitrary constant and the $O$-notation hides exponential factors in $k$,\n$1/t$, and $c$ and polynomials in $d$. Our new data structures also give an\nimprovement in the space requirement over the previous result for $1$-ANN: we\ncan achieve near-linear space and sublinear query time, a further step towards\npractical applications where space constitutes the bottleneck.\n", "Comment: 22 pages, 1 figure"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational geometry"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1519"}}, {"publisher": {"name": ""}, "description": "  Social networks help to bond people who share similar interests all over the\nworld. As a complement, the Facebook \"Like\" button is an efficient tool that\nbonds people with the online information. People click on the \"Like\" button to\nexpress their fondness of a particular piece of information and in turn tend to\nvisit webpages with high \"Like\" count. The important fact of the Like count is\nthat it reflects the number of actual users who \"liked\" this information.\nHowever, according to our study, one can easily exploit the defects of the\n\"Like\" button to counterfeit a high \"Like\" count. We provide a proof-of-concept\nimplementation of these exploits, and manage to generate 100 fake Likes in 5\nminutes with a single account. We also reveal existing counterfeiting\ntechniques used by some online sellers to achieve unfair advantage for\npromoting their products. To address this fake Like problem, we study the\nvarying patterns of Like count and propose an innovative fake Like detection\nmethod based on clustering. To evaluate the effectiveness of our algorithm, we\ncollect the Like count history of more than 9,000 websites. Our experiments\nsuccessfully uncover 16 suspicious fake Like buyers that show abnormal Like\ncount increase patterns.\n", "contributors": [{"name": "Lin, Xinye", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Xinye", "email": ""}, {"name": "Xia, Mingyuan", "sameAs": [], "familyName": "Xia", "additionalName": "", "givenName": "Mingyuan", "email": ""}, {"name": "Liu, Xue", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Xue", "email": ""}], "title": "Does \"Like\" Really Mean Like? A Study of the Facebook Fake Like\n  Phenomenon and an Efficient Countermeasure", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-18", "2015-03-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.05414", "oai:arXiv.org:1503.05414"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Social networks help to bond people who share similar interests all over the\nworld. As a complement, the Facebook \"Like\" button is an efficient tool that\nbonds people with the online information. People click on the \"Like\" button to\nexpress their fondness of a particular piece of information and in turn tend to\nvisit webpages with high \"Like\" count. The important fact of the Like count is\nthat it reflects the number of actual users who \"liked\" this information.\nHowever, according to our study, one can easily exploit the defects of the\n\"Like\" button to counterfeit a high \"Like\" count. We provide a proof-of-concept\nimplementation of these exploits, and manage to generate 100 fake Likes in 5\nminutes with a single account. We also reveal existing counterfeiting\ntechniques used by some online sellers to achieve unfair advantage for\npromoting their products. To address this fake Like problem, we study the\nvarying patterns of Like count and propose an innovative fake Like detection\nmethod based on clustering. To evaluate the effectiveness of our algorithm, we\ncollect the Like count history of more than 9,000 websites. Our experiments\nsuccessfully uncover 16 suspicious fake Like buyers that show abnormal Like\ncount increase patterns.\n", "Comment: 10 pages; updated the flaw details according to new Facebook API"]}}], "languages": [null], "subjects": ["k.4.1", "h.4", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.05414"}}, {"publisher": {"name": ""}, "description": "  Fires, lights at night and mobile phone activity have been separately used as\nproxy indicators of human activity with high potential for measuring human\ndevelopment. In this preliminary report, we develop some tools and\nmethodologies to identify and visualize relations among remote sensing datasets\ncontaining fires and night lights information with mobile phone activity in\nCote D'Ivoire from December 2011 to April 2012.\n", "contributors": [{"name": "Pastor-Escuredo, David", "sameAs": [], "familyName": "Pastor-Escuredo", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Savy, Thierry", "sameAs": [], "familyName": "Savy", "additionalName": "", "givenName": "Thierry", "email": ""}, {"name": "Luengo-Oroz, Miguel A.", "sameAs": [], "familyName": "Luengo-Oroz", "additionalName": "A.", "givenName": "Miguel", "email": ""}], "title": "Can Fires, Night Lights, and Mobile Phones reveal behavioral\n  fingerprints useful for Development?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00549", "oai:arXiv.org:1501.00549"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Fires, lights at night and mobile phone activity have been separately used as\nproxy indicators of human activity with high potential for measuring human\ndevelopment. In this preliminary report, we develop some tools and\nmethodologies to identify and visualize relations among remote sensing datasets\ncontaining fires and night lights information with mobile phone activity in\nCote D'Ivoire from December 2011 to April 2012.\n", "Comment: Published in D4D Challenge. NetMob, May 1-3, 2013, MIT"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00549"}}, {"publisher": {"name": ""}, "description": "  Sorting algorithms have attracted a great deal of attention and study, as\nthey have numerous applications to Mathematics, Computer Science and related\nfields. In this thesis, we first deal with the mathematical analysis of the\nQuicksort algorithm and its variants. Specifically, we study the time\ncomplexity of the algorithm and we provide a complete demonstration of the\nvariance of the number of comparisons required, a known result but one whose\ndetailed proof is not easy to read out of the literature. We also examine\nvariants of Quicksort, where multiple pivots are chosen for the partitioning of\nthe array.\n  The rest of this work is dedicated to the analysis of finding the true order\nby further pairwise comparisons when a partial order compatible with the true\norder is given in advance. We discuss a number of cases where the partially\nordered sets arise at random. To this end, we employ results from Graph and\nInformation Theory. Finally, we obtain an alternative bound on the number of\nlinear extensions when the partially ordered set arises from a random graph,\nand discuss the possible application of Shellsort in merging chains.\n", "contributors": [{"name": "Iliopoulos, Vasileios", "sameAs": [], "familyName": "Iliopoulos", "additionalName": "", "givenName": "Vasileios", "email": ""}], "title": "The Quicksort algorithm and related topics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-09", "2015-03-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02504", "oai:arXiv.org:1503.02504"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Sorting algorithms have attracted a great deal of attention and study, as\nthey have numerous applications to Mathematics, Computer Science and related\nfields. In this thesis, we first deal with the mathematical analysis of the\nQuicksort algorithm and its variants. Specifically, we study the time\ncomplexity of the algorithm and we provide a complete demonstration of the\nvariance of the number of comparisons required, a known result but one whose\ndetailed proof is not easy to read out of the literature. We also examine\nvariants of Quicksort, where multiple pivots are chosen for the partitioning of\nthe array.\n  The rest of this work is dedicated to the analysis of finding the true order\nby further pairwise comparisons when a partial order compatible with the true\norder is given in advance. We discuss a number of cases where the partially\nordered sets arise at random. To this end, we employ results from Graph and\nInformation Theory. Finally, we obtain an alternative bound on the number of\nlinear extensions when the partially ordered set arises from a random graph,\nand discuss the possible application of Shellsort in merging chains.\n", "Comment: PhD thesis. Reference [23] was missing in first version. It now reads\n  correctly in page 142, Section 5.6"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02504"}}, {"publisher": {"name": ""}, "description": "  In this work we propose a generalization of Winfree's abstract Tile Assembly\nModel (aTAM) in which tile types are assigned rigid shapes, or geometries,\nalong each tile face. We examine the number of distinct tile types needed to\nassemble shapes within this model, the temperature required for efficient\nassembly, and the problem of designing compact geometric faces to meet given\ncompatibility specifications. Our results show a dramatic decrease in the\nnumber of tile types needed to assemble $n \\times n$ squares to\n$\\Theta(\\sqrt{\\log n})$ at temperature 1 for the most simple model which meets\na lower bound from Kolmogorov complexity, and $O(\\log\\log n)$ in a model in\nwhich tile aggregates must move together through obstacle free paths within the\nplane. This stands in contrast to the $\\Theta(\\log n / \\log\\log n)$ tile types\nat temperature 2 needed in the basic aTAM. We also provide a general method for\nsimulating a large and computationally universal class of temperature 2 aTAM\nsystems with geometric tiles at temperature 1. Finally, we consider the problem\nof computing a set of compact geometric faces for a tile system to implement a\ngiven set of compatibility specifications. We show a number of bounds on the\ncomplexity of geometry size needed for various classes of compatibility\nspecifications, many of which we directly apply to our tile assembly results to\nachieve non-trivial reductions in geometry size.\n", "contributors": [{"name": "Fu, Bin", "sameAs": [], "familyName": "Fu", "additionalName": "", "givenName": "Bin", "email": ""}, {"name": "Patitz, Matthew J.", "sameAs": [], "familyName": "Patitz", "additionalName": "J.", "givenName": "Matthew", "email": ""}, {"name": "Schweller, Robert T.", "sameAs": [], "familyName": "Schweller", "additionalName": "T.", "givenName": "Robert", "email": ""}, {"name": "Sheline, Bobby", "sameAs": [], "familyName": "Sheline", "additionalName": "", "givenName": "Bobby", "email": ""}], "title": "Self-Assembly with Geometric Tiles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-04-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.2809", "oai:arXiv.org:1104.2809"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this work we propose a generalization of Winfree's abstract Tile Assembly\nModel (aTAM) in which tile types are assigned rigid shapes, or geometries,\nalong each tile face. We examine the number of distinct tile types needed to\nassemble shapes within this model, the temperature required for efficient\nassembly, and the problem of designing compact geometric faces to meet given\ncompatibility specifications. Our results show a dramatic decrease in the\nnumber of tile types needed to assemble $n \\times n$ squares to\n$\\Theta(\\sqrt{\\log n})$ at temperature 1 for the most simple model which meets\na lower bound from Kolmogorov complexity, and $O(\\log\\log n)$ in a model in\nwhich tile aggregates must move together through obstacle free paths within the\nplane. This stands in contrast to the $\\Theta(\\log n / \\log\\log n)$ tile types\nat temperature 2 needed in the basic aTAM. We also provide a general method for\nsimulating a large and computationally universal class of temperature 2 aTAM\nsystems with geometric tiles at temperature 1. Finally, we consider the problem\nof computing a set of compact geometric faces for a tile system to implement a\ngiven set of compatibility specifications. We show a number of bounds on the\ncomplexity of geometry size needed for various classes of compatibility\nspecifications, many of which we directly apply to our tile assembly results to\nachieve non-trivial reductions in geometry size.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity", "computer science - emerging technologies", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.2809"}}, {"publisher": {"name": ""}, "description": "  We undertake an extensive numerical investigation of the graph spectra of\nthousands regular graphs, a set of random Erd\\\"os-R\\'enyi graphs, the two most\npopular types of complex networks and an evolving genetic network by using\nnovel conceptual and experimental tools. Our objective in so doing is to\ncontribute to an understanding of the meaning of the Eigenvalues of a graph\nrelative to its topological and information-theoretic properties. We introduce\na technique for identifying the most informative Eigenvalues of evolving\nnetworks by comparing graph spectra behavior to their algorithmic complexity.\nWe suggest that extending techniques can be used to further investigate the\nbehavior of evolving biological networks. In the extended version of this paper\nwe apply these techniques to seven tissue specific regulatory networks as\nstatic example and network of a na\\\"ive pluripotent immune cell in the process\nof differentiating towards a Th17 cell as evolving example, finding the most\nand least informative Eigenvalues at every stage.\n", "contributors": [{"name": "Zenil, Hector", "sameAs": [], "familyName": "Zenil", "additionalName": "", "givenName": "Hector", "email": ""}, {"name": "Kiani, Narsis A.", "sameAs": [], "familyName": "Kiani", "additionalName": "A.", "givenName": "Narsis", "email": ""}, {"name": "Tegn\u00e9r, Jesper", "sameAs": [], "familyName": "Tegn\u00e9r", "additionalName": "", "givenName": "Jesper", "email": ""}], "title": "Numerical Investigation of Graph Spectra and Information\n  Interpretability of Eigenvalues", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06080", "oai:arXiv.org:1501.06080"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We undertake an extensive numerical investigation of the graph spectra of\nthousands regular graphs, a set of random Erd\\\"os-R\\'enyi graphs, the two most\npopular types of complex networks and an evolving genetic network by using\nnovel conceptual and experimental tools. Our objective in so doing is to\ncontribute to an understanding of the meaning of the Eigenvalues of a graph\nrelative to its topological and information-theoretic properties. We introduce\na technique for identifying the most informative Eigenvalues of evolving\nnetworks by comparing graph spectra behavior to their algorithmic complexity.\nWe suggest that extending techniques can be used to further investigate the\nbehavior of evolving biological networks. In the extended version of this paper\nwe apply these techniques to seven tissue specific regulatory networks as\nstatic example and network of a na\\\"ive pluripotent immune cell in the process\nof differentiating towards a Th17 cell as evolving example, finding the most\nand least informative Eigenvalues at every stage.\n", "Comment: Forthcoming in 3rd International Work-Conference on Bioinformatics\n  and Biomedical Engineering (IWBBIO), Lecture Notes in Bioinformatics, 2015"]}}], "languages": [null], "subjects": ["computer science - information theory", "mathematics - spectral theory", "mathematics - dynamical systems"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06080"}}, {"publisher": {"name": ""}, "description": "  We introduce the Xapagy cognitive architecture: a software system designed to\nperform narrative reasoning. The architecture has been designed from scratch to\nmodel and mimic the activities performed by humans when witnessing, reading,\nrecalling, narrating and talking about stories.\n", "contributors": [{"name": "B\u00f6l\u00f6ni, Ladislau", "sameAs": [], "familyName": "B\u00f6l\u00f6ni", "additionalName": "", "givenName": "Ladislau", "email": ""}], "title": "Xapagy: a cognitive architecture for narrative reasoning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.3486", "oai:arXiv.org:1105.3486"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We introduce the Xapagy cognitive architecture: a software system designed to\nperform narrative reasoning. The architecture has been designed from scratch to\nmodel and mimic the activities performed by humans when witnessing, reading,\nrecalling, narrating and talking about stories.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "i.2.0", "68t01"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.3486"}}, {"publisher": {"name": ""}, "description": "  Territorial subdivisions and geographic borders are essential for\nunderstanding phenomena in sociology, political science, history, and\neconomics. They influence the interregional flow of information and\ncross-border trade and affect the diffusion of innovation and technology.\nHowever, most existing administrative borders were determined by a variety of\nhistoric and political circumstances along with some degree of arbitrariness.\nSocieties have changed drastically, and it is doubtful that currently existing\nborders reflect the most logical divisions. Fortunately, at this point in\nhistory we are in a position to actually measure some aspects of the geographic\nstructure of society through human mobility. Large-scale transportation systems\nsuch as trains and airlines provide data about the number of people traveling\nbetween geographic locations, and many promising human mobility proxies are\nbeing discovered, such as cell phones, bank notes, and various online social\nnetworks. In this chapter we apply two optimization techniques to a human\nmobility proxy (bank note circulation) to investigate the effective geographic\nborders that emerge from a direct analysis of human mobility.\n", "contributors": [{"name": "Grady, Daniel", "sameAs": [], "familyName": "Grady", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Brune, Rafael", "sameAs": [], "familyName": "Brune", "additionalName": "", "givenName": "Rafael", "email": ""}, {"name": "Thiemann, Christian", "sameAs": [], "familyName": "Thiemann", "additionalName": "", "givenName": "Christian", "email": ""}, {"name": "Theis, Fabian", "sameAs": [], "familyName": "Theis", "additionalName": "", "givenName": "Fabian", "email": ""}, {"name": "Brockmann, Dirk", "sameAs": [], "familyName": "Brockmann", "additionalName": "", "givenName": "Dirk", "email": ""}], "title": "Modularity maximization and tree clustering: Novel ways to determine\n  effective geographic borders", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.1200", "oai:arXiv.org:1104.1200"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Territorial subdivisions and geographic borders are essential for\nunderstanding phenomena in sociology, political science, history, and\neconomics. They influence the interregional flow of information and\ncross-border trade and affect the diffusion of innovation and technology.\nHowever, most existing administrative borders were determined by a variety of\nhistoric and political circumstances along with some degree of arbitrariness.\nSocieties have changed drastically, and it is doubtful that currently existing\nborders reflect the most logical divisions. Fortunately, at this point in\nhistory we are in a position to actually measure some aspects of the geographic\nstructure of society through human mobility. Large-scale transportation systems\nsuch as trains and airlines provide data about the number of people traveling\nbetween geographic locations, and many promising human mobility proxies are\nbeing discovered, such as cell phones, bank notes, and various online social\nnetworks. In this chapter we apply two optimization techniques to a human\nmobility proxy (bank note circulation) to investigate the effective geographic\nborders that emerge from a direct analysis of human mobility.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.1200"}}, {"publisher": {"name": ""}, "description": "  Recent years have witnessed significant interest in convex relaxations of the\npower flows, several papers showing that the second-order cone relaxation is\ntight for tree networks under various conditions on loads or voltages. This\npaper shows that AC-feasibility, i.e., to find whether some generator dispatch\ncan satisfy a given demand, is NP-Hard for tree networks.\n", "contributors": [{"name": "Lehmann, Karsten", "sameAs": [], "familyName": "Lehmann", "additionalName": "", "givenName": "Karsten", "email": ""}, {"name": "Grastien, Alban", "sameAs": [], "familyName": "Grastien", "additionalName": "", "givenName": "Alban", "email": ""}, {"name": "Van Hentenryck, Pascal", "sameAs": [], "familyName": "Van Hentenryck", "additionalName": "", "givenName": "Pascal", "email": ""}], "title": "AC-Feasibility on Tree Networks is NP-Hard", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.8253", "oai:arXiv.org:1410.8253"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Recent years have witnessed significant interest in convex relaxations of the\npower flows, several papers showing that the second-order cone relaxation is\ntight for tree networks under various conditions on loads or voltages. This\npaper shows that AC-feasibility, i.e., to find whether some generator dispatch\ncan satisfy a given demand, is NP-Hard for tree networks.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - computational complexity"], "providerUpdatedDateTime": "2014-10-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.8253"}}, {"publisher": {"name": ""}, "description": "  Exact synthesis is a tool used in algorithms for approximating an arbitrary\nqubit unitary with a sequence of quantum gates from some finite set. These\napproximation algorithms find asymptotically optimal approximations in\nprobabilistic polynomial time, in some cases even finding the optimal solution\nin probabilistic polynomial time given access to an oracle for factoring\nintegers. In this paper, we present a common mathematical structure underlying\nall results related to the exact synthesis of qubit unitaries known to date,\nincluding Clifford+T, Clifford-cyclotomic and V-basis gate sets, as well as\ngates sets induced by the braiding of Fibonacci anyons in topological quantum\ncomputing. The framework presented here also provides a means to answer\nquestions related to the exact synthesis of unitaries for wide classes of other\ngate sets, such as Clifford+T+V and SU(2) level k anyons.\n", "contributors": [{"name": "Kliuchnikov, Vadym", "sameAs": [], "familyName": "Kliuchnikov", "additionalName": "", "givenName": "Vadym", "email": ""}, {"name": "Yard, Jon", "sameAs": [], "familyName": "Yard", "additionalName": "", "givenName": "Jon", "email": ""}], "title": "A framework for exact synthesis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.04350", "oai:arXiv.org:1504.04350"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": ["  Exact synthesis is a tool used in algorithms for approximating an arbitrary\nqubit unitary with a sequence of quantum gates from some finite set. These\napproximation algorithms find asymptotically optimal approximations in\nprobabilistic polynomial time, in some cases even finding the optimal solution\nin probabilistic polynomial time given access to an oracle for factoring\nintegers. In this paper, we present a common mathematical structure underlying\nall results related to the exact synthesis of qubit unitaries known to date,\nincluding Clifford+T, Clifford-cyclotomic and V-basis gate sets, as well as\ngates sets induced by the braiding of Fibonacci anyons in topological quantum\ncomputing. The framework presented here also provides a means to answer\nquestions related to the exact synthesis of unitaries for wide classes of other\ngate sets, such as Clifford+T+V and SU(2) level k anyons.\n", "Comment: 40 pages, preliminary version"]}}], "languages": [null], "subjects": ["quantum physics", "computer science - emerging technologies"], "providerUpdatedDateTime": "2015-04-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.04350"}}, {"publisher": {"name": ""}, "description": "  The three standard products (the Cartesian, the direct and the strong\nproduct) of undirected graphs have been wellinvestigated, unique prime factor\ndecomposition (PFD) are known and polynomial time algorithms have been\nestablished for determining the prime factors.\n  For directed graphs, unique PFD results with respect to the standard products\nare known. However, there is still a lack of algorithms, that computes the PFD\nof directed graphs with respect to the direct and the strong product in\ngeneral. In this contribution, we focus on the algorithmic aspects for\ndetermining the PFD of directed graphs with respect to the strong product.\nEssential for computing the prime factors is the construction of a so-called\nCartesian skeleton. This article introduces the notion of the Cartesian\nskeleton of directed graphs as a generalization of the Cartesian skeleton of\nundirected graphs. We provide new, fast and transparent algorithms for its\nconstruction. Moreover, we present a first polynomial time algorithm for\ndetermining the PFD with respect to the strong product of arbitrary connected\ndigraphs.\n", "contributors": [{"name": "Hellmuth, Marc", "sameAs": [], "familyName": "Hellmuth", "additionalName": "", "givenName": "Marc", "email": ""}, {"name": "Marc, Tilen", "sameAs": [], "familyName": "Marc", "additionalName": "", "givenName": "Tilen", "email": ""}], "title": "On the Cartesian Skeleton and the Factorization of the Strong Product of\n  Digraphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-01-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1401.4965", "doi:10.1016/j.tcs.2014.10.045", "oai:arXiv.org:1401.4965"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  The three standard products (the Cartesian, the direct and the strong\nproduct) of undirected graphs have been wellinvestigated, unique prime factor\ndecomposition (PFD) are known and polynomial time algorithms have been\nestablished for determining the prime factors.\n  For directed graphs, unique PFD results with respect to the standard products\nare known. However, there is still a lack of algorithms, that computes the PFD\nof directed graphs with respect to the direct and the strong product in\ngeneral. In this contribution, we focus on the algorithmic aspects for\ndetermining the PFD of directed graphs with respect to the strong product.\nEssential for computing the prime factors is the construction of a so-called\nCartesian skeleton. This article introduces the notion of the Cartesian\nskeleton of directed graphs as a generalization of the Cartesian skeleton of\nundirected graphs. We provide new, fast and transparent algorithms for its\nconstruction. Moreover, we present a first polynomial time algorithm for\ndetermining the PFD with respect to the strong product of arbitrary connected\ndigraphs.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1401.4965"}}, {"publisher": {"name": ""}, "description": "  This article surveys work done in the last six years on the unification of\nvarious functional interpretations including G\\\"odel's dialectica\ninterpretation, its Diller-Nahm variant, Kreisel modified realizability,\nStein's family of functional interpretations, functional interpretations \"with\ntruth\", and bounded functional interpretations. Our goal in the present paper\nis twofold: (1) to look back and single out the main lessons learnt so far, and\n(2) to look forward and list several open questions and possible directions for\nfurther research.\n", "contributors": [{"name": "Oliva, Paulo", "sameAs": [], "familyName": "Oliva", "additionalName": "", "givenName": "Paulo", "email": ""}], "title": "Unifying Functional Interpretations: Past and Future", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4364", "oai:arXiv.org:1410.4364"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This article surveys work done in the last six years on the unification of\nvarious functional interpretations including G\\\"odel's dialectica\ninterpretation, its Diller-Nahm variant, Kreisel modified realizability,\nStein's family of functional interpretations, functional interpretations \"with\ntruth\", and bounded functional interpretations. Our goal in the present paper\nis twofold: (1) to look back and single out the main lessons learnt so far, and\n(2) to look forward and list several open questions and possible directions for\nfurther research.\n", "Comment: 18 pages"]}}], "languages": [null], "subjects": ["mathematics - logic", "computer science - logic in computer science", "03b47", "03f25"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4364"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Can we model the temporal evolution of topics in Web image collections? If so, can we exploit the understanding of dynamics to solve novel visual problems or improve recognition performance? These two challenging questions are the motivation for this work. We propose a nonparametric approach to modeling and analysis of topical evolution in image sets. A scalable and parallelizable sequential Monte Carlo based method is developed to construct the similarity network of a large-scale dataset that provides a base representation for wide ranges of dynamics analysis. In this paper, we provide several experimental results to support the usefulness of image dynamics with the datasets of 47 topics gathered from Flickr. First, we produce some interesting observations such as tracking of subtopic evolution and outbreak detection, which cannot be achieved with conventional image sets. Second, we also present the complementary benefits that the images can introduce over the associated text analysis. Finally, we show that the training using the temporal association significantly improves the recognition performance.", "contributors": [{"name": "Kim, Gunhee", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Gunhee", "email": ""}, {"name": "Xing, Eric P.", "sameAs": [], "familyName": "Xing", "additionalName": "P.", "givenName": "Eric", "email": ""}, {"name": "Torralba, Antonio", "sameAs": [], "familyName": "Torralba", "additionalName": "", "givenName": "Antonio", "email": ""}], "title": "Modeling and Analysis of Dynamic Behaviors of Web Image Collections", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2010-09-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/239", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1235&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1235"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Can we model the temporal evolution of topics in Web image collections? If so, can we exploit the understanding of dynamics to solve novel visual problems or improve recognition performance? These two challenging questions are the motivation for this work. We propose a nonparametric approach to modeling and analysis of topical evolution in image sets. A scalable and parallelizable sequential Monte Carlo based method is developed to construct the similarity network of a large-scale dataset that provides a base representation for wide ranges of dynamics analysis. In this paper, we provide several experimental results to support the usefulness of image dynamics with the datasets of 47 topics gathered from Flickr. First, we produce some interesting observations such as tracking of subtopic evolution and outbreak detection, which cannot be achieved with conventional image sets. Second, we also present the complementary benefits that the images can introduce over the associated text analysis. Finally, we show that the training using the temporal association significantly improves the recognition performance."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-04-13T21:30:13", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/239"}}, {"publisher": {"name": ""}, "description": "  Suppose $(X,\\omega)$ is a compact K\\\"ahler manifold. Following Mabuchi, the\nspace of smooth K\\\"ahler potentials $\\mathcal H$ can be endowed with a\nRiemannian structure, which induces an infinite dimensional path length metric\nspace $(\\mathcal H,d)$. We prove that the metric completion of $(\\mathcal H,d)$\ncan be identified with $(\\mathcal E^2(X,\\omega),\\tilde d)$, and this latter\nspace is a complete non-positively curved geodesic metric space. In obtaining\nthis result, we will rely on envelope techniques which allow for a treatment in\na very general context. Profiting from this, we will characterize the pairs of\npotentials in $\\text{PSH}(X,\\omega)$ that can be connected by weak geodesics\nand we will also give a characterization of $\\mathcal E(X,\\omega)$ in this\ncontext.\n", "contributors": [{"name": "Darvas, Tam\u00e1s", "sameAs": [], "familyName": "Darvas", "additionalName": "", "givenName": "Tam\u00e1s", "email": ""}], "title": "The Mabuchi Completion of the Space of K\\\"ahler Potentials", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-01-28", "2015-03-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1401.7318", "oai:arXiv.org:1401.7318"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Suppose $(X,\\omega)$ is a compact K\\\"ahler manifold. Following Mabuchi, the\nspace of smooth K\\\"ahler potentials $\\mathcal H$ can be endowed with a\nRiemannian structure, which induces an infinite dimensional path length metric\nspace $(\\mathcal H,d)$. We prove that the metric completion of $(\\mathcal H,d)$\ncan be identified with $(\\mathcal E^2(X,\\omega),\\tilde d)$, and this latter\nspace is a complete non-positively curved geodesic metric space. In obtaining\nthis result, we will rely on envelope techniques which allow for a treatment in\na very general context. Profiting from this, we will characterize the pairs of\npotentials in $\\text{PSH}(X,\\omega)$ that can be connected by weak geodesics\nand we will also give a characterization of $\\mathcal E(X,\\omega)$ in this\ncontext.\n", "Comment: v3 New title and new introduction. No other changes"]}}], "languages": [null], "subjects": ["mathematics - differential geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1401.7318"}}, {"publisher": {"name": ""}, "description": "  The ability to recognize the liquid surface and the liquid level in\ntransparent containers is perhaps the most commonly used evaluation method when\ndealing with fluids. Such recognition is essential in determining the liquid\nvolume, fill level, phase boundaries and phase separation in various fluid\nsystems. The recognition of liquid surfaces is particularly important in\nsolution chemistry, where it is essential to many laboratory techniques (e.g.,\nextraction, distillation, titration). A general method for the recognition of\ninterfaces between liquid and air or between phase-separating liquids could\nhave a wide range of applications and contribute to the understanding of the\nvisual properties of such interfaces. This work examines a computer vision\nmethod for the recognition of liquid surfaces and liquid levels in various\ntransparent containers. The method can be applied to recognition of both\nliquid-air and liquid-liquid surfaces. No prior knowledge of the number of\nphases is required. The method receives the image of the liquid container and\nthe boundaries of the container in the image and scans all possible curves that\ncould correspond to the outlines of liquid surfaces in the image. The method\nthen compares each curve to the image to rate its correspondence with the\noutline of the real liquid surface by examining various image properties in the\narea surrounding each point of the curve. The image properties that were found\nto give the best indication of the liquid surface are the relative intensity\nchange, the edge density change and the gradient direction relative to the\ncurve normal.\n", "contributors": [{"name": "Eppel, Sagi", "sameAs": [], "familyName": "Eppel", "additionalName": "", "givenName": "Sagi", "email": ""}, {"name": "Kachman, Tal", "sameAs": [], "familyName": "Kachman", "additionalName": "", "givenName": "Tal", "email": ""}], "title": "Computer vision-based recognition of liquid surfaces and phase\n  boundaries in transparent vessels, with emphasis on chemistry applications", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-28", "2014-11-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.7174", "oai:arXiv.org:1404.7174"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The ability to recognize the liquid surface and the liquid level in\ntransparent containers is perhaps the most commonly used evaluation method when\ndealing with fluids. Such recognition is essential in determining the liquid\nvolume, fill level, phase boundaries and phase separation in various fluid\nsystems. The recognition of liquid surfaces is particularly important in\nsolution chemistry, where it is essential to many laboratory techniques (e.g.,\nextraction, distillation, titration). A general method for the recognition of\ninterfaces between liquid and air or between phase-separating liquids could\nhave a wide range of applications and contribute to the understanding of the\nvisual properties of such interfaces. This work examines a computer vision\nmethod for the recognition of liquid surfaces and liquid levels in various\ntransparent containers. The method can be applied to recognition of both\nliquid-air and liquid-liquid surfaces. No prior knowledge of the number of\nphases is required. The method receives the image of the liquid container and\nthe boundaries of the container in the image and scans all possible curves that\ncould correspond to the outlines of liquid surfaces in the image. The method\nthen compares each curve to the image to rate its correspondence with the\noutline of the real liquid surface by examining various image properties in the\narea surrounding each point of the curve. The image properties that were found\nto give the best indication of the liquid surface are the relative intensity\nchange, the edge density change and the gradient direction relative to the\ncurve normal.\n", "Comment: Source code for phase boundary and liquid surface recognition\n  available at:\n  http://www.mathworks.com/matlabcentral/fileexchange/46893-computer-vision-based-recognition-of-liquid-surface-and-liquid-level-of-liquid-of-transparent-vessel"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.7174"}}, {"publisher": {"name": ""}, "description": "  I examine the topic of training scientific generalists. To focus the\ndiscussion, I propose the creation of a new graduate program, analogous in\nstructure to existing MD/PhD programs, aimed at training a critical mass of\nscientific researchers with substantial intellectual breadth. In addition to\ncompleting the normal requirements for a PhD, students would undergo an\nintense, several year training period designed to expose them to the core\nvocabulary of multiple subjects at the graduate level. After providing some\nhistorical and philosophical context for this proposal, I outline how such a\nprogram could be implemented with little institutional overhead by existing\nresearch universities. Finally, I discuss alternative possibilities for\ntraining generalists by taking advantage of contemporary developments in online\nlearning and open science.\n", "contributors": [{"name": "Sarma, Gopal", "sameAs": [], "familyName": "Sarma", "additionalName": "", "givenName": "Gopal", "email": ""}], "title": "Should we train scientific generalists?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4422", "oai:arXiv.org:1410.4422"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  I examine the topic of training scientific generalists. To focus the\ndiscussion, I propose the creation of a new graduate program, analogous in\nstructure to existing MD/PhD programs, aimed at training a critical mass of\nscientific researchers with substantial intellectual breadth. In addition to\ncompleting the normal requirements for a PhD, students would undergo an\nintense, several year training period designed to expose them to the core\nvocabulary of multiple subjects at the graduate level. After providing some\nhistorical and philosophical context for this proposal, I outline how such a\nprogram could be implemented with little institutional overhead by existing\nresearch universities. Finally, I discuss alternative possibilities for\ntraining generalists by taking advantage of contemporary developments in online\nlearning and open science.\n", "Comment: 8 pages"]}}], "languages": [null], "subjects": ["computer science - computers and society", "physics - physics education"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4422"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose and study a new semi-random model for graph\npartitioning problems. We believe that it captures many properties of\nreal--world instances. The model is more flexible than the semi-random model of\nFeige and Kilian and planted random model of Bui, Chaudhuri, Leighton and\nSipser.\n  We develop a general framework for solving semi-random instances and apply it\nto several problems of interest. We present constant factor bi-criteria\napproximation algorithms for semi-random instances of the Balanced Cut,\nMulticut, Min Uncut, Sparsest Cut and Small Set Expansion problems. We also\nshow how to almost recover the optimal solution if the instance satisfies an\nadditional expanding condition. Our algorithms work in a wider range of\nparameters than most algorithms for previously studied random and semi-random\nmodels.\n  Additionally, we study a new planted algebraic expander model and develop\nconstant factor bi-criteria approximation algorithms for graph partitioning\nproblems in this model.\n", "contributors": [{"name": "Makarychev, Konstantin", "sameAs": [], "familyName": "Makarychev", "additionalName": "", "givenName": "Konstantin", "email": ""}, {"name": "Makarychev, Yury", "sameAs": [], "familyName": "Makarychev", "additionalName": "", "givenName": "Yury", "email": ""}, {"name": "Vijayaraghavan, Aravindan", "sameAs": [], "familyName": "Vijayaraghavan", "additionalName": "", "givenName": "Aravindan", "email": ""}], "title": "Approximation Algorithms for Semi-random Graph Partitioning Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-05-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.2234", "oai:arXiv.org:1205.2234"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we propose and study a new semi-random model for graph\npartitioning problems. We believe that it captures many properties of\nreal--world instances. The model is more flexible than the semi-random model of\nFeige and Kilian and planted random model of Bui, Chaudhuri, Leighton and\nSipser.\n  We develop a general framework for solving semi-random instances and apply it\nto several problems of interest. We present constant factor bi-criteria\napproximation algorithms for semi-random instances of the Balanced Cut,\nMulticut, Min Uncut, Sparsest Cut and Small Set Expansion problems. We also\nshow how to almost recover the optimal solution if the instance satisfies an\nadditional expanding condition. Our algorithms work in a wider range of\nparameters than most algorithms for previously studied random and semi-random\nmodels.\n  Additionally, we study a new planted algebraic expander model and develop\nconstant factor bi-criteria approximation algorithms for graph partitioning\nproblems in this model.\n", "Comment: To appear at the 44th ACM Symposium on Theory of Computing (STOC\n  2012)"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.2234"}}, {"publisher": {"name": ""}, "description": "  We propose a method called Fast and Realistic Attacker Modeling and\nEvaluation (FRAME) that can reduce pessimism in static noise analysis by\nexploiting temporal logical correlation of attackers and using novel techniques\ntermed envelopes and $\\sigma$ functions. Unlike conventional pruning-based\napproaches, FRAME efficiently considers all relevant attackers, thereby\nproducing more realistic results. FRAME was tested with complex industrial\ndesign and successfully reduced the pessimism of conventional techniques by\n30.4% on average, with little computational overhead.\n", "contributors": [{"name": "Yoon, Sungroh", "sameAs": [], "familyName": "Yoon", "additionalName": "", "givenName": "Sungroh", "email": ""}, {"name": "Oh, Nahmsuk", "sameAs": [], "familyName": "Oh", "additionalName": "", "givenName": "Nahmsuk", "email": ""}, {"name": "Tehrani, Peivand", "sameAs": [], "familyName": "Tehrani", "additionalName": "", "givenName": "Peivand", "email": ""}, {"name": "Chung, Eui-Young", "sameAs": [], "familyName": "Chung", "additionalName": "", "givenName": "Eui-Young", "email": ""}, {"name": "De Micheli, Giovanni", "sameAs": [], "familyName": "De Micheli", "additionalName": "", "givenName": "Giovanni", "email": ""}], "title": "FRAME: Fast and Realistic Attacker Modeling and Evaluation for Temporal\n  Logical Correlation in Static Noise", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02236", "oai:arXiv.org:1502.02236"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We propose a method called Fast and Realistic Attacker Modeling and\nEvaluation (FRAME) that can reduce pessimism in static noise analysis by\nexploiting temporal logical correlation of attackers and using novel techniques\ntermed envelopes and $\\sigma$ functions. Unlike conventional pruning-based\napproaches, FRAME efficiently considers all relevant attackers, thereby\nproducing more realistic results. FRAME was tested with complex industrial\ndesign and successfully reduced the pessimism of conventional techniques by\n30.4% on average, with little computational overhead.\n"}}], "languages": [null], "subjects": ["computer science - other computer science", "b.7.2"], "providerUpdatedDateTime": "2015-02-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02236"}}, {"publisher": {"name": ""}, "description": "  The structure of the network underlying many complex systems, whether\nartificial or natural, plays a significant role in how these systems operate.\nAs a result, much emphasis has been placed on accurately describing networks\nusing network theoretic metrics. When it comes to generating networks with\nsimilar properties, however, the set of available techniques and properties\nthat can be controlled for remains limited. Further, whilst it is becoming\nclear that some of the metrics currently used to control the generation of such\nnetworks are not very prescriptive so that networks could potentially exhibit\nvery different higher-order structure within those constraints, network\ngenerating algorithms typically produce fairly contrived networks and lack\nmechanisms by which to systematically explore the space of network solutions.\nIn this paper, we explore the potential of a multi-objective novelty-biased GA\nto provide a viable alternative to these algorithms. We believe our results\nprovide the first proof of principle that (i) it is possible to use GAs to\ngenerate graphs satisfying set levels of key classical graph theoretic\nproperties and (ii) it is possible to generate diverse solutions within these\nconstraints. The paper is only a preliminary step, however, and we identify key\navenues for further development.\n", "contributors": [{"name": "Overbury, Peter", "sameAs": [], "familyName": "Overbury", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Berthouze, Luc", "sameAs": [], "familyName": "Berthouze", "additionalName": "", "givenName": "Luc", "email": ""}], "title": "Using novelty-biased GA to sample diversity in graphs satisfying\n  constraints", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06342", "oai:arXiv.org:1503.06342"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The structure of the network underlying many complex systems, whether\nartificial or natural, plays a significant role in how these systems operate.\nAs a result, much emphasis has been placed on accurately describing networks\nusing network theoretic metrics. When it comes to generating networks with\nsimilar properties, however, the set of available techniques and properties\nthat can be controlled for remains limited. Further, whilst it is becoming\nclear that some of the metrics currently used to control the generation of such\nnetworks are not very prescriptive so that networks could potentially exhibit\nvery different higher-order structure within those constraints, network\ngenerating algorithms typically produce fairly contrived networks and lack\nmechanisms by which to systematically explore the space of network solutions.\nIn this paper, we explore the potential of a multi-objective novelty-biased GA\nto provide a viable alternative to these algorithms. We believe our results\nprovide the first proof of principle that (i) it is possible to use GAs to\ngenerate graphs satisfying set levels of key classical graph theoretic\nproperties and (ii) it is possible to generate diverse solutions within these\nconstraints. The paper is only a preliminary step, however, and we identify key\navenues for further development.\n", "Comment: Extended version of a short paper accepted for publication in\n  Proceedings of Genetic and Evolutionary Computation Conference (GECCO'15)"]}}], "languages": [null], "subjects": ["g.2.2", "05c85", "90b15", "computer science - social and information networks", "physics - physics and society", "68r10", "computer science - neural and evolutionary computing", "mathematics - combinatorics", "90c35"], "providerUpdatedDateTime": "2015-03-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06342"}}, {"publisher": {"name": ""}, "description": "  Quantum computation, in particular Grover's algorithm, has aroused a great\ndeal of interest since it allows for a quadratic speedup to be obtained in\nsearch procedures. Classical search procedures for an $N$ element database\nrequire at most $O(N)$ time complexity. Grover's algorithm is able to find a\nsolution with high probability in $O(\\sqrt{N})$ time through an amplitude\namplification scheme. In this work we draw elements from both classical and\nquantum computation to develop an alternative search proposal based on quantum\nentanglement detection schemes. In 2002, Horodecki and Ekert proposed an\nefficient method for direct detection of quantum entanglement. Our proposition\nto quantum search combines quantum entanglement detection alongside\nentanglement inducing operators. Grover's quantum search relies on measuring a\nquantum superposition after having applied a unitary evolution. We deviate from\nthe standard method by focusing on fine-tuning a unitary operator in order to\ninfer the solution with certainty. Our proposal sacrifices space for speed and\ndepends on the mathematical properties of linear positive maps $\\Lambda$ which\nhave not been operationally characterized. Whether such a $\\Lambda$ can be\neasily determined remains an open question.\n", "contributors": [{"name": "Tarrataca, Lu\u00eds", "sameAs": [], "familyName": "Tarrataca", "additionalName": "", "givenName": "Lu\u00eds", "email": ""}, {"name": "Wichert, Andreas", "sameAs": [], "familyName": "Wichert", "additionalName": "", "givenName": "Andreas", "email": ""}], "title": "Can Quantum Entanglement Detection Schemes Improve Search?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01959", "Quantum Information Processing, 2012, 11:1, 55-66", "doi:10.1007/s11128-011-0231-4", "oai:arXiv.org:1502.01959"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": "  Quantum computation, in particular Grover's algorithm, has aroused a great\ndeal of interest since it allows for a quadratic speedup to be obtained in\nsearch procedures. Classical search procedures for an $N$ element database\nrequire at most $O(N)$ time complexity. Grover's algorithm is able to find a\nsolution with high probability in $O(\\sqrt{N})$ time through an amplitude\namplification scheme. In this work we draw elements from both classical and\nquantum computation to develop an alternative search proposal based on quantum\nentanglement detection schemes. In 2002, Horodecki and Ekert proposed an\nefficient method for direct detection of quantum entanglement. Our proposition\nto quantum search combines quantum entanglement detection alongside\nentanglement inducing operators. Grover's quantum search relies on measuring a\nquantum superposition after having applied a unitary evolution. We deviate from\nthe standard method by focusing on fine-tuning a unitary operator in order to\ninfer the solution with certainty. Our proposal sacrifices space for speed and\ndepends on the mathematical properties of linear positive maps $\\Lambda$ which\nhave not been operationally characterized. Whether such a $\\Lambda$ can be\neasily determined remains an open question.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "quantum physics"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01959"}}, {"publisher": {"name": ""}, "description": "  A pure geometric description of the Kobayashi balls of C-convex domains is\ngiven in terms of the so-called minimal basis.\n", "contributors": [{"name": "Nikolov, Nikolai", "sameAs": [], "familyName": "Nikolov", "additionalName": "", "givenName": "Nikolai", "email": ""}, {"name": "Trybula, Maria", "sameAs": [], "familyName": "Trybula", "additionalName": "", "givenName": "Maria", "email": ""}], "title": "The Kobayashi balls of C-convex domains", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-25", "2014-05-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.6481", "doi:10.1007/s00605-015-0746-3", "oai:arXiv.org:1404.6481"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  A pure geometric description of the Kobayashi balls of C-convex domains is\ngiven in terms of the so-called minimal basis.\n", "Comment: v2: Proposition 3 (iii) is improved - the Lempert function is\n  replaced by the Kobayashi metric"]}}], "languages": [null], "subjects": ["32f45", "32f17", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.6481"}}, {"publisher": {"name": ""}, "description": "  We analyze tensors in the tensor product of three m-dimensional vector spaces\nsatisfying Strassen's equations for border rank m. Results include: two purely\ngeometric characterizations of the Coppersmith-Winograd tensor, a reduction to\nthe study of symmetric tensors under a mild genericity hypothesis, and numerous\nadditional equations and examples. This study is closely connected to the study\nof the variety of m-dimensional abelian subspaces of the space of endomorphisms\nof an m-dimensional vector space, and the subvariety consisting of the Zariski\nclosure of the variety of maximal tori, called the variety of reductions.\n", "contributors": [{"name": "Landsberg, J. M.", "sameAs": [], "familyName": "Landsberg", "additionalName": "M.", "givenName": "J.", "email": ""}, {"name": "Micha\u0142ek, Mateusz", "sameAs": [], "familyName": "Micha\u0142ek", "additionalName": "", "givenName": "Mateusz", "email": ""}], "title": "Abelian Tensors", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03732", "oai:arXiv.org:1504.03732"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We analyze tensors in the tensor product of three m-dimensional vector spaces\nsatisfying Strassen's equations for border rank m. Results include: two purely\ngeometric characterizations of the Coppersmith-Winograd tensor, a reduction to\nthe study of symmetric tensors under a mild genericity hypothesis, and numerous\nadditional equations and examples. This study is closely connected to the study\nof the variety of m-dimensional abelian subspaces of the space of endomorphisms\nof an m-dimensional vector space, and the subvariety consisting of the Zariski\nclosure of the variety of maximal tori, called the variety of reductions.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "15a69", "14n05", "15a21", "68q17", "mathematics - algebraic geometry"], "providerUpdatedDateTime": "2015-04-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03732"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose a new method for detecting unauthorized network\nintrusions, based on a traffic flow model and Cisco NetFlow protocol\napplication. The method developed allows us not only to detect the most common\ntypes of network attack (DDoS and port scanning), but also to make a list of\ntrespassers' IP-addresses. Therefore, this method can be applied in intrusion\ndetection systems, and in those systems which lock these IP-addresses.\n", "contributors": [{"name": "Galtsev, Aleksey A.", "sameAs": [], "familyName": "Galtsev", "additionalName": "A.", "givenName": "Aleksey", "email": ""}, {"name": "Sukhov, Andrei M.", "sameAs": [], "familyName": "Sukhov", "additionalName": "M.", "givenName": "Andrei", "email": ""}], "title": "Network attack detection at flow level", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.1010", "oai:arXiv.org:1104.1010"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we propose a new method for detecting unauthorized network\nintrusions, based on a traffic flow model and Cisco NetFlow protocol\napplication. The method developed allows us not only to detect the most common\ntypes of network attack (DDoS and port scanning), but also to make a list of\ntrespassers' IP-addresses. Therefore, this method can be applied in intrusion\ndetection systems, and in those systems which lock these IP-addresses.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.1010"}}, {"publisher": {"name": ""}, "description": "  Operational semantics has established itself as a flexible but rigorous means\nto describe the meaning of programming languages. Oftentimes, it is felt\nnecessary to keep a semantics small, for example to facilitate its use for\nmodel checking by avoiding state space explosion. However, omitting many\ndetails in a semantics typically makes results valid for a limited core\nlanguage only, leaving a wide gap towards any real implementation. In this\npaper we present a full-fledged semantics of the concurrent object-oriented\nprogramming language SCOOP (Simple Concurrent Object-Oriented Programming). The\nsemantics has been found detailed enough to guide an implementation of the\nSCOOP compiler and runtime system, and to detect and correct a variety of\nerrors and ambiguities in the original informal specification and prototype\nimplementation. In our formal specification, we use abstract data types with\npreconditions and axioms to describe the state, and introduce a number of\nspecial run-time operations to model the runtime system with our inference\nrules. This approach allows us to make our large formal specification\nmanageable, providing a first step towards reference documents for specifying\nobject-oriented languages based on operational semantics.\n", "contributors": [{"name": "Morandi, Benjamin", "sameAs": [], "familyName": "Morandi", "additionalName": "", "givenName": "Benjamin", "email": ""}, {"name": "Nanz, Sebastian", "sameAs": [], "familyName": "Nanz", "additionalName": "", "givenName": "Sebastian", "email": ""}, {"name": "Meyer, Bertrand", "sameAs": [], "familyName": "Meyer", "additionalName": "", "givenName": "Bertrand", "email": ""}], "title": "A comprehensive operational semantics of the SCOOP programming model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-05", "2012-04-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.1038", "oai:arXiv.org:1101.1038"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Operational semantics has established itself as a flexible but rigorous means\nto describe the meaning of programming languages. Oftentimes, it is felt\nnecessary to keep a semantics small, for example to facilitate its use for\nmodel checking by avoiding state space explosion. However, omitting many\ndetails in a semantics typically makes results valid for a limited core\nlanguage only, leaving a wide gap towards any real implementation. In this\npaper we present a full-fledged semantics of the concurrent object-oriented\nprogramming language SCOOP (Simple Concurrent Object-Oriented Programming). The\nsemantics has been found detailed enough to guide an implementation of the\nSCOOP compiler and runtime system, and to detect and correct a variety of\nerrors and ambiguities in the original informal specification and prototype\nimplementation. In our formal specification, we use abstract data types with\npreconditions and axioms to describe the state, and introduce a number of\nspecial run-time operations to model the runtime system with our inference\nrules. This approach allows us to make our large formal specification\nmanageable, providing a first step towards reference documents for specifying\nobject-oriented languages based on operational semantics.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "computer science - programming languages", "f.3.2", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.1038"}}, {"publisher": {"name": ""}, "description": "  The outage probability performance of a dual-hop amplify-and-forward\nselective relaying system with global relay selection is analyzed for\nNakagami-$m$ fading channels in the presence of multiple interferers at both\nthe relays and the destination. Two different cases are considered. In the\nfirst case, the interferers are assumed to have random number and locations.\nOutage probability using the generalized Gamma approximation (GGA) in the form\nof one-dimensional integral is derived. In the second case, the interferers are\nassumed to have fixed number and locations. Exact outage probability in the\nform of one-dimensional integral is derived. For both cases, closed-form\nexpressions of lower bounds and asymptotic expressions for high\nsignal-to-interference-plus-noise ratio are also provided. Simplified\nclosed-form expressions of outage probability for special cases (e.g., dominant\ninterferences, i.i.d. interferers, Rayleigh distributed signals) are studied.\nNumerical results are presented to show the accuracy of our analysis by\nexamining the effects of the number and locations of interferers on the outage\nperformances of both AF systems with random and fixed interferers.\n", "contributors": [{"name": "Wang, Kezhi", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Kezhi", "email": ""}, {"name": "Chen, Yunfei", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Yunfei", "email": ""}, {"name": "Di Renzo, Marco", "sameAs": [], "familyName": "Di Renzo", "additionalName": "", "givenName": "Marco", "email": ""}], "title": "Outage Probability of Dual-Hop Selective AF With Randomly Distributed\n  and Fixed Interferers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1074", "oai:arXiv.org:1410.1074"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The outage probability performance of a dual-hop amplify-and-forward\nselective relaying system with global relay selection is analyzed for\nNakagami-$m$ fading channels in the presence of multiple interferers at both\nthe relays and the destination. Two different cases are considered. In the\nfirst case, the interferers are assumed to have random number and locations.\nOutage probability using the generalized Gamma approximation (GGA) in the form\nof one-dimensional integral is derived. In the second case, the interferers are\nassumed to have fixed number and locations. Exact outage probability in the\nform of one-dimensional integral is derived. For both cases, closed-form\nexpressions of lower bounds and asymptotic expressions for high\nsignal-to-interference-plus-noise ratio are also provided. Simplified\nclosed-form expressions of outage probability for special cases (e.g., dominant\ninterferences, i.i.d. interferers, Rayleigh distributed signals) are studied.\nNumerical results are presented to show the accuracy of our analysis by\nexamining the effects of the number and locations of interferers on the outage\nperformances of both AF systems with random and fixed interferers.\n", "Comment: 35 pages, 11 figures, accepted with minor revisions for publication\n  as a regular paper in the IEEE Transactions on Vehicular Technology on\n  21/09/2014"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1074"}}, {"publisher": {"name": "BMJ Publishing Group"}, "description": "", "contributors": [{"name": "Mo, Qian", "sameAs": [], "familyName": "Mo", "additionalName": "", "givenName": "Qian", "email": ""}, {"name": "Wang, Yang", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yang", "email": ""}, {"name": "Ye, Yongming", "sameAs": [], "familyName": "Ye", "additionalName": "", "givenName": "Yongming", "email": ""}, {"name": "Yu, Jinna", "sameAs": [], "familyName": "Yu", "additionalName": "", "givenName": "Jinna", "email": ""}, {"name": "Liu, Zhishun", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Zhishun", "email": ""}], "title": "Acupuncture for adults with overactive bladder: a systematic review protocol", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["complementary medicine"], "providerUpdatedDateTime": "2015-01-16T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4289716"}}, {"publisher": {"name": ""}, "description": "  We examine the characteristic features of reversible and quantum computations\nin the presence of supplementary external information, known as advice. In\nparticular, we present a simple, algebraic characterization of languages\nrecognized by one-way reversible finite automata augmented with deterministic\nadvice. With a further elaborate argument, we prove a similar but slightly\nweaker result for bounded-error one-way quantum finite automata with advice.\nImmediate applications of those properties lead to containments and separations\namong various language families when they are assisted by appropriately chosen\nadvice. We further demonstrate the power and limitation of randomized advice\nand quantum advice when they are given to one-way quantum finite automata.\n", "contributors": [{"name": "Yamakami, Tomoyuki", "sameAs": [], "familyName": "Yamakami", "additionalName": "", "givenName": "Tomoyuki", "email": ""}], "title": "One-Way Reversible and Quantum Finite Automata with Advice", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-08-30", "2014-10-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1208.6092", "oai:arXiv.org:1208.6092"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": ["  We examine the characteristic features of reversible and quantum computations\nin the presence of supplementary external information, known as advice. In\nparticular, we present a simple, algebraic characterization of languages\nrecognized by one-way reversible finite automata augmented with deterministic\nadvice. With a further elaborate argument, we prove a similar but slightly\nweaker result for bounded-error one-way quantum finite automata with advice.\nImmediate applications of those properties lead to containments and separations\namong various language families when they are assisted by appropriately chosen\nadvice. We further demonstrate the power and limitation of randomized advice\nand quantum advice when they are given to one-way quantum finite automata.\n", "Comment: A4, 10pt, 1 figure, 31 pages. This is a complete version of an\n  extended abstract appeared in the Proceedings of the 6th International\n  Conference on Language and Automata Theory and Applications (LATA 2012),\n  March 5-9, 2012, A Coruna, Spain, Lecture Notes in Computer Science,\n  Springer-Verlag, Vol.7183, pp.526-537, 2012"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "quantum physics", "computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2014-10-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1208.6092"}}, {"publisher": {"name": ""}, "description": "  We study convergence properties of pseudo-marginal Markov chain Monte Carlo\nalgorithms (Andrieu and Roberts [Ann. Statist. 37 (2009) 697-725]). We find\nthat the asymptotic variance of the pseudo-marginal algorithm is always at\nleast as large as that of the marginal algorithm. We show that if the marginal\nchain admits a (right) spectral gap and the weights (normalised estimates of\nthe target density) are uniformly bounded, then the pseudo-marginal chain has a\nspectral gap. In many cases, a similar result holds for the absolute spectral\ngap, which is equivalent to geometric ergodicity. We consider also unbounded\nweight distributions and recover polynomial convergence rates in more specific\ncases, when the marginal algorithm is uniformly ergodic or an independent\nMetropolis-Hastings or a random-walk Metropolis targeting a super-exponential\ndensity with regular contours. Our results on geometric and polynomial\nconvergence rates imply central limit theorems. We also prove that under\ngeneral conditions, the asymptotic variance of the pseudo-marginal algorithm\nconverges to the asymptotic variance of the marginal algorithm if the accuracy\nof the estimators is increased.\n", "contributors": [{"name": "Andrieu, Christophe", "sameAs": [], "familyName": "Andrieu", "additionalName": "", "givenName": "Christophe", "email": ""}, {"name": "Vihola, Matti", "sameAs": [], "familyName": "Vihola", "additionalName": "", "givenName": "Matti", "email": ""}], "title": "Convergence properties of pseudo-marginal Markov chain Monte Carlo\n  algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-10-04", "2015-03-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1210.1484", "Annals of Applied Probability 2015, Vol. 25, No. 2, 1030-1077", "doi:10.1214/14-AAP1022", "oai:arXiv.org:1210.1484"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "stat"]}}, {"name": "description", "properties": {"description": ["  We study convergence properties of pseudo-marginal Markov chain Monte Carlo\nalgorithms (Andrieu and Roberts [Ann. Statist. 37 (2009) 697-725]). We find\nthat the asymptotic variance of the pseudo-marginal algorithm is always at\nleast as large as that of the marginal algorithm. We show that if the marginal\nchain admits a (right) spectral gap and the weights (normalised estimates of\nthe target density) are uniformly bounded, then the pseudo-marginal chain has a\nspectral gap. In many cases, a similar result holds for the absolute spectral\ngap, which is equivalent to geometric ergodicity. We consider also unbounded\nweight distributions and recover polynomial convergence rates in more specific\ncases, when the marginal algorithm is uniformly ergodic or an independent\nMetropolis-Hastings or a random-walk Metropolis targeting a super-exponential\ndensity with regular contours. Our results on geometric and polynomial\nconvergence rates imply central limit theorems. We also prove that under\ngeneral conditions, the asymptotic variance of the pseudo-marginal algorithm\nconverges to the asymptotic variance of the marginal algorithm if the accuracy\nof the estimators is increased.\n", "Comment: Published at http://dx.doi.org/10.1214/14-AAP1022 in the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)"]}}], "languages": [null], "subjects": ["statistics - computation", "mathematics - probability"], "providerUpdatedDateTime": "2015-03-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1210.1484"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "The American daytime serial drama is among the oldest television genres and remains a vital part of the television lineup for ABC and CBS as what this thesis calls an immersive story world. However, many within the television industry are now predicting that the genre will fade into obscurity after two decades of declining ratings. This study outlines how the soap opera industry is and could be further adapting to the technological and social changes of a convergence culture to maintain and revitalize the genre's relevance for viewers and advertisers alike. CBS/Procter and Gamble Productions/TeleVest's As the World Turns will serve as a case study for these changes. This project examines how the existing fan base plays an active role in gaining and maintaining new fans by researching historical and contemporary examples of social relationships that fans form with other fans and the show itself. In addition to looking at how these fan communities operate, this thesis focuses on how soap operas have adapted and might adapt to alternate revenue models such as product placement, capitalize on their vast content archives, and tell stories through multiple media formats. The study concludes that soap operas should be managed as brands and not ephemeral television content because of their permanence in the television landscape, that fans outside the target advertising demographic should be empowered as proselytizers for the show, and that a transgenerational storytelling approach best utilizes the power of the genre to tell its stories.", "contributors": [{"name": "Ford, Samuel Earl", "sameAs": [], "familyName": "Ford", "additionalName": "Earl", "givenName": "Samuel", "email": ""}, {"name": "Massachusetts Institute of Technology. Dept. of Comparative Media Studies.", "sameAs": [], "familyName": "Studies.", "additionalName": "Institute of Technology. Dept. of Comparative Media", "givenName": "Massachusetts", "email": ""}, {"name": "William Charles Uricchio.", "sameAs": [], "familyName": "Uricchio.", "additionalName": "Charles", "givenName": "William", "email": ""}], "title": "As the world turns in a convergence culture", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "176 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/39223", "166228334", "oai:dspace.mit.edu:1721.1/39223"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2007-10-19T21:05:08Z", "2007-10-19T21:05:08Z", "2007", "2007"]}}, {"name": "description", "properties": {"description": ["The American daytime serial drama is among the oldest television genres and remains a vital part of the television lineup for ABC and CBS as what this thesis calls an immersive story world. However, many within the television industry are now predicting that the genre will fade into obscurity after two decades of declining ratings. This study outlines how the soap opera industry is and could be further adapting to the technological and social changes of a convergence culture to maintain and revitalize the genre's relevance for viewers and advertisers alike. CBS/Procter and Gamble Productions/TeleVest's As the World Turns will serve as a case study for these changes. This project examines how the existing fan base plays an active role in gaining and maintaining new fans by researching historical and contemporary examples of social relationships that fans form with other fans and the show itself. In addition to looking at how these fan communities operate, this thesis focuses on how soap operas have adapted and might adapt to alternate revenue models such as product placement, capitalize on their vast content archives, and tell stories through multiple media formats. The study concludes that soap operas should be managed as brands and not ephemeral television content because of their permanence in the television landscape, that fans outside the target advertising demographic should be empowered as proselytizers for the show, and that a transgenerational storytelling approach best utilizes the power of the genre to tell its stories.", "by Samuel Earl Ford.", "Thesis (S.M.)--Massachusetts Institute of Technology, Dept. of Comparative Media Studies, 2007.", "This electronic version was submitted by the student author.  The certified thesis is available in the Institute Archives and Special Collections.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39100", "hdl_1721.1_39097"]}}], "languages": [null], "subjects": ["comparative media studies.", "as the world turns (television program)"], "providerUpdatedDateTime": "2015-04-27T14:44:36", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/39223"}}, {"publisher": {"name": ""}, "description": "  This paper presents a probabilistic omnidirectional millimeter-wave path loss\nmodel based on real-world 28 GHz and 73 GHz measurements collected in New York\nCity. The probabilistic path loss approach uses a free space line-of-sight\npropagation model, and for non-line-of-sight conditions uses either a close-in\nfree space reference distance path loss model or a floating-intercept path loss\nmodel. The probabilistic model employs a weighting function that specifies the\nline-of-sight probability for a given transmitter-receiver separation distance.\nResults show that the probabilistic path loss model offers virtually identical\nresults whether one uses a non-line-of-sight close-in free space reference\ndistance path loss model, with a reference distance of 1 meter, or a\nfloating-intercept path loss model. This letter also shows that site-specific\nenvironmental information may be used to yield the probabilistic weighting\nfunction for choosing between line-of-sight and non-line-of-sight conditions.\n", "contributors": [{"name": "Samimi, Mathew K.", "sameAs": [], "familyName": "Samimi", "additionalName": "K.", "givenName": "Mathew", "email": ""}, {"name": "Rappaport, Theodore S.", "sameAs": [], "familyName": "Rappaport", "additionalName": "S.", "givenName": "Theodore", "email": ""}, {"name": "MacCartney Jr, George R.", "sameAs": [], "familyName": "MacCartney", "additionalName": "R.", "givenName": "George", "email": ""}], "title": "Probabilistic Omnidirectional Path Loss Models for Millimeter-Wave\n  Outdoor Communications", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-25", "2015-03-31"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07612", "oai:arXiv.org:1503.07612"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper presents a probabilistic omnidirectional millimeter-wave path loss\nmodel based on real-world 28 GHz and 73 GHz measurements collected in New York\nCity. The probabilistic path loss approach uses a free space line-of-sight\npropagation model, and for non-line-of-sight conditions uses either a close-in\nfree space reference distance path loss model or a floating-intercept path loss\nmodel. The probabilistic model employs a weighting function that specifies the\nline-of-sight probability for a given transmitter-receiver separation distance.\nResults show that the probabilistic path loss model offers virtually identical\nresults whether one uses a non-line-of-sight close-in free space reference\ndistance path loss model, with a reference distance of 1 meter, or a\nfloating-intercept path loss model. This letter also shows that site-specific\nenvironmental information may be used to yield the probabilistic weighting\nfunction for choosing between line-of-sight and non-line-of-sight conditions.\n", "Comment: 4 pages, 4 figures, IEEE Wireless Communications Letters (March 2015)"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07612"}}, {"publisher": {"name": ""}, "description": "  The advance in RF energy transfer and harvesting technique over the past\ndecade has enabled wireless energy replenishment for electronic devices, which\nis deemed as a promising alternative to address the energy bottleneck of\nconventional battery-powered devices. In this paper, by using a stochastic\ngeometry approach, we aim to analyze the performance of an RF-powered wireless\nsensor in a downlink simultaneous wireless information and power transfer\n(SWIPT) system with ambient RF transmitters. Specifically, we consider the\npoint-to-point downlink SWIPT transmission from an access point to a wireless\nsensor in a network, where ambient RF transmitters are distributed as a Ginibre\n?$\\alpha$-determinantal point process (DPP), which becomes the Poisson point\nprocess when $\\alpha$? approaches zero. In the considered network, we focus on\nanalyzing the performance of a sensor equipped with the power-splitting\narchitecture. Under this architecture, we characterize the expected RF energy\nharvesting rate of the sensor. Moreover, we derive the upper bound of both\npower and transmission outage probabilities. Numerical results show that our\nupper bounds are accurate for different value of ?$\\alpha$.\n", "contributors": [{"name": "Lu, Xiao", "sameAs": [], "familyName": "Lu", "additionalName": "", "givenName": "Xiao", "email": ""}, {"name": "Flint, Ian", "sameAs": [], "familyName": "Flint", "additionalName": "", "givenName": "Ian", "email": ""}, {"name": "Niyato, Dusit", "sameAs": [], "familyName": "Niyato", "additionalName": "", "givenName": "Dusit", "email": ""}, {"name": "Privault, Nicolas", "sameAs": [], "familyName": "Privault", "additionalName": "", "givenName": "Nicolas", "email": ""}, {"name": "Wang, Ping", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Ping", "email": ""}], "title": "Performance Analysis of Simultaneous Wireless Information and Power\n  Transfer with Ambient RF Energy Harvesting", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00683", "oai:arXiv.org:1501.00683"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The advance in RF energy transfer and harvesting technique over the past\ndecade has enabled wireless energy replenishment for electronic devices, which\nis deemed as a promising alternative to address the energy bottleneck of\nconventional battery-powered devices. In this paper, by using a stochastic\ngeometry approach, we aim to analyze the performance of an RF-powered wireless\nsensor in a downlink simultaneous wireless information and power transfer\n(SWIPT) system with ambient RF transmitters. Specifically, we consider the\npoint-to-point downlink SWIPT transmission from an access point to a wireless\nsensor in a network, where ambient RF transmitters are distributed as a Ginibre\n?$\\alpha$-determinantal point process (DPP), which becomes the Poisson point\nprocess when $\\alpha$? approaches zero. In the considered network, we focus on\nanalyzing the performance of a sensor equipped with the power-splitting\narchitecture. Under this architecture, we characterize the expected RF energy\nharvesting rate of the sensor. Moreover, we derive the upper bound of both\npower and transmission outage probabilities. Numerical results show that our\nupper bounds are accurate for different value of ?$\\alpha$.\n", "Comment: IEEE Wireless Communications and Networking Conference"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00683"}}, {"publisher": {"name": ""}, "description": "  In this paper, we present a framework for resource allocations for multicast\ndevice-to-device (D2D) communications underlaying a cellular network. The\nobjective is to maximize the sum throughput of active cellular users (CUs) and\nfeasible D2D groups in a cell, while meeting a certain\nsignal-to-interferenceplus- noise ratio (SINR) constraint for both the CUs and\nD2D groups. We formulate the problem of power and channel allocation as a mixed\ninteger nonlinear programming (MINLP) problem where one D2D group can reuse the\nchannels of multiple CUs and the channel of each CU can be reused by multiple\nD2D groups. Distinct from existing approaches in the literature, our\nformulation and solution methods provide an effective and flexible means to\nutilize radio resources in cellular networks and share them with multicast\ngroups without causing harmful interference to each other. A variant of the\ngeneralized bender decomposition (GBD) is applied to optimally solve the MINLP\nproblem. A greedy algorithm and a low-complexity heuristic solution are then\ndevised. The performance of all schemes is evaluated through extensive\nsimulations. Numerical results demonstrate that the proposed greedy algorithm\ncan achieve closeto- optimal performance, and the heuristic algorithm provides\ngood performance, though inferior than that of the greedy, with much lower\ncomplexity.\n", "contributors": [{"name": "Meshgi, Hadi", "sameAs": [], "familyName": "Meshgi", "additionalName": "", "givenName": "Hadi", "email": ""}, {"name": "Zhao, Dongmei", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Dongmei", "email": ""}, {"name": "Zheng, Rong", "sameAs": [], "familyName": "Zheng", "additionalName": "", "givenName": "Rong", "email": ""}], "title": "Optimal Resource Allocation in Multicast Device-to-Device Communications\n  Underlaying LTE Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03576", "oai:arXiv.org:1503.03576"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we present a framework for resource allocations for multicast\ndevice-to-device (D2D) communications underlaying a cellular network. The\nobjective is to maximize the sum throughput of active cellular users (CUs) and\nfeasible D2D groups in a cell, while meeting a certain\nsignal-to-interferenceplus- noise ratio (SINR) constraint for both the CUs and\nD2D groups. We formulate the problem of power and channel allocation as a mixed\ninteger nonlinear programming (MINLP) problem where one D2D group can reuse the\nchannels of multiple CUs and the channel of each CU can be reused by multiple\nD2D groups. Distinct from existing approaches in the literature, our\nformulation and solution methods provide an effective and flexible means to\nutilize radio resources in cellular networks and share them with multicast\ngroups without causing harmful interference to each other. A variant of the\ngeneralized bender decomposition (GBD) is applied to optimally solve the MINLP\nproblem. A greedy algorithm and a low-complexity heuristic solution are then\ndevised. The performance of all schemes is evaluated through extensive\nsimulations. Numerical results demonstrate that the proposed greedy algorithm\ncan achieve closeto- optimal performance, and the heuristic algorithm provides\ngood performance, though inferior than that of the greedy, with much lower\ncomplexity.\n", "Comment: 29 pages"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03576"}}, {"publisher": {"name": ""}, "description": "  We propose a new coding scheme for the discrete memoryless two-user\nmulti-access channel (MAC) with rate-limited feedback. Our scheme combines\nideas from the Venkataramanan-Pradhan scheme for perfect feedback with ideas\nfrom the Shaviv-Steinberg scheme for rate-limited feedback.\n  Our achievable region includes the Shaviv-Steinberg achievable region and\nthis inclusion can be strict. For general MACs and for sufficiently large\nfeedback rates, our scheme outperforms the Shaviv-Steinberg scheme as it\nachieves the same rate region as the Venkataramanan-Pradhan scheme for perfect\nfeedback (which cannot be achieved by the Shaviv-Steinberg scheme).\nFurthermore, we numerically evaluate our achievable region with a specific\n(Gaussian) choice of random variables for the memoryless two-user Gaussian MAC.\nOur simulation results show that for some parameters of the Gaussian MAC and\nthe feedback rate, our scheme achieves a strictly larger sum-rate than the\nShaviv-Steinberg scheme.\n", "contributors": [{"name": "Amor, Selma Belhadj", "sameAs": [], "familyName": "Amor", "additionalName": "Belhadj", "givenName": "Selma", "email": ""}], "title": "A New Coding Scheme for Discrete Memoryless MACs with Common\n  Rate-Limited Feedback", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03266", "oai:arXiv.org:1503.03266"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We propose a new coding scheme for the discrete memoryless two-user\nmulti-access channel (MAC) with rate-limited feedback. Our scheme combines\nideas from the Venkataramanan-Pradhan scheme for perfect feedback with ideas\nfrom the Shaviv-Steinberg scheme for rate-limited feedback.\n  Our achievable region includes the Shaviv-Steinberg achievable region and\nthis inclusion can be strict. For general MACs and for sufficiently large\nfeedback rates, our scheme outperforms the Shaviv-Steinberg scheme as it\nachieves the same rate region as the Venkataramanan-Pradhan scheme for perfect\nfeedback (which cannot be achieved by the Shaviv-Steinberg scheme).\nFurthermore, we numerically evaluate our achievable region with a specific\n(Gaussian) choice of random variables for the memoryless two-user Gaussian MAC.\nOur simulation results show that for some parameters of the Gaussian MAC and\nthe feedback rate, our scheme achieves a strictly larger sum-rate than the\nShaviv-Steinberg scheme.\n", "Comment: 5 pages, 1 figure, submitted to the European Conference on Networks\n  and Communications 2015 (EuCNC'2015), Paris, France"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03266"}}, {"publisher": {"name": ""}, "description": "  In this paper, we present two symbiotic optimizations to optimize recursive\ntask parallel (RTP) programs by reducing the task creation and termination\noverheads. Our first optimization Aggressive Finish-Elimination (AFE) helps\nreduce the redundant join operations to a large extent. The second optimization\nDynamic Load-Balanced loop Chunking (DLBC) extends the prior work on loop\nchunking to decide on the number of parallel tasks based on the number of\navailable worker threads, at runtime. Further, we discuss the impact of\nexceptions on our optimizations and extend them to handle RTP programs that may\nthrow exceptions. We implemented DCAFE (= DLBC+AFE) in the X10v2.3 compiler and\ntested it over a set of benchmark kernels on two different hardwares (a 16-core\nIntel system and a 64-core AMD system). With respect to the base X10 compiler\nextended with loop-chunking of Nandivada et al [Nandivada et\nal.(2013)Nandivada, Shirako, Zhao, and Sarkar](LC), DCAFE achieved a geometric\nmean speed up of 5.75x and 4.16x on the Intel and AMD system, respectively. We\nalso present an evaluation with respect to the energy consumption on the Intel\nsystem and show that on average, compared to the LC versions, the DCAFE\nversions consume 71.2% less energy.\n", "contributors": [{"name": "Gupta, Suyash", "sameAs": [], "familyName": "Gupta", "additionalName": "", "givenName": "Suyash", "email": ""}, {"name": "Shrivastava, Rahul", "sameAs": [], "familyName": "Shrivastava", "additionalName": "", "givenName": "Rahul", "email": ""}, {"name": "Nandivada, V. Krishna", "sameAs": [], "familyName": "Nandivada", "additionalName": "Krishna", "givenName": "V.", "email": ""}], "title": "DCAFE: Dynamic load-balanced loop Chunking & Aggressive Finish\n  Elimination for Recursive Task Parallel Programs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06086", "oai:arXiv.org:1502.06086"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we present two symbiotic optimizations to optimize recursive\ntask parallel (RTP) programs by reducing the task creation and termination\noverheads. Our first optimization Aggressive Finish-Elimination (AFE) helps\nreduce the redundant join operations to a large extent. The second optimization\nDynamic Load-Balanced loop Chunking (DLBC) extends the prior work on loop\nchunking to decide on the number of parallel tasks based on the number of\navailable worker threads, at runtime. Further, we discuss the impact of\nexceptions on our optimizations and extend them to handle RTP programs that may\nthrow exceptions. We implemented DCAFE (= DLBC+AFE) in the X10v2.3 compiler and\ntested it over a set of benchmark kernels on two different hardwares (a 16-core\nIntel system and a 64-core AMD system). With respect to the base X10 compiler\nextended with loop-chunking of Nandivada et al [Nandivada et\nal.(2013)Nandivada, Shirako, Zhao, and Sarkar](LC), DCAFE achieved a geometric\nmean speed up of 5.75x and 4.16x on the Intel and AMD system, respectively. We\nalso present an evaluation with respect to the energy consumption on the Intel\nsystem and show that on average, compared to the LC versions, the DCAFE\nversions consume 71.2% less energy.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06086"}}, {"publisher": {"name": ""}, "description": "  We assume a full-duplex (FD) cooperative network subject to hostile attacks\nand undergoing composite fading channels. We focus on two scenarios:\n\\textit{a)} the transmitter has full CSI, for which we derive closed-form\nexpressions for the \\textit{average secrecy rate}; and \\textit{b)} the\ntransmitter only knows the CSI of the legitimate nodes, for which we obtain\nclosed-form expressions for the \\textit{secrecy outage probability}. We show\nthat secure FD relaying is feasible, even under strong self-interference and in\nthe presence of sophisticated multiple antenna eavesdropper.\n", "contributors": [{"name": "Alves, Hirley", "sameAs": [], "familyName": "Alves", "additionalName": "", "givenName": "Hirley", "email": ""}, {"name": "Brante, Glauber", "sameAs": [], "familyName": "Brante", "additionalName": "", "givenName": "Glauber", "email": ""}, {"name": "Souza, Richard D.", "sameAs": [], "familyName": "Souza", "additionalName": "D.", "givenName": "Richard", "email": ""}, {"name": "da Costa, Daniel B.", "sameAs": [], "familyName": "da Costa", "additionalName": "B.", "givenName": "Daniel", "email": ""}, {"name": "Latva-aho, Matti", "sameAs": [], "familyName": "Latva-aho", "additionalName": "", "givenName": "Matti", "email": ""}], "title": "On the Performance of Secure Full-Duplex Relaying under Composite Fading\n  Channels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3856", "oai:arXiv.org:1411.3856"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We assume a full-duplex (FD) cooperative network subject to hostile attacks\nand undergoing composite fading channels. We focus on two scenarios:\n\\textit{a)} the transmitter has full CSI, for which we derive closed-form\nexpressions for the \\textit{average secrecy rate}; and \\textit{b)} the\ntransmitter only knows the CSI of the legitimate nodes, for which we obtain\nclosed-form expressions for the \\textit{secrecy outage probability}. We show\nthat secure FD relaying is feasible, even under strong self-interference and in\nthe presence of sophisticated multiple antenna eavesdropper.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3856"}}, {"publisher": {"name": ""}, "description": "  Neural spikes in the brain form stochastic sequences, i.e., belong to the\nclass of pulse noises. This stochasticity is a counterintuitive feature because\nextracting information - such as the commonly supposed neural information of\nmean spike frequency - requires long times for reasonably low error\nprobability. The mystery could be solved by noise-based logic, wherein\nrandomness has an important function and allows large speed enhancements for\nspecial-purpose tasks, and the same mechanism is at work for the brain logic\nversion of this concept.\n", "contributors": [{"name": "Kish, Laszlo B.", "sameAs": [], "familyName": "Kish", "additionalName": "B.", "givenName": "Laszlo", "email": ""}, {"name": "Granqvist, Claes-Goran", "sameAs": [], "familyName": "Granqvist", "additionalName": "", "givenName": "Claes-Goran", "email": ""}, {"name": "Bezrukov, Sergey M.", "sameAs": [], "familyName": "Bezrukov", "additionalName": "M.", "givenName": "Sergey", "email": ""}, {"name": "Horvath, Tamas", "sameAs": [], "familyName": "Horvath", "additionalName": "", "givenName": "Tamas", "email": ""}], "title": "Brain: Biological noise-based logic", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-08-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.4077", "Advances in Cognitive Neurodynamics 2015, pp 319-322", "doi:10.1007/978-94-017-9548-7_45", "oai:arXiv.org:1408.4077"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Neural spikes in the brain form stochastic sequences, i.e., belong to the\nclass of pulse noises. This stochasticity is a counterintuitive feature because\nextracting information - such as the commonly supposed neural information of\nmean spike frequency - requires long times for reasonably low error\nprobability. The mystery could be solved by noise-based logic, wherein\nrandomness has an important function and allows large speed enhancements for\nspecial-purpose tasks, and the same mechanism is at work for the brain logic\nversion of this concept.\n", "Comment: paper in press"]}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - emerging technologies"], "providerUpdatedDateTime": "2015-03-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.4077"}}, {"publisher": {"name": ""}, "description": "  Applying traditional collaborative filtering to digital publishing is\nchallenging because user data is very sparse due to the high volume of\ndocuments relative to the number of users. Content based approaches, on the\nother hand, is attractive because textual content is often very informative. In\nthis paper we describe large-scale content based collaborative filtering for\ndigital publishing. To solve the digital publishing recommender problem we\ncompare two approaches: latent Dirichlet allocation (LDA) and deep belief nets\n(DBN) that both find low-dimensional latent representations for documents.\nEfficient retrieval can be carried out in the latent representation. We work\nboth on public benchmarks and digital media content provided by Issuu, an\nonline publishing platform. This article also comes with a newly developed deep\nbelief nets toolbox for topic modeling tailored towards performance evaluation\nof the DBN model and comparisons to the LDA model.\n", "contributors": [{"name": "Maaloe, Lars", "sameAs": [], "familyName": "Maaloe", "additionalName": "", "givenName": "Lars", "email": ""}, {"name": "Arngren, Morten", "sameAs": [], "familyName": "Arngren", "additionalName": "", "givenName": "Morten", "email": ""}, {"name": "Winther, Ole", "sameAs": [], "familyName": "Winther", "additionalName": "", "givenName": "Ole", "email": ""}], "title": "Deep Belief Nets for Topic Modeling", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04325", "oai:arXiv.org:1501.04325"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Applying traditional collaborative filtering to digital publishing is\nchallenging because user data is very sparse due to the high volume of\ndocuments relative to the number of users. Content based approaches, on the\nother hand, is attractive because textual content is often very informative. In\nthis paper we describe large-scale content based collaborative filtering for\ndigital publishing. To solve the digital publishing recommender problem we\ncompare two approaches: latent Dirichlet allocation (LDA) and deep belief nets\n(DBN) that both find low-dimensional latent representations for documents.\nEfficient retrieval can be carried out in the latent representation. We work\nboth on public benchmarks and digital media content provided by Issuu, an\nonline publishing platform. This article also comes with a newly developed deep\nbelief nets toolbox for topic modeling tailored towards performance evaluation\nof the DBN model and comparisons to the LDA model.\n", "Comment: Accepted to the ICML-2014 Workshop on Knowledge-Powered Deep Learning\n  for Text Mining"]}}], "languages": [null], "subjects": ["computer science - computation and language", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04325"}}, {"publisher": {"name": ""}, "description": "  In this paper we address the following problem in web document and\ninformation retrieval (IR): How can we use long-term context information to\ngain better IR performance? Unlike common IR methods that use bag of words\nrepresentation for queries and documents, we treat them as a sequence of words\nand use long short term memory (LSTM) to capture contextual dependencies. The\nresulting model, the LSTM version of the Deep-Structured Semantic Model (DSSM),\nis a significant extension of the recent Recurrent-DSSM(Palangi et al., 2015)\nwithout the LSTMstructure. Experimental evaluation on an IR task derived from\nthe Bing web search demonstrates the ability of the proposed LSTM-DSSM in\naddressing both lexical mismatch and long-term context modelling issues,\nthereby, significantly outperforming the state of the art method of R-DSSM for\nweb search.\n", "contributors": [{"name": "Palangi, H.", "sameAs": [], "familyName": "Palangi", "additionalName": "", "givenName": "H.", "email": ""}, {"name": "Deng, L.", "sameAs": [], "familyName": "Deng", "additionalName": "", "givenName": "L.", "email": ""}, {"name": "Shen, Y.", "sameAs": [], "familyName": "Shen", "additionalName": "", "givenName": "Y.", "email": ""}, {"name": "Gao, J.", "sameAs": [], "familyName": "Gao", "additionalName": "", "givenName": "J.", "email": ""}, {"name": "He, X.", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "X.", "email": ""}, {"name": "Chen, J.", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "J.", "email": ""}, {"name": "Song, X.", "sameAs": [], "familyName": "Song", "additionalName": "", "givenName": "X.", "email": ""}, {"name": "Ward, R.", "sameAs": [], "familyName": "Ward", "additionalName": "", "givenName": "R.", "email": ""}], "title": "Semantic Modelling with Long-Short-Term Memory for Information Retrieval", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-20", "2014-12-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6629", "oai:arXiv.org:1412.6629"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper we address the following problem in web document and\ninformation retrieval (IR): How can we use long-term context information to\ngain better IR performance? Unlike common IR methods that use bag of words\nrepresentation for queries and documents, we treat them as a sequence of words\nand use long short term memory (LSTM) to capture contextual dependencies. The\nresulting model, the LSTM version of the Deep-Structured Semantic Model (DSSM),\nis a significant extension of the recent Recurrent-DSSM(Palangi et al., 2015)\nwithout the LSTMstructure. Experimental evaluation on an IR task derived from\nthe Bing web search demonstrates the ability of the proposed LSTM-DSSM in\naddressing both lexical mismatch and long-term context modelling issues,\nthereby, significantly outperforming the state of the art method of R-DSSM for\nweb search.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6629"}}, {"publisher": {"name": ""}, "description": "  Deep within the networks of distributed systems, one often finds anomalies\nthat affect their efficiency and performance. These anomalies are difficult to\ndetect because the distributed systems may not have sufficient sensors to\nmonitor the flow of traffic within the interconnected nodes of the networks.\nWithout early detection and making corrections, these anomalies may aggravate\nover time and could possibly cause disastrous outcomes in the system in the\nunforeseeable future. Using only coarse-grained information from the two end\npoints of network flows, we propose a network transmission model and a\nlocalization algorithm, to detect the location of anomalies and rank them using\na proposed metric within distributed systems. We evaluate our approach on\npassengers' records of an urbanized city's public transportation system and\ncorrelate our findings with passengers' postings on social media microblogs.\nOur experiments show that the metric derived using our localization algorithm\ngives a better ranking of anomalies as compared to standard deviation measures\nfrom statistical models. Our case studies also demonstrate that transportation\nevents reported in social media microblogs matches the locations of our detect\nanomalies, suggesting that our algorithm performs well in locating the\nanomalies within distributed systems.\n", "contributors": [{"name": "Chua, Freddy Chong Tat", "sameAs": [], "familyName": "Chua", "additionalName": "Chong Tat", "givenName": "Freddy", "email": ""}, {"name": "Lim, Ee-Peng", "sameAs": [], "familyName": "Lim", "additionalName": "", "givenName": "Ee-Peng", "email": ""}, {"name": "Huberman, Bernardo A.", "sameAs": [], "familyName": "Huberman", "additionalName": "A.", "givenName": "Bernardo", "email": ""}], "title": "Detecting Flow Anomalies in Distributed Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-22", "2014-12-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.6064", "oai:arXiv.org:1407.6064"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Deep within the networks of distributed systems, one often finds anomalies\nthat affect their efficiency and performance. These anomalies are difficult to\ndetect because the distributed systems may not have sufficient sensors to\nmonitor the flow of traffic within the interconnected nodes of the networks.\nWithout early detection and making corrections, these anomalies may aggravate\nover time and could possibly cause disastrous outcomes in the system in the\nunforeseeable future. Using only coarse-grained information from the two end\npoints of network flows, we propose a network transmission model and a\nlocalization algorithm, to detect the location of anomalies and rank them using\na proposed metric within distributed systems. We evaluate our approach on\npassengers' records of an urbanized city's public transportation system and\ncorrelate our findings with passengers' postings on social media microblogs.\nOur experiments show that the metric derived using our localization algorithm\ngives a better ranking of anomalies as compared to standard deviation measures\nfrom statistical models. Our case studies also demonstrate that transportation\nevents reported in social media microblogs matches the locations of our detect\nanomalies, suggesting that our algorithm performs well in locating the\nanomalies within distributed systems.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - computers and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.6064"}}, {"publisher": {"name": ""}, "description": "  We study the Bayesian model averaging approach to learning Bayesian network\nstructures (DAGs) from data. We develop new algorithms including the first\nalgorithm that is able to efficiently sample DAGs according to the exact\nstructure posterior. The DAG samples can then be used to construct estimators\nfor the posterior of any feature. We theoretically prove good properties of our\nestimators and empirically show that our estimators considerably outperform the\nestimators from the previous state-of-the-art methods.\n", "contributors": [{"name": "He, Ru", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Ru", "email": ""}, {"name": "Tian, Jin", "sameAs": [], "familyName": "Tian", "additionalName": "", "givenName": "Jin", "email": ""}, {"name": "Wu, Huaiqing", "sameAs": [], "familyName": "Wu", "additionalName": "", "givenName": "Huaiqing", "email": ""}], "title": "Structure Learning in Bayesian Networks of Moderate Size by Efficient\n  Sampling", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04370", "oai:arXiv.org:1501.04370"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  We study the Bayesian model averaging approach to learning Bayesian network\nstructures (DAGs) from data. We develop new algorithms including the first\nalgorithm that is able to efficiently sample DAGs according to the exact\nstructure posterior. The DAG samples can then be used to construct estimators\nfor the posterior of any feature. We theoretically prove good properties of our\nestimators and empirically show that our estimators considerably outperform the\nestimators from the previous state-of-the-art methods.\n", "Comment: 51 pages"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04370"}}, {"publisher": {"name": ""}, "description": "  The adjoint method, among other sensitivity analysis methods, can fail in\nchaotic dynamical systems. The result from these methods can be too large,\noften by orders of magnitude, when the result is the derivative of a long time\naveraged quantity. This failure is known to be caused by ill-conditioned\ninitial value problems. This paper overcomes this failure by replacing the\ninitial value problem with the well-conditioned \"least squares shadowing (LSS)\nproblem\". The LSS problem is then linearized in our sensitivity analysis\nalgorithm, which computes a derivative that converges to the derivative of the\ninfinitely long time average. We demonstrate our algorithm in several dynamical\nsystems exhibiting both periodic and chaotic oscillations.\n", "contributors": [{"name": "Wang, Qiqi", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Qiqi", "email": ""}, {"name": "Hu, Rui", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Rui", "email": ""}, {"name": "Blonigan, Patrick", "sameAs": [], "familyName": "Blonigan", "additionalName": "", "givenName": "Patrick", "email": ""}], "title": "Least Squares Shadowing sensitivity analysis of chaotic limit cycle\n  oscillations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-04-01", "2014-02-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1204.0159", "doi:10.1016/j.jcp.2014.03.002", "oai:arXiv.org:1204.0159"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:nlin", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The adjoint method, among other sensitivity analysis methods, can fail in\nchaotic dynamical systems. The result from these methods can be too large,\noften by orders of magnitude, when the result is the derivative of a long time\naveraged quantity. This failure is known to be caused by ill-conditioned\ninitial value problems. This paper overcomes this failure by replacing the\ninitial value problem with the well-conditioned \"least squares shadowing (LSS)\nproblem\". The LSS problem is then linearized in our sensitivity analysis\nalgorithm, which computes a derivative that converges to the derivative of the\ninfinitely long time average. We demonstrate our algorithm in several dynamical\nsystems exhibiting both periodic and chaotic oscillations.\n", "Comment: submitted to JCP in revised form"]}}], "languages": [null], "subjects": ["physics - computational physics", "physics - fluid dynamics", "nonlinear sciences - chaotic dynamics"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1204.0159"}}, {"publisher": {"name": ""}, "description": "  Radio-frequency (RF) impairments in the transceiver hardware of communication\nsystems (e.g., phase noise (PN), high power amplifier (HPA) nonlinearities, or\nin-phase/quadrature-phase (I/Q) imbalance) can severely degrade the performance\nof traditional multiple-input multiple-output (MIMO) systems. Although\ncalibration algorithms can partially compensate these impairments, the\nremaining distortion still has substantial impact. Despite this, most prior\nworks have not analyzed this type of distortion. In this paper, we investigate\nthe impact of residual transceiver hardware impairments on the MIMO system\nperformance. In particular, we consider a transceiver impairment model, which\nhas been experimentally validated, and derive analytical ergodic capacity\nexpressions for both exact and high signal-to-noise ratios (SNRs). We\ndemonstrate that the capacity saturates in the high-SNR regime, thereby\ncreating a finite capacity ceiling. We also present a linear approximation for\nthe ergodic capacity in the low-SNR regime, and show that impairments have only\na second-order impact on the capacity. Furthermore, we analyze the effect of\ntransceiver impairments on large-scale MIMO systems; interestingly, we prove\nthat if one increases the number of antennas at one side only, the capacity\nbehaves similar to the finite-dimensional case. On the contrary, if the number\nof antennas on both sides increases with a fixed ratio, the capacity ceiling\nvanishes; thus, impairments cause only a bounded offset in the capacity\ncompared to the ideal transceiver hardware case.\n", "contributors": [{"name": "Zhang, Xinlin", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Xinlin", "email": ""}, {"name": "Matthaiou, Michail", "sameAs": [], "familyName": "Matthaiou", "additionalName": "", "givenName": "Michail", "email": ""}, {"name": "Bj\u00f6rnson, Emil", "sameAs": [], "familyName": "Bj\u00f6rnson", "additionalName": "", "givenName": "Emil", "email": ""}, {"name": "Coldrey, Mikael", "sameAs": [], "familyName": "Coldrey", "additionalName": "", "givenName": "Mikael", "email": ""}, {"name": "Debbah, M\u00e9rouane", "sameAs": [], "familyName": "Debbah", "additionalName": "", "givenName": "M\u00e9rouane", "email": ""}], "title": "On the MIMO Capacity with Residual Transceiver Hardware Impairments", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-13", "2014-12-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.3619", "oai:arXiv.org:1406.3619"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Radio-frequency (RF) impairments in the transceiver hardware of communication\nsystems (e.g., phase noise (PN), high power amplifier (HPA) nonlinearities, or\nin-phase/quadrature-phase (I/Q) imbalance) can severely degrade the performance\nof traditional multiple-input multiple-output (MIMO) systems. Although\ncalibration algorithms can partially compensate these impairments, the\nremaining distortion still has substantial impact. Despite this, most prior\nworks have not analyzed this type of distortion. In this paper, we investigate\nthe impact of residual transceiver hardware impairments on the MIMO system\nperformance. In particular, we consider a transceiver impairment model, which\nhas been experimentally validated, and derive analytical ergodic capacity\nexpressions for both exact and high signal-to-noise ratios (SNRs). We\ndemonstrate that the capacity saturates in the high-SNR regime, thereby\ncreating a finite capacity ceiling. We also present a linear approximation for\nthe ergodic capacity in the low-SNR regime, and show that impairments have only\na second-order impact on the capacity. Furthermore, we analyze the effect of\ntransceiver impairments on large-scale MIMO systems; interestingly, we prove\nthat if one increases the number of antennas at one side only, the capacity\nbehaves similar to the finite-dimensional case. On the contrary, if the number\nof antennas on both sides increases with a fixed ratio, the capacity ceiling\nvanishes; thus, impairments cause only a bounded offset in the capacity\ncompared to the ideal transceiver hardware case.\n", "Comment: Accepted for publication at the IEEE International Conference on\n  Communications (ICC 2014), 7 pages, 6 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.3619"}}, {"publisher": {"name": ""}, "description": "  This paper summarizes the work on implementing few solutions for the Steiner\nTree problem which we undertook in the PAAL project. The main focus of the\nproject is the development of generic implementations of approximation\nalgorithms together with universal solution frameworks. In particular, we have\nimplemented Zelikovsky 11/6-approximation using local search framework, and\n1.39-approximation by Byrka et al. using iterative rounding framework. These\ntwo algorithms are experimentally compared with greedy 2-approximation, with\nexact but exponential time Dreyfus-Wagner algorithm, as well as with results\ngiven by a state-of-the-art local search techniques by Uchoa and Werneck. The\nresults of this paper are twofold. On one hand, we demonstrate that high level\nalgorithmic concepts can be designed and efficiently used in C++. On the other\nhand, we show that the above algorithms with good theoretical guarantees, give\ndecent results in practice, but are inferior to state-of-the-art heuristical\napproaches.\n", "contributors": [{"name": "Ciebiera, Krzysztof", "sameAs": [], "familyName": "Ciebiera", "additionalName": "", "givenName": "Krzysztof", "email": ""}, {"name": "Godlewski, Piotr", "sameAs": [], "familyName": "Godlewski", "additionalName": "", "givenName": "Piotr", "email": ""}, {"name": "Sankowski, Piotr", "sameAs": [], "familyName": "Sankowski", "additionalName": "", "givenName": "Piotr", "email": ""}, {"name": "Wygocki, Piotr", "sameAs": [], "familyName": "Wygocki", "additionalName": "", "givenName": "Piotr", "email": ""}], "title": "Approximation Algorithms for Steiner Tree Problems Based on Universal\n  Solution Frameworks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.7534", "oai:arXiv.org:1410.7534"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper summarizes the work on implementing few solutions for the Steiner\nTree problem which we undertook in the PAAL project. The main focus of the\nproject is the development of generic implementations of approximation\nalgorithms together with universal solution frameworks. In particular, we have\nimplemented Zelikovsky 11/6-approximation using local search framework, and\n1.39-approximation by Byrka et al. using iterative rounding framework. These\ntwo algorithms are experimentally compared with greedy 2-approximation, with\nexact but exponential time Dreyfus-Wagner algorithm, as well as with results\ngiven by a state-of-the-art local search techniques by Uchoa and Werneck. The\nresults of this paper are twofold. On one hand, we demonstrate that high level\nalgorithmic concepts can be designed and efficiently used in C++. On the other\nhand, we show that the above algorithms with good theoretical guarantees, give\ndecent results in practice, but are inferior to state-of-the-art heuristical\napproaches.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - software engineering"], "providerUpdatedDateTime": "2014-10-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.7534"}}, {"publisher": {"name": ""}, "description": "  The wide bandwidth and large number of antennas used in millimeter wave\nsystems put a heavy burden on the power consumption at the receiver. In this\npaper, using an additive quantization noise model, the effect of analog-digital\nconversion (ADC) resolution and bandwidth on the achievable rate is\ninvestigated for a multi-antenna system under a receiver power constraint. Two\nreceiver architectures, analog and digital combining, are compared in terms of\nperformance. Results demonstrate that: (i) For both analog and digital\ncombining, there is a maximum bandwidth beyond which the achievable rate\ndecreases; (ii) Depending on the operating regime of the system, analog\ncombiner may have higher rate but digital combining uses less bandwidth when\nonly ADC power consumption is considered, (iii) digital combining may have\nhigher rate when power consumption of all the components in the receiver\nfront-end are taken into account.\n", "contributors": [{"name": "Orhan, Oner", "sameAs": [], "familyName": "Orhan", "additionalName": "", "givenName": "Oner", "email": ""}, {"name": "Erkip, Elza", "sameAs": [], "familyName": "Erkip", "additionalName": "", "givenName": "Elza", "email": ""}, {"name": "Rangan, Sundeep", "sameAs": [], "familyName": "Rangan", "additionalName": "", "givenName": "Sundeep", "email": ""}], "title": "Low Power Analog-to-Digital Conversion in Millimeter Wave Systems:\n  Impact of Resolution and Bandwidth on Performance", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01980", "oai:arXiv.org:1502.01980"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The wide bandwidth and large number of antennas used in millimeter wave\nsystems put a heavy burden on the power consumption at the receiver. In this\npaper, using an additive quantization noise model, the effect of analog-digital\nconversion (ADC) resolution and bandwidth on the achievable rate is\ninvestigated for a multi-antenna system under a receiver power constraint. Two\nreceiver architectures, analog and digital combining, are compared in terms of\nperformance. Results demonstrate that: (i) For both analog and digital\ncombining, there is a maximum bandwidth beyond which the achievable rate\ndecreases; (ii) Depending on the operating regime of the system, analog\ncombiner may have higher rate but digital combining uses less bandwidth when\nonly ADC power consumption is considered, (iii) digital combining may have\nhigher rate when power consumption of all the components in the receiver\nfront-end are taken into account.\n", "Comment: 8 pages, 6 figures, in Proc. of IEEE Information Theory and\n  Applications Workshop, Feb. 2015"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01980"}}, {"publisher": {"name": ""}, "description": "  In this paper, we examine the evolution of the impact of non-elite journals.\nWe attempt to answer two questions. First, what fraction of the top-cited\narticles are published in non-elite journals and how has this changed over\ntime. Second, what fraction of the total citations are to non-elite journals\nand how has this changed over time.\n  We studied citations to articles published in 1995-2013. We computed the 10\nmost-cited journals and the 1000 most-cited articles each year for all 261\nsubject categories in Scholar Metrics. We marked the 10 most-cited journals in\na category as the elite journals for the category and the rest as non-elite.\n  There are two conclusions from our study. First, the fraction of top-cited\narticles published in non-elite journals increased steadily over 1995-2013.\nWhile the elite journals still publish a substantial fraction of high-impact\narticles, many more authors of well-regarded papers in diverse research fields\nare choosing other venues.\n  The number of top-1000 papers published in non-elite journals for the\nrepresentative subject category went from 149 in 1995 to 245 in 2013, a growth\nof 64%. Looking at broad research areas, 4 out of 9 areas saw at least\none-third of the top-cited articles published in non-elite journals in 2013.\nFor 6 out of 9 areas, the fraction of top-cited papers published in non-elite\njournals for the representative subject category grew by 45% or more.\n  Second, now that finding and reading relevant articles in non-elite journals\nis about as easy as finding and reading articles in elite journals, researchers\nare increasingly building on and citing work published everywhere. Considering\ncitations to all articles, the percentage of citations to articles in non-elite\njournals went from 27% in 1995 to 47% in 2013. Six out of nine broad areas had\nat least 50% of citations going to articles published in non-elite journals in\n2013.\n", "contributors": [{"name": "Acharya, Anurag", "sameAs": [], "familyName": "Acharya", "additionalName": "", "givenName": "Anurag", "email": ""}, {"name": "Verstak, Alex", "sameAs": [], "familyName": "Verstak", "additionalName": "", "givenName": "Alex", "email": ""}, {"name": "Suzuki, Helder", "sameAs": [], "familyName": "Suzuki", "additionalName": "", "givenName": "Helder", "email": ""}, {"name": "Henderson, Sean", "sameAs": [], "familyName": "Henderson", "additionalName": "", "givenName": "Sean", "email": ""}, {"name": "Iakhiaev, Mikhail", "sameAs": [], "familyName": "Iakhiaev", "additionalName": "", "givenName": "Mikhail", "email": ""}, {"name": "Lin, Cliff Chiung Yu", "sameAs": [], "familyName": "Lin", "additionalName": "Chiung Yu", "givenName": "Cliff", "email": ""}, {"name": "Shetty, Namit", "sameAs": [], "familyName": "Shetty", "additionalName": "", "givenName": "Namit", "email": ""}], "title": "Rise of the Rest: The Growing Impact of Non-Elite Journals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2217", "oai:arXiv.org:1410.2217"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we examine the evolution of the impact of non-elite journals.\nWe attempt to answer two questions. First, what fraction of the top-cited\narticles are published in non-elite journals and how has this changed over\ntime. Second, what fraction of the total citations are to non-elite journals\nand how has this changed over time.\n  We studied citations to articles published in 1995-2013. We computed the 10\nmost-cited journals and the 1000 most-cited articles each year for all 261\nsubject categories in Scholar Metrics. We marked the 10 most-cited journals in\na category as the elite journals for the category and the rest as non-elite.\n  There are two conclusions from our study. First, the fraction of top-cited\narticles published in non-elite journals increased steadily over 1995-2013.\nWhile the elite journals still publish a substantial fraction of high-impact\narticles, many more authors of well-regarded papers in diverse research fields\nare choosing other venues.\n  The number of top-1000 papers published in non-elite journals for the\nrepresentative subject category went from 149 in 1995 to 245 in 2013, a growth\nof 64%. Looking at broad research areas, 4 out of 9 areas saw at least\none-third of the top-cited articles published in non-elite journals in 2013.\nFor 6 out of 9 areas, the fraction of top-cited papers published in non-elite\njournals for the representative subject category grew by 45% or more.\n  Second, now that finding and reading relevant articles in non-elite journals\nis about as easy as finding and reading articles in elite journals, researchers\nare increasingly building on and citing work published everywhere. Considering\ncitations to all articles, the percentage of citations to articles in non-elite\njournals went from 27% in 1995 to 47% in 2013. Six out of nine broad areas had\nat least 50% of citations going to articles published in non-elite journals in\n2013.\n"}}], "languages": [null], "subjects": ["computer science - digital libraries"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2217"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Developing and implementing measurable methodologies for improving the security and resilience of a national postal sector directly contribute to protecting public and postal personnel, assets, and revenues. Such methodologies also contribute to the security and resilience of the mode of transport used to carry mail and the protection of the global mail supply chain. Since 2011, the U.S. Postal Inspection Service (USPIS) has collaborated with the CERT Division at Carnegie Mellon University\u2019s Software Engineering Institute to improve the resilience of selected U.S. Postal Service (USPS) products and services. The CERT Resilience Management Model (CERT-RMM) and its companion diagnostic methods served as the foundational tool for this collaboration.\nThis report includes one result of the USPIS/CERT collaboration. It is an extension of CERT-RMM to include a new mail-specific process area for the transportation of international mail. The purpose is to ensure that all international mail is transported in accordance with the standards established by the Universal Postal Union (UPU), which is the governing body that regulates the transportation of international mail.", "contributors": [{"name": "Allen, Julia H.", "sameAs": [], "familyName": "Allen", "additionalName": "H.", "givenName": "Julia", "email": ""}, {"name": "Crabb, Greg", "sameAs": [], "familyName": "Crabb", "additionalName": "", "givenName": "Greg", "email": ""}, {"name": "Curtis, Pamela D", "sameAs": [], "familyName": "Curtis", "additionalName": "D", "givenName": "Pamela", "email": ""}, {"name": "Lin, Sam", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Sam", "email": ""}, {"name": "Mehravari, Nader", "sameAs": [], "familyName": "Mehravari", "additionalName": "", "givenName": "Nader", "email": ""}, {"name": "Wilkes, Dawn", "sameAs": [], "familyName": "Wilkes", "additionalName": "", "givenName": "Dawn", "email": ""}], "title": "CERT Resilience Management Model\u2014Mail-Specific Process Areas: International Mail Transportation (Version 1.0)", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-08-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/sei/795", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1807&amp;context=sei", "oai:repository.cmu.edu:sei-1807"]}}, {"name": "setSpec", "properties": {"setSpec": "publication:sei"}}, {"name": "description", "properties": {"description": "Developing and implementing measurable methodologies for improving the security and resilience of a national postal sector directly contribute to protecting public and postal personnel, assets, and revenues. Such methodologies also contribute to the security and resilience of the mode of transport used to carry mail and the protection of the global mail supply chain. Since 2011, the U.S. Postal Inspection Service (USPIS) has collaborated with the CERT Division at Carnegie Mellon University\u2019s Software Engineering Institute to improve the resilience of selected U.S. Postal Service (USPS) products and services. The CERT Resilience Management Model (CERT-RMM) and its companion diagnostic methods served as the foundational tool for this collaboration.\nThis report includes one result of the USPIS/CERT collaboration. It is an extension of CERT-RMM to include a new mail-specific process area for the transportation of international mail. The purpose is to ensure that all international mail is transported in accordance with the standards established by the Universal Postal Union (UPU), which is the governing body that regulates the transportation of international mail."}}], "languages": [null], "subjects": ["software engineering", "uspis", "usps", "international mail transportation", "computer sciences", "universal postal union", "cert-rmm", "upu", "resilience", "mail specific"], "providerUpdatedDateTime": "2014-11-04T16:15:19", "uris": {"canonicalUri": "http://repository.cmu.edu/sei/795"}}, {"publisher": {"name": ""}, "description": "  Ubiquitous sensing is tightly coupled with activity recognition. This survey\nreviews recent advances in Ubiquitous sensing and looks ahead on promising\nfuture directions. In particular, Ubiquitous sensing crosses new barriers\ngiving us new ways to interact with the environment or to inspect our psyche.\nThrough sensing paradigms that parasitically utilise stimuli from the noise of\nenvironmental, third-party pre-installed systems, sensing leaves the boundaries\nof the personal domain. Compared to previous environmental sensing approaches,\nthese new systems mitigate high installation and placement cost by providing a\nrobustness towards process noise. On the other hand, sensing focuses inward and\nattempts to capture mental activities such as cognitive load, fatigue or\nemotion through advances in, for instance, eye-gaze sensing systems or\ninterpretation of body gesture or pose. This survey summarises these\ndevelopments and discusses current research questions and promising future\ndirections.\n", "contributors": [{"name": "Sigg, Stephan", "sameAs": [], "familyName": "Sigg", "additionalName": "", "givenName": "Stephan", "email": ""}, {"name": "Kunze, Kai", "sameAs": [], "familyName": "Kunze", "additionalName": "", "givenName": "Kai", "email": ""}, {"name": "Fu, Xiaoming", "sameAs": [], "familyName": "Fu", "additionalName": "", "givenName": "Xiaoming", "email": ""}], "title": "Recent Advances and Challenges in Ubiquitous Sensing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04973", "oai:arXiv.org:1503.04973"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Ubiquitous sensing is tightly coupled with activity recognition. This survey\nreviews recent advances in Ubiquitous sensing and looks ahead on promising\nfuture directions. In particular, Ubiquitous sensing crosses new barriers\ngiving us new ways to interact with the environment or to inspect our psyche.\nThrough sensing paradigms that parasitically utilise stimuli from the noise of\nenvironmental, third-party pre-installed systems, sensing leaves the boundaries\nof the personal domain. Compared to previous environmental sensing approaches,\nthese new systems mitigate high installation and placement cost by providing a\nrobustness towards process noise. On the other hand, sensing focuses inward and\nattempts to capture mental activities such as cognitive load, fatigue or\nemotion through advances in, for instance, eye-gaze sensing systems or\ninterpretation of body gesture or pose. This survey summarises these\ndevelopments and discusses current research questions and promising future\ndirections.\n", "Comment: Submitted to PIEEE"]}}], "languages": [null], "subjects": ["computer science - human-computer interaction"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04973"}}, {"publisher": {"name": ""}, "description": "abstract: The Game As Life - Life As Game (GALLAG) project investigates how people might change their lives if they think of and/or experience their life as a game. The GALLAG system aims to help people reach their personal goals through the use of context-aware computing, and tailored games and applications. To accomplish this, the GALLAG system uses a combination of sensing technologies, remote audio/video feedback, mobile devices and an application programming interface (API) to empower users to create their own context-aware applications. However, the API requires programming through source code, a task that is too complicated and abstract for many users. This thesis presents GALLAG Strip, a novel approach to programming sensor-based context-aware applications that combines the Programming With Demonstration technique and a mobile device to enable users to experience their applications as they program them. GALLAG Strip lets users create sensor-based context-aware applications in an intuitive and appealing way without the need of computer programming skills; instead, they program their applications by physically demonstrating their envisioned interactions within a space using the same interface that they will later use to interact with the system, that is, using GALLAG-compatible sensors and mobile devices. GALLAG Strip was evaluated through a study with end users in a real world setting, measuring their ability to program simple and complex applications accurately and in a timely manner. The evaluation also comprises a benchmark with expert GALLAG system programmers in creating the same applications. Data and feedback collected from the study show that GALLAG Strip successfully allows users to create sensor-based context-aware applications easily and accurately without the need of prior programming skills currently required by the GALLAG system and enables them to create almost all of their envisioned applications.", "contributors": [{"name": "Garduno Massieu, Luis  (Author)", "sameAs": [], "familyName": "Garduno Massieu", "additionalName": "", "givenName": "Luis", "email": ""}, {"name": "Burleson, Winslow  (Advisor)", "sameAs": [], "familyName": "Burleson", "additionalName": "", "givenName": "Winslow", "email": ""}, {"name": "Hekler, Eric  (Committee member)", "sameAs": [], "familyName": "Hekler", "additionalName": "", "givenName": "Eric", "email": ""}, {"name": "Gupta, Sandeep  (Committee member)", "sameAs": [], "familyName": "Gupta", "additionalName": "", "givenName": "Sandeep", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "GALLAG Strip: A Mobile, Programming With Demonstration Environment for Sensor-Based Context-Aware Application Programming", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Masters Thesis"}}, {"name": "format", "properties": {"format": "90 pages"}}, {"name": "date", "properties": {"date": "2012"}}, {"name": "description", "properties": {"description": ["abstract: The Game As Life - Life As Game (GALLAG) project investigates how people might change their lives if they think of and/or experience their life as a game. The GALLAG system aims to help people reach their personal goals through the use of context-aware computing, and tailored games and applications. To accomplish this, the GALLAG system uses a combination of sensing technologies, remote audio/video feedback, mobile devices and an application programming interface (API) to empower users to create their own context-aware applications. However, the API requires programming through source code, a task that is too complicated and abstract for many users. This thesis presents GALLAG Strip, a novel approach to programming sensor-based context-aware applications that combines the Programming With Demonstration technique and a mobile device to enable users to experience their applications as they program them. GALLAG Strip lets users create sensor-based context-aware applications in an intuitive and appealing way without the need of computer programming skills; instead, they program their applications by physically demonstrating their envisioned interactions within a space using the same interface that they will later use to interact with the system, that is, using GALLAG-compatible sensors and mobile devices. GALLAG Strip was evaluated through a study with end users in a real world setting, measuring their ability to program simple and complex applications accurately and in a timely manner. The evaluation also comprises a benchmark with expert GALLAG system programmers in creating the same applications. Data and feedback collected from the study show that GALLAG Strip successfully allows users to create sensor-based context-aware applications easily and accurately without the need of prior programming skills currently required by the GALLAG system and enables them to create almost all of their envisioned applications.", "Dissertation/Thesis", "M.S. Computer Science 2012"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.14871", "item:14871"]}}], "languages": [null], "subjects": ["human computer interaction", "arts", "ame", "pwd", "computer science", "hci", "media and engineering"], "providerUpdatedDateTime": "2015-02-12T01:13:31", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.14871"}}, {"publisher": {"name": ""}, "description": "  Schelling's model of segregation is one of the first and most influential\nmodels in the field of social simulation. There are many variations of the\nmodel which have been proposed and simulated over the last forty years, though\nthe present state of the literature on the subject is somewhat fragmented and\nlacking comprehensive analytical treatments. In this article a unified\nmathematical framework for Schelling's model and its many variants is\ndeveloped. This methodology is useful in two regards: firstly, it provides a\ntool with which to understand the differences observed between models;\nsecondly, phenomena which appear in several model variations may be understood\nin more depth through analytic studies of simpler versions.\n", "contributors": [{"name": "Rogers, Tim", "sameAs": [], "familyName": "Rogers", "additionalName": "", "givenName": "Tim", "email": ""}, {"name": "McKane, Alan J.", "sameAs": [], "familyName": "McKane", "additionalName": "J.", "givenName": "Alan", "email": ""}], "title": "A unified framework for Schelling's model of segregation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-11", "2011-05-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.1971", "J. Stat. Mech. (2011) P07006", "doi:10.1088/1742-5468/2011/07/P07006", "oai:arXiv.org:1104.1971"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Schelling's model of segregation is one of the first and most influential\nmodels in the field of social simulation. There are many variations of the\nmodel which have been proposed and simulated over the last forty years, though\nthe present state of the literature on the subject is somewhat fragmented and\nlacking comprehensive analytical treatments. In this article a unified\nmathematical framework for Schelling's model and its many variants is\ndeveloped. This methodology is useful in two regards: firstly, it provides a\ntool with which to understand the differences observed between models;\nsecondly, phenomena which appear in several model variations may be understood\nin more depth through analytic studies of simpler versions.\n", "Comment: 21 pages, 3 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "condensed matter - statistical mechanics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.1971"}}, {"publisher": {"name": ""}, "description": "  In computational biology and bioinformatics, the manner to understand\nevolution processes within various related organisms paid a lot of attention\nthese last decades. However, accurate methodologies are still needed to\ndiscover genes content evolution. In a previous work, two novel approaches\nbased on sequence similarities and genes features have been proposed. More\nprecisely, we proposed to use genes names, sequence similarities, or both,\ninsured either from NCBI or from DOGMA annotation tools. Dogma has the\nadvantage to be an up-to-date accurate automatic tool specifically designed for\nchloroplasts, whereas NCBI possesses high quality human curated genes (together\nwith wrongly annotated ones). The key idea of the former proposal was to take\nthe best from these two tools. However, the first proposal was limited by name\nvariations and spelling errors on the NCBI side, leading to core trees of low\nquality. In this paper, these flaws are fixed by improving the comparison of\nNCBI and DOGMA results, and by relaxing constraints on gene names while adding\na stage of post-validation on gene sequences. The two stages of similarity\nmeasures, on names and sequences, are thus proposed for sequence clustering.\nThis improves results that can be obtained using either NCBI or DOGMA alone.\nResults obtained with this quality control test are further investigated and\ncompared with previously released ones, on both computational and biological\naspects, considering a set of 99 chloroplastic genomes.\n", "contributors": [{"name": "AlKindy, Bassam", "sameAs": [], "familyName": "AlKindy", "additionalName": "", "givenName": "Bassam", "email": ""}, {"name": "Guyeux, Christophe", "sameAs": [], "familyName": "Guyeux", "additionalName": "", "givenName": "Christophe", "email": ""}, {"name": "Couchot, Jean-Fran\u00e7ois", "sameAs": [], "familyName": "Couchot", "additionalName": "", "givenName": "Jean-Fran\u00e7ois", "email": ""}, {"name": "Salomon, Michel", "sameAs": [], "familyName": "Salomon", "additionalName": "", "givenName": "Michel", "email": ""}, {"name": "Bahi, Jacques M.", "sameAs": [], "familyName": "Bahi", "additionalName": "M.", "givenName": "Jacques", "email": ""}], "title": "Gene Similarity-based Approaches for Determining Core-Genes of\n  Chloroplasts", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5323", "oai:arXiv.org:1412.5323"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": ["  In computational biology and bioinformatics, the manner to understand\nevolution processes within various related organisms paid a lot of attention\nthese last decades. However, accurate methodologies are still needed to\ndiscover genes content evolution. In a previous work, two novel approaches\nbased on sequence similarities and genes features have been proposed. More\nprecisely, we proposed to use genes names, sequence similarities, or both,\ninsured either from NCBI or from DOGMA annotation tools. Dogma has the\nadvantage to be an up-to-date accurate automatic tool specifically designed for\nchloroplasts, whereas NCBI possesses high quality human curated genes (together\nwith wrongly annotated ones). The key idea of the former proposal was to take\nthe best from these two tools. However, the first proposal was limited by name\nvariations and spelling errors on the NCBI side, leading to core trees of low\nquality. In this paper, these flaws are fixed by improving the comparison of\nNCBI and DOGMA results, and by relaxing constraints on gene names while adding\na stage of post-validation on gene sequences. The two stages of similarity\nmeasures, on names and sequences, are thus proposed for sequence clustering.\nThis improves results that can be obtained using either NCBI or DOGMA alone.\nResults obtained with this quality control test are further investigated and\ncompared with previously released ones, on both computational and biological\naspects, considering a set of 99 chloroplastic genomes.\n", "Comment: 4 pages, IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM 2014)"]}}], "languages": [null], "subjects": ["quantitative biology - genomics", "computer science - neural and evolutionary computing"], "providerUpdatedDateTime": "2014-12-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5323"}}, {"publisher": {"name": ""}, "description": "  The aim of rendezvous in a graph is meeting of two mobile agents at some node\nof an unknown anonymous connected graph. In this paper, we focus on rendezvous\nin trees, and, analogously to the efforts that have been made for solving the\nexploration problem with compact automata, we study the size of memory of\nmobile agents that permits to solve the rendezvous problem deterministically.\nWe assume that the agents are identical, and move in synchronous rounds.\n  We first show that if the delay between the starting times of the agents is\narbitrary, then the lower bound on memory required for rendezvous is Omega(log\nn) bits, even for the line of length n. This lower bound meets a previously\nknown upper bound of O(log n) bits for rendezvous in arbitrary graphs of size\nat most n. Our main result is a proof that the amount of memory needed for\nrendezvous with simultaneous start depends essentially on the number L of\nleaves of the tree, and is exponentially less impacted by the number n of\nnodes. Indeed, we present two identical agents with O(log L + loglog n) bits of\nmemory that solve the rendezvous problem in all trees with at most n nodes and\nat most L leaves. Hence, for the class of trees with polylogarithmically many\nleaves, there is an exponential gap in minimum memory size needed for\nrendezvous between the scenario with arbitrary delay and the scenario with\ndelay zero. Moreover, we show that our upper bound is optimal by proving that\nOmega(log L + loglog n)$ bits of memory are required for rendezvous, even in\nthe class of trees with degrees bounded by 3.\n", "contributors": [{"name": "Fraigniaud, Pierre", "sameAs": [], "familyName": "Fraigniaud", "additionalName": "", "givenName": "Pierre", "email": ""}, {"name": "Pelc, Andrzej", "sameAs": [], "familyName": "Pelc", "additionalName": "", "givenName": "Andrzej", "email": ""}], "title": "Delays Induce an Exponential Memory Gap for Rendezvous in Trees", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-02-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1102.0467", "oai:arXiv.org:1102.0467"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The aim of rendezvous in a graph is meeting of two mobile agents at some node\nof an unknown anonymous connected graph. In this paper, we focus on rendezvous\nin trees, and, analogously to the efforts that have been made for solving the\nexploration problem with compact automata, we study the size of memory of\nmobile agents that permits to solve the rendezvous problem deterministically.\nWe assume that the agents are identical, and move in synchronous rounds.\n  We first show that if the delay between the starting times of the agents is\narbitrary, then the lower bound on memory required for rendezvous is Omega(log\nn) bits, even for the line of length n. This lower bound meets a previously\nknown upper bound of O(log n) bits for rendezvous in arbitrary graphs of size\nat most n. Our main result is a proof that the amount of memory needed for\nrendezvous with simultaneous start depends essentially on the number L of\nleaves of the tree, and is exponentially less impacted by the number n of\nnodes. Indeed, we present two identical agents with O(log L + loglog n) bits of\nmemory that solve the rendezvous problem in all trees with at most n nodes and\nat most L leaves. Hence, for the class of trees with polylogarithmically many\nleaves, there is an exponential gap in minimum memory size needed for\nrendezvous between the scenario with arbitrary delay and the scenario with\ndelay zero. Moreover, we show that our upper bound is optimal by proving that\nOmega(log L + loglog n)$ bits of memory are required for rendezvous, even in\nthe class of trees with degrees bounded by 3.\n"}}], "languages": [null], "subjects": ["computer science - robotics", "computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1102.0467"}}, {"publisher": {"name": ""}, "description": "  Software model checking, as an undecidable problem, has three possible\noutcomes: (1) the program satisfies the specification, (2) the program does not\nsatisfy the specification, and (3) the model checker fails. The third outcome\nusually manifests itself in a space-out, time-out, or one component of the\nverification tool giving up; in all of these failing cases, significant\ncomputation is performed by the verification tool before the failure, but no\nresult is reported. We propose to reformulate the model-checking problem as\nfollows, in order to have the verification tool report a summary of the\nperformed work even in case of failure: given a program and a specification,\nthe model checker returns a condition P ---usually a state predicate--- such\nthat the program satisfies the specification under the condition P ---that is,\nas long as the program does not leave states in which P is satisfied. We are of\ncourse interested in model checkers that return conditions P that are as weak\nas possible. Instead of outcome (1), the model checker will return P = true;\ninstead of (2), the condition P will return the part of the state space that\nsatisfies the specification; and in case (3), the condition P can summarize the\nwork that has been performed by the model checker before space-out, time-out,\nor giving up. If complete verification is necessary, then a different\nverification method or tool may be used to focus on the states that violate the\ncondition. We give such conditions as input to a conditional model checker,\nsuch that the verification problem is restricted to the part of the state space\nthat satisfies the condition. Our experiments show that repeated application of\nconditional model checkers, using different conditions, can significantly\nimprove the verification results, state-space coverage, and performance.\n", "contributors": [{"name": "Beyer, Dirk", "sameAs": [], "familyName": "Beyer", "additionalName": "", "givenName": "Dirk", "email": ""}, {"name": "Henzinger, Thomas A.", "sameAs": [], "familyName": "Henzinger", "additionalName": "A.", "givenName": "Thomas", "email": ""}, {"name": "Keremoglu, M. Erkan", "sameAs": [], "familyName": "Keremoglu", "additionalName": "Erkan", "givenName": "M.", "email": ""}, {"name": "Wendler, Philipp", "sameAs": [], "familyName": "Wendler", "additionalName": "", "givenName": "Philipp", "email": ""}], "title": "Conditional Model Checking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-09-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.6926", "oai:arXiv.org:1109.6926"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Software model checking, as an undecidable problem, has three possible\noutcomes: (1) the program satisfies the specification, (2) the program does not\nsatisfy the specification, and (3) the model checker fails. The third outcome\nusually manifests itself in a space-out, time-out, or one component of the\nverification tool giving up; in all of these failing cases, significant\ncomputation is performed by the verification tool before the failure, but no\nresult is reported. We propose to reformulate the model-checking problem as\nfollows, in order to have the verification tool report a summary of the\nperformed work even in case of failure: given a program and a specification,\nthe model checker returns a condition P ---usually a state predicate--- such\nthat the program satisfies the specification under the condition P ---that is,\nas long as the program does not leave states in which P is satisfied. We are of\ncourse interested in model checkers that return conditions P that are as weak\nas possible. Instead of outcome (1), the model checker will return P = true;\ninstead of (2), the condition P will return the part of the state space that\nsatisfies the specification; and in case (3), the condition P can summarize the\nwork that has been performed by the model checker before space-out, time-out,\nor giving up. If complete verification is necessary, then a different\nverification method or tool may be used to focus on the states that violate the\ncondition. We give such conditions as input to a conditional model checker,\nsuch that the verification problem is restricted to the part of the state space\nthat satisfies the condition. Our experiments show that repeated application of\nconditional model checkers, using different conditions, can significantly\nimprove the verification results, state-space coverage, and performance.\n", "Comment: 14 pages, 8 figures, 3 tables"]}}], "languages": [null], "subjects": ["computer science - programming languages", "computer science - software engineering"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.6926"}}, {"publisher": {"name": ""}, "description": "  Motifs are a fundamental building block and distinguishing feature of\nnetworks. While characteristic motif distribution have been found in many\nnetworks, very little is known today about the evolution of network motifs.\nThis paper studies the most important motifs in social networks, triangles, and\nhow directed triangle motifs change over time. Our chosen subject is one of the\nlargest Online Social Networks, Google+. Google+ has two distinguishing\nfeatures that make it particularly interesting: (1) it is a directed network,\nwhich yields a rich set of triangle motifs, and (2) it is a young and fast\nevolving network, whose role in the OSN space is still not fully understood.\nFor the purpose of this study, we crawled the network over a time period of six\nweeks, collecting several snapshots. We find that some triangle types display\nsignificant dynamics, e.g., for some specific initial types, up to 20% of the\ninstances evolve to other types. Due to the fast growth of the OSN in the\nobserved time period, many new triangles emerge. We also observe that many\ntriangles evolve into less-connected motifs (with less edges), suggesting that\ngrowth also comes with pruning. We complement the topological study by also\nconsidering publicly available user profile data (mostly geographic locations).\nThe corresponding results shed some light on the semantics of the triangle\nmotifs. Indeed, we find that users in more symmetric triangle motifs live\ncloser together, indicating more personal relationships. In contrast,\nasymmetric links in motifs often point to faraway users with a high in-degree\n(celebrities).\n", "contributors": [{"name": "Schi\u00f6berg, Doris", "sameAs": [], "familyName": "Schi\u00f6berg", "additionalName": "", "givenName": "Doris", "email": ""}, {"name": "Schneidery, Fabian", "sameAs": [], "familyName": "Schneidery", "additionalName": "", "givenName": "Fabian", "email": ""}, {"name": "Schmid, Stefan", "sameAs": [], "familyName": "Schmid", "additionalName": "", "givenName": "Stefan", "email": ""}, {"name": "Uhlig, Steve", "sameAs": [], "familyName": "Uhlig", "additionalName": "", "givenName": "Steve", "email": ""}, {"name": "Feldmann, Anja", "sameAs": [], "familyName": "Feldmann", "additionalName": "", "givenName": "Anja", "email": ""}], "title": "Evolution of Directed Triangle Motifs in the Google+ OSN", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04321", "oai:arXiv.org:1502.04321"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Motifs are a fundamental building block and distinguishing feature of\nnetworks. While characteristic motif distribution have been found in many\nnetworks, very little is known today about the evolution of network motifs.\nThis paper studies the most important motifs in social networks, triangles, and\nhow directed triangle motifs change over time. Our chosen subject is one of the\nlargest Online Social Networks, Google+. Google+ has two distinguishing\nfeatures that make it particularly interesting: (1) it is a directed network,\nwhich yields a rich set of triangle motifs, and (2) it is a young and fast\nevolving network, whose role in the OSN space is still not fully understood.\nFor the purpose of this study, we crawled the network over a time period of six\nweeks, collecting several snapshots. We find that some triangle types display\nsignificant dynamics, e.g., for some specific initial types, up to 20% of the\ninstances evolve to other types. Due to the fast growth of the OSN in the\nobserved time period, many new triangles emerge. We also observe that many\ntriangles evolve into less-connected motifs (with less edges), suggesting that\ngrowth also comes with pruning. We complement the topological study by also\nconsidering publicly available user profile data (mostly geographic locations).\nThe corresponding results shed some light on the semantics of the triangle\nmotifs. Indeed, we find that users in more symmetric triangle motifs live\ncloser together, indicating more personal relationships. In contrast,\nasymmetric links in motifs often point to faraway users with a high in-degree\n(celebrities).\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04321"}}, {"publisher": {"name": ""}, "description": "  In this paper, we study the impact of different channel output feedback\narchitectures on the capacity of the two-user interference channel. For a\ntwo-user interference channel, a feedback link can exist between receivers and\ntransmitters in 9 canonical architectures (see Fig. 2), ranging from only one\nfeedback link to four feedback links. We derive the exact capacity region for\nthe symmetric deterministic interference channel and the constant-gap capacity\nregion for the symmetric Gaussian interference channel for all of the 9\narchitectures. We show that for a linear deterministic symmetric interference\nchannel, in the weak interference regime, all models of feedback, except the\none, which has only one of the receivers feeding back to its own transmitter,\nhave the identical capacity region. When only one of the receivers feeds back\nto its own transmitter, the capacity region is a strict subset of the capacity\nregion of the rest of the feedback models in the weak interference regime.\nHowever, the sum-capacity of all feedback models is identical in the weak\ninterference regime. Moreover, in the strong interference regime all models of\nfeedback with at least one of the receivers feeding back to its own transmitter\nhave the identical sum-capacity. For the Gaussian interference channel, the\nresults of the linear deterministic model follow, where capacity is replaced\nwith approximate capacity.\n", "contributors": [{"name": "Sahai, Achaleshwar", "sameAs": [], "familyName": "Sahai", "additionalName": "", "givenName": "Achaleshwar", "email": ""}, {"name": "Aggarwal, Vaneet", "sameAs": [], "familyName": "Aggarwal", "additionalName": "", "givenName": "Vaneet", "email": ""}, {"name": "Yuksel, Melda", "sameAs": [], "familyName": "Yuksel", "additionalName": "", "givenName": "Melda", "email": ""}, {"name": "Sabharwal, Ashutosh", "sameAs": [], "familyName": "Sabharwal", "additionalName": "", "givenName": "Ashutosh", "email": ""}], "title": "Capacity of All Nine Models of Channel Output Feedback for the Two-user\n  Interference Channel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-25", "2013-01-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.4805", "IEEE Transactions on Information Theory, vol.59, no.11,\n  pp.6957,6979, Nov. 2013", "doi:10.1109/TIT.2013.2278691", "oai:arXiv.org:1104.4805"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we study the impact of different channel output feedback\narchitectures on the capacity of the two-user interference channel. For a\ntwo-user interference channel, a feedback link can exist between receivers and\ntransmitters in 9 canonical architectures (see Fig. 2), ranging from only one\nfeedback link to four feedback links. We derive the exact capacity region for\nthe symmetric deterministic interference channel and the constant-gap capacity\nregion for the symmetric Gaussian interference channel for all of the 9\narchitectures. We show that for a linear deterministic symmetric interference\nchannel, in the weak interference regime, all models of feedback, except the\none, which has only one of the receivers feeding back to its own transmitter,\nhave the identical capacity region. When only one of the receivers feeds back\nto its own transmitter, the capacity region is a strict subset of the capacity\nregion of the rest of the feedback models in the weak interference regime.\nHowever, the sum-capacity of all feedback models is identical in the weak\ninterference regime. Moreover, in the strong interference regime all models of\nfeedback with at least one of the receivers feeding back to its own transmitter\nhave the identical sum-capacity. For the Gaussian interference channel, the\nresults of the linear deterministic model follow, where capacity is replaced\nwith approximate capacity.\n", "Comment: submitted to IEEE Transactions on Information Theory, results\n  improved by deriving capacity region of all 9 canonical feedback models in\n  two-user interference channel"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.4805"}}, {"publisher": {"name": ""}, "description": "abstract: Mobile ad hoc networks (MANETs) have attracted attention for mission critical applications. This dissertation investigates techniques of statistical monitoring and control for overhead reduction in a proactive MANET routing protocol. Proactive protocols transmit overhead periodically. Instead, we propose that the local conditions of a node should determine this transmission decision. While the goal is to minimize overhead, a balance in the amount of overhead transmitted and the performance achieved is required. Statistical monitoring consists of techniques to determine if a characteristic has shifted away from an in-control state. A basic tool for monitoring is a control chart, a time-oriented representation of the characteristic. When a sample deviates outside control limits, a significant change has occurred and corrective actions are required to return to the in-control state. We investigate the use of statistical monitoring of local conditions in the Optimized Link State Routing (OLSR) protocol. Three versions are developed. In A-OLSR, each node uses a Shewhart chart to monitor betweenness of its two-hop neighbourhood. Betweenness is a social network metric that measures a node's influence; betweenness is larger when a node has more influence. Changes in topology are associated with changes in betweenness. We incorporate additional local node conditions including speed, density, packet arrival rate, and number of flows it forwards in A+-OLSR. Response Surface Methodology (RSM) is used to optimize timer values. As well, the Shewhart chart is replaced by an Exponentially Weighted Moving Average (EWMA) chart, which is more sensitive to small changes in the characteristic. It is known that control charts do not work as well in the presence of correlation. Hence, in A*-OLSR the autocorrelation in the time series is removed and an Auto-Regressive Integrated Moving Average (ARIMA) model found; this removes the dependence on node speed. A*-OLSR also extends monitoring to two characteristics concurrently using multivariate cumulative sum (MCUSUM) charts. The protocols are evaluated in simulation, and compared to OLSR and its variants. The techniques for statistical monitoring and control are general and have great potential to be applied to the adaptive control of many network protocols.", "contributors": [{"name": "Shaukat, Kahkashan  (Author)", "sameAs": [], "familyName": "Shaukat", "additionalName": "", "givenName": "Kahkashan", "email": ""}, {"name": "Syrotiuk, Violet R (Advisor)", "sameAs": [], "familyName": "Syrotiuk", "additionalName": "R", "givenName": "Violet", "email": ""}, {"name": "Colbourn, Charles J (Committee member)", "sameAs": [], "familyName": "Colbourn", "additionalName": "J", "givenName": "Charles", "email": ""}, {"name": "Montgomery, Douglas C (Committee member)", "sameAs": [], "familyName": "Montgomery", "additionalName": "C", "givenName": "Douglas", "email": ""}, {"name": "Sarjoughian, Hessam S (Committee member)", "sameAs": [], "familyName": "Sarjoughian", "additionalName": "S", "givenName": "Hessam", "email": ""}, {"name": "Sen, Arunabha  (Committee member)", "sameAs": [], "familyName": "Sen", "additionalName": "", "givenName": "Arunabha", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Statistical Monitoring and Control of Locally Proactive Routing Protocols in MANETs", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "168 pages"}}, {"name": "date", "properties": {"date": "2012"}}, {"name": "description", "properties": {"description": ["abstract: Mobile ad hoc networks (MANETs) have attracted attention for mission critical applications. This dissertation investigates techniques of statistical monitoring and control for overhead reduction in a proactive MANET routing protocol. Proactive protocols transmit overhead periodically. Instead, we propose that the local conditions of a node should determine this transmission decision. While the goal is to minimize overhead, a balance in the amount of overhead transmitted and the performance achieved is required. Statistical monitoring consists of techniques to determine if a characteristic has shifted away from an in-control state. A basic tool for monitoring is a control chart, a time-oriented representation of the characteristic. When a sample deviates outside control limits, a significant change has occurred and corrective actions are required to return to the in-control state. We investigate the use of statistical monitoring of local conditions in the Optimized Link State Routing (OLSR) protocol. Three versions are developed. In A-OLSR, each node uses a Shewhart chart to monitor betweenness of its two-hop neighbourhood. Betweenness is a social network metric that measures a node's influence; betweenness is larger when a node has more influence. Changes in topology are associated with changes in betweenness. We incorporate additional local node conditions including speed, density, packet arrival rate, and number of flows it forwards in A+-OLSR. Response Surface Methodology (RSM) is used to optimize timer values. As well, the Shewhart chart is replaced by an Exponentially Weighted Moving Average (EWMA) chart, which is more sensitive to small changes in the characteristic. It is known that control charts do not work as well in the presence of correlation. Hence, in A*-OLSR the autocorrelation in the time series is removed and an Auto-Regressive Integrated Moving Average (ARIMA) model found; this removes the dependence on node speed. A*-OLSR also extends monitoring to two characteristics concurrently using multivariate cumulative sum (MCUSUM) charts. The protocols are evaluated in simulation, and compared to OLSR and its variants. The techniques for statistical monitoring and control are general and have great potential to be applied to the adaptive control of many network protocols.", "Dissertation/Thesis", "Ph.D. Computer Science 2012"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.14511", "item:14511"]}}], "languages": [null], "subjects": ["control charts", "multivariate control charts", "ewma charts", "statistical monitoring", "cusum charts", "computer science", "locally proactive protocols"], "providerUpdatedDateTime": "2015-02-12T01:13:14", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.14511"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Transmission of information from DNA to RNA to protein underlies the core of modem life forms. The advance in sequencing and genetic technologies has revolutionized the study of molecular biology, genetics and developmental biology enabling delineation of biological processes in unprecedented details. Through the study of epigenetics and posttranscriptional regulation of gene expression by high-throughput sequencing technologies in several biological processes, namely embryonic stem cells, somatic reprogramming, erythroid differentiation, epithelial-mesenchymal transition and cancer metastasis, this thesis work has identified novel players and regulatory mechanisms underlying these developmental processes and diseases. Furthermore, an attempt to engineer CRISPRzymes - protein fusions of RNA-guided DNA binding dCas9 - will enable experiments to directly test biological processes at defined genomic loci and expands the toolbox for synthetic biology and potentially opens up opportunities for novel therapeutics.", "contributors": [{"name": "Cheng, Wu Albert", "sameAs": [], "familyName": "Cheng", "additionalName": "Albert", "givenName": "Wu", "email": ""}, {"name": "Massachusetts Institute of Technology. Computational and Systems Biology Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computational and Systems Biology", "givenName": "Massachusetts", "email": ""}, {"name": "Rudolf Jaenisch.", "sameAs": [], "familyName": "Jaenisch.", "additionalName": "", "givenName": "Rudolf", "email": ""}], "title": "Epigenetic and post-transcriptional regulation of gene expression in pluripotent stem cells, differentiation and metastasis", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "309 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/91122", "892972629", "oai:dspace.mit.edu:1721.1/91122"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2014-10-21T17:27:36Z", "2014-10-21T17:27:36Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["Transmission of information from DNA to RNA to protein underlies the core of modem life forms. The advance in sequencing and genetic technologies has revolutionized the study of molecular biology, genetics and developmental biology enabling delineation of biological processes in unprecedented details. Through the study of epigenetics and posttranscriptional regulation of gene expression by high-throughput sequencing technologies in several biological processes, namely embryonic stem cells, somatic reprogramming, erythroid differentiation, epithelial-mesenchymal transition and cancer metastasis, this thesis work has identified novel players and regulatory mechanisms underlying these developmental processes and diseases. Furthermore, an attempt to engineer CRISPRzymes - protein fusions of RNA-guided DNA binding dCas9 - will enable experiments to directly test biological processes at defined genomic loci and expands the toolbox for synthetic biology and potentially opens up opportunities for novel therapeutics.", "by Wu Albert Cheng.", "Thesis: Ph. D., Massachusetts Institute of Technology, Computational and Systems Biology Program, 2014.", "Cataloged from PDF version of thesis.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_54828", "hdl_1721.1_54823"]}}], "languages": [null], "subjects": ["computational and systems biology program."], "providerUpdatedDateTime": "2015-04-27T14:53:07", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/91122"}}, {"publisher": {"name": ""}, "description": "  This paper introduces constrained mixtures for continuous distributions,\ncharacterized by a mixture of distributions where each distribution has a shape\nsimilar to the base distribution and disjoint domains. This new concept is used\nto create generalized asymmetric versions of the Laplace and normal\ndistributions, which are shown to define exponential families, with known\nconjugate priors, and to have maximum likelihood estimates for the original\nparameters, with known closed-form expressions. The asymmetric and symmetric\nnormal distributions are compared in a linear regression example, showing that\nthe asymmetric version performs at least as well as the symmetric one, and in a\nreal world time-series problem, where a hidden Markov model is used to fit a\nstock index, indicating that the asymmetric version provides higher likelihood\nand may learn distribution models over states and transition distributions with\nconsiderably less entropy.\n", "contributors": [{"name": "Miranda, Conrado S.", "sameAs": [], "familyName": "Miranda", "additionalName": "S.", "givenName": "Conrado", "email": ""}, {"name": "Von Zuben, Fernando J.", "sameAs": [], "familyName": "Von Zuben", "additionalName": "J.", "givenName": "Fernando", "email": ""}], "title": "Asymmetric Distributions from Constrained Mixtures", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06429", "oai:arXiv.org:1503.06429"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  This paper introduces constrained mixtures for continuous distributions,\ncharacterized by a mixture of distributions where each distribution has a shape\nsimilar to the base distribution and disjoint domains. This new concept is used\nto create generalized asymmetric versions of the Laplace and normal\ndistributions, which are shown to define exponential families, with known\nconjugate priors, and to have maximum likelihood estimates for the original\nparameters, with known closed-form expressions. The asymmetric and symmetric\nnormal distributions are compared in a linear regression example, showing that\nthe asymmetric version performs at least as well as the symmetric one, and in a\nreal world time-series problem, where a hidden Markov model is used to fit a\nstock index, indicating that the asymmetric version provides higher likelihood\nand may learn distribution models over states and transition distributions with\nconsiderably less entropy.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06429"}}, {"publisher": {"name": ""}, "description": "  We illustrate the use of tools (asymptotic theories of standard error\nquantification using appropriate statistical models, bootstrapping, model\ncomparison techniques) in addition to sensitivity that may be employed to\ndetermine the information content in data sets. We do this in the context of\nrecent models [23] for nucleated polymerization in proteins, about which very\nlittle is known regarding the underlying mechanisms; thus the methodology we\ndevelop here may be of great help to experimentalists.\n", "contributors": [{"name": "Banks, H. T.", "sameAs": [], "familyName": "Banks", "additionalName": "T.", "givenName": "H.", "email": ""}, {"name": "Doumic, M", "sameAs": [], "familyName": "Doumic", "additionalName": "", "givenName": "M", "email": ""}, {"name": "Kruse, C", "sameAs": [], "familyName": "Kruse", "additionalName": "", "givenName": "C", "email": ""}, {"name": "Prigent, S", "sameAs": [], "familyName": "Prigent", "additionalName": "", "givenName": "S", "email": ""}, {"name": "Rezaei, H", "sameAs": [], "familyName": "Rezaei", "additionalName": "", "givenName": "H", "email": ""}], "title": "Information Content in Data Sets for a Nucleated-Polymerization Model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04682", "oai:arXiv.org:1503.04682"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  We illustrate the use of tools (asymptotic theories of standard error\nquantification using appropriate statistical models, bootstrapping, model\ncomparison techniques) in addition to sensitivity that may be employed to\ndetermine the information content in data sets. We do this in the context of\nrecent models [23] for nucleated polymerization in proteins, about which very\nlittle is known regarding the underlying mechanisms; thus the methodology we\ndevelop here may be of great help to experimentalists.\n"}}], "languages": [null], "subjects": ["statistics - applications", "computer science - computational engineering", "mathematics - analysis of pdes", "finance", "and science"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04682"}}, {"publisher": {"name": ""}, "description": "  Marcus, Spielman, and Srivastava in their seminal work [MSS13] resolved the\nKadison-Singer conjecture by proving that the sum of any set of finitely\nsupported independently distributed random vectors with \"small\" expected\nsquared norm that are in isotropic position (in expectation) attains a \"small\"\nspectral norm with a nonzero probability. Their proof crucially employs real\nstability of polynomials which is the natural generalization of real-rootedness\nto multivariate polynomials.\n  Strongly Rayleigh distributions are families of probability distributions\nwhose generating polynomials are real stable [BBL09]. As independent\ndistributions are just special cases of strongly Rayleigh measures, it is a\nnatural question to see if the main theorem of [MSS13] can be extended to\nfamilies of vectors assigned to the elements of a strongly Rayleigh\ndistribution.\n  In this paper we answer this question affirmatively; we show that for any\nhomogeneous strongly Rayleigh distribution where the marginal probabilities are\nupper bounded by $\\epsilon_1$ and any isotropic set of vectors assigned to the\nunderlying elements whose norms are at most $\\sqrt{\\epsilon_2}$, there is a set\nin the support of the distribution such that the spectral norm of the sum of\nthe vectors assigned to the elements of the set is at most\n$O(\\epsilon_1+\\epsilon_2)$. We employ our theorem to provide a sufficient\ncondition for the existence of spectrally thin trees. This, together with a\nrecent work of the authors, provide an improved upper bound on the integrality\ngap of the natural LP relaxation of the Asymmetric Traveling Salesman Problem.\n", "contributors": [{"name": "Anari, Nima", "sameAs": [], "familyName": "Anari", "additionalName": "", "givenName": "Nima", "email": ""}, {"name": "Gharan, Shayan Oveis", "sameAs": [], "familyName": "Gharan", "additionalName": "Oveis", "givenName": "Shayan", "email": ""}], "title": "The Kadison-Singer Problem for Strongly Rayleigh Measures and\n  Applications to Asymmetric TSP", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1143", "oai:arXiv.org:1412.1143"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Marcus, Spielman, and Srivastava in their seminal work [MSS13] resolved the\nKadison-Singer conjecture by proving that the sum of any set of finitely\nsupported independently distributed random vectors with \"small\" expected\nsquared norm that are in isotropic position (in expectation) attains a \"small\"\nspectral norm with a nonzero probability. Their proof crucially employs real\nstability of polynomials which is the natural generalization of real-rootedness\nto multivariate polynomials.\n  Strongly Rayleigh distributions are families of probability distributions\nwhose generating polynomials are real stable [BBL09]. As independent\ndistributions are just special cases of strongly Rayleigh measures, it is a\nnatural question to see if the main theorem of [MSS13] can be extended to\nfamilies of vectors assigned to the elements of a strongly Rayleigh\ndistribution.\n  In this paper we answer this question affirmatively; we show that for any\nhomogeneous strongly Rayleigh distribution where the marginal probabilities are\nupper bounded by $\\epsilon_1$ and any isotropic set of vectors assigned to the\nunderlying elements whose norms are at most $\\sqrt{\\epsilon_2}$, there is a set\nin the support of the distribution such that the spectral norm of the sum of\nthe vectors assigned to the elements of the set is at most\n$O(\\epsilon_1+\\epsilon_2)$. We employ our theorem to provide a sufficient\ncondition for the existence of spectrally thin trees. This, together with a\nrecent work of the authors, provide an improved upper bound on the integrality\ngap of the natural LP relaxation of the Asymmetric Traveling Salesman Problem.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - combinatorics", "mathematics - probability"], "providerUpdatedDateTime": "2014-12-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1143"}}, {"publisher": {"name": ""}, "description": "  A stochastic combinatorial semi-bandit is an online learning problem where at\neach step a learning agent chooses a subset of ground items subject to\nconstraints, and then observes stochastic weights of these items and receives\ntheir sum as a payoff. In this paper, we close the problem of computationally\nand sample efficient learning in stochastic combinatorial semi-bandits. In\nparticular, we analyze a UCB-like algorithm for solving the problem, which is\nknown to be computationally efficient; and prove $O(K L (1 / \\Delta) \\log n)$\nand $O(\\sqrt{K L n \\log n})$ upper bounds on its $n$-step regret, where $L$ is\nthe number of ground items, $K$ is the maximum number of chosen items, and\n$\\Delta$ is the gap between the expected returns of the optimal and best\nsuboptimal solutions. The gap-dependent bound is tight up to a constant factor\nand the gap-free bound is tight up to a polylogarithmic factor.\n", "contributors": [{"name": "Kveton, Branislav", "sameAs": [], "familyName": "Kveton", "additionalName": "", "givenName": "Branislav", "email": ""}, {"name": "Wen, Zheng", "sameAs": [], "familyName": "Wen", "additionalName": "", "givenName": "Zheng", "email": ""}, {"name": "Ashkan, Azin", "sameAs": [], "familyName": "Ashkan", "additionalName": "", "givenName": "Azin", "email": ""}, {"name": "Szepesvari, Csaba", "sameAs": [], "familyName": "Szepesvari", "additionalName": "", "givenName": "Csaba", "email": ""}], "title": "Tight Regret Bounds for Stochastic Combinatorial Semi-Bandits", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-03", "2015-01-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.0949", "oai:arXiv.org:1410.0949"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  A stochastic combinatorial semi-bandit is an online learning problem where at\neach step a learning agent chooses a subset of ground items subject to\nconstraints, and then observes stochastic weights of these items and receives\ntheir sum as a payoff. In this paper, we close the problem of computationally\nand sample efficient learning in stochastic combinatorial semi-bandits. In\nparticular, we analyze a UCB-like algorithm for solving the problem, which is\nknown to be computationally efficient; and prove $O(K L (1 / \\Delta) \\log n)$\nand $O(\\sqrt{K L n \\log n})$ upper bounds on its $n$-step regret, where $L$ is\nthe number of ground items, $K$ is the maximum number of chosen items, and\n$\\Delta$ is the gap between the expected returns of the optimal and best\nsuboptimal solutions. The gap-dependent bound is tight up to a constant factor\nand the gap-free bound is tight up to a polylogarithmic factor.\n", "Comment: Proceedings of the 18th International Conference on Artificial\n  Intelligence and Statistics"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.0949"}}, {"publisher": {"name": ""}, "description": "  Exchangeable random partition processes are the basis for Bayesian approaches\nto statistical inference in large alphabet settings. On the other hand, the\nnotion of the pattern of a sequence provides an information-theoretic framework\nfor data compression in large alphabet scenarios. Because data compression and\nparameter estimation are intimately related, we study the redundancy of Bayes\nestimators coming from Poisson-Dirichlet priors (or \"Chinese restaurant\nprocesses\") and the Pitman-Yor prior. This provides an understanding of these\nestimators in the setting of unknown discrete alphabets from the perspective of\nuniversal compression. In particular, we identify relations between alphabet\nsizes and sample sizes where the redundancy is small, thereby characterizing\nuseful regimes for these estimators.\n", "contributors": [{"name": "Santhanam, Narayana P.", "sameAs": [], "familyName": "Santhanam", "additionalName": "P.", "givenName": "Narayana", "email": ""}, {"name": "Sarwate, Anand D.", "sameAs": [], "familyName": "Sarwate", "additionalName": "D.", "givenName": "Anand", "email": ""}, {"name": "Woo, Jae Oh", "sameAs": [], "familyName": "Woo", "additionalName": "Oh", "givenName": "Jae", "email": ""}], "title": "Redundancy of Exchangeable Estimators", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-21", "2014-10-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.5383", "oai:arXiv.org:1407.5383"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Exchangeable random partition processes are the basis for Bayesian approaches\nto statistical inference in large alphabet settings. On the other hand, the\nnotion of the pattern of a sequence provides an information-theoretic framework\nfor data compression in large alphabet scenarios. Because data compression and\nparameter estimation are intimately related, we study the redundancy of Bayes\nestimators coming from Poisson-Dirichlet priors (or \"Chinese restaurant\nprocesses\") and the Pitman-Yor prior. This provides an understanding of these\nestimators in the setting of unknown discrete alphabets from the perspective of\nuniversal compression. In particular, we identify relations between alphabet\nsizes and sample sizes where the redundancy is small, thereby characterizing\nuseful regimes for these estimators.\n", "Comment: 18 pages"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.5383"}}, {"publisher": {"name": ""}, "description": "  In the Red-Blue Dominating Set problem, we are given a bipartite graph $G =\n(V_B \\cup V_R,E)$ and an integer $k$, and asked whether $G$ has a subset $D\n\\subseteq V_B$ of at most $k$ \"blue\" vertices such that each \"red\" vertex from\n$V_R$ is adjacent to a vertex in $D$. We provide the first explicit linear\nkernel for this problem on planar graphs, of size at most $46k$.\n", "contributors": [{"name": "Garnero, Valentin", "sameAs": [], "familyName": "Garnero", "additionalName": "", "givenName": "Valentin", "email": ""}, {"name": "Sau, Ignasi", "sameAs": [], "familyName": "Sau", "additionalName": "", "givenName": "Ignasi", "email": ""}, {"name": "Thilikos, Dimitrios M.", "sameAs": [], "familyName": "Thilikos", "additionalName": "M.", "givenName": "Dimitrios", "email": ""}], "title": "A linear kernel for planar red-blue dominating set", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-27", "2015-01-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6388", "oai:arXiv.org:1408.6388"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In the Red-Blue Dominating Set problem, we are given a bipartite graph $G =\n(V_B \\cup V_R,E)$ and an integer $k$, and asked whether $G$ has a subset $D\n\\subseteq V_B$ of at most $k$ \"blue\" vertices such that each \"red\" vertex from\n$V_R$ is adjacent to a vertex in $D$. We provide the first explicit linear\nkernel for this problem on planar graphs, of size at most $46k$.\n", "Comment: 15 pages, 4 figures"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "05c10", "05c85", "g.2.2"], "providerUpdatedDateTime": "2015-01-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6388"}}, {"publisher": {"name": ""}, "description": "  A topological constraint on the possible values of the universal quantization\nparameter is revealed in the case of geometric quantization on (boundary)\ncurves diffeomorphic to $S^1$, analytically extended on a bounded domain in\n$\\mathbb{C}$, with $n \\ge 2$ boundary components. Unlike the case of one\nboundary component (such as the canonical Berezin quantization of the\nPoincar\\'e upper-half plane or the case of conformally-invariant 2D systems),\nthe more general case considered here leads to a strictly positive minimum\nvalue for the quantization parameter, which depends on the geometrical data of\nthe domain (specifically, the total area and total perimeter in the smooth\ncase). It is proven that if the lower bound is attained, then $n=2$ and the\ndomain must be annular, with a direct interpretation in terms of the global\nmonodromy.\n", "contributors": [{"name": "Teodorescu, Razvan", "sameAs": [], "familyName": "Teodorescu", "additionalName": "", "givenName": "Razvan", "email": ""}], "title": "Topological constraints in geometric deformation quantization on domains\n  with multiple boundary components", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7716", "oai:arXiv.org:1412.7716"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "physics:hep-th", "physics:math-ph"]}}, {"name": "description", "properties": {"description": "  A topological constraint on the possible values of the universal quantization\nparameter is revealed in the case of geometric quantization on (boundary)\ncurves diffeomorphic to $S^1$, analytically extended on a bounded domain in\n$\\mathbb{C}$, with $n \\ge 2$ boundary components. Unlike the case of one\nboundary component (such as the canonical Berezin quantization of the\nPoincar\\'e upper-half plane or the case of conformally-invariant 2D systems),\nthe more general case considered here leads to a strictly positive minimum\nvalue for the quantization parameter, which depends on the geometrical data of\nthe domain (specifically, the total area and total perimeter in the smooth\ncase). It is proven that if the lower bound is attained, then $n=2$ and the\ndomain must be annular, with a direct interpretation in terms of the global\nmonodromy.\n"}}], "languages": [null], "subjects": ["high energy physics - theory", "11f99", "81s99", "mathematical physics", "mathematics - complex variables", "mathematics - operator algebras", "46l37", "46l35"], "providerUpdatedDateTime": "2014-12-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7716"}}, {"publisher": {"name": ""}, "description": "  This paper presents generalized probabilistic models for high-order\nprojective dependency parsing and an algorithmic framework for learning these\nstatistical models involving dependency trees. Partition functions and\nmarginals for high-order dependency trees can be computed efficiently, by\nadapting our algorithms which extend the inside-outside algorithm to\nhigher-order cases. To show the effectiveness of our algorithms, we perform\nexperiments on three languages---English, Chinese and Czech, using maximum\nconditional likelihood estimation for model training and L-BFGS for parameter\nestimation. Our methods achieve competitive performance for English, and\noutperform all previously reported dependency parsers for Chinese and Czech.\n", "contributors": [{"name": "Ma, Xuezhe", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Xuezhe", "email": ""}, {"name": "Zhao, Hai", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Hai", "email": ""}], "title": "Probabilistic Models for High-Order Projective Dependency Parsing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04174", "oai:arXiv.org:1502.04174"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper presents generalized probabilistic models for high-order\nprojective dependency parsing and an algorithmic framework for learning these\nstatistical models involving dependency trees. Partition functions and\nmarginals for high-order dependency trees can be computed efficiently, by\nadapting our algorithms which extend the inside-outside algorithm to\nhigher-order cases. To show the effectiveness of our algorithms, we perform\nexperiments on three languages---English, Chinese and Czech, using maximum\nconditional likelihood estimation for model training and L-BFGS for parameter\nestimation. Our methods achieve competitive performance for English, and\noutperform all previously reported dependency parsers for Chinese and Czech.\n"}}], "languages": [null], "subjects": ["computer science - computation and language"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04174"}}, {"publisher": {"name": ""}, "description": "  Microcanonical thermostatistics analysis has become an important tool to\nreveal essential aspects of phase transitions in complex systems. An efficient\nway to estimate the microcanonical inverse temperature $\\beta(E)$ and the\nmicrocanonical entropy $S(E)$ is achieved with the statistical temperature\nweighted histogram analysis method (ST-WHAM). The strength of this method lies\non its flexibility, as it can be used to analyse data produced by algorithms\nwith generalised sampling weights. However, for any sampling weight, ST-WHAM\nrequires the calculation of derivatives of energy histograms $H(E)$, which\nleads to non-trivial and tedious binning tasks for models with continuous\nenergy spectrum such as those for biomolecular and colloidal systems. Here, we\ndiscuss two alternative methods that avoid the need for such energy binning to\nobtain continuous estimates for $H(E)$ in order to evaluate $\\beta(E)$ by using\nST-WHAM: (i) a series expansion to estimate probability densities from the\nempirical cumulative distribution function (CDF), and (ii) a Bayesian approach\nto model this CDF. Comparison with a simple linear regression method is also\ncarried out. The performance of these approaches is evaluated considering\ncoarse-grained protein models for folding and peptide aggregation.\n", "contributors": [{"name": "Alves, Nelson A.", "sameAs": [], "familyName": "Alves", "additionalName": "A.", "givenName": "Nelson", "email": ""}, {"name": "Morero, Lucas D.", "sameAs": [], "familyName": "Morero", "additionalName": "D.", "givenName": "Lucas", "email": ""}, {"name": "Rizzi, Leandro G.", "sameAs": [], "familyName": "Rizzi", "additionalName": "G.", "givenName": "Leandro", "email": ""}], "title": "Microcanonical thermostatistics analysis without histograms: cumulative\n  distribution and Bayesian approaches", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07964", "doi:10.1016/j.cpc.2015.02.010", "oai:arXiv.org:1502.07964"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Microcanonical thermostatistics analysis has become an important tool to\nreveal essential aspects of phase transitions in complex systems. An efficient\nway to estimate the microcanonical inverse temperature $\\beta(E)$ and the\nmicrocanonical entropy $S(E)$ is achieved with the statistical temperature\nweighted histogram analysis method (ST-WHAM). The strength of this method lies\non its flexibility, as it can be used to analyse data produced by algorithms\nwith generalised sampling weights. However, for any sampling weight, ST-WHAM\nrequires the calculation of derivatives of energy histograms $H(E)$, which\nleads to non-trivial and tedious binning tasks for models with continuous\nenergy spectrum such as those for biomolecular and colloidal systems. Here, we\ndiscuss two alternative methods that avoid the need for such energy binning to\nobtain continuous estimates for $H(E)$ in order to evaluate $\\beta(E)$ by using\nST-WHAM: (i) a series expansion to estimate probability densities from the\nempirical cumulative distribution function (CDF), and (ii) a Bayesian approach\nto model this CDF. Comparison with a simple linear regression method is also\ncarried out. The performance of these approaches is evaluated considering\ncoarse-grained protein models for folding and peptide aggregation.\n", "Comment: 9 pages, 11 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "condensed matter - statistical mechanics", "physics - biological physics"], "providerUpdatedDateTime": "2015-03-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07964"}}, {"publisher": {"name": ""}, "description": "  We study asymptotic distribution of zeros of random holomorphic sections of\nhigh powers of positive line bundles defined over projective homogenous\nmanifolds. We work with a wide class of distributions that includes real and\ncomplex Gaussians. As a special case, we obtain asymptotic zero distribution of\nensembles of orthogonal polynomials. Namely, we prove that normalized zero\nmeasures of m i.i.d random polynomials, orthonormalized on a regular compact\nset $K\\subset \\Bbb{C}^m,$ are almost surely asymptotic to the equilibrium\nmeasure of $K$.\n", "contributors": [{"name": "Bayraktar, Turgay", "sameAs": [], "familyName": "Bayraktar", "additionalName": "", "givenName": "Turgay", "email": ""}], "title": "Equidistribution of zeros of random holomorphic sections", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-03", "2015-02-23"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.0933", "oai:arXiv.org:1312.0933"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We study asymptotic distribution of zeros of random holomorphic sections of\nhigh powers of positive line bundles defined over projective homogenous\nmanifolds. We work with a wide class of distributions that includes real and\ncomplex Gaussians. As a special case, we obtain asymptotic zero distribution of\nensembles of orthogonal polynomials. Namely, we prove that normalized zero\nmeasures of m i.i.d random polynomials, orthonormalized on a regular compact\nset $K\\subset \\Bbb{C}^m,$ are almost surely asymptotic to the equilibrium\nmeasure of $K$.\n", "Comment: Minor revisions and corrections. Some examples and references added.\n  26 pages"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - probability", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.0933"}}, {"publisher": {"name": ""}, "description": "  This study investigates the significance of Rogers Diffusion of Innovations\n(DOI) theory with regard to the use of a Virtual Learning Environment (VLE) at\nthe Royal University of Bhutan (RUB). The focus is on different adoption types\nand characteristics of users. Rogers DOI theory is applied to investigate the\ninfluence of five predictors (relative advantage, complexity, compatibility,\ntrialability and observability) and their significance in the perception of\nacademic staff at the RUB in relation to the probability of VLE adoption. These\npredictors are attributes of the VLE that determine the rate of adoption by\nvarious adopter group memberships (Innovators, Early Adopters, Early Majority,\nLate Majority, Laggards). Descriptive statistics and regression analysis were\ndeployed to analyse adopter group memberships and predictor significance in VLE\nadoption and use. The results reveal varying attitudes towards VLE adoption by\nacademic staff at RUB. Few predictors are consistent with previous research on\nVLE adoption. There are also significant differences from previous research on\npredictors such as the deviation in adopter frequency from that predicted by\nRogers DOI theory. Therefore, it can be concluded that it is misleading to rely\non the DOI theory in the way it is currently operationalised for predicting VLE\nuse.\n", "contributors": [{"name": "Penjor, Sonam", "sameAs": [], "familyName": "Penjor", "additionalName": "", "givenName": "Sonam", "email": ""}, {"name": "Zander, Par-Ola", "sameAs": [], "familyName": "Zander", "additionalName": "", "givenName": "Par-Ola", "email": ""}], "title": "Predictors for the Adoption of Virtual Learning Environments - a Case\n  Study from Bhutan", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02408", "oai:arXiv.org:1503.02408"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This study investigates the significance of Rogers Diffusion of Innovations\n(DOI) theory with regard to the use of a Virtual Learning Environment (VLE) at\nthe Royal University of Bhutan (RUB). The focus is on different adoption types\nand characteristics of users. Rogers DOI theory is applied to investigate the\ninfluence of five predictors (relative advantage, complexity, compatibility,\ntrialability and observability) and their significance in the perception of\nacademic staff at the RUB in relation to the probability of VLE adoption. These\npredictors are attributes of the VLE that determine the rate of adoption by\nvarious adopter group memberships (Innovators, Early Adopters, Early Majority,\nLate Majority, Laggards). Descriptive statistics and regression analysis were\ndeployed to analyse adopter group memberships and predictor significance in VLE\nadoption and use. The results reveal varying attitudes towards VLE adoption by\nacademic staff at RUB. Few predictors are consistent with previous research on\nVLE adoption. There are also significant differences from previous research on\npredictors such as the deviation in adopter frequency from that predicted by\nRogers DOI theory. Therefore, it can be concluded that it is misleading to rely\non the DOI theory in the way it is currently operationalised for predicting VLE\nuse.\n", "Comment: In review - comments welcome also from other colleagues!"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02408"}}, {"publisher": {"name": ""}, "description": "  Bloom filters are probabilistic data structures commonly used for approximate\nmembership problems in many areas of Computer Science (networking, distributed\nsystems, databases, etc.). With the increase in data size and distribution of\ndata, problems arise where a large number of Bloom filters are available, and\nall them need to be searched for potential matches. As an example, in a\nfederated cloud environment, each cloud provider could encode the information\nusing Bloom filters and share the Bloom filters with a central coordinator. The\nproblem of interest is not only whether a given element is in any of the sets\nrepresented by the Bloom filters, but which of the existing sets contain the\ngiven element. This problem cannot be solved by just constructing a Bloom\nfilter on the union of all the sets. Instead, we effectively have a\nmultidimensional Bloom filter problem: given an element, we wish to receive a\nlist of candidate sets where the element might be.\n  To solve this problem, we consider 3 alternatives. Firstly, we can naively\ncheck many Bloom filters. Secondly, we propose to organize the Bloom filters in\na hierarchical index structure akin to a B+ tree, that we call Bloofi. Finally,\nwe propose another data structure that packs the Bloom filters in such a way as\nto exploit bit-level parallelism, which we call Flat-Bloofi.\n  Our theoretical and experimental results show that Bloofi and Flat-Bloofi\nprovide scalable and efficient solutions alternatives to search through a large\nnumber of Bloom filters.\n", "contributors": [{"name": "Crainiceanu, Adina", "sameAs": [], "familyName": "Crainiceanu", "additionalName": "", "givenName": "Adina", "email": ""}, {"name": "Lemire, Daniel", "sameAs": [], "familyName": "Lemire", "additionalName": "", "givenName": "Daniel", "email": ""}], "title": "Bloofi: Multidimensional Bloom Filters", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-08", "2015-02-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.01941", "doi:10.1016/j.is.2015.01.002", "oai:arXiv.org:1501.01941"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Bloom filters are probabilistic data structures commonly used for approximate\nmembership problems in many areas of Computer Science (networking, distributed\nsystems, databases, etc.). With the increase in data size and distribution of\ndata, problems arise where a large number of Bloom filters are available, and\nall them need to be searched for potential matches. As an example, in a\nfederated cloud environment, each cloud provider could encode the information\nusing Bloom filters and share the Bloom filters with a central coordinator. The\nproblem of interest is not only whether a given element is in any of the sets\nrepresented by the Bloom filters, but which of the existing sets contain the\ngiven element. This problem cannot be solved by just constructing a Bloom\nfilter on the union of all the sets. Instead, we effectively have a\nmultidimensional Bloom filter problem: given an element, we wish to receive a\nlist of candidate sets where the element might be.\n  To solve this problem, we consider 3 alternatives. Firstly, we can naively\ncheck many Bloom filters. Secondly, we propose to organize the Bloom filters in\na hierarchical index structure akin to a B+ tree, that we call Bloofi. Finally,\nwe propose another data structure that packs the Bloom filters in such a way as\nto exploit bit-level parallelism, which we call Flat-Bloofi.\n  Our theoretical and experimental results show that Bloofi and Flat-Bloofi\nprovide scalable and efficient solutions alternatives to search through a large\nnumber of Bloom filters.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - databases"], "providerUpdatedDateTime": "2015-02-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.01941"}}, {"publisher": {"name": ""}, "description": "  We show that if $(X_t,\\mathcal{F}_t)_t$ is a family of foliations with\nreduced singularities on a smooth family of surfaces, then invariance of\nplurigenera holds for sufficiently large $m$. On the other hand, we provide\nexamples on which the result fails, for small values of $m$.\n", "contributors": [{"name": "Cascini, Paolo", "sameAs": [], "familyName": "Cascini", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Floris, Enrica", "sameAs": [], "familyName": "Floris", "additionalName": "", "givenName": "Enrica", "email": ""}], "title": "On invariance of plurigenera for foliations on surfaces", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.00817", "oai:arXiv.org:1502.00817"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We show that if $(X_t,\\mathcal{F}_t)_t$ is a family of foliations with\nreduced singularities on a smooth family of surfaces, then invariance of\nplurigenera holds for sufficiently large $m$. On the other hand, we provide\nexamples on which the result fails, for small values of $m$.\n", "Comment: 33 pages"]}}], "languages": [null], "subjects": ["37f75", "mathematics - complex variables", "14j99", "32l10", "mathematics - algebraic geometry", "14d06", "32g10"], "providerUpdatedDateTime": "2015-02-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.00817"}}, {"publisher": {"name": ""}, "description": "  The analysis of astronomical images is a non-trivial task. The D3PO algorithm\naddresses the inference problem of denoising, deconvolving, and decomposing\nphoton observations. Its primary goal is the simultaneous but individual\nreconstruction of the diffuse and point-like photon flux given a single photon\ncount image, where the fluxes are superimposed. In order to discriminate\nbetween these morphologically different signal components, a probabilistic\nalgorithm is derived in the language of information field theory based on a\nhierarchical Bayesian parameter model. The signal inference exploits prior\ninformation on the spatial correlation structure of the diffuse component and\nthe brightness distribution of the spatially uncorrelated point-like sources. A\nmaximum a posteriori solution and a solution minimizing the Gibbs free energy\nof the inference problem using variational Bayesian methods are discussed.\nSince the derivation of the solution is not dependent on the underlying\nposition space, the implementation of the D3PO algorithm uses the NIFTY package\nto ensure applicability to various spatial grids and at any resolution. The\nfidelity of the algorithm is validated by the analysis of simulated data,\nincluding a realistic high energy photon count image showing a 32 x 32 arcmin^2\nobservation with a spatial resolution of 0.1 arcmin. In all tests the D3PO\nalgorithm successfully denoised, deconvolved, and decomposed the data into a\ndiffuse and a point-like signal estimate for the respective photon flux\ncomponents.\n", "contributors": [{"name": "Selig, Marco", "sameAs": [], "familyName": "Selig", "additionalName": "", "givenName": "Marco", "email": ""}, {"name": "En\u00dflin, Torsten", "sameAs": [], "familyName": "En\u00dflin", "additionalName": "", "givenName": "Torsten", "email": ""}], "title": "D$^3$PO - Denoising, Deconvolving, and Decomposing Photon Observations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-11-08", "2015-01-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1311.1888", "A&A 574, A74 (2015)", "doi:10.1051/0004-6361/201323006", "oai:arXiv.org:1311.1888"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:astro-ph", "physics:physics", "stat"]}}, {"name": "description", "properties": {"description": ["  The analysis of astronomical images is a non-trivial task. The D3PO algorithm\naddresses the inference problem of denoising, deconvolving, and decomposing\nphoton observations. Its primary goal is the simultaneous but individual\nreconstruction of the diffuse and point-like photon flux given a single photon\ncount image, where the fluxes are superimposed. In order to discriminate\nbetween these morphologically different signal components, a probabilistic\nalgorithm is derived in the language of information field theory based on a\nhierarchical Bayesian parameter model. The signal inference exploits prior\ninformation on the spatial correlation structure of the diffuse component and\nthe brightness distribution of the spatially uncorrelated point-like sources. A\nmaximum a posteriori solution and a solution minimizing the Gibbs free energy\nof the inference problem using variational Bayesian methods are discussed.\nSince the derivation of the solution is not dependent on the underlying\nposition space, the implementation of the D3PO algorithm uses the NIFTY package\nto ensure applicability to various spatial grids and at any resolution. The\nfidelity of the algorithm is validated by the analysis of simulated data,\nincluding a realistic high energy photon count image showing a 32 x 32 arcmin^2\nobservation with a spatial resolution of 0.1 arcmin. In all tests the D3PO\nalgorithm successfully denoised, deconvolved, and decomposed the data into a\ndiffuse and a point-like signal estimate for the respective photon flux\ncomponents.\n", "Comment: 22 pages, 8 figures, 2 tables, accepted by Astronomy & Astrophysics;\n  refereed version, 1 figure added, results unchanged, software available at\n  http://www.mpa-garching.mpg.de/ift/d3po/"]}}], "languages": [null], "subjects": ["statistics and probability", "statistics - computation", "computer science - information theory", "astrophysics - instrumentation and methods for astrophysics", "physics - data analysis"], "providerUpdatedDateTime": "2015-01-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1311.1888"}}, {"publisher": {"name": ""}, "description": "  Inspired by the chemical metaphor, this paper proposes an extension of\nLinda-like languages in the aim of modeling the coordination of complex\ndistributed systems. The new language manipulates finite sets of tuples and\ndistributes a density among them. This new concept adds to the non-determinism\ninherent in the selection of matched tuples a non-determinism to the tell, ask\nand get primitives on the consideration of different tuples. Furthermore,\nthanks to de Boer and Palamidessi's notion of modular embedding, we establish\nthat this new language strictly increases the expressiveness of the Dense Bach\nlanguage introduced earlier and, consequently, Linda-like languages.\n", "contributors": [{"name": "Darquennes, Denis", "sameAs": [], "familyName": "Darquennes", "additionalName": "", "givenName": "Denis", "email": ""}, {"name": "Jacquet, Jean-Marie", "sameAs": [], "familyName": "Jacquet", "additionalName": "", "givenName": "Jean-Marie", "email": ""}, {"name": "Linden, Isabelle", "sameAs": [], "familyName": "Linden", "additionalName": "", "givenName": "Isabelle", "email": ""}], "title": "On Distributed Density in Tuple-based Coordination Languages", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03513", "EPTCS 175, 2015, pp. 36-53", "doi:10.4204/EPTCS.175.3", "oai:arXiv.org:1502.03513"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Inspired by the chemical metaphor, this paper proposes an extension of\nLinda-like languages in the aim of modeling the coordination of complex\ndistributed systems. The new language manipulates finite sets of tuples and\ndistributes a density among them. This new concept adds to the non-determinism\ninherent in the selection of matched tuples a non-determinism to the tell, ask\nand get primitives on the consideration of different tuples. Furthermore,\nthanks to de Boer and Palamidessi's notion of modular embedding, we establish\nthat this new language strictly increases the expressiveness of the Dense Bach\nlanguage introduced earlier and, consequently, Linda-like languages.\n", "Comment: In Proceedings FOCLASA 2014, arXiv:1502.03157"]}}], "languages": [null], "subjects": ["d.3.2", "computer science - multiagent systems", "f.1.2", "and cluster computing", "d.1.3", "computer science - distributed", "computer science - programming languages", "parallel"], "providerUpdatedDateTime": "2015-02-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03513"}}, {"publisher": {"name": ""}, "description": "  We show that unconverged stochastic gradient descent can be interpreted as a\nprocedure that samples from a nonparametric variational approximate posterior\ndistribution. This distribution is implicitly defined as the transformation of\nan initial distribution by a sequence of optimization updates. By tracking the\nchange in entropy over this sequence of transformations during optimization, we\nform a scalable, unbiased estimate of the variational lower bound on the log\nmarginal likelihood. We can use this bound to optimize hyperparameters instead\nof using cross-validation. This Bayesian interpretation of SGD suggests\nimproved, overfitting-resistant optimization procedures, and gives a\ntheoretical foundation for popular tricks such as early stopping and\nensembling. We investigate the properties of this marginal likelihood estimator\non neural network models.\n", "contributors": [{"name": "Maclaurin, Dougal", "sameAs": [], "familyName": "Maclaurin", "additionalName": "", "givenName": "Dougal", "email": ""}, {"name": "Duvenaud, David", "sameAs": [], "familyName": "Duvenaud", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Adams, Ryan P.", "sameAs": [], "familyName": "Adams", "additionalName": "P.", "givenName": "Ryan", "email": ""}], "title": "Early Stopping is Nonparametric Variational Inference", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01344", "oai:arXiv.org:1504.01344"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  We show that unconverged stochastic gradient descent can be interpreted as a\nprocedure that samples from a nonparametric variational approximate posterior\ndistribution. This distribution is implicitly defined as the transformation of\nan initial distribution by a sequence of optimization updates. By tracking the\nchange in entropy over this sequence of transformations during optimization, we\nform a scalable, unbiased estimate of the variational lower bound on the log\nmarginal likelihood. We can use this bound to optimize hyperparameters instead\nof using cross-validation. This Bayesian interpretation of SGD suggests\nimproved, overfitting-resistant optimization procedures, and gives a\ntheoretical foundation for popular tricks such as early stopping and\nensembling. We investigate the properties of this marginal likelihood estimator\non neural network models.\n", "Comment: 8 pages, 5 figures"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01344"}}, {"publisher": {"name": ""}, "description": "  This paper divide some complexity class by using fixpoint of Decidable\nUniversal Turing Machine (UTM). Decidable Deterministic Turing Machine (DTM)\nhave fixpointless combinator that add no extra resources (like Negation), but\nUTM makes some fixpoint in the combinator if UTM Target DTM set close under the\ncombinator. This means that we can jump out of the fixpointless combinator\nsystem by making more complex problem with UTM and diagonal method.\n  We proof that L is not P as concrete example. We can make Polynomial time UTM\nthat emulate all Logarithm space DTM (LDTM). LDTM set close under Negation,\ntherefore UTM does not close under LDTM set. We can proof this theorem like\nhalting problem and time/space hierarchy theorem. We can extend this proof to\ndivide time/space limited DTM set. These are new hierarchy that use UTM and\nNegation.\n  As appendix, We proof P is not NP by using P is not L.\n", "contributors": [{"name": "Kobayashi, Koji", "sameAs": [], "familyName": "Kobayashi", "additionalName": "", "givenName": "Koji", "email": ""}], "title": "Small Jump with Negation-UTM Trampoline", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-12-05", "2014-10-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1112.0987", "oai:arXiv.org:1112.0987"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper divide some complexity class by using fixpoint of Decidable\nUniversal Turing Machine (UTM). Decidable Deterministic Turing Machine (DTM)\nhave fixpointless combinator that add no extra resources (like Negation), but\nUTM makes some fixpoint in the combinator if UTM Target DTM set close under the\ncombinator. This means that we can jump out of the fixpointless combinator\nsystem by making more complex problem with UTM and diagonal method.\n  We proof that L is not P as concrete example. We can make Polynomial time UTM\nthat emulate all Logarithm space DTM (LDTM). LDTM set close under Negation,\ntherefore UTM does not close under LDTM set. We can proof this theorem like\nhalting problem and time/space hierarchy theorem. We can extend this proof to\ndivide time/space limited DTM set. These are new hierarchy that use UTM and\nNegation.\n  As appendix, We proof P is not NP by using P is not L.\n", "Comment: 3 pages"]}}], "languages": [null], "subjects": ["computer science - computational complexity"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1112.0987"}}, {"publisher": {"name": ""}, "description": "  We consider the problem of tracking with small relative error an integer\nfunction $f(n)$ defined by a distributed update stream $f'(n)$. Existing\nstreaming algorithms with worst-case guarantees for this problem assume $f(n)$\nto be monotone; there are very large lower bounds on the space requirements for\nsummarizing a distributed non-monotonic stream, often linear in the size $n$ of\nthe stream.\n  Input streams that give rise to large space requirements are highly variable,\nmaking relatively large jumps from one timestep to the next. However, streams\noften vary slowly in practice. What has heretofore been lacking is a framework\nfor non-monotonic streams that admits algorithms whose worst-case performance\nis as good as existing algorithms for monotone streams and degrades gracefully\nfor non-monotonic streams as those streams vary more quickly.\n  In this paper we propose such a framework. We introduce a new stream\nparameter, the \"variability\" $v$, deriving its definition in a way that shows\nit to be a natural parameter to consider for non-monotonic streams. It is also\na useful parameter. From a theoretical perspective, we can adapt existing\nalgorithms for monotone streams to work for non-monotonic streams, with only\nminor modifications, in such a way that they reduce to the monotone case when\nthe stream happens to be monotone, and in such a way that we can refine the\nworst-case communication bounds from $\\Theta(n)$ to $\\tilde{O}(v)$. From a\npractical perspective, we demonstrate that $v$ can be small in practice by\nproving that $v$ is $O(\\log f(n))$ for monotone streams and $o(n)$ for streams\nthat are \"nearly\" monotone or that are generated by random walks. We expect $v$\nto be $o(n)$ for many other interesting input classes as well.\n", "contributors": [{"name": "Felber, David", "sameAs": [], "familyName": "Felber", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Ostrovsky, Rafail", "sameAs": [], "familyName": "Ostrovsky", "additionalName": "", "givenName": "Rafail", "email": ""}], "title": "Variability in data streams", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07027", "oai:arXiv.org:1502.07027"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We consider the problem of tracking with small relative error an integer\nfunction $f(n)$ defined by a distributed update stream $f'(n)$. Existing\nstreaming algorithms with worst-case guarantees for this problem assume $f(n)$\nto be monotone; there are very large lower bounds on the space requirements for\nsummarizing a distributed non-monotonic stream, often linear in the size $n$ of\nthe stream.\n  Input streams that give rise to large space requirements are highly variable,\nmaking relatively large jumps from one timestep to the next. However, streams\noften vary slowly in practice. What has heretofore been lacking is a framework\nfor non-monotonic streams that admits algorithms whose worst-case performance\nis as good as existing algorithms for monotone streams and degrades gracefully\nfor non-monotonic streams as those streams vary more quickly.\n  In this paper we propose such a framework. We introduce a new stream\nparameter, the \"variability\" $v$, deriving its definition in a way that shows\nit to be a natural parameter to consider for non-monotonic streams. It is also\na useful parameter. From a theoretical perspective, we can adapt existing\nalgorithms for monotone streams to work for non-monotonic streams, with only\nminor modifications, in such a way that they reduce to the monotone case when\nthe stream happens to be monotone, and in such a way that we can refine the\nworst-case communication bounds from $\\Theta(n)$ to $\\tilde{O}(v)$. From a\npractical perspective, we demonstrate that $v$ can be small in practice by\nproving that $v$ is $O(\\log f(n))$ for monotone streams and $o(n)$ for streams\nthat are \"nearly\" monotone or that are generated by random walks. We expect $v$\nto be $o(n)$ for many other interesting input classes as well.\n", "Comment: submitted to ICALP 2015 (here, fullpage formatting)"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07027"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "This thesis explores the evolving nature of independent music practices in the context of offline and online social networks. The pivotal role of social networks in the cultural production of music is first examined by treating an independent record label of the post-punk era as an offline social network. This develops a useful framework for then considering the similar and distinctive ways in which contemporary independent practices are enabled and/or shaped by online social networks. Analysis is based on close, comparative readings of the structures and affordances of two case studies: the UK-based Rough Trade record label (1978 - 1991) and MySpace (2003 - present). Numerous examples of artists and their practices are drawn upon to illustrate how discursive meanings of independence are negotiated within each network. Investigated are potentials for realizing not only autonomy from the mainstream music industry, but also a range of other post-punk ideals tied to a broader independent ethos concerned with issues of access and participation, artistic control and freedom, as well as desires to engender more diverse music cultures. The intersection of offline and online networks in the context of today's dynamic, transitional music industry further provides new opportunities for more meaningful artist-to-artist, artist-to-fan, and artist-to-company/label interactions. By emphasizing the centrality of social networks, conceptions of autonomous, \"do-it-yourself\" music making are problematized in favor of \"do-it-together\" understandings that foreground cooperation.", "contributors": [{"name": "Wendel, Evan Landon", "sameAs": [], "familyName": "Wendel", "additionalName": "Landon", "givenName": "Evan", "email": ""}, {"name": "Massachusetts Institute of Technology. Dept. of Comparative Media Studies.", "sameAs": [], "familyName": "Studies.", "additionalName": "Institute of Technology. Dept. of Comparative Media", "givenName": "Massachusetts", "email": ""}, {"name": "William Uricchio.", "sameAs": [], "familyName": "Uricchio.", "additionalName": "", "givenName": "William", "email": ""}], "title": "New potentials for \"independent\" music : social networks, old and new, and the ongoing struggles to reshape the music industry", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "112 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/43197", "256929823", "oai:dspace.mit.edu:1721.1/43197"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2008-11-07T19:14:35Z", "2008-11-07T19:14:35Z", "2008", "2008"]}}, {"name": "description", "properties": {"description": ["This thesis explores the evolving nature of independent music practices in the context of offline and online social networks. The pivotal role of social networks in the cultural production of music is first examined by treating an independent record label of the post-punk era as an offline social network. This develops a useful framework for then considering the similar and distinctive ways in which contemporary independent practices are enabled and/or shaped by online social networks. Analysis is based on close, comparative readings of the structures and affordances of two case studies: the UK-based Rough Trade record label (1978 - 1991) and MySpace (2003 - present). Numerous examples of artists and their practices are drawn upon to illustrate how discursive meanings of independence are negotiated within each network. Investigated are potentials for realizing not only autonomy from the mainstream music industry, but also a range of other post-punk ideals tied to a broader independent ethos concerned with issues of access and participation, artistic control and freedom, as well as desires to engender more diverse music cultures. The intersection of offline and online networks in the context of today's dynamic, transitional music industry further provides new opportunities for more meaningful artist-to-artist, artist-to-fan, and artist-to-company/label interactions. By emphasizing the centrality of social networks, conceptions of autonomous, \"do-it-yourself\" music making are problematized in favor of \"do-it-together\" understandings that foreground cooperation.", "by Evan Landon Wendel.", "Thesis (S.M.)--Massachusetts Institute of Technology, Dept. of Comparative Media Studies, 2008.", "Includes bibliographical references (p. 105-111)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39100", "hdl_1721.1_39097"]}}], "languages": [null], "subjects": ["comparative media studies."], "providerUpdatedDateTime": "2015-04-27T14:44:36", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/43197"}}, {"publisher": {"name": ""}, "description": "  Many inference problems involve inferring the number $N$ of objects in some\nregion, along with their properties $\\{\\mathbf{x}_i\\}_{i=1}^N$, from a dataset\n$\\mathcal{D}$. A common statistical example is finite mixture modelling. In the\nBayesian framework, these problems are typically solved using one of the\nfollowing two methods: i) by executing a Monte Carlo algorithm (such as Nested\nSampling) once for each possible value of $N$, and calculating the marginal\nlikelihood or evidence as a function of $N$; or ii) by doing a single run that\nallows the model dimension $N$ to change (such as Markov Chain Monte Carlo with\nbirth/death moves), and obtaining the posterior for $N$ directly. In this paper\nwe present a general approach to this problem that uses trans-dimensional MCMC\nembedded {\\it within} a Nested Sampling algorithm, allowing us to explore the\nposterior distribution and calculate the marginal likelihood (summed over $N$)\neven if the problem contains a phase transition or other difficult features\nsuch as multimodality. We present two example problems, finding sinusoidal\nsignals in noisy data, and finding and measuring galaxies in a noisy\nastronomical image. Both of the examples demonstrate phase transitions in the\nrelationship between the likelihood and the cumulative prior mass.\n", "contributors": [{"name": "Brewer, Brendon J.", "sameAs": [], "familyName": "Brewer", "additionalName": "J.", "givenName": "Brendon", "email": ""}], "title": "Inference for Trans-dimensional Bayesian Models with Diffusive Nested\n  Sampling", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-14", "2014-11-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3921", "oai:arXiv.org:1411.3921"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:astro-ph", "physics:physics", "stat"]}}, {"name": "description", "properties": {"description": ["  Many inference problems involve inferring the number $N$ of objects in some\nregion, along with their properties $\\{\\mathbf{x}_i\\}_{i=1}^N$, from a dataset\n$\\mathcal{D}$. A common statistical example is finite mixture modelling. In the\nBayesian framework, these problems are typically solved using one of the\nfollowing two methods: i) by executing a Monte Carlo algorithm (such as Nested\nSampling) once for each possible value of $N$, and calculating the marginal\nlikelihood or evidence as a function of $N$; or ii) by doing a single run that\nallows the model dimension $N$ to change (such as Markov Chain Monte Carlo with\nbirth/death moves), and obtaining the posterior for $N$ directly. In this paper\nwe present a general approach to this problem that uses trans-dimensional MCMC\nembedded {\\it within} a Nested Sampling algorithm, allowing us to explore the\nposterior distribution and calculate the marginal likelihood (summed over $N$)\neven if the problem contains a phase transition or other difficult features\nsuch as multimodality. We present two example problems, finding sinusoidal\nsignals in noisy data, and finding and measuring galaxies in a noisy\nastronomical image. Both of the examples demonstrate phase transitions in the\nrelationship between the likelihood and the cumulative prior mass.\n", "Comment: Submitted. Comments welcome. 14 pages, 7 figures. Software available\n  at https://github.com/eggplantbren/RJObject"]}}], "languages": [null], "subjects": ["statistics - computation", "statistics and probability", "astrophysics - instrumentation and methods for astrophysics", "physics - data analysis"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3921"}}, {"publisher": {"name": ""}, "description": "  Estimating the difficulty level of math word problems is an important task\nfor many educational applications. Identification of relevant and irrelevant\nsentences in math word problems is an important step for calculating the\ndifficulty levels of such problems. This paper addresses a novel application of\ntext categorization to identify two types of sentences in mathematical word\nproblems, namely relevant and irrelevant sentences. A novel joint probabilistic\nclassification model is proposed to estimate the joint probability of\nclassification decisions for all sentences of a math word problem by utilizing\nthe correlation among all sentences along with the correlation between the\nquestion sentence and other sentences, and sentence text. The proposed model is\ncompared with i) a SVM classifier which makes independent classification\ndecisions for individual sentences by only using the sentence text and ii) a\nnovel SVM classifier that considers the correlation between the question\nsentence and other sentences along with the sentence text. An extensive set of\nexperiments demonstrates the effectiveness of the joint probabilistic\nclassification model for identifying relevant and irrelevant sentences as well\nas the novel SVM classifier that utilizes the correlation between the question\nsentence and other sentences. Furthermore, empirical results and analysis show\nthat i) it is highly beneficial not to remove stopwords and ii) utilizing part\nof speech tagging does not make a significant improvement although it has been\nshown to be effective for the related task of math word problem type\nclassification.\n", "contributors": [{"name": "Cetintas, Suleyman", "sameAs": [], "familyName": "Cetintas", "additionalName": "", "givenName": "Suleyman", "email": ""}, {"name": "Si, Luo", "sameAs": [], "familyName": "Si", "additionalName": "", "givenName": "Luo", "email": ""}, {"name": "Xin, Yan Ping", "sameAs": [], "familyName": "Xin", "additionalName": "Ping", "givenName": "Yan", "email": ""}, {"name": "Zhang, Dake", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Dake", "email": ""}, {"name": "Park, Joo Young", "sameAs": [], "familyName": "Park", "additionalName": "Young", "givenName": "Joo", "email": ""}, {"name": "Tzur, Ron", "sameAs": [], "familyName": "Tzur", "additionalName": "", "givenName": "Ron", "email": ""}], "title": "A Joint Probabilistic Classification Model of Relevant and Irrelevant\n  Sentences in Mathematical Word Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5732", "oai:arXiv.org:1411.5732"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Estimating the difficulty level of math word problems is an important task\nfor many educational applications. Identification of relevant and irrelevant\nsentences in math word problems is an important step for calculating the\ndifficulty levels of such problems. This paper addresses a novel application of\ntext categorization to identify two types of sentences in mathematical word\nproblems, namely relevant and irrelevant sentences. A novel joint probabilistic\nclassification model is proposed to estimate the joint probability of\nclassification decisions for all sentences of a math word problem by utilizing\nthe correlation among all sentences along with the correlation between the\nquestion sentence and other sentences, and sentence text. The proposed model is\ncompared with i) a SVM classifier which makes independent classification\ndecisions for individual sentences by only using the sentence text and ii) a\nnovel SVM classifier that considers the correlation between the question\nsentence and other sentences along with the sentence text. An extensive set of\nexperiments demonstrates the effectiveness of the joint probabilistic\nclassification model for identifying relevant and irrelevant sentences as well\nas the novel SVM classifier that utilizes the correlation between the question\nsentence and other sentences. Furthermore, empirical results and analysis show\nthat i) it is highly beneficial not to remove stopwords and ii) utilizing part\nof speech tagging does not make a significant improvement although it has been\nshown to be effective for the related task of math word problem type\nclassification.\n", "Comment: appears in Journal of Educational Data Mining (JEDM, 2010)"]}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - computation and language", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-11-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5732"}}, {"publisher": {"name": ""}, "description": "  The development and evolution of malware including computer viruses, worms,\nand trojan horses, is shown to be closely analogous to the process of community\nsuccession long recognized in ecology. In particular, both changes in the\noverall environment by external disturbances, as well as, feedback effects from\nmalware competition and antivirus coevolution have driven community succession\nand the development of different types of malware with varying modes of\ntransmission and adaptability.\n", "contributors": [{"name": "Smith, Reginald D.", "sameAs": [], "familyName": "Smith", "additionalName": "D.", "givenName": "Reginald", "email": ""}], "title": "Malware \"Ecology\" Viewed as Ecological Succession: Historical Trends and\n  Future Prospects", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-09-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.8082", "oai:arXiv.org:1410.8082"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": ["  The development and evolution of malware including computer viruses, worms,\nand trojan horses, is shown to be closely analogous to the process of community\nsuccession long recognized in ecology. In particular, both changes in the\noverall environment by external disturbances, as well as, feedback effects from\nmalware competition and antivirus coevolution have driven community succession\nand the development of different types of malware with varying modes of\ntransmission and adaptability.\n", "Comment: 13 pages, 3 figures"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "quantitative biology - populations and evolution"], "providerUpdatedDateTime": "2014-10-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.8082"}}, {"publisher": {"name": ""}, "description": "  String diagrams are a powerful tool for reasoning about composite structures\nin symmetric monoidal categories. By representing string diagrams as graphs,\nequational reasoning can be done automatically by double-pushout rewriting.\n!-graphs give us the means of expressing and proving properties about whole\nfamilies of these graphs simultaneously. While !-graphs provide elegant proofs\nof surprisingly powerful theorems, little is known about the formal properties\nof the graph languages they define. This paper takes the first step in\ncharacterising these languages by showing that an important subclass of\n!-graphs\u00c3\u00a2\u00c2\u0080\u00c2\u0094those whose repeated structures only overlap trivially\u00c3\u00a2\u00c2\u0080\u00c2\u0094can be encoded\nusing a (context-free) vertex replacement grammar.\n", "contributors": [{"name": "Kissinger, Aleks", "sameAs": [], "familyName": "Kissinger", "additionalName": "", "givenName": "Aleks", "email": ""}, {"name": "Zamdzhiev, Vladimir", "sameAs": [], "familyName": "Zamdzhiev", "additionalName": "", "givenName": "Vladimir", "email": ""}], "title": "!-Graphs with Trivial Overlap are Context-Free", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-24", "2015-04-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06059", "EPTCS 181, 2015, pp. 16-31", "doi:10.4204/EPTCS.181.2", "oai:arXiv.org:1501.06059"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  String diagrams are a powerful tool for reasoning about composite structures\nin symmetric monoidal categories. By representing string diagrams as graphs,\nequational reasoning can be done automatically by double-pushout rewriting.\n!-graphs give us the means of expressing and proving properties about whole\nfamilies of these graphs simultaneously. While !-graphs provide elegant proofs\nof surprisingly powerful theorems, little is known about the formal properties\nof the graph languages they define. This paper takes the first step in\ncharacterising these languages by showing that an important subclass of\n!-graphs\u00c3\u00a2\u00c2\u0080\u00c2\u0094those whose repeated structures only overlap trivially\u00c3\u00a2\u00c2\u0080\u00c2\u0094can be encoded\nusing a (context-free) vertex replacement grammar.\n", "Comment: In Proceedings GaM 2015, arXiv:1504.02448"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "computer science - logic in computer science", "mathematics - category theory"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06059"}}, {"publisher": {"name": ""}, "description": "  Considering congestion games with uncertain delays, we compute the\ninefficiency introduced in network routing by risk-averse agents. At\nequilibrium, agents may select paths that do not minimize the expected latency\nto obtain lower variability. A social planner, who is likely to be more risk\nneutral than agents because it operates at a longer time-scale, quantifies\nsocial cost with the total expected delay along routes. From that perspective,\nagents may make suboptimal decisions that degrade long-term quality. We define\nthe price of risk aversion (PRA) as the worst-case ratio of the social cost at\na risk-averse Wardrop equilibrium to that where agents are risk-neutral. For\nnetworks with arbitrary delays and a single source-sink pair, we show that the\nPRA depends linearly on the agents' risk tolerance and on the degree of\nvariability present in the network. In contrast to the price of anarchy, in\ngeneral the PRA increases when the network gets larger but does not depend on\nthe shape of the delay functions. To get this result we rely on a combinatorial\nproof that employs alternating paths that are reminiscent of those used in\nmax-flow algorithms. Restricting topologies to the class of series-parallel\n(SP) graphs, the PRA is independent of the network topology and its size. As a\npartial result of independent interest, we prove that for SP networks with\ndeterministic delays, among all feasible flows, Wardrop equilibria maximize the\nshortest path objective.\n", "contributors": [{"name": "Nikolova, E.", "sameAs": [], "familyName": "Nikolova", "additionalName": "", "givenName": "E.", "email": ""}, {"name": "Stier-Moses, N.", "sameAs": [], "familyName": "Stier-Moses", "additionalName": "", "givenName": "N.", "email": ""}], "title": "The Burden of Risk Aversion in Mean-Risk Selfish Routing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0059", "oai:arXiv.org:1411.0059"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Considering congestion games with uncertain delays, we compute the\ninefficiency introduced in network routing by risk-averse agents. At\nequilibrium, agents may select paths that do not minimize the expected latency\nto obtain lower variability. A social planner, who is likely to be more risk\nneutral than agents because it operates at a longer time-scale, quantifies\nsocial cost with the total expected delay along routes. From that perspective,\nagents may make suboptimal decisions that degrade long-term quality. We define\nthe price of risk aversion (PRA) as the worst-case ratio of the social cost at\na risk-averse Wardrop equilibrium to that where agents are risk-neutral. For\nnetworks with arbitrary delays and a single source-sink pair, we show that the\nPRA depends linearly on the agents' risk tolerance and on the degree of\nvariability present in the network. In contrast to the price of anarchy, in\ngeneral the PRA increases when the network gets larger but does not depend on\nthe shape of the delay functions. To get this result we rely on a combinatorial\nproof that employs alternating paths that are reminiscent of those used in\nmax-flow algorithms. Restricting topologies to the class of series-parallel\n(SP) graphs, the PRA is independent of the network topology and its size. As a\npartial result of independent interest, we prove that for SP networks with\ndeterministic delays, among all feasible flows, Wardrop equilibria maximize the\nshortest path objective.\n", "Comment: 21 pages, 4 figures"]}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0059"}}, {"publisher": {"name": ""}, "description": "  Inference in general Ising models is difficult, due to high treewidth making\ntree-based algorithms intractable. Moreover, when interactions are strong,\nGibbs sampling may take exponential time to converge to the stationary\ndistribution. We present an algorithm to project Ising model parameters onto a\nparameter set that is guaranteed to be fast mixing, under several divergences.\nWe find that Gibbs sampling using the projected parameters is more accurate\nthan with the original parameters when interaction strengths are strong and\nwhen limited time is available for sampling.\n", "contributors": [{"name": "Domke, Justin", "sameAs": [], "familyName": "Domke", "additionalName": "", "givenName": "Justin", "email": ""}, {"name": "Liu, Xianghang", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Xianghang", "email": ""}], "title": "Projecting Ising Model Parameters for Fast Mixing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-02", "2014-10-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.0749", "oai:arXiv.org:1407.0749"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Inference in general Ising models is difficult, due to high treewidth making\ntree-based algorithms intractable. Moreover, when interactions are strong,\nGibbs sampling may take exponential time to converge to the stationary\ndistribution. We present an algorithm to project Ising model parameters onto a\nparameter set that is guaranteed to be fast mixing, under several divergences.\nWe find that Gibbs sampling using the projected parameters is more accurate\nthan with the original parameters when interaction strengths are strong and\nwhen limited time is available for sampling.\n", "Comment: Advances in Neural Information Processing Systems 2013"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.0749"}}, {"publisher": {"name": ""}, "description": "  We present a new type of polyominoes that can have transparent squares\n(holes). We show how these polyominoes can tile rectangles and we categorise\nthem according to their tiling ability. We were able to categorise all but 7\npolyominoes with 5 or fewer visible squares.\n", "contributors": [{"name": "Kamenetsky, Dmitry", "sameAs": [], "familyName": "Kamenetsky", "additionalName": "", "givenName": "Dmitry", "email": ""}, {"name": "Cooke, Tristrom", "sameAs": [], "familyName": "Cooke", "additionalName": "", "givenName": "Tristrom", "email": ""}], "title": "Tiling rectangles with holey polyominoes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2699", "oai:arXiv.org:1411.2699"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We present a new type of polyominoes that can have transparent squares\n(holes). We show how these polyominoes can tile rectangles and we categorise\nthem according to their tiling ability. We were able to categorise all but 7\npolyominoes with 5 or fewer visible squares.\n", "Comment: 23 pages"]}}], "languages": [null], "subjects": ["g.2.1", "05-02", "computer science - computational geometry"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2699"}}, {"publisher": {"name": ""}, "description": "  The reproduction and replication of novel results has become a major issue\nfor a number of scientific disciplines. In computer science and related\ncomputational disciplines such as systems biology, the issues closely revolve\naround the ability to implement novel algorithms and models. Taking an approach\nfrom the literature and applying it to a new codebase frequently requires local\nknowledge missing from the published manuscripts and project websites.\nAlongside this issue, benchmarking, and the development of fair -- and publicly\navailable -- benchmark sets present another barrier.\n  In this paper, we outline several suggestions to address these issues, driven\nby specific examples from a range of scientific domains. Finally, based on\nthese suggestions, we propose a new open automated platform for scientific\nsoftware development which effectively abstracts specific dependencies from the\nindividual researcher and their workstation, allowing easy sharing and\nreproduction of results. This new cyberinfrastructure for computational science\noffers the potential to incentivise a culture change and drive the adoption of\nnew techniques to improve the efficiency of scientific exploration.\n", "contributors": [{"name": "Crick, Tom", "sameAs": [], "familyName": "Crick", "additionalName": "", "givenName": "Tom", "email": ""}, {"name": "Ishtiaq, Samin", "sameAs": [], "familyName": "Ishtiaq", "additionalName": "", "givenName": "Samin", "email": ""}, {"name": "Hall, Benjamin A.", "sameAs": [], "familyName": "Hall", "additionalName": "A.", "givenName": "Benjamin", "email": ""}], "title": "Towards \"Reproducibility-as-a-Service\"", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02388", "oai:arXiv.org:1503.02388"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The reproduction and replication of novel results has become a major issue\nfor a number of scientific disciplines. In computer science and related\ncomputational disciplines such as systems biology, the issues closely revolve\naround the ability to implement novel algorithms and models. Taking an approach\nfrom the literature and applying it to a new codebase frequently requires local\nknowledge missing from the published manuscripts and project websites.\nAlongside this issue, benchmarking, and the development of fair -- and publicly\navailable -- benchmark sets present another barrier.\n  In this paper, we outline several suggestions to address these issues, driven\nby specific examples from a range of scientific domains. Finally, based on\nthese suggestions, we propose a new open automated platform for scientific\nsoftware development which effectively abstracts specific dependencies from the\nindividual researcher and their workstation, allowing easy sharing and\nreproduction of results. This new cyberinfrastructure for computational science\noffers the potential to incentivise a culture change and drive the adoption of\nnew techniques to improve the efficiency of scientific exploration.\n", "Comment: Invited submission to Journal of Open Research Software; 10 pages,\n  LaTeX"]}}], "languages": [null], "subjects": ["computer science - computers and society", "computer science - computational engineering", "computer science - software engineering", "and science", "finance"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02388"}}, {"publisher": {"name": ""}, "description": "  We prove that two algebraic embeddings of a smooth variety $X$ in\n$\\mathbb{C}^m$ are the same up to a holomorphic coordinate change, provided\nthat $2 \\dim X + 1$ is smaller than or equal to $m$. This improves an algebraic\nresult of Nori and Srinivas. For the proof we extend a technique of Kaliman\nusing generic linear projections of $\\mathbb{C}^m$.\n", "contributors": [{"name": "Feller, Peter", "sameAs": [], "familyName": "Feller", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Stampfli, Immanuel", "sameAs": [], "familyName": "Stampfli", "additionalName": "", "givenName": "Immanuel", "email": ""}], "title": "Holomorphically Equivalent Algebraic Embeddings", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-25", "2014-10-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.7319", "oai:arXiv.org:1409.7319"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We prove that two algebraic embeddings of a smooth variety $X$ in\n$\\mathbb{C}^m$ are the same up to a holomorphic coordinate change, provided\nthat $2 \\dim X + 1$ is smaller than or equal to $m$. This improves an algebraic\nresult of Nori and Srinivas. For the proof we extend a technique of Kaliman\nusing generic linear projections of $\\mathbb{C}^m$.\n", "Comment: 17 pages. Version 2 acknowledges the fact that the main result of\n  this paper was previously established by Kaliman, see\n  http://arxiv.org/abs/1309.3791"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.7319"}}, {"publisher": {"name": ""}, "description": "  Advertisement (abbreviated ad) options are a recent development in online\nadvertising. Simply, an ad option is a contract in which a publisher or search\nengine grants an advertiser a right but not obligation to enter into\ntransactions to purchase impressions or clicks from a specific ad slot at a\npre-specified price on a specific delivery date. Such a structure provides\nadvertisers with more flexibility of their guaranteed deliveries. The valuation\nof ad options is an important topic and previous studies on ad options pricing\nhave been mostly restricted to the situations where the underlying prices\nfollow a geometric Brownian motion (GBM). This assumption is reasonable for\nsponsored search; however, some studies have also indicated that it is not\nvalid for display advertising. In this paper, we address this issue by\nemploying a stochastic volatility (SV) model and discuss a lattice framework to\napproximate the proposed SV model in option pricing. Our developments are\nvalidated by experiments with real advertising data: (i) we find that the SV\nmodel has a better fitness over the GBM model; (ii) we validate the proposed\nlattice model via two sequential Monte Carlo simulation methods; (iii) we\ndemonstrate that advertisers are able to flexibly manage their guaranteed\ndeliveries by using the proposed options, and publishers can have an increased\nrevenue when some of their inventories are sold via ad options.\n", "contributors": [{"name": "Chen, Bowei", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Bowei", "email": ""}, {"name": "Wang, Jun", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Jun", "email": ""}], "title": "A Lattice Framework for Pricing Display Ad Options with the Stochastic\n  Volatility Underlying Model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-02", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.0697", "oai:arXiv.org:1409.0697"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-fin"]}}, {"name": "description", "properties": {"description": ["  Advertisement (abbreviated ad) options are a recent development in online\nadvertising. Simply, an ad option is a contract in which a publisher or search\nengine grants an advertiser a right but not obligation to enter into\ntransactions to purchase impressions or clicks from a specific ad slot at a\npre-specified price on a specific delivery date. Such a structure provides\nadvertisers with more flexibility of their guaranteed deliveries. The valuation\nof ad options is an important topic and previous studies on ad options pricing\nhave been mostly restricted to the situations where the underlying prices\nfollow a geometric Brownian motion (GBM). This assumption is reasonable for\nsponsored search; however, some studies have also indicated that it is not\nvalid for display advertising. In this paper, we address this issue by\nemploying a stochastic volatility (SV) model and discuss a lattice framework to\napproximate the proposed SV model in option pricing. Our developments are\nvalidated by experiments with real advertising data: (i) we find that the SV\nmodel has a better fitness over the GBM model; (ii) we validate the proposed\nlattice model via two sequential Monte Carlo simulation methods; (iii) we\ndemonstrate that advertisers are able to flexibly manage their guaranteed\ndeliveries by using the proposed options, and publishers can have an increased\nrevenue when some of their inventories are sold via ad options.\n", "Comment: 23 pages, working paper"]}}], "languages": [null], "subjects": ["computer science - computer science and game theory", "quantitative finance - computational finance"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.0697"}}, {"publisher": {"name": ""}, "description": "  Existing document filtering systems learn user profiles based on user\nrelevance feedback on documents. In some cases, users may have prior knowledge\nabout what features are important. For example, a Spanish speaker may only want\nnews written in Spanish, and thus a relevant document should contain the\nfeature \"Language: Spanish\"; a researcher focusing on HIV knows an article with\nthe medical subject \"Subject: AIDS\" is very likely to be relevant to him/her.\n  Semi-structured documents with rich metadata are increasingly prevalent on\nthe Internet. Motivated by the well-adopted faceted search interface in\ne-commerce, we study the exploitation of user prior knowledge on faceted\nfeatures for semi-structured document filtering. We envision two faceted\nfeedback mechanisms, and propose a novel user profile learning algorithm that\ncan incorporate user feedback on features. To evaluate the proposed work, we\nuse two data sets from the TREC filtering track, and conduct a user study on\nAmazon Mechanical Turk. Our experiment results show that user feedback on\nfaceted features is useful for filtering. The proposed user profile learning\nalgorithm can effectively learn from user feedback on both documents and\nfeatures, and performs better than several existing methods.\n", "contributors": [{"name": "Zhang, Lanbo", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Lanbo", "email": ""}, {"name": "Zhang, Yi", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Yi", "email": ""}, {"name": "Xing, Qianli", "sameAs": [], "familyName": "Xing", "additionalName": "", "givenName": "Qianli", "email": ""}], "title": "Learning from Labeled Features for Document Filtering", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.8125", "oai:arXiv.org:1412.8125"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Existing document filtering systems learn user profiles based on user\nrelevance feedback on documents. In some cases, users may have prior knowledge\nabout what features are important. For example, a Spanish speaker may only want\nnews written in Spanish, and thus a relevant document should contain the\nfeature \"Language: Spanish\"; a researcher focusing on HIV knows an article with\nthe medical subject \"Subject: AIDS\" is very likely to be relevant to him/her.\n  Semi-structured documents with rich metadata are increasingly prevalent on\nthe Internet. Motivated by the well-adopted faceted search interface in\ne-commerce, we study the exploitation of user prior knowledge on faceted\nfeatures for semi-structured document filtering. We envision two faceted\nfeedback mechanisms, and propose a novel user profile learning algorithm that\ncan incorporate user feedback on features. To evaluate the proposed work, we\nuse two data sets from the TREC filtering track, and conduct a user study on\nAmazon Mechanical Turk. Our experiment results show that user feedback on\nfaceted features is useful for filtering. The proposed user profile learning\nalgorithm can effectively learn from user feedback on both documents and\nfeatures, and performs better than several existing methods.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.8125"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "The mammalian accessory olfactory system is specialized for the detection of chemicals that identify kin and conspecifics. Vomeronasal sensory neurons (VSNs) residing in the vomeronasal organ project axons to the accessory olfactory bulb (AOB), where they form synapses with principal neurons known as mitral cells. The organization of this projection is quite precise and is believed to be essential for appropriate function of this system. However, how this precise connectivity is established is unknown. We show here that in mice the vomeronasal duct is open at birth, allowing external chemical stimuli access to sensory neurons, and that these sensory neurons are capable of releasing neurotransmitter to downstream neurons as early as the first postnatal day (P). Using major histocompatibility complex class I peptides to activate a selective subset of VSNs during the first few postnatal days of development, we show that increased activity results in exuberant VSN axonal projections and a delay in axonal coalescence into well defined glomeruli in the AOB. Finally, we show that mitral cell dendritic refinement occurs just after the coalescence of presynaptic axons. Such a mechanism may allow the formation of precise connectivity with specific glomeruli that receive input from sensory neurons expressing the same receptor type.", "contributors": [{"name": "Hovis, Kenneth R.", "sameAs": [], "familyName": "Hovis", "additionalName": "R.", "givenName": "Kenneth", "email": ""}, {"name": "Ramnath, Rohit", "sameAs": [], "familyName": "Ramnath", "additionalName": "", "givenName": "Rohit", "email": ""}, {"name": "Dahlen, Jeffrey E.", "sameAs": [], "familyName": "Dahlen", "additionalName": "E.", "givenName": "Jeffrey", "email": ""}, {"name": "Romanova, Anna L.", "sameAs": [], "familyName": "Romanova", "additionalName": "L.", "givenName": "Anna", "email": ""}, {"name": "LaRocca, Greg", "sameAs": [], "familyName": "LaRocca", "additionalName": "", "givenName": "Greg", "email": ""}, {"name": "Bier, Mark E.", "sameAs": [], "familyName": "Bier", "additionalName": "E.", "givenName": "Mark", "email": ""}, {"name": "Urban, Nathaniel N.", "sameAs": [], "familyName": "Urban", "additionalName": "N.", "givenName": "Nathaniel", "email": ""}], "title": "Activity regulates functional connectivity from the vomeronasal organ to the accessory olfactory bulb.", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2012-06-06T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/biology/461", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1468&amp;context=biology", "oai:repository.cmu.edu:biology-1468"]}}, {"name": "setSpec", "properties": {"setSpec": "publication:biology"}}, {"name": "description", "properties": {"description": "The mammalian accessory olfactory system is specialized for the detection of chemicals that identify kin and conspecifics. Vomeronasal sensory neurons (VSNs) residing in the vomeronasal organ project axons to the accessory olfactory bulb (AOB), where they form synapses with principal neurons known as mitral cells. The organization of this projection is quite precise and is believed to be essential for appropriate function of this system. However, how this precise connectivity is established is unknown. We show here that in mice the vomeronasal duct is open at birth, allowing external chemical stimuli access to sensory neurons, and that these sensory neurons are capable of releasing neurotransmitter to downstream neurons as early as the first postnatal day (P). Using major histocompatibility complex class I peptides to activate a selective subset of VSNs during the first few postnatal days of development, we show that increased activity results in exuberant VSN axonal projections and a delay in axonal coalescence into well defined glomeruli in the AOB. Finally, we show that mitral cell dendritic refinement occurs just after the coalescence of presynaptic axons. Such a mechanism may allow the formation of precise connectivity with specific glomeruli that receive input from sensory neurons expressing the same receptor type."}}], "languages": [null], "subjects": ["olfactory bulb", "mhc class i", "biology", "receptors", "female", "patch-clamp techniques", "image processing", "vomeronasal organ", "neuropeptides", "olfactory receptor neurons", "computer-assisted", "gene expression", "electroporation", "immunohistochemistry", "presynaptic", "axons", "genes", "proto-oncogene proteins c-fos", "freeze drying", "mice", "animals", "smell", "transgenic", "microscopy", "confocal", "dendrites", "neural pathways", "male"], "providerUpdatedDateTime": "2014-10-28T19:52:16", "uris": {"canonicalUri": "http://repository.cmu.edu/biology/461"}}, {"publisher": {"name": ""}, "description": "  The Multiple Depot Ring-Star Problem (MDRSP) is an important combinatorial\noptimization problem that arises in the context of optical fiber network\ndesign, and in applications pertaining to collecting data using stationary\nsensing devices and autonomous vehicles. Given the locations of a set of\ncustomers and a set of depots, the goal is to (i) find a set of simple cycles\nsuch that each cycle (ring) passes through a subset of customers and exactly\none depot, (ii) assign each non-visited customer to a visited customer or a\ndepot, and (iii) minimize the sum of the routing costs, i.e., the cost of the\ncycles and the assignment costs. We present a mixed integer linear programming\nformulation for the MDRSP and propose valid inequalities to strengthen the\nlinear programming relaxation. Furthermore, we present a polyhedral analysis\nand derive facet-inducing results for the MDRSP. All these results are then\nused to develop a branch-and-cut algorithm to obtain optimal solutions to the\nMDRSP. The performance of the branch-and-cut algorithm is evaluated through\nextensive computational experiments on several classes of test instances.\n", "contributors": [{"name": "Sundar, Kaarthik", "sameAs": [], "familyName": "Sundar", "additionalName": "", "givenName": "Kaarthik", "email": ""}, {"name": "Rathinam, Sivakumar", "sameAs": [], "familyName": "Rathinam", "additionalName": "", "givenName": "Sivakumar", "email": ""}], "title": "Multiple Depot Ring Star Problem: A polyhedral study and exact algorithm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-18", "2014-10-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.5080", "oai:arXiv.org:1407.5080"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The Multiple Depot Ring-Star Problem (MDRSP) is an important combinatorial\noptimization problem that arises in the context of optical fiber network\ndesign, and in applications pertaining to collecting data using stationary\nsensing devices and autonomous vehicles. Given the locations of a set of\ncustomers and a set of depots, the goal is to (i) find a set of simple cycles\nsuch that each cycle (ring) passes through a subset of customers and exactly\none depot, (ii) assign each non-visited customer to a visited customer or a\ndepot, and (iii) minimize the sum of the routing costs, i.e., the cost of the\ncycles and the assignment costs. We present a mixed integer linear programming\nformulation for the MDRSP and propose valid inequalities to strengthen the\nlinear programming relaxation. Furthermore, we present a polyhedral analysis\nand derive facet-inducing results for the MDRSP. All these results are then\nused to develop a branch-and-cut algorithm to obtain optimal solutions to the\nMDRSP. The performance of the branch-and-cut algorithm is evaluated through\nextensive computational experiments on several classes of test instances.\n", "Comment: Submitted to Optimization Letters"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - systems and control"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.5080"}}, {"publisher": {"name": ""}, "description": "  There has been rapidly growing interest in studying and designing online\ndeliberative processes and technologies. This SIG aims at providing a venue for\ncontinuous and constructive dialogue between social, political and cognitive\nsciences as well as computer science, HCI, and CSCW. Through an online\ncommunity and a modified version of world cafe discussions, we contribute to\nthe definition of the theoretical building blocks, the identification of a\nresearch agenda for the CHI community, and the network of individuals from\nacademia, industry, and the public sector who share interests in different\naspects of online deliberation.\n", "contributors": [{"name": "Xiao, Lu", "sameAs": [], "familyName": "Xiao", "additionalName": "", "givenName": "Lu", "email": ""}, {"name": "Zhang, Weiyu", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Weiyu", "email": ""}, {"name": "Przybylska, Anna", "sameAs": [], "familyName": "Przybylska", "additionalName": "", "givenName": "Anna", "email": ""}, {"name": "De Liddo, Anna", "sameAs": [], "familyName": "De Liddo", "additionalName": "", "givenName": "Anna", "email": ""}, {"name": "Convertino, Gregorio", "sameAs": [], "familyName": "Convertino", "additionalName": "", "givenName": "Gregorio", "email": ""}, {"name": "Davies, Todd", "sameAs": [], "familyName": "Davies", "additionalName": "", "givenName": "Todd", "email": ""}, {"name": "Klein, Mark", "sameAs": [], "familyName": "Klein", "additionalName": "", "givenName": "Mark", "email": ""}], "title": "Design for Online Deliberative Processes and Technologies: Towards a\n  Multidisciplinary Research Agenda", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-03", "2015-03-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01145", "doi:10.1145/2702613.2727687", "oai:arXiv.org:1503.01145"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  There has been rapidly growing interest in studying and designing online\ndeliberative processes and technologies. This SIG aims at providing a venue for\ncontinuous and constructive dialogue between social, political and cognitive\nsciences as well as computer science, HCI, and CSCW. Through an online\ncommunity and a modified version of world cafe discussions, we contribute to\nthe definition of the theoretical building blocks, the identification of a\nresearch agenda for the CHI community, and the network of individuals from\nacademia, industry, and the public sector who share interests in different\naspects of online deliberation.\n", "Comment: CHI'15 Extended Abstracts, Apr 18-23, 2015, Seoul, Republic of Korea,\n  ACM 978-1-4503-3146-3/15/04, 4 pages"]}}], "languages": [null], "subjects": ["k.4.3", "computer science - human-computer interaction", "k.4.1", "h.5.3"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01145"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "We propose a new fast algorithm for approximate MAP inference on factor graphs, which combines augmented Lagrangian optimization with the dual decomposition method. Each slave subproblem is given a quadratic penalty, which pushes toward faster consensus than in previous subgradient approaches. Our algorithm is provably convergent, parallelizable, and suitable for fine decompositions of the graph. We show how it can efficiently handle problems with (possibly global) structural constraints via simple sort operations. Experiments on synthetic and real-world data show that our approach compares favorably with the state-of-the-art.", "contributors": [{"name": "Martins, Andre F.T.", "sameAs": [], "familyName": "Martins", "additionalName": "F.T.", "givenName": "Andre", "email": ""}, {"name": "Figeuiredo, Mario A. T.", "sameAs": [], "familyName": "Figeuiredo", "additionalName": "A. T.", "givenName": "Mario", "email": ""}, {"name": "Aguiar, Pedro M.Q.", "sameAs": [], "familyName": "Aguiar", "additionalName": "M.Q.", "givenName": "Pedro", "email": ""}, {"name": "Smith, Noah A.", "sameAs": [], "familyName": "Smith", "additionalName": "A.", "givenName": "Noah", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "An Augmented Lagrangian Approach to Constrained MAP Inference", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2011-06-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/213", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1211&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1211"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "We propose a new fast algorithm for approximate MAP inference on factor graphs, which combines augmented Lagrangian optimization with the dual decomposition method. Each slave subproblem is given a quadratic penalty, which pushes toward faster consensus than in previous subgradient approaches. Our algorithm is provably convergent, parallelizable, and suitable for fine decompositions of the graph. We show how it can efficiently handle problems with (possibly global) structural constraints via simple sort operations. Experiments on synthetic and real-world data show that our approach compares favorably with the state-of-the-art."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-04-08T21:48:26", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/213"}}, {"publisher": {"name": ""}, "description": "abstract: In many classication problems data samples cannot be collected easily, example in drug trials, biological experiments and study on cancer patients. In many situations the data set size is small and there are many outliers. When classifying such data, example cancer vs normal patients the consequences of mis-classication are probably more important than any other data type, because the data point could be a cancer patient or the classication decision could help determine what gene might be over expressed and perhaps a cause of cancer. These mis-classications are typically higher in the presence of outlier data points. The aim of this thesis is to develop a maximum margin classier that is suited to address the lack of robustness of discriminant based classiers (like the Support Vector Machine (SVM)) to noise and outliers. The underlying notion is to adopt and develop a natural loss function that is more robust to outliers and more representative of the true loss function of the data. It is demonstrated experimentally that SVM's are indeed susceptible to outliers and that the new classier developed, here coined as Robust-SVM (RSVM), is superior to all studied classier on the synthetic datasets. It is superior to the SVM in both the synthetic and experimental data from biomedical studies and is competent to a classier derived on similar lines when real life data examples are considered.", "contributors": [{"name": "Gupta, Sidharth  (Author)", "sameAs": [], "familyName": "Gupta", "additionalName": "", "givenName": "Sidharth", "email": ""}, {"name": "Kim, Seungchan  (Advisor)", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Seungchan", "email": ""}, {"name": "Welfert, Bruno  (Committee member)", "sameAs": [], "familyName": "Welfert", "additionalName": "", "givenName": "Bruno", "email": ""}, {"name": "Li, Baoxin  (Committee member)", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Baoxin", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Robust Margin Based Classifiers For Small Sample Data", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Masters Thesis"}}, {"name": "format", "properties": {"format": "46 pages"}}, {"name": "date", "properties": {"date": "2011"}}, {"name": "description", "properties": {"description": ["abstract: In many classication problems data samples cannot be collected easily, example in drug trials, biological experiments and study on cancer patients. In many situations the data set size is small and there are many outliers. When classifying such data, example cancer vs normal patients the consequences of mis-classication are probably more important than any other data type, because the data point could be a cancer patient or the classication decision could help determine what gene might be over expressed and perhaps a cause of cancer. These mis-classications are typically higher in the presence of outlier data points. The aim of this thesis is to develop a maximum margin classier that is suited to address the lack of robustness of discriminant based classiers (like the Support Vector Machine (SVM)) to noise and outliers. The underlying notion is to adopt and develop a natural loss function that is more robust to outliers and more representative of the true loss function of the data. It is demonstrated experimentally that SVM's are indeed susceptible to outliers and that the new classier developed, here coined as Robust-SVM (RSVM), is superior to all studied classier on the synthetic datasets. It is superior to the SVM in both the synthetic and experimental data from biomedical studies and is competent to a classier derived on similar lines when real life data examples are considered.", "Dissertation/Thesis", "Source Code for RSVM(MATLAB)", "Presentation on RSVM", "M.S. Computer Science 2011"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.9162", "item:9162"]}}], "languages": [null], "subjects": ["overfitting", "small sample", "rsvm", "statistics", "svm", "computer science", "bioinformatics", "classifier"], "providerUpdatedDateTime": "2015-02-12T01:08:46", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.9162"}}, {"publisher": {"name": ""}, "description": "  We study the problem of the transmission of currently observed time variable\nsignals via a channel that is capable of sending a single binary signal only\nfor each measurement of the underlying process. For encoding and decoding, we\nsuggest a modification othe adaptive delta modulation algorithm. This\nmodification ensures tracking of time variable signals. We obtained upper\nestimates for the error for the case of noiseless transmission.\n", "contributors": [{"name": "Dokuchaev, Nikolai", "sameAs": [], "familyName": "Dokuchaev", "additionalName": "", "givenName": "Nikolai", "email": ""}], "title": "Transmission of a continuous signal via one-bit capacity channel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-12", "2014-12-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.3507", "oai:arXiv.org:1312.3507"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We study the problem of the transmission of currently observed time variable\nsignals via a channel that is capable of sending a single binary signal only\nfor each measurement of the underlying process. For encoding and decoding, we\nsuggest a modification othe adaptive delta modulation algorithm. This\nmodification ensures tracking of time variable signals. We obtained upper\nestimates for the error for the case of noiseless transmission.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "94a12", "computer science - information theory", "94a40"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.3507"}}, {"publisher": {"name": ""}, "description": "  This note establishes smooth approximation from above for J-plurisubharmonic\nfunctions on an almost complex manifold (X,J). The following theorem is proved.\nSuppose X is J-pseudoconvex, i.e., X admits a smooth strictly\nJ-plurisubharmonic exhaustion function. Let u be an (upper semi-continuous)\nJ-plurisubharmonic function on X. Then there exists a sequence {u_j} of smooth,\nstrictly J-plurisubharmonic functions point-wise decreasing down to u.\n  On any almost complex manifold (X,J) each point has a fundamental\nneighborhood system of J-pseudoconvex domains, and so the theorem above\nestablishes local smooth approximation on X.\n  This result was proved in complex dimension 2 by the third author, who also\nshowed that the result would hold in general dimensions if a parallel result\nfor continuous approximation were known. This paper establishes the required\nstep by solving the obstacle problem.\n", "contributors": [{"name": "Harvey, F. Reese", "sameAs": [], "familyName": "Harvey", "additionalName": "Reese", "givenName": "F.", "email": ""}, {"name": "Lawson, Jr., H. Blaine", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Lawson", "email": ""}, {"name": "Pli\u015b, Szymon", "sameAs": [], "familyName": "Pli\u015b", "additionalName": "", "givenName": "Szymon", "email": ""}], "title": "Smooth Approximation of Plurisubharmonic Functions on Almost Complex\n  Manifolds", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7137", "oai:arXiv.org:1411.7137"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  This note establishes smooth approximation from above for J-plurisubharmonic\nfunctions on an almost complex manifold (X,J). The following theorem is proved.\nSuppose X is J-pseudoconvex, i.e., X admits a smooth strictly\nJ-plurisubharmonic exhaustion function. Let u be an (upper semi-continuous)\nJ-plurisubharmonic function on X. Then there exists a sequence {u_j} of smooth,\nstrictly J-plurisubharmonic functions point-wise decreasing down to u.\n  On any almost complex manifold (X,J) each point has a fundamental\nneighborhood system of J-pseudoconvex domains, and so the theorem above\nestablishes local smooth approximation on X.\n  This result was proved in complex dimension 2 by the third author, who also\nshowed that the result would hold in general dimensions if a parallel result\nfor continuous approximation were known. This paper establishes the required\nstep by solving the obstacle problem.\n"}}], "languages": [null], "subjects": ["32e99", "32q60", "mathematics - complex variables", "mathematics - symplectic geometry", "53d99", "32u05", "31c10", "32u15", "mathematics - differential geometry"], "providerUpdatedDateTime": "2014-11-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7137"}}, {"publisher": {"name": ""}, "description": "  Devaney and Krych showed that for $0<\\lambda<1/e$ the Julia set of $\\lambda\ne^z$ consists of pairwise disjoint curves, called hairs, which connect finite\npoints, called the endpoints of the hairs, with $\\infty$. McMullen showed that\nthe Julia set has Hausdorff dimension $2$ and Karpi\\'nska showed that the set\nof hairs without endpoints has Hausdorff dimension $1$. We study for which\ngauge functions the Hausdorff measure of the set of hairs without endpoints is\nfinite.\n", "contributors": [{"name": "Bergweiler, Walter", "sameAs": [], "familyName": "Bergweiler", "additionalName": "", "givenName": "Walter", "email": ""}, {"name": "Wang, Jun", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Jun", "email": ""}], "title": "Hausdorff measure of hairs without endpoints in the exponential family", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01961", "oai:arXiv.org:1502.01961"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Devaney and Krych showed that for $0<\\lambda<1/e$ the Julia set of $\\lambda\ne^z$ consists of pairwise disjoint curves, called hairs, which connect finite\npoints, called the endpoints of the hairs, with $\\infty$. McMullen showed that\nthe Julia set has Hausdorff dimension $2$ and Karpi\\'nska showed that the set\nof hairs without endpoints has Hausdorff dimension $1$. We study for which\ngauge functions the Hausdorff measure of the set of hairs without endpoints is\nfinite.\n", "Comment: 18 pages"]}}], "languages": [null], "subjects": ["37f10", "30d05", "mathematics - dynamical systems", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01961"}}, {"publisher": {"name": ""}, "description": "  One long-standing question in epidemiological research is how best to\nallocate limited amounts of vaccine or similar preventative measures in order\nto minimize the severity of an epidemic. Much of the literature on the problem\nof vaccine allocation has focused on influenza epidemics and used mathematical\nmodels of epidemic spread to determine the effectiveness of proposed methods.\nOur work applies computational models of epidemics to the problem of\ngeographically allocating a limited number of vaccines within several Texas\ncounties. We developed a graph-based, stochastic model for epidemics that is\nbased on the SEIR model, and tested vaccine allocation methods based on\nmultiple centrality measures. This approach provides an alternative method for\naddressing the vaccine allocation problem, which can be combined with more\nconventional approaches to yield more effective epidemic suppression\nstrategies. We found that allocation methods based on in-degree and inverse\nbetweenness centralities tended to be the most effective at containing\nepidemics.\n", "contributors": [{"name": "Drewniak, Krzysztof", "sameAs": [], "familyName": "Drewniak", "additionalName": "", "givenName": "Krzysztof", "email": ""}, {"name": "Helsing, Joseph", "sameAs": [], "familyName": "Helsing", "additionalName": "", "givenName": "Joseph", "email": ""}, {"name": "Mikler, Armin R.", "sameAs": [], "familyName": "Mikler", "additionalName": "R.", "givenName": "Armin", "email": ""}], "title": "A Method for Reducing the Severity of Epidemics by Allocating Vaccines\n  According to Centrality", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-07-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.7288", "doi:10.1145/2649387.2649409", "oai:arXiv.org:1407.7288"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  One long-standing question in epidemiological research is how best to\nallocate limited amounts of vaccine or similar preventative measures in order\nto minimize the severity of an epidemic. Much of the literature on the problem\nof vaccine allocation has focused on influenza epidemics and used mathematical\nmodels of epidemic spread to determine the effectiveness of proposed methods.\nOur work applies computational models of epidemics to the problem of\ngeographically allocating a limited number of vaccines within several Texas\ncounties. We developed a graph-based, stochastic model for epidemics that is\nbased on the SEIR model, and tested vaccine allocation methods based on\nmultiple centrality measures. This approach provides an alternative method for\naddressing the vaccine allocation problem, which can be combined with more\nconventional approaches to yield more effective epidemic suppression\nstrategies. We found that allocation methods based on in-degree and inverse\nbetweenness centralities tended to be the most effective at containing\nepidemics.\n", "Comment: 10 pages, accepted to ACM BCB 2014"]}}], "languages": [null], "subjects": ["j.3", "g.2.2", "finance", "and science", "computer science - social and information networks", "physics - physics and society", "computer science - computational engineering"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.7288"}}, {"publisher": {"name": ""}, "description": "  For every Gaussian network, there exists a corresponding deterministic\nnetwork called the discrete superposition network. We show that this discrete\nsuperposition network provides a near-optimal digital interface for operating a\nclass consisting of many Gaussian networks in the sense that any code for the\ndiscrete superposition network can be naturally lifted to a corresponding code\nfor the Gaussian network, while achieving a rate that is no more than a\nconstant number of bits lesser than the rate it achieves for the discrete\nsuperposition network. This constant depends only on the number of nodes in the\nnetwork and not on the channel gains or SNR. Moreover the capacities of the two\nnetworks are within a constant of each other, again independent of channel\ngains and SNR. We show that the class of Gaussian networks for which this\ninterface property holds includes relay networks with a single\nsource-destination pair, interference networks, multicast networks, and the\ncounterparts of these networks with multiple transmit and receive antennas.\n  The code for the Gaussian relay network can be obtained from any code for the\ndiscrete superposition network simply by pruning it. This lifting scheme\nestablishes that the superposition model can indeed potentially serve as a\nstrong surrogate for designing codes for Gaussian relay networks.\n  We present similar results for the K x K Gaussian interference network, MIMO\nGaussian interference networks, MIMO Gaussian relay networks, and multicast\nnetworks, with the constant gap depending additionally on the number of\nantennas in case of MIMO networks.\n", "contributors": [{"name": "Anand, M.", "sameAs": [], "familyName": "Anand", "additionalName": "", "givenName": "M.", "email": ""}, {"name": "Kumar, P. R.", "sameAs": [], "familyName": "Kumar", "additionalName": "R.", "givenName": "P.", "email": ""}], "title": "A digital interface for Gaussian relay and interference networks:\n  Lifting codes from the discrete superposition model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-05-02", "2011-05-20"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.0167", "Special issue on interference Networks, IEEE Trans. Info. Theory,\n  vol. 57, no. 5, pp. 2548 - 2564, May 2011", "doi:10.1109/TIT.2011.2120070", "oai:arXiv.org:1005.0167"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  For every Gaussian network, there exists a corresponding deterministic\nnetwork called the discrete superposition network. We show that this discrete\nsuperposition network provides a near-optimal digital interface for operating a\nclass consisting of many Gaussian networks in the sense that any code for the\ndiscrete superposition network can be naturally lifted to a corresponding code\nfor the Gaussian network, while achieving a rate that is no more than a\nconstant number of bits lesser than the rate it achieves for the discrete\nsuperposition network. This constant depends only on the number of nodes in the\nnetwork and not on the channel gains or SNR. Moreover the capacities of the two\nnetworks are within a constant of each other, again independent of channel\ngains and SNR. We show that the class of Gaussian networks for which this\ninterface property holds includes relay networks with a single\nsource-destination pair, interference networks, multicast networks, and the\ncounterparts of these networks with multiple transmit and receive antennas.\n  The code for the Gaussian relay network can be obtained from any code for the\ndiscrete superposition network simply by pruning it. This lifting scheme\nestablishes that the superposition model can indeed potentially serve as a\nstrong surrogate for designing codes for Gaussian relay networks.\n  We present similar results for the K x K Gaussian interference network, MIMO\nGaussian interference networks, MIMO Gaussian relay networks, and multicast\nnetworks, with the constant gap depending additionally on the number of\nantennas in case of MIMO networks.\n", "Comment: Final version"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.0167"}}, {"publisher": {"name": ""}, "description": "  Vehicular communication channels are characterized by a non-stationary time-\nand frequency-selective fading process due to fast changes in the environment.\nWe characterize the distribution of the envelope of the first delay bin in\nvehicle-to-vehicle channels by means of its Rician $K$-factor. We analyze the\ntime-frequency variability of this channel parameter using vehicular channel\nmeasurements at 5.6 GHz with a bandwidth of 240 MHz for safety-relevant\nscenarios in intelligent transportation systems (ITS). This data enables a\nfrequency-variability analysis from an IEEE 802.11p system point of view, which\nuses 10 MHz channels. We show that the small-scale fading of the envelope of\nthe first delay bin is Ricean distributed with a varying $K$-factor. The later\ndelay bins are Rayleigh distributed. We demonstrate that the $K$-factor cannot\nbe assumed to be constant in time and frequency. The causes of these variations\nare the frequency-varying antenna radiation patterns as well as the\ntime-varying number of active scatterers, and the effects of vegetation. We\nalso present a simple but accurate bi-modal Gaussian mixture model, that allows\nto capture the $K$-factor variability in time for safety-relevant ITS\nscenarios.\n", "contributors": [{"name": "Bernad\u00f3, Laura", "sameAs": [], "familyName": "Bernad\u00f3", "additionalName": "", "givenName": "Laura", "email": ""}, {"name": "Zemen, Thomas", "sameAs": [], "familyName": "Zemen", "additionalName": "", "givenName": "Thomas", "email": ""}, {"name": "Tufvesson, Fredrik", "sameAs": [], "familyName": "Tufvesson", "additionalName": "", "givenName": "Fredrik", "email": ""}, {"name": "Molisch, Andreas F.", "sameAs": [], "familyName": "Molisch", "additionalName": "F.", "givenName": "Andreas", "email": ""}, {"name": "Mecklenbr\u00e4uker, Christoph F.", "sameAs": [], "familyName": "Mecklenbr\u00e4uker", "additionalName": "F.", "givenName": "Christoph", "email": ""}], "title": "Time- and Frequency-Varying $K$-Factor of Non-Stationary Vehicular\n  Channels for Safety Relevant Scenarios", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-17", "2014-04-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.3914", "IEEE Transactions on Intelligent Transportation Systems, vol. 16,\n  no. 2, April 2015", "doi:10.1109/TITS.2014.2349364", "oai:arXiv.org:1306.3914"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Vehicular communication channels are characterized by a non-stationary time-\nand frequency-selective fading process due to fast changes in the environment.\nWe characterize the distribution of the envelope of the first delay bin in\nvehicle-to-vehicle channels by means of its Rician $K$-factor. We analyze the\ntime-frequency variability of this channel parameter using vehicular channel\nmeasurements at 5.6 GHz with a bandwidth of 240 MHz for safety-relevant\nscenarios in intelligent transportation systems (ITS). This data enables a\nfrequency-variability analysis from an IEEE 802.11p system point of view, which\nuses 10 MHz channels. We show that the small-scale fading of the envelope of\nthe first delay bin is Ricean distributed with a varying $K$-factor. The later\ndelay bins are Rayleigh distributed. We demonstrate that the $K$-factor cannot\nbe assumed to be constant in time and frequency. The causes of these variations\nare the frequency-varying antenna radiation patterns as well as the\ntime-varying number of active scatterers, and the effects of vegetation. We\nalso present a simple but accurate bi-modal Gaussian mixture model, that allows\nto capture the $K$-factor variability in time for safety-relevant ITS\nscenarios.\n", "Comment: 26 pages, 12 figures, submitted to IEEE Transactions on Intelligent\n  Transportation Systems for possible publication"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.3914"}}, {"publisher": {"name": ""}, "description": "  This paper compares the Value--at--Risk (VaR) forecasts delivered by\nalternative model specifications using the Model Confidence Set (MCS) procedure\nrecently developed by Hansen et al. (2011). The direct VaR estimate provided by\nthe Conditional Autoregressive Value--at--Risk (CAViaR) models of Eengle and\nManganelli (2004) are compared to those obtained by the popular Autoregressive\nConditional Heteroskedasticity (ARCH) models of Engle (1982) and to the\nrecently introduced Generalised Autoregressive Score (GAS) models of Creal et\nal. (2013) and Harvey (2013). The Hansen's procedure consists on a sequence of\ntests which permits to construct a set of \"superior\" models, where the null\nhypothesis of Equal Predictive Ability (EPA) is not rejected at a certain\nconfidence level. Our empirical results, suggest that, after the Global\nFinancial Crisis (GFC) of 2007-2008, highly non-linear volatility models\ndeliver better VaR forecasts for the European countries as opposed to other\nregions. The R package MCS is introduced for performing the model comparisons\nwhose main features are discussed throughout the paper.\n", "contributors": [{"name": "Bernardi, Mauro", "sameAs": [], "familyName": "Bernardi", "additionalName": "", "givenName": "Mauro", "email": ""}, {"name": "Catania, Leopoldo", "sameAs": [], "familyName": "Catania", "additionalName": "", "givenName": "Leopoldo", "email": ""}], "title": "Comparison of Value-at-Risk models: the MCS package", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04472", "oai:arXiv.org:1502.04472"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": ["  This paper compares the Value--at--Risk (VaR) forecasts delivered by\nalternative model specifications using the Model Confidence Set (MCS) procedure\nrecently developed by Hansen et al. (2011). The direct VaR estimate provided by\nthe Conditional Autoregressive Value--at--Risk (CAViaR) models of Eengle and\nManganelli (2004) are compared to those obtained by the popular Autoregressive\nConditional Heteroskedasticity (ARCH) models of Engle (1982) and to the\nrecently introduced Generalised Autoregressive Score (GAS) models of Creal et\nal. (2013) and Harvey (2013). The Hansen's procedure consists on a sequence of\ntests which permits to construct a set of \"superior\" models, where the null\nhypothesis of Equal Predictive Ability (EPA) is not rejected at a certain\nconfidence level. Our empirical results, suggest that, after the Global\nFinancial Crisis (GFC) of 2007-2008, highly non-linear volatility models\ndeliver better VaR forecasts for the European countries as opposed to other\nregions. The R package MCS is introduced for performing the model comparisons\nwhose main features are discussed throughout the paper.\n", "Comment: 25 pages. arXiv admin note: substantial text overlap with\n  arXiv:1410.8504"]}}], "languages": [null], "subjects": ["statistics - computation"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04472"}}, {"publisher": {"name": ""}, "description": "  The achievable and converse regions for sparse representation of white\nGaussian noise based on an overcomplete dictionary are derived in the limit of\nlarge systems. Furthermore, the marginal distribution of such sparse\nrepresentations is also inferred. The results are obtained via the Replica\nmethod which stems from statistical mechanics. A direct outcome of these\nresults is the introduction of sharp threshold for $\\ell_{0}$-norm decoding in\nnoisy compressed sensing, and its mean-square error for underdetermined\nGaussian vector channels.\n", "contributors": [{"name": "Shental, Ori", "sameAs": [], "familyName": "Shental", "additionalName": "", "givenName": "Ori", "email": ""}], "title": "Sparse Representation of White Gaussian Noise with Application to\n  L0-Norm Decoding in Noisy Compressed Sensing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-12", "2011-12-20"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.2215", "oai:arXiv.org:1104.2215"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The achievable and converse regions for sparse representation of white\nGaussian noise based on an overcomplete dictionary are derived in the limit of\nlarge systems. Furthermore, the marginal distribution of such sparse\nrepresentations is also inferred. The results are obtained via the Replica\nmethod which stems from statistical mechanics. A direct outcome of these\nresults is the introduction of sharp threshold for $\\ell_{0}$-norm decoding in\nnoisy compressed sensing, and its mean-square error for underdetermined\nGaussian vector channels.\n", "Comment: VER1"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.2215"}}, {"publisher": {"name": "Virginia Tech"}, "description": "Reticulitermids were significantly more likely to discover subterranean baits connected by physical guidelines than freestanding baits under both laboratory and field conditions.  In the laboratory, subterranean termites built significantly longer tunnels adjacent to cellulosic guidelines than plastic guidelines.   In the field, all guideline materials were equally effective at directing tunneling activity.   Reticulitermes spp. workers were tested to determine their preferred substrate temperature.  The preferred range for Reticulitermes spp. workers was found to be 18 to 27 degrees C.   A laboratory bioassay was performed to determine if Reticulitermes spp. aggregates within thermal shadows.  Significantly more Reticulitermes spp. workers aggregated within cool thermal shadows than control areas.   In a multiple choice bioassay, mean consumption was higher for paper baits treated with fructose, galactose, glucose, raffinose, sucrose, trehalose and uric acid than for control baits.  In a multiple choice bioassay, mean consumption was significantly lower for baits treated with arbutin, and most amino acids than for control baits.  In the no-choice bioassay, the amount of paper bait consumed did not differ significantly for any of the treated baits tested and control baits.", "contributors": [{"name": "Swoboda, Lois Elizabeth", "sameAs": [], "familyName": "Swoboda", "additionalName": "Elizabeth", "givenName": "Lois", "email": ""}, {"name": "Fell, Richard D.", "sameAs": [], "familyName": "Fell", "additionalName": "D.", "givenName": "Richard", "email": ""}, {"name": "Weaver, Michael J.", "sameAs": [], "familyName": "Weaver", "additionalName": "J.", "givenName": "Michael", "email": ""}, {"name": "Mullins, Donald E.", "sameAs": [], "familyName": "Mullins", "additionalName": "E.", "givenName": "Donald", "email": ""}, {"name": "Miller, Dini M.", "sameAs": [], "familyName": "Miller", "additionalName": "M.", "givenName": "Dini", "email": ""}, {"name": "Schabenberger, Oliver", "sameAs": [], "familyName": "Schabenberger", "additionalName": "", "givenName": "Oliver", "email": ""}, {"name": "Entomology", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Entomology", "email": ""}], "title": "Environmental Influences on Subterranean Termite Foraging Behavior and Bait Acceptance", "shareProperties": {"source": "vtech"}, "otherProperties": [{"name": "type", "properties": {"type": "Other - Dissertation"}}, {"name": "source", "properties": {"source": "http://scholar.lib.vt.edu/theses/available/etd-05262004-184108"}}, {"name": "format", "properties": {"format": "ETD"}}, {"name": "date", "properties": {"date": ["2011-08-22T19:02:28Z", "2011-08-22T19:02:28Z", "2004-07-06"]}}, {"name": "identifier", "properties": {"identifier": ["etd-05262004-184108", "http://hdl.handle.net/10919/11205", "oai:vtechworks.lib.vt.edu:10919/11205"]}}, {"name": "setSpec", "properties": {"setSpec": ["com_10919_5534", "col_10919_11041"]}}, {"name": "rights", "properties": {"rights": "The authors of the theses and dissertations are the copyright owners.  Virginia Tech's Digital Library and Archives has their permission to store and provide access to these works."}}, {"name": "relation", "properties": {"relation": "Onefilegood.pdf"}}], "languages": [null], "subjects": ["foraging", "temperature", "nutrients", "subterranean termites", "wood thermoplastic composites", "physical guidelines"], "providerUpdatedDateTime": "2015-03-24T12:02:47", "uris": {"canonicalUri": "http://hdl.handle.net/10919/11205"}}, {"publisher": {"name": ""}, "description": "  Often, when analyzing the behaviour of systems modelled as context-free\nlanguages, we wish to know if two languages overlap. To this end, we present an\neffective semi-decision procedure for regular separability of context-free\nlanguages, based on counter-example guided abstraction refinement. We propose\ntwo refinement methods, one inexpensive but incomplete, and the other complete\nbut more expensive. We provide an experimental evaluation of this procedure,\nand demonstrate its practicality on a range of verification and\nlanguage-theoretic instances.\n", "contributors": [{"name": "Gange, Graeme", "sameAs": [], "familyName": "Gange", "additionalName": "", "givenName": "Graeme", "email": ""}, {"name": "Navas, Jorge A.", "sameAs": [], "familyName": "Navas", "additionalName": "A.", "givenName": "Jorge", "email": ""}, {"name": "Schachte, Peter", "sameAs": [], "familyName": "Schachte", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Sondergaard, Harald", "sameAs": [], "familyName": "Sondergaard", "additionalName": "", "givenName": "Harald", "email": ""}, {"name": "Stuckey, Peter J.", "sameAs": [], "familyName": "Stuckey", "additionalName": "J.", "givenName": "Peter", "email": ""}], "title": "A Complete Refinement Procedure for Regular Separability of Context-Free\n  Languages", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5131", "oai:arXiv.org:1411.5131"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Often, when analyzing the behaviour of systems modelled as context-free\nlanguages, we wish to know if two languages overlap. To this end, we present an\neffective semi-decision procedure for regular separability of context-free\nlanguages, based on counter-example guided abstraction refinement. We propose\ntwo refinement methods, one inexpensive but incomplete, and the other complete\nbut more expensive. We provide an experimental evaluation of this procedure,\nand demonstrate its practicality on a range of verification and\nlanguage-theoretic instances.\n"}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2014-11-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5131"}}, {"publisher": {"name": ""}, "description": "  We formalize and analyze a new automata-theoretic problem termed control\nimprovisation. Given an automaton, the problem is to produce an improviser, a\nprobabilistic algorithm that randomly generates words in its language, subject\nto two additional constraints: the satisfaction of an admissibility predicate,\nand exhibition of a specified amount of randomness. This problem has proved\nuseful, for example, in generating musical improvisations that satisfy rhythmic\nand melodic constraints, where admissibility was determined by some bounded\ndivergence from a reference melody. We analyze the complexity of the control\nimprovisation problem, giving cases where it is efficiently solvable and cases\nwhere it is #P-hard or undecidable. We also show how symbolic techniques based\non SAT solvers can be used to approximately solve some of the intractable\ncases.\n", "contributors": [{"name": "Fremont, Daniel J.", "sameAs": [], "familyName": "Fremont", "additionalName": "J.", "givenName": "Daniel", "email": ""}, {"name": "Donz\u00e9, Alexandre", "sameAs": [], "familyName": "Donz\u00e9", "additionalName": "", "givenName": "Alexandre", "email": ""}, {"name": "Seshia, Sanjit A.", "sameAs": [], "familyName": "Seshia", "additionalName": "A.", "givenName": "Sanjit", "email": ""}, {"name": "Wessel, David", "sameAs": [], "familyName": "Wessel", "additionalName": "", "givenName": "David", "email": ""}], "title": "Control Improvisation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-03", "2015-03-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0698", "oai:arXiv.org:1411.0698"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We formalize and analyze a new automata-theoretic problem termed control\nimprovisation. Given an automaton, the problem is to produce an improviser, a\nprobabilistic algorithm that randomly generates words in its language, subject\nto two additional constraints: the satisfaction of an admissibility predicate,\nand exhibition of a specified amount of randomness. This problem has proved\nuseful, for example, in generating musical improvisations that satisfy rhythmic\nand melodic constraints, where admissibility was determined by some bounded\ndivergence from a reference melody. We analyze the complexity of the control\nimprovisation problem, giving cases where it is efficiently solvable and cases\nwhere it is #P-hard or undecidable. We also show how symbolic techniques based\non SAT solvers can be used to approximately solve some of the intractable\ncases.\n", "Comment: 16 pages"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0698"}}, {"publisher": {"name": ""}, "description": "  We consider planning with uncertainty in the initial state as a case study of\nincremental quantified Boolean formula (QBF) solving. We report on experiments\nwith a workflow to incrementally encode a planning instance into a sequence of\nQBFs. To solve this sequence of incrementally constructed QBFs, we use our\ngeneral-purpose incremental QBF solver DepQBF. Since the generated QBFs have\nmany clauses and variables in common, our approach avoids redundancy both in\nthe encoding phase and in the solving phase. Experimental results show that\nincremental QBF solving outperforms non-incremental QBF solving. Our results\nare the first empirical study of incremental QBF solving in the context of\nplanning and motivate its use in other application domains.\n", "contributors": [{"name": "Egly, Uwe", "sameAs": [], "familyName": "Egly", "additionalName": "", "givenName": "Uwe", "email": ""}, {"name": "Kronegger, Martin", "sameAs": [], "familyName": "Kronegger", "additionalName": "", "givenName": "Martin", "email": ""}, {"name": "Lonsing, Florian", "sameAs": [], "familyName": "Lonsing", "additionalName": "", "givenName": "Florian", "email": ""}, {"name": "Pfandler, Andreas", "sameAs": [], "familyName": "Pfandler", "additionalName": "", "givenName": "Andreas", "email": ""}], "title": "Conformant Planning as a Case Study of Incremental QBF Solving", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-28", "2014-10-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.7253", "doi:10.1007/978-3-319-13770-4_11", "oai:arXiv.org:1405.7253"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We consider planning with uncertainty in the initial state as a case study of\nincremental quantified Boolean formula (QBF) solving. We report on experiments\nwith a workflow to incrementally encode a planning instance into a sequence of\nQBFs. To solve this sequence of incrementally constructed QBFs, we use our\ngeneral-purpose incremental QBF solver DepQBF. Since the generated QBFs have\nmany clauses and variables in common, our approach avoids redundancy both in\nthe encoding phase and in the solving phase. Experimental results show that\nincremental QBF solving outperforms non-incremental QBF solving. Our results\nare the first empirical study of incremental QBF solving in the context of\nplanning and motivate its use in other application domains.\n", "Comment: revision (camera-ready, to appear in the proceedings of AISC 2014,\n  volume 8884 of LNAI, Springer)"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - logic in computer science"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.7253"}}, {"publisher": {"name": ""}, "description": "  Although the many forms of modern social media have become major channels for\nthe dissemination of information, they are becoming overloaded because of the\nrapidly-expanding number of information feeds. We analyze the expanding\nuser-generated content in Sina Weibo, the largest micro-blog site in China, and\nfind evidence that popular messages often follow a mechanism that differs from\nthat found in the spread of disease, in contrast to common believe. In this\nmechanism, an individual with more friends needs more repeated exposures to\nspread further the information. Moreover, our data suggest that in contrast to\nepidemics, for certain messages the chance of an individual to share the\nmessage is proportional to the fraction of its neighbours who shared it with\nhim/her. Thus the greater the number of friends an individual has the greater\nthe number of repeated contacts needed to spread the message, which is a result\nof competition for attention. We model this process using a fractional\nsusceptible infected recovered (FSIR) model, where the infection probability of\na node is proportional to its fraction of infected neighbors. Our findings have\ndramatic implications for information contagion. For example, using the FSIR\nmodel we find that real-world social networks have a finite epidemic threshold.\nThis is in contrast to the zero threshold that conventional wisdom derives from\ndisease epidemic models. This means that when individuals are overloaded with\nexcess information feeds, the information either reaches out the population if\nit is above the critical epidemic threshold, or it would never be well\nreceived, leading to only a handful of information contents that can be widely\nspread throughout the population.\n", "contributors": [{"name": "Feng, Ling", "sameAs": [], "familyName": "Feng", "additionalName": "", "givenName": "Ling", "email": ""}, {"name": "Hu, Yanqing", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Yanqing", "email": ""}, {"name": "Li, Baowen", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Baowen", "email": ""}, {"name": "Stanley, H. Eugene", "sameAs": [], "familyName": "Stanley", "additionalName": "Eugene", "givenName": "H.", "email": ""}, {"name": "Havlin, Shlomo", "sameAs": [], "familyName": "Havlin", "additionalName": "", "givenName": "Shlomo", "email": ""}, {"name": "Braunstein, Lidia A.", "sameAs": [], "familyName": "Braunstein", "additionalName": "A.", "givenName": "Lidia", "email": ""}], "title": "Competing for Attention in Social Media under Information Overload\n  Conditions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1668", "oai:arXiv.org:1410.1668"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Although the many forms of modern social media have become major channels for\nthe dissemination of information, they are becoming overloaded because of the\nrapidly-expanding number of information feeds. We analyze the expanding\nuser-generated content in Sina Weibo, the largest micro-blog site in China, and\nfind evidence that popular messages often follow a mechanism that differs from\nthat found in the spread of disease, in contrast to common believe. In this\nmechanism, an individual with more friends needs more repeated exposures to\nspread further the information. Moreover, our data suggest that in contrast to\nepidemics, for certain messages the chance of an individual to share the\nmessage is proportional to the fraction of its neighbours who shared it with\nhim/her. Thus the greater the number of friends an individual has the greater\nthe number of repeated contacts needed to spread the message, which is a result\nof competition for attention. We model this process using a fractional\nsusceptible infected recovered (FSIR) model, where the infection probability of\na node is proportional to its fraction of infected neighbors. Our findings have\ndramatic implications for information contagion. For example, using the FSIR\nmodel we find that real-world social networks have a finite epidemic threshold.\nThis is in contrast to the zero threshold that conventional wisdom derives from\ndisease epidemic models. This means that when individuals are overloaded with\nexcess information feeds, the information either reaches out the population if\nit is above the critical epidemic threshold, or it would never be well\nreceived, leading to only a handful of information contents that can be widely\nspread throughout the population.\n", "Comment: 11 pages, 5 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-10-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1668"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Association mapping studies promise to link DNA mutations to gene expression data, possibly leading to innovative treatments for diseases. One challenge in large-scale association mapping studies is exploring the results of the computational analysis to find relevant and interesting associations. Although many association mapping studies find associations from a genome-wide collection of genomic data to hundreds or thousands of traits, current visualization software only allow these associations to be explored one trait at a time. The inability to explore the association of a genomic location to multiple traits hides the inherent interaction between traits in the analysis. Additionally, researchers must rely on collections of in-house scripts and multiple tools to perform an analysis, adding time and effort to find interesting associations. In this paper, we present a novel visual analytics system called GenAMap. GenAMap replaces the time-consuming analysis of large-scale association mapping studies with exploratory visualization tools that give geneticists an overview of the data and lead them to relevant information. We present the results of a preliminary evaluation that validated our basic approach.", "contributors": [{"name": "Curtis, Ross E.", "sameAs": [], "familyName": "Curtis", "additionalName": "E.", "givenName": "Ross", "email": ""}, {"name": "Kinnaird, Peter", "sameAs": [], "familyName": "Kinnaird", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "GenAMap: Visualization Strategies for Structured Association Mapping", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2011-10-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/215", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1209&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1209"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Association mapping studies promise to link DNA mutations to gene expression data, possibly leading to innovative treatments for diseases. One challenge in large-scale association mapping studies is exploring the results of the computational analysis to find relevant and interesting associations. Although many association mapping studies find associations from a genome-wide collection of genomic data to hundreds or thousands of traits, current visualization software only allow these associations to be explored one trait at a time. The inability to explore the association of a genomic location to multiple traits hides the inherent interaction between traits in the analysis. Additionally, researchers must rely on collections of in-house scripts and multiple tools to perform an analysis, adding time and effort to find interesting associations. In this paper, we present a novel visual analytics system called GenAMap. GenAMap replaces the time-consuming analysis of large-scale association mapping studies with exploratory visualization tools that give geneticists an overview of the data and lead them to relevant information. We present the results of a preliminary evaluation that validated our basic approach."}}], "languages": [null], "subjects": ["visual analytics", "theory and algorithms", "structured association mapping", "computer sciences", "eqtl analysis", "genome-wide association studies"], "providerUpdatedDateTime": "2015-04-08T21:48:31", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/215"}}, {"publisher": {"name": ""}, "description": "  Bayesian Networks (BNs) are popular graphical models for the representation\nof statistical problems embodying dependence relationships between a number of\nvariables. Much of this popularity is due to the d-separation theorem of Pearl\nand Lauritzen, which allows an analyst to identify the conditional independence\nstatements that a model of the problem embodies using only the topology of the\ngraph. However for many problems the complete model dependence structure cannot\nbe depicted by a BN. The Chain Event Graph (CEG) was introduced for these types\nof problem. In this paper we introduce a separation theorem for CEGs, analogous\nto the d-separation theorem for BNs, which likewise allows an analyst to\nidentify the conditional independence structure of their model from the\ntopology of the graph.\n", "contributors": [{"name": "Thwaites, Peter A.", "sameAs": [], "familyName": "Thwaites", "additionalName": "A.", "givenName": "Peter", "email": ""}, {"name": "Smith, Jim Q.", "sameAs": [], "familyName": "Smith", "additionalName": "Q.", "givenName": "Jim", "email": ""}], "title": "A Separation Theorem for Chain Event Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05215", "oai:arXiv.org:1501.05215"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Bayesian Networks (BNs) are popular graphical models for the representation\nof statistical problems embodying dependence relationships between a number of\nvariables. Much of this popularity is due to the d-separation theorem of Pearl\nand Lauritzen, which allows an analyst to identify the conditional independence\nstatements that a model of the problem embodies using only the topology of the\ngraph. However for many problems the complete model dependence structure cannot\nbe depicted by a BN. The Chain Event Graph (CEG) was introduced for these types\nof problem. In this paper we introduce a separation theorem for CEGs, analogous\nto the d-separation theorem for BNs, which likewise allows an analyst to\nidentify the conditional independence structure of their model from the\ntopology of the graph.\n", "Comment: 39 pages, 10 figures. Submitted to Electronic Journal of Statistics"]}}], "languages": [null], "subjects": ["68t37 (secondary)", "computer science - artificial intelligence", "62f15 (primary)", "statistics - methodology"], "providerUpdatedDateTime": "2015-01-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05215"}}, {"publisher": {"name": ""}, "description": "  Stencil computations on low dimensional grids are kernels of many scientific\napplications including finite difference methods used to solve partial\ndifferential equations. On typical modern computer architectures, such stencil\ncomputations are limited by the performance of the memory subsystem, namely by\nthe bandwidth between main memory and the cache. This work considers the\ncomputation of star stencils, like the 5-point and 7-point stencil, in the\nexternal memory model and parallel external memory model and analyses the\nconstant of the leading term of the non-compulsory I/Os. While optimizing\nstencil computations is an active field of research, there has been a\nsignificant gap between the lower bounds and the performance of the algorithms\nso far. In two dimensions, this work provides matching constants for lower and\nupper bounds closing a multiplicative gap of 4. In three dimensions, the bounds\nmatch up to a factor of $\\sqrt{2}$ improving the known results by a factor of\n$2 \\sqrt{3}\\sqrt{B}$, where $B$ is the block (cache line) size of the external\nmemory model. For dimensions $d\\geq 4$, the lower bound is improved between a\nfactor of $4$ and $6$. For arbitrary dimension~$d$, the first analysis of the\nconstant of the leading term of the non-compulsory I/Os is presented. For\n$d\\geq 3$ the lower and upper bound match up to a factor of\n$\\sqrt[d-1]{d!}\\approx \\frac{d}{e}$.\n", "contributors": [{"name": "Hupp, Philipp", "sameAs": [], "familyName": "Hupp", "additionalName": "", "givenName": "Philipp", "email": ""}, {"name": "Jacob, Riko", "sameAs": [], "familyName": "Jacob", "additionalName": "", "givenName": "Riko", "email": ""}], "title": "Tight Bounds for Low Dimensional Star Stencils in the Parallel External\n  Memory Model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-05-02", "2015-01-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.0606", "WADS 2013, LNCS 8037, pp. 415-426, 2013", "doi:10.1007/978-3-642-40104-6_36", "oai:arXiv.org:1205.0606"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Stencil computations on low dimensional grids are kernels of many scientific\napplications including finite difference methods used to solve partial\ndifferential equations. On typical modern computer architectures, such stencil\ncomputations are limited by the performance of the memory subsystem, namely by\nthe bandwidth between main memory and the cache. This work considers the\ncomputation of star stencils, like the 5-point and 7-point stencil, in the\nexternal memory model and parallel external memory model and analyses the\nconstant of the leading term of the non-compulsory I/Os. While optimizing\nstencil computations is an active field of research, there has been a\nsignificant gap between the lower bounds and the performance of the algorithms\nso far. In two dimensions, this work provides matching constants for lower and\nupper bounds closing a multiplicative gap of 4. In three dimensions, the bounds\nmatch up to a factor of $\\sqrt{2}$ improving the known results by a factor of\n$2 \\sqrt{3}\\sqrt{B}$, where $B$ is the block (cache line) size of the external\nmemory model. For dimensions $d\\geq 4$, the lower bound is improved between a\nfactor of $4$ and $6$. For arbitrary dimension~$d$, the first analysis of the\nconstant of the leading term of the non-compulsory I/Os is presented. For\n$d\\geq 3$ the lower and upper bound match up to a factor of\n$\\sqrt[d-1]{d!}\\approx \\frac{d}{e}$.\n", "Comment: 64 pages, 8 figures, 4 tables"]}}], "languages": [null], "subjects": ["computer science - computational complexity"], "providerUpdatedDateTime": "2015-01-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.0606"}}, {"publisher": {"name": ""}, "description": "  Sensitivity, certificate complexity and block sensitivity are widely used\nBoolean function complexity measures. A longstanding open problem, proposed by\nNisan and Szegedy, is whether sensitivity and block sensitivity are\npolynomially related. Motivated by the constructions of functions which achieve\nthe largest known separations, we study the relation between 1-certificate\ncomplexity and 0-sensitivity and 0-block sensitivity.\n  Previously the best known lower bound was $C_1(f)\\geq \\frac{bs_0(f)}{2\ns_0(f)}$, achieved by Kenyon and Kutin. We improve this to $C_1(f)\\geq \\frac{3\nbs_0(f)}{2 s_0(f)}$. While this improvement is only by a constant factor, this\nis quite important, as it precludes achieving a superquadratic separation\nbetween $bs(f)$ and $s(f)$ by iterating functions which reach this bound. In\naddition, this bound is tight, as it matches the construction of Ambainis and\nSun up to an additive constant.\n", "contributors": [{"name": "Ambainis, Andris", "sameAs": [], "familyName": "Ambainis", "additionalName": "", "givenName": "Andris", "email": ""}, {"name": "Pr\u016bsis, Kri\u0161j\u0101nis", "sameAs": [], "familyName": "Pr\u016bsis", "additionalName": "", "givenName": "Kri\u0161j\u0101nis", "email": ""}], "title": "A Tight Lower Bound on Certificate Complexity in Terms of Block\n  Sensitivity and Sensitivity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-20", "2014-07-31"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.5078", "doi:10.1007/978-3-662-44465-8_4", "oai:arXiv.org:1402.5078"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Sensitivity, certificate complexity and block sensitivity are widely used\nBoolean function complexity measures. A longstanding open problem, proposed by\nNisan and Szegedy, is whether sensitivity and block sensitivity are\npolynomially related. Motivated by the constructions of functions which achieve\nthe largest known separations, we study the relation between 1-certificate\ncomplexity and 0-sensitivity and 0-block sensitivity.\n  Previously the best known lower bound was $C_1(f)\\geq \\frac{bs_0(f)}{2\ns_0(f)}$, achieved by Kenyon and Kutin. We improve this to $C_1(f)\\geq \\frac{3\nbs_0(f)}{2 s_0(f)}$. While this improvement is only by a constant factor, this\nis quite important, as it precludes achieving a superquadratic separation\nbetween $bs(f)$ and $s(f)$ by iterating functions which reach this bound. In\naddition, this bound is tight, as it matches the construction of Ambainis and\nSun up to an additive constant.\n", "Comment: 12 pages"]}}], "languages": [null], "subjects": ["computer science - computational complexity"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.5078"}}, {"publisher": {"name": ""}, "description": "  This work is about the use of regularized optimal-transport distances for\nconvex, histogram-based image segmentation. In the considered framework, fixed\nexemplar histograms define a prior on the statistical features of the two\nregions in competition. In this paper, we investigate the use of various\ntransport-based cost functions as discrepancy measures and rely on a\nprimal-dual algorithm to solve the obtained convex optimization problem.\n", "contributors": [{"name": "Rabin, Julien", "sameAs": [], "familyName": "Rabin", "additionalName": "", "givenName": "Julien", "email": ""}, {"name": "Papadakis, Nicolas", "sameAs": [], "familyName": "Papadakis", "additionalName": "", "givenName": "Nicolas", "email": ""}], "title": "Convex Color Image Segmentation with Optimal Transport Distances", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-06", "2015-03-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01986", "oai:arXiv.org:1503.01986"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This work is about the use of regularized optimal-transport distances for\nconvex, histogram-based image segmentation. In the considered framework, fixed\nexemplar histograms define a prior on the statistical features of the two\nregions in competition. In this paper, we investigate the use of various\ntransport-based cost functions as discrepancy measures and rely on a\nprimal-dual algorithm to solve the obtained convex optimization problem.\n", "Comment: A short version of this report has been submitted to the Fifth\n  International Conference on Scale Space and Variational Methods in Computer\n  Vision (SSVM) 2015"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01986"}}, {"publisher": {"name": ""}, "description": "  A classical result of Conway and Pless is that a natural projection of the\nfixed code of an automorphism of odd prime order of a self-dual binary linear\ncode is self-dual. In this paper we prove that the same holds for involutions\nunder some (quite strong) conditions on the codes. In order to prove it, we\nintroduce a new family of binary codes: the semi self-dual codes. A binary\nself-orthogonal code is called semi self-dual if it contains the all-ones\nvector and is of codimension 2 in its dual code. We prove upper bounds on the\ndual distance of semi self-dual codes. As an application we get the following:\nlet C be an extremal self-dual binary linear code of length 24m and s in Aut(C)\nbe a fixed point free automorphism of order 2. If m is odd or if m=2k with\nbinom{5k-1}{k-1} odd then C is a free F_2<s>-module. This result has quite\nstrong consequences on the structure of the automorphism group of such codes.\n", "contributors": [{"name": "Borello, Martino", "sameAs": [], "familyName": "Borello", "additionalName": "", "givenName": "Martino", "email": ""}, {"name": "Nebe, Gabriele", "sameAs": [], "familyName": "Nebe", "additionalName": "", "givenName": "Gabriele", "email": ""}], "title": "On involutions in extremal self-dual codes and the dual distance of semi\n  self-dual codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-01-23", "2014-11-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1401.6036", "oai:arXiv.org:1401.6036"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A classical result of Conway and Pless is that a natural projection of the\nfixed code of an automorphism of odd prime order of a self-dual binary linear\ncode is self-dual. In this paper we prove that the same holds for involutions\nunder some (quite strong) conditions on the codes. In order to prove it, we\nintroduce a new family of binary codes: the semi self-dual codes. A binary\nself-orthogonal code is called semi self-dual if it contains the all-ones\nvector and is of codimension 2 in its dual code. We prove upper bounds on the\ndual distance of semi self-dual codes. As an application we get the following:\nlet C be an extremal self-dual binary linear code of length 24m and s in Aut(C)\nbe a fixed point free automorphism of order 2. If m is odd or if m=2k with\nbinom{5k-1}{k-1} odd then C is a free F_2<s>-module. This result has quite\nstrong consequences on the structure of the automorphism group of such codes.\n", "Comment: 12 pages"]}}], "languages": [null], "subjects": ["computer science - information theory", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1401.6036"}}, {"publisher": {"name": ""}, "description": "  This paper presents a theoretical analysis of multi-view embedding -- feature\nembedding that can be learned from unlabeled data through the task of\npredicting one view from another. We prove its usefulness in supervised\nlearning under certain conditions. The result explains the effectiveness of\nsome existing methods such as word embedding. Based on this theory, we propose\na new semi-supervised learning framework that learns a multi-view embedding of\nsmall text regions with convolutional neural networks. The method derived from\nthis framework outperforms state-of-the-art methods on sentiment classification\nand topic categorization.\n", "contributors": [{"name": "Johnson, Rie", "sameAs": [], "familyName": "Johnson", "additionalName": "", "givenName": "Rie", "email": ""}, {"name": "Zhang, Tong", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Tong", "email": ""}], "title": "Semi-Supervised Learning with Multi-View Embedding: Theory and\n  Application with Convolutional Neural Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01255", "oai:arXiv.org:1504.01255"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  This paper presents a theoretical analysis of multi-view embedding -- feature\nembedding that can be learned from unlabeled data through the task of\npredicting one view from another. We prove its usefulness in supervised\nlearning under certain conditions. The result explains the effectiveness of\nsome existing methods such as word embedding. Based on this theory, we propose\na new semi-supervised learning framework that learns a multi-view embedding of\nsmall text regions with convolutional neural networks. The method derived from\nthis framework outperforms state-of-the-art methods on sentiment classification\nand topic categorization.\n"}}], "languages": [null], "subjects": ["computer science - computation and language", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01255"}}, {"publisher": {"name": ""}, "description": "  We consider the problem of optimal multi-modes switching in finite horizon,\nwhen the state of the system, including the switching cost functions are\narbitrary ($g_{ij}(t,x)\\geq 0$). We show existence of the optimal strategy, and\ngive when the optimal strategy is finite via a verification theorem. Finally,\nwhen the state of the system is a markov process, we show that the vector of\nvalue functions of the optimal problem is the unique viscosity solution to the\nsystem of $m$ variational partial differential inequalities with\ninter-connected obstacles.\n", "contributors": [{"name": "Asri, Brahim El", "sameAs": [], "familyName": "Asri", "additionalName": "El", "givenName": "Brahim", "email": ""}], "title": "Stochastic Optimal Multi-Modes Switching with a Viscosity Solution\n  Approach", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-02-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1102.1256", "oai:arXiv.org:1102.1256"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider the problem of optimal multi-modes switching in finite horizon,\nwhen the state of the system, including the switching cost functions are\narbitrary ($g_{ij}(t,x)\\geq 0$). We show existence of the optimal strategy, and\ngive when the optimal strategy is finite via a verification theorem. Finally,\nwhen the state of the system is a markov process, we show that the vector of\nvalue functions of the optimal problem is the unique viscosity solution to the\nsystem of $m$ variational partial differential inequalities with\ninter-connected obstacles.\n", "Comment: 2 figures"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - systems and control", "real options", "viscosity solution of pdes", "snell\n  envelope", "variational\n  inequalities", "stopping times", "switching", "backward stochastic differential equations", "mathematics - probability"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1102.1256"}}, {"publisher": {"name": ""}, "description": "  In this work we derive fundamental limits for many linear and non-linear\nsparse signal processing models including linear and non-linear sparse\nregression, group testing, multivariate regression and problems with missing\nfeatures. In general, sparse signal processing problems can be characterized in\nterms of the following Markovian property. We are given a set of $N$ variables\n$X_1,X_2,\\ldots,X_N$, and there is an unknown subset of variables $S \\subset\n\\{1,2,\\ldots, N\\}$ that are \\emph{relevant} for predicting outcomes/outputs\n$Y$. More specifically, when $Y$ is conditioned on $\\{X_n\\}_{n\\in S}$ it is\nconditionally independent of the other variables, $\\{X_n\\}_{n \\not \\in S}$. Our\ngoal is to identify the set $S$ from samples of the variables $X$ and the\nassociated outcomes $Y$. We characterize this problem as a version of the noisy\nchannel coding problem. Using asymptotic information theoretic analyses, we\nestablish mutual information formulas that provide sufficient and necessary\nconditions on the number of samples required to successfully recover the\nsalient variables. These mutual information expressions unify conditions for\nboth linear and non-linear observations. We then compute sample complexity\nbounds for the aforementioned models, based on the mutual information\nexpressions in order to demonstrate the applicability and flexibility of our\nresults in general sparse signal processing models.\n", "contributors": [{"name": "Aksoylar, Cem", "sameAs": [], "familyName": "Aksoylar", "additionalName": "", "givenName": "Cem", "email": ""}, {"name": "Atia, George", "sameAs": [], "familyName": "Atia", "additionalName": "", "givenName": "George", "email": ""}, {"name": "Saligrama, Venkatesh", "sameAs": [], "familyName": "Saligrama", "additionalName": "", "givenName": "Venkatesh", "email": ""}], "title": "Sparse Signal Processing with Linear and Non-Linear Observations: A\n  Unified Shannon Theoretic Approach", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-04-02", "2015-01-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1304.0682", "oai:arXiv.org:1304.0682"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  In this work we derive fundamental limits for many linear and non-linear\nsparse signal processing models including linear and non-linear sparse\nregression, group testing, multivariate regression and problems with missing\nfeatures. In general, sparse signal processing problems can be characterized in\nterms of the following Markovian property. We are given a set of $N$ variables\n$X_1,X_2,\\ldots,X_N$, and there is an unknown subset of variables $S \\subset\n\\{1,2,\\ldots, N\\}$ that are \\emph{relevant} for predicting outcomes/outputs\n$Y$. More specifically, when $Y$ is conditioned on $\\{X_n\\}_{n\\in S}$ it is\nconditionally independent of the other variables, $\\{X_n\\}_{n \\not \\in S}$. Our\ngoal is to identify the set $S$ from samples of the variables $X$ and the\nassociated outcomes $Y$. We characterize this problem as a version of the noisy\nchannel coding problem. Using asymptotic information theoretic analyses, we\nestablish mutual information formulas that provide sufficient and necessary\nconditions on the number of samples required to successfully recover the\nsalient variables. These mutual information expressions unify conditions for\nboth linear and non-linear observations. We then compute sample complexity\nbounds for the aforementioned models, based on the mutual information\nexpressions in order to demonstrate the applicability and flexibility of our\nresults in general sparse signal processing models.\n", "Comment: Major rewrite of the technical part, errors in notation, theorem\n  statements and proofs are corrected"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "computer science - information theory", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-01-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1304.0682"}}, {"publisher": {"name": ""}, "description": "  Human-Robot Social Interaction became one of active research fields in which\nresearchers from different areas propose solutions and directives leading\nrobots to improve their interactions with humans. In this paper we propose to\nintroduce works in both human robot interaction and human computer interaction\nand to make a bridge between them, i.e. to integrate emotions and capabilities\nconcepts of the robot in human computer model to become adequate for human\nrobot interaction and discuss challenges related to the proposed model. Finally\nan illustration through real case of this model will be presented.\n", "contributors": [{"name": "Toumi, Tarek", "sameAs": [], "familyName": "Toumi", "additionalName": "", "givenName": "Tarek", "email": ""}, {"name": "Zidani, Abdelmadjid", "sameAs": [], "familyName": "Zidani", "additionalName": "", "givenName": "Abdelmadjid", "email": ""}], "title": "From Human-Computer Interaction to Human-Robot Social Interaction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1251", "IJCSI International Journal of Computer Science Issues, Vol. 11,\n  Issue 1, No 1, 2014 1694-0814", "oai:arXiv.org:1412.1251"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Human-Robot Social Interaction became one of active research fields in which\nresearchers from different areas propose solutions and directives leading\nrobots to improve their interactions with humans. In this paper we propose to\nintroduce works in both human robot interaction and human computer interaction\nand to make a bridge between them, i.e. to integrate emotions and capabilities\nconcepts of the robot in human computer model to become adequate for human\nrobot interaction and discuss challenges related to the proposed model. Finally\nan illustration through real case of this model will be presented.\n"}}], "languages": [null], "subjects": ["computer science - robotics", "computer science - systems and control", "computer science - human-computer interaction"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1251"}}, {"publisher": {"name": ""}, "description": "  We study the dynamics of the normal implied volatility in a local volatility\nmodel, using a small-time expansion in powers of maturity T. At leading order\nin this expansion, the asymptotics of the normal implied volatility is similar,\nup to a different definition of the moneyness, to that of the log-normal\nvolatility. This relation is preserved also to order O(T) in the small-time\nexpansion, and differences with the log-normal case appear first at O(T^2). The\nresults are illustrated on a few examples of local volatility models with\nanalytical local volatility, finding generally good agreement with exact or\nnumerical solutions. We point out that the asymptotic expansion can fail if\napplied naively for models with nonanalytical local volatility, for example\nwhich have discontinuous derivatives. Using perturbation theory methods, we\nshow that the ATM normal implied volatility for such a model contains a term ~\n\\sqrt{T}, with a coefficient which is proportional with the jump of the\nderivative.\n", "contributors": [{"name": "Costeanu, Viorel", "sameAs": [], "familyName": "Costeanu", "additionalName": "", "givenName": "Viorel", "email": ""}, {"name": "Pirjol, Dan", "sameAs": [], "familyName": "Pirjol", "additionalName": "", "givenName": "Dan", "email": ""}], "title": "Asymptotic Expansion for the Normal Implied Volatility in Local\n  Volatility Models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.3359", "oai:arXiv.org:1105.3359"]}}, {"name": "setSpec", "properties": {"setSpec": "q-fin"}}, {"name": "description", "properties": {"description": ["  We study the dynamics of the normal implied volatility in a local volatility\nmodel, using a small-time expansion in powers of maturity T. At leading order\nin this expansion, the asymptotics of the normal implied volatility is similar,\nup to a different definition of the moneyness, to that of the log-normal\nvolatility. This relation is preserved also to order O(T) in the small-time\nexpansion, and differences with the log-normal case appear first at O(T^2). The\nresults are illustrated on a few examples of local volatility models with\nanalytical local volatility, finding generally good agreement with exact or\nnumerical solutions. We point out that the asymptotic expansion can fail if\napplied naively for models with nonanalytical local volatility, for example\nwhich have discontinuous derivatives. Using perturbation theory methods, we\nshow that the ATM normal implied volatility for such a model contains a term ~\n\\sqrt{T}, with a coefficient which is proportional with the jump of the\nderivative.\n", "Comment: 29 pages, 5 figures"]}}], "languages": [null], "subjects": ["quantitative finance - pricing of securities", "quantitative finance - computational finance"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.3359"}}, {"publisher": {"name": ""}, "description": "  High-order harmonic generation is investigated for H$_2^+$ and D$_2^+$ with\nand without Born-Oppenheimer approximation by numerical solution of full\ndimensional electronic time-dependent Schr\\\"{o}dinger equation under 4-cycle\nintense laser pulses of 800 nm wavelength and $I$=4, 5, 7, 10 $\\times 10^{14}$\nW$/$cm$^2$ intensities. For most harmonic orders, the intensity obtained for\nD$_2^+$ is higher than that for H$_2^+$, and the yield difference increases as\nthe harmonic order increases. Only at some low harmonic orders, H$_2^+$\ngenerates more intense harmonics compared to D$_2^+$. The results show that\nnuclear motion, ionization probability and system dimensionality must be\nsimultaneously taken into account to properly explain the isotopic effects on\nhigh-order harmonic generation and to justify experimental observations.\n", "contributors": [{"name": "Ahmadi, Hamed", "sameAs": [], "familyName": "Ahmadi", "additionalName": "", "givenName": "Hamed", "email": ""}, {"name": "Maghari, Ali", "sameAs": [], "familyName": "Maghari", "additionalName": "", "givenName": "Ali", "email": ""}, {"name": "Sabzyan, Hassan", "sameAs": [], "familyName": "Sabzyan", "additionalName": "", "givenName": "Hassan", "email": ""}, {"name": "Niknam, Ali Reza", "sameAs": [], "familyName": "Niknam", "additionalName": "Reza", "givenName": "Ali", "email": ""}, {"name": "Vafaee, Mohsen", "sameAs": [], "familyName": "Vafaee", "additionalName": "", "givenName": "Mohsen", "email": ""}], "title": "Effect of nuclear motion on high-order harmonic generation of H$_2^+$ in\n  intense ultrashort laser pulses", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-07-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.5458", "Phys. Rev. A 90, 043411 (2014)", "doi:10.1103/PhysRevA.90.043411", "oai:arXiv.org:1407.5458"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": ["  High-order harmonic generation is investigated for H$_2^+$ and D$_2^+$ with\nand without Born-Oppenheimer approximation by numerical solution of full\ndimensional electronic time-dependent Schr\\\"{o}dinger equation under 4-cycle\nintense laser pulses of 800 nm wavelength and $I$=4, 5, 7, 10 $\\times 10^{14}$\nW$/$cm$^2$ intensities. For most harmonic orders, the intensity obtained for\nD$_2^+$ is higher than that for H$_2^+$, and the yield difference increases as\nthe harmonic order increases. Only at some low harmonic orders, H$_2^+$\ngenerates more intense harmonics compared to D$_2^+$. The results show that\nnuclear motion, ionization probability and system dimensionality must be\nsimultaneously taken into account to properly explain the isotopic effects on\nhigh-order harmonic generation and to justify experimental observations.\n", "Comment: 7 pages, 5 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "physics - chemical physics", "physics - atomic physics"], "providerUpdatedDateTime": "2014-10-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.5458"}}, {"publisher": {"name": ""}, "description": "  Numerous machine learning algorithms contain pairwise statistical problems at\ntheir core---that is, tasks that require computations over all pairs of input\npoints if implemented naively. Often, tree structures are used to solve these\nproblems efficiently. Dual-tree algorithms can efficiently solve or approximate\nmany of these problems. Using cover trees, rigorous worst-case runtime\nguarantees have been proven for some of these algorithms. In this paper, we\npresent a problem-independent runtime guarantee for any dual-tree algorithm\nusing the cover tree, separating out the problem-dependent and the\nproblem-independent elements. This allows us to just plug in bounds for the\nproblem-dependent elements to get runtime guarantees for dual-tree algorithms\nfor any pairwise statistical problem without re-deriving the entire proof. We\ndemonstrate this plug-and-play procedure for nearest-neighbor search and\napproximate kernel density estimation to get improved runtime guarantees. Under\nmild assumptions, we also present the first linear runtime guarantee for\ndual-tree based range search.\n", "contributors": [{"name": "Curtin, Ryan R.", "sameAs": [], "familyName": "Curtin", "additionalName": "R.", "givenName": "Ryan", "email": ""}, {"name": "Lee, Dongryeol", "sameAs": [], "familyName": "Lee", "additionalName": "", "givenName": "Dongryeol", "email": ""}, {"name": "March, William B.", "sameAs": [], "familyName": "March", "additionalName": "B.", "givenName": "William", "email": ""}, {"name": "Ram, Parikshit", "sameAs": [], "familyName": "Ram", "additionalName": "", "givenName": "Parikshit", "email": ""}], "title": "Plug-and-play dual-tree algorithm runtime analysis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05222", "oai:arXiv.org:1501.05222"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Numerous machine learning algorithms contain pairwise statistical problems at\ntheir core---that is, tasks that require computations over all pairs of input\npoints if implemented naively. Often, tree structures are used to solve these\nproblems efficiently. Dual-tree algorithms can efficiently solve or approximate\nmany of these problems. Using cover trees, rigorous worst-case runtime\nguarantees have been proven for some of these algorithms. In this paper, we\npresent a problem-independent runtime guarantee for any dual-tree algorithm\nusing the cover tree, separating out the problem-dependent and the\nproblem-independent elements. This allows us to just plug in bounds for the\nproblem-dependent elements to get runtime guarantees for dual-tree algorithms\nfor any pairwise statistical problem without re-deriving the entire proof. We\ndemonstrate this plug-and-play procedure for nearest-neighbor search and\napproximate kernel density estimation to get improved runtime guarantees. Under\nmild assumptions, we also present the first linear runtime guarantee for\ndual-tree based range search.\n", "Comment: Submitted to JMLR"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - learning"], "providerUpdatedDateTime": "2015-01-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05222"}}, {"publisher": {"name": ""}, "description": "  Given a high-dimensional and large-scale tensor, how can we decompose it into\nlatent factors? Can we process it on commodity computers with limited memory?\nThese questions are closely related to recommendation systems exploiting\ncontext information such as time and location. They require tensor\nfactorization methods scalable with both the dimension and size of a tensor. In\nthis paper, we propose two distributed tensor factorization methods, SALS and\nCDTF. Both methods are scalable with all aspects of data, and they show an\ninteresting trade-off between convergence speed and memory requirements. SALS\nupdates a subset of the columns of a factor matrix at a time, and CDTF, a\nspecial case of SALS, updates one column at a time. On our experiment, only our\nmethods factorize a 5-dimensional tensor with 1B observable entries, 10M mode\nlength, and 1K rank, while all other state-of-the-art methods fail. Moreover,\nour methods require several orders of magnitude less memory than the\ncompetitors. We implement our methods on MapReduce with two widely applicable\noptimization techniques: local disk caching and greedy row assignment.\n", "contributors": [{"name": "Shin, Kijung", "sameAs": [], "familyName": "Shin", "additionalName": "", "givenName": "Kijung", "email": ""}, {"name": "Kang, U.", "sameAs": [], "familyName": "Kang", "additionalName": "", "givenName": "U.", "email": ""}], "title": "Distributed Methods for High-dimensional and Large-scale Tensor\n  Factorization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-20", "2015-02-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5209", "oai:arXiv.org:1410.5209"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Given a high-dimensional and large-scale tensor, how can we decompose it into\nlatent factors? Can we process it on commodity computers with limited memory?\nThese questions are closely related to recommendation systems exploiting\ncontext information such as time and location. They require tensor\nfactorization methods scalable with both the dimension and size of a tensor. In\nthis paper, we propose two distributed tensor factorization methods, SALS and\nCDTF. Both methods are scalable with all aspects of data, and they show an\ninteresting trade-off between convergence speed and memory requirements. SALS\nupdates a subset of the columns of a factor matrix at a time, and CDTF, a\nspecial case of SALS, updates one column at a time. On our experiment, only our\nmethods factorize a 5-dimensional tensor with 1B observable entries, 10M mode\nlength, and 1K rank, while all other state-of-the-art methods fail. Moreover,\nour methods require several orders of magnitude less memory than the\ncompetitors. We implement our methods on MapReduce with two widely applicable\noptimization techniques: local disk caching and greedy row assignment.\n"}}], "languages": [null], "subjects": ["computer science - databases", "computer science - information retrieval", "computer science - numerical analysis"], "providerUpdatedDateTime": "2015-02-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5209"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose a new mathematical model for image processing. It\nis a logarithmical one. We consider the bounded interval (-1, 1) as the set of\ngray levels. Firstly, we define two operations: addition <+> and real scalar\nmultiplication <x>. With these operations, the set of gray levels becomes a\nreal vector space. Then, defining the scalar product (.|.) and the norm || .\n||, we obtain an Euclidean space of the gray levels. Secondly, we extend these\noperations and functions for color images. We finally show the effect of\nvarious simple operations on an image.\n", "contributors": [{"name": "Patrascu, Vasile", "sameAs": [], "familyName": "Patrascu", "additionalName": "", "givenName": "Vasile", "email": ""}, {"name": "Buzuloiu, Vasile", "sameAs": [], "familyName": "Buzuloiu", "additionalName": "", "givenName": "Vasile", "email": ""}], "title": "A Mathematical Model for Logarithmic Image Processing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5328", "oai:arXiv.org:1412.5328"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we propose a new mathematical model for image processing. It\nis a logarithmical one. We consider the bounded interval (-1, 1) as the set of\ngray levels. Firstly, we define two operations: addition <+> and real scalar\nmultiplication <x>. With these operations, the set of gray levels becomes a\nreal vector space. Then, defining the scalar product (.|.) and the norm || .\n||, we obtain an Euclidean space of the gray levels. Secondly, we extend these\noperations and functions for color images. We finally show the effect of\nvarious simple operations on an image.\n", "Comment: The 5th World Multi-Conference on Systemics, Cybernetics and\n  Informatics, Vol 13, pp. 117-122, SCI2001, July 22-25, 2001, Orlando, USA"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5328"}}, {"publisher": {"name": ""}, "description": "  This paper considers the problem of detecting the support (sparsity pattern)\nof a sparse vector from random noisy measurements. Conditional power of a\ncomponent of the sparse vector is defined as the energy conditioned on the\ncomponent being nonzero. Analysis of a simplified version of orthogonal\nmatching pursuit (OMP) called sequential OMP (SequOMP) demonstrates the\nimportance of knowledge of the rankings of conditional powers. When the simple\nSequOMP algorithm is applied to components in nonincreasing order of\nconditional power, the detrimental effect of dynamic range on thresholding\nperformance is eliminated. Furthermore, under the most favorable conditional\npowers, the performance of SequOMP approaches maximum likelihood performance at\nhigh signal-to-noise ratio.\n", "contributors": [{"name": "Fletcher, Alyson K.", "sameAs": [], "familyName": "Fletcher", "additionalName": "K.", "givenName": "Alyson", "email": ""}, {"name": "Rangan, Sundeep", "sameAs": [], "familyName": "Rangan", "additionalName": "", "givenName": "Sundeep", "email": ""}, {"name": "Goyal, Vivek K", "sameAs": [], "familyName": "Goyal", "additionalName": "K", "givenName": "Vivek", "email": ""}], "title": "Ranked Sparse Signal Support Detection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-10-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1110.6188", "IEEE Trans. on Signal Processing, vol. 60, no. 11, pp. 5919-5931,\n  November 2012", "doi:10.1109/TSP.2012.2208957", "oai:arXiv.org:1110.6188"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper considers the problem of detecting the support (sparsity pattern)\nof a sparse vector from random noisy measurements. Conditional power of a\ncomponent of the sparse vector is defined as the energy conditioned on the\ncomponent being nonzero. Analysis of a simplified version of orthogonal\nmatching pursuit (OMP) called sequential OMP (SequOMP) demonstrates the\nimportance of knowledge of the rankings of conditional powers. When the simple\nSequOMP algorithm is applied to components in nonincreasing order of\nconditional power, the detrimental effect of dynamic range on thresholding\nperformance is eliminated. Furthermore, under the most favorable conditional\npowers, the performance of SequOMP approaches maximum likelihood performance at\nhigh signal-to-noise ratio.\n", "Comment: 13 pages"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1110.6188"}}, {"publisher": {"name": ""}, "description": "  A common goal of privacy research is to release synthetic data that satisfies\na formal privacy guarantee and can be used by an analyst in place of the\noriginal data. To achieve reasonable accuracy, a synthetic data set must be\ntuned to support a specified set of queries accurately, sacrificing fidelity\nfor other queries.\n  This work considers methods for producing synthetic data under differential\nprivacy and investigates what makes a set of queries \"easy\" or \"hard\" to\nanswer. We consider answering sets of linear counting queries using the matrix\nmechanism, a recent differentially-private mechanism that can reduce error by\nadding complex correlated noise adapted to a specified workload.\n  Our main result is a novel lower bound on the minimum total error required to\nsimultaneously release answers to a set of workload queries. The bound reveals\nthat the hardness of a query workload is related to the spectral properties of\nthe workload when it is represented in matrix form. The bound is most\ninformative for $(\\epsilon,\\delta)$-differential privacy but also applies to\n$\\epsilon$-differential privacy.\n", "contributors": [{"name": "Li, Chao", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Chao", "email": ""}, {"name": "Miklau, Gerome", "sameAs": [], "familyName": "Miklau", "additionalName": "", "givenName": "Gerome", "email": ""}], "title": "Optimal error of query sets under the differentially-private matrix\n  mechanism", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-02-15", "2012-12-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1202.3399", "oai:arXiv.org:1202.3399"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  A common goal of privacy research is to release synthetic data that satisfies\na formal privacy guarantee and can be used by an analyst in place of the\noriginal data. To achieve reasonable accuracy, a synthetic data set must be\ntuned to support a specified set of queries accurately, sacrificing fidelity\nfor other queries.\n  This work considers methods for producing synthetic data under differential\nprivacy and investigates what makes a set of queries \"easy\" or \"hard\" to\nanswer. We consider answering sets of linear counting queries using the matrix\nmechanism, a recent differentially-private mechanism that can reduce error by\nadding complex correlated noise adapted to a specified workload.\n  Our main result is a novel lower bound on the minimum total error required to\nsimultaneously release answers to a set of workload queries. The bound reveals\nthat the hardness of a query workload is related to the spectral properties of\nthe workload when it is represented in matrix form. The bound is most\ninformative for $(\\epsilon,\\delta)$-differential privacy but also applies to\n$\\epsilon$-differential privacy.\n", "Comment: 35 pages; Short version to appear in the 16th International\n  Conference on Database Theory (ICDT), 2013"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - databases", "f.2", "h.2.8"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1202.3399"}}, {"publisher": {"name": ""}, "description": "  We develop a coherent framework for integrative simultaneous analysis of the\nexploration-exploitation and model order selection trade-offs. We improve over\nour preceding results on the same subject (Seldin et al., 2011) by combining\nPAC-Bayesian analysis with Bernstein-type inequality for martingales. Such a\ncombination is also of independent interest for studies of multiple\nsimultaneously evolving martingales.\n", "contributors": [{"name": "Seldin, Yevgeny", "sameAs": [], "familyName": "Seldin", "additionalName": "", "givenName": "Yevgeny", "email": ""}, {"name": "Cesa-Bianchi, Nicol\u00f2", "sameAs": [], "familyName": "Cesa-Bianchi", "additionalName": "", "givenName": "Nicol\u00f2", "email": ""}, {"name": "Laviolette, Fran\u00e7ois", "sameAs": [], "familyName": "Laviolette", "additionalName": "", "givenName": "Fran\u00e7ois", "email": ""}, {"name": "Auer, Peter", "sameAs": [], "familyName": "Auer", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Shawe-Taylor, John", "sameAs": [], "familyName": "Shawe-Taylor", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Peters, Jan", "sameAs": [], "familyName": "Peters", "additionalName": "", "givenName": "Jan", "email": ""}], "title": "PAC-Bayesian Analysis of the Exploration-Exploitation Trade-off", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.4585", "oai:arXiv.org:1105.4585"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  We develop a coherent framework for integrative simultaneous analysis of the\nexploration-exploitation and model order selection trade-offs. We improve over\nour preceding results on the same subject (Seldin et al., 2011) by combining\nPAC-Bayesian analysis with Bernstein-type inequality for martingales. Such a\ncombination is also of independent interest for studies of multiple\nsimultaneously evolving martingales.\n", "Comment: On-line Trading of Exploration and Exploitation 2 - ICML-2011\n  workshop. http://explo.cs.ucl.ac.uk/workshop/"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.4585"}}, {"publisher": {"name": ""}, "description": "  In recent scene recognition research images or large image regions are often\nrepresented as disorganized \"bags\" of features which can then be analyzed using\nmodels originally developed to capture co-variation of word counts in text.\nHowever, image feature counts are likely to be constrained in different ways\nthan word counts in text. For example, as a camera pans upwards from a building\nentrance over its first few floors and then further up into the sky Fig. 1,\nsome feature counts in the image drop while others rise -- only to drop again\ngiving way to features found more often at higher elevations. The space of all\npossible feature count combinations is constrained both by the properties of\nthe larger scene and the size and the location of the window into it. To\ncapture such variation, in this paper we propose the use of the counting grid\nmodel. This generative model is based on a grid of feature counts, considerably\nlarger than any of the modeled images, and considerably smaller than the real\nestate needed to tile the images next to each other tightly. Each modeled image\nis assumed to have a representative window in the grid in which the feature\ncounts mimic the feature distribution in the image. We provide a learning\nprocedure that jointly maps all images in the training set to the counting grid\nand estimates the appropriate local counts in it. Experimentally, we\ndemonstrate that the resulting representation captures the space of feature\ncount combinations more accurately than the traditional models, not only when\nthe input images come from a panning camera, but even when modeling images of\ndifferent scenes from the same category.\n", "contributors": [{"name": "Perina, Alessandro", "sameAs": [], "familyName": "Perina", "additionalName": "", "givenName": "Alessandro", "email": ""}, {"name": "Jojic, Nebojsa", "sameAs": [], "familyName": "Jojic", "additionalName": "", "givenName": "Nebojsa", "email": ""}], "title": "Capturing spatial interdependence in image features: the counting grid,\n  an epitomic representation for bags of features", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6264", "oai:arXiv.org:1410.6264"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In recent scene recognition research images or large image regions are often\nrepresented as disorganized \"bags\" of features which can then be analyzed using\nmodels originally developed to capture co-variation of word counts in text.\nHowever, image feature counts are likely to be constrained in different ways\nthan word counts in text. For example, as a camera pans upwards from a building\nentrance over its first few floors and then further up into the sky Fig. 1,\nsome feature counts in the image drop while others rise -- only to drop again\ngiving way to features found more often at higher elevations. The space of all\npossible feature count combinations is constrained both by the properties of\nthe larger scene and the size and the location of the window into it. To\ncapture such variation, in this paper we propose the use of the counting grid\nmodel. This generative model is based on a grid of feature counts, considerably\nlarger than any of the modeled images, and considerably smaller than the real\nestate needed to tile the images next to each other tightly. Each modeled image\nis assumed to have a representative window in the grid in which the feature\ncounts mimic the feature distribution in the image. We provide a learning\nprocedure that jointly maps all images in the training set to the counting grid\nand estimates the appropriate local counts in it. Experimentally, we\ndemonstrate that the resulting representation captures the space of feature\ncount combinations more accurately than the traditional models, not only when\nthe input images come from a panning camera, but even when modeling images of\ndifferent scenes from the same category.\n", "Comment: The counting grid code is available at www.alessandroperina.com"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-10-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6264"}}, {"publisher": {"name": "ScholarlyCommons"}, "description": "Epidermal growth factor receptor (EGFR) mutation and overexpression promote tumorigenesis in multiple cancers. Understanding the complex EGFR regulatory network is critical for developing effective therapeutic interventions. To this end, this work investigated the functions of two incompletely characterized regulators of EGFR trafficking and signaling, mitogen-inducible gene 6 (MIG6) and Sprouty2 (SPRY2), in two cancer settings where EGFR mutation is common, non-small cell lung cancer (NSCLC) and glioblastoma multiforme (GBM). In NSCLC cells, results indicate that MIG6, an endogenous inhibitor of EGFR activity and endocytic adaptor, is surprisingly responsible for at least half of EGFR endocytosis, suggesting that a substantial fraction of internalized EGFR may not be competent to drive signaling. Computational modeling further suggested that in cells expressing kinase-activated, endocytosis-impaired EGFR mutants, the importance of MIG6 relative to other endocytic pathways is increased, but that MIG6 internalization capacity is reduced compared to cells expressing wild-type EGFR. Additional data indicate that SPRY2 expression reduces EGFR endocytosis rate primarily by promoting EGFR expression, which overwhelms the saturable EGFR endocytic pathway, but that SPRY2 also promotes ERK phosphorylation and resistance to EGFR inhibition independent of EGFR expression level. In GBM cell lines, our data demonstrate that SPRY2 expression promotes proliferation, anchorage-independent growth, resistance to EGFR and c-MET co-inhibition, and growth as mouse tumor xenografts. Additional studies identified SPRY2-mediated regulation of the strength and effects of JNK and p38 MAP kinase pathways as important for controlling GBM cell behaviors. Through analysis of public datasets and a collaborative analysis of human and rat tumors, we further found that elevated SPRY2 expression is associated with reduced patient survival and expression of EGFR variant III, an EGFR mutant linked to aggressive GBM. Thus, while SPRY2 is a candidate tumor suppressor in other contexts, our results support a tumor promoter role for SPRY2 in GBM and identify SPRY2 and the pathways it regulates as potential therapeutic targets or biomarkers for therapeutic response. Overall, these findings add new qualitative and quantitative understanding of the complexities of EGFR trafficking and signaling regulation and the functions of SPRY2 and MIG6 that may be leveraged to develop improved cancer therapies.", "contributors": [{"name": "Walsh, Alice Macdonald", "sameAs": [], "familyName": "Walsh", "additionalName": "Macdonald", "givenName": "Alice", "email": ""}], "title": "Regulation of cell signaling by MIG6 and Sprouty2 in cancers with EGFR mutations", "shareProperties": {"source": "upennsylvania"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-01-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.upenn.edu/edissertations/1638", "http://repository.upenn.edu/cgi/viewcontent.cgi?article=2762&amp;context=edissertations", "oai:repository.upenn.edu:edissertations-2762"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:be", "publication:edissertations", "publication:seas"]}}, {"name": "source", "properties": {"source": "Publicly Accessible Penn Dissertations"}}, {"name": "rights", "properties": {"rights": []}}], "languages": [null], "subjects": ["cancer", "drug resistance", "feedback", "cell biology", "biomedical", "computational modeling", "signaling"], "providerUpdatedDateTime": "2015-03-16T19:06:23", "uris": {"canonicalUri": "http://repository.upenn.edu/edissertations/1638"}}, {"publisher": {"name": ""}, "description": "  In this work, we propose and address a new computer vision task, which we\ncall fashion item detection, where the aim is to detect various fashion items a\nperson in the image is wearing or carrying. The types of fashion items we\nconsider in this work include hat, glasses, bag, pants, shoes and so on. The\ndetection of fashion items can be an important first step of various e-commerce\napplications for fashion industry. Our method is based on state-of-the-art\nobject detection method which combines object proposal methods with a Deep\nConvolutional Neural Network. Since the locations of fashion items are in\nstrong correlation with the locations of body joints positions, we propose a\nhybrid discriminative-generative model to incorporate contextual information\nfrom body poses in order to improve the detection performance. Through the\nexperiments, we demonstrate that our algorithm outperforms baseline methods\nwith a large margin.\n", "contributors": [{"name": "Hara, Kota", "sameAs": [], "familyName": "Hara", "additionalName": "", "givenName": "Kota", "email": ""}, {"name": "Jagadeesh, Vignesh", "sameAs": [], "familyName": "Jagadeesh", "additionalName": "", "givenName": "Vignesh", "email": ""}, {"name": "Piramuthu, Robinson", "sameAs": [], "familyName": "Piramuthu", "additionalName": "", "givenName": "Robinson", "email": ""}], "title": "Fashion Apparel Detection: The Role of Deep Convolutional Neural Network\n  and Pose-dependent Priors", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5319", "oai:arXiv.org:1411.5319"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this work, we propose and address a new computer vision task, which we\ncall fashion item detection, where the aim is to detect various fashion items a\nperson in the image is wearing or carrying. The types of fashion items we\nconsider in this work include hat, glasses, bag, pants, shoes and so on. The\ndetection of fashion items can be an important first step of various e-commerce\napplications for fashion industry. Our method is based on state-of-the-art\nobject detection method which combines object proposal methods with a Deep\nConvolutional Neural Network. Since the locations of fashion items are in\nstrong correlation with the locations of body joints positions, we propose a\nhybrid discriminative-generative model to incorporate contextual information\nfrom body poses in order to improve the detection performance. Through the\nexperiments, we demonstrate that our algorithm outperforms baseline methods\nwith a large margin.\n", "Comment: 9 pages, 6 figures, 5 tables"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5319"}}, {"publisher": {"name": ""}, "description": "  Consider the standard family of complex H\\'enon maps $H(x,y) = (p(x) - ay,\nx)$, where $p$ is a quadratic polynomial and $a$ is a complex parameter. Let\n$U^{+}$ be the set of points that escape to infinity under forward iterations.\nThe analytic structure of the escaping set $U^{+}$ is well understood from\nprevious work of J. Hubbard and R. Oberste-Vorth as a quotient of\n$(\\mathbb{C}-\\overline{\\mathbb{D}}) \\times\\mathbb{C}$ by a discrete group of\nautomorphisms $\\Gamma$ isomorphic to $\\mathbb{Z}[1/2]/\\mathbb{Z}$. On the other\nhand, the boundary $J^{+}$ of $U^{+}$ is a complicated fractal object on which\nthe H\\'enon map behaves chaotically. We show how to extend the group action to\n$\\mathbb{S}^1\\times\\mathbb{C}$, in order to represent the set $J^{+}$ as a\nquotient of $\\mathbb{S}^1\\times \\mathbb{C}/\\,\\Gamma$ by an equivalence\nrelation. We analyze this extension for H\\'enon maps that are small\nperturbations of hyperbolic polynomials with connected Julia sets or\npolynomials with a parabolic fixed point.\n", "contributors": [{"name": "Tanase, Raluca", "sameAs": [], "familyName": "Tanase", "additionalName": "", "givenName": "Raluca", "email": ""}], "title": "Complex H\\'enon maps and discrete groups", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03665", "oai:arXiv.org:1503.03665"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Consider the standard family of complex H\\'enon maps $H(x,y) = (p(x) - ay,\nx)$, where $p$ is a quadratic polynomial and $a$ is a complex parameter. Let\n$U^{+}$ be the set of points that escape to infinity under forward iterations.\nThe analytic structure of the escaping set $U^{+}$ is well understood from\nprevious work of J. Hubbard and R. Oberste-Vorth as a quotient of\n$(\\mathbb{C}-\\overline{\\mathbb{D}}) \\times\\mathbb{C}$ by a discrete group of\nautomorphisms $\\Gamma$ isomorphic to $\\mathbb{Z}[1/2]/\\mathbb{Z}$. On the other\nhand, the boundary $J^{+}$ of $U^{+}$ is a complicated fractal object on which\nthe H\\'enon map behaves chaotically. We show how to extend the group action to\n$\\mathbb{S}^1\\times\\mathbb{C}$, in order to represent the set $J^{+}$ as a\nquotient of $\\mathbb{S}^1\\times \\mathbb{C}/\\,\\Gamma$ by an equivalence\nrelation. We analyze this extension for H\\'enon maps that are small\nperturbations of hyperbolic polynomials with connected Julia sets or\npolynomials with a parabolic fixed point.\n", "Comment: 33 pages, 12 figures"]}}], "languages": [null], "subjects": ["mathematics - group theory", "37f99", "57m60", "mathematics - dynamical systems", "mathematics - complex variables", "37c85", "57m10"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03665"}}, {"publisher": {"name": ""}, "description": "  High throughput is a fundamental goal of network design and is of particular\ninterest in data center and high performance computing networks. Although\nmyriad network topologies have been recently proposed, a broad head-to-head\ncomparison of these proposals is absent, and the right way to compare\nworst-case throughput performance turns out to be a subtle problem.\n  In this paper, we present a framework to benchmark the throughput of network\ntopologies. First, we show that cut-based metrics such as bisection bandwidth\nare the wrong measure: they yield incorrect conclusions about throughput\nperformance. Next, we show how to generate a near-worst-case traffic matrix for\na given topology, which empirically approaches a theoretical lower bound.\nFinally, we employ this metric, along with other traffic matrices, to analyze\nthe throughput performance of a variety of networks proposed for data centers\nand high performance computing. Our evaluation code is freely available to\nfacilitate future reproducible work on rigorously designing and evaluating\nnetworks.\n", "contributors": [{"name": "Jyothi, Sangeetha Abdu", "sameAs": [], "familyName": "Jyothi", "additionalName": "Abdu", "givenName": "Sangeetha", "email": ""}, {"name": "Singla, Ankit", "sameAs": [], "familyName": "Singla", "additionalName": "", "givenName": "Ankit", "email": ""}, {"name": "Godfrey, P. Brighten", "sameAs": [], "familyName": "Godfrey", "additionalName": "Brighten", "givenName": "P.", "email": ""}, {"name": "Kolla, Alexandra", "sameAs": [], "familyName": "Kolla", "additionalName": "", "givenName": "Alexandra", "email": ""}], "title": "Measuring and Understanding Throughput of Network Topologies", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-11", "2015-02-09"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.2531", "oai:arXiv.org:1402.2531"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  High throughput is a fundamental goal of network design and is of particular\ninterest in data center and high performance computing networks. Although\nmyriad network topologies have been recently proposed, a broad head-to-head\ncomparison of these proposals is absent, and the right way to compare\nworst-case throughput performance turns out to be a subtle problem.\n  In this paper, we present a framework to benchmark the throughput of network\ntopologies. First, we show that cut-based metrics such as bisection bandwidth\nare the wrong measure: they yield incorrect conclusions about throughput\nperformance. Next, we show how to generate a near-worst-case traffic matrix for\na given topology, which empirically approaches a theoretical lower bound.\nFinally, we employ this metric, along with other traffic matrices, to analyze\nthe throughput performance of a variety of networks proposed for data centers\nand high performance computing. Our evaluation code is freely available to\nfacilitate future reproducible work on rigorously designing and evaluating\nnetworks.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-02-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.2531"}}, {"publisher": {"name": ""}, "description": "  The majority of research on efficient and scalable algorithms in\ncomputational science and engineering has focused on the forward problem: given\nparameter inputs, solve the governing equations to determine output quantities\nof interest. In contrast, here we consider the broader question: given a\n(large-scale) model containing uncertain parameters, (possibly) noisy\nobservational data, and a prediction quantity of interest, how do we construct\nefficient and scalable algorithms to (1) infer the model parameters from the\ndata (the deterministic inverse problem), (2) quantify the uncertainty in the\ninferred parameters (the Bayesian inference problem), and (3) propagate the\nresulting uncertain parameters through the model to issue predictions with\nquantified uncertainties (the forward uncertainty propagation problem)? We\npresent efficient and scalable algorithms for this end-to-end,\ndata-to-prediction process under the Gaussian approximation and in the context\nof modeling the flow of the Antarctic ice sheet and its effect on sea level.\nThe ice is modeled as a viscous, incompressible, creeping, shear-thinning\nfluid. The observational data come from InSAR satellite measurements of surface\nice flow velocity, and the uncertain parameter field to be inferred is the\nbasal sliding parameter. The prediction quantity of interest is the present-day\nice mass flux from the Antarctic continent to the ocean. We show that the work\nrequired for executing this data-to-prediction process is independent of the\nstate dimension, parameter dimension, data dimension, and number of processor\ncores. The key to achieving this dimension independence is to exploit the fact\nthat the observational data typically provide only sparse information on model\nparameters. This property can be exploited to construct a low rank\napproximation of the linearized parameter-to-observable map.\n", "contributors": [{"name": "Isaac, Tobin", "sameAs": [], "familyName": "Isaac", "additionalName": "", "givenName": "Tobin", "email": ""}, {"name": "Petra, Noemi", "sameAs": [], "familyName": "Petra", "additionalName": "", "givenName": "Noemi", "email": ""}, {"name": "Stadler, Georg", "sameAs": [], "familyName": "Stadler", "additionalName": "", "givenName": "Georg", "email": ""}, {"name": "Ghattas, Omar", "sameAs": [], "familyName": "Ghattas", "additionalName": "", "givenName": "Omar", "email": ""}], "title": "Scalable and efficient algorithms for the propagation of uncertainty\n  from data through inference to prediction for large-scale problems, with\n  application to flow of the Antarctic ice sheet", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1221", "oai:arXiv.org:1410.1221"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "stat"]}}, {"name": "description", "properties": {"description": "  The majority of research on efficient and scalable algorithms in\ncomputational science and engineering has focused on the forward problem: given\nparameter inputs, solve the governing equations to determine output quantities\nof interest. In contrast, here we consider the broader question: given a\n(large-scale) model containing uncertain parameters, (possibly) noisy\nobservational data, and a prediction quantity of interest, how do we construct\nefficient and scalable algorithms to (1) infer the model parameters from the\ndata (the deterministic inverse problem), (2) quantify the uncertainty in the\ninferred parameters (the Bayesian inference problem), and (3) propagate the\nresulting uncertain parameters through the model to issue predictions with\nquantified uncertainties (the forward uncertainty propagation problem)? We\npresent efficient and scalable algorithms for this end-to-end,\ndata-to-prediction process under the Gaussian approximation and in the context\nof modeling the flow of the Antarctic ice sheet and its effect on sea level.\nThe ice is modeled as a viscous, incompressible, creeping, shear-thinning\nfluid. The observational data come from InSAR satellite measurements of surface\nice flow velocity, and the uncertain parameter field to be inferred is the\nbasal sliding parameter. The prediction quantity of interest is the present-day\nice mass flux from the Antarctic continent to the ocean. We show that the work\nrequired for executing this data-to-prediction process is independent of the\nstate dimension, parameter dimension, data dimension, and number of processor\ncores. The key to achieving this dimension independence is to exploit the fact\nthat the observational data typically provide only sparse information on model\nparameters. This property can be exploited to construct a low rank\napproximation of the linearized parameter-to-observable map.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "35q93", "statistics - methodology", "35r30", "62f15", "35q62", "mathematics - numerical analysis", "49m15", "statistics - computation", "65c60", "86a40"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1221"}}, {"publisher": {"name": ""}, "description": "  Currently Public Safety and Security communication systems rely on reliable\nand secure Professional Mobile Radio (PMR) Networks that are mainly devoted to\nprovide voice services. However, the evolution trend for PMR networks is\ntowards the provision of new value-added multimedia services such as video\nstreaming, in order to improve the situational awareness and enhance the\nlife-saving operations. The challenge here is to exploit the future commercial\nbroadband networks to deliver voice and multimedia services satisfying the PMR\nservice requirements. In particular, a viable solution till now seems that of\nadapting the new Long Term Evolution technology to provide IP-based broadband\nservices with the security and reliability typical of PMR networks. This paper\noutlines different alternatives to achieve this goal and, in particular,\nproposes a proper solution for providing multimedia services with PMR standards\nover commercial LTE networks.\n", "contributors": [{"name": "Carl\u00e0, Lorenzo", "sameAs": [], "familyName": "Carl\u00e0", "additionalName": "", "givenName": "Lorenzo", "email": ""}, {"name": "Fantacci, Romano", "sameAs": [], "familyName": "Fantacci", "additionalName": "", "givenName": "Romano", "email": ""}, {"name": "Gei, Francesco", "sameAs": [], "familyName": "Gei", "additionalName": "", "givenName": "Francesco", "email": ""}, {"name": "Marabissi, Dania", "sameAs": [], "familyName": "Marabissi", "additionalName": "", "givenName": "Dania", "email": ""}, {"name": "Micciullo, Luigia", "sameAs": [], "familyName": "Micciullo", "additionalName": "", "givenName": "Luigia", "email": ""}], "title": "LTE enhancements for Public Safety and Security communications to\n  support Group Multimedia Communications", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.03613", "oai:arXiv.org:1501.03613"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Currently Public Safety and Security communication systems rely on reliable\nand secure Professional Mobile Radio (PMR) Networks that are mainly devoted to\nprovide voice services. However, the evolution trend for PMR networks is\ntowards the provision of new value-added multimedia services such as video\nstreaming, in order to improve the situational awareness and enhance the\nlife-saving operations. The challenge here is to exploit the future commercial\nbroadband networks to deliver voice and multimedia services satisfying the PMR\nservice requirements. In particular, a viable solution till now seems that of\nadapting the new Long Term Evolution technology to provide IP-based broadband\nservices with the security and reliability typical of PMR networks. This paper\noutlines different alternatives to achieve this goal and, in particular,\nproposes a proper solution for providing multimedia services with PMR standards\nover commercial LTE networks.\n", "Comment: IEEE Network Magazine, to appear"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - multimedia"], "providerUpdatedDateTime": "2015-01-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.03613"}}, {"publisher": {"name": ""}, "description": "  In this paper, we study idea mining from crowdsourcing applications which\nencourage a group of people, who are usually undefined and very large sized, to\ngenerate ideas for new product development (NPD). In order to isolate the\nrelatively small number of potential ones among ideas from crowd, decision\nmakers not only have to identify the key textual information representing the\nideas, but they also need to consider online opinions of people who gave\ncomments and votes on the ideas. Due to the extremely large size of text data\ngenerated by people on the Internet, identifying textual information has been\ncarried out in manual ways, and has been considered very time consuming and\ncostly. To overcome the ineffectiveness, this paper introduces a novel\nframework that can help decision makers discover ideas having the potential to\nbe used in an NPD process. To achieve this, a semi-automatic text mining\ntechnique that retrieves useful text patterns from ideas posted on\ncrowdsourcing application is proposed. Then, we provide an online learning\nalgorithm to evaluate whether the idea is potential or not. Finally to verify\nthe effectiveness of our algorithm, we conducted experiments on the data, which\nare collected from an existing crowd sourcing website.\n", "contributors": [{"name": "Dinh, Thanh-Cong", "sameAs": [], "familyName": "Dinh", "additionalName": "", "givenName": "Thanh-Cong", "email": ""}, {"name": "Bae, Hyerim", "sameAs": [], "familyName": "Bae", "additionalName": "", "givenName": "Hyerim", "email": ""}, {"name": "Park, Jaehun", "sameAs": [], "familyName": "Park", "additionalName": "", "givenName": "Jaehun", "email": ""}, {"name": "Bae, Joonsoo", "sameAs": [], "familyName": "Bae", "additionalName": "", "givenName": "Joonsoo", "email": ""}], "title": "A framework to discover potential ideas of new product development from\n  crowdsourcing application", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07015", "oai:arXiv.org:1502.07015"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we study idea mining from crowdsourcing applications which\nencourage a group of people, who are usually undefined and very large sized, to\ngenerate ideas for new product development (NPD). In order to isolate the\nrelatively small number of potential ones among ideas from crowd, decision\nmakers not only have to identify the key textual information representing the\nideas, but they also need to consider online opinions of people who gave\ncomments and votes on the ideas. Due to the extremely large size of text data\ngenerated by people on the Internet, identifying textual information has been\ncarried out in manual ways, and has been considered very time consuming and\ncostly. To overcome the ineffectiveness, this paper introduces a novel\nframework that can help decision makers discover ideas having the potential to\nbe used in an NPD process. To achieve this, a semi-automatic text mining\ntechnique that retrieves useful text patterns from ideas posted on\ncrowdsourcing application is proposed. Then, we provide an online learning\nalgorithm to evaluate whether the idea is potential or not. Finally to verify\nthe effectiveness of our algorithm, we conducted experiments on the data, which\nare collected from an existing crowd sourcing website.\n", "Comment: International Conference on Computer, Networks, Systems, and\n  Industrial Applications (CNSI 2012), Jeju Island, Korea, July 16-18, 2012"]}}], "languages": [null], "subjects": ["computer science - information retrieval"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07015"}}, {"publisher": {"name": ""}, "description": "  This paper presents a novel pairwise constraint propagation approach by\ndecomposing the challenging constraint propagation problem into a set of\nindependent semi-supervised learning subproblems which can be solved in\nquadratic time using label propagation based on k-nearest neighbor graphs.\nConsidering that this time cost is proportional to the number of all possible\npairwise constraints, our approach actually provides an efficient solution for\nexhaustively propagating pairwise constraints throughout the entire dataset.\nThe resulting exhaustive set of propagated pairwise constraints are further\nused to adjust the similarity matrix for constrained spectral clustering. Other\nthan the traditional constraint propagation on single-source data, our approach\nis also extended to more challenging constraint propagation on multi-source\ndata where each pairwise constraint is defined over a pair of data points from\ndifferent sources. This multi-source constraint propagation has an important\napplication to cross-modal multimedia retrieval. Extensive results have shown\nthe superior performance of our approach.\n", "contributors": [{"name": "Lu, Zhiwu", "sameAs": [], "familyName": "Lu", "additionalName": "", "givenName": "Zhiwu", "email": ""}, {"name": "Ip, Horace H. S.", "sameAs": [], "familyName": "Ip", "additionalName": "H. S.", "givenName": "Horace", "email": ""}, {"name": "Peng, Yuxin", "sameAs": [], "familyName": "Peng", "additionalName": "", "givenName": "Yuxin", "email": ""}], "title": "Exhaustive and Efficient Constraint Propagation: A Semi-Supervised\n  Learning Perspective and Its Applications", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-09-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.4684", "International Journal of Computer Vision (IJCV), 2012", "doi:10.1007/s11263-012-0602-z", "oai:arXiv.org:1109.4684"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper presents a novel pairwise constraint propagation approach by\ndecomposing the challenging constraint propagation problem into a set of\nindependent semi-supervised learning subproblems which can be solved in\nquadratic time using label propagation based on k-nearest neighbor graphs.\nConsidering that this time cost is proportional to the number of all possible\npairwise constraints, our approach actually provides an efficient solution for\nexhaustively propagating pairwise constraints throughout the entire dataset.\nThe resulting exhaustive set of propagated pairwise constraints are further\nused to adjust the similarity matrix for constrained spectral clustering. Other\nthan the traditional constraint propagation on single-source data, our approach\nis also extended to more challenging constraint propagation on multi-source\ndata where each pairwise constraint is defined over a pair of data points from\ndifferent sources. This multi-source constraint propagation has an important\napplication to cross-modal multimedia retrieval. Extensive results have shown\nthe superior performance of our approach.\n", "Comment: The short version of this paper appears as oral paper in ECCV 2010"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - learning"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.4684"}}, {"publisher": {"name": ""}, "description": "  Residential Thermostatically Controlled Loads (TCLs) such as Air Conditioners\n(ACs), heat pumps, water heaters, and refrigerators have an enormous thermal\nstorage potential for providing regulation reserve to the grid. In this paper,\nwe study the potential resource and economic analysis of TCLs providing\nfrequency regulation service. In particular, we show that the potential\nresource of TCLs in California is more than enough for both current and\npredicted near-future regulation requirements for the California power system.\nMoreover, we estimate the cost and revenue of TCLs, discuss the qualification\nrequirements, recommended policy changes, and participation incentive methods,\nand compare TCLs with other energy storage technologies. We show that TCLs are\npotentially more cost-effective than other energy storage technologies such as\nflywheels, Li-ion, advanced lead acid, and Zinc Bromide batteries.\n", "contributors": [{"name": "Hao, He", "sameAs": [], "familyName": "Hao", "additionalName": "", "givenName": "He", "email": ""}, {"name": "Sanandaji, Borhan M.", "sameAs": [], "familyName": "Sanandaji", "additionalName": "M.", "givenName": "Borhan", "email": ""}, {"name": "Poolla, Kameshwar", "sameAs": [], "familyName": "Poolla", "additionalName": "", "givenName": "Kameshwar", "email": ""}, {"name": "Vincent, Tyrone L.", "sameAs": [], "familyName": "Vincent", "additionalName": "L.", "givenName": "Tyrone", "email": ""}], "title": "Potentials and Economics of Residential Thermal Loads Providing\n  Regulation Reserve", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-16", "2014-12-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.5320", "oai:arXiv.org:1409.5320"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Residential Thermostatically Controlled Loads (TCLs) such as Air Conditioners\n(ACs), heat pumps, water heaters, and refrigerators have an enormous thermal\nstorage potential for providing regulation reserve to the grid. In this paper,\nwe study the potential resource and economic analysis of TCLs providing\nfrequency regulation service. In particular, we show that the potential\nresource of TCLs in California is more than enough for both current and\npredicted near-future regulation requirements for the California power system.\nMoreover, we estimate the cost and revenue of TCLs, discuss the qualification\nrequirements, recommended policy changes, and participation incentive methods,\nand compare TCLs with other energy storage technologies. We show that TCLs are\npotentially more cost-effective than other energy storage technologies such as\nflywheels, Li-ion, advanced lead acid, and Zinc Bromide batteries.\n"}}], "languages": [null], "subjects": ["computer science - systems and control"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.5320"}}, {"publisher": {"name": ""}, "description": "  The citation potential is a measure of the probability of being cited.\nObviously, it is different among fields of science, social science, and\nhumanities because of systematic differences in publication and citation\nbehaviour across disciplines. In the past, the citation potential was studied\nat journal level considering the average number of references in established\ngroups of journals (for example, the crown indicator is based on the journal\nsubject categories in the Web of Science database). In this paper, some\ncharacterizations of the author?s scientific research through three different\nresearch dimensions are proposed: production (journal papers), impact (journal\ncitations), and reference (bibliographical sources). Then, we propose different\nmeasures of the citation potential for authors based on a proportion of these\ndimensions. An empirical application, in a set of 120 randomly selected highly\nproductive authors from the CSIC Research Centre (Spain) in four subject areas,\nshows that the ratio between production and impact dimensions is a normalized\nmeasure of the citation potential at the level of individual authors. Moreover,\nthis ratio reduces the between-group variance in relation to the within-group\nvariance in a higher proportion than the rest of the indicators analysed.\nFurthermore, it is consistent with the type of journal impact indicator used. A\npossible application of this result is in the selection and promotion process\nwithin interdisciplinary institutions, since it allows comparisons of authors\nbased on their particular scientific research.\n", "contributors": [{"name": "Dorta-Gonzalez, Pablo", "sameAs": [], "familyName": "Dorta-Gonzalez", "additionalName": "", "givenName": "Pablo", "email": ""}, {"name": "Dorta-Gonzalez, Maria Isabel", "sameAs": [], "familyName": "Dorta-Gonzalez", "additionalName": "Isabel", "givenName": "Maria", "email": ""}, {"name": "Suarez-Vega, Rafael", "sameAs": [], "familyName": "Suarez-Vega", "additionalName": "", "givenName": "Rafael", "email": ""}], "title": "An approach to the author citation potential: Measures of scientific\n  performance which are invariant across scientific fields", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2065", "oai:arXiv.org:1410.2065"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The citation potential is a measure of the probability of being cited.\nObviously, it is different among fields of science, social science, and\nhumanities because of systematic differences in publication and citation\nbehaviour across disciplines. In the past, the citation potential was studied\nat journal level considering the average number of references in established\ngroups of journals (for example, the crown indicator is based on the journal\nsubject categories in the Web of Science database). In this paper, some\ncharacterizations of the author?s scientific research through three different\nresearch dimensions are proposed: production (journal papers), impact (journal\ncitations), and reference (bibliographical sources). Then, we propose different\nmeasures of the citation potential for authors based on a proportion of these\ndimensions. An empirical application, in a set of 120 randomly selected highly\nproductive authors from the CSIC Research Centre (Spain) in four subject areas,\nshows that the ratio between production and impact dimensions is a normalized\nmeasure of the citation potential at the level of individual authors. Moreover,\nthis ratio reduces the between-group variance in relation to the within-group\nvariance in a higher proportion than the rest of the indicators analysed.\nFurthermore, it is consistent with the type of journal impact indicator used. A\npossible application of this result is in the selection and promotion process\nwithin interdisciplinary institutions, since it allows comparisons of authors\nbased on their particular scientific research.\n", "Comment: 31 pages, 4 figures and 7 tables. arXiv admin note: text overlap with\n  arXiv:1402.6317, arXiv:1304.5101; and with arXiv:1003.2167 by other authors"]}}], "languages": [null], "subjects": ["computer science - digital libraries"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2065"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "The growth and decline of manufacturing industries in the past century and the industrial landscape that this activity has produced has had profound physical, environmental, social and economic impact on the communities of which they are an integral part. Throughout the past century, industry has dominated the man-made environment in tenns of its size, frequency of occurrence and highly prominent position in the community. In America this is particularly true, as the history of urban industrialism has shaped our nation and the character of our urban environment over the last one hundred years. Because industrial sites have played a significant role in the physical form, social composition and environmental-both natural and man-made character of American communities - their obsolescence, whether creating a change in function or eliminating the function entirely, leaves a tremendous void, both physically and economically. The obsolete industrial landscape,whether abandoned or underutilized, leaves the public and private sectors, as well as the community with the task of \"reconstructing\"-the reintegration of large scale environments through reuse and reprogramming-the site, architecture and infrastructure that is left as obsolete. Reconstruction of obsolete or redundant industrial sites occurs in various ways, though efforts are generally of a fairly singular focus, with the private sector making decisions based largely on market and financial considerations. While the private sector has made some effort to retrofit existing facilities with new technology and processes, the conventional approach has been to leave them behind and start fresh. Existing infrastructure, environmental quality and employee relations are generally deemed too difficult to retrofit, and so new plants are developed on green fields elsewhere, while older facilities are abandoned, demolished or sold to other parties for redevelopment. Reuse strategies have focused on the subdivision of older industrial structures to accommodate incubator industries which require less square footage than traditional heavy industries. While examples of this conventional redevelopment approach dominate in the United States, a multidisciplinary, participatory approach has been used in both European countries and the United States. Over the last decade, increased interest in the industrial landscape and its reconstruction has spawned numerous efforts world wide. In Italy and France, private sector finns such as Fiat, Pirelli, and Schlumberger have joined forces with the public sector in order to develop planning and design directions for important pieces of the urban landscape. Programs range from institutional and mixed use development to industrial and commercial reuse. In the United States, planning efforts at the federal, state and local levels have produced various participatory approaches. In recent years, the Department of the Interior through the National Park Service, has developed and implemented a program of \"heritage areas\", focused on the country's transportation and industrial heritage. The objectives of the cultural development strategy are to preserve industrial heritage while catalyzing economic development in the surrounding community. A candidate for multidisciplinary reconstruction planning is the Ford Rouge Complex in Dearborn, Michigan. The Rouge Complex has served for its 75 years as the center piece of the regional automotive economy in Southeastern Michigan and the automotive manufacturing in the country as a whole. From its modest beginnings on remote farm and marshland in 1917, Henry Ford I and Albert Kahn's joint vision for the Rouge quickly eclipsed their revolutionary Highland Park facility, inherited its assembly line and grew to become the largest manufacturing complex in the world. Once, the self proclaimed \"industrial city\" was admired, imitated, portrayed and visited by industrialists, artists and designers and tourists from every comer of the world. Today, the complex is in a state of transition and uncertainty about the future. Poised for reconstruction, it is now at the center of an economy which has been wholly dependent on the cyclical nature of the automotive industry and tied to its convulsions, relocations and downsizing. The Rouge is also in the midst of the region's economic and social strife Based on these existing conditions, can a reconstruction approach for the site create new economic and social value? If a strategy which embraces a multidimensional notion of value, emphasizing \"information value\", is employed, the answer may be in the affirmative. Considered in this way, the Rouge represents a major redevelopment opportunity. Nowhere is there a more potent site for such a redevelopment; nowhere in the region does the confluence of these three notions of value occur in a more powerful way. The infrastructure that exists there could not be cost effectively reproduced today. There is no other location in the region which is better served by modal options or better positioned in relation to such options. Most importantly, there are few other sites in the world which are so charged with historic and cultural meaning which is of significance at a local, national and international level, and where the juxtaposition of 20th and 21st century industrial landscape and technology meet. The thesis concludes with a recommended scenario for the reconstruction of the Rouge, focusing on a master planning approach and recommended development program which draw from examples of industrial reconstruction precedents in the the European Community and the United States. The recommended scenario advocates a multidisciplinary, participatory master planning approach. The process identifies different notions of \"value\" that are inherent in the Rouge. The development concept consists of four development components, each embracing different notions of value, all of which hold economic potential: infrastructure value, which focuses on the value of the buildings and infrastructure to the market, location value, which focuses on the sites context, adjacencies and linkages; and the information value, which focuses on the symbolic, historic and cultural meaning of the site. In approaching the site with this combination, the results are enhanced economic value and a physical result which addresses the concerns and issues of the stakeholders in the process-the company, the union and the community.", "contributors": [{"name": "Bodurow Rea, Constance Corinne", "sameAs": [], "familyName": "Bodurow Rea", "additionalName": "Corinne", "givenName": "Constance", "email": ""}, {"name": "Julian Beinart.", "sameAs": [], "familyName": "Beinart.", "additionalName": "", "givenName": "Julian", "email": ""}], "title": "Rethinking the industrial landscape : the future of the Ford Rouge complex", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": ["273 p.", "22872770 bytes", "22912824 bytes", "application/pdf", "application/pdf"]}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/26826", "24874210", "oai:dspace.mit.edu:1721.1/26826"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2005-09-06T20:21:57Z", "2005-09-06T20:21:57Z", "1991", "1991"]}}, {"name": "description", "properties": {"description": ["The growth and decline of manufacturing industries in the past century and the industrial landscape that this activity has produced has had profound physical, environmental, social and economic impact on the communities of which they are an integral part. Throughout the past century, industry has dominated the man-made environment in tenns of its size, frequency of occurrence and highly prominent position in the community. In America this is particularly true, as the history of urban industrialism has shaped our nation and the character of our urban environment over the last one hundred years. Because industrial sites have played a significant role in the physical form, social composition and environmental-both natural and man-made character of American communities - their obsolescence, whether creating a change in function or eliminating the function entirely, leaves a tremendous void, both physically and economically. The obsolete industrial landscape,whether abandoned or underutilized, leaves the public and private sectors, as well as the community with the task of \"reconstructing\"-the reintegration of large scale environments through reuse and reprogramming-the site, architecture and infrastructure that is left as obsolete. Reconstruction of obsolete or redundant industrial sites occurs in various ways, though efforts are generally of a fairly singular focus, with the private sector making decisions based largely on market and financial considerations. While the private sector has made some effort to retrofit existing facilities with new technology and processes, the conventional approach has been to leave them behind and start fresh. Existing infrastructure, environmental quality and employee relations are generally deemed too difficult to retrofit, and so new plants are developed on green fields elsewhere, while older facilities are abandoned, demolished or sold to other parties for redevelopment. Reuse strategies have focused on the subdivision of older industrial structures to accommodate incubator industries which require less square footage than traditional heavy industries. While examples of this conventional redevelopment approach dominate in the United States, a multidisciplinary, participatory approach has been used in both European countries and the United States. Over the last decade, increased interest in the industrial landscape and its reconstruction has spawned numerous efforts world wide. In Italy and France, private sector finns such as Fiat, Pirelli, and Schlumberger have joined forces with the public sector in order to develop planning and design directions for important pieces of the urban landscape. Programs range from institutional and mixed use development to industrial and commercial reuse. In the United States, planning efforts at the federal, state and local levels have produced various participatory approaches. In recent years, the Department of the Interior through the National Park Service, has developed and implemented a program of \"heritage areas\", focused on the country's transportation and industrial heritage. The objectives of the cultural development strategy are to preserve industrial heritage while catalyzing economic development in the surrounding community. A candidate for multidisciplinary reconstruction planning is the Ford Rouge Complex in Dearborn, Michigan. The Rouge Complex has served for its 75 years as the center piece of the regional automotive economy in Southeastern Michigan and the automotive manufacturing in the country as a whole. From its modest beginnings on remote farm and marshland in 1917, Henry Ford I and Albert Kahn's joint vision for the Rouge quickly eclipsed their revolutionary Highland Park facility, inherited its assembly line and grew to become the largest manufacturing complex in the world. Once, the self proclaimed \"industrial city\" was admired, imitated, portrayed and visited by industrialists, artists and designers and tourists from every comer of the world. Today, the complex is in a state of transition and uncertainty about the future. Poised for reconstruction, it is now at the center of an economy which has been wholly dependent on the cyclical nature of the automotive industry and tied to its convulsions, relocations and downsizing. The Rouge is also in the midst of the region's economic and social strife Based on these existing conditions, can a reconstruction approach for the site create new economic and social value? If a strategy which embraces a multidimensional notion of value, emphasizing \"information value\", is employed, the answer may be in the affirmative. Considered in this way, the Rouge represents a major redevelopment opportunity. Nowhere is there a more potent site for such a redevelopment; nowhere in the region does the confluence of these three notions of value occur in a more powerful way. The infrastructure that exists there could not be cost effectively reproduced today. There is no other location in the region which is better served by modal options or better positioned in relation to such options. Most importantly, there are few other sites in the world which are so charged with historic and cultural meaning which is of significance at a local, national and international level, and where the juxtaposition of 20th and 21st century industrial landscape and technology meet. The thesis concludes with a recommended scenario for the reconstruction of the Rouge, focusing on a master planning approach and recommended development program which draw from examples of industrial reconstruction precedents in the the European Community and the United States. The recommended scenario advocates a multidisciplinary, participatory master planning approach. The process identifies different notions of \"value\" that are inherent in the Rouge. The development concept consists of four development components, each embracing different notions of value, all of which hold economic potential: infrastructure value, which focuses on the value of the buildings and infrastructure to the market, location value, which focuses on the sites context, adjacencies and linkages; and the information value, which focuses on the symbolic, historic and cultural meaning of the site. In approaching the site with this combination, the results are enhanced economic value and a physical result which addresses the concerns and issues of the stakeholders in the process-the company, the union and the community.", "by Constance Corinne Bodurow Rea.", "Thesis (M.S.)--Massachusetts Institute of Technology, Dept. of Architecture, 1991.", "Includes bibliographical references (p. 267-273)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7635", "hdl_1721.1_7772"]}}], "languages": [null], "subjects": ["ford motor company. rouge river plant.", "architecture"], "providerUpdatedDateTime": "2015-04-27T15:29:47", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/26826"}}, {"publisher": {"name": ""}, "description": "  We consider the Bayesian Persuasion problem, as formalized by Kamenica and\nGentzkow, from an algorithmic perspective in the presence of high dimensional\nand combinatorial uncertainty. Specifically, one player (the receiver) must\ntake one of a number of actions with a-priori unknown payoff; another player\n(the sender) is privy to additional information regarding the payoffs of the\nvarious actions for both players. The sender can commit to revealing a noisy\nsignal regarding the realization of the payoffs of various actions, and would\nlike to do so as to maximize her own payoff in expectation assuming that the\nreceiver rationally acts to maximize his own payoff. This models a number of\nnatural strategic interactions, in domains as diverse as e-commerce, politics,\nlaw, security, finance, and others.\n  Assuming a Bayesian receiver, we study the sender's problem with an\nalgorithmic and approximation lens. We show two results for the case in which\nthe payoffs of different actions are i.i.d and given explicitly: a\npolynomial-time (exact) algorithmic solution, and a \"simple\" $(1-1/e)$\napproximation algorithm. Both results hinge on a \"symmetry characterization\" of\nthe optimal signaling scheme. We then turn our attention to the general\nproblem, and consider distributions over action payoffs given by a sampling\noracle. Somewhat surprisingly, we show that even in this general setting the\npersuasion problem admits a fully polynomial-time approximation scheme (FPTAS)\nin a bi-criteria sense. As our main technical tool to prove this theorem, we\ndesign algorithms for a natural and abstract question on vector spaces, which\nwe term dispersion testing: Given two distributions $\\mathcal{A}$ and\n$\\mathcal{B}$ supported on a finite-dimensional vector space, decide whether\n$\\mathcal{A}$ is approximately a mean-preserving spread of $\\mathcal{B}$, and\nif so compute the associated spreading map approximately.\n", "contributors": [{"name": "Dughmi, Shaddin", "sameAs": [], "familyName": "Dughmi", "additionalName": "", "givenName": "Shaddin", "email": ""}, {"name": "Xu, Haifeng", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Haifeng", "email": ""}], "title": "Algorithmic Bayesian Persuasion", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-20", "2015-04-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.05988", "oai:arXiv.org:1503.05988"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We consider the Bayesian Persuasion problem, as formalized by Kamenica and\nGentzkow, from an algorithmic perspective in the presence of high dimensional\nand combinatorial uncertainty. Specifically, one player (the receiver) must\ntake one of a number of actions with a-priori unknown payoff; another player\n(the sender) is privy to additional information regarding the payoffs of the\nvarious actions for both players. The sender can commit to revealing a noisy\nsignal regarding the realization of the payoffs of various actions, and would\nlike to do so as to maximize her own payoff in expectation assuming that the\nreceiver rationally acts to maximize his own payoff. This models a number of\nnatural strategic interactions, in domains as diverse as e-commerce, politics,\nlaw, security, finance, and others.\n  Assuming a Bayesian receiver, we study the sender's problem with an\nalgorithmic and approximation lens. We show two results for the case in which\nthe payoffs of different actions are i.i.d and given explicitly: a\npolynomial-time (exact) algorithmic solution, and a \"simple\" $(1-1/e)$\napproximation algorithm. Both results hinge on a \"symmetry characterization\" of\nthe optimal signaling scheme. We then turn our attention to the general\nproblem, and consider distributions over action payoffs given by a sampling\noracle. Somewhat surprisingly, we show that even in this general setting the\npersuasion problem admits a fully polynomial-time approximation scheme (FPTAS)\nin a bi-criteria sense. As our main technical tool to prove this theorem, we\ndesign algorithms for a natural and abstract question on vector spaces, which\nwe term dispersion testing: Given two distributions $\\mathcal{A}$ and\n$\\mathcal{B}$ supported on a finite-dimensional vector space, decide whether\n$\\mathcal{A}$ is approximately a mean-preserving spread of $\\mathcal{B}$, and\nif so compute the associated spreading map approximately.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.05988"}}, {"publisher": {"name": ""}, "description": "  Decision trees are a popular technique in statistical data classification.\nThey recursively partition the feature space into disjoint sub-regions until\neach sub-region becomes homogeneous with respect to a particular class. The\nbasic Classification and Regression Tree (CART) algorithm partitions the\nfeature space using axis parallel splits. When the true decision boundaries are\nnot aligned with the feature axes, this approach can produce a complicated\nboundary structure. Oblique decision trees use oblique decision boundaries to\npotentially simplify the boundary structure. The major limitation of this\napproach is that the tree induction algorithm is computationally expensive. In\nthis article we present a new decision tree algorithm, called HHCART. The\nmethod utilizes a series of Householder matrices to reflect the training data\nat each node during the tree construction. Each reflection is based on the\ndirections of the eigenvectors from each classes' covariance matrix.\nConsidering axis parallel splits in the reflected training data provides an\nefficient way of finding oblique splits in the unreflected training data.\nExperimental results show that the accuracy and size of the HHCART trees are\ncomparable with some benchmark methods in the literature. The appealing feature\nof HHCART is that it can handle both qualitative and quantitative features in\nthe same oblique split.\n", "contributors": [{"name": "Wickramarachchi, D. C.", "sameAs": [], "familyName": "Wickramarachchi", "additionalName": "C.", "givenName": "D.", "email": ""}, {"name": "Robertson, B. L.", "sameAs": [], "familyName": "Robertson", "additionalName": "L.", "givenName": "B.", "email": ""}, {"name": "Reale, M.", "sameAs": [], "familyName": "Reale", "additionalName": "", "givenName": "M.", "email": ""}, {"name": "Price, C. J.", "sameAs": [], "familyName": "Price", "additionalName": "J.", "givenName": "C.", "email": ""}, {"name": "Brown, J.", "sameAs": [], "familyName": "Brown", "additionalName": "", "givenName": "J.", "email": ""}], "title": "HHCART: An Oblique Decision Tree", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03415", "oai:arXiv.org:1504.03415"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Decision trees are a popular technique in statistical data classification.\nThey recursively partition the feature space into disjoint sub-regions until\neach sub-region becomes homogeneous with respect to a particular class. The\nbasic Classification and Regression Tree (CART) algorithm partitions the\nfeature space using axis parallel splits. When the true decision boundaries are\nnot aligned with the feature axes, this approach can produce a complicated\nboundary structure. Oblique decision trees use oblique decision boundaries to\npotentially simplify the boundary structure. The major limitation of this\napproach is that the tree induction algorithm is computationally expensive. In\nthis article we present a new decision tree algorithm, called HHCART. The\nmethod utilizes a series of Householder matrices to reflect the training data\nat each node during the tree construction. Each reflection is based on the\ndirections of the eigenvectors from each classes' covariance matrix.\nConsidering axis parallel splits in the reflected training data provides an\nefficient way of finding oblique splits in the unreflected training data.\nExperimental results show that the accuracy and size of the HHCART trees are\ncomparable with some benchmark methods in the literature. The appealing feature\nof HHCART is that it can handle both qualitative and quantitative features in\nthe same oblique split.\n", "Comment: 13 Pages, 1 Figure, 4 Tables, 1 Algorithm"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03415"}}, {"publisher": {"name": ""}, "description": "  Pheet is a C++ task-scheduling framework that allows for easy customization\nof internal data-structures. The implementation was started before the C++11\nstandard was committed and therefore did not use the new standardized memory\nmodel but compiler/platform specific intrinsics for atomic memory operations.\nThis not only makes the implementation harder to port to other compilers or\narchitectures but also suffers from the fact that prior C++ versions did not\nspecify any memory model.\n  In this report I discuss the porting of one of the internal Pheet data\nstructures to the new memory model and provide reasoning about the correctness\nbased on the semantics of the memory consistency model. Using two benchmarks\nfrom the Pheet benchmark suite I compare the performance of the original\nagainst the new implementation which shows a significant speedup under certain\nconditions on one of the two test machines.\n", "contributors": [{"name": "P\u00f6ter, Manuel", "sameAs": [], "familyName": "P\u00f6ter", "additionalName": "", "givenName": "Manuel", "email": ""}], "title": "Pheet meets C++11", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1951", "oai:arXiv.org:1411.1951"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Pheet is a C++ task-scheduling framework that allows for easy customization\nof internal data-structures. The implementation was started before the C++11\nstandard was committed and therefore did not use the new standardized memory\nmodel but compiler/platform specific intrinsics for atomic memory operations.\nThis not only makes the implementation harder to port to other compilers or\narchitectures but also suffers from the fact that prior C++ versions did not\nspecify any memory model.\n  In this report I discuss the porting of one of the internal Pheet data\nstructures to the new memory model and provide reasoning about the correctness\nbased on the semantics of the memory consistency model. Using two benchmarks\nfrom the Pheet benchmark suite I compare the performance of the original\nagainst the new implementation which shows a significant speedup under certain\nconditions on one of the two test machines.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-11-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1951"}}, {"publisher": {"name": ""}, "description": "  We present a formally verified global optimization framework. Given a\nsemialgebraic or transcendental function $f$ and a compact semialgebraic domain\n$K$, we use the nonlinear maxplus template approximation algorithm to provide a\ncertified lower bound of $f$ over $K$. This method allows to bound in a modular\nway some of the constituents of $f$ by suprema of quadratic forms with a well\nchosen curvature. Thus, we reduce the initial goal to a hierarchy of\nsemialgebraic optimization problems, solved by sums of squares relaxations. Our\nimplementation tool interleaves semialgebraic approximations with sums of\nsquares witnesses to form certificates. It is interfaced with Coq and thus\nbenefits from the trusted arithmetic available inside the proof assistant. This\nfeature is used to produce, from the certificates, both valid underestimators\nand lower bounds for each approximated constituent. The application range for\nsuch a tool is widespread; for instance Hales' proof of Kepler's conjecture\nyields thousands of multivariate transcendental inequalities. We illustrate the\nperformance of our formal framework on some of these inequalities as well as on\nexamples from the global optimization literature.\n", "contributors": [{"name": "Magron, Victor", "sameAs": [], "familyName": "Magron", "additionalName": "", "givenName": "Victor", "email": ""}, {"name": "Allamigeon, Xavier", "sameAs": [], "familyName": "Allamigeon", "additionalName": "", "givenName": "Xavier", "email": ""}, {"name": "Gaubert, St\u00e9phane", "sameAs": [], "familyName": "Gaubert", "additionalName": "", "givenName": "St\u00e9phane", "email": ""}, {"name": "Werner, Benjamin", "sameAs": [], "familyName": "Werner", "additionalName": "", "givenName": "Benjamin", "email": ""}], "title": "Formal Proofs for Nonlinear Optimization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-29", "2015-01-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.7282", "oai:arXiv.org:1404.7282"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We present a formally verified global optimization framework. Given a\nsemialgebraic or transcendental function $f$ and a compact semialgebraic domain\n$K$, we use the nonlinear maxplus template approximation algorithm to provide a\ncertified lower bound of $f$ over $K$. This method allows to bound in a modular\nway some of the constituents of $f$ by suprema of quadratic forms with a well\nchosen curvature. Thus, we reduce the initial goal to a hierarchy of\nsemialgebraic optimization problems, solved by sums of squares relaxations. Our\nimplementation tool interleaves semialgebraic approximations with sums of\nsquares witnesses to form certificates. It is interfaced with Coq and thus\nbenefits from the trusted arithmetic available inside the proof assistant. This\nfeature is used to produce, from the certificates, both valid underestimators\nand lower bounds for each approximated constituent. The application range for\nsuch a tool is widespread; for instance Hales' proof of Kepler's conjecture\nyields thousands of multivariate transcendental inequalities. We illustrate the\nperformance of our formal framework on some of these inequalities as well as on\nexamples from the global optimization literature.\n", "Comment: 24 pages, 2 figures, 3 tables"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - logic in computer science"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.7282"}}, {"publisher": {"name": ""}, "description": "  Motivated by the analogy between successive interference cancellation and\niterative belief-propagation on erasure channels, irregular repetition slotted\nALOHA (IRSA) strategies have received a lot of attention in the design of\nmedium access control protocols. The IRSA schemes have been mostly analyzed for\ntheoretical scenarios for homogenous sources, where they are shown to\nsubstantially improve the system performance compared to classical slotted\nALOHA protocols. In this work, we consider generic systems where sources in\ndifferent importance classes compete for a common channel. We propose a new\nprioritized IRSA algorithm and derive the probability to correctly resolve\ncollisions for data from each source class. We then make use of our theoretical\nanalysis to formulate a new optimization problem for selecting the transmission\nstrategies of heterogenous sources. We optimize both the replication\nprobability per class and the source rate per class, in such a way that the\noverall system utility is maximized. We then propose a heuristic-based\nalgorithm for the selection of the transmission strategy, which is built on\nintrinsic characteristics of the iterative decoding methods adopted for\nrecovering from collisions. Experimental results validate the accuracy of the\ntheoretical study and show the gain of well-chosen prioritized transmission\nstrategies for transmission of data from heterogenous classes over shared\nwireless channels.\n", "contributors": [{"name": "Toni, Laura", "sameAs": [], "familyName": "Toni", "additionalName": "", "givenName": "Laura", "email": ""}, {"name": "Frossard, Pascal", "sameAs": [], "familyName": "Frossard", "additionalName": "", "givenName": "Pascal", "email": ""}], "title": "Prioritized Random MAC Optimization via Graph-based Analysis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00587", "oai:arXiv.org:1501.00587"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Motivated by the analogy between successive interference cancellation and\niterative belief-propagation on erasure channels, irregular repetition slotted\nALOHA (IRSA) strategies have received a lot of attention in the design of\nmedium access control protocols. The IRSA schemes have been mostly analyzed for\ntheoretical scenarios for homogenous sources, where they are shown to\nsubstantially improve the system performance compared to classical slotted\nALOHA protocols. In this work, we consider generic systems where sources in\ndifferent importance classes compete for a common channel. We propose a new\nprioritized IRSA algorithm and derive the probability to correctly resolve\ncollisions for data from each source class. We then make use of our theoretical\nanalysis to formulate a new optimization problem for selecting the transmission\nstrategies of heterogenous sources. We optimize both the replication\nprobability per class and the source rate per class, in such a way that the\noverall system utility is maximized. We then propose a heuristic-based\nalgorithm for the selection of the transmission strategy, which is built on\nintrinsic characteristics of the iterative decoding methods adopted for\nrecovering from collisions. Experimental results validate the accuracy of the\ntheoretical study and show the gain of well-chosen prioritized transmission\nstrategies for transmission of data from heterogenous classes over shared\nwireless channels.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00587"}}, {"publisher": {"name": ""}, "description": "  \"If we know more, we can achieve more.\" This adage also applies to\ncommunication networks, where more information about the network state\ntranslates into higher sumrates. In this paper, we formalize this increase of\nsum-rate with increased knowledge of the network state. The knowledge of\nnetwork state is measured in terms of the number of hops, h, of information\navailable to each transmitter and is labeled as h-local view. To understand how\nmuch capacity is lost due to limited information, we propose to use the metric\nof normalized sum-capacity, which is the h-local view sum-capacity divided by\nglobal-view sum capacity. For the cases of one and two-local view, we\ncharacterize the normalized sum-capacity for many classes of deterministic and\nGaussian interference networks. In many cases, a scheduling scheme called\nmaximal independent graph scheduling is shown to achieve normalized\nsum-capacity. We also show that its generalization for 1-local view, labeled\ncoded set scheduling, achieves normalized sum-capacity in some cases where its\nuncoded counterpart fails to do so.\n", "contributors": [{"name": "Aggarwal, Vaneet", "sameAs": [], "familyName": "Aggarwal", "additionalName": "", "givenName": "Vaneet", "email": ""}, {"name": "Avestimehr, A. Salman", "sameAs": [], "familyName": "Avestimehr", "additionalName": "Salman", "givenName": "A.", "email": ""}, {"name": "Sabharwal, Ashutosh", "sameAs": [], "familyName": "Sabharwal", "additionalName": "", "givenName": "Ashutosh", "email": ""}], "title": "On Achieving Local View Capacity Via Maximal Independent Graph\n  Scheduling", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-04-30", "2010-10-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1004.5588", "Special Issue of the IEEE Transactions on Information Theory on\n  Interference Networks, vol.57, no.5, pp.2711,2729, May 2011", "doi:10.1109/TIT.2011.2119630", "oai:arXiv.org:1004.5588"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  \"If we know more, we can achieve more.\" This adage also applies to\ncommunication networks, where more information about the network state\ntranslates into higher sumrates. In this paper, we formalize this increase of\nsum-rate with increased knowledge of the network state. The knowledge of\nnetwork state is measured in terms of the number of hops, h, of information\navailable to each transmitter and is labeled as h-local view. To understand how\nmuch capacity is lost due to limited information, we propose to use the metric\nof normalized sum-capacity, which is the h-local view sum-capacity divided by\nglobal-view sum capacity. For the cases of one and two-local view, we\ncharacterize the normalized sum-capacity for many classes of deterministic and\nGaussian interference networks. In many cases, a scheduling scheme called\nmaximal independent graph scheduling is shown to achieve normalized\nsum-capacity. We also show that its generalization for 1-local view, labeled\ncoded set scheduling, achieves normalized sum-capacity in some cases where its\nuncoded counterpart fails to do so.\n", "Comment: Submitted to Special Issue of the IEEE Transactions on Information\n  Theory on Interference Networks, Apr 2010"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1004.5588"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "With the widespread availability of video cameras, we are facing an ever-growing enormous collection of unedited and unstructured video data. Due to lack of an automatic way to generate summaries from this large collection of consumer videos, they can be tedious and time consuming to index or search. In this work, we propose online video highlighting, a principled way of generating short video summarizing the most important and interesting contents of an unedited and unstructured video, costly both time-wise and financially for manual processing. Specifically, our method learns a dictionary from given video using group sparse coding, and updates atoms in the dictionary on-the-fly. A summary video is then generated by combining segments that cannot be sparsely reconstructed using the learned dictionary. The online fashion of our proposed method enables it to process arbitrarily long videos and start generating summaries before seeing the end of the video. Moreover, the processing time required by our proposed method is close to the original video length, achieving quasi real-time summarization speed. Theoretical analysis, together with experimental results on more than 12 hours of surveillance and YouTube videos are provided, demonstrating the effectiveness of online video highlighting.", "contributors": [{"name": "Zhao, Bin", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Bin", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "Quasi Real-Time Summarization for Consumer Videos", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-06-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/158", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1153&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1153"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "With the widespread availability of video cameras, we are facing an ever-growing enormous collection of unedited and unstructured video data. Due to lack of an automatic way to generate summaries from this large collection of consumer videos, they can be tedious and time consuming to index or search. In this work, we propose online video highlighting, a principled way of generating short video summarizing the most important and interesting contents of an unedited and unstructured video, costly both time-wise and financially for manual processing. Specifically, our method learns a dictionary from given video using group sparse coding, and updates atoms in the dictionary on-the-fly. A summary video is then generated by combining segments that cannot be sparsely reconstructed using the learned dictionary. The online fashion of our proposed method enables it to process arbitrarily long videos and start generating summaries before seeing the end of the video. Moreover, the processing time required by our proposed method is close to the original video length, achieving quasi real-time summarization speed. Theoretical analysis, together with experimental results on more than 12 hours of surveillance and YouTube videos are provided, demonstrating the effectiveness of online video highlighting."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-04-01T21:24:48", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/158"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Nuclear morphology and structure as visualized from histopathology microscopy images can yield important diagnostic clues in some benign and malignant tissue lesions. Precise quantitative information about nuclear structure and morphology, however, is currently not available for many diagnostic challenges. This is due, in part, to the lack of methods to quantify these differences from image data. We describe a method to characterize and contrast the distribution of nuclear structure in different tissue classes (normal, benign, cancer, etc.). The approach is based on quantifying chromatin morphology in different groups of cells using the optimal transportation (Kantorovich-Wasserstein) metric in combination with the Fisher discriminant analysis and multidimensional scaling techniques. We show that the optimal transportation metric is able to measure relevant biological information as it enables automatic determination of the class (e.g., normal versus cancer) of a set of nuclei. We show that the classification accuracies obtained using this metric are, on average, as good or better than those obtained utilizing a set of previously described numerical features. We apply our methods to two diagnostic challenges for surgical pathology: one in the liver and one in the thyroid. Results automatically computed using this technique show potentially biologically relevant differences in nuclear structure in liver and thyroid cancers.", "contributors": [{"name": "Wang, Wei", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Ozolek, John A.", "sameAs": [], "familyName": "Ozolek", "additionalName": "A.", "givenName": "John", "email": ""}, {"name": "Slepcev, Dejan", "sameAs": [], "familyName": "Slepcev", "additionalName": "", "givenName": "Dejan", "email": ""}, {"name": "Lee, Ann B.", "sameAs": [], "familyName": "Lee", "additionalName": "B.", "givenName": "Ann", "email": ""}, {"name": "Chen, Cheng", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Cheng", "email": ""}, {"name": "Rohde, Gustavo K.", "sameAs": [], "familyName": "Rohde", "additionalName": "K.", "givenName": "Gustavo", "email": ""}], "title": "An optimal transportation approach for nuclear structure-based pathology.", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2011-03-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/bme/147", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1139&amp;context=bme", "oai:repository.cmu.edu:bme-1139"]}}, {"name": "setSpec", "properties": {"setSpec": "publication:bme"}}, {"name": "description", "properties": {"description": "Nuclear morphology and structure as visualized from histopathology microscopy images can yield important diagnostic clues in some benign and malignant tissue lesions. Precise quantitative information about nuclear structure and morphology, however, is currently not available for many diagnostic challenges. This is due, in part, to the lack of methods to quantify these differences from image data. We describe a method to characterize and contrast the distribution of nuclear structure in different tissue classes (normal, benign, cancer, etc.). The approach is based on quantifying chromatin morphology in different groups of cells using the optimal transportation (Kantorovich-Wasserstein) metric in combination with the Fisher discriminant analysis and multidimensional scaling techniques. We show that the optimal transportation metric is able to measure relevant biological information as it enables automatic determination of the class (e.g., normal versus cancer) of a set of nuclei. We show that the classification accuracies obtained using this metric are, on average, as good or better than those obtained utilizing a set of previously described numerical features. We apply our methods to two diagnostic challenges for surgical pathology: one in the liver and one in the thyroid. Results automatically computed using this technique show potentially biologically relevant differences in nuclear structure in liver and thyroid cancers."}}], "languages": [null], "subjects": ["sensitivity and specificity", "cell nucleus", "image enhancement", "biomedical engineering and bioengineering", "thyroid neoplasms", "automated", "humans", "reproducibility of results", "algorithms", "computer-assisted", "pattern recognition", "liver neoplasms", "artificial intelligence", "image interpretation"], "providerUpdatedDateTime": "2015-01-29T22:32:54", "uris": {"canonicalUri": "http://repository.cmu.edu/bme/147"}}, {"publisher": {"name": ""}, "description": "  This volume contains a selection of the papers presented at the XIV Jornadas\nsobre Programaci\\'on y Lenguajes (PROLE 2014), held at C\\'adiz, Spain, during\nSeptember 17th-19th, 2014. Previous editions of the workshop were held in\nMadrid (2013), Almer\\'ia (2012), A Coru\\~na (2011), Val\\'encia (2010), San\nSebasti\\'an (2009), Gij\\'on (2008), Zaragoza (2007), Sitges (2006), Granada\n(2005), M\\'alaga (2004), Alicante (2003), El Escorial (2002), and Almagro\n(2001).\n  Programming languages provide a conceptual framework which is necessary for\nthe development, analysis, optimization and understanding of programs and\nprogramming tasks. The aim of the PROLE series of conferences (PROLE stems from\nthe spanish PROgramaci\\'on y LEnguajes) is to serve as a meeting point for\nspanish research groups which develop their work in the area of programming and\nprogramming languages. The organization of this series of events aims at\nfostering the exchange of ideas, experiences and results among these groups.\nPromoting further collaboration is also one of the main goals of PROLE.\n", "contributors": [{"name": "Escobar, Santiago", "sameAs": [], "familyName": "Escobar", "additionalName": "", "givenName": "Santiago", "email": ""}], "title": "Proceedings XIV Jornadas sobre Programaci\\'on y Lenguajes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.01693", "EPTCS 173, 2015", "doi:10.4204/EPTCS.173", "oai:arXiv.org:1501.01693"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This volume contains a selection of the papers presented at the XIV Jornadas\nsobre Programaci\\'on y Lenguajes (PROLE 2014), held at C\\'adiz, Spain, during\nSeptember 17th-19th, 2014. Previous editions of the workshop were held in\nMadrid (2013), Almer\\'ia (2012), A Coru\\~na (2011), Val\\'encia (2010), San\nSebasti\\'an (2009), Gij\\'on (2008), Zaragoza (2007), Sitges (2006), Granada\n(2005), M\\'alaga (2004), Alicante (2003), El Escorial (2002), and Almagro\n(2001).\n  Programming languages provide a conceptual framework which is necessary for\nthe development, analysis, optimization and understanding of programs and\nprogramming tasks. The aim of the PROLE series of conferences (PROLE stems from\nthe spanish PROgramaci\\'on y LEnguajes) is to serve as a meeting point for\nspanish research groups which develop their work in the area of programming and\nprogramming languages. The organization of this series of events aims at\nfostering the exchange of ideas, experiences and results among these groups.\nPromoting further collaboration is also one of the main goals of PROLE.\n"}}], "languages": [null], "subjects": ["computer science - programming languages", "computer science - logic in computer science", "computer science - software engineering"], "providerUpdatedDateTime": "2015-01-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.01693"}}, {"publisher": {"name": ""}, "description": "  Transactional memory (TM) allows concurrent processes to organize sequences\nof operations on shared \\emph{data items} into atomic transactions. A\ntransaction may commit, in which case it appears to have executed sequentially\nor it may \\emph{abort}, in which case no data item is updated.\n  The TM programming paradigm emerged as an alternative to conventional\nfine-grained locking techniques, offering ease of programming and\ncompositionality. Though typically themselves implemented using locks, TMs hide\nthe inherent issues of lock-based synchronization behind a nice transactional\nprogramming interface.\n  In this paper, we explore inherent time and space complexity of lock-based\nTMs, with a focus of the most popular class of \\emph{progressive} lock-based\nTMs. We derive that a progressive TM might enforce a read-only transaction to\nperform a quadratic (in the number of the data items it reads) number of steps\nand access a linear number of distinct memory locations, closing the question\nof inherent cost of \\emph{read validation} in TMs. We then show that the total\nnumber of \\emph{remote memory references} (RMRs) that take place in an\nexecution of a progressive TM in which $n$ concurrent processes perform\ntransactions on a single data item might reach $\\Omega(n \\log n)$, which\nappears to be the first RMR complexity lower bound for transactional memory.\n", "contributors": [{"name": "Kuznetsov, Petr", "sameAs": [], "familyName": "Kuznetsov", "additionalName": "", "givenName": "Petr", "email": ""}, {"name": "Ravi, Srivatsan", "sameAs": [], "familyName": "Ravi", "additionalName": "", "givenName": "Srivatsan", "email": ""}], "title": "Progressive Transactional Memory in Time and Space", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04908", "oai:arXiv.org:1502.04908"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Transactional memory (TM) allows concurrent processes to organize sequences\nof operations on shared \\emph{data items} into atomic transactions. A\ntransaction may commit, in which case it appears to have executed sequentially\nor it may \\emph{abort}, in which case no data item is updated.\n  The TM programming paradigm emerged as an alternative to conventional\nfine-grained locking techniques, offering ease of programming and\ncompositionality. Though typically themselves implemented using locks, TMs hide\nthe inherent issues of lock-based synchronization behind a nice transactional\nprogramming interface.\n  In this paper, we explore inherent time and space complexity of lock-based\nTMs, with a focus of the most popular class of \\emph{progressive} lock-based\nTMs. We derive that a progressive TM might enforce a read-only transaction to\nperform a quadratic (in the number of the data items it reads) number of steps\nand access a linear number of distinct memory locations, closing the question\nof inherent cost of \\emph{read validation} in TMs. We then show that the total\nnumber of \\emph{remote memory references} (RMRs) that take place in an\nexecution of a progressive TM in which $n$ concurrent processes perform\ntransactions on a single data item might reach $\\Omega(n \\log n)$, which\nappears to be the first RMR complexity lower bound for transactional memory.\n", "Comment: arXiv admin note: text overlap with arXiv:1407.6876, arXiv:1502.02725"]}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-02-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04908"}}, {"publisher": {"name": ""}, "description": "  Nuclear Magnetic Resonance (NMR) Spectroscopy is a widely used technique to\npredict the native structure of proteins. However, NMR machines are only able\nto report approximate and partial distances between pair of atoms. To build the\nprotein structure one has to solve the Euclidean distance geometry problem\ngiven the incomplete interval distance data produced by NMR machines. In this\npaper, we propose a new genetic algorithm for solving the Euclidean distance\ngeometry problem for protein structure prediction given sparse NMR data. Our\ngenetic algorithm uses a greedy mutation operator to intensify the search, a\ntwin removal technique for diversification in the population and a random\nrestart method to recover stagnation. On a standard set of benchmark dataset,\nour algorithm significantly outperforms standard genetic algorithms.\n", "contributors": [{"name": "Islam, Md. Lisul", "sameAs": [], "familyName": "Islam", "additionalName": "Lisul", "givenName": "Md.", "email": ""}, {"name": "Shatabda, Swakkhar", "sameAs": [], "familyName": "Shatabda", "additionalName": "", "givenName": "Swakkhar", "email": ""}, {"name": "Rahman, M. Sohel", "sameAs": [], "familyName": "Rahman", "additionalName": "Sohel", "givenName": "M.", "email": ""}], "title": "GreMuTRRR: A Novel Genetic Algorithm to Solve Distance Geometry Problem\n  for Protein Structures", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4246", "oai:arXiv.org:1411.4246"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Nuclear Magnetic Resonance (NMR) Spectroscopy is a widely used technique to\npredict the native structure of proteins. However, NMR machines are only able\nto report approximate and partial distances between pair of atoms. To build the\nprotein structure one has to solve the Euclidean distance geometry problem\ngiven the incomplete interval distance data produced by NMR machines. In this\npaper, we propose a new genetic algorithm for solving the Euclidean distance\ngeometry problem for protein structure prediction given sparse NMR data. Our\ngenetic algorithm uses a greedy mutation operator to intensify the search, a\ntwin removal technique for diversification in the population and a random\nrestart method to recover stagnation. On a standard set of benchmark dataset,\nour algorithm significantly outperforms standard genetic algorithms.\n", "Comment: Accepted for publication in the 8th International Conference on\n  Electrical and Computer Engineering (ICECE 2014)"]}}], "languages": [null], "subjects": ["computer science - computational engineering", "computer science - neural and evolutionary computing", "finance", "and science"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4246"}}, {"publisher": {"name": ""}, "description": "  In part one of the Critique of Judgment, Immanuel Kant wrote that \"the\njudgment of taste...is not a cognitive judgment, and so not logical, but is\naesthetic.\"\\cite{Kant} While the condition of aesthetic discernment has long\nbeen the subject of philosophical discourse, the role of the arbiters of that\njudgment has more often been assumed than questioned. The art historian,\ncritic, connoisseur, and curator have long held the esteemed position of the\naesthetic judge, their training, instinct, and eye part of the inimitable\nsubjective processes that Kant described as occurring upon artistic evaluation.\nAlthough the concept of intangible knowledge in regard to aesthetic theory has\nbeen much explored, little discussion has arisen in response to the development\nof new types of artificial intelligence as a challenge to the seemingly\nineffable abilities of the human observer. This paper examines the developments\nin the field of computer vision analysis of paintings from canonical movements\nwith the history of Western art and the reaction of art historians to the\napplication of this technology in the field. Through an investigation of the\nethical consequences of this innovative technology, the unquestioned authority\nof the art expert is challenged and the subjective nature of aesthetic judgment\nis brought to philosophical scrutiny once again.\n", "contributors": [{"name": "Spratt, Emily L.", "sameAs": [], "familyName": "Spratt", "additionalName": "L.", "givenName": "Emily", "email": ""}, {"name": "Elgammal, Ahmed", "sameAs": [], "familyName": "Elgammal", "additionalName": "", "givenName": "Ahmed", "email": ""}], "title": "Computational Beauty: Aesthetic Judgment at the Intersection of Art and\n  Science", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-09-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2488", "oai:arXiv.org:1410.2488"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  In part one of the Critique of Judgment, Immanuel Kant wrote that \"the\njudgment of taste...is not a cognitive judgment, and so not logical, but is\naesthetic.\"\\cite{Kant} While the condition of aesthetic discernment has long\nbeen the subject of philosophical discourse, the role of the arbiters of that\njudgment has more often been assumed than questioned. The art historian,\ncritic, connoisseur, and curator have long held the esteemed position of the\naesthetic judge, their training, instinct, and eye part of the inimitable\nsubjective processes that Kant described as occurring upon artistic evaluation.\nAlthough the concept of intangible knowledge in regard to aesthetic theory has\nbeen much explored, little discussion has arisen in response to the development\nof new types of artificial intelligence as a challenge to the seemingly\nineffable abilities of the human observer. This paper examines the developments\nin the field of computer vision analysis of paintings from canonical movements\nwith the history of Western art and the reaction of art historians to the\napplication of this technology in the field. Through an investigation of the\nethical consequences of this innovative technology, the unquestioned authority\nof the art expert is challenged and the subjective nature of aesthetic judgment\nis brought to philosophical scrutiny once again.\n"}}], "languages": [null], "subjects": ["physics - history and philosophy of physics", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-10-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2488"}}, {"publisher": {"name": ""}, "description": "  Given facilities with capacities and clients with penalties and demands, the\ntransportation problem with market choice consists in finding the minimum-cost\nway to partition the clients into unserved clients, paying the penalties, and\ninto served clients, paying the transportation cost to serve them. We give\npolynomial-time reductions from this problem and variants to the\n(un)capacitated facility location problem, directly yielding approximation\nalgorithms, two with constant factors in the metric case, one with a\nlogarithmic factor in the general case.\n", "contributors": [{"name": "Aardal, Karen", "sameAs": [], "familyName": "Aardal", "additionalName": "", "givenName": "Karen", "email": ""}, {"name": "Bodic, Pierre Le", "sameAs": [], "familyName": "Bodic", "additionalName": "Le", "givenName": "Pierre", "email": ""}], "title": "Approximation algorithms for the Transportation Problem with Market\n  Choice and related models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-09-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1409", "oai:arXiv.org:1410.1409"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Given facilities with capacities and clients with penalties and demands, the\ntransportation problem with market choice consists in finding the minimum-cost\nway to partition the clients into unserved clients, paying the penalties, and\ninto served clients, paying the transportation cost to serve them. We give\npolynomial-time reductions from this problem and variants to the\n(un)capacitated facility location problem, directly yielding approximation\nalgorithms, two with constant factors in the metric case, one with a\nlogarithmic factor in the general case.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1409"}}, {"publisher": {"name": ""}, "description": "  We present a domain adaption framework to address a domain mismatch between\nsynthetic training and real-world testing data. We demonstrate our method on a\nchallenging fine-grain classification problem: recognizing a font style from an\nimage of text. In this task, it is very easy to generate lots of rendered font\nexamples but very hard to obtain real-world labeled images. This\nreal-to-synthetic domain gap caused poor generalization to new real data in\nprevious font recognition methods (Chen et al. (2014)). In this paper, we\nintroduce a Convolutional Neural Network decomposition approach, leveraging a\nlarge training corpus of synthetic data to obtain effective features for\nclassification. This is done using an adaptation technique based on a Stacked\nConvolutional Auto-Encoder that exploits a large collection of unlabeled\nreal-world text images combined with synthetic data preprocessed in a specific\nway. The proposed DeepFont method achieves an accuracy of higher than 80%\n(top-5) on a new large labeled real-world dataset we collected.\n", "contributors": [{"name": "Wang, Zhangyang", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Zhangyang", "email": ""}, {"name": "Yang, Jianchao", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Jianchao", "email": ""}, {"name": "Jin, Hailin", "sameAs": [], "familyName": "Jin", "additionalName": "", "givenName": "Hailin", "email": ""}, {"name": "Shechtman, Eli", "sameAs": [], "familyName": "Shechtman", "additionalName": "", "givenName": "Eli", "email": ""}, {"name": "Agarwala, Aseem", "sameAs": [], "familyName": "Agarwala", "additionalName": "", "givenName": "Aseem", "email": ""}, {"name": "Brandt, Jonathan", "sameAs": [], "familyName": "Brandt", "additionalName": "", "givenName": "Jonathan", "email": ""}, {"name": "Huang, Thomas S.", "sameAs": [], "familyName": "Huang", "additionalName": "S.", "givenName": "Thomas", "email": ""}], "title": "Decomposition-Based Domain Adaptation for Real-World Font Recognition", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-18", "2015-04-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5758", "oai:arXiv.org:1412.5758"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We present a domain adaption framework to address a domain mismatch between\nsynthetic training and real-world testing data. We demonstrate our method on a\nchallenging fine-grain classification problem: recognizing a font style from an\nimage of text. In this task, it is very easy to generate lots of rendered font\nexamples but very hard to obtain real-world labeled images. This\nreal-to-synthetic domain gap caused poor generalization to new real data in\nprevious font recognition methods (Chen et al. (2014)). In this paper, we\nintroduce a Convolutional Neural Network decomposition approach, leveraging a\nlarge training corpus of synthetic data to obtain effective features for\nclassification. This is done using an adaptation technique based on a Stacked\nConvolutional Auto-Encoder that exploits a large collection of unlabeled\nreal-world text images combined with synthetic data preprocessed in a specific\nway. The proposed DeepFont method achieves an accuracy of higher than 80%\n(top-5) on a new large labeled real-world dataset we collected.\n", "Comment: This paper has been withdrawn by the author due to project concerns"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-04-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5758"}}, {"publisher": {"name": ""}, "description": "  We develop estimation for potentially high-dimensional additive structural\nequation models. A key component of our approach is to decouple order search\namong the variables from feature or edge selection in a directed acyclic graph\nencoding the causal structure. We show that the former can be done with\nnonregularized (restricted) maximum likelihood estimation while the latter can\nbe efficiently addressed using sparse regression techniques. Thus, we\nsubstantially simplify the problem of structure search and estimation for an\nimportant class of causal models. We establish consistency of the (restricted)\nmaximum likelihood estimator for low- and high-dimensional scenarios, and we\nalso allow for misspecification of the error distribution. Furthermore, we\ndevelop an efficient computational algorithm which can deal with many\nvariables, and the new method's accuracy and performance is illustrated on\nsimulated and real data.\n", "contributors": [{"name": "B\u00fchlmann, Peter", "sameAs": [], "familyName": "B\u00fchlmann", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Peters, Jonas", "sameAs": [], "familyName": "Peters", "additionalName": "", "givenName": "Jonas", "email": ""}, {"name": "Ernest, Jan", "sameAs": [], "familyName": "Ernest", "additionalName": "", "givenName": "Jan", "email": ""}], "title": "CAM: Causal additive models, high-dimensional order search and penalized\n  regression", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-05", "2014-12-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.1533", "Annals of Statistics 2014, Vol. 42, No. 6, 2526-2556", "doi:10.1214/14-AOS1260", "oai:arXiv.org:1310.1533"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  We develop estimation for potentially high-dimensional additive structural\nequation models. A key component of our approach is to decouple order search\namong the variables from feature or edge selection in a directed acyclic graph\nencoding the causal structure. We show that the former can be done with\nnonregularized (restricted) maximum likelihood estimation while the latter can\nbe efficiently addressed using sparse regression techniques. Thus, we\nsubstantially simplify the problem of structure search and estimation for an\nimportant class of causal models. We establish consistency of the (restricted)\nmaximum likelihood estimator for low- and high-dimensional scenarios, and we\nalso allow for misspecification of the error distribution. Furthermore, we\ndevelop an efficient computational algorithm which can deal with many\nvariables, and the new method's accuracy and performance is illustrated on\nsimulated and real data.\n", "Comment: Published in at http://dx.doi.org/10.1214/14-AOS1260 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)"]}}], "languages": [null], "subjects": ["statistics - methodology", "statistics - machine learning", "computer science - learning"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.1533"}}, {"publisher": {"name": ""}, "description": "  Business Process Reengineering increases enterprise's chance to survive in\ncompetition among organizations , but failure rate among reengineering efforts\nis high, so new methods that decrease failure, are needed, in this paper a\nbusiness process reengineering method is presented that uses Enterprise\nOntology for modelling the current system and its goal is to improve analysing\ncurrent system and decreasing failure rate of BPR, and cost and time of\nperforming processes, In this method instead of just modelling processes,\nprocesses with their : interactions and relations, environment, staffs and\ncustomers will be modelled in enterprise ontology. Also in choosing processes\nfor reengineering step, after choosing them, processes which, according to the\nenterprise ontology, has the most connection with the chosen ones, will also be\nchosen to reengineer, finally this method is implemented on a company and As-Is\nand To-Be processes are simulated and compared by ARIS tools, Report and\nSimulation Experiment\n", "contributors": [{"name": "Bahramnejad, Pedram", "sameAs": [], "familyName": "Bahramnejad", "additionalName": "", "givenName": "Pedram", "email": ""}, {"name": "Sharafi, Sayed Mehran", "sameAs": [], "familyName": "Sharafi", "additionalName": "Mehran", "givenName": "Sayed", "email": ""}, {"name": "Nabiollahi, Akbar", "sameAs": [], "familyName": "Nabiollahi", "additionalName": "", "givenName": "Akbar", "email": ""}], "title": "A method for business process reengineering based on enterprise ontology", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07713", "doi:10.5121/ijsea.2015.6103", "oai:arXiv.org:1503.07713"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Business Process Reengineering increases enterprise's chance to survive in\ncompetition among organizations , but failure rate among reengineering efforts\nis high, so new methods that decrease failure, are needed, in this paper a\nbusiness process reengineering method is presented that uses Enterprise\nOntology for modelling the current system and its goal is to improve analysing\ncurrent system and decreasing failure rate of BPR, and cost and time of\nperforming processes, In this method instead of just modelling processes,\nprocesses with their : interactions and relations, environment, staffs and\ncustomers will be modelled in enterprise ontology. Also in choosing processes\nfor reengineering step, after choosing them, processes which, according to the\nenterprise ontology, has the most connection with the chosen ones, will also be\nchosen to reengineer, finally this method is implemented on a company and As-Is\nand To-Be processes are simulated and compared by ARIS tools, Report and\nSimulation Experiment\n", "Comment: 15 pages, published in IJSEA"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07713"}}, {"publisher": {"name": ""}, "description": "  This paper proposes a novel generalization of group testing, called\nmulti-group testing, which relaxes the notion of \"testing subset\" in group\ntesting to \"testing multi-set\". The generalization aims to learn more\ninformation of each item to be tested rather than identify only defectives as\nwas done in conventional group testing. This paper provides efficient\nnonadaptive strategies for the multi-group testing problem. The major tool is a\nnew structure, $q$-ary additive $(w,d)$-disjunct matrix, which is a\ngeneralization of the well-known binary disjunct matrix introduced by Kautz and\nSingleton in 1964.\n", "contributors": [{"name": "Chang, Fei-Huang", "sameAs": [], "familyName": "Chang", "additionalName": "", "givenName": "Fei-Huang", "email": ""}, {"name": "Chen, Hong-Bin", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Hong-Bin", "email": ""}, {"name": "Guo, Jun-Yi", "sameAs": [], "familyName": "Guo", "additionalName": "", "givenName": "Jun-Yi", "email": ""}, {"name": "Huang, Yu-Pei", "sameAs": [], "familyName": "Huang", "additionalName": "", "givenName": "Yu-Pei", "email": ""}], "title": "Multi-Group Testing for Items with Real-Valued Status under Standard\n  Arithmetic", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-03-24", "2014-12-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1303.6020", "oai:arXiv.org:1303.6020"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper proposes a novel generalization of group testing, called\nmulti-group testing, which relaxes the notion of \"testing subset\" in group\ntesting to \"testing multi-set\". The generalization aims to learn more\ninformation of each item to be tested rather than identify only defectives as\nwas done in conventional group testing. This paper provides efficient\nnonadaptive strategies for the multi-group testing problem. The major tool is a\nnew structure, $q$-ary additive $(w,d)$-disjunct matrix, which is a\ngeneralization of the well-known binary disjunct matrix introduced by Kautz and\nSingleton in 1964.\n", "Comment: presented in part at 2nd Japan-Taiwan Conference of Combinatorics and\n  its Applications, Nagoya University, Japan, 2012"]}}], "languages": [null], "subjects": ["05c85", "computer science - information theory", "mathematics - combinatorics", "05c35"], "providerUpdatedDateTime": "2014-12-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1303.6020"}}, {"publisher": {"name": ""}, "description": "  Non-obviousness or inventive step is a general requirement for patentability\nin most patent law systems. An invention should be at an adequate distance\nbeyond its prior art in order to be patented. This short paper provides an\noverview on a methodology proposed for legal norm validation of FSTP facts\nusing rule reasoning approach.\n", "contributors": [{"name": "Karam, Naouel", "sameAs": [], "familyName": "Karam", "additionalName": "", "givenName": "Naouel", "email": ""}, {"name": "Ramakrishna, Shashishekar", "sameAs": [], "familyName": "Ramakrishna", "additionalName": "", "givenName": "Shashishekar", "email": ""}, {"name": "Paschke, Adrian", "sameAs": [], "familyName": "Paschke", "additionalName": "", "givenName": "Adrian", "email": ""}], "title": "Rule reasoning for legal norm validation of FSTP facts", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3137", "oai:arXiv.org:1412.3137"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Non-obviousness or inventive step is a general requirement for patentability\nin most patent law systems. An invention should be at an adequate distance\nbeyond its prior art in order to be patented. This short paper provides an\noverview on a methodology proposed for legal norm validation of FSTP facts\nusing rule reasoning approach.\n", "Comment: 1st International workshop on Artificial Intelligence and IP Law,\n  AIIP- Jurix 2012- Amsterdam"]}}], "languages": [null], "subjects": ["f.4.1", "computer science - artificial intelligence", "k.6.3", "d.2.5"], "providerUpdatedDateTime": "2014-12-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3137"}}, {"publisher": {"name": ""}, "description": "  We analyze the phenomenon of collusion for the purpose of boosting the\npagerank of a node in an interlinked environment. We investigate the optimal\nattack pattern for a group of nodes (attackers) attempting to improve the\nranking of a specific node (the victim). We consider attacks where the\nattackers can only manipulate their own outgoing links. We show that the\noptimal attacks in this scenario are uncoordinated, i.e. the attackers link\ndirectly to the victim and no one else. nodes do not link to each other. We\nalso discuss optimal attack patterns for a group that wants to hide itself by\nnot pointing directly to the victim. In these disguised attacks, the attackers\nlink to nodes $l$ hops away from the victim. We show that an optimal disguised\nattack exists and how it can be computed. The optimal disguised attack also\nallows us to find optimal link farm configurations. A link farm can be\nconsidered a special case of our approach: the target page of the link farm is\nthe victim and the other nodes in the link farm are the attackers for the\npurpose of improving the rank of the victim. The target page can however\ncontrol its own outgoing links for the purpose of improving its own rank, which\ncan be modeled as an optimal disguised attack of 1-hop on itself. Our results\nare unique in the literature as we show optimality not only in the pagerank\nscore, but also in the rank based on the pagerank score. We further validate\nour results with experiments on a variety of random graph models.\n", "contributors": [{"name": "Adali, Sibel", "sameAs": [], "familyName": "Adali", "additionalName": "", "givenName": "Sibel", "email": ""}, {"name": "Liu, Tina", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Tina", "email": ""}, {"name": "Magdon-Ismail, Malik", "sameAs": [], "familyName": "Magdon-Ismail", "additionalName": "", "givenName": "Malik", "email": ""}], "title": "An Analysis of Optimal Link Bombs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-03-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1103.1359", "oai:arXiv.org:1103.1359"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We analyze the phenomenon of collusion for the purpose of boosting the\npagerank of a node in an interlinked environment. We investigate the optimal\nattack pattern for a group of nodes (attackers) attempting to improve the\nranking of a specific node (the victim). We consider attacks where the\nattackers can only manipulate their own outgoing links. We show that the\noptimal attacks in this scenario are uncoordinated, i.e. the attackers link\ndirectly to the victim and no one else. nodes do not link to each other. We\nalso discuss optimal attack patterns for a group that wants to hide itself by\nnot pointing directly to the victim. In these disguised attacks, the attackers\nlink to nodes $l$ hops away from the victim. We show that an optimal disguised\nattack exists and how it can be computed. The optimal disguised attack also\nallows us to find optimal link farm configurations. A link farm can be\nconsidered a special case of our approach: the target page of the link farm is\nthe victim and the other nodes in the link farm are the attackers for the\npurpose of improving the rank of the victim. The target page can however\ncontrol its own outgoing links for the purpose of improving its own rank, which\ncan be modeled as an optimal disguised attack of 1-hop on itself. Our results\nare unique in the literature as we show optimality not only in the pagerank\nscore, but also in the rank based on the pagerank score. We further validate\nour results with experiments on a variety of random graph models.\n", "Comment: Full Version of a version which appeared in AIRweb 2005"]}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1103.1359"}}, {"publisher": {"name": ""}, "description": "  Sharing global channel information at base stations (BSs) is commonly assumed\nfor downlink multi-cell precoding. In the context of massive multi-input\nmulti-output (MIMO) systems where each BS is equipped with a large number of\nantennas, sharing instant fading channel coefficients consumes a large amount\nof resource. To consider practically implementable methods, we study in this\npaper interference reduction based on precoding using the large-scale fading\ncoefficients that depend on the path-loss model and are independent of a\nspecific antenna. We focus on the downlink multi-cell precoding designs when\neach BS is equipped with a practically finite number of antennas. In this\noperation regime, pilot contamination is not the dominant source of\ninterference, and mitigation of all types of interference is required. This\npaper uses an optimization approach to design precoding methods for equal\nqualities of service (QoS) to all users in the network, i.e.,maximizing the\nminimum signal-to-interference-plus-noise ratios (SINRs) among all users. The\nformulated optimization is proved to be quasi-convex, and can be solved\noptimally. We also propose low-complexity suboptimal algorithms through uplink\nand downlink duality. Simulation results show that the proposed precoding\nmethods improve 5% outage rate for more than 1000 times, compared to other\nknown interference mitigation techniques.\n", "contributors": [{"name": "Li, Liangbin", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Liangbin", "email": ""}, {"name": "Ashikhmin, Alexei", "sameAs": [], "familyName": "Ashikhmin", "additionalName": "", "givenName": "Alexei", "email": ""}, {"name": "Marzetta, Thomas", "sameAs": [], "familyName": "Marzetta", "additionalName": "", "givenName": "Thomas", "email": ""}], "title": "Interference Reduction in Multi-Cell Massive MIMO Systems II: Downlink\n  Analysis for a Finite Number of Antennas", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4183", "oai:arXiv.org:1411.4183"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Sharing global channel information at base stations (BSs) is commonly assumed\nfor downlink multi-cell precoding. In the context of massive multi-input\nmulti-output (MIMO) systems where each BS is equipped with a large number of\nantennas, sharing instant fading channel coefficients consumes a large amount\nof resource. To consider practically implementable methods, we study in this\npaper interference reduction based on precoding using the large-scale fading\ncoefficients that depend on the path-loss model and are independent of a\nspecific antenna. We focus on the downlink multi-cell precoding designs when\neach BS is equipped with a practically finite number of antennas. In this\noperation regime, pilot contamination is not the dominant source of\ninterference, and mitigation of all types of interference is required. This\npaper uses an optimization approach to design precoding methods for equal\nqualities of service (QoS) to all users in the network, i.e.,maximizing the\nminimum signal-to-interference-plus-noise ratios (SINRs) among all users. The\nformulated optimization is proved to be quasi-convex, and can be solved\noptimally. We also propose low-complexity suboptimal algorithms through uplink\nand downlink duality. Simulation results show that the proposed precoding\nmethods improve 5% outage rate for more than 1000 times, compared to other\nknown interference mitigation techniques.\n", "Comment: submitted to IEEE Transactions on Information Theory"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4183"}}, {"publisher": {"name": ""}, "description": "  In this paper we study the inherent trade-off between time and communication\ncomplexity for the distributed consensus problem. In our model, communication\ncomplexity is measured as the maximum data throughput (in bits per second) sent\nthrough the network at a given instant. Such a notion of communication\ncomplexity, referred to as bandwidth complexity, is related to the frequency\nbandwidth a designer should collectively allocate to the agents if they were to\ncommunicate via a wireless channel, which represents an important constraint\nfor dense robotic networks. We prove a lower bound on the bandwidth complexity\nof the consensus problem and provide a consensus algorithm that is\nbandwidth-optimal for a wide class of consensus functions. We then propose a\ndistributed algorithm that can trade communication complexity versus time\ncomplexity as a function of a tunable parameter, which can be adjusted by a\nsystem designer as a function of the properties of the wireless communication\nchannel. We rigorously characterize the tunable algorithm's worst-case\nbandwidth complexity and show that it compares favorably with the bandwidth\ncomplexity of well-known consensus algorithm.\n", "contributors": [{"name": "Rossi, Federico", "sameAs": [], "familyName": "Rossi", "additionalName": "", "givenName": "Federico", "email": ""}, {"name": "Pavone, Marco", "sameAs": [], "familyName": "Pavone", "additionalName": "", "givenName": "Marco", "email": ""}], "title": "Distributed consensus with mixed time/communication bandwidth\n  performance metrics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.0956", "oai:arXiv.org:1410.0956"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper we study the inherent trade-off between time and communication\ncomplexity for the distributed consensus problem. In our model, communication\ncomplexity is measured as the maximum data throughput (in bits per second) sent\nthrough the network at a given instant. Such a notion of communication\ncomplexity, referred to as bandwidth complexity, is related to the frequency\nbandwidth a designer should collectively allocate to the agents if they were to\ncommunicate via a wireless channel, which represents an important constraint\nfor dense robotic networks. We prove a lower bound on the bandwidth complexity\nof the consensus problem and provide a consensus algorithm that is\nbandwidth-optimal for a wide class of consensus functions. We then propose a\ndistributed algorithm that can trade communication complexity versus time\ncomplexity as a function of a tunable parameter, which can be adjusted by a\nsystem designer as a function of the properties of the wireless communication\nchannel. We rigorously characterize the tunable algorithm's worst-case\nbandwidth complexity and show that it compares favorably with the bandwidth\ncomplexity of well-known consensus algorithm.\n", "Comment: Draft, submitted to Allerton 2014"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.0956"}}, {"publisher": {"name": ""}, "description": "  A simple construction of pseudorandom generator is appear.This pseudorandom\ngenerator is always passed by NIST statistical test.This paper reports a\npseudorandom number generator which has good property is able to construct\nusing only permutation and data rewriting by XOR.\n", "contributors": [{"name": "Terasawa, Yoshihiro", "sameAs": [], "familyName": "Terasawa", "additionalName": "", "givenName": "Yoshihiro", "email": ""}], "title": "A Simple construction of the Pseudorandom Generator from Permutation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5619", "oai:arXiv.org:1412.5619"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  A simple construction of pseudorandom generator is appear.This pseudorandom\ngenerator is always passed by NIST statistical test.This paper reports a\npseudorandom number generator which has good property is able to construct\nusing only permutation and data rewriting by XOR.\n", "Comment: in japanese"]}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2014-12-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5619"}}, {"publisher": {"name": ""}, "description": "  Designing networks with specified collective properties is useful in a\nvariety of application areas, enabling the study of how given properties affect\nthe behavior of network models, the downscaling of empirical networks to\nworkable sizes, and the analysis of network evolution. Despite the importance\nof the task, there currently exists a gap in our ability to systematically\ngenerate networks that adhere to theoretical guarantees for the given property\nspecifications. In this paper, we propose the use of Mixed-Integer Linear\nOptimization modeling and solution methodologies to address this Network\nGeneration Problem. We present a number of useful modeling techniques and apply\nthem to mathematically express and constrain network properties in the context\nof an optimization formulation. We then develop complete formulations for the\ngeneration of networks that attain specified levels of connectivity, spread,\nassortativity and robustness, and we illustrate these via a number of\ncomputational case studies.\n", "contributors": [{"name": "Gounaris, Chrysanthos E.", "sameAs": [], "familyName": "Gounaris", "additionalName": "E.", "givenName": "Chrysanthos", "email": ""}, {"name": "Rajendran, Karthikeyan", "sameAs": [], "familyName": "Rajendran", "additionalName": "", "givenName": "Karthikeyan", "email": ""}, {"name": "Kevrekidis, Ioannis G.", "sameAs": [], "familyName": "Kevrekidis", "additionalName": "G.", "givenName": "Ioannis", "email": ""}, {"name": "Floudas, Christodoulos A.", "sameAs": [], "familyName": "Floudas", "additionalName": "A.", "givenName": "Christodoulos", "email": ""}], "title": "Designing Networks: A Mixed-Integer Linear Optimization Approach", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.00362", "oai:arXiv.org:1502.00362"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Designing networks with specified collective properties is useful in a\nvariety of application areas, enabling the study of how given properties affect\nthe behavior of network models, the downscaling of empirical networks to\nworkable sizes, and the analysis of network evolution. Despite the importance\nof the task, there currently exists a gap in our ability to systematically\ngenerate networks that adhere to theoretical guarantees for the given property\nspecifications. In this paper, we propose the use of Mixed-Integer Linear\nOptimization modeling and solution methodologies to address this Network\nGeneration Problem. We present a number of useful modeling techniques and apply\nthem to mathematically express and constrain network properties in the context\nof an optimization formulation. We then develop complete formulations for the\ngeneration of networks that attain specified levels of connectivity, spread,\nassortativity and robustness, and we illustrate these via a number of\ncomputational case studies.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.00362"}}, {"publisher": {"name": ""}, "description": "  Rational relations are binary relations of finite words that are realised by\nnon-deterministic finite state transducers (NFT). A particular kind of rational\nrelations is the sequential functions. Sequential functions are the functions\nthat can be realised by input-deterministic transducers. Some rational\nfunctions are not sequential. However, based on a property on transducers\ncalled the twinning property, it is decidable in PTime whether a rational\nfunction given by an NFT is sequential. In this paper, we investigate the\ngeneralisation of this result to multi-sequential relations, i.e. relations\nthat are equal to a finite union of sequential functions. We show that given an\nNFT, it is decidable in PTime whether the relation it defines is\nmulti-sequential, based on a property called the weak twinning property. If the\nweak twinning property is satisfied, we give a procedure that effectively\nconstructs a finite set of input-deterministic transducers whose union defines\nthe relation. This procedure generalises to arbitrary NFT the determinisation\nprocedure of functional NFT.\n", "contributors": [{"name": "Jecker, Isma\u00ebl", "sameAs": [], "familyName": "Jecker", "additionalName": "", "givenName": "Isma\u00ebl", "email": ""}, {"name": "Filiot, Emmanuel", "sameAs": [], "familyName": "Filiot", "additionalName": "", "givenName": "Emmanuel", "email": ""}], "title": "Multi-Sequential Word Relations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03864", "oai:arXiv.org:1504.03864"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Rational relations are binary relations of finite words that are realised by\nnon-deterministic finite state transducers (NFT). A particular kind of rational\nrelations is the sequential functions. Sequential functions are the functions\nthat can be realised by input-deterministic transducers. Some rational\nfunctions are not sequential. However, based on a property on transducers\ncalled the twinning property, it is decidable in PTime whether a rational\nfunction given by an NFT is sequential. In this paper, we investigate the\ngeneralisation of this result to multi-sequential relations, i.e. relations\nthat are equal to a finite union of sequential functions. We show that given an\nNFT, it is decidable in PTime whether the relation it defines is\nmulti-sequential, based on a property called the weak twinning property. If the\nweak twinning property is satisfied, we give a procedure that effectively\nconstructs a finite set of input-deterministic transducers whose union defines\nthe relation. This procedure generalises to arbitrary NFT the determinisation\nprocedure of functional NFT.\n", "Comment: 23 pages"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2015-04-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03864"}}, {"publisher": {"name": ""}, "description": "  A system is AG EF terminating, if and only if from every reachable state, a\nterminal state is reachable. This publication argues that it is beneficial for\nboth catching non-progress errors and stubborn set state space reduction to try\nto make verification models AG EF terminating. An incorrect mutual exclusion\nalgorithm is used as an example. The error does not manifest itself, unless the\nfirst action of the customers is modelled differently from other actions. An\nappropriate method is to add an alternative first action that models the\ncustomer stopping for good. This method typically makes the model AG EF\nterminating. If the model is AG EF terminating, then the basic strong stubborn\nset method preserves safety and some progress properties without any additional\ncondition for solving the ignoring problem. Furthermore, whether the model is\nAG EF terminating can be checked efficiently from the reduced state space.\n", "contributors": [{"name": "Valmari, Antti", "sameAs": [], "familyName": "Valmari", "additionalName": "", "givenName": "Antti", "email": ""}], "title": "Stop It, and Be Stubborn!", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.02587", "oai:arXiv.org:1504.02587"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  A system is AG EF terminating, if and only if from every reachable state, a\nterminal state is reachable. This publication argues that it is beneficial for\nboth catching non-progress errors and stubborn set state space reduction to try\nto make verification models AG EF terminating. An incorrect mutual exclusion\nalgorithm is used as an example. The error does not manifest itself, unless the\nfirst action of the customers is modelled differently from other actions. An\nappropriate method is to add an alternative first action that models the\ncustomer stopping for good. This method typically makes the model AG EF\nterminating. If the model is AG EF terminating, then the basic strong stubborn\nset method preserves safety and some progress properties without any additional\ncondition for solving the ignoring problem. Furthermore, whether the model is\nAG EF terminating can be checked efficiently from the reduced state space.\n"}}], "languages": [null], "subjects": ["computer science - logic in computer science", "f.3.1", "d.2.4", "68n30", "68q60", "68q85"], "providerUpdatedDateTime": "2015-04-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.02587"}}, {"publisher": {"name": ""}, "description": "  In this paper, we study the sensitivity of the spectral clustering based\ncommunity detection algorithm subject to a Erdos-Renyi type random noise model.\nWe prove phase transitions in community detectability as a function of the\nexternal edge connection probability and the noisy edge presence probability\nunder a general network model where two arbitrarily connected communities are\ninterconnected by random external edges. Specifically, the community detection\nperformance transitions from almost perfect detectability to low detectability\nas the inter-community edge connection probability exceeds some critical value.\nWe derive upper and lower bounds on the critical value and show that the bounds\nare identical when the two communities have the same size. The phase transition\nresults are validated using network simulations. Using the derived expressions\nfor the phase transition threshold we propose a method for estimating this\nthreshold from observed data.\n", "contributors": [{"name": "Chen, Pin-Yu", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Pin-Yu", "email": ""}, {"name": "Hero III, Alfred O.", "sameAs": [], "familyName": "Hero", "additionalName": "O.", "givenName": "Alfred", "email": ""}], "title": "Phase Transitions in Spectral Community Detection of Large Noisy\n  Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-04-09", "2015-04-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.02412", "oai:arXiv.org:1504.02412"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics", "stat"]}}, {"name": "description", "properties": {"description": ["  In this paper, we study the sensitivity of the spectral clustering based\ncommunity detection algorithm subject to a Erdos-Renyi type random noise model.\nWe prove phase transitions in community detectability as a function of the\nexternal edge connection probability and the noisy edge presence probability\nunder a general network model where two arbitrarily connected communities are\ninterconnected by random external edges. Specifically, the community detection\nperformance transitions from almost perfect detectability to low detectability\nas the inter-community edge connection probability exceeds some critical value.\nWe derive upper and lower bounds on the critical value and show that the bounds\nare identical when the two communities have the same size. The phase transition\nresults are validated using network simulations. Using the derived expressions\nfor the phase transition threshold we propose a method for estimating this\nthreshold from observed data.\n", "Comment: conference paper at IEEE ICASSP 2015"]}}], "languages": [null], "subjects": ["statistics and probability", "physics - data analysis", "physics - physics and society", "statistics - machine learning", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.02412"}}, {"publisher": {"name": ""}, "description": "  In a K-user Gaussian interference channel, it has been shown by Geng et al.\nthat if for each user the desired signal strength is no less than the sum of\nthe strengths of the strongest interference from this user and the strongest\ninterference to this user (all values in dB scale), then power control and\ntreating interference as noise (TIN) is optimal from the perspective of\ngeneralized degrees of freedom (GDoF) and achieves the entire channel capacity\nregion to within a constant gap. In this work, we generalize the optimality of\nTIN to compound networks. We show that for a K-user compound Gaussian\ninterference channel, if in every possible state for each receiver, the channel\nalways satisfies the TIN-optimality condition identified by Geng et al., then\nthe GDoF region of the compound channel is the intersection of the GDoF regions\nof all possible network realizations, which is achievable by power control and\nTIN. Furthermore, we demonstrate that for a general K-user compound\ninterference channel, regardless of the number of states of each receiver, we\ncan always construct a counterpart K-user regular interference channel that has\nthe same TIN region as the original compound channel. The regular interference\nchannel has only one state for each receiver, which may be different from all\nof the original states. Solving the GDoF-based power control problem for the\ncompound channel is equivalent to solving the same problem in its regular\ncounterpart. Exploring the power control problem further we develop a\ncentralized power control scheme for K-user compound interference channels, to\nachieve all the Pareto optimal GDoF tuples. Finally, based on this scheme, we\ndevise an iterative power control algorithm which requires at most K updates to\nobtain the globally optimal power allocation for any feasible GDoF tuple.\n", "contributors": [{"name": "Geng, Chunhua", "sameAs": [], "familyName": "Geng", "additionalName": "", "givenName": "Chunhua", "email": ""}, {"name": "Jafar, Syed A.", "sameAs": [], "familyName": "Jafar", "additionalName": "A.", "givenName": "Syed", "email": ""}], "title": "On the Optimality of Treating Interference as Noise: Compound\n  Interference Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2711", "oai:arXiv.org:1412.2711"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In a K-user Gaussian interference channel, it has been shown by Geng et al.\nthat if for each user the desired signal strength is no less than the sum of\nthe strengths of the strongest interference from this user and the strongest\ninterference to this user (all values in dB scale), then power control and\ntreating interference as noise (TIN) is optimal from the perspective of\ngeneralized degrees of freedom (GDoF) and achieves the entire channel capacity\nregion to within a constant gap. In this work, we generalize the optimality of\nTIN to compound networks. We show that for a K-user compound Gaussian\ninterference channel, if in every possible state for each receiver, the channel\nalways satisfies the TIN-optimality condition identified by Geng et al., then\nthe GDoF region of the compound channel is the intersection of the GDoF regions\nof all possible network realizations, which is achievable by power control and\nTIN. Furthermore, we demonstrate that for a general K-user compound\ninterference channel, regardless of the number of states of each receiver, we\ncan always construct a counterpart K-user regular interference channel that has\nthe same TIN region as the original compound channel. The regular interference\nchannel has only one state for each receiver, which may be different from all\nof the original states. Solving the GDoF-based power control problem for the\ncompound channel is equivalent to solving the same problem in its regular\ncounterpart. Exploring the power control problem further we develop a\ncentralized power control scheme for K-user compound interference channels, to\nachieve all the Pareto optimal GDoF tuples. Finally, based on this scheme, we\ndevise an iterative power control algorithm which requires at most K updates to\nobtain the globally optimal power allocation for any feasible GDoF tuple.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2711"}}, {"publisher": {"name": ""}, "description": "  We determine all pairs $(f,g)$ of meromorphic functions that share four pairs\nof values $(a_\\nu,b_\\nu)$, $1\\le\\nu\\le 4$, and a fifth pair $(a_5,b_5)$ under\nsome mild additional condition.\n", "contributors": [{"name": "Steinmetz, Norbert", "sameAs": [], "familyName": "Steinmetz", "additionalName": "", "givenName": "Norbert", "email": ""}], "title": "Remark on meromorphic functions that share five pairs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7199", "oai:arXiv.org:1411.7199"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  We determine all pairs $(f,g)$ of meromorphic functions that share four pairs\nof values $(a_\\nu,b_\\nu)$, $1\\le\\nu\\le 4$, and a fifth pair $(a_5,b_5)$ under\nsome mild additional condition.\n"}}], "languages": [null], "subjects": ["30d35", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7199"}}, {"publisher": {"name": ""}, "description": "  In our basic model, we study a stationary Poisson pattern of nodes on a line\nembedded in an independent planar Poisson field of interfering nodes. Assuming\nslotted Aloha and the signal-to-interference-and-noise ratio capture condition,\nwith the usual power-law path loss model and Rayleigh fading, we explicitly\nevaluate several local and end-to-end performance characteristics related to\nthe nearest-neighbor packet relaying on this line, and study their dependence\non the model parameters (the density of relaying and interfering nodes, Aloha\ntuning and the external noise power). Our model can be applied in two cases:\nthe first use is for vehicular ad-hoc networks, where vehicles are randomly\nlocated on a straight road. The second use is to study a typical route traced\nin a (general) planar ad-hoc network by some routing mechanism. The approach we\nhave chosen allows us to quantify the non-efficiency of long-distance routing\nin pure ad-hoc networks and evaluate a possible remedy for it in the form of\nadditional fixed relaying nodes, called road-side units in a vehicular network.\nIt also allows us to consider a more general field of interfering nodes and\nstudy the impact of the clustering of its nodes the routing performance. As a\nspecial case of a field with more clustering than the Poison field, we consider\na Poisson-line field of interfering nodes, in which all the nodes are randomly\nlocated on random straight lines. The comparison to our basic model reveals a\nparadox: clustering of interfering nodes decreases the outage probability of a\nsingle (typical) transmission on the route, but increases the mean end-to-end\ndelay.\n", "contributors": [{"name": "Blaszczyszyn, Bartlomiej", "sameAs": [], "familyName": "Blaszczyszyn", "additionalName": "", "givenName": "Bartlomiej", "email": ""}, {"name": "Muhlethaler, Paul", "sameAs": [], "familyName": "Muhlethaler", "additionalName": "", "givenName": "Paul", "email": ""}], "title": "Random linear multihop relaying in a general field of interferers using\n  spatial Aloha", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-07-31", "2015-03-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1207.7219", "oai:arXiv.org:1207.7219"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In our basic model, we study a stationary Poisson pattern of nodes on a line\nembedded in an independent planar Poisson field of interfering nodes. Assuming\nslotted Aloha and the signal-to-interference-and-noise ratio capture condition,\nwith the usual power-law path loss model and Rayleigh fading, we explicitly\nevaluate several local and end-to-end performance characteristics related to\nthe nearest-neighbor packet relaying on this line, and study their dependence\non the model parameters (the density of relaying and interfering nodes, Aloha\ntuning and the external noise power). Our model can be applied in two cases:\nthe first use is for vehicular ad-hoc networks, where vehicles are randomly\nlocated on a straight road. The second use is to study a typical route traced\nin a (general) planar ad-hoc network by some routing mechanism. The approach we\nhave chosen allows us to quantify the non-efficiency of long-distance routing\nin pure ad-hoc networks and evaluate a possible remedy for it in the form of\nadditional fixed relaying nodes, called road-side units in a vehicular network.\nIt also allows us to consider a more general field of interfering nodes and\nstudy the impact of the clustering of its nodes the routing performance. As a\nspecial case of a field with more clustering than the Poison field, we consider\na Poisson-line field of interfering nodes, in which all the nodes are randomly\nlocated on random straight lines. The comparison to our basic model reveals a\nparadox: clustering of interfering nodes decreases the outage probability of a\nsingle (typical) transmission on the route, but increases the mean end-to-end\ndelay.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "mathematics - probability"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1207.7219"}}, {"publisher": {"name": ""}, "description": "  Motivated by communication through a network employing linear network coding,\ncapacities of linear operator channels (LOCs) with arbitrarily distributed\ntransfer matrices over finite fields are studied. Both the Shannon capacity $C$\nand the subspace coding capacity $C_{\\text{SS}}$ are analyzed. By establishing\nand comparing lower bounds on $C$ and upper bounds on $C_{\\text{SS}}$, various\nnecessary conditions and sufficient conditions such that $C=C_{\\text{SS}}$ are\nobtained. A new class of LOCs such that $C=C_{\\text{SS}}$ is identified, which\nincludes LOCs with uniform-given-rank transfer matrices as special cases. It is\nalso demonstrated that $C_{\\text{SS}}$ is strictly less than $C$ for a broad\nclass of LOCs. In general, an optimal subspace coding scheme is difficult to\nfind because it requires to solve the maximization of a non-concave function.\nHowever, for a LOC with a unique subspace degradation, $C_{\\text{SS}}$ can be\nobtained by solving a convex optimization problem over rank distribution.\nClasses of LOCs with a unique subspace degradation are characterized. Since\nLOCs with uniform-given-rank transfer matrices have unique subspace\ndegradations, some existing results on LOCs with uniform-given-rank transfer\nmatrices are explained from a more general way.\n", "contributors": [{"name": "Yang, Shenghao", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Shenghao", "email": ""}, {"name": "Ho, Siu-Wai", "sameAs": [], "familyName": "Ho", "additionalName": "", "givenName": "Siu-Wai", "email": ""}, {"name": "Meng, Jin", "sameAs": [], "familyName": "Meng", "additionalName": "", "givenName": "Jin", "email": ""}, {"name": "Yeung, En-hui", "sameAs": [], "familyName": "Yeung", "additionalName": "", "givenName": "En-hui", "email": ""}], "title": "Capacity Analysis of Linear Operator Channels over Finite Fields", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-08-22", "2014-02-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1108.4257", "Information Theory, IEEE Transactions on , vol.60, no.8,\n  pp.4880-4901, Aug. 2014", "doi:10.1109/TIT.2013.2262454", "oai:arXiv.org:1108.4257"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Motivated by communication through a network employing linear network coding,\ncapacities of linear operator channels (LOCs) with arbitrarily distributed\ntransfer matrices over finite fields are studied. Both the Shannon capacity $C$\nand the subspace coding capacity $C_{\\text{SS}}$ are analyzed. By establishing\nand comparing lower bounds on $C$ and upper bounds on $C_{\\text{SS}}$, various\nnecessary conditions and sufficient conditions such that $C=C_{\\text{SS}}$ are\nobtained. A new class of LOCs such that $C=C_{\\text{SS}}$ is identified, which\nincludes LOCs with uniform-given-rank transfer matrices as special cases. It is\nalso demonstrated that $C_{\\text{SS}}$ is strictly less than $C$ for a broad\nclass of LOCs. In general, an optimal subspace coding scheme is difficult to\nfind because it requires to solve the maximization of a non-concave function.\nHowever, for a LOC with a unique subspace degradation, $C_{\\text{SS}}$ can be\nobtained by solving a convex optimization problem over rank distribution.\nClasses of LOCs with a unique subspace degradation are characterized. Since\nLOCs with uniform-given-rank transfer matrices have unique subspace\ndegradations, some existing results on LOCs with uniform-given-rank transfer\nmatrices are explained from a more general way.\n", "Comment: To appear in IEEE Transactions on Information Theory"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1108.4257"}}, {"publisher": {"name": ""}, "description": "  Multi-agent geographical models integrate very large numbers of spatial\ninteractions. In order to validate those models large amount of computing is\nnecessary for their simulation and calibration. Here a new data processing\nchain including an automated calibration procedure is experimented on a\ncomputational grid using evolutionary algorithms. This is applied for the first\ntime to a geographical model designed to simulate the evolution of an early\nurban settlement system. The method enables us to reduce the computing time and\nprovides robust results. Using this method, we identify several parameter\nsettings that minimise three objective functions that quantify how closely the\nmodel results match a reference pattern. As the values of each parameter in\ndifferent settings are very close, this estimation considerably reduces the\ninitial possible domain of variation of the parameters. The model is thus a\nuseful tool for further multiple applications on empirical historical\nsituations.\n", "contributors": [{"name": "Schmitt, Clara", "sameAs": [], "familyName": "Schmitt", "additionalName": "", "givenName": "Clara", "email": ""}, {"name": "Rey-Coyrehourcq, S\u00e9bastien", "sameAs": [], "familyName": "Rey-Coyrehourcq", "additionalName": "", "givenName": "S\u00e9bastien", "email": ""}, {"name": "Reuillon, Romain", "sameAs": [], "familyName": "Reuillon", "additionalName": "", "givenName": "Romain", "email": ""}, {"name": "Pumain, Denise", "sameAs": [], "familyName": "Pumain", "additionalName": "", "givenName": "Denise", "email": ""}], "title": "Half a billion simulations: evolutionary algorithms and distributed\n  computing for calibrating the SimpopLocal geographical model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06752", "doi:10.1068/b130064p", "oai:arXiv.org:1502.06752"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Multi-agent geographical models integrate very large numbers of spatial\ninteractions. In order to validate those models large amount of computing is\nnecessary for their simulation and calibration. Here a new data processing\nchain including an automated calibration procedure is experimented on a\ncomputational grid using evolutionary algorithms. This is applied for the first\ntime to a geographical model designed to simulate the evolution of an early\nurban settlement system. The method enables us to reduce the computing time and\nprovides robust results. Using this method, we identify several parameter\nsettings that minimise three objective functions that quantify how closely the\nmodel results match a reference pattern. As the values of each parameter in\ndifferent settings are very close, this estimation considerably reduces the\ninitial possible domain of variation of the parameters. The model is thus a\nuseful tool for further multiple applications on empirical historical\nsituations.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - computers and society"], "providerUpdatedDateTime": "2015-02-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06752"}}, {"publisher": {"name": ""}, "description": "  A Barker sequence is a binary sequence for which all nontrivial aperiodic\nautocorrelations are at most 1 in magnitude. An old conjecture due to Turyn\nasserts that there is no Barker sequence of length greater than 13. In 1961,\nTuryn and Storer gave an elementary, though somewhat complicated, proof that\nthis conjecture holds for odd lengths. We give a new and simpler proof of this\nresult.\n", "contributors": [{"name": "Schmidt, Kai-Uwe", "sameAs": [], "familyName": "Schmidt", "additionalName": "", "givenName": "Kai-Uwe", "email": ""}, {"name": "Willms, J\u00fcrgen", "sameAs": [], "familyName": "Willms", "additionalName": "", "givenName": "J\u00fcrgen", "email": ""}], "title": "Barker sequences of odd length", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06035", "oai:arXiv.org:1501.06035"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A Barker sequence is a binary sequence for which all nontrivial aperiodic\nautocorrelations are at most 1 in magnitude. An old conjecture due to Turyn\nasserts that there is no Barker sequence of length greater than 13. In 1961,\nTuryn and Storer gave an elementary, though somewhat complicated, proof that\nthis conjecture holds for odd lengths. We give a new and simpler proof of this\nresult.\n", "Comment: 6 pages, this note supersedes the main result of arXiv:1409.1434"]}}], "languages": [null], "subjects": ["11b83", "94a55", "computer science - information theory", "mathematics - combinatorics", "05b10"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06035"}}, {"publisher": {"name": ""}, "description": "  Multi-tier cellular communication networks constitute a promising approach to\nexpand the coverage of cellular networks and enable them to offer higher data\nrates. In this paper, an uplink two-tier communication network is studied, in\nwhich macro users, femto users and femto access points are geometrically\nlocated inside the coverage area of a macro base station according to Poisson\npoint processes. Each femtocell is assumed to have a fixed backhaul constraint\nthat puts a limit on the maximum number of femto and macro users it can\nservice. Under this backhaul constraint, the network adopts a special open\naccess policy, in which each macro user is either assigned to its closest femto\naccess point or to the macro base station, depending on the ratio between its\ndistances from those two. Under this model, upper and lower bounds on the\noutage probabilities experienced by users serviced by femto access points are\nderived as functions of the distance between the macro base station and the\nfemto access point serving them. Similarly, upper and lower bounds on the\noutage probabilities of the users serviced by the macro base station are\nobtained. The bounds in both cases are confirmed via simulation results.\n", "contributors": [{"name": "Jalali, Shirin", "sameAs": [], "familyName": "Jalali", "additionalName": "", "givenName": "Shirin", "email": ""}, {"name": "Zeinalpour-Yazdi, Zolfa", "sameAs": [], "familyName": "Zeinalpour-Yazdi", "additionalName": "", "givenName": "Zolfa", "email": ""}, {"name": "Poor, H. Vincent", "sameAs": [], "familyName": "Poor", "additionalName": "Vincent", "givenName": "H.", "email": ""}], "title": "Outage Performance of Uplink Two-tier Networks Under Backhaul\n  Constraints", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.0260", "oai:arXiv.org:1412.0260"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Multi-tier cellular communication networks constitute a promising approach to\nexpand the coverage of cellular networks and enable them to offer higher data\nrates. In this paper, an uplink two-tier communication network is studied, in\nwhich macro users, femto users and femto access points are geometrically\nlocated inside the coverage area of a macro base station according to Poisson\npoint processes. Each femtocell is assumed to have a fixed backhaul constraint\nthat puts a limit on the maximum number of femto and macro users it can\nservice. Under this backhaul constraint, the network adopts a special open\naccess policy, in which each macro user is either assigned to its closest femto\naccess point or to the macro base station, depending on the ratio between its\ndistances from those two. Under this model, upper and lower bounds on the\noutage probabilities experienced by users serviced by femto access points are\nderived as functions of the distance between the macro base station and the\nfemto access point serving them. Similarly, upper and lower bounds on the\noutage probabilities of the users serviced by the macro base station are\nobtained. The bounds in both cases are confirmed via simulation results.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.0260"}}, {"publisher": {"name": ""}, "description": "  In this article, we consider the problem of loop-back interference\nsuppression for orthogonal frequency division multiplexing (OFDM) signals in\namplify-and-forward single-frequency full-duplex relay stations. The loop-back\ninterference makes the system a closed-loop system, and hence it is important\nnot only to suppress the interference but also to stabilize the system. For\nthis purpose, we propose sampled-data $H^{\\infty}$ design of digital filters\nthat ensure the stability of the system and suppress the continuous-time effect\nof interference at the same time. Simulation results are shown to illustrate\nthe effectiveness of the proposed method.\n", "contributors": [{"name": "Sasahara, Hampei", "sameAs": [], "familyName": "Sasahara", "additionalName": "", "givenName": "Hampei", "email": ""}, {"name": "Nagahara, Masaaki", "sameAs": [], "familyName": "Nagahara", "additionalName": "", "givenName": "Masaaki", "email": ""}, {"name": "Hayashi, Kazunori", "sameAs": [], "familyName": "Hayashi", "additionalName": "", "givenName": "Kazunori", "email": ""}, {"name": "Yamamoto, Yutaka", "sameAs": [], "familyName": "Yamamoto", "additionalName": "", "givenName": "Yutaka", "email": ""}], "title": "Loop-Back Interference Suppression for OFDM Signals via Sampled-Data\n  Control", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-10", "2015-04-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3238", "oai:arXiv.org:1412.3238"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this article, we consider the problem of loop-back interference\nsuppression for orthogonal frequency division multiplexing (OFDM) signals in\namplify-and-forward single-frequency full-duplex relay stations. The loop-back\ninterference makes the system a closed-loop system, and hence it is important\nnot only to suppress the interference but also to stabilize the system. For\nthis purpose, we propose sampled-data $H^{\\infty}$ design of digital filters\nthat ensure the stability of the system and suppress the continuous-time effect\nof interference at the same time. Simulation results are shown to illustrate\nthe effectiveness of the proposed method.\n", "Comment: 10th Asian Control Conference 2015 (ASCC 2015), 2015; 4 pages, 10\n  figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "computer science - information theory"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3238"}}, {"publisher": {"name": ""}, "description": "  Tracing criminal ties and mining evidence from a large network to begin a\ncrime case analysis has been difficult for criminal investigators due to large\nnumbers of nodes and their complex relationships. In this paper, trust networks\nusing blind carbon copy (BCC) emails were formed. We show that our new shortest\npaths network search algorithm combining shortest paths and network centrality\nmeasures can isolate and identify criminals' connections within a trust\nnetwork. A group of BCC emails out of 1,887,305 Enron email transactions were\nisolated for this purpose. The algorithm uses two central nodes, most\ninfluential and middle man, to extract a shortest paths trust network.\n", "contributors": [{"name": "Magalingam, Pritheega", "sameAs": [], "familyName": "Magalingam", "additionalName": "", "givenName": "Pritheega", "email": ""}, {"name": "Rao, Asha", "sameAs": [], "familyName": "Rao", "additionalName": "", "givenName": "Asha", "email": ""}, {"name": "Davis, Stephen", "sameAs": [], "familyName": "Davis", "additionalName": "", "givenName": "Stephen", "email": ""}], "title": "Identifying a Criminal's Network of Trust", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04896", "doi:10.1109/SITIS.2014.64", "oai:arXiv.org:1503.04896"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Tracing criminal ties and mining evidence from a large network to begin a\ncrime case analysis has been difficult for criminal investigators due to large\nnumbers of nodes and their complex relationships. In this paper, trust networks\nusing blind carbon copy (BCC) emails were formed. We show that our new shortest\npaths network search algorithm combining shortest paths and network centrality\nmeasures can isolate and identify criminals' connections within a trust\nnetwork. A group of BCC emails out of 1,887,305 Enron email transactions were\nisolated for this purpose. The algorithm uses two central nodes, most\ninfluential and middle man, to extract a shortest paths trust network.\n", "Comment: 2014 Tenth International Conference on Signal-Image Technology &\n  Internet-Based Systems (Presented at Third International Workshop on Complex\n  Networks and their Applications,SITIS 2014, Marrakesh, Morocco, 23-27,\n  November 2014)"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04896"}}, {"publisher": {"name": ""}, "description": "  We define a new topological summary for data that we call the persistence\nlandscape. Since this summary lies in a vector space, it is easy to combine\nwith tools from statistics and machine learning, in contrast to the standard\ntopological summaries. Viewed as a random variable with values in a Banach\nspace, this summary obeys a strong law of large numbers and a central limit\ntheorem. We show how a number of standard statistical tests can be used for\nstatistical inference using this summary. We also prove that this summary is\nstable and that it can be used to provide lower bounds for the bottleneck and\nWasserstein distances.\n", "contributors": [{"name": "Bubenik, Peter", "sameAs": [], "familyName": "Bubenik", "additionalName": "", "givenName": "Peter", "email": ""}], "title": "Statistical topological data analysis using persistence landscapes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-07-26", "2015-01-23"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1207.6437", "oai:arXiv.org:1207.6437"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  We define a new topological summary for data that we call the persistence\nlandscape. Since this summary lies in a vector space, it is easy to combine\nwith tools from statistics and machine learning, in contrast to the standard\ntopological summaries. Viewed as a random variable with values in a Banach\nspace, this summary obeys a strong law of large numbers and a central limit\ntheorem. We show how a number of standard statistical tests can be used for\nstatistical inference using this summary. We also prove that this summary is\nstable and that it can be used to provide lower bounds for the bottleneck and\nWasserstein distances.\n", "Comment: 26 pages, final version, to appear in Journal of Machine Learning\n  Research, includes two additional examples not in the journal version: random\n  geometric complexes and Erdos-Renyi random clique complexes"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "55n99", "62g99", "54e35", "mathematics - metric geometry", "mathematics - algebraic topology", "68w30", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1207.6437"}}, {"publisher": {"name": ""}, "description": "  In this work we study the quantitative relation between VC-dimension and two\nother basic parameters related to learning and teaching. We present relatively\nefficient constructions of {\\em sample compression schemes} and {\\em teaching\nsets} for classes of low VC-dimension. Let $C$ be a finite boolean concept\nclass of VC-dimension $d$. Set $k = O(d 2^d \\log \\log |C|)$.\n  We construct sample compression schemes of size $k$ for $C$, with additional\ninformation of $k \\log(k)$ bits. Roughly speaking, given any list of\n$C$-labelled examples of arbitrary length, we can retain only $k$ labeled\nexamples in a way that allows to recover the labels of all others examples in\nthe list.\n  We also prove that there always exists a concept $c$ in $C$ with a teaching\nset (i.e. a list of $c$-labelled examples uniquely identifying $c$) of size\n$k$. Equivalently, we prove that the recursive teaching dimension of $C$ is at\nmost $k$.\n  The question of constructing sample compression schemes for classes of small\nVC-dimension was suggested by Littlestone and Warmuth (1986), and the problem\nof constructing teaching sets for classes of small VC-dimension was suggested\nby Kuhlmann (1999). Previous constructions for general concept classes yielded\nsize $O(\\log |C|)$ for both questions, even when the VC-dimension is constant.\n", "contributors": [{"name": "Moran, Shay", "sameAs": [], "familyName": "Moran", "additionalName": "", "givenName": "Shay", "email": ""}, {"name": "Shpilka, Amir", "sameAs": [], "familyName": "Shpilka", "additionalName": "", "givenName": "Amir", "email": ""}, {"name": "Wigderson, Avi", "sameAs": [], "familyName": "Wigderson", "additionalName": "", "givenName": "Avi", "email": ""}, {"name": "Yehudayoff, Amir", "sameAs": [], "familyName": "Yehudayoff", "additionalName": "", "givenName": "Amir", "email": ""}], "title": "Teaching and compressing for low VC-dimension", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06187", "oai:arXiv.org:1502.06187"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this work we study the quantitative relation between VC-dimension and two\nother basic parameters related to learning and teaching. We present relatively\nefficient constructions of {\\em sample compression schemes} and {\\em teaching\nsets} for classes of low VC-dimension. Let $C$ be a finite boolean concept\nclass of VC-dimension $d$. Set $k = O(d 2^d \\log \\log |C|)$.\n  We construct sample compression schemes of size $k$ for $C$, with additional\ninformation of $k \\log(k)$ bits. Roughly speaking, given any list of\n$C$-labelled examples of arbitrary length, we can retain only $k$ labeled\nexamples in a way that allows to recover the labels of all others examples in\nthe list.\n  We also prove that there always exists a concept $c$ in $C$ with a teaching\nset (i.e. a list of $c$-labelled examples uniquely identifying $c$) of size\n$k$. Equivalently, we prove that the recursive teaching dimension of $C$ is at\nmost $k$.\n  The question of constructing sample compression schemes for classes of small\nVC-dimension was suggested by Littlestone and Warmuth (1986), and the problem\nof constructing teaching sets for classes of small VC-dimension was suggested\nby Kuhlmann (1999). Previous constructions for general concept classes yielded\nsize $O(\\log |C|)$ for both questions, even when the VC-dimension is constant.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06187"}}, {"publisher": {"name": ""}, "description": "  Let X be a complex projective variety and D a reduced divisor on X. Under a\nnatural minimal condition on the singularities of the pair (X, D), which\nincludes the case of smooth X with simple normal crossing D, we ask for\ngeometric criteria guaranteeing various positivity conditions for the\nlog-canonical divisor K_X+D. By adjunction and running the log minimal model\nprogram, natural to our setting, we obtain a geometric criterion for K_X+D to\nbe numerically effective as well as a geometric version of the cone theorem,\ngeneralizing to the context of log pairs these results of Mori. A criterion for\nK_X+D to be pseudo-effective with mild hypothesis on D follows. We also obtain,\nassuming the abundance conjecture and the existence of rational curves on\nCalabi-Yau manifolds, an optimal geometric sharpening of the Nakai-Moishezon\ncriterion for the ampleness of a divisor of the form K_X+D, a criterion\nverified under a canonical hyperbolicity assumption on (X,D). Without these\nconjectures, we verify this ampleness criterion with assumptions on the number\nof ample and non ample components of D.\n", "contributors": [{"name": "Lu, Steven S. Y.", "sameAs": [], "familyName": "Lu", "additionalName": "S. Y.", "givenName": "Steven", "email": ""}, {"name": "Zhang, De-Qi", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "De-Qi", "email": ""}], "title": "Positivity criteria for log canonical divisors and hyperbolicity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-07-31", "2015-02-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1207.7346", "oai:arXiv.org:1207.7346"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Let X be a complex projective variety and D a reduced divisor on X. Under a\nnatural minimal condition on the singularities of the pair (X, D), which\nincludes the case of smooth X with simple normal crossing D, we ask for\ngeometric criteria guaranteeing various positivity conditions for the\nlog-canonical divisor K_X+D. By adjunction and running the log minimal model\nprogram, natural to our setting, we obtain a geometric criterion for K_X+D to\nbe numerically effective as well as a geometric version of the cone theorem,\ngeneralizing to the context of log pairs these results of Mori. A criterion for\nK_X+D to be pseudo-effective with mild hypothesis on D follows. We also obtain,\nassuming the abundance conjecture and the existence of rational curves on\nCalabi-Yau manifolds, an optimal geometric sharpening of the Nakai-Moishezon\ncriterion for the ampleness of a divisor of the form K_X+D, a criterion\nverified under a canonical hyperbolicity assumption on (X,D). Without these\nconjectures, we verify this ampleness criterion with assumptions on the number\nof ample and non ample components of D.\n", "Comment: Journal f\\\"ur die reine und angewandte Mathematik (to appear); final\n  version; this arXiv version contains the proof of Remark 4.9 (2-dimensional\n  case for dlt pairs) as Appendix"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "32q45", "14e30", "mathematics - differential geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1207.7346"}}, {"publisher": {"name": ""}, "description": "  The exact nonnegative matrix factorization (exact NMF) problem is the\nfollowing: given an $m$-by-$n$ nonnegative matrix $X$ and a factorization rank\n$r$, find, if possible, an $m$-by-$r$ nonnegative matrix $W$ and an $r$-by-$n$\nnonnegative matrix $H$ such that $X = WH$. In this paper, we propose two\nheuristics for exact NMF, one inspired from simulated annealing and the other\nfrom the greedy randomized adaptive search procedure. We show that these two\nheuristics are able to compute exact nonnegative factorizations for several\nclasses of nonnegative matrices (namely, linear Euclidean distance matrices,\nslack matrices, unique-disjointness matrices, and randomly generated matrices)\nand as such demonstrate their superiority over standard multi-start strategies.\nWe also consider a hybridization between these two heuristics that allows us to\ncombine the advantages of both methods. Finally, we discuss the use of these\nheuristics to gain insight on the behavior of the nonnegative rank, i.e., the\nminimum factorization rank such that an exact NMF exists. In particular, we\ndisprove a conjecture on the nonnegative rank of a Kronecker product, propose a\nnew upper bound on the extension complexity of generic $n$-gons and conjecture\nthe exact value of (i) the extension complexity of regular $n$-gons and (ii)\nthe nonnegative rank of a submatrix of the slack matrix of the correlation\npolytope.\n", "contributors": [{"name": "Vandaele, Arnaud", "sameAs": [], "familyName": "Vandaele", "additionalName": "", "givenName": "Arnaud", "email": ""}, {"name": "Gillis, Nicolas", "sameAs": [], "familyName": "Gillis", "additionalName": "", "givenName": "Nicolas", "email": ""}, {"name": "Glineur, Fran\u00e7ois", "sameAs": [], "familyName": "Glineur", "additionalName": "", "givenName": "Fran\u00e7ois", "email": ""}, {"name": "Tuyttens, Daniel", "sameAs": [], "familyName": "Tuyttens", "additionalName": "", "givenName": "Daniel", "email": ""}], "title": "Heuristics for Exact Nonnegative Matrix Factorization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7245", "oai:arXiv.org:1411.7245"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  The exact nonnegative matrix factorization (exact NMF) problem is the\nfollowing: given an $m$-by-$n$ nonnegative matrix $X$ and a factorization rank\n$r$, find, if possible, an $m$-by-$r$ nonnegative matrix $W$ and an $r$-by-$n$\nnonnegative matrix $H$ such that $X = WH$. In this paper, we propose two\nheuristics for exact NMF, one inspired from simulated annealing and the other\nfrom the greedy randomized adaptive search procedure. We show that these two\nheuristics are able to compute exact nonnegative factorizations for several\nclasses of nonnegative matrices (namely, linear Euclidean distance matrices,\nslack matrices, unique-disjointness matrices, and randomly generated matrices)\nand as such demonstrate their superiority over standard multi-start strategies.\nWe also consider a hybridization between these two heuristics that allows us to\ncombine the advantages of both methods. Finally, we discuss the use of these\nheuristics to gain insight on the behavior of the nonnegative rank, i.e., the\nminimum factorization rank such that an exact NMF exists. In particular, we\ndisprove a conjecture on the nonnegative rank of a Kronecker product, propose a\nnew upper bound on the extension complexity of generic $n$-gons and conjecture\nthe exact value of (i) the extension complexity of regular $n$-gons and (ii)\nthe nonnegative rank of a submatrix of the slack matrix of the correlation\npolytope.\n", "Comment: 32 pages, 2 figures, 16 tables"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - learning", "statistics - machine learning", "computer science - numerical analysis"], "providerUpdatedDateTime": "2014-11-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7245"}}, {"publisher": {"name": ""}, "description": "  While analyzing vehicular sensor data, we found that frequently occurring\nwaveforms could serve as features for further analysis, such as rule mining,\nclassification, and anomaly detection. The discovery of waveform patterns, also\nknown as time-series motifs, has been studied extensively; however, available\ntechniques for discovering frequently occurring time-series motifs were found\nlacking in either efficiency or quality: Standard subsequence clustering\nresults in poor quality, to the extent that it has even been termed\n'meaningless'. Variants of hierarchical clustering using techniques for\nefficient discovery of 'exact pair motifs' find high-quality frequent motifs,\nbut at the cost of high computational complexity, making such techniques\nunusable for our voluminous vehicular sensor data. We show that good quality\nfrequent motifs can be discovered using bounded spherical clustering of\ntime-series subsequences, which we refer to as COIN clustering, with near\nlinear complexity in time-series size. COIN clustering addresses many of the\nchallenges that previously led to subsequence clustering being viewed as\nmeaningless. We describe an end-to-end motif-discovery procedure using a\nsequence of pre and post-processing techniques that remove trivial-matches and\nshifted-motifs, which also plagued previous subsequence-clustering approaches.\nWe demonstrate that our technique efficiently discovers frequent motifs in\nvoluminous vehicular sensor data as well as in publicly available data sets.\n", "contributors": [{"name": "Agarwal, Puneet", "sameAs": [], "familyName": "Agarwal", "additionalName": "", "givenName": "Puneet", "email": ""}, {"name": "Shroff, Gautam", "sameAs": [], "familyName": "Shroff", "additionalName": "", "givenName": "Gautam", "email": ""}, {"name": "Saikia, Sarmimala", "sameAs": [], "familyName": "Saikia", "additionalName": "", "givenName": "Sarmimala", "email": ""}, {"name": "Khan, Zaigham", "sameAs": [], "familyName": "Khan", "additionalName": "", "givenName": "Zaigham", "email": ""}], "title": "Efficiently Discovering Frequent Motifs in Large-scale Sensor Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00405", "oai:arXiv.org:1501.00405"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  While analyzing vehicular sensor data, we found that frequently occurring\nwaveforms could serve as features for further analysis, such as rule mining,\nclassification, and anomaly detection. The discovery of waveform patterns, also\nknown as time-series motifs, has been studied extensively; however, available\ntechniques for discovering frequently occurring time-series motifs were found\nlacking in either efficiency or quality: Standard subsequence clustering\nresults in poor quality, to the extent that it has even been termed\n'meaningless'. Variants of hierarchical clustering using techniques for\nefficient discovery of 'exact pair motifs' find high-quality frequent motifs,\nbut at the cost of high computational complexity, making such techniques\nunusable for our voluminous vehicular sensor data. We show that good quality\nfrequent motifs can be discovered using bounded spherical clustering of\ntime-series subsequences, which we refer to as COIN clustering, with near\nlinear complexity in time-series size. COIN clustering addresses many of the\nchallenges that previously led to subsequence clustering being viewed as\nmeaningless. We describe an end-to-end motif-discovery procedure using a\nsequence of pre and post-processing techniques that remove trivial-matches and\nshifted-motifs, which also plagued previous subsequence-clustering approaches.\nWe demonstrate that our technique efficiently discovers frequent motifs in\nvoluminous vehicular sensor data as well as in publicly available data sets.\n", "Comment: 13 pages, 8 figures, Technical Report"]}}], "languages": [null], "subjects": ["computer science - databases", "computer science - learning"], "providerUpdatedDateTime": "2015-01-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00405"}}, {"publisher": {"name": ""}, "description": "  A coloring of a graph G = (V,E) is a partition {V1, V2, . . ., Vk} of V into\nindependent sets or color classes. A vertex v Vi is a Grundy vertex if it is\nadjacent to at least one vertex in each color class Vj . A coloring is a Grundy\ncoloring if every color class contains at least one Grundy vertex, and the\nGrundy number of a graph is the maximum number of colors in a Grundy coloring.\nWe derive a natural upper bound on this parameter and show that graphs with\nsufficiently large girth achieve equality in the bound. In particular, this\ngives a linear time algorithm to determine the Grundy number of a tree.\n", "contributors": [{"name": "Mansouri, Ali", "sameAs": [], "familyName": "Mansouri", "additionalName": "", "givenName": "Ali", "email": ""}, {"name": "Bouhlel, Mohamed Salim", "sameAs": [], "familyName": "Bouhlel", "additionalName": "Salim", "givenName": "Mohamed", "email": ""}], "title": "A linear algorithm for the grundy number of a tree", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-06-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.0196", "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 6, No 1, February 2014", "doi:10.5121/ijcsit.2014.6112", "oai:arXiv.org:1406.0196"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  A coloring of a graph G = (V,E) is a partition {V1, V2, . . ., Vk} of V into\nindependent sets or color classes. A vertex v Vi is a Grundy vertex if it is\nadjacent to at least one vertex in each color class Vj . A coloring is a Grundy\ncoloring if every color class contains at least one Grundy vertex, and the\nGrundy number of a graph is the maximum number of colors in a Grundy coloring.\nWe derive a natural upper bound on this parameter and show that graphs with\nsufficiently large girth achieve equality in the bound. In particular, this\ngives a linear time algorithm to determine the Grundy number of a tree.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-02-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.0196"}}, {"publisher": {"name": ""}, "description": "  In this paper we study the motion of a fluid with several dispersed particles\nwhose concentration is very small (smaller than $10^{-3}$), with possible\napplications to problems coming from geophysics, meteorology, and oceanography.\nWe consider a very dilute suspension of heavy particles in a\nquasi-incompressible fluid (low Mach number). In our case the Stokes number is\nsmall and --as pointed out in the theory of multiphase turbulence-- we can use\nan Eulerian model instead of a Lagrangian one. The assumption of low\nconcentration allows us to disregard particle--particle interactions, but we\ntake into account the effect of particles on the fluid (two-way coupling). In\nthis way we can study the physical effect of particle inertia (and not only\npassive tracers), with a model similar to the Boussinesq equations. The\nresulting model is used in both direct numerical simulations and large eddy\nsimulations of a dam-break (lock-exchange) problem, which is a well-known\nacademic test case. Keywords: Dilute suspensions, Eulerian models, direct and\nlarge eddy simulations, slightly compressible flows, dam-break (lock-exchange)\nproblem.\n", "contributors": [{"name": "Berselli, Luigi Carlo", "sameAs": [], "familyName": "Berselli", "additionalName": "Carlo", "givenName": "Luigi", "email": ""}, {"name": "Cerminara, Matteo", "sameAs": [], "familyName": "Cerminara", "additionalName": "", "givenName": "Matteo", "email": ""}, {"name": "Iliescu, Traian", "sameAs": [], "familyName": "Iliescu", "additionalName": "", "givenName": "Traian", "email": ""}], "title": "Disperse two-phase flows, with applications to geophysical problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-03-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.5448", "doi:10.1007/s00024-014-0889-5", "oai:arXiv.org:1403.5448"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  In this paper we study the motion of a fluid with several dispersed particles\nwhose concentration is very small (smaller than $10^{-3}$), with possible\napplications to problems coming from geophysics, meteorology, and oceanography.\nWe consider a very dilute suspension of heavy particles in a\nquasi-incompressible fluid (low Mach number). In our case the Stokes number is\nsmall and --as pointed out in the theory of multiphase turbulence-- we can use\nan Eulerian model instead of a Lagrangian one. The assumption of low\nconcentration allows us to disregard particle--particle interactions, but we\ntake into account the effect of particles on the fluid (two-way coupling). In\nthis way we can study the physical effect of particle inertia (and not only\npassive tracers), with a model similar to the Boussinesq equations. The\nresulting model is used in both direct numerical simulations and large eddy\nsimulations of a dam-break (lock-exchange) problem, which is a well-known\nacademic test case. Keywords: Dilute suspensions, Eulerian models, direct and\nlarge eddy simulations, slightly compressible flows, dam-break (lock-exchange)\nproblem.\n", "Comment: 28 pages, 7 figures"]}}], "languages": [null], "subjects": ["physics - geophysics", "86a04", "physics - fluid dynamics", "primary: 76t15", "physics - computational physics", "35q35", "physics - atmospheric and oceanic physics", "mathematics - analysis of pdes", "secondary: 86-08"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.5448"}}, {"publisher": {"name": ""}, "description": "  This paper defines a new problem, The Dead Cryptographers Society Problem -\nDCS (where several great cryptographers created many polynomial-time\nDeterministic Turing Machines (DTMs), ran them on their proper descriptions\nconcatenated with some arbitrary strings, deleted them and leaved only the\nresults from those running, after they dyed: if those DTMs only permute the\nbits on input, is it possible to decide the language formed by such resulting\nstrings within polynomial time?), proves some facts about its computational\ncomplexity, and discusses some possible uses on Cryptography, such as into\ndistance keys distribution, online reverse auction and secure communication.\n", "contributors": [{"name": "Barbosa, Andr\u00e9 Luiz", "sameAs": [], "familyName": "Barbosa", "additionalName": "Luiz", "givenName": "Andr\u00e9", "email": ""}], "title": "The Dead Cryptographers Society Problem", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.03872", "oai:arXiv.org:1501.03872"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper defines a new problem, The Dead Cryptographers Society Problem -\nDCS (where several great cryptographers created many polynomial-time\nDeterministic Turing Machines (DTMs), ran them on their proper descriptions\nconcatenated with some arbitrary strings, deleted them and leaved only the\nresults from those running, after they dyed: if those DTMs only permute the\nbits on input, is it possible to decide the language formed by such resulting\nstrings within polynomial time?), proves some facts about its computational\ncomplexity, and discusses some possible uses on Cryptography, such as into\ndistance keys distribution, online reverse auction and secure communication.\n", "Comment: 4 pages and some new ideas on Cryptography!"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "primary 94a60", "secondary 94a62", "computer science - cryptography and security"], "providerUpdatedDateTime": "2015-01-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.03872"}}, {"publisher": {"name": ""}, "description": "  Evaluating the performance of researchers and measuring the impact of papers\nwritten by scientists is the main objective of citation analysis. Various\nindices and metrics have been proposed for this. In this paper, we propose a\nnew citation index CITEX, which gives normalized scores to authors and papers\nto determine their rankings. To the best of our knowledge, this is the first\ncitation index which simultaneously assigns scores to both authors and papers.\nUsing these scores, we can get an objective measure of the reputation of an\nauthor and the impact of a paper.\n  We model this problem as an iterative computation on a publication graph,\nwhose vertices are authors and papers, and whose edges indicate which author\nhas written which paper. We prove that this iterative computation converges in\nthe limit, by using a powerful theorem from linear algebra. We run this\nalgorithm on several examples, and find that the author and paper scores match\nclosely with what is suggested by our intuition. The algorithm is theoretically\nsound and runs very fast in practice. We compare this index with several\nexisting metrics and find that CITEX gives far more accurate scores compared to\nthe traditional metrics.\n", "contributors": [{"name": "Pal, Arindam", "sameAs": [], "familyName": "Pal", "additionalName": "", "givenName": "Arindam", "email": ""}, {"name": "Ruj, Sushmita", "sameAs": [], "familyName": "Ruj", "additionalName": "", "givenName": "Sushmita", "email": ""}], "title": "CITEX: A new citation index to measure the relative importance of\n  authors and papers in scientific publications", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04894", "oai:arXiv.org:1501.04894"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Evaluating the performance of researchers and measuring the impact of papers\nwritten by scientists is the main objective of citation analysis. Various\nindices and metrics have been proposed for this. In this paper, we propose a\nnew citation index CITEX, which gives normalized scores to authors and papers\nto determine their rankings. To the best of our knowledge, this is the first\ncitation index which simultaneously assigns scores to both authors and papers.\nUsing these scores, we can get an objective measure of the reputation of an\nauthor and the impact of a paper.\n  We model this problem as an iterative computation on a publication graph,\nwhose vertices are authors and papers, and whose edges indicate which author\nhas written which paper. We prove that this iterative computation converges in\nthe limit, by using a powerful theorem from linear algebra. We run this\nalgorithm on several examples, and find that the author and paper scores match\nclosely with what is suggested by our intuition. The algorithm is theoretically\nsound and runs very fast in practice. We compare this index with several\nexisting metrics and find that CITEX gives far more accurate scores compared to\nthe traditional metrics.\n", "Comment: Accepted for publication in IEEE International Conference on\n  Communications (ICC) 2015"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - digital libraries", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04894"}}, {"publisher": {"name": ""}, "description": "  The capacity of a learning machine is measured by its Vapnik-Chervonenkis\ndimension, and learning machines with a low VC dimension generalize better. It\nis well known that the VC dimension of SVMs can be very large or unbounded,\neven though they generally yield state-of-the-art learning performance. In this\npaper, we show how to learn a hyperplane regressor by minimizing an exact, or\n\\boldmath{$\\Theta$} bound on its VC dimension. The proposed approach, termed as\nthe Minimal Complexity Machine (MCM) Regressor, involves solving a simple\nlinear programming problem. Experimental results show, that on a number of\nbenchmark datasets, the proposed approach yields regressors with error rates\nmuch less than those obtained with conventional SVM regresssors, while often\nusing fewer support vectors. On some benchmark datasets, the number of support\nvectors is less than one tenth the number used by SVMs, indicating that the MCM\ndoes indeed learn simpler representations.\n", "contributors": [{"name": "Jayadeva", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Jayadeva", "email": ""}, {"name": "Chandra, Suresh", "sameAs": [], "familyName": "Chandra", "additionalName": "", "givenName": "Suresh", "email": ""}, {"name": "Sabharwal, Siddarth", "sameAs": [], "familyName": "Sabharwal", "additionalName": "", "givenName": "Siddarth", "email": ""}, {"name": "Batra, Sanjit S.", "sameAs": [], "familyName": "Batra", "additionalName": "S.", "givenName": "Sanjit", "email": ""}], "title": "Learning a hyperplane regressor by minimizing an exact bound on the VC\n  dimension", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4573", "oai:arXiv.org:1410.4573"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The capacity of a learning machine is measured by its Vapnik-Chervonenkis\ndimension, and learning machines with a low VC dimension generalize better. It\nis well known that the VC dimension of SVMs can be very large or unbounded,\neven though they generally yield state-of-the-art learning performance. In this\npaper, we show how to learn a hyperplane regressor by minimizing an exact, or\n\\boldmath{$\\Theta$} bound on its VC dimension. The proposed approach, termed as\nthe Minimal Complexity Machine (MCM) Regressor, involves solving a simple\nlinear programming problem. Experimental results show, that on a number of\nbenchmark datasets, the proposed approach yields regressors with error rates\nmuch less than those obtained with conventional SVM regresssors, while often\nusing fewer support vectors. On some benchmark datasets, the number of support\nvectors is less than one tenth the number used by SVMs, indicating that the MCM\ndoes indeed learn simpler representations.\n", "Comment: see\n  http://www.sciencedirect.com/science/article/pii/S0925231214010194 or\n  arXiv:1408.2803 for background information"]}}], "languages": [null], "subjects": ["i.5.1", "computer science - learning", "i.5.2", "68t10", "68t05", "68q32"], "providerUpdatedDateTime": "2014-10-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4573"}}, {"publisher": {"name": ""}, "description": "  Xampling generalizes compressed sensing (CS) to reduced-rate sampling of\nanalog signals. A unified framework is introduced for low rate sampling and\nprocessing of signals lying in a union of subspaces. Xampling consists of two\nmain blocks: Analog compression that narrows down the input bandwidth prior to\nsampling with commercial devices followed by a nonlinear algorithm that detects\nthe input subspace prior to conventional signal processing. A variety of analog\nCS applications are reviewed within the unified Xampling framework including a\ngeneral filter-bank scheme for sparse shift-invariant spaces, periodic\nnonuniform sampling and modulated wideband conversion for multiband\ncommunications with unknown carrier frequencies, acquisition techniques for\nfinite rate of innovation signals with applications to medical and radar\nimaging, and random demodulation of sparse harmonic tones. A hardware-oriented\nviewpoint is advocated throughout, addressing practical constraints and\nexemplifying hardware realizations where relevant. It will appear as a chapter\nin a book on \"Compressed Sensing: Theory and Applications\" edited by Yonina\nEldar and Gitta Kutyniok.\n", "contributors": [{"name": "Mishali, Moshe", "sameAs": [], "familyName": "Mishali", "additionalName": "", "givenName": "Moshe", "email": ""}, {"name": "Eldar, Yonina C.", "sameAs": [], "familyName": "Eldar", "additionalName": "C.", "givenName": "Yonina", "email": ""}], "title": "Xampling: Compressed Sensing of Analog Signals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-03-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1103.2960", "in: \"Compressed Sensing: Theory and Applications\", Cambridge\n  University Press, 2011", "oai:arXiv.org:1103.2960"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Xampling generalizes compressed sensing (CS) to reduced-rate sampling of\nanalog signals. A unified framework is introduced for low rate sampling and\nprocessing of signals lying in a union of subspaces. Xampling consists of two\nmain blocks: Analog compression that narrows down the input bandwidth prior to\nsampling with commercial devices followed by a nonlinear algorithm that detects\nthe input subspace prior to conventional signal processing. A variety of analog\nCS applications are reviewed within the unified Xampling framework including a\ngeneral filter-bank scheme for sparse shift-invariant spaces, periodic\nnonuniform sampling and modulated wideband conversion for multiband\ncommunications with unknown carrier frequencies, acquisition techniques for\nfinite rate of innovation signals with applications to medical and radar\nimaging, and random demodulation of sparse harmonic tones. A hardware-oriented\nviewpoint is advocated throughout, addressing practical constraints and\nexemplifying hardware realizations where relevant. It will appear as a chapter\nin a book on \"Compressed Sensing: Theory and Applications\" edited by Yonina\nEldar and Gitta Kutyniok.\n", "Comment: 58 pages, 26 figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1103.2960"}}, {"publisher": {"name": ""}, "description": "  Data from Online Social Networks (OSNs) are providing analysts with an\nunprecedented access to public opinion on elections, news, movies etc. However,\ncaution must be taken to determine whether and how much of the opinion\nextracted from OSN user data is indeed reflective of the opinion of the larger\nonline population. In this work we study this issue in the context of movie\nreviews on Twitter and compare the opinion of Twitter users with that of the\nonline population of IMDb and Rotten Tomatoes. We introduce new metrics to show\nthat the Twitter users can be characteristically different from general users,\nboth in their rating and their relative preference for Oscar-nominated and\nnon-nominated movies. Additionally, we investigate whether such data can truly\npredict a movie's box-office success.\n", "contributors": [{"name": "Wong, Felix Ming Fai", "sameAs": [], "familyName": "Wong", "additionalName": "Ming Fai", "givenName": "Felix", "email": ""}, {"name": "Sen, Soumya", "sameAs": [], "familyName": "Sen", "additionalName": "", "givenName": "Soumya", "email": ""}, {"name": "Chiang, Mung", "sameAs": [], "familyName": "Chiang", "additionalName": "", "givenName": "Mung", "email": ""}], "title": "Why Watching Movie Tweets Won't Tell the Whole Story?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-03-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1203.4642", "oai:arXiv.org:1203.4642"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Data from Online Social Networks (OSNs) are providing analysts with an\nunprecedented access to public opinion on elections, news, movies etc. However,\ncaution must be taken to determine whether and how much of the opinion\nextracted from OSN user data is indeed reflective of the opinion of the larger\nonline population. In this work we study this issue in the context of movie\nreviews on Twitter and compare the opinion of Twitter users with that of the\nonline population of IMDb and Rotten Tomatoes. We introduce new metrics to show\nthat the Twitter users can be characteristically different from general users,\nboth in their rating and their relative preference for Oscar-nominated and\nnon-nominated movies. Additionally, we investigate whether such data can truly\npredict a movie's box-office success.\n", "Comment: 6 pages, 4 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "h.1.2", "h.3.1", "j.4", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1203.4642"}}, {"publisher": {"name": ""}, "description": "  We study a linear threshold agent-based model (ABM) for the spread of\npolitical revolutions on social networks using empirical network data. We\npropose new techniques for building a hierarchy of simplified ordinary\ndifferential equation (ODE) based models that aim to capture essential features\nof the ABM, including effects of the actual networks, and give insight in the\nparameter regime transitions of the ABM. We relate the ABM and the hierarchy of\nmodels to a population-level compartmental ODE model that we proposed\npreviously for the spread of political revolutions [1], which is shown to be\nmathematically consistent with the proposed ABM and provides a way to analyze\nthe global behaviour of the ABM. This consistency with the linear threshold ABM\nalso provides further justification a posteriori for the compartmental model of\n[1]. Extending concepts from epidemiological modelling, we define a basic\nreproduction number $R_0$ for the linear threshold ABM and apply it to predict\nABM behaviour on empirical networks. In small-scale numerical tests we\ninvestigate experimentally the differences in spreading behaviour that occur\nunder the linear threshold ABM model when applied to some empirical online and\noffline social networks, searching for quantitative evidence that political\nrevolutions may be facilitated by the modern online social networks of social\nmedia.\n", "contributors": [{"name": "Lang, John C.", "sameAs": [], "familyName": "Lang", "additionalName": "C.", "givenName": "John", "email": ""}, {"name": "De Sterck, Hans", "sameAs": [], "familyName": "De Sterck", "additionalName": "", "givenName": "Hans", "email": ""}], "title": "A Hierarchy of Linear Threshold Models for the Spread of Political\n  Revolutions on Social Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04091", "oai:arXiv.org:1501.04091"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  We study a linear threshold agent-based model (ABM) for the spread of\npolitical revolutions on social networks using empirical network data. We\npropose new techniques for building a hierarchy of simplified ordinary\ndifferential equation (ODE) based models that aim to capture essential features\nof the ABM, including effects of the actual networks, and give insight in the\nparameter regime transitions of the ABM. We relate the ABM and the hierarchy of\nmodels to a population-level compartmental ODE model that we proposed\npreviously for the spread of political revolutions [1], which is shown to be\nmathematically consistent with the proposed ABM and provides a way to analyze\nthe global behaviour of the ABM. This consistency with the linear threshold ABM\nalso provides further justification a posteriori for the compartmental model of\n[1]. Extending concepts from epidemiological modelling, we define a basic\nreproduction number $R_0$ for the linear threshold ABM and apply it to predict\nABM behaviour on empirical networks. In small-scale numerical tests we\ninvestigate experimentally the differences in spreading behaviour that occur\nunder the linear threshold ABM model when applied to some empirical online and\noffline social networks, searching for quantitative evidence that political\nrevolutions may be facilitated by the modern online social networks of social\nmedia.\n"}}], "languages": [null], "subjects": ["70g60", "physics - physics and society", "91d30", "91d10", "computer science - social and information networks", "37m99"], "providerUpdatedDateTime": "2015-01-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04091"}}, {"publisher": {"name": ""}, "description": "  The generalized Hamming weights (GHWs) of linear codes are fundamental\nparameters, the knowledge of which is of great interest in many applications.\nHowever, to determine the GHWs of linear codes is difficult in general. In this\npaper, we study the GHWs for a family of reducible cyclic codes and obtain the\ncomplete weight hierarchy in several cases. This is achieved by extending the\nidea of \\cite{YLFL} into higher dimension and by employing some interesting\ncombinatorial arguments. It shall be noted that these cyclic codes may have\narbitrary number of nonzeroes.\n", "contributors": [{"name": "Xiong, Maosheng", "sameAs": [], "familyName": "Xiong", "additionalName": "", "givenName": "Maosheng", "email": ""}, {"name": "Li, Shuxing", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Shuxing", "email": ""}, {"name": "Ge, Gennian", "sameAs": [], "familyName": "Ge", "additionalName": "", "givenName": "Gennian", "email": ""}], "title": "The Weight Hierarchy of Some Reducible Cyclic Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01274", "oai:arXiv.org:1504.01274"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  The generalized Hamming weights (GHWs) of linear codes are fundamental\nparameters, the knowledge of which is of great interest in many applications.\nHowever, to determine the GHWs of linear codes is difficult in general. In this\npaper, we study the GHWs for a family of reducible cyclic codes and obtain the\ncomplete weight hierarchy in several cases. This is achieved by extending the\nidea of \\cite{YLFL} into higher dimension and by employing some interesting\ncombinatorial arguments. It shall be noted that these cyclic codes may have\narbitrary number of nonzeroes.\n"}}], "languages": [null], "subjects": ["computer science - information theory", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01274"}}, {"publisher": {"name": ""}, "description": "  The paper shows that when an answer of a definite logic program contains\nsymbols not occurring in the program then a more general answer exists. Also a\nnew sufficient condition is given under which least Herbrand models exactly\ncharacterize the answers of programs. It is shown that, under a reasonable\nassumption, the sufficient condition is also necessary.\n", "contributors": [{"name": "Drabent, W\u0142odzimierz", "sameAs": [], "familyName": "Drabent", "additionalName": "", "givenName": "W\u0142odzimierz", "email": ""}], "title": "On definite program answers and least Herbrand models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03324", "oai:arXiv.org:1503.03324"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The paper shows that when an answer of a definite logic program contains\nsymbols not occurring in the program then a more general answer exists. Also a\nnew sufficient condition is given under which least Herbrand models exactly\ncharacterize the answers of programs. It is shown that, under a reasonable\nassumption, the sufficient condition is also necessary.\n", "Comment: 9 pages"]}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2015-03-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03324"}}, {"publisher": {"name": ""}, "description": "  Cloud environment is very different from traditional computing environment\nand therefore tracking the performance of cloud leverages additional\nrequirements. The movement of data in cloud is very fast. Hence, it requires\nthat resources and infrastructure available at disposal must be equally\ncompetent. Infrastructure level performance in cloud involves the performance\nof servers, network and storage which act as the heart and soul for driving the\nentire cloud business. Thus a constant improvement and enhancement of\ninfrastructure level performance is an important task that needs to be taken\ninto account. This paper proposes a framework for infrastructure performance\nenhancement in a cloud based environment. The framework is broadly divided into\nfour steps: a) Infrastructure level monitoring of usage pattern and behaviour\nof the cloud end users, b) Reporting of the monitoring activities to the cloud\nservice provider c) Cloud service provider assigns priority according to our\ndecision matrix based max-min algorithm (DMMM) d) Providing services to cloud\nusers leading to infrastructure performance enhancement. Our framework is based\non decision matrix and monitoring in cloud using our proposed decision matrix\nbased max-min algorithm, which draws its inspiration from the original min-min\nalgorithm. This algorithm makes use of decision matrix to make decisions\nregarding distribution of resources among the cloud users.\n", "contributors": [{"name": "Alam, Mansaf", "sameAs": [], "familyName": "Alam", "additionalName": "", "givenName": "Mansaf", "email": ""}, {"name": "Shakil, Kashish Ara", "sameAs": [], "familyName": "Shakil", "additionalName": "Ara", "givenName": "Kashish", "email": ""}], "title": "A Decision Matrix and Monitoring based Framework for Infrastructure\n  Performance Enhancement in A Cloud based Environment", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.8029", "oai:arXiv.org:1412.8029"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Cloud environment is very different from traditional computing environment\nand therefore tracking the performance of cloud leverages additional\nrequirements. The movement of data in cloud is very fast. Hence, it requires\nthat resources and infrastructure available at disposal must be equally\ncompetent. Infrastructure level performance in cloud involves the performance\nof servers, network and storage which act as the heart and soul for driving the\nentire cloud business. Thus a constant improvement and enhancement of\ninfrastructure level performance is an important task that needs to be taken\ninto account. This paper proposes a framework for infrastructure performance\nenhancement in a cloud based environment. The framework is broadly divided into\nfour steps: a) Infrastructure level monitoring of usage pattern and behaviour\nof the cloud end users, b) Reporting of the monitoring activities to the cloud\nservice provider c) Cloud service provider assigns priority according to our\ndecision matrix based max-min algorithm (DMMM) d) Providing services to cloud\nusers leading to infrastructure performance enhancement. Our framework is based\non decision matrix and monitoring in cloud using our proposed decision matrix\nbased max-min algorithm, which draws its inspiration from the original min-min\nalgorithm. This algorithm makes use of decision matrix to make decisions\nregarding distribution of resources among the cloud users.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.8029"}}, {"publisher": {"name": ""}, "description": "  Migrating computational intensive tasks from mobile devices to more\nresourceful cloud servers is a promising technique to increase the\ncomputational capacity of mobile devices while saving their battery energy. In\nthis paper, we consider a MIMO multicell system where multiple mobile users\n(MUs) ask for computation offloading to a common cloud server. We formulate the\noffloading problem as the joint optimization of the radio resources-the\ntransmit precoding matrices of the MUs-and the computational resources-the CPU\ncycles/second assigned by the cloud to each MU-in order to minimize the overall\nusers' energy consumption, while meeting latency constraints. The resulting\noptimization problem is nonconvex (in the objective function and constraints).\nNevertheless, in the single-user case, we are able to express the global\noptimal solution in closed form. In the more challenging multiuser scenario, we\npropose an iterative algorithm, based on a novel successive convex\napproximation technique, converging to a local optimal solution of the original\nnonconvex problem. Then, we reformulate the algorithm in a distributed and\nparallel implementation across the radio access points, requiring only a\nlimited coordination/signaling with the cloud. Numerical results show that the\nproposed schemes outperform disjoint optimization algorithms.\n", "contributors": [{"name": "Sardellitti, Stefania", "sameAs": [], "familyName": "Sardellitti", "additionalName": "", "givenName": "Stefania", "email": ""}, {"name": "Scutari, Gesualdo", "sameAs": [], "familyName": "Scutari", "additionalName": "", "givenName": "Gesualdo", "email": ""}, {"name": "Barbarossa, Sergio", "sameAs": [], "familyName": "Barbarossa", "additionalName": "", "givenName": "Sergio", "email": ""}], "title": "Joint Optimization of Radio and Computational Resources for Multicell\n  Mobile-Edge Computing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.8416", "oai:arXiv.org:1412.8416"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Migrating computational intensive tasks from mobile devices to more\nresourceful cloud servers is a promising technique to increase the\ncomputational capacity of mobile devices while saving their battery energy. In\nthis paper, we consider a MIMO multicell system where multiple mobile users\n(MUs) ask for computation offloading to a common cloud server. We formulate the\noffloading problem as the joint optimization of the radio resources-the\ntransmit precoding matrices of the MUs-and the computational resources-the CPU\ncycles/second assigned by the cloud to each MU-in order to minimize the overall\nusers' energy consumption, while meeting latency constraints. The resulting\noptimization problem is nonconvex (in the objective function and constraints).\nNevertheless, in the single-user case, we are able to express the global\noptimal solution in closed form. In the more challenging multiuser scenario, we\npropose an iterative algorithm, based on a novel successive convex\napproximation technique, converging to a local optimal solution of the original\nnonconvex problem. Then, we reformulate the algorithm in a distributed and\nparallel implementation across the radio access points, requiring only a\nlimited coordination/signaling with the cloud. Numerical results show that the\nproposed schemes outperform disjoint optimization algorithms.\n", "Comment: Paper submitted to IEEE Trans. on Signal and Information Processing\n  over Networks"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.8416"}}, {"publisher": {"name": "Bioscientifica Ltd"}, "description": "This competency framework was developed by a working group of endocrine specialist nurses with the support of the Society for Endocrinology to enhance the clinical care that adults with an endocrine disorder receive. Nurses should be able to demonstrate that they are functioning at an optimal level in order for patients to receive appropriate care. By formulating a competency framework from which an adult endocrine nurse specialist can work, it is envisaged that their development as professional practitioners can be enhanced. This is the second edition of the Competency Framework for Adult Endocrine Nursing. It introduces four new competencies on benign adrenal tumours, hypo- and hyperparathyroidism, osteoporosis and polycystic ovary syndrome. The authors and the Society for Endocrinology welcome constructive feedback on the document, both nationally and internationally, in anticipation that further developments and ideas can be incorporated into future versions.", "contributors": [{"name": "Kieffer, Veronica", "sameAs": [], "familyName": "Kieffer", "additionalName": "", "givenName": "Veronica", "email": ""}, {"name": "Davies, Kate", "sameAs": [], "familyName": "Davies", "additionalName": "", "givenName": "Kate", "email": ""}, {"name": "Gibson, Christine", "sameAs": [], "familyName": "Gibson", "additionalName": "", "givenName": "Christine", "email": ""}, {"name": "Middleton, Morag", "sameAs": [], "familyName": "Middleton", "additionalName": "", "givenName": "Morag", "email": ""}, {"name": "Munday, Jean", "sameAs": [], "familyName": "Munday", "additionalName": "", "givenName": "Jean", "email": ""}, {"name": "Shalet, Shashana", "sameAs": [], "familyName": "Shalet", "additionalName": "", "givenName": "Shashana", "email": ""}, {"name": "Shepherd, Lisa", "sameAs": [], "familyName": "Shepherd", "additionalName": "", "givenName": "Lisa", "email": ""}, {"name": "Yeoh, Phillip", "sameAs": [], "familyName": "Yeoh", "additionalName": "", "givenName": "Phillip", "email": ""}], "title": "Society for Endocrinology Competency Framework for Adult Endocrine Nursing: 2nd edition", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["competency framework"], "providerUpdatedDateTime": "2015-03-09T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4326532"}}, {"publisher": {"name": ""}, "description": "  Distributed Information SHaring (DISH) is a new cooperative approach to\ndesigning multi-channel MAC protocols. It aids nodes in their decision making\nprocesses by compensating for their missing information via information sharing\nthrough other neighboring nodes. This approach was recently shown to\nsignificantly boost the throughput of multi-channel MAC protocols. However, a\ncritical issue for ad hoc communication devices, i.e., energy efficiency, has\nyet to be addressed. In this paper, we address this issue by developing simple\nsolutions which (1) reduce the energy consumption (2) without compromising the\nthroughput performance, and meanwhile (3) maximize cost efficiency. We propose\ntwo energy-efficient strategies: in-situ energy conscious DISH which uses\nexisting nodes only, and altruistic DISH which needs additional nodes called\naltruists. We compare five protocols with respect to the strategies and\nidentify altruistic DISH to be the right choice in general: it (1) conserves\n40-80% of energy, (2) maintains the throughput advantage gained from the DISH\napproach, and (3) more than doubles the cost efficiency compared to protocols\nwithout applying the strategy. On the other hand, our study shows that in-situ\nenergy conscious DISH is suitable only in certain limited scenarios.\n", "contributors": [{"name": "Luo, Tie", "sameAs": [], "familyName": "Luo", "additionalName": "", "givenName": "Tie", "email": ""}, {"name": "Motani, Mehul", "sameAs": [], "familyName": "Motani", "additionalName": "", "givenName": "Mehul", "email": ""}, {"name": "Srinivasan, Vikram", "sameAs": [], "familyName": "Srinivasan", "additionalName": "", "givenName": "Vikram", "email": ""}], "title": "Energy-Efficient Strategies for Cooperative Multi-Channel MAC Protocols", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.6521", "IEEE Transactions on Mobile Computing (TMC), vol. 11, no. 4, pp.\n  553-566, April 2012", "doi:10.1109/TMC.2011.60", "oai:arXiv.org:1411.6521"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Distributed Information SHaring (DISH) is a new cooperative approach to\ndesigning multi-channel MAC protocols. It aids nodes in their decision making\nprocesses by compensating for their missing information via information sharing\nthrough other neighboring nodes. This approach was recently shown to\nsignificantly boost the throughput of multi-channel MAC protocols. However, a\ncritical issue for ad hoc communication devices, i.e., energy efficiency, has\nyet to be addressed. In this paper, we address this issue by developing simple\nsolutions which (1) reduce the energy consumption (2) without compromising the\nthroughput performance, and meanwhile (3) maximize cost efficiency. We propose\ntwo energy-efficient strategies: in-situ energy conscious DISH which uses\nexisting nodes only, and altruistic DISH which needs additional nodes called\naltruists. We compare five protocols with respect to the strategies and\nidentify altruistic DISH to be the right choice in general: it (1) conserves\n40-80% of energy, (2) maintains the throughput advantage gained from the DISH\napproach, and (3) more than doubles the cost efficiency compared to protocols\nwithout applying the strategy. On the other hand, our study shows that in-situ\nenergy conscious DISH is suitable only in certain limited scenarios.\n", "Comment: Energy efficiency, cost efficiency, distributed information sharing,\n  DISH, altruistic cooperation"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - performance"], "providerUpdatedDateTime": "2014-11-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.6521"}}, {"publisher": {"name": ""}, "description": "  As a robust nonlinear similarity measure in kernel space, correntropy has\nreceived increasing attention in domains of machine learning and signal\nprocessing. In particular, the maximum correntropy criterion (MCC) has recently\nbeen successfully applied in robust regression and filtering. The default\nkernel function in correntropy is the Gaussian kernel, which is, of course, not\nalways the best choice. In this work, we propose a generalized correntropy that\nadopts the generalized Gaussian density (GGD) function as the kernel (not\nnecessarily a Mercer kernel), and present some important properties. We further\npropose the generalized maximum correntropy criterion (GMCC), and apply it to\nadaptive filtering. An adaptive algorithm, called the GMCC algorithm, is\nderived, and the mean square convergence performance is studied. We show that\nthe proposed algorithm is very stable and can achieve zero probability of\ndivergence (POD). Simulation results confirm the theoretical expectations and\ndemonstrate the desirable performance of the new algorithm.\n", "contributors": [{"name": "Chen, Badong", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Badong", "email": ""}, {"name": "Xing, Lei", "sameAs": [], "familyName": "Xing", "additionalName": "", "givenName": "Lei", "email": ""}, {"name": "Zhao, Haiquan", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Haiquan", "email": ""}, {"name": "Zheng, Nanning", "sameAs": [], "familyName": "Zheng", "additionalName": "", "givenName": "Nanning", "email": ""}, {"name": "Pr\u00edncipe, Jos\u00e9 C.", "sameAs": [], "familyName": "Pr\u00edncipe", "additionalName": "C.", "givenName": "Jos\u00e9", "email": ""}], "title": "Generalized Correntropy for Robust Adaptive Filtering", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.02931", "oai:arXiv.org:1504.02931"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  As a robust nonlinear similarity measure in kernel space, correntropy has\nreceived increasing attention in domains of machine learning and signal\nprocessing. In particular, the maximum correntropy criterion (MCC) has recently\nbeen successfully applied in robust regression and filtering. The default\nkernel function in correntropy is the Gaussian kernel, which is, of course, not\nalways the best choice. In this work, we propose a generalized correntropy that\nadopts the generalized Gaussian density (GGD) function as the kernel (not\nnecessarily a Mercer kernel), and present some important properties. We further\npropose the generalized maximum correntropy criterion (GMCC), and apply it to\nadaptive filtering. An adaptive algorithm, called the GMCC algorithm, is\nderived, and the mean square convergence performance is studied. We show that\nthe proposed algorithm is very stable and can achieve zero probability of\ndivergence (POD). Simulation results confirm the theoretical expectations and\ndemonstrate the desirable performance of the new algorithm.\n", "Comment: 34 pages, 9 figures, submitted to IEEE Transactions on Signal\n  Processing"]}}], "languages": [null], "subjects": ["computer science - information theory", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.02931"}}, {"publisher": {"name": ""}, "description": "  In this note we study the greedy algorithm for combinatorial auctions with\nsubmodular bidders. It is well known that this algorithm provides an\napproximation ratio of $2$ for every order of the items. We show that if the\nvaluations are vertex cover functions and the order is random then the expected\napproximation ratio imrpoves to $\\frac 7 4$.\n", "contributors": [{"name": "Dobzinski, Shahar", "sameAs": [], "familyName": "Dobzinski", "additionalName": "", "givenName": "Shahar", "email": ""}, {"name": "Mor, Ami", "sameAs": [], "familyName": "Mor", "additionalName": "", "givenName": "Ami", "email": ""}], "title": "On the Greedy Algorithm for Combinatorial Auctions with a Random Order", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02178", "oai:arXiv.org:1502.02178"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this note we study the greedy algorithm for combinatorial auctions with\nsubmodular bidders. It is well known that this algorithm provides an\napproximation ratio of $2$ for every order of the items. We show that if the\nvaluations are vertex cover functions and the order is random then the expected\napproximation ratio imrpoves to $\\frac 7 4$.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory", "computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-02-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02178"}}, {"publisher": {"name": ""}, "description": "  This essay presents an exploration of elements from information theory and\ncibernetics on the struggle against corruption behavior in public sector and\nbeyond; the existence of an exemplary or corrupt ethical equilibriums are\nexplored by updating Klitgaard corruption formula along with the presence of\ninformation pressure, entropy and cibernetics servomechanisms in digital\nsocieties, including alternatives and sistemics approaches for further\nanti-corruption policies implementation.\n", "contributors": [{"name": "Lopez-Pablos, Rodrigo", "sameAs": [], "familyName": "Lopez-Pablos", "additionalName": "", "givenName": "Rodrigo", "email": ""}], "title": "Apuntes sobre teor\\'ia del comportamiento corrupto: nociones\n  cibern\\'eticas e inform\\'aticas para una actualizaci\\'on de la ecuaci\\'on de\n  Klitgaard", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-23", "2015-04-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06842", "oai:arXiv.org:1503.06842"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This essay presents an exploration of elements from information theory and\ncibernetics on the struggle against corruption behavior in public sector and\nbeyond; the existence of an exemplary or corrupt ethical equilibriums are\nexplored by updating Klitgaard corruption formula along with the presence of\ninformation pressure, entropy and cibernetics servomechanisms in digital\nsocieties, including alternatives and sistemics approaches for further\nanti-corruption policies implementation.\n", "Comment: 21 pages, 2 figures, written in castilian"]}}], "languages": [null], "subjects": ["k.4.1", "computer science - information theory", "j.4"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06842"}}, {"publisher": {"name": ""}, "description": "  Nowadays this is very popular to use deep architectures in machine learning.\nDeep Belief Networks (DBNs) are deep architectures that use stack of Restricted\nBoltzmann Machines (RBM) to create a powerful generative model using training\ndata. DBNs have many ability like feature extraction and classification that\nare used in many application like image processing, speech processing and etc.\nThe paper provides a survey of the relevant literatures on DBNs and introduces\na new object oriented MATLAB toolbox with most of DBN's abilities. According to\nthe results on MNIST (image dataset) and ISOLET (speech dataset), the toolbox\ncan extract useful features with acceptable discrimination between them without\nusing label information. Also on both datasets, the obtained classification\nerrors are comparable to the state of the arts literatures on them. In addition\nthe toolbox can be used in other applications like generating data from trained\nmodel, reconstructing data and reducing noise. The toolbox is open source\nsoftware and freely available on the website http://ceit.aut.ac.ir/~keyvanrad/ .\n", "contributors": [{"name": "Keyvanrad, Mohammad Ali", "sameAs": [], "familyName": "Keyvanrad", "additionalName": "Ali", "givenName": "Mohammad", "email": ""}, {"name": "Homayounpour, Mohammad Mehdi", "sameAs": [], "familyName": "Homayounpour", "additionalName": "Mehdi", "givenName": "Mohammad", "email": ""}], "title": "A brief survey on deep belief networks and introducing a new object\n  oriented MATLAB toolbox (DeeBNet)", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-14", "2014-12-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.3264", "oai:arXiv.org:1408.3264"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Nowadays this is very popular to use deep architectures in machine learning.\nDeep Belief Networks (DBNs) are deep architectures that use stack of Restricted\nBoltzmann Machines (RBM) to create a powerful generative model using training\ndata. DBNs have many ability like feature extraction and classification that\nare used in many application like image processing, speech processing and etc.\nThe paper provides a survey of the relevant literatures on DBNs and introduces\na new object oriented MATLAB toolbox with most of DBN's abilities. According to\nthe results on MNIST (image dataset) and ISOLET (speech dataset), the toolbox\ncan extract useful features with acceptable discrimination between them without\nusing label information. Also on both datasets, the obtained classification\nerrors are comparable to the state of the arts literatures on them. In addition\nthe toolbox can be used in other applications like generating data from trained\nmodel, reconstructing data and reducing noise. The toolbox is open source\nsoftware and freely available on the website http://ceit.aut.ac.ir/~keyvanrad/ .\n", "Comment: Technical Report 25 pages"]}}], "languages": [null], "subjects": ["68t01", "computer science - mathematical software", "computer science - learning", "computer science - neural and evolutionary computing", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.3264"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "In the early twentieth century, the emergence of national market and maturation of color printing technologies brought a revolution in advertising. Consumers received and collected many colorful advertising images and pasted them into scrapbooks. Nowadays, a group of visually-driven social commerce sites like Pinterest.com provides a platform on which both businesses and consumer-collectors publish, collect, and circulate images en masse. This thesis examines historical scrapbooks as well as a variety of Pinterest collections through the theoretical lens of sociology to determine whether Pinterest enables new modes of collection, consumption and community formation. This thesis shows that while collections of commercial images of products are often spaces in which we express consumer desires for products and engage in hedonistic imaginative play, the socially-networked nature of Pinterest allows a new type of malleable, global and taste-based community to develop that can engage in collective imaginative play.", "contributors": [{"name": "Zhong, Lingyuxiu", "sameAs": [], "familyName": "Zhong", "additionalName": "", "givenName": "Lingyuxiu", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Comparative Media Studies.", "sameAs": [], "familyName": "Studies.", "additionalName": "Institute of Technology. Department of Comparative Media", "givenName": "Massachusetts", "email": ""}, {"name": "William Uricchio.", "sameAs": [], "familyName": "Uricchio.", "additionalName": "", "givenName": "William", "email": ""}], "title": "My pins are my dreams : Pinterest, collective daydreams, and the aspirational gap", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "101 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/89975", "890129765", "oai:dspace.mit.edu:1721.1/89975"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2014-09-19T21:32:08Z", "2014-09-19T21:32:08Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["In the early twentieth century, the emergence of national market and maturation of color printing technologies brought a revolution in advertising. Consumers received and collected many colorful advertising images and pasted them into scrapbooks. Nowadays, a group of visually-driven social commerce sites like Pinterest.com provides a platform on which both businesses and consumer-collectors publish, collect, and circulate images en masse. This thesis examines historical scrapbooks as well as a variety of Pinterest collections through the theoretical lens of sociology to determine whether Pinterest enables new modes of collection, consumption and community formation. This thesis shows that while collections of commercial images of products are often spaces in which we express consumer desires for products and engage in hedonistic imaginative play, the socially-networked nature of Pinterest allows a new type of malleable, global and taste-based community to develop that can engage in collective imaginative play.", "by Lingyuxiu Zhong.", "Thesis: S.M., Massachusetts Institute of Technology, Department of Comparative Media Studies, 2014.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (pages 90-101)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39097", "hdl_1721.1_39100"]}}], "languages": [null], "subjects": ["comparative media studies."], "providerUpdatedDateTime": "2015-04-27T14:44:39", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/89975"}}, {"publisher": {"name": ""}, "description": "  Laser cooling and trapping together with ready access to massive computer\nclusters have created the interesting confluence that we now have both the\nmotive and the opportunity to study light propagation in a dense cold atomic\ngas by means of basically exact numerical simulations. Even faithful\natom-by-atom simulations are possible for the smallest samples used in the\npresent experiments. Here we report on a direct comparison between traditional\noptics, that is, electrodynamics of a polarizable medium (EDPM), and numerical\nsimulations in an elementary problem of light propagating through a slab of\nmatter. The standard optics fails already at quite low atom densities, and the\nfailure becomes dramatic when the average interatomic separation is reduced to\naround $k^{-1}$, where $k$ is the wave number of resonant light. The difference\nbetween the two solutions originates from the strong correlations between the\natoms induced by light-mediated dipole-dipole interactions.\n", "contributors": [{"name": "Javanainen, Juha", "sameAs": [], "familyName": "Javanainen", "additionalName": "", "givenName": "Juha", "email": ""}, {"name": "Ruostekoski, Janne", "sameAs": [], "familyName": "Ruostekoski", "additionalName": "", "givenName": "Janne", "email": ""}], "title": "Strong correlations in light propagation beyond the mean-field theory of\n  optics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-16", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.4598", "oai:arXiv.org:1409.4598"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": "  Laser cooling and trapping together with ready access to massive computer\nclusters have created the interesting confluence that we now have both the\nmotive and the opportunity to study light propagation in a dense cold atomic\ngas by means of basically exact numerical simulations. Even faithful\natom-by-atom simulations are possible for the smallest samples used in the\npresent experiments. Here we report on a direct comparison between traditional\noptics, that is, electrodynamics of a polarizable medium (EDPM), and numerical\nsimulations in an elementary problem of light propagating through a slab of\nmatter. The standard optics fails already at quite low atom densities, and the\nfailure becomes dramatic when the average interatomic separation is reduced to\naround $k^{-1}$, where $k$ is the wave number of resonant light. The difference\nbetween the two solutions originates from the strong correlations between the\natoms induced by light-mediated dipole-dipole interactions.\n"}}], "languages": [null], "subjects": ["physics - computational physics", "physics - optics", "condensed matter - quantum gases", "quantum physics", "physics - atomic physics"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.4598"}}, {"publisher": {"name": ""}, "description": "  Let $\\mathbb{A}_n^m$ be an arbitrary $n$-dimensional commutative associative\nalgebra over the field of complex numbers with $m$ idempotents. Let\n$e_1=1,e_2,\\ldots,e_k$ with $2\\leq k\\leq 2n$ be elements of $\\mathbb{A}_n^m$\nwhich are linearly independent over the field of real numbers. We consider\nmonogenic (i.e. continuous and differentiable in the sense of Gateaux)\nfunctions of the variable $\\sum_{j=1}^k x_j\\,e_j$, where $x_1,x_2,\\ldots,x_k$\nare real, and we prove curvilinear analogues of the Cauchy integral theorem,\nthe Morera theorem and the Cauchy integral formula in $k$-dimensional ($2\\leq\nk\\leq 2n$) real subset of the algebra $\\mathbb{A}_n^m$. The present article is\ngeneralized of the author's paper [1], where mentioned results are obtained for\n$k=3$.\n", "contributors": [{"name": "Shpakivskyi, V. S.", "sameAs": [], "familyName": "Shpakivskyi", "additionalName": "S.", "givenName": "V.", "email": ""}], "title": "Integral theorems for monogenic functions in commutative algebras", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07162", "oai:arXiv.org:1503.07162"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Let $\\mathbb{A}_n^m$ be an arbitrary $n$-dimensional commutative associative\nalgebra over the field of complex numbers with $m$ idempotents. Let\n$e_1=1,e_2,\\ldots,e_k$ with $2\\leq k\\leq 2n$ be elements of $\\mathbb{A}_n^m$\nwhich are linearly independent over the field of real numbers. We consider\nmonogenic (i.e. continuous and differentiable in the sense of Gateaux)\nfunctions of the variable $\\sum_{j=1}^k x_j\\,e_j$, where $x_1,x_2,\\ldots,x_k$\nare real, and we prove curvilinear analogues of the Cauchy integral theorem,\nthe Morera theorem and the Cauchy integral formula in $k$-dimensional ($2\\leq\nk\\leq 2n$) real subset of the algebra $\\mathbb{A}_n^m$. The present article is\ngeneralized of the author's paper [1], where mentioned results are obtained for\n$k=3$.\n", "Comment: arXiv admin note: substantial text overlap with arXiv:1503.03464,\n  arXiv:1503.07134"]}}], "languages": [null], "subjects": ["mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07162"}}, {"publisher": {"name": ""}, "description": "  We present new parallel sorting networks for $17$ to $20$ inputs. For $17,\n19,$ and $20$ inputs these new networks are faster (i.e., they require less\ncomputation steps) than the previously known best networks. Therefore, we\nimprove upon the known upper bounds for minimal depth sorting networks on $17,\n19,$ and $20$ channels. Furthermore, we show that our sorting network for $17$\ninputs is optimal in the sense that no sorting network using less layers\nexists. This solves the main open problem of [D. Bundala & J. Za\\'vodn\\'y.\nOptimal sorting networks, Proc. LATA 2014].\n", "contributors": [{"name": "Ehlers, Thorsten", "sameAs": [], "familyName": "Ehlers", "additionalName": "", "givenName": "Thorsten", "email": ""}, {"name": "M\u00fcller, Mike", "sameAs": [], "familyName": "M\u00fcller", "additionalName": "", "givenName": "Mike", "email": ""}], "title": "New Bounds on Optimal Sorting Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06946", "oai:arXiv.org:1501.06946"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We present new parallel sorting networks for $17$ to $20$ inputs. For $17,\n19,$ and $20$ inputs these new networks are faster (i.e., they require less\ncomputation steps) than the previously known best networks. Therefore, we\nimprove upon the known upper bounds for minimal depth sorting networks on $17,\n19,$ and $20$ channels. Furthermore, we show that our sorting network for $17$\ninputs is optimal in the sense that no sorting network using less layers\nexists. This solves the main open problem of [D. Bundala & J. Za\\'vodn\\'y.\nOptimal sorting networks, Proc. LATA 2014].\n", "Comment: Submitted to CiE. arXiv admin note: text overlap with arXiv:1410.2736"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - discrete mathematics"], "providerUpdatedDateTime": "2015-01-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06946"}}, {"publisher": {"name": ""}, "description": "  In this work, a coarse-graining method previously proposed by the authors in\na companion paper based on solving diffusion equations is applied to CFD-DEM\nsimulations, where coarse graining is used to obtain solid volume fraction,\nparticle phase velocity, and fluid-particle interaction forces. By examining\nthe conservation requirements, the variables to solve diffusion equations for\nin CFD-DEM simulations are identified. The algorithm is then implemented into a\nCFD-DEM solver based on OpenFOAM and LAMMPS, the former being a\ngeneral-purpose, three-dimensional CFD solver based on unstructured meshes.\nNumerical simulations are performed for a fluidized bed by using the CFD-DEM\nsolver with the diffusion-based coarse-graining algorithm. Converged results\nare obtained on successively refined meshes, even for meshes with cell sizes\ncomparable to or smaller than the particle diameter. This is a critical\nadvantage of the proposed method over many existing coarse-graining methods,\nand would be particularly valuable when small cells are required in part of the\nCFD mesh to resolve certain flow features such as boundary layers in wall\nbounded flows and shear layers in jets and wakes. Moreover, we demonstrate that\nthe overhead computational costs incurred by the proposed coarse-graining\nprocedure are a small portion of the total costs in typical CFD-DEM simulations\nas long as the number of particles per cell is reasonably large, although\nadmittedly the computational overhead of the coarse graining often exceeds that\nof the CFD solver. Other advantages of the present algorithm include more\nrobust and physically realistic results, flexibility and easy implementation in\nalmost any CFD solvers, and clear physical interpretation of the computational\nparameter needed in the algorithm. In summary, the diffusion-based method is a\ntheoretically elegant and practically viable option for CFD-DEM simulations.\n", "contributors": [{"name": "Sun, Rui", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Rui", "email": ""}, {"name": "Xiao, Heng", "sameAs": [], "familyName": "Xiao", "additionalName": "", "givenName": "Heng", "email": ""}], "title": "Diffusion-Based Coarse Graining in Hybrid Continuum-Discrete Solvers:\n  Applications in CFD-DEM", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-29", "2015-01-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.0022", "oai:arXiv.org:1409.0022"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": "  In this work, a coarse-graining method previously proposed by the authors in\na companion paper based on solving diffusion equations is applied to CFD-DEM\nsimulations, where coarse graining is used to obtain solid volume fraction,\nparticle phase velocity, and fluid-particle interaction forces. By examining\nthe conservation requirements, the variables to solve diffusion equations for\nin CFD-DEM simulations are identified. The algorithm is then implemented into a\nCFD-DEM solver based on OpenFOAM and LAMMPS, the former being a\ngeneral-purpose, three-dimensional CFD solver based on unstructured meshes.\nNumerical simulations are performed for a fluidized bed by using the CFD-DEM\nsolver with the diffusion-based coarse-graining algorithm. Converged results\nare obtained on successively refined meshes, even for meshes with cell sizes\ncomparable to or smaller than the particle diameter. This is a critical\nadvantage of the proposed method over many existing coarse-graining methods,\nand would be particularly valuable when small cells are required in part of the\nCFD mesh to resolve certain flow features such as boundary layers in wall\nbounded flows and shear layers in jets and wakes. Moreover, we demonstrate that\nthe overhead computational costs incurred by the proposed coarse-graining\nprocedure are a small portion of the total costs in typical CFD-DEM simulations\nas long as the number of particles per cell is reasonably large, although\nadmittedly the computational overhead of the coarse graining often exceeds that\nof the CFD solver. Other advantages of the present algorithm include more\nrobust and physically realistic results, flexibility and easy implementation in\nalmost any CFD solvers, and clear physical interpretation of the computational\nparameter needed in the algorithm. In summary, the diffusion-based method is a\ntheoretically elegant and practically viable option for CFD-DEM simulations.\n"}}], "languages": [null], "subjects": ["physics - computational physics", "physics - fluid dynamics"], "providerUpdatedDateTime": "2015-01-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.0022"}}, {"publisher": {"name": ""}, "description": "  This short article presents a class of projection-based solution algorithms\nto the problem considered in the pioneering work on compressed sensing -\nperfect reconstruction of a phantom image from 22 radial lines in the frequency\ndomain. Under the framework of projection-based image reconstruction, we will\nshow experimentally that several old and new tools of nonlinear filtering\n(including Perona-Malik diffusion, nonlinear diffusion, Translation-Invariant\nthresholding and SA-DCT thresholding) all lead to perfect reconstruction of the\nphantom image.\n", "contributors": [{"name": "Li, Xin", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Xin", "email": ""}], "title": "All Roads Lead To Rome", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-03-08", "2011-03-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1103.1587", "IEEE SPM'2011 as a Column Paper for DSP Tips&Tricks", "oai:arXiv.org:1103.1587"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This short article presents a class of projection-based solution algorithms\nto the problem considered in the pioneering work on compressed sensing -\nperfect reconstruction of a phantom image from 22 radial lines in the frequency\ndomain. Under the framework of projection-based image reconstruction, we will\nshow experimentally that several old and new tools of nonlinear filtering\n(including Perona-Malik diffusion, nonlinear diffusion, Translation-Invariant\nthresholding and SA-DCT thresholding) all lead to perfect reconstruction of the\nphantom image.\n", "Comment: 5 pages, 1 figure, submitted"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1103.1587"}}, {"publisher": {"name": ""}, "description": "  In this paper, we analyze several recent schemes for watermarking network\nflows that are based on splitting the flow into timing intervals. We show that\nthis approach creates time-dependent correlations that enable an attack that\ncombines multiple watermarked flows. Such an attack can easily be mounted in\nnearly all applications of network flow watermarking, both in anonymous\ncommunication and stepping stone detection. The attack can be used to detect\nthe presence of a watermark, recover the secret parameters, and remove the\nwatermark from a flow. The attack can be effective even if different flows are\nmarked with different values of a watermark.\n  We analyze the efficacy of our attack using a probabilistic model and a\nMarkov-Modulated Poisson Process (MMPP) model of interactive traffic. We also\nimplement our attack and test it using both synthetic and real-world traces,\nshowing that our attack is effective with as few as 10 watermarked flows.\nFinally, we propose possible countermeasures to defeat the multi-flow attack.\n", "contributors": [{"name": "Kiyavash, Negar", "sameAs": [], "familyName": "Kiyavash", "additionalName": "", "givenName": "Negar", "email": ""}, {"name": "Houmansadr, Amir", "sameAs": [], "familyName": "Houmansadr", "additionalName": "", "givenName": "Amir", "email": ""}, {"name": "Borisov, Nikita", "sameAs": [], "familyName": "Borisov", "additionalName": "", "givenName": "Nikita", "email": ""}], "title": "Multi-Flow Attacks Against Network Flow Watermarks: Analysis and\n  Countermeasures", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-03-07", "2012-03-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1203.1390", "oai:arXiv.org:1203.1390"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we analyze several recent schemes for watermarking network\nflows that are based on splitting the flow into timing intervals. We show that\nthis approach creates time-dependent correlations that enable an attack that\ncombines multiple watermarked flows. Such an attack can easily be mounted in\nnearly all applications of network flow watermarking, both in anonymous\ncommunication and stepping stone detection. The attack can be used to detect\nthe presence of a watermark, recover the secret parameters, and remove the\nwatermark from a flow. The attack can be effective even if different flows are\nmarked with different values of a watermark.\n  We analyze the efficacy of our attack using a probabilistic model and a\nMarkov-Modulated Poisson Process (MMPP) model of interactive traffic. We also\nimplement our attack and test it using both synthetic and real-world traces,\nshowing that our attack is effective with as few as 10 watermarked flows.\nFinally, we propose possible countermeasures to defeat the multi-flow attack.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1203.1390"}}, {"publisher": {"name": ""}, "description": "abstract: Ranking is of definitive importance to both usability and profitability of web information systems. While ranking of results is crucial for the accessibility of information to the user, the ranking of online ads increases the profitability of the search provider. The scope of my thesis includes both search and ad ranking. I consider the emerging problem of ranking the deep web data considering trustworthiness and relevance. I address the end-to-end deep web ranking by focusing on: (i) ranking and selection of the deep web databases (ii) topic sensitive ranking of the sources (iii) ranking the result tuples from the selected databases. Especially, assessing the trustworthiness and relevances of results for ranking is hard since the currently used link analysis is inapplicable (since deep web records do not have links). I formulated a method---namely SourceRank---to assess the trustworthiness and relevance of the sources based on the inter-source agreement. Secondly, I extend the SourceRank to consider the topic of the agreeing sources in multi-topic environments. Further, I formulate a ranking sensitive to trustworthiness and relevance for the individual results returned by the selected sources. For ad ranking, I formulate a generalized ranking function---namely Click Efficiency (CE)---based on a realistic user click model of ads and documents. The CE ranking considers hitherto ignored parameters of perceived relevance and user dissatisfaction. CE ranking guaranteeing optimal utilities for the click model. Interestingly, I show that the existing ad and document ranking functions are reduced forms of the CE ranking under restrictive assumptions. Subsequently, I extend the CE ranking to include a pricing mechanism, designing a complete auction mechanism. My analysis proves several desirable properties including revenue dominance over popular Vickery-Clarke-Groves (VCG) auctions for the same bid vector and existence of a Nash equilibrium in pure strategies. The equilibrium is socially optimal, and revenue equivalent to the truthful VCG equilibrium. Further, I relax the independence assumption in CE ranking and analyze the diversity ranking problem. I show that optimal diversity ranking is NP-Hard in general, and that a constant time approximation algorithm is not likely.", "contributors": [{"name": "Balakrishnan, Raju  (Author)", "sameAs": [], "familyName": "Balakrishnan", "additionalName": "", "givenName": "Raju", "email": ""}, {"name": "Kambhampati, Subbarao  (Advisor)", "sameAs": [], "familyName": "Kambhampati", "additionalName": "", "givenName": "Subbarao", "email": ""}, {"name": "Chen, Yi  (Committee member)", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Yi", "email": ""}, {"name": "Doan, Anhai  (Committee member)", "sameAs": [], "familyName": "Doan", "additionalName": "", "givenName": "Anhai", "email": ""}, {"name": "Liu, Huan  (Committee member)", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Huan", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Trust and Profit Sensitive Ranking for the Deep Web and On-line Advertisements", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "152 pages"}}, {"name": "date", "properties": {"date": "2012"}}, {"name": "description", "properties": {"description": ["abstract: Ranking is of definitive importance to both usability and profitability of web information systems. While ranking of results is crucial for the accessibility of information to the user, the ranking of online ads increases the profitability of the search provider. The scope of my thesis includes both search and ad ranking. I consider the emerging problem of ranking the deep web data considering trustworthiness and relevance. I address the end-to-end deep web ranking by focusing on: (i) ranking and selection of the deep web databases (ii) topic sensitive ranking of the sources (iii) ranking the result tuples from the selected databases. Especially, assessing the trustworthiness and relevances of results for ranking is hard since the currently used link analysis is inapplicable (since deep web records do not have links). I formulated a method---namely SourceRank---to assess the trustworthiness and relevance of the sources based on the inter-source agreement. Secondly, I extend the SourceRank to consider the topic of the agreeing sources in multi-topic environments. Further, I formulate a ranking sensitive to trustworthiness and relevance for the individual results returned by the selected sources. For ad ranking, I formulate a generalized ranking function---namely Click Efficiency (CE)---based on a realistic user click model of ads and documents. The CE ranking considers hitherto ignored parameters of perceived relevance and user dissatisfaction. CE ranking guaranteeing optimal utilities for the click model. Interestingly, I show that the existing ad and document ranking functions are reduced forms of the CE ranking under restrictive assumptions. Subsequently, I extend the CE ranking to include a pricing mechanism, designing a complete auction mechanism. My analysis proves several desirable properties including revenue dominance over popular Vickery-Clarke-Groves (VCG) auctions for the same bid vector and existence of a Nash equilibrium in pure strategies. The equilibrium is socially optimal, and revenue equivalent to the truthful VCG equilibrium. Further, I relax the independence assumption in CE ranking and analyze the diversity ranking problem. I show that optimal diversity ranking is NP-Hard in general, and that a constant time approximation algorithm is not likely.", "Dissertation/Thesis", "Ph.D. Computer Science 2012"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.15153", "item:15153"]}}], "languages": [null], "subjects": ["web integration", "document ranking", "trust analysis", "deep web", "computer science", "ad ranking", "ad auctions"], "providerUpdatedDateTime": "2015-02-12T01:13:49", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.15153"}}, {"publisher": {"name": ""}, "description": "  We study information processing in populations of Boolean networks with\nevolving connectivity and systematically explore the interplay between the\nlearning capability, robustness, the network topology, and the task complexity.\nWe solve a long-standing open question and find computationally that, for large\nsystem sizes $N$, adaptive information processing drives the networks to a\ncritical connectivity $K_{c}=2$. For finite size networks, the connectivity\napproaches the critical value with a power-law of the system size $N$. We show\nthat network learning and generalization are optimized near criticality, given\ntask complexity and the amount of information provided threshold values. Both\nrandom and evolved networks exhibit maximal topological diversity near $K_{c}$.\nWe hypothesize that this supports efficient exploration and robustness of\nsolutions. Also reflected in our observation is that the variance of the values\nis maximal in critical network populations. Finally, we discuss implications of\nour results for determining the optimal topology of adaptive dynamical networks\nthat solve computational tasks.\n", "contributors": [{"name": "Goudarzi, Alireza", "sameAs": [], "familyName": "Goudarzi", "additionalName": "", "givenName": "Alireza", "email": ""}, {"name": "Teuscher, Christof", "sameAs": [], "familyName": "Teuscher", "additionalName": "", "givenName": "Christof", "email": ""}, {"name": "Gulbahce, Natali", "sameAs": [], "familyName": "Gulbahce", "additionalName": "", "givenName": "Natali", "email": ""}, {"name": "Rohlf, Thimo", "sameAs": [], "familyName": "Rohlf", "additionalName": "", "givenName": "Thimo", "email": ""}], "title": "Emergent Criticality Through Adaptive Information Processing in Boolean\n  Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-20", "2012-04-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.4141", "Physical Review Letters, 108(12):128702 (2012)", "doi:10.1103/PhysRevLett.108.128702", "oai:arXiv.org:1104.4141"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:nlin"]}}, {"name": "description", "properties": {"description": ["  We study information processing in populations of Boolean networks with\nevolving connectivity and systematically explore the interplay between the\nlearning capability, robustness, the network topology, and the task complexity.\nWe solve a long-standing open question and find computationally that, for large\nsystem sizes $N$, adaptive information processing drives the networks to a\ncritical connectivity $K_{c}=2$. For finite size networks, the connectivity\napproaches the critical value with a power-law of the system size $N$. We show\nthat network learning and generalization are optimized near criticality, given\ntask complexity and the amount of information provided threshold values. Both\nrandom and evolved networks exhibit maximal topological diversity near $K_{c}$.\nWe hypothesize that this supports efficient exploration and robustness of\nsolutions. Also reflected in our observation is that the variance of the values\nis maximal in critical network populations. Finally, we discuss implications of\nour results for determining the optimal topology of adaptive dynamical networks\nthat solve computational tasks.\n", "Comment: 5 pages, 4 figures"]}}], "languages": [null], "subjects": ["condensed matter - disordered systems and neural networks", "computer science - neural and evolutionary computing", "nonlinear sciences - adaptation and self-organizing systems"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.4141"}}, {"publisher": {"name": ""}, "description": "  A low-complexity algorithm for calculation of the LMMSE filter coefficients\nfor GFDM in a block-fading multipath environment is derived in this letter. The\nsimplification is based on the block circularity of the involved matrices. The\nproposal reduces complexity from cubic to squared order. The proposed approach\ncan be generalized to other waveforms with circular pulse shaping.\n", "contributors": [{"name": "Matth\u00e9, Maximilian", "sameAs": [], "familyName": "Matth\u00e9", "additionalName": "", "givenName": "Maximilian", "email": ""}, {"name": "Gaspar, Ivan", "sameAs": [], "familyName": "Gaspar", "additionalName": "", "givenName": "Ivan", "email": ""}, {"name": "Zhang, Dan", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Dan", "email": ""}, {"name": "Fettweis, Gerhard", "sameAs": [], "familyName": "Fettweis", "additionalName": "", "givenName": "Gerhard", "email": ""}], "title": "Reduced Complexity Calculation of LMMSE Filter Coefficients for GFDM", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-10", "2015-04-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02782", "oai:arXiv.org:1503.02782"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A low-complexity algorithm for calculation of the LMMSE filter coefficients\nfor GFDM in a block-fading multipath environment is derived in this letter. The\nsimplification is based on the block circularity of the involved matrices. The\nproposal reduces complexity from cubic to squared order. The proposed approach\ncan be generalized to other waveforms with circular pulse shaping.\n", "Comment: Submitted to IEEE Electronics Letters"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02782"}}, {"publisher": {"name": ""}, "description": "  For any $n>1$ and $0<\\varepsilon<1/2$, we show the existence of an\n$n^{O(1)}$-point subset $X$ of $\\mathbb{R}^n$ such that any linear map from\n$(X,\\ell_2)$ to $\\ell_2^m$ with distortion at most $1+\\varepsilon$ must have $m\n= \\Omega(\\min\\{n, \\varepsilon^{-2}\\log n\\})$. Our lower bound matches the upper\nbounds provided by the identity matrix and the Johnson-Lindenstrauss lemma,\nimproving the previous lower bound of Alon by a $\\log(1/\\varepsilon)$ factor.\n", "contributors": [{"name": "Larsen, Kasper Green", "sameAs": [], "familyName": "Larsen", "additionalName": "Green", "givenName": "Kasper", "email": ""}, {"name": "Nelson, Jelani", "sameAs": [], "familyName": "Nelson", "additionalName": "", "givenName": "Jelani", "email": ""}], "title": "The Johnson-Lindenstrauss lemma is optimal for linear dimensionality\n  reduction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2404", "oai:arXiv.org:1411.2404"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  For any $n>1$ and $0<\\varepsilon<1/2$, we show the existence of an\n$n^{O(1)}$-point subset $X$ of $\\mathbb{R}^n$ such that any linear map from\n$(X,\\ell_2)$ to $\\ell_2^m$ with distortion at most $1+\\varepsilon$ must have $m\n= \\Omega(\\min\\{n, \\varepsilon^{-2}\\log n\\})$. Our lower bound matches the upper\nbounds provided by the identity matrix and the Johnson-Lindenstrauss lemma,\nimproving the previous lower bound of Alon by a $\\log(1/\\varepsilon)$ factor.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - information theory", "mathematics - functional analysis", "computer science - computational geometry"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2404"}}, {"publisher": {"name": ""}, "description": "  Consider a pair of terminals connected by two independent additive white\nGaussian noise channels, and limited by individual power constraints. The first\nterminal would like to reliably send information to the second terminal, within\na given error probability. We construct an explicit interactive scheme\nconsisting of only (non-linear) scalar operations, by endowing the\nSchalkwijk-Kailath noiseless feedback scheme with modulo arithmetic. Our scheme\nachieves a communication rate close to the Shannon limit, in a small number of\nrounds. For example, for an error probability of $10^{-6}$, if the Signal to\nNoise Ratio ($\\mathrm{SNR}$) of the feedback channel exceeds the $\\mathrm{SNR}$\nof the forward channel by $20\\mathrm{dB}$, our scheme operates $0.8\\mathrm{dB}$\nfrom the Shannon limit with only $19$ rounds of interaction. In comparison,\nattaining the same performance using state of the art Forward Error Correction\n(FEC) codes requires two orders of magnitude increase in delay and complexity.\nOn the other extreme, a minimal delay uncoded system with the same error\nprobability is bounded away by $9\\mathrm{dB}$ from the Shannon limit.\n", "contributors": [{"name": "Ben-Yishai, Assaf", "sameAs": [], "familyName": "Ben-Yishai", "additionalName": "", "givenName": "Assaf", "email": ""}, {"name": "Shayevitz, Ofer", "sameAs": [], "familyName": "Shayevitz", "additionalName": "", "givenName": "Ofer", "email": ""}], "title": "The Gaussian Channel with Noisy Feedback: Near-Capacity Performance via\n  Simple Interaction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-30", "2014-12-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.8022", "oai:arXiv.org:1407.8022"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Consider a pair of terminals connected by two independent additive white\nGaussian noise channels, and limited by individual power constraints. The first\nterminal would like to reliably send information to the second terminal, within\na given error probability. We construct an explicit interactive scheme\nconsisting of only (non-linear) scalar operations, by endowing the\nSchalkwijk-Kailath noiseless feedback scheme with modulo arithmetic. Our scheme\nachieves a communication rate close to the Shannon limit, in a small number of\nrounds. For example, for an error probability of $10^{-6}$, if the Signal to\nNoise Ratio ($\\mathrm{SNR}$) of the feedback channel exceeds the $\\mathrm{SNR}$\nof the forward channel by $20\\mathrm{dB}$, our scheme operates $0.8\\mathrm{dB}$\nfrom the Shannon limit with only $19$ rounds of interaction. In comparison,\nattaining the same performance using state of the art Forward Error Correction\n(FEC) codes requires two orders of magnitude increase in delay and complexity.\nOn the other extreme, a minimal delay uncoded system with the same error\nprobability is bounded away by $9\\mathrm{dB}$ from the Shannon limit.\n", "Comment: Allerton Conference on Communication, Control, and Computing, October\n  2014"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.8022"}}, {"publisher": {"name": ""}, "description": "  Braid is a 2008 puzzle game centered around the ability to reverse time. We\nshow that Braid can simulate an arbitrary computation. Our construction makes\nno use of Braid's unique time mechanics, and therefore may apply to many other\nvideo games.\n  We also show that a plausible \"bounded\" variant of Braid lies within\n2-EXPSPACE. Our proof relies on a technical lemma about Turing machines which\nmay be of independent interest. Namely, define a braidlike Turing machine to be\na Turing machine that, when it writes to the tape, deletes all data on the tape\nto the right of the head. We prove that deciding the behavior of such a machine\nlies in EXPSPACE.\n", "contributors": [{"name": "Hamilton, Linus", "sameAs": [], "familyName": "Hamilton", "additionalName": "", "givenName": "Linus", "email": ""}], "title": "Braid is undecidable", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.0784", "oai:arXiv.org:1412.0784"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Braid is a 2008 puzzle game centered around the ability to reverse time. We\nshow that Braid can simulate an arbitrary computation. Our construction makes\nno use of Braid's unique time mechanics, and therefore may apply to many other\nvideo games.\n  We also show that a plausible \"bounded\" variant of Braid lies within\n2-EXPSPACE. Our proof relies on a technical lemma about Turing machines which\nmay be of independent interest. Namely, define a braidlike Turing machine to be\na Turing machine that, when it writes to the tape, deletes all data on the tape\nto the right of the head. We prove that deciding the behavior of such a machine\nlies in EXPSPACE.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity"], "providerUpdatedDateTime": "2014-12-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.0784"}}, {"publisher": {"name": ""}, "description": "  Flexible piezoelectric devices made of polymeric materials are widely used\nfor micro- and nanoelectro-mechanical systems. In particular, numerous recent\napplications concern energy harvesting. Due to the importance of computational\nmodeling to understand the influence that microscale geometry and constitutive\nvariables exert on the macroscopic behavior, a numerical approach is developed\nhere for multiscale and multi physics modeling of piezoelectric materials made\nof aligned arrays of polymeric nanofibers. At the micro scale, the\nrepresentative volume element consists in piezoelectric polymeric nanofibers,\nassumed to feature a linear piezoelastic constitutive behavior and subjected to\nelectromechanical contact constraints. From the solution of the micro-scale\nboundary value problem, a suitable scale transition procedure leads to\nidentifying the performance of a macroscopic thin piezoelectric shell element.\n", "contributors": [{"name": "Maruccio, Claudio", "sameAs": [], "familyName": "Maruccio", "additionalName": "", "givenName": "Claudio", "email": ""}, {"name": "De Lorenzis, Laura", "sameAs": [], "familyName": "De Lorenzis", "additionalName": "", "givenName": "Laura", "email": ""}, {"name": "Persano, Luana", "sameAs": [], "familyName": "Persano", "additionalName": "", "givenName": "Luana", "email": ""}, {"name": "Pisignano, Dario", "sameAs": [], "familyName": "Pisignano", "additionalName": "", "givenName": "Dario", "email": ""}], "title": "Computational homogenization of fibrous piezoelectric materials", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-13", "2015-03-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.3302", "oai:arXiv.org:1405.3302"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Flexible piezoelectric devices made of polymeric materials are widely used\nfor micro- and nanoelectro-mechanical systems. In particular, numerous recent\napplications concern energy harvesting. Due to the importance of computational\nmodeling to understand the influence that microscale geometry and constitutive\nvariables exert on the macroscopic behavior, a numerical approach is developed\nhere for multiscale and multi physics modeling of piezoelectric materials made\nof aligned arrays of polymeric nanofibers. At the micro scale, the\nrepresentative volume element consists in piezoelectric polymeric nanofibers,\nassumed to feature a linear piezoelastic constitutive behavior and subjected to\nelectromechanical contact constraints. From the solution of the micro-scale\nboundary value problem, a suitable scale transition procedure leads to\nidentifying the performance of a macroscopic thin piezoelectric shell element.\n", "Comment: 22 pages, 13 figures"]}}], "languages": [null], "subjects": ["computer science - computational engineering", "finance", "and science"], "providerUpdatedDateTime": "2015-03-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.3302"}}, {"publisher": {"name": ""}, "description": "  Enforcing local consistencies in cost function networks is performed by\napplying so-called Equivalent Preserving Transformations (EPTs) to the cost\nfunctions. As EPTs transform the cost functions, they may break the property\nthat was making local consistency enforcement tractable on a global cost\nfunction. A global cost function is called tractable projection-safe when\napplying an EPT to it is tractable and does not break the tractability\nproperty. In this paper, we prove that depending on the size r of the smallest\nscopes used for performing EPTs, the tractability of global cost functions can\nbe preserved (r = 0) or destroyed (r > 1). When r = 1, the answer is\nindefinite. We show that on a large family of cost functions, EPTs can be\ncomputed via dynamic programming-based algorithms, leading to tractable\nprojection-safety. We also show that when a global cost function can be\ndecomposed into a Berge acyclic network of bounded arity cost functions, soft\nlocal consistencies such as soft Directed or Virtual Arc Consistency can\ndirectly emulate dynamic programming. These different approaches to\ndecomposable cost functions are then embedded in a solver for extensive\nexperiments that confirm the feasibility and efficiency of our proposal.\n", "contributors": [{"name": "Allouche, David", "sameAs": [], "familyName": "Allouche", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Bessiere, Christian", "sameAs": [], "familyName": "Bessiere", "additionalName": "", "givenName": "Christian", "email": ""}, {"name": "Boizumault, Patrice", "sameAs": [], "familyName": "Boizumault", "additionalName": "", "givenName": "Patrice", "email": ""}, {"name": "de Givry, Simon", "sameAs": [], "familyName": "de Givry", "additionalName": "", "givenName": "Simon", "email": ""}, {"name": "Gutierrez, Patricia", "sameAs": [], "familyName": "Gutierrez", "additionalName": "", "givenName": "Patricia", "email": ""}, {"name": "Lee, Jimmy H. M.", "sameAs": [], "familyName": "Lee", "additionalName": "H. M.", "givenName": "Jimmy", "email": ""}, {"name": "Leung, Kam Lun", "sameAs": [], "familyName": "Leung", "additionalName": "Lun", "givenName": "Kam", "email": ""}, {"name": "Loudni, Samir", "sameAs": [], "familyName": "Loudni", "additionalName": "", "givenName": "Samir", "email": ""}, {"name": "M\u00e9tivier, Jean-Philippe", "sameAs": [], "familyName": "M\u00e9tivier", "additionalName": "", "givenName": "Jean-Philippe", "email": ""}, {"name": "Schiex, Thomas", "sameAs": [], "familyName": "Schiex", "additionalName": "", "givenName": "Thomas", "email": ""}, {"name": "Wu, Yi", "sameAs": [], "familyName": "Wu", "additionalName": "", "givenName": "Yi", "email": ""}], "title": "Tractability and Decompositions of Global Cost Functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02414", "oai:arXiv.org:1502.02414"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Enforcing local consistencies in cost function networks is performed by\napplying so-called Equivalent Preserving Transformations (EPTs) to the cost\nfunctions. As EPTs transform the cost functions, they may break the property\nthat was making local consistency enforcement tractable on a global cost\nfunction. A global cost function is called tractable projection-safe when\napplying an EPT to it is tractable and does not break the tractability\nproperty. In this paper, we prove that depending on the size r of the smallest\nscopes used for performing EPTs, the tractability of global cost functions can\nbe preserved (r = 0) or destroyed (r > 1). When r = 1, the answer is\nindefinite. We show that on a large family of cost functions, EPTs can be\ncomputed via dynamic programming-based algorithms, leading to tractable\nprojection-safety. We also show that when a global cost function can be\ndecomposed into a Berge acyclic network of bounded arity cost functions, soft\nlocal consistencies such as soft Directed or Virtual Arc Consistency can\ndirectly emulate dynamic programming. These different approaches to\ndecomposable cost functions are then embedded in a solver for extensive\nexperiments that confirm the feasibility and efficiency of our proposal.\n", "Comment: 32 pages for the main paper, extra Appendix with examples of\n  DAG-decomposed global cost functions"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "etc.)", "search strategies", "68t20 problem solving (heuristics"], "providerUpdatedDateTime": "2015-02-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02414"}}, {"publisher": {"name": ""}, "description": "  Dynamic model reduction in power systems is necessary for improving\ncomputational efficiency. Traditional model reduction using linearized models\nor offline analysis would not be adequate to capture power system dynamic\nbehaviors, especially the new mix of intermittent generation and intelligent\nconsumption makes the power system more dynamic and non-linear. Real-time\ndynamic model reduction emerges as an important need. This paper explores the\nuse of clustering techniques to analyze real-time phasor measurements to\ndetermine generator groups and representative generators for dynamic model\nreduction. Two clustering techniques -- graph clustering and evolutionary\nclustering -- are studied in this paper. Various implementations of these\ntechniques are compared and also compared with a previously developed Singular\nValue Decomposition (SVD)-based dynamic model reduction approach. Various\nmethods exhibit different levels of accuracy when comparing the reduced model\nsimulation against the original model. But some of them are consistently\naccurate. From this comparative perspective, this paper provides a good\nreference point for practical implementations.\n", "contributors": [{"name": "Hogan, Emilie", "sameAs": [], "familyName": "Hogan", "additionalName": "", "givenName": "Emilie", "email": ""}, {"name": "Cotilla-Sanchez, Eduardo", "sameAs": [], "familyName": "Cotilla-Sanchez", "additionalName": "", "givenName": "Eduardo", "email": ""}, {"name": "Halappanavar, Mahantesh", "sameAs": [], "familyName": "Halappanavar", "additionalName": "", "givenName": "Mahantesh", "email": ""}, {"name": "Huang, Zhenyu", "sameAs": [], "familyName": "Huang", "additionalName": "", "givenName": "Zhenyu", "email": ""}, {"name": "Lin, Guang", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Guang", "email": ""}, {"name": "Lu, Shuai", "sameAs": [], "familyName": "Lu", "additionalName": "", "givenName": "Shuai", "email": ""}, {"name": "Wang, Shaobu", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Shaobu", "email": ""}], "title": "Comparative Studies of Clustering Techniques for Real-Time Dynamic Model\n  Reduction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00943", "oai:arXiv.org:1501.00943"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Dynamic model reduction in power systems is necessary for improving\ncomputational efficiency. Traditional model reduction using linearized models\nor offline analysis would not be adequate to capture power system dynamic\nbehaviors, especially the new mix of intermittent generation and intelligent\nconsumption makes the power system more dynamic and non-linear. Real-time\ndynamic model reduction emerges as an important need. This paper explores the\nuse of clustering techniques to analyze real-time phasor measurements to\ndetermine generator groups and representative generators for dynamic model\nreduction. Two clustering techniques -- graph clustering and evolutionary\nclustering -- are studied in this paper. Various implementations of these\ntechniques are compared and also compared with a previously developed Singular\nValue Decomposition (SVD)-based dynamic model reduction approach. Various\nmethods exhibit different levels of accuracy when comparing the reduced model\nsimulation against the original model. But some of them are consistently\naccurate. From this comparative perspective, this paper provides a good\nreference point for practical implementations.\n", "Comment: 8 pages, 13 figures, submitted to IEEE transactions"]}}], "languages": [null], "subjects": ["computer science - systems and control", "physics - physics and society"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00943"}}, {"publisher": {"name": ""}, "description": "  Multiple people tracking is a key problem for many applications such as\nsurveillance, animation or car navigation, and a key input for tasks such as\nactivity recognition. In crowded environments occlusions and false detections\nare common, and although there have been substantial advances in recent years,\ntracking is still a challenging task. Tracking is typically divided into two\nsteps: detection, i.e., locating the pedestrians in the image, and data\nassociation, i.e., linking detections across frames to form complete\ntrajectories.\n  For the data association task, approaches typically aim at developing new,\nmore complex formulations, which in turn put the focus on the optimization\ntechniques required to solve them. However, they still utilize very basic\ninformation such as distance between detections. In this thesis, I focus on the\ndata association task and argue that there is contextual information that has\nnot been fully exploited yet in the tracking community, mainly social context\nand spatial context coming from different views.\n", "contributors": [{"name": "Leal-Taix\u00e9, Laura", "sameAs": [], "familyName": "Leal-Taix\u00e9", "additionalName": "", "givenName": "Laura", "email": ""}], "title": "Multiple object tracking with context awareness", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7935", "oai:arXiv.org:1411.7935"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Multiple people tracking is a key problem for many applications such as\nsurveillance, animation or car navigation, and a key input for tasks such as\nactivity recognition. In crowded environments occlusions and false detections\nare common, and although there have been substantial advances in recent years,\ntracking is still a challenging task. Tracking is typically divided into two\nsteps: detection, i.e., locating the pedestrians in the image, and data\nassociation, i.e., linking detections across frames to form complete\ntrajectories.\n  For the data association task, approaches typically aim at developing new,\nmore complex formulations, which in turn put the focus on the optimization\ntechniques required to solve them. However, they still utilize very basic\ninformation such as distance between detections. In this thesis, I focus on the\ndata association task and argue that there is contextual information that has\nnot been fully exploited yet in the tracking community, mainly social context\nand spatial context coming from different views.\n", "Comment: PhD thesis, Leibniz University Hannover, Germany"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7935"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "We explore a number of problems related to learning and covering structured distributions: Hypothesis Selection: We provide an improved and generalized algorithm for selecting a good candidate distribution from among competing hypotheses. Namely, given a collection of ... hypotheses containing at least one candidate that is ...-close to an unknown distribution, our algorithm outputs a candidate which is ...-close to the distribution. The algorithm requires ... samples from the unknown distribution and ... time, which improves previous such results (such as the Scheff\u00e9 estimator) from a quadratic dependence of the running time on ... to quasilinear. Given the wide use of such results for the purpose of hypothesis selection, our improved algorithm implies immediate improvements to any such use. Proper Learning Gaussian Mixture Models: We describe an algorithm for properly learning mixtures of two single-dimensional Gaussians without any separability assumptions. Given ... samples from an unknown mixture, our algorithm outputs a mixture that is ...-close in total variation distance, in time ... Our sample complexity is optimal up to logarithmic factors, and significantly improves upon both Kalai et al., whose algorithm has a prohibitive dependence on 1/..., and Feldman et al., whose algorithm requires bounds on the mixture parameters and depends pseudo-polynomially in these parameters. Covering Poisson Multinomial Distributions: We provide a sparse ..-cover for the set of Poisson Multinomial Distributions. Specifically, we describe a set of ... distributions such that any Poisson Multinomial Distribution of size ?? and dimension ... is ...-close to a distribution in the set. This is a significant sparsification over the previous best-known ...-cover due to Daskalakis and Papadimitriou [24], which is of size ..., where ... is polynomial in ... and exponential in ... This cover also implies an algorithm for learning Poisson Multinomial Distributions with a sample complexity which is polynomial in ... and log ...", "contributors": [{"name": "Kamath, Gautam (Gautam Chetan)", "sameAs": [], "familyName": "Kamath", "additionalName": "", "givenName": "Gautam", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Electrical Engineering and Computer Science.", "sameAs": [], "familyName": "Science.", "additionalName": "Institute of Technology. Department of Electrical Engineering and Computer", "givenName": "Massachusetts", "email": ""}, {"name": "Constantinos Daskalakis.", "sameAs": [], "familyName": "Daskalakis.", "additionalName": "", "givenName": "Constantinos", "email": ""}], "title": "On Learning and Covering Structured Distributions", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "95 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/92966", "900006537", "oai:dspace.mit.edu:1721.1/92966"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2015-01-20T15:30:36Z", "2015-01-20T15:30:36Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["We explore a number of problems related to learning and covering structured distributions: Hypothesis Selection: We provide an improved and generalized algorithm for selecting a good candidate distribution from among competing hypotheses. Namely, given a collection of ... hypotheses containing at least one candidate that is ...-close to an unknown distribution, our algorithm outputs a candidate which is ...-close to the distribution. The algorithm requires ... samples from the unknown distribution and ... time, which improves previous such results (such as the Scheff\u00e9 estimator) from a quadratic dependence of the running time on ... to quasilinear. Given the wide use of such results for the purpose of hypothesis selection, our improved algorithm implies immediate improvements to any such use. Proper Learning Gaussian Mixture Models: We describe an algorithm for properly learning mixtures of two single-dimensional Gaussians without any separability assumptions. Given ... samples from an unknown mixture, our algorithm outputs a mixture that is ...-close in total variation distance, in time ... Our sample complexity is optimal up to logarithmic factors, and significantly improves upon both Kalai et al., whose algorithm has a prohibitive dependence on 1/..., and Feldman et al., whose algorithm requires bounds on the mixture parameters and depends pseudo-polynomially in these parameters. Covering Poisson Multinomial Distributions: We provide a sparse ..-cover for the set of Poisson Multinomial Distributions. Specifically, we describe a set of ... distributions such that any Poisson Multinomial Distribution of size ?? and dimension ... is ...-close to a distribution in the set. This is a significant sparsification over the previous best-known ...-cover due to Daskalakis and Papadimitriou [24], which is of size ..., where ... is polynomial in ... and exponential in ... This cover also implies an algorithm for learning Poisson Multinomial Distributions with a sample complexity which is polynomial in ... and log ...", "by Gautam Kamath.", "Thesis: S.M., Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2014.", "This electronic version was submitted by the student author.  The certified thesis is available in the Institute Archives and Special Collections.", "Cataloged from student-submitted PDF version of thesis.", "Includes bibliographical references (pages 91-95)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7817", "hdl_1721.1_7663"]}}], "languages": [null], "subjects": ["electrical engineering and computer science."], "providerUpdatedDateTime": "2015-01-21T07:25:09", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/92966"}}, {"publisher": {"name": ""}, "description": "  We analyse optimum reject strategies for prototype-based classifiers and\nreal-valued rejection measures, using the distance of a data point to the\nclosest prototype or probabilistic counterparts. We compare reject schemes with\nglobal thresholds, and local thresholds for the Voronoi cells of the\nclassifier. For the latter, we develop a polynomial-time algorithm to compute\noptimum thresholds based on a dynamic programming scheme, and we propose an\nintuitive linear time, memory efficient approximation thereof with competitive\naccuracy. Evaluating the performance in various benchmarks, we conclude that\nlocal reject options are beneficial in particular for simple prototype-based\nclassifiers, while the improvement is less pronounced for advanced models. For\nthe latter, an accuracy-reject curve which is comparable to support vector\nmachine classifiers with state of the art reject options can be reached.\n", "contributors": [{"name": "Fischer, Lydia", "sameAs": [], "familyName": "Fischer", "additionalName": "", "givenName": "Lydia", "email": ""}, {"name": "Hammer, Barbara", "sameAs": [], "familyName": "Hammer", "additionalName": "", "givenName": "Barbara", "email": ""}, {"name": "Wersing, Heiko", "sameAs": [], "familyName": "Wersing", "additionalName": "", "givenName": "Heiko", "email": ""}], "title": "Optimum Reject Options for Prototype-based Classification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06549", "oai:arXiv.org:1503.06549"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We analyse optimum reject strategies for prototype-based classifiers and\nreal-valued rejection measures, using the distance of a data point to the\nclosest prototype or probabilistic counterparts. We compare reject schemes with\nglobal thresholds, and local thresholds for the Voronoi cells of the\nclassifier. For the latter, we develop a polynomial-time algorithm to compute\noptimum thresholds based on a dynamic programming scheme, and we propose an\nintuitive linear time, memory efficient approximation thereof with competitive\naccuracy. Evaluating the performance in various benchmarks, we conclude that\nlocal reject options are beneficial in particular for simple prototype-based\nclassifiers, while the improvement is less pronounced for advanced models. For\nthe latter, an accuracy-reject curve which is comparable to support vector\nmachine classifiers with state of the art reject options can be reached.\n", "Comment: 19 pages"]}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06549"}}, {"publisher": {"name": ""}, "description": "  Francis Castro, et al computed the exact divisibility of families of\nexponential sums associated to binomials F(X) = aXd1 + bXd2 over Fp, and a\nconjecture is presented for related work. Here we study this question.\n", "contributors": [{"name": "Liu, Xiaogang", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Xiaogang", "email": ""}], "title": "A problem related to the divisibility of exponential sums", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07281", "oai:arXiv.org:1502.07281"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Francis Castro, et al computed the exact divisibility of families of\nexponential sums associated to binomials F(X) = aXd1 + bXd2 over Fp, and a\nconjecture is presented for related work. Here we study this question.\n", "Comment: 3 pages"]}}], "languages": [null], "subjects": ["mathematics - number theory", "computer science - information theory"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07281"}}, {"publisher": {"name": ""}, "description": "  This paper considers hybrid beamforming (HB) for downlink multiuser massive\nMIMO systems with frequency selective channels. For this system, first we\nquantify the required number of radio frequency (RF) chains and phase shifters\n(PSs) such that the proposed HB achieves the same performance as that of the\ndigital beamforming (DB) which utilizes $N$ (number of transmitter antennas) RF\nchains. We show that the performance of the DB can be achieved with our HB just\nby utilizing $r_t$ RF chains and $2r_t(N-r_t + 1)$ PSs, where $r_t \\leq N$ is\nthe rank of the combined digital precoder matrices of all sub-carriers. Second,\nwe provide a simple and novel approach to reduce the number of PSs with only a\nnegligible performance degradation. Numerical results reveal that only $20-40$\nPSs per RF chain are sufficient for practically relevant parameter settings.\nFinally, for the scenario where the deployed number of RF chains $(N_a)$ is\nless than $r_t$, we propose a simple user scheduling algorithm to select the\nbest set of users in each sub-carrier. Simulation results validate theoretical\nexpressions, and demonstrate the superiority of the proposed HB design over the\nexisting HB designs in both flat fading and frequency selective channels.\n", "contributors": [{"name": "Bogale, Tadilo Endeshaw", "sameAs": [], "familyName": "Bogale", "additionalName": "Endeshaw", "givenName": "Tadilo", "email": ""}, {"name": "Le, Long Bao", "sameAs": [], "familyName": "Le", "additionalName": "Bao", "givenName": "Long", "email": ""}, {"name": "Haghighat, Afshin", "sameAs": [], "familyName": "Haghighat", "additionalName": "", "givenName": "Afshin", "email": ""}], "title": "Hybrid Analog-Digital Beamforming: How Many RF Chains and Phase Shifters\n  Do We Need?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-09-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2609", "oai:arXiv.org:1410.2609"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper considers hybrid beamforming (HB) for downlink multiuser massive\nMIMO systems with frequency selective channels. For this system, first we\nquantify the required number of radio frequency (RF) chains and phase shifters\n(PSs) such that the proposed HB achieves the same performance as that of the\ndigital beamforming (DB) which utilizes $N$ (number of transmitter antennas) RF\nchains. We show that the performance of the DB can be achieved with our HB just\nby utilizing $r_t$ RF chains and $2r_t(N-r_t + 1)$ PSs, where $r_t \\leq N$ is\nthe rank of the combined digital precoder matrices of all sub-carriers. Second,\nwe provide a simple and novel approach to reduce the number of PSs with only a\nnegligible performance degradation. Numerical results reveal that only $20-40$\nPSs per RF chain are sufficient for practically relevant parameter settings.\nFinally, for the scenario where the deployed number of RF chains $(N_a)$ is\nless than $r_t$, we propose a simple user scheduling algorithm to select the\nbest set of users in each sub-carrier. Simulation results validate theoretical\nexpressions, and demonstrate the superiority of the proposed HB design over the\nexisting HB designs in both flat fading and frequency selective channels.\n", "Comment: Submitted to IEEE Transactions on Wireless Communications"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2609"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "The regulation of gene expression underlies the morphological, physiological, and functional differences between human cell types, developmental stages, and healthy and disease states. Gene regulation in eukaryotes is controlled by a complex milieu including transcription factors, microRNAs (miRNAs), cis-regulatory DNA and RNA. It is the quantitative and combinatorial interactions of these regulatory elements that defines gene expression, but these interactions are incompletely understood. In this thesis, I present two new methods for determining the quantitative specificity of gene regulatory factors. First, I present a comparative genomics approach that utilizes signatures of natural selection to detect the conserved biological relevance of miRNAs and their targets. Using this method, I quantify the abundance of different conserved miRNA target types, including different seed matches and 30-compensatory targets. I show that over 60% of mammalian mRNAs are conserved targets of miRNAs and that a surprising amount of conserved miRNA targeting is mediated by seed matches with relatively low efficacy. Extending this method from mammals to other organisms, I find that miRNA targeting rules are mostly conserved, although I show evidence for new types of miRNA targets in nematodes. Taking advantage of variations in 30 UTR lengths between species, I describe general properties of miRNA targeting that are affected by 30 UTR length. Finally, I introduce a new, high-throughput assay for the quantification of transcription factor in vitro binding affinity to millions of sequences. I apply this method to GCN4, a yeast transcription factor, and reconstruct all known properties of its binding preferences. Additionally, I discover some new subtleties in its specificity and estimate dissociation constants for hundreds of thousands of sequences. I verify the utility of the binding affinities by comparing to in vivo binding data and to the regulatory response following GCN4 induction.", "contributors": [{"name": "Friedman, Robin Carl", "sameAs": [], "familyName": "Friedman", "additionalName": "Carl", "givenName": "Robin", "email": ""}, {"name": "Massachusetts Institute of Technology. Computational and Systems Biology Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computational and Systems Biology", "givenName": "Massachusetts", "email": ""}, {"name": "Christopher B. Burge and David P. Bartel.", "sameAs": [], "familyName": "Bartel.", "additionalName": "B. Burge and David P.", "givenName": "Christopher", "email": ""}], "title": "The specificity and evolution of gene regulatory elements", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "157 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/61790", "706716524", "oai:dspace.mit.edu:1721.1/61790"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2011-03-24T18:52:42Z", "2011-03-24T18:52:42Z", "2010", "2010"]}}, {"name": "description", "properties": {"description": ["The regulation of gene expression underlies the morphological, physiological, and functional differences between human cell types, developmental stages, and healthy and disease states. Gene regulation in eukaryotes is controlled by a complex milieu including transcription factors, microRNAs (miRNAs), cis-regulatory DNA and RNA. It is the quantitative and combinatorial interactions of these regulatory elements that defines gene expression, but these interactions are incompletely understood. In this thesis, I present two new methods for determining the quantitative specificity of gene regulatory factors. First, I present a comparative genomics approach that utilizes signatures of natural selection to detect the conserved biological relevance of miRNAs and their targets. Using this method, I quantify the abundance of different conserved miRNA target types, including different seed matches and 30-compensatory targets. I show that over 60% of mammalian mRNAs are conserved targets of miRNAs and that a surprising amount of conserved miRNA targeting is mediated by seed matches with relatively low efficacy. Extending this method from mammals to other organisms, I find that miRNA targeting rules are mostly conserved, although I show evidence for new types of miRNA targets in nematodes. Taking advantage of variations in 30 UTR lengths between species, I describe general properties of miRNA targeting that are affected by 30 UTR length. Finally, I introduce a new, high-throughput assay for the quantification of transcription factor in vitro binding affinity to millions of sequences. I apply this method to GCN4, a yeast transcription factor, and reconstruct all known properties of its binding preferences. Additionally, I discover some new subtleties in its specificity and estimate dissociation constants for hundreds of thousands of sequences. I verify the utility of the binding affinities by comparing to in vivo binding data and to the regulatory response following GCN4 induction.", "by Robin Carl Friedman.", "Thesis (Ph. D.)--Massachusetts Institute of Technology, Computational and Systems Biology Program, 2010.", "This electronic version was submitted by the student author.  The certified thesis is available in the Institute Archives and Special Collections.", "Cataloged from student-submitted PDF version of thesis.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_54823", "hdl_1721.1_54828"]}}], "languages": [null], "subjects": ["computational and systems biology program."], "providerUpdatedDateTime": "2015-04-27T14:53:05", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/61790"}}, {"publisher": {"name": ""}, "description": "  This paper deals with grouping of entities in a fleet based on their\nbehavior. The behavior of each entity is characterized by its historical\ndataset, which comprises a dependent variable, typically a performance measure,\nand multiple independent variables, typically operating conditions. A\nregression model built using this dataset is used as a proxy for the behavior\nof an entity. The validation error of the model of one unit with respect to the\ndataset of another unit is used as a measure of the difference in behavior\nbetween two units. Grouping entities based on their behavior is posed as a\ngraph clustering problem with nodes representing regression models and edge\nweights given by the validation errors. Specifically, we find communities in\nthis graph, having dense edge connections within and sparse connections\noutside. A way to assess the goodness of grouping and finding the optimum\nnumber of divisions is proposed. The algorithm and measures proposed are\nillustrated with application to synthetic data.\n", "contributors": [{"name": "Pansari, Pankaj", "sameAs": [], "familyName": "Pansari", "additionalName": "", "givenName": "Pankaj", "email": ""}, {"name": "Rajagopalan, C.", "sameAs": [], "familyName": "Rajagopalan", "additionalName": "", "givenName": "C.", "email": ""}, {"name": "Sundararajan, Ramasubramanian", "sameAs": [], "familyName": "Sundararajan", "additionalName": "", "givenName": "Ramasubramanian", "email": ""}], "title": "Grouping Entities in a Fleet by Community Detection in Network of\n  Regression Models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04281", "oai:arXiv.org:1501.04281"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  This paper deals with grouping of entities in a fleet based on their\nbehavior. The behavior of each entity is characterized by its historical\ndataset, which comprises a dependent variable, typically a performance measure,\nand multiple independent variables, typically operating conditions. A\nregression model built using this dataset is used as a proxy for the behavior\nof an entity. The validation error of the model of one unit with respect to the\ndataset of another unit is used as a measure of the difference in behavior\nbetween two units. Grouping entities based on their behavior is posed as a\ngraph clustering problem with nodes representing regression models and edge\nweights given by the validation errors. Specifically, we find communities in\nthis graph, having dense edge connections within and sparse connections\noutside. A way to assess the goodness of grouping and finding the optimum\nnumber of divisions is proposed. The algorithm and measures proposed are\nillustrated with application to synthetic data.\n", "Comment: 8 pages, 4 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04281"}}, {"publisher": {"name": ""}, "description": "  Extracellular recordings with multi-electrode arrays is one of the basic\ntools of contemporary neuroscience. These recordings are mostly used to monitor\nthe activities, understood as sequences of emitted action potentials, of many\nindividual neurons. But the raw data produced by extracellular recordings are\nmost commonly a mixture of activities from several neurons. In order to get the\nactivities of the individual contributing neurons, a pre-processing step called\nspike sorting is required. We present here a pure Python implementation of a\nwell tested spike sorting procedure. The latter was designed in a modular way\nin order to favour a smooth transition from an interactive sorting, for\ninstance with IPython, to an automatic one. Surprisingly enough - or sadly\nenough, depending on one's view point -, recoding our now 15 years old\nprocedure into Python was the occasion of major methodological improvements.\n", "contributors": [{"name": "Pouzat, Christophe", "sameAs": [], "familyName": "Pouzat", "additionalName": "", "givenName": "Christophe", "email": ""}, {"name": "Detorakis, Georgios Is.", "sameAs": [], "familyName": "Detorakis", "additionalName": "Is.", "givenName": "Georgios", "email": ""}], "title": "SPySort: Neuronal Spike Sorting with Python", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6383", "oai:arXiv.org:1412.6383"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": ["  Extracellular recordings with multi-electrode arrays is one of the basic\ntools of contemporary neuroscience. These recordings are mostly used to monitor\nthe activities, understood as sequences of emitted action potentials, of many\nindividual neurons. But the raw data produced by extracellular recordings are\nmost commonly a mixture of activities from several neurons. In order to get the\nactivities of the individual contributing neurons, a pre-processing step called\nspike sorting is required. We present here a pure Python implementation of a\nwell tested spike sorting procedure. The latter was designed in a modular way\nin order to favour a smooth transition from an interactive sorting, for\ninstance with IPython, to an automatic one. Surprisingly enough - or sadly\nenough, depending on one's view point -, recoding our now 15 years old\nprocedure into Python was the occasion of major methodological improvements.\n", "Comment: Part of the Proceedings of the 7th European Conference on Python in\n  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)"]}}], "languages": [null], "subjects": ["quantitative biology - neurons and cognition", "computer science - computational engineering", "finance", "and science"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6383"}}, {"publisher": {"name": ""}, "description": "  In this paper we document distributions for spike rates, synaptic weights and\nneural gains for principal neurons in various tissues and under different\nbehavioral conditions. We find a remarkable consistency of a power-law,\nspecifically lognormal, distribution across observations from auditory or\nvisual cortex as well as midbrain nuclei, cerebellar Purkinje cells and\nstriatal medium spiny neurons. An exception is documented for fast-spiking\ninterneurons, as non-coding neurons, which seem to follow a normal\ndistribution. The difference between strongly recurrent and transfer\nconnectivity (cortex vs. striatum and cerebellum), or the level of activation\n(low in cortex, high in Purkinje cells and midbrain nuclei) seems to be\nirrelevant for these distributions. This has certain implications on neural\ncoding. In particular, logarithmic scale distribution of neuronal output\nappears as a structural phenomenon that is always present in coding neurons. We\nalso report data for a lognormal distribution of synaptic strengths in cortex,\ncerebellum and hippocampus and for intrinsic excitability in striatum, cortex\nand cerebellum. We present a neural model for gain, weights and spike rates,\nspecifically matching the width of distributions. We discuss the data from the\nperspective of a hierarchical coding scheme with few sparse or top-level\nfeatures and many additional distributed low-level features. Logarithmic-scale\ncoding may solve an access problem by combining a local modular structure with\nfew high frequency contact points. Computational models may need to incorporate\nthese observations as primary constraints. More data are needed to consolidate\nthe observations.\n", "contributors": [{"name": "Scheler, Gabriele", "sameAs": [], "familyName": "Scheler", "additionalName": "", "givenName": "Gabriele", "email": ""}], "title": "Universality of Power Law Coding for Principal Neurons", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5610", "oai:arXiv.org:1410.5610"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": "  In this paper we document distributions for spike rates, synaptic weights and\nneural gains for principal neurons in various tissues and under different\nbehavioral conditions. We find a remarkable consistency of a power-law,\nspecifically lognormal, distribution across observations from auditory or\nvisual cortex as well as midbrain nuclei, cerebellar Purkinje cells and\nstriatal medium spiny neurons. An exception is documented for fast-spiking\ninterneurons, as non-coding neurons, which seem to follow a normal\ndistribution. The difference between strongly recurrent and transfer\nconnectivity (cortex vs. striatum and cerebellum), or the level of activation\n(low in cortex, high in Purkinje cells and midbrain nuclei) seems to be\nirrelevant for these distributions. This has certain implications on neural\ncoding. In particular, logarithmic scale distribution of neuronal output\nappears as a structural phenomenon that is always present in coding neurons. We\nalso report data for a lognormal distribution of synaptic strengths in cortex,\ncerebellum and hippocampus and for intrinsic excitability in striatum, cortex\nand cerebellum. We present a neural model for gain, weights and spike rates,\nspecifically matching the width of distributions. We discuss the data from the\nperspective of a hierarchical coding scheme with few sparse or top-level\nfeatures and many additional distributed low-level features. Logarithmic-scale\ncoding may solve an access problem by combining a local modular structure with\nfew high frequency contact points. Computational models may need to incorporate\nthese observations as primary constraints. More data are needed to consolidate\nthe observations.\n"}}], "languages": [null], "subjects": ["quantitative biology - neurons and cognition", "computer science - neural and evolutionary computing"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5610"}}, {"publisher": {"name": ""}, "description": "  Sybil accounts are fake identities created to unfairly increase the power or\nresources of a single malicious user. Researchers have long known about the\nexistence of Sybil accounts in online communities such as file-sharing systems,\nbut have not been able to perform large scale measurements to detect them or\nmeasure their activities. In this paper, we describe our efforts to detect,\ncharacterize and understand Sybil account activity in the Renren online social\nnetwork (OSN). We use ground truth provided by Renren Inc. to build measurement\nbased Sybil account detectors, and deploy them on Renren to detect over 100,000\nSybil accounts. We study these Sybil accounts, as well as an additional 560,000\nSybil accounts caught by Renren, and analyze their link creation behavior. Most\ninterestingly, we find that contrary to prior conjecture, Sybil accounts in\nOSNs do not form tight-knit communities. Instead, they integrate into the\nsocial graph just like normal users. Using link creation timestamps, we verify\nthat the large majority of links between Sybil accounts are created\naccidentally, unbeknownst to the attacker. Overall, only a very small portion\nof Sybil accounts are connected to other Sybils with social links. Our study\nshows that existing Sybil defenses are unlikely to succeed in today's OSNs, and\nwe must design new techniques to effectively detect and defend against Sybil\nattacks.\n", "contributors": [{"name": "Yang, Zhi", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Zhi", "email": ""}, {"name": "Wilson, Christo", "sameAs": [], "familyName": "Wilson", "additionalName": "", "givenName": "Christo", "email": ""}, {"name": "Wang, Xiao", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Xiao", "email": ""}, {"name": "Gao, Tingting", "sameAs": [], "familyName": "Gao", "additionalName": "", "givenName": "Tingting", "email": ""}, {"name": "Zhao, Ben Y.", "sameAs": [], "familyName": "Zhao", "additionalName": "Y.", "givenName": "Ben", "email": ""}, {"name": "Dai, Yafei", "sameAs": [], "familyName": "Dai", "additionalName": "", "givenName": "Yafei", "email": ""}], "title": "Uncovering Social Network Sybils in the Wild", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-06-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1106.5321", "oai:arXiv.org:1106.5321"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Sybil accounts are fake identities created to unfairly increase the power or\nresources of a single malicious user. Researchers have long known about the\nexistence of Sybil accounts in online communities such as file-sharing systems,\nbut have not been able to perform large scale measurements to detect them or\nmeasure their activities. In this paper, we describe our efforts to detect,\ncharacterize and understand Sybil account activity in the Renren online social\nnetwork (OSN). We use ground truth provided by Renren Inc. to build measurement\nbased Sybil account detectors, and deploy them on Renren to detect over 100,000\nSybil accounts. We study these Sybil accounts, as well as an additional 560,000\nSybil accounts caught by Renren, and analyze their link creation behavior. Most\ninterestingly, we find that contrary to prior conjecture, Sybil accounts in\nOSNs do not form tight-knit communities. Instead, they integrate into the\nsocial graph just like normal users. Using link creation timestamps, we verify\nthat the large majority of links between Sybil accounts are created\naccidentally, unbeknownst to the attacker. Overall, only a very small portion\nof Sybil accounts are connected to other Sybils with social links. Our study\nshows that existing Sybil defenses are unlikely to succeed in today's OSNs, and\nwe must design new techniques to effectively detect and defend against Sybil\nattacks.\n", "Comment: 7 pages"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1106.5321"}}, {"publisher": {"name": ""}, "description": "  We consider the problem of covering hypersphere by a set of spherical\nhypercaps. This sort of problem has numerous practical applications such as\nerror correcting codes and reverse k-nearest neighbor problem. Using the\nreduction of non degenerated concave quadratic programming (QP) problem, we\ndemonstrate that spherical coverage verification is NP hard. We propose a\nrecursive algorithm based on reducing the problem to several lower dimension\nsubproblems. We test the performance of the proposed algorithm on a number of\ngenerated constellations. We demonstrate that the proposed algorithm, in spite\nof its exponential worst-case complexity, is applicable in practice. In\ncontrast, our results indicate that spherical coverage verification using QP\nsolvers that utilize heuristics, due to numerical instability, may produce\nfalse positives.\n", "contributors": [{"name": "Petkovic, Marko D.", "sameAs": [], "familyName": "Petkovic", "additionalName": "D.", "givenName": "Marko", "email": ""}, {"name": "Pokrajac, Dragoljub", "sameAs": [], "familyName": "Pokrajac", "additionalName": "", "givenName": "Dragoljub", "email": ""}, {"name": "Latecki, Longin Jan", "sameAs": [], "familyName": "Latecki", "additionalName": "Jan", "givenName": "Longin", "email": ""}], "title": "Spherical coverage verification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-09-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.2361", "oai:arXiv.org:1109.2361"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We consider the problem of covering hypersphere by a set of spherical\nhypercaps. This sort of problem has numerous practical applications such as\nerror correcting codes and reverse k-nearest neighbor problem. Using the\nreduction of non degenerated concave quadratic programming (QP) problem, we\ndemonstrate that spherical coverage verification is NP hard. We propose a\nrecursive algorithm based on reducing the problem to several lower dimension\nsubproblems. We test the performance of the proposed algorithm on a number of\ngenerated constellations. We demonstrate that the proposed algorithm, in spite\nof its exponential worst-case complexity, is applicable in practice. In\ncontrast, our results indicate that spherical coverage verification using QP\nsolvers that utilize heuristics, due to numerical instability, may produce\nfalse positives.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - computational complexity", "mathematics - numerical analysis", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.2361"}}, {"publisher": {"name": ""}, "description": "  This chapter deals with decentralized learning algorithms for in-network\nprocessing of graph-valued data. A generic learning problem is formulated and\nrecast into a separable form, which is iteratively minimized using the\nalternating-direction method of multipliers (ADMM) so as to gain the desired\ndegree of parallelization. Without exchanging elements from the distributed\ntraining sets and keeping inter-node communications at affordable levels, the\nlocal (per-node) learners consent to the desired quantity inferred globally,\nmeaning the one obtained if the entire training data set were centrally\navailable. Impact of the decentralized learning framework to contemporary\nwireless communications and networking tasks is illustrated through case\nstudies including target tracking using wireless sensor networks, unveiling\nInternet traffic anomalies, power system state estimation, as well as spectrum\ncartography for wireless cognitive radio networks.\n", "contributors": [{"name": "Giannakis, Georgios B.", "sameAs": [], "familyName": "Giannakis", "additionalName": "B.", "givenName": "Georgios", "email": ""}, {"name": "Ling, Qing", "sameAs": [], "familyName": "Ling", "additionalName": "", "givenName": "Qing", "email": ""}, {"name": "Mateos, Gonzalo", "sameAs": [], "familyName": "Mateos", "additionalName": "", "givenName": "Gonzalo", "email": ""}, {"name": "Schizas, Ioannis D.", "sameAs": [], "familyName": "Schizas", "additionalName": "D.", "givenName": "Ioannis", "email": ""}, {"name": "Zhu, Hao", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "Hao", "email": ""}], "title": "Decentralized learning for wireless communications and networking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08855", "oai:arXiv.org:1503.08855"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  This chapter deals with decentralized learning algorithms for in-network\nprocessing of graph-valued data. A generic learning problem is formulated and\nrecast into a separable form, which is iteratively minimized using the\nalternating-direction method of multipliers (ADMM) so as to gain the desired\ndegree of parallelization. Without exchanging elements from the distributed\ntraining sets and keeping inter-node communications at affordable levels, the\nlocal (per-node) learners consent to the desired quantity inferred globally,\nmeaning the one obtained if the entire training data set were centrally\navailable. Impact of the decentralized learning framework to contemporary\nwireless communications and networking tasks is illustrated through case\nstudies including target tracking using wireless sensor networks, unveiling\nInternet traffic anomalies, power system state estimation, as well as spectrum\ncartography for wireless cognitive radio networks.\n", "Comment: Contributed chapter to appear in Splitting Methods in Communication\n  and Imaging, Science and Engineering, R. Glowinski, S. Osher, and W. Yin,\n  Editors, New York, Springer, 2015"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - systems and control", "computer science - learning", "computer science - multiagent systems", "computer science - information theory", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08855"}}, {"publisher": {"name": ""}, "description": "  Transmission control protocol (TCP) was originally designed for fixed\nnetworks to provide the reliability of the data delivery. The improvement of\nTCP performance was also achieved with different types of networks with\nintroduction of new TCP variants. However, there are still many factors that\naffect performance of TCP. Mobility is one of the major affects on TCP\nperformance in wireless networks and MANET (Mobile Ad Hoc Network). To\ndetermine the best TCP variant from mobility point of view, we simulate some\nTCP variants in real life scenario. This paper addresses the performance of TCP\nvariants such as TCP-Tahoe, TCP-Reno, TCP-New Reno, TCPVegas,TCP-SACK and\nTCP-Westwood from mobility point of view.The scenarios presented in this paper\nare supported by Zone routing Protocol (ZRP) with integration of random\nwaypoint mobility model in MANET area. The scenario shows the speed of walking\nperson to a vehicle and suited particularly for mountainous and deserted areas.\nOn the basis of simulation, we analyze Round trip time (RTT) fairness,\nEnd-to-End delay, control overhead, number of broken links during the delivery\nof data. Finally analyzed parameters help to find out the best TCP variant.\n", "contributors": [{"name": "Elmannai, Wafa", "sameAs": [], "familyName": "Elmannai", "additionalName": "", "givenName": "Wafa", "email": ""}, {"name": "Razaque, Abdul", "sameAs": [], "familyName": "Razaque", "additionalName": "", "givenName": "Abdul", "email": ""}, {"name": "Elleithy, Khaled", "sameAs": [], "familyName": "Elleithy", "additionalName": "", "givenName": "Khaled", "email": ""}], "title": "Simulation based Study of TCP Variants in Hybrid Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5127", "oai:arXiv.org:1410.5127"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Transmission control protocol (TCP) was originally designed for fixed\nnetworks to provide the reliability of the data delivery. The improvement of\nTCP performance was also achieved with different types of networks with\nintroduction of new TCP variants. However, there are still many factors that\naffect performance of TCP. Mobility is one of the major affects on TCP\nperformance in wireless networks and MANET (Mobile Ad Hoc Network). To\ndetermine the best TCP variant from mobility point of view, we simulate some\nTCP variants in real life scenario. This paper addresses the performance of TCP\nvariants such as TCP-Tahoe, TCP-Reno, TCP-New Reno, TCPVegas,TCP-SACK and\nTCP-Westwood from mobility point of view.The scenarios presented in this paper\nare supported by Zone routing Protocol (ZRP) with integration of random\nwaypoint mobility model in MANET area. The scenario shows the speed of walking\nperson to a vehicle and suited particularly for mountainous and deserted areas.\nOn the basis of simulation, we analyze Round trip time (RTT) fairness,\nEnd-to-End delay, control overhead, number of broken links during the delivery\nof data. Finally analyzed parameters help to find out the best TCP variant.\n", "Comment: 09 pages, 09 pages, In proceedings of international conference on\n  2011 ASEE Northeast Section Conference, At University of Hartford,\n  Connecticut, USA"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-10-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5127"}}, {"publisher": {"name": ""}, "description": "  We propose a new methodology to estimate the spatial reuse of CSMA-like\nscheduling. Instead of focusing on spatial configurations of users, we model\nthe interferences between users as a random graph. Using configuration models\nfor random graphs, we show how the properties of the medium access mechanism\nare captured by some deterministic differential equations, when the size of the\ngraph gets large. Performance indicators such as the probability of connection\nof a given node can then be efficiently computed from these equations. We also\nperform simulations to illustrate the results on different types of random\ngraphs. Even on spatial structures, these estimates get very accurate as soon\nas the variance of the interference is not negligible.\n", "contributors": [{"name": "Bermolen, Paola", "sameAs": [], "familyName": "Bermolen", "additionalName": "", "givenName": "Paola", "email": ""}, {"name": "Jonckheere, Matthieu", "sameAs": [], "familyName": "Jonckheere", "additionalName": "", "givenName": "Matthieu", "email": ""}, {"name": "Larroca, Federico", "sameAs": [], "familyName": "Larroca", "additionalName": "", "givenName": "Federico", "email": ""}, {"name": "Moyal, Pascal", "sameAs": [], "familyName": "Moyal", "additionalName": "", "givenName": "Pascal", "email": ""}], "title": "Estimating the Spatial Reuse with Configuration Models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0143", "oai:arXiv.org:1411.0143"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We propose a new methodology to estimate the spatial reuse of CSMA-like\nscheduling. Instead of focusing on spatial configurations of users, we model\nthe interferences between users as a random graph. Using configuration models\nfor random graphs, we show how the properties of the medium access mechanism\nare captured by some deterministic differential equations, when the size of the\ngraph gets large. Performance indicators such as the probability of connection\nof a given node can then be efficiently computed from these equations. We also\nperform simulations to illustrate the results on different types of random\ngraphs. Even on spatial structures, these estimates get very accurate as soon\nas the variance of the interference is not negligible.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - performance"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0143"}}, {"publisher": {"name": ""}, "description": "  The listsize capacity of a discrete memoryless channel is the largest\ntransmission rate for which the expectation---or, more generally, the $\\rho$-th\nmoment---of the number of messages that could have produced the output of the\nchannel approaches one as the blocklength tends to infinity. We show that for\nchannels with feedback this rate is upper-bounded by the maximum of Gallager's\n$E_0$ function divided by $\\rho$, and that equality holds when the zero-error\ncapacity of the channel is positive. To establish this inequality we prove that\nfeedback does not increase the cutoff rate.\n", "contributors": [{"name": "Bunte, Christoph", "sameAs": [], "familyName": "Bunte", "additionalName": "", "givenName": "Christoph", "email": ""}, {"name": "Lapidoth, Amos", "sameAs": [], "familyName": "Lapidoth", "additionalName": "", "givenName": "Amos", "email": ""}], "title": "On the listsize capacity with feedback", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-11-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1311.0195", "doi:10.1109/TIT.2014.2355815", "oai:arXiv.org:1311.0195"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The listsize capacity of a discrete memoryless channel is the largest\ntransmission rate for which the expectation---or, more generally, the $\\rho$-th\nmoment---of the number of messages that could have produced the output of the\nchannel approaches one as the blocklength tends to infinity. We show that for\nchannels with feedback this rate is upper-bounded by the maximum of Gallager's\n$E_0$ function divided by $\\rho$, and that equality holds when the zero-error\ncapacity of the channel is positive. To establish this inequality we prove that\nfeedback does not increase the cutoff rate.\n", "Comment: 26 pages, submitted to IEEE Transactions on Information Theory,\n  presented in part at the 2013 IEEE Information Theory Workshop"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1311.0195"}}, {"publisher": {"name": ""}, "description": "  Even with impressive advances in automated formal methods, certain problems\nin system verification and synthesis remain challenging. Examples include the\nverification of quantitative properties of software involving constraints on\ntiming and energy consumption, and the automatic synthesis of systems from\nspecifications. The major challenges include environment modeling,\nincompleteness in specifications, and the complexity of underlying decision\nproblems.\n  This position paper proposes sciduction, an approach to tackle these\nchallenges by integrating inductive inference, deductive reasoning, and\nstructure hypotheses. Deductive reasoning, which leads from general rules or\nconcepts to conclusions about specific problem instances, includes techniques\nsuch as logical inference and constraint solving. Inductive inference, which\ngeneralizes from specific instances to yield a concept, includes algorithmic\nlearning from examples. Structure hypotheses are used to define the class of\nartifacts, such as invariants or program fragments, generated during\nverification or synthesis. Sciduction constrains inductive and deductive\nreasoning using structure hypotheses, and actively combines inductive and\ndeductive reasoning: for instance, deductive techniques generate examples for\nlearning, and inductive reasoning is used to guide the deductive engines.\n  We illustrate this approach with three applications: (i) timing analysis of\nsoftware; (ii) synthesis of loop-free programs, and (iii) controller synthesis\nfor hybrid systems. Some future applications are also discussed.\n", "contributors": [{"name": "Seshia, Sanjit A.", "sameAs": [], "familyName": "Seshia", "additionalName": "A.", "givenName": "Sanjit", "email": ""}], "title": "Sciduction: Combining Induction, Deduction, and Structure for\n  Verification and Synthesis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-01-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1201.0979", "oai:arXiv.org:1201.0979"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Even with impressive advances in automated formal methods, certain problems\nin system verification and synthesis remain challenging. Examples include the\nverification of quantitative properties of software involving constraints on\ntiming and energy consumption, and the automatic synthesis of systems from\nspecifications. The major challenges include environment modeling,\nincompleteness in specifications, and the complexity of underlying decision\nproblems.\n  This position paper proposes sciduction, an approach to tackle these\nchallenges by integrating inductive inference, deductive reasoning, and\nstructure hypotheses. Deductive reasoning, which leads from general rules or\nconcepts to conclusions about specific problem instances, includes techniques\nsuch as logical inference and constraint solving. Inductive inference, which\ngeneralizes from specific instances to yield a concept, includes algorithmic\nlearning from examples. Structure hypotheses are used to define the class of\nartifacts, such as invariants or program fragments, generated during\nverification or synthesis. Sciduction constrains inductive and deductive\nreasoning using structure hypotheses, and actively combines inductive and\ndeductive reasoning: for instance, deductive techniques generate examples for\nlearning, and inductive reasoning is used to guide the deductive engines.\n  We illustrate this approach with three applications: (i) timing analysis of\nsoftware; (ii) synthesis of loop-free programs, and (iii) controller synthesis\nfor hybrid systems. Some future applications are also discussed.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - logic in computer science", "c.3", "i.2.6", "i.2.2", "b.5.2", "i.2.3", "computer science - programming languages"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1201.0979"}}, {"publisher": {"name": ""}, "description": "  The digitization of the medical data has been a sensitive topic. In modern\ntimes laws such as the HIPAA provide some guidelines for electronic\ntransactions in medical data to prevent attacks and fraudulent usage of private\ninformation. In our paper, we explore an architecture that uses hybrid\ncomputing with decentralized key management and show how it is suitable in\npreventing a special form of re-identification attack that we name as the\nre-assembly attack. This architecture would be able to use current\ninfrastructure from mobile phones to server certificates and cloud based\ndecentralized storage models in an efficient way to provide a reliable model\nfor communication of medical data. We encompass entities including patients,\ndoctors, insurance agents, emergency contacts, researchers, medical test\nlaboratories and technicians. This is a complete architecture that provides\npatients with a good level of privacy, secure communication and more direct\ncontrol.\n", "contributors": [{"name": "Sharma, Rajesh", "sameAs": [], "familyName": "Sharma", "additionalName": "", "givenName": "Rajesh", "email": ""}, {"name": "Subramanian, Deepak", "sameAs": [], "familyName": "Subramanian", "additionalName": "", "givenName": "Deepak", "email": ""}, {"name": "Srirama, Satish N.", "sameAs": [], "familyName": "Srirama", "additionalName": "N.", "givenName": "Satish", "email": ""}], "title": "DAPriv: Decentralized architecture for preserving the privacy of medical\n  data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5696", "oai:arXiv.org:1410.5696"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The digitization of the medical data has been a sensitive topic. In modern\ntimes laws such as the HIPAA provide some guidelines for electronic\ntransactions in medical data to prevent attacks and fraudulent usage of private\ninformation. In our paper, we explore an architecture that uses hybrid\ncomputing with decentralized key management and show how it is suitable in\npreventing a special form of re-identification attack that we name as the\nre-assembly attack. This architecture would be able to use current\ninfrastructure from mobile phones to server certificates and cloud based\ndecentralized storage models in an efficient way to provide a reliable model\nfor communication of medical data. We encompass entities including patients,\ndoctors, insurance agents, emergency contacts, researchers, medical test\nlaboratories and technicians. This is a complete architecture that provides\npatients with a good level of privacy, secure communication and more direct\ncontrol.\n", "Comment: 7 pages"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - computers and society"], "providerUpdatedDateTime": "2014-10-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5696"}}, {"publisher": {"name": ""}, "description": "  Topological data analysis offers a rich source of valuable information to\nstudy vision problems. Yet, so far we lack a theoretically sound connection to\npopular kernel-based learning techniques, such as kernel SVMs or kernel PCA. In\nthis work, we establish such a connection by designing a multi-scale kernel for\npersistence diagrams, a stable summary representation of topological features\nin data. We show that this kernel is positive definite and prove its stability\nwith respect to the 1-Wasserstein distance. Experiments on two benchmark\ndatasets for 3D shape classification/retrieval and texture recognition show\nconsiderable performance gains of the proposed method compared to an\nalternative approach that is based on the recently introduced persistence\nlandscapes.\n", "contributors": [{"name": "Reininghaus, Jan", "sameAs": [], "familyName": "Reininghaus", "additionalName": "", "givenName": "Jan", "email": ""}, {"name": "Huber, Stefan", "sameAs": [], "familyName": "Huber", "additionalName": "", "givenName": "Stefan", "email": ""}, {"name": "Bauer, Ulrich", "sameAs": [], "familyName": "Bauer", "additionalName": "", "givenName": "Ulrich", "email": ""}, {"name": "Kwitt, Roland", "sameAs": [], "familyName": "Kwitt", "additionalName": "", "givenName": "Roland", "email": ""}], "title": "A Stable Multi-Scale Kernel for Topological Machine Learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6821", "oai:arXiv.org:1412.6821"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  Topological data analysis offers a rich source of valuable information to\nstudy vision problems. Yet, so far we lack a theoretically sound connection to\npopular kernel-based learning techniques, such as kernel SVMs or kernel PCA. In\nthis work, we establish such a connection by designing a multi-scale kernel for\npersistence diagrams, a stable summary representation of topological features\nin data. We show that this kernel is positive definite and prove its stability\nwith respect to the 1-Wasserstein distance. Experiments on two benchmark\ndatasets for 3D shape classification/retrieval and texture recognition show\nconsiderable performance gains of the proposed method compared to an\nalternative approach that is based on the recently introduced persistence\nlandscapes.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6821"}}, {"publisher": {"name": ""}, "description": "  Motivated by the problem of computing investment portfolio weightings we\ninvestigate various methods of clustering as alternatives to traditional\nmean-variance approaches. Such methods can have significant benefits from a\npractical point of view since they remove the need to invert a sample\ncovariance matrix, which can suffer from estimation error and will almost\ncertainly be non-stationary. The general idea is to find groups of assets which\nshare similar return characteristics over time and treat each group as a single\ncomposite asset. We then apply inverse volatility weightings to these new\ncomposite assets. In the course of our investigation we devise a method of\nclustering based on triangular potentials and we present associated theoretical\nresults as well as various examples based on synthetic data.\n", "contributors": [{"name": "Pacchiano, Aldo", "sameAs": [], "familyName": "Pacchiano", "additionalName": "", "givenName": "Aldo", "email": ""}, {"name": "Williams, Oliver", "sameAs": [], "familyName": "Williams", "additionalName": "", "givenName": "Oliver", "email": ""}], "title": "Real time clustering of time series using triangular potentials", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.05090", "oai:arXiv.org:1502.05090"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Motivated by the problem of computing investment portfolio weightings we\ninvestigate various methods of clustering as alternatives to traditional\nmean-variance approaches. Such methods can have significant benefits from a\npractical point of view since they remove the need to invert a sample\ncovariance matrix, which can suffer from estimation error and will almost\ncertainly be non-stationary. The general idea is to find groups of assets which\nshare similar return characteristics over time and treat each group as a single\ncomposite asset. We then apply inverse volatility weightings to these new\ncomposite assets. In the course of our investigation we devise a method of\nclustering based on triangular potentials and we present associated theoretical\nresults as well as various examples based on synthetic data.\n", "Comment: AIFU15"]}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-02-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.05090"}}, {"publisher": {"name": ""}, "description": "  We present a solution to the sign problem in dynamical random matrix\nsimulations of a two-matrix model at nonzero chemical potential. The sign\nproblem, caused by the complex fermion determinants, is solved by gathering the\nmatrices into subsets, whose sums of determinants are real and positive even\nthough their cardinality only grows linearly with the matrix size. A detailed\nproof of this positivity theorem is given for an arbitrary number of fermion\nflavors. We performed importance sampling Monte Carlo simulations to compute\nthe chiral condensate and the quark number density for varying chemical\npotential and volume. The statistical errors on the results only show a mild\ndependence on the matrix size and chemical potential, which confirms the\nabsence of sign problem in the subset method. This strongly contrasts with the\nexponential growth of the statistical error in standard reweighting methods,\nwhich was also analyzed quantitatively using the subset method. Finally, we\nshow how the method elegantly resolves the Silver Blaze puzzle in the\nmicroscopic limit of the matrix model, where it is equivalent to QCD.\n", "contributors": [{"name": "Bloch, Jacques", "sameAs": [], "familyName": "Bloch", "additionalName": "", "givenName": "Jacques", "email": ""}], "title": "A subset solution to the sign problem in random matrix simulations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-05-24", "2012-10-12"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.5500", "Phys. Rev. D 86, 074505 (2012)", "doi:10.1103/PhysRevD.86.074505", "oai:arXiv.org:1205.5500"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:hep-lat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We present a solution to the sign problem in dynamical random matrix\nsimulations of a two-matrix model at nonzero chemical potential. The sign\nproblem, caused by the complex fermion determinants, is solved by gathering the\nmatrices into subsets, whose sums of determinants are real and positive even\nthough their cardinality only grows linearly with the matrix size. A detailed\nproof of this positivity theorem is given for an arbitrary number of fermion\nflavors. We performed importance sampling Monte Carlo simulations to compute\nthe chiral condensate and the quark number density for varying chemical\npotential and volume. The statistical errors on the results only show a mild\ndependence on the matrix size and chemical potential, which confirms the\nabsence of sign problem in the subset method. This strongly contrasts with the\nexponential growth of the statistical error in standard reweighting methods,\nwhich was also analyzed quantitatively using the subset method. Finally, we\nshow how the method elegantly resolves the Silver Blaze puzzle in the\nmicroscopic limit of the matrix model, where it is equivalent to QCD.\n", "Comment: 18 pages, 11 figures, as published in Phys. Rev. D; added references;\n  in Sec. VB: added discussion of model satisfying the Silver Blaze for all N\n  (proof in Appendix E)"]}}], "languages": [null], "subjects": ["physics - computational physics", "condensed matter - statistical mechanics", "high energy physics - lattice"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.5500"}}, {"publisher": {"name": ""}, "description": "  We present an auditory stimulus optimization and a pilot study of a two-step\ninput speller application combined with a spatial auditory brain-computer\ninterface (saBCI) for paralyzed users. The application has been developed for\n45, out of 48 defining the full set, Japanese kana characters in a two-step\ninput procedure setting for an easy-to-use BCI-speller interface. The user\nfirst selects the representative letter of a subset, defining the second step.\nIn the second step, the final choice is made. At each interfacing step, the\nchoices are classified based on the P300 event related potential (ERP)\nresponses captured in the EEG, as in the classic oddball paradigm. The BCI\nonline experiment and EEG responses classification results of the pilot study\nconfirm the effectiveness of the proposed spelling method.\n", "contributors": [{"name": "Chang, Moonjeong", "sameAs": [], "familyName": "Chang", "additionalName": "", "givenName": "Moonjeong", "email": ""}, {"name": "Rutkowski, Tomasz M.", "sameAs": [], "familyName": "Rutkowski", "additionalName": "M.", "givenName": "Tomasz", "email": ""}], "title": "Two-step Input Spatial Auditory BCI for Japanese Kana Characters", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02903", "oai:arXiv.org:1503.02903"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": ["  We present an auditory stimulus optimization and a pilot study of a two-step\ninput speller application combined with a spatial auditory brain-computer\ninterface (saBCI) for paralyzed users. The application has been developed for\n45, out of 48 defining the full set, Japanese kana characters in a two-step\ninput procedure setting for an easy-to-use BCI-speller interface. The user\nfirst selects the representative letter of a subset, defining the second step.\nIn the second step, the final choice is made. At each interfacing step, the\nchoices are classified based on the P300 event related potential (ERP)\nresponses captured in the EEG, as in the classic oddball paradigm. The BCI\nonline experiment and EEG responses classification results of the pilot study\nconfirm the effectiveness of the proposed spelling method.\n", "Comment: 7 pages, 2 figures, accepted for publication in Advances in Cognitive\n  Neurodynamics Volume 5 -- Proceedings of the 5th International Conference on\n  Cognitive Neurodynamics (ICCN 2015)"]}}], "languages": [null], "subjects": ["h.1.2", "quantitative biology - neurons and cognition", "computer science - human-computer interaction", "h.5.2"], "providerUpdatedDateTime": "2015-03-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02903"}}, {"publisher": {"name": ""}, "description": "  We revisit the complexity of online computation in the cell probe model. We\nconsider a class of problems where we are first given a fixed pattern or vector\n$F$ of $n$ symbols and then one symbol arrives at a time in a stream. After\neach symbol has arrived we must output some function of $F$ and the $n$-length\nsuffix of the arriving stream. Cell probe bounds of $\\Omega(\\delta\\lg{n}/w)$\nhave previously been shown for both convolution and Hamming distance in this\nsetting, where $\\delta$ is the size of a symbol in bits and\n$w\\in\\Omega(\\lg{n})$ is the cell size in bits. However, when $\\delta$ is a\nconstant, as it is in many natural situations, these previous results no longer\ngive us non-trivial bounds.\n  We introduce a new lop-sided information transfer proof technique which\nenables us to prove meaningful lower bounds even for constant size input\nalphabets. We use our new framework to prove an amortised cell probe lower\nbound of $\\Omega(\\lg^2 n/(w\\cdot \\lg \\lg n))$ time per arriving bit for an\nonline version of a well studied problem known as pattern matching with address\nerrors. This is the first non-trivial cell probe lower bound for any online\nproblem on bit streams that still holds when the cell sizes are large. We also\nshow the same bound for online convolution conditioned on a new combinatorial\nconjecture related to Toeplitz matrices.\n", "contributors": [{"name": "Clifford, Raphael", "sameAs": [], "familyName": "Clifford", "additionalName": "", "givenName": "Raphael", "email": ""}, {"name": "Jalsenius, Markus", "sameAs": [], "familyName": "Jalsenius", "additionalName": "", "givenName": "Markus", "email": ""}, {"name": "Sach, Benjamin", "sameAs": [], "familyName": "Sach", "additionalName": "", "givenName": "Benjamin", "email": ""}], "title": "The complexity of computation in bit streams", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.00834", "oai:arXiv.org:1504.00834"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We revisit the complexity of online computation in the cell probe model. We\nconsider a class of problems where we are first given a fixed pattern or vector\n$F$ of $n$ symbols and then one symbol arrives at a time in a stream. After\neach symbol has arrived we must output some function of $F$ and the $n$-length\nsuffix of the arriving stream. Cell probe bounds of $\\Omega(\\delta\\lg{n}/w)$\nhave previously been shown for both convolution and Hamming distance in this\nsetting, where $\\delta$ is the size of a symbol in bits and\n$w\\in\\Omega(\\lg{n})$ is the cell size in bits. However, when $\\delta$ is a\nconstant, as it is in many natural situations, these previous results no longer\ngive us non-trivial bounds.\n  We introduce a new lop-sided information transfer proof technique which\nenables us to prove meaningful lower bounds even for constant size input\nalphabets. We use our new framework to prove an amortised cell probe lower\nbound of $\\Omega(\\lg^2 n/(w\\cdot \\lg \\lg n))$ time per arriving bit for an\nonline version of a well studied problem known as pattern matching with address\nerrors. This is the first non-trivial cell probe lower bound for any online\nproblem on bit streams that still holds when the cell sizes are large. We also\nshow the same bound for online convolution conditioned on a new combinatorial\nconjecture related to Toeplitz matrices.\n", "Comment: 24 pages"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.00834"}}, {"publisher": {"name": ""}, "description": "  Rough sets were proposed to deal with the vagueness and incompleteness of\nknowledge in information systems. There are may optimization issues in this\nfield such as attribute reduction. Matroids generalized from matrices are\nwidely used in optimization. Therefore, it is necessary to connect matroids\nwith rough sets. In this paper, we take field into consideration and introduce\nmatrix to study rough sets through vector matroids. First, a matrix\nrepresentation of an equivalence relation is proposed, and then a matroidal\nstructure of rough sets over a field is presented by the matrix. Second, the\nproperties of the matroidal structure including circuits, bases and so on are\nstudied through two special matrix solution spaces, especially null space.\nThird, over a binary field, we construct an equivalence relation from matrix\nnull space, and establish an algebra isomorphism from the collection of\nequivalence relations to the collection of sets, which any member is a family\nof the minimal non-empty sets that are supports of members of null space of a\nbinary dependence matrix. In a word, matrix provides a new viewpoint to study\nrough sets.\n", "contributors": [{"name": "Huang, Aiping", "sameAs": [], "familyName": "Huang", "additionalName": "", "givenName": "Aiping", "email": ""}, {"name": "Zhu, William", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "William", "email": ""}], "title": "Matrix approach to rough sets through vector matroids over a field", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-11-03", "2013-03-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1211.0611", "oai:arXiv.org:1211.0611"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Rough sets were proposed to deal with the vagueness and incompleteness of\nknowledge in information systems. There are may optimization issues in this\nfield such as attribute reduction. Matroids generalized from matrices are\nwidely used in optimization. Therefore, it is necessary to connect matroids\nwith rough sets. In this paper, we take field into consideration and introduce\nmatrix to study rough sets through vector matroids. First, a matrix\nrepresentation of an equivalence relation is proposed, and then a matroidal\nstructure of rough sets over a field is presented by the matrix. Second, the\nproperties of the matroidal structure including circuits, bases and so on are\nstudied through two special matrix solution spaces, especially null space.\nThird, over a binary field, we construct an equivalence relation from matrix\nnull space, and establish an algebra isomorphism from the collection of\nequivalence relations to the collection of sets, which any member is a family\nof the minimal non-empty sets that are supports of members of null space of a\nbinary dependence matrix. In a word, matrix provides a new viewpoint to study\nrough sets.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1211.0611"}}, {"publisher": {"name": ""}, "description": "  A principled approach to the design of program verification and con-\nstruction tools is applied to separation logic. The control flow is modelled by\npower series with convolution as separating conjunction. A generic construction\nlifts resource monoids to assertion and predicate transformer quantales. The\ndata flow is captured by concrete store/heap models. These are linked to the\nseparation algebra by soundness proofs. Verification conditions and\ntransformation laws are derived by equational reasoning within the predicate\ntransformer quantale. This separation of concerns makes an implementation in\nthe Isabelle/HOL proof as- sistant simple and highly automatic. The resulting\ntool is correct by construction; it is explained on the classical linked list\nreversal example.\n", "contributors": [{"name": "Dongol, Brijesh", "sameAs": [], "familyName": "Dongol", "additionalName": "", "givenName": "Brijesh", "email": ""}, {"name": "Gomes, Victor B. F.", "sameAs": [], "familyName": "Gomes", "additionalName": "B. F.", "givenName": "Victor", "email": ""}, {"name": "Struth, Georg", "sameAs": [], "familyName": "Struth", "additionalName": "", "givenName": "Georg", "email": ""}], "title": "Principles for Verification Tools: Separation Logic", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4439", "oai:arXiv.org:1410.4439"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  A principled approach to the design of program verification and con-\nstruction tools is applied to separation logic. The control flow is modelled by\npower series with convolution as separating conjunction. A generic construction\nlifts resource monoids to assertion and predicate transformer quantales. The\ndata flow is captured by concrete store/heap models. These are linked to the\nseparation algebra by soundness proofs. Verification conditions and\ntransformation laws are derived by equational reasoning within the predicate\ntransformer quantale. This separation of concerns makes an implementation in\nthe Isabelle/HOL proof as- sistant simple and highly automatic. The resulting\ntool is correct by construction; it is explained on the classical linked list\nreversal example.\n"}}], "languages": [null], "subjects": ["computer science - programming languages", "computer science - logic in computer science"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4439"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "This case study shows how an analytical architecture fault-modeling approach can be combined with confidence arguments to diagnose a time-sensitive design error in a control system and to provide evidence that proposed changes to the system address the problem. The analytical approach, based on the SAE Architecture Analysis and Design Language for its well-defined timing and fault behavior semantics, demonstrates that such hard-to-test errors can be discovered and corrected early in the lifecycle, thereby reducing rework cost. The case study shows that by combining the analytical approach with confidence maps, we can present a structured argument that system requirements have been met and problems in the design have been addressed adequately\u2014increasing our confidence in the system quality. The case study analyzes an aircraft engine control system that manages fuel flow with a stepper motor. The original design was developed and verified in a commercial model-based development environment without discovering the potential for missed step commanding. During system tests, actual fuel flow did not correspond to the desired fuel flow under certain circumstances. The problem was traced to missed execution of commanded steps due to variation in execution time.", "contributors": [{"name": "Feiler, Peter", "sameAs": [], "familyName": "Feiler", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Goodenough, John", "sameAs": [], "familyName": "Goodenough", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Weinstock, Charles B.", "sameAs": [], "familyName": "Weinstock", "additionalName": "B.", "givenName": "Charles", "email": ""}, {"name": "Delange, Julian", "sameAs": [], "familyName": "Delange", "additionalName": "", "givenName": "Julian", "email": ""}, {"name": "Ernst, Neil", "sameAs": [], "familyName": "Ernst", "additionalName": "", "givenName": "Neil", "email": ""}], "title": "Improving Quality Using Architecture Fault Analysis with Confidence Arguments", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2015-03-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/sei/826", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1826&amp;context=sei", "oai:repository.cmu.edu:sei-1826"]}}, {"name": "setSpec", "properties": {"setSpec": "publication:sei"}}, {"name": "description", "properties": {"description": "This case study shows how an analytical architecture fault-modeling approach can be combined with confidence arguments to diagnose a time-sensitive design error in a control system and to provide evidence that proposed changes to the system address the problem. The analytical approach, based on the SAE Architecture Analysis and Design Language for its well-defined timing and fault behavior semantics, demonstrates that such hard-to-test errors can be discovered and corrected early in the lifecycle, thereby reducing rework cost. The case study shows that by combining the analytical approach with confidence maps, we can present a structured argument that system requirements have been met and problems in the design have been addressed adequately\u2014increasing our confidence in the system quality. The case study analyzes an aircraft engine control system that manages fuel flow with a stepper motor. The original design was developed and verified in a commercial model-based development environment without discovering the potential for missed step commanding. During system tests, actual fuel flow did not correspond to the desired fuel flow under certain circumstances. The problem was traced to missed execution of commanded steps due to variation in execution time."}}], "languages": [null], "subjects": ["argumentation", "fault modeling", "software engineering", "software architecture", "requirements modeling", "computer sciences", "aadl", "error annex", "confidence maps"], "providerUpdatedDateTime": "2015-03-13T16:26:56", "uris": {"canonicalUri": "http://repository.cmu.edu/sei/826"}}, {"publisher": {"name": ""}, "description": "  Quantitative games are two-player zero-sum games played on directed weighted\ngraphs. Total-payoff games (that can be seen as a refinement of the\nwell-studied mean-payoff games) are the variant where the payoff of a play is\ncomputed as the sum of the weights. Our aim is to describe the first\npseudo-polynomial time algorithm for total-payoff games in the presence of\narbitrary weights. It consists of a non-trivial application of the value\niteration paradigm. Indeed, it requires to study, as a milestone, a refinement\nof these games, called min-cost reachability games, where we add a reachability\nobjective to one of the players. For these games, we give an efficient value\niteration algorithm to compute the values and optimal strategies (when they\nexist), that runs in pseudo-polynomial time. We also propose heuristics\nallowing one to possibly speed up the computations in both cases.\n", "contributors": [{"name": "Brihaye, Thomas", "sameAs": [], "familyName": "Brihaye", "additionalName": "", "givenName": "Thomas", "email": ""}, {"name": "Geeraerts, Gilles", "sameAs": [], "familyName": "Geeraerts", "additionalName": "", "givenName": "Gilles", "email": ""}, {"name": "Haddad, Axel", "sameAs": [], "familyName": "Haddad", "additionalName": "", "givenName": "Axel", "email": ""}, {"name": "Monmege, Benjamin", "sameAs": [], "familyName": "Monmege", "additionalName": "", "givenName": "Benjamin", "email": ""}], "title": "To Reach or not to Reach? Efficient Algorithms for Total-Payoff Games", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-18", "2015-02-12"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.5030", "oai:arXiv.org:1407.5030"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Quantitative games are two-player zero-sum games played on directed weighted\ngraphs. Total-payoff games (that can be seen as a refinement of the\nwell-studied mean-payoff games) are the variant where the payoff of a play is\ncomputed as the sum of the weights. Our aim is to describe the first\npseudo-polynomial time algorithm for total-payoff games in the presence of\narbitrary weights. It consists of a non-trivial application of the value\niteration paradigm. Indeed, it requires to study, as a milestone, a refinement\nof these games, called min-cost reachability games, where we add a reachability\nobjective to one of the players. For these games, we give an efficient value\niteration algorithm to compute the values and optimal strategies (when they\nexist), that runs in pseudo-polynomial time. We also propose heuristics\nallowing one to possibly speed up the computations in both cases.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2015-02-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.5030"}}, {"publisher": {"name": ""}, "description": "  The Discrete Morse Theory of Forman appeared to be useful for providing\nfiltration-preserving reductions of complexes in the study of persistent\nhomology. So far, the algorithms computing discrete Morse matchings have only\nbeen used for one-dimensional filtrations. This paper is perhaps the first\nattempt in the direction of extending such algorithms to multidimensional\nfiltrations. Initial framework related to Morse matchings for the\nmultidimensional setting is proposed, and a matching algorithm given by King,\nKnudson, and Mramor is extended in this direction. The correctness of the\nalgorithm is proved, and its complexity analyzed. The algorithm is used for\nestablishing a reduction of a simplicial complex to a smaller but not\nnecessarily optimal cellular complex. First experiments with filtrations of\ntriangular meshes are presented.\n", "contributors": [{"name": "Allili, Madjid", "sameAs": [], "familyName": "Allili", "additionalName": "", "givenName": "Madjid", "email": ""}, {"name": "Kaczynski, Tomasz", "sameAs": [], "familyName": "Kaczynski", "additionalName": "", "givenName": "Tomasz", "email": ""}, {"name": "Landi, Claudia", "sameAs": [], "familyName": "Landi", "additionalName": "", "givenName": "Claudia", "email": ""}], "title": "Reducing complexes in multidimensional persistent homology theory", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-30", "2015-03-12"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.8089", "oai:arXiv.org:1310.8089"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The Discrete Morse Theory of Forman appeared to be useful for providing\nfiltration-preserving reductions of complexes in the study of persistent\nhomology. So far, the algorithms computing discrete Morse matchings have only\nbeen used for one-dimensional filtrations. This paper is perhaps the first\nattempt in the direction of extending such algorithms to multidimensional\nfiltrations. Initial framework related to Morse matchings for the\nmultidimensional setting is proposed, and a matching algorithm given by King,\nKnudson, and Mramor is extended in this direction. The correctness of the\nalgorithm is proved, and its complexity analyzed. The algorithm is used for\nestablishing a reduction of a simplicial complex to a smaller but not\nnecessarily optimal cellular complex. First experiments with filtrations of\ntriangular meshes are presented.\n", "Comment: Construction of indexing map on vertices has been added"]}}], "languages": [null], "subjects": ["computer science - computational geometry"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.8089"}}, {"publisher": {"name": ""}, "description": "  Efforts to ensure reliable operation of existing low-voltage distribution\nsystems with high photovoltaic (PV) generation have focused on the possibility\nof inverters providing ancillary services such as active power curtailment and\nreactive power compensation. Major benefits include the possibility of averting\novervoltages, which may otherwise be experienced when PV generation exceeds the\ndemand. This paper deals with ancillary service procurement in the face of\nsolar irradiance forecasting errors. In particular, assuming that the\nforecasted PV irradiance can be described by a random variable with known\n(empirical) distribution, the proposed uncertainty-aware optimal inverter\ndispatch (OID) framework indicates which inverters should provide ancillary\nservices with a guaranteed a-priori risk level of PV generation surplus. To\ncapture forecasting errors, and strike a balance between risk of overvoltages\nand (re)active power reserves, the concept of conditional value-at-risk is\nadvocated. Due to AC power balance equations and binary inverter selection\nvariables, the formulated OID involves the solution of a nonconvex\nmixed-integer nonlinear program. However, a computationally-affordable convex\nrelaxation is derived by leveraging sparsity-promoting regularization\napproaches and semidefinite relaxation techniques. The proposed scheme is\ntested using real-world PV-generation and load-profile data for an illustrative\nlow-voltage residential distribution system.\n", "contributors": [{"name": "Dall'Anese, Emiliano", "sameAs": [], "familyName": "Dall'Anese", "additionalName": "", "givenName": "Emiliano", "email": ""}, {"name": "Dhople, Sairaj V.", "sameAs": [], "familyName": "Dhople", "additionalName": "V.", "givenName": "Sairaj", "email": ""}, {"name": "Johnson, Brian B.", "sameAs": [], "familyName": "Johnson", "additionalName": "B.", "givenName": "Brian", "email": ""}, {"name": "Giannakis, Georgios B.", "sameAs": [], "familyName": "Giannakis", "additionalName": "B.", "givenName": "Georgios", "email": ""}], "title": "Optimal Dispatch of Residential Photovoltaic Inverters Under Forecasting\n  Uncertainties", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-02", "2014-10-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.0597", "oai:arXiv.org:1407.0597"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Efforts to ensure reliable operation of existing low-voltage distribution\nsystems with high photovoltaic (PV) generation have focused on the possibility\nof inverters providing ancillary services such as active power curtailment and\nreactive power compensation. Major benefits include the possibility of averting\novervoltages, which may otherwise be experienced when PV generation exceeds the\ndemand. This paper deals with ancillary service procurement in the face of\nsolar irradiance forecasting errors. In particular, assuming that the\nforecasted PV irradiance can be described by a random variable with known\n(empirical) distribution, the proposed uncertainty-aware optimal inverter\ndispatch (OID) framework indicates which inverters should provide ancillary\nservices with a guaranteed a-priori risk level of PV generation surplus. To\ncapture forecasting errors, and strike a balance between risk of overvoltages\nand (re)active power reserves, the concept of conditional value-at-risk is\nadvocated. Due to AC power balance equations and binary inverter selection\nvariables, the formulated OID involves the solution of a nonconvex\nmixed-integer nonlinear program. However, a computationally-affordable convex\nrelaxation is derived by leveraging sparsity-promoting regularization\napproaches and semidefinite relaxation techniques. The proposed scheme is\ntested using real-world PV-generation and load-profile data for an illustrative\nlow-voltage residential distribution system.\n", "Comment: To appear in the IEEE Journal of Photovoltaics"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - systems and control"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.0597"}}, {"publisher": {"name": ""}, "description": "  Codes with local permutation constraints are described. Belief propagation\ndecoding is shown to require the computation of permanents, and trellis-based\nmethods for computing the permanents are introduced. New insights into the\nasymptotic performance of such codes are presented. A universal encoder for\ncodes with local constraints is introduced, and simulation results for two code\nstructures, SUDOKU and semi-pandiagonal Latin squares, are presented.\n", "contributors": [{"name": "Sayir, Jossy", "sameAs": [], "familyName": "Sayir", "additionalName": "", "givenName": "Jossy", "email": ""}, {"name": "Sarwar, Joned", "sameAs": [], "familyName": "Sarwar", "additionalName": "", "givenName": "Joned", "email": ""}], "title": "An investigation of SUDOKU-inspired non-linear codes with local\n  constraints", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-04-15", "2015-04-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03946", "oai:arXiv.org:1504.03946"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Codes with local permutation constraints are described. Belief propagation\ndecoding is shown to require the computation of permanents, and trellis-based\nmethods for computing the permanents are introduced. New insights into the\nasymptotic performance of such codes are presented. A universal encoder for\ncodes with local constraints is introduced, and simulation results for two code\nstructures, SUDOKU and semi-pandiagonal Latin squares, are presented.\n", "Comment: Accepted for presentation at ISIT 2015"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03946"}}, {"publisher": {"name": ""}, "description": "  Spatial compressive sensing (SCS) has recently been applied to\ndirection-of-arrival (DOA) estimation owing to advantages over conventional\nones. However the performance of compressive sensing (CS)-based estimation\nmethods decreases when true DOAs are not exactly on the discretized sampling\ngrid. We solve the off-grid DOA estimation problem using the deterministic\nmaximum likelihood (DML) estimation method. In this work, we analyze the\nconvexity of the DML function in the vicinity of the global solution.\nEspecially under the condition of large array, we search for an approximately\nconvex range around the ture DOAs to guarantee the DML function convex. Based\non the convexity of the DML function, we propose a computationally efficient\nalgorithm framework for off-grid DOA estimation. Numerical experiments show\nthat the rough convex range accords well with the exact convex range of the DML\nfunction with large array and demonstrate the superior performance of the\nproposed methods in terms of accuracy, robustness and speed.\n", "contributors": [{"name": "Liu, Liang", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Liang", "email": ""}, {"name": "Wei, Ping", "sameAs": [], "familyName": "Wei", "additionalName": "", "givenName": "Ping", "email": ""}], "title": "Off-grid DOA Estimation Based on Analysis of the Convexity of Maximum\n  Likelihood Function", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6720", "oai:arXiv.org:1412.6720"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Spatial compressive sensing (SCS) has recently been applied to\ndirection-of-arrival (DOA) estimation owing to advantages over conventional\nones. However the performance of compressive sensing (CS)-based estimation\nmethods decreases when true DOAs are not exactly on the discretized sampling\ngrid. We solve the off-grid DOA estimation problem using the deterministic\nmaximum likelihood (DML) estimation method. In this work, we analyze the\nconvexity of the DML function in the vicinity of the global solution.\nEspecially under the condition of large array, we search for an approximately\nconvex range around the ture DOAs to guarantee the DML function convex. Based\non the convexity of the DML function, we propose a computationally efficient\nalgorithm framework for off-grid DOA estimation. Numerical experiments show\nthat the rough convex range accords well with the exact convex range of the DML\nfunction with large array and demonstrate the superior performance of the\nproposed methods in terms of accuracy, robustness and speed.\n", "Comment: 10 pages, 6 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:1108.5838 by other authors"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6720"}}, {"publisher": {"name": ""}, "description": "  We evaluate the performance of the Krylov subspace method by using highly\nefficient multiple precision sparse matrix-vector multiplication (SpMV).\nBNCpack is our multiple precision numerical computation library based on\nMPFR/GMP, which is one of the most efficient arbitrary precision floating-point\narithmetic libraries. However, it does not include functions that can\nmanipulate multiple precision sparse matrices. Therefore, by using benchmark\ntests, we show that SpMV implemented in these functions can be more efficient.\nFinally, we also show that product-type Krylov subspace methods such as BiCG\nand GPBiCG in which we have embedded SpMV, can efficiently solve large-scale\nlinear systems of equations provided in the UF sparse matrix collections in a\nmemory-restricted computing environment.\n", "contributors": [{"name": "Kouya, Tomonori", "sameAs": [], "familyName": "Kouya", "additionalName": "", "givenName": "Tomonori", "email": ""}], "title": "A Highly Efficient Implementation of Multiple Precision Sparse\n  Matrix-Vector Multiplication and Its Application to Product-type Krylov\n  Subspace Methods", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2377", "International Journal of Numerical Methods and Applications,\n  Vol.7, Issue 2, 2012, Pages 107 - 119", "oai:arXiv.org:1411.2377"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We evaluate the performance of the Krylov subspace method by using highly\nefficient multiple precision sparse matrix-vector multiplication (SpMV).\nBNCpack is our multiple precision numerical computation library based on\nMPFR/GMP, which is one of the most efficient arbitrary precision floating-point\narithmetic libraries. However, it does not include functions that can\nmanipulate multiple precision sparse matrices. Therefore, by using benchmark\ntests, we show that SpMV implemented in these functions can be more efficient.\nFinally, we also show that product-type Krylov subspace methods such as BiCG\nand GPBiCG in which we have embedded SpMV, can efficiently solve large-scale\nlinear systems of equations provided in the UF sparse matrix collections in a\nmemory-restricted computing environment.\n"}}], "languages": [null], "subjects": ["mathematics - numerical analysis", "computer science - numerical analysis"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2377"}}, {"publisher": {"name": ""}, "description": "  In the past few decades, the world has witnessed a rapid growth in mobile\ncommunication and reaped great benefits from it. Even though the fourth\ngeneration (4G) mobile communication system is just being deployed worldwide,\nproliferating mobile demands call for newer wireless communication technologies\nwith even better performance. Consequently, the fifth generation (5G) system is\nalready emerging in the research field. However, simply evolving the current\nmobile networks can hardly meet such great expectations, because over the years\nthe infrastructures have generally become ossified, closed, and vertically\nconstructed. Aiming to establish a new paradigm for 5G mobile networks, in this\narticle, we propose a cross-layer software-defined 5G network architecture. By\njointly considering both the network layer and the physical layer together, we\nestablish the two software-defined programmable components, the control plane\nand the cloud computing pool, which enable an effective control of the mobile\nnetwork from the global perspective and benefit technological innovations.\nSpecifically, by the cross-layer design for software-defining, the logically\ncentralized and programmable control plane abstracts the control functions from\nthe network layer down to the physical layer, through which we achieve the\nfine-grained controlling of mobile network, while the cloud computing pool\nprovides powerful computing capability to implement the baseband data\nprocessing of multiple heterogeneous networks. We discuss the main challenges\nof our architecture, including the fine-grained control strategies, network\nvirtualization, and programmability. The architecture significantly benefits\nthe convergence towards heterogeneous networks and it enables much more\ncontrollable, programmable and evolvable mobile networks.\n", "contributors": [{"name": "Yang, Mao", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Mao", "email": ""}, {"name": "Li, Yong", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Yong", "email": ""}, {"name": "Hu, Long", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Long", "email": ""}, {"name": "Li, Bo", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Bo", "email": ""}, {"name": "Jin, Depeng", "sameAs": [], "familyName": "Jin", "additionalName": "", "givenName": "Depeng", "email": ""}, {"name": "Chen, Sheng", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Sheng", "email": ""}, {"name": "Yan, Zhongjiang", "sameAs": [], "familyName": "Yan", "additionalName": "", "givenName": "Zhongjiang", "email": ""}], "title": "Cross-Layer Software-Defined 5G Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.6189", "oai:arXiv.org:1411.6189"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In the past few decades, the world has witnessed a rapid growth in mobile\ncommunication and reaped great benefits from it. Even though the fourth\ngeneration (4G) mobile communication system is just being deployed worldwide,\nproliferating mobile demands call for newer wireless communication technologies\nwith even better performance. Consequently, the fifth generation (5G) system is\nalready emerging in the research field. However, simply evolving the current\nmobile networks can hardly meet such great expectations, because over the years\nthe infrastructures have generally become ossified, closed, and vertically\nconstructed. Aiming to establish a new paradigm for 5G mobile networks, in this\narticle, we propose a cross-layer software-defined 5G network architecture. By\njointly considering both the network layer and the physical layer together, we\nestablish the two software-defined programmable components, the control plane\nand the cloud computing pool, which enable an effective control of the mobile\nnetwork from the global perspective and benefit technological innovations.\nSpecifically, by the cross-layer design for software-defining, the logically\ncentralized and programmable control plane abstracts the control functions from\nthe network layer down to the physical layer, through which we achieve the\nfine-grained controlling of mobile network, while the cloud computing pool\nprovides powerful computing capability to implement the baseband data\nprocessing of multiple heterogeneous networks. We discuss the main challenges\nof our architecture, including the fine-grained control strategies, network\nvirtualization, and programmability. The architecture significantly benefits\nthe convergence towards heterogeneous networks and it enables much more\ncontrollable, programmable and evolvable mobile networks.\n", "Comment: 9 pages, 5 figures, submitted to Mobile Networks & Applications"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.6189"}}, {"publisher": {"name": ""}, "description": "  This paper describes a novel refinement to a Tabu search algorithm that has\nbeen implemented in an attempt to improve the robustness of the search when\napplied to particularly complex problems. In this approach, two Tabu searches\nare carried out in parallel. Each search thread is characterised by it's own\nshort term memory which forces that point out of local optima. However, the two\nsearch threads share an intermediate term memory so allowing a degree of\ninformation to be passed between them. Results are presented for both\nunconstrained and constrained numerical functions as well as a problem in the\nfield of hydraulic circuit optimization. Simulation of hydraulic circuit\nperformance is achieved by linking the optimization algorithm to the commercial\nsimulation package Bathfp.\n", "contributors": [{"name": "Connor, A. M.", "sameAs": [], "familyName": "Connor", "additionalName": "M.", "givenName": "A.", "email": ""}], "title": "A mutli-thread tabu search algorithm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.7849", "Design Optimization: International Journal of Product and Process\n  Improvement, 1(3), 293-304, 1999", "oai:arXiv.org:1410.7849"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper describes a novel refinement to a Tabu search algorithm that has\nbeen implemented in an attempt to improve the robustness of the search when\napplied to particularly complex problems. In this approach, two Tabu searches\nare carried out in parallel. Each search thread is characterised by it's own\nshort term memory which forces that point out of local optima. However, the two\nsearch threads share an intermediate term memory so allowing a degree of\ninformation to be passed between them. Results are presented for both\nunconstrained and constrained numerical functions as well as a problem in the\nfield of hydraulic circuit optimization. Simulation of hydraulic circuit\nperformance is achieved by linking the optimization algorithm to the commercial\nsimulation package Bathfp.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2014-10-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.7849"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "We present a simple and scalable graph clustering method called power iteration clustering (PIC). PIC finds a very low-dimensional embedding of a dataset using truncated power iteration on a normalized pair-wise similarity matrix of the data. This embedding turns out to be an effective cluster indicator, consistently outperforming widely used spectral methods such as NCut on real datasets. PIC is very fast on large datasets, running over 1,000 times faster than an NCut implementation based on the state-of-the-art IRAM eigenvector computation technique", "contributors": [{"name": "Lin, Frank", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Frank", "email": ""}, {"name": "Cohen, William W.", "sameAs": [], "familyName": "Cohen", "additionalName": "W.", "givenName": "William", "email": ""}], "title": "Power Iteration Clustering", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2010-06-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/36", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1038&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1038"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "We present a simple and scalable graph clustering method called power iteration clustering (PIC). PIC finds a very low-dimensional embedding of a dataset using truncated power iteration on a normalized pair-wise similarity matrix of the data. This embedding turns out to be an effective cluster indicator, consistently outperforming widely used spectral methods such as NCut on real datasets. PIC is very fast on large datasets, running over 1,000 times faster than an NCut implementation based on the state-of-the-art IRAM eigenvector computation technique"}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-06T21:56:31", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/36"}}, {"publisher": {"name": ""}, "description": "  A method to couple interparticle contact models with Stokesian dynamics (SD)\nis introduced to simulate colloidal aggregates under flow conditions. The\ncontact model mimics both the elastic and plastic behavior of the cohesive\nconnections between particles within clusters. Owing to this, clusters can\nmaintain their structures under low stress while restructuring or even breakage\nmay occur under sufficiently high stress conditions. SD is an efficient method\nto deal with the long-ranged and many-body nature of hydrodynamic interactions\nfor low Reynolds number flows. By using such a coupled model, the restructuring\nof colloidal aggregates under stepwise increasing shear flows was studied.\nIrreversible compaction occurs due to the increase of hydrodynamic stress on\nclusters. Results show that the greater part of the fractal clusters are\ncompacted to rod-shaped packed structures, while the others show isotropic\ncompaction.\n", "contributors": [{"name": "Seto, Ryohei", "sameAs": [], "familyName": "Seto", "additionalName": "", "givenName": "Ryohei", "email": ""}, {"name": "Botet, Robert", "sameAs": [], "familyName": "Botet", "additionalName": "", "givenName": "Robert", "email": ""}, {"name": "Auernhammer, G\u00fcnter K.", "sameAs": [], "familyName": "Auernhammer", "additionalName": "K.", "givenName": "G\u00fcnter", "email": ""}, {"name": "Briesen, Heiko", "sameAs": [], "familyName": "Briesen", "additionalName": "", "givenName": "Heiko", "email": ""}], "title": "Restructuring of colloidal aggregates in shear flow: Coupling\n  interparticle contact models with Stokesian dynamics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-04-25", "2012-12-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1204.5680", "Eur. Phys. J. E, 35 12 (2012) 128", "doi:10.1140/epje/i2012-12128-4", "oai:arXiv.org:1204.5680"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  A method to couple interparticle contact models with Stokesian dynamics (SD)\nis introduced to simulate colloidal aggregates under flow conditions. The\ncontact model mimics both the elastic and plastic behavior of the cohesive\nconnections between particles within clusters. Owing to this, clusters can\nmaintain their structures under low stress while restructuring or even breakage\nmay occur under sufficiently high stress conditions. SD is an efficient method\nto deal with the long-ranged and many-body nature of hydrodynamic interactions\nfor low Reynolds number flows. By using such a coupled model, the restructuring\nof colloidal aggregates under stepwise increasing shear flows was studied.\nIrreversible compaction occurs due to the increase of hydrodynamic stress on\nclusters. Results show that the greater part of the fractal clusters are\ncompacted to rod-shaped packed structures, while the others show isotropic\ncompaction.\n", "Comment: A simulation movie be found at\n  http://www-levich.engr.ccny.cuny.edu/~seto/sites/colloidal_aggregates_shearflow.html"]}}], "languages": [null], "subjects": ["physics - computational physics", "physics - fluid dynamics", "condensed matter - soft condensed matter"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1204.5680"}}, {"publisher": {"name": ""}, "description": "  New phase transition phenomena have recently been discovered for the\nstochastic block model, for the special case of two non-overlapping symmetric\ncommunities. This gives raise in particular to new algorithmic challenges\ndriven by the thresholds. This paper investigates whether a general phenomenon\ntakes place for multiple communities, without imposing symmetry.\n  In the general stochastic block model $\\text{SBM}(n,p,Q)$, $n$ vertices are\nsplit into $k$ communities of relative size $\\{p_i\\}_{i \\in [k]}$, and vertices\nin community $i$ and $j$ connect independently with probability\n$\\{Q_{i,j}\\}_{i,j \\in [k]}$. This paper investigates the partial and exact\nrecovery of communities in the general SBM (in the constant and logarithmic\ndegree regimes), and uses the generality of the results to tackle overlapping\ncommunities.\n  The contributions of the paper are: (i) an explicit characterization of the\nrecovery threshold in the general SBM in terms of a new divergence function\n$D_+$, which generalizes the Hellinger and Chernoff divergences, and which\nprovides an operational meaning to a divergence function analog to the\nKL-divergence in the channel coding theorem, (ii) the development of an\nalgorithm that recovers the communities all the way down to the optimal\nthreshold and runs in quasi-linear time, showing that exact recovery has no\ninformation-theoretic to computational gap for multiple communities, in\ncontrast to the conjectures made for detection with more than 4 communities;\nnote that the algorithm is optimal both in terms of achieving the threshold and\nin having quasi-linear complexity, (iii) the development of an efficient\nalgorithm that detects communities in the constant degree regime with an\nexplicit accuracy bound that can be made arbitrarily close to 1 when a\nprescribed signal-to-noise ratio (defined in term of the spectrum of\n$\\diag(p)Q$) tends to infinity.\n", "contributors": [{"name": "Abbe, Emmanuel", "sameAs": [], "familyName": "Abbe", "additionalName": "", "givenName": "Emmanuel", "email": ""}, {"name": "Sandon, Colin", "sameAs": [], "familyName": "Sandon", "additionalName": "", "givenName": "Colin", "email": ""}], "title": "Community detection in general stochastic block models: fundamental\n  limits and efficient recovery algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-02", "2015-04-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.00609", "oai:arXiv.org:1503.00609"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  New phase transition phenomena have recently been discovered for the\nstochastic block model, for the special case of two non-overlapping symmetric\ncommunities. This gives raise in particular to new algorithmic challenges\ndriven by the thresholds. This paper investigates whether a general phenomenon\ntakes place for multiple communities, without imposing symmetry.\n  In the general stochastic block model $\\text{SBM}(n,p,Q)$, $n$ vertices are\nsplit into $k$ communities of relative size $\\{p_i\\}_{i \\in [k]}$, and vertices\nin community $i$ and $j$ connect independently with probability\n$\\{Q_{i,j}\\}_{i,j \\in [k]}$. This paper investigates the partial and exact\nrecovery of communities in the general SBM (in the constant and logarithmic\ndegree regimes), and uses the generality of the results to tackle overlapping\ncommunities.\n  The contributions of the paper are: (i) an explicit characterization of the\nrecovery threshold in the general SBM in terms of a new divergence function\n$D_+$, which generalizes the Hellinger and Chernoff divergences, and which\nprovides an operational meaning to a divergence function analog to the\nKL-divergence in the channel coding theorem, (ii) the development of an\nalgorithm that recovers the communities all the way down to the optimal\nthreshold and runs in quasi-linear time, showing that exact recovery has no\ninformation-theoretic to computational gap for multiple communities, in\ncontrast to the conjectures made for detection with more than 4 communities;\nnote that the algorithm is optimal both in terms of achieving the threshold and\nin having quasi-linear complexity, (iii) the development of an efficient\nalgorithm that detects communities in the constant degree regime with an\nexplicit accuracy bound that can be made arbitrarily close to 1 when a\nprescribed signal-to-noise ratio (defined in term of the spectrum of\n$\\diag(p)Q$) tends to infinity.\n"}}], "languages": [null], "subjects": ["computer science - social and information networks", "computer science - information theory", "mathematics - probability"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.00609"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "We consider the problem of recovering a low rank matrix given a sampling of its entries. Such problems are of considerable interest in a diverse set of fields including control, system identification, statistics and signal processing. Although the general low rank matrix completion problem is NP-hard, there exist several heuristic methods that solve the problem approximately by solving the convex relaxation of the original problem. One particularly popular method is to use nuclear norm (sum of singular values) to approximate the rank of the matrix and formulate the problem as a semidefinite program that can be solved efficiently. In this thesis, we propose a local completion algorithm that searches for possible completion in the neighborhood of each unspecified entry given the rank of the matrix. Unlike existing methods, this algorithm requires only local information of the matrix if the rank is known. Critical in all low rank matrix completion algorithms is the sampling density. The denser the matrix is sampled, the more likely it can be recovered accurately. We then propose a condensation process that increases the sampling density in a specific part of the matrix through elementary row and column re-ordering. Hence we can solve a sub-problem of the original low rank matrix completion problem and gain information on the rank of the matrix. Then the local algorithm is readily applicable to recover the entire matrix. We also explore the effect of additional sampling structures on the completion rate of the low rank matrix completion problems. In particular, we show that imposing regularity in the sampling process leads to slightly better completion rates.", "contributors": [{"name": "Nan, Feng, S.M. Massachusetts Institute of Technology", "sameAs": [], "familyName": "Nan", "additionalName": "", "givenName": "Feng", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "Pablo.A.Parrilo.", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Pablo.A.Parrilo.", "email": ""}], "title": "Low rank matrix completion", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "76 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/55077", "587442816", "oai:dspace.mit.edu:1721.1/55077"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2010-05-25T20:39:01Z", "2010-05-25T20:39:01Z", "2009", "2009"]}}, {"name": "description", "properties": {"description": ["We consider the problem of recovering a low rank matrix given a sampling of its entries. Such problems are of considerable interest in a diverse set of fields including control, system identification, statistics and signal processing. Although the general low rank matrix completion problem is NP-hard, there exist several heuristic methods that solve the problem approximately by solving the convex relaxation of the original problem. One particularly popular method is to use nuclear norm (sum of singular values) to approximate the rank of the matrix and formulate the problem as a semidefinite program that can be solved efficiently. In this thesis, we propose a local completion algorithm that searches for possible completion in the neighborhood of each unspecified entry given the rank of the matrix. Unlike existing methods, this algorithm requires only local information of the matrix if the rank is known. Critical in all low rank matrix completion algorithms is the sampling density. The denser the matrix is sampled, the more likely it can be recovered accurately. We then propose a condensation process that increases the sampling density in a specific part of the matrix through elementary row and column re-ordering. Hence we can solve a sub-problem of the original low rank matrix completion problem and gain information on the rank of the matrix. Then the local algorithm is readily applicable to recover the entire matrix. We also explore the effect of additional sampling structures on the completion rate of the low rank matrix completion problems. In particular, we show that imposing regularity in the sampling process leads to slightly better completion rates.", "(cont.) We also provide a new semidefinite formulation for a particular block sampling structure that reduces the size of the constraint matrix sizes by a factor of 1.5.", "by Feng Nan.", "Thesis (S.M.)--Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2009.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (p. 75-76)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39115", "hdl_1721.1_39117"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:18", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/55077"}}, {"publisher": {"name": ""}, "description": "  The input numerical aperture (NA) of multimode fiber (MMF) can be effectively\nincreased by placing turbid media at the input end of the MMF. This provides\nthe potential for high-resolution imaging through the MMF. While the input NA\nis increased, the number of propagation modes in the MMF and hence the output\nNA remains the same. This makes the image reconstruction process\nunderdetermined and may limit the quality of the image reconstruction. In this\npaper, we aim to improve the signal to noise ratio (SNR) of the image\nreconstruction in imaging through MMF. We notice that turbid media placed in\nthe input of the MMF transforms the incoming waves into a better format for\ninformation transmission and information extraction. We call this\ntransformation as holistic random (HR) encoding of turbid media. By exploiting\nthe HR encoding, we make a considerable improvement on the SNR of the image\nreconstruction. For efficient utilization of the HR encoding, we employ sparse\nrepresentation (SR), a relatively new signal reconstruction framework when it\nis provided with a HR encoded signal. This study shows for the first time to\nour knowledge the benefit of utilizing the HR encoding of turbid media for\nrecovery in the optically underdetermined systems where the output NA of it is\nsmaller than the input NA for imaging through MMF.\n", "contributors": [{"name": "Jang, Hwanchol", "sameAs": [], "familyName": "Jang", "additionalName": "", "givenName": "Hwanchol", "email": ""}, {"name": "Yoon, Changhyeong", "sameAs": [], "familyName": "Yoon", "additionalName": "", "givenName": "Changhyeong", "email": ""}, {"name": "Chung, Euiheon", "sameAs": [], "familyName": "Chung", "additionalName": "", "givenName": "Euiheon", "email": ""}, {"name": "Choi, Wonshik", "sameAs": [], "familyName": "Choi", "additionalName": "", "givenName": "Wonshik", "email": ""}, {"name": "Lee, Heung-No", "sameAs": [], "familyName": "Lee", "additionalName": "", "givenName": "Heung-No", "email": ""}], "title": "Holistic random encoding for imaging through multimode fibers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.03997", "oai:arXiv.org:1501.03997"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The input numerical aperture (NA) of multimode fiber (MMF) can be effectively\nincreased by placing turbid media at the input end of the MMF. This provides\nthe potential for high-resolution imaging through the MMF. While the input NA\nis increased, the number of propagation modes in the MMF and hence the output\nNA remains the same. This makes the image reconstruction process\nunderdetermined and may limit the quality of the image reconstruction. In this\npaper, we aim to improve the signal to noise ratio (SNR) of the image\nreconstruction in imaging through MMF. We notice that turbid media placed in\nthe input of the MMF transforms the incoming waves into a better format for\ninformation transmission and information extraction. We call this\ntransformation as holistic random (HR) encoding of turbid media. By exploiting\nthe HR encoding, we make a considerable improvement on the SNR of the image\nreconstruction. For efficient utilization of the HR encoding, we employ sparse\nrepresentation (SR), a relatively new signal reconstruction framework when it\nis provided with a HR encoded signal. This study shows for the first time to\nour knowledge the benefit of utilizing the HR encoding of turbid media for\nrecovery in the optically underdetermined systems where the output NA of it is\nsmaller than the input NA for imaging through MMF.\n", "Comment: under review for possible publication in Optics express"]}}], "languages": [null], "subjects": ["physics - optics", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.03997"}}, {"publisher": {"name": ""}, "description": "  A robust controller is developed for uncertain, second-order nonlinear\nsystems subject to simultaneous unknown, time-varying state delays and known,\ntime-varying input delays in addition to additive, sufficiently smooth\ndisturbances. An integral term composed of previous control values facilitates\na delay-free open-loop error system and the development of the feedback control\nstructure. A stability analysis based on Lyapunov-Krasovskii (LK) functionals\nguarantees uniformly ultimately bounded tracking under the assumption that the\ndelays are bounded and slowly varying.\n", "contributors": [{"name": "Kamalapurkar, Rushikesh", "sameAs": [], "familyName": "Kamalapurkar", "additionalName": "", "givenName": "Rushikesh", "email": ""}, {"name": "Fischer, Nicholas", "sameAs": [], "familyName": "Fischer", "additionalName": "", "givenName": "Nicholas", "email": ""}, {"name": "Obuz, Serhat", "sameAs": [], "familyName": "Obuz", "additionalName": "", "givenName": "Serhat", "email": ""}, {"name": "Dixon, Warren E.", "sameAs": [], "familyName": "Dixon", "additionalName": "E.", "givenName": "Warren", "email": ""}], "title": "Time-Varying Input and State Delay Compensation for Uncertain Nonlinear\n  Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.03810", "oai:arXiv.org:1501.03810"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  A robust controller is developed for uncertain, second-order nonlinear\nsystems subject to simultaneous unknown, time-varying state delays and known,\ntime-varying input delays in addition to additive, sufficiently smooth\ndisturbances. An integral term composed of previous control values facilitates\na delay-free open-loop error system and the development of the feedback control\nstructure. A stability analysis based on Lyapunov-Krasovskii (LK) functionals\nguarantees uniformly ultimately bounded tracking under the assumption that the\ndelays are bounded and slowly varying.\n"}}], "languages": [null], "subjects": ["computer science - systems and control"], "providerUpdatedDateTime": "2015-01-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.03810"}}, {"publisher": {"name": ""}, "description": "  A space-time physical-layer network coding (ST- PNC) method is presented for\ninformation exchange among multiple users over fully-connected multi-way relay\nnetworks. The method involves two steps: i) side-information learning and ii)\nspace-time relay transmission. In the first step, different sets of users are\nscheduled to send signals over networks and the remaining users and relays\noverhear the transmitted signals, thereby learning the interference patterns.\nIn the second step, multiple relays cooperatively send out linear combinations\nof signals received in the previous phase using space-time precoding so that\nall users efficiently exploit their side-information in the form of: 1) what\nthey sent and 2) what they overheard in decoding. This coding concept is\nillustrated through two simple network examples. It is shown that ST-PNC\nimproves the sum of degrees of freedom (sum-DoF) of the network compared to\nexisting interference management methods. With ST-PNC, the sum-DoF of a general\nmulti-way relay network without channel knowledge at the users is characterized\nin terms of relevant system parameters, chiefly the number of users, the number\nof relays, and the number of antennas at relays. A major implication of the\nderived results is that efficiently harnessing both transmit- ted and overheard\nsignals as side-information brings significant performance improvements to\nfully-connected multi-way relay networks.\n", "contributors": [{"name": "Lee, Namyoon", "sameAs": [], "familyName": "Lee", "additionalName": "", "givenName": "Namyoon", "email": ""}, {"name": "Heath Jr, Robert W.", "sameAs": [], "familyName": "Heath", "additionalName": "W.", "givenName": "Robert", "email": ""}], "title": "Space-Time Physical-Layer Network Coding", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-30", "2014-10-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.0029", "oai:arXiv.org:1405.0029"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A space-time physical-layer network coding (ST- PNC) method is presented for\ninformation exchange among multiple users over fully-connected multi-way relay\nnetworks. The method involves two steps: i) side-information learning and ii)\nspace-time relay transmission. In the first step, different sets of users are\nscheduled to send signals over networks and the remaining users and relays\noverhear the transmitted signals, thereby learning the interference patterns.\nIn the second step, multiple relays cooperatively send out linear combinations\nof signals received in the previous phase using space-time precoding so that\nall users efficiently exploit their side-information in the form of: 1) what\nthey sent and 2) what they overheard in decoding. This coding concept is\nillustrated through two simple network examples. It is shown that ST-PNC\nimproves the sum of degrees of freedom (sum-DoF) of the network compared to\nexisting interference management methods. With ST-PNC, the sum-DoF of a general\nmulti-way relay network without channel knowledge at the users is characterized\nin terms of relevant system parameters, chiefly the number of users, the number\nof relays, and the number of antennas at relays. A major implication of the\nderived results is that efficiently harnessing both transmit- ted and overheard\nsignals as side-information brings significant performance improvements to\nfully-connected multi-way relay networks.\n", "Comment: To appear in IEEE JSAC special issue on \"Fundamental Approaches to\n  Network Coding in Wireless Communication Systems.\"\""]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.0029"}}, {"publisher": {"name": ""}, "description": "  This paper presents four different ways of looking at the well-known Least\nSquares Temporal Differences (LSTD) algorithm for computing the value function\nof a Markov Reward Process, each of them leading to different insights: the\noperator-theory approach via the Galerkin method, the statistical approach via\ninstrumental variables, the linear dynamical system view as well as the limit\nof the TD iteration. We also give a geometric view of the algorithm as an\noblique projection. Furthermore, there is an extensive comparison of the\noptimization problem solved by LSTD as compared to Bellman Residual\nMinimization (BRM). We then review several schemes for the regularization of\nthe LSTD solution. We then proceed to treat the modification of LSTD for the\ncase of episodic Markov Reward Processes.\n", "contributors": [{"name": "Ciosek, Kamil", "sameAs": [], "familyName": "Ciosek", "additionalName": "", "givenName": "Kamil", "email": ""}], "title": "Properties of the Least Squares Temporal Difference learning algorithm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-01-22", "2015-04-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1301.5220", "oai:arXiv.org:1301.5220"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  This paper presents four different ways of looking at the well-known Least\nSquares Temporal Differences (LSTD) algorithm for computing the value function\nof a Markov Reward Process, each of them leading to different insights: the\noperator-theory approach via the Galerkin method, the statistical approach via\ninstrumental variables, the linear dynamical system view as well as the limit\nof the TD iteration. We also give a geometric view of the algorithm as an\noblique projection. Furthermore, there is an extensive comparison of the\noptimization problem solved by LSTD as compared to Bellman Residual\nMinimization (BRM). We then review several schemes for the regularization of\nthe LSTD solution. We then proceed to treat the modification of LSTD for the\ncase of episodic Markov Reward Processes.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1301.5220"}}, {"publisher": {"name": "DigitalCommons@CalPoly"}, "description": "", "contributors": [{"name": "Jacobiius, Alexander", "sameAs": [], "familyName": "Jacobiius", "additionalName": "", "givenName": "Alexander", "email": ""}], "title": "Cliffhanger: for Saxophone Quartet", "shareProperties": {"source": "calpoly"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "source", "properties": {"source": "Music"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2015-03-01T08:00:00Z"}}, {"name": "setSpec", "properties": {"setSpec": ["publication:musp", "publication:students", "publication:seniorprojects"]}}], "languages": [null], "subjects": ["saxophone", "music", "composition"], "providerUpdatedDateTime": "2015-04-15T23:50:05", "uris": {"canonicalUri": "http://digitalcommons.calpoly.edu/musp/61"}}, {"publisher": {"name": ""}, "description": "  We study the following problem: preprocess a set O of objects into a data\nstructure that allows us to efficiently report all pairs of objects from O that\nintersect inside an axis-aligned query range Q. We present data structures of\nsize $O(n({\\rm polylog} n))$ and with query time $O((k+1)({\\rm polylog} n))$\ntime, where k is the number of reported pairs, for two classes of objects in\nthe plane: axis-aligned rectangles and objects with small union complexity. For\nthe 3-dimensional case where the objects and the query range are axis-aligned\nboxes in R^3, we present a data structures of size $O(n\\sqrt{n}({\\rm polylog}\nn))$ and query time $O((\\sqrt{n}+k)({\\rm polylog} n))$. When the objects and\nquery are fat, we obtain $O((k+1)({\\rm polylog} n))$ query time using $O(n({\\rm\npolylog} n))$ storage.\n", "contributors": [{"name": "de Berg, Mark", "sameAs": [], "familyName": "de Berg", "additionalName": "", "givenName": "Mark", "email": ""}, {"name": "Gudmundsson, Joachim", "sameAs": [], "familyName": "Gudmundsson", "additionalName": "", "givenName": "Joachim", "email": ""}, {"name": "Mehrabi, Ali D.", "sameAs": [], "familyName": "Mehrabi", "additionalName": "D.", "givenName": "Ali", "email": ""}], "title": "Finding Pairwise Intersections Inside a Query Range", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06079", "oai:arXiv.org:1502.06079"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We study the following problem: preprocess a set O of objects into a data\nstructure that allows us to efficiently report all pairs of objects from O that\nintersect inside an axis-aligned query range Q. We present data structures of\nsize $O(n({\\rm polylog} n))$ and with query time $O((k+1)({\\rm polylog} n))$\ntime, where k is the number of reported pairs, for two classes of objects in\nthe plane: axis-aligned rectangles and objects with small union complexity. For\nthe 3-dimensional case where the objects and the query range are axis-aligned\nboxes in R^3, we present a data structures of size $O(n\\sqrt{n}({\\rm polylog}\nn))$ and query time $O((\\sqrt{n}+k)({\\rm polylog} n))$. When the objects and\nquery are fat, we obtain $O((k+1)({\\rm polylog} n))$ query time using $O(n({\\rm\npolylog} n))$ storage.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06079"}}, {"publisher": {"name": ""}, "description": "  This paper introduces a novel approach of clustering, which is based on group\nconsensus of dynamic linear high-order multi-agent systems. The graph topology\nis associated with a selected multi-agent system, with each agent corresponding\nto one vertex. In order to reveal the cluster structure, the agents belonging\nto a similar cluster are expected to aggregate together. As theoretical\nfoundation, a necessary and sufficient condition is given to check the group\nconsensus. Two numerical instances are shown to illustrate the process of\napproach.\n", "contributors": [{"name": "Cai, Ning", "sameAs": [], "familyName": "Cai", "additionalName": "", "givenName": "Ning", "email": ""}, {"name": "Diao, Chen", "sameAs": [], "familyName": "Diao", "additionalName": "", "givenName": "Chen", "email": ""}, {"name": "Khan, M. Junaid", "sameAs": [], "familyName": "Khan", "additionalName": "Junaid", "givenName": "M.", "email": ""}], "title": "A Novel Clustering Approach Based on Group Quasi-Consensus of Unstable\n  Dynamic Linear High-Order Multi-Agent Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.02588", "oai:arXiv.org:1501.02588"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper introduces a novel approach of clustering, which is based on group\nconsensus of dynamic linear high-order multi-agent systems. The graph topology\nis associated with a selected multi-agent system, with each agent corresponding\nto one vertex. In order to reveal the cluster structure, the agents belonging\nto a similar cluster are expected to aggregate together. As theoretical\nfoundation, a necessary and sufficient condition is given to check the group\nconsensus. Two numerical instances are shown to illustrate the process of\napproach.\n"}}], "languages": [null], "subjects": ["computer science - systems and control"], "providerUpdatedDateTime": "2015-01-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.02588"}}, {"publisher": {"name": ""}, "description": "  We prove that Ochiai similarity of the co-occurrence matrix is equal to\ncosine similarity in the underlying occurrence matrix. Neither the cosine nor\nthe Pearson correlation should be used for the normalization of co-occurrence\nmatrices because the similarity is then normalized twice, and therefore\nover-estimated; the Ochiai coefficient can be used instead. Results are shown\nusing a small matrix (5 cases, 4 variables) for didactic reasons, and also\nAhlgren et al.'s (2003) co-occurrence matrix of 24 authors in library and\ninformation sciences. The over-estimation is shown numerically and will be\nillustrated using multidimensional scaling and cluster dendograms. If the\noccurrence matrix is not available (such as in internet research or author\nco-citation analysis) using Ochiai for the normalization is preferable to using\nthe cosine.\n", "contributors": [{"name": "Zhou, Qiuju", "sameAs": [], "familyName": "Zhou", "additionalName": "", "givenName": "Qiuju", "email": ""}, {"name": "Leydesdorff, Loet", "sameAs": [], "familyName": "Leydesdorff", "additionalName": "", "givenName": "Loet", "email": ""}], "title": "The Normalization of Occurrence and Co-occurrence Matrices in\n  Bibliometrics using Cosine Similarities and Ochiai Coefficients", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-31", "2015-04-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08944", "oai:arXiv.org:1503.08944"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We prove that Ochiai similarity of the co-occurrence matrix is equal to\ncosine similarity in the underlying occurrence matrix. Neither the cosine nor\nthe Pearson correlation should be used for the normalization of co-occurrence\nmatrices because the similarity is then normalized twice, and therefore\nover-estimated; the Ochiai coefficient can be used instead. Results are shown\nusing a small matrix (5 cases, 4 variables) for didactic reasons, and also\nAhlgren et al.'s (2003) co-occurrence matrix of 24 authors in library and\ninformation sciences. The over-estimation is shown numerically and will be\nillustrated using multidimensional scaling and cluster dendograms. If the\noccurrence matrix is not available (such as in internet research or author\nco-citation analysis) using Ochiai for the normalization is preferable to using\nthe cosine.\n"}}], "languages": [null], "subjects": ["computer science - digital libraries"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08944"}}, {"publisher": {"name": ""}, "description": "  We show that the series of all walks between any two vertices of any\n(possibly weighted) directed graph $\\mathcal{G}$ is given by a universal\ncontinued fraction of finite depth and breadth involving the simple paths and\nsimple cycles of $\\mathcal{G}$. A simple path is a walk forbidden to visit any\nvertex more than once. We obtain an explicit formula giving this continued\nfraction. Our results are based on an equivalent to the fundamental theorem of\narithmetic: we demonstrate that arbitrary walks on $\\mathcal{G}$ factorize\nuniquely into nesting products of simple paths and simple cycles, where nesting\nis a product operation between walks that we define. We show that the simple\npaths and simple cycles are the prime elements of the set of all walks on\n$\\mathcal{G}$ equipped with the nesting product. We give an algorithm producing\nthe prime factorization of individual walks, and obtain a recursive formula\nproducing the prime factorization of sets of walks. Our results have already\nfound applications in machine learning, matrix computations and quantum\nmechanics.\n", "contributors": [{"name": "Giscard, P. -L.", "sameAs": [], "familyName": "Giscard", "additionalName": "-L.", "givenName": "P.", "email": ""}, {"name": "Thwaite, S. J.", "sameAs": [], "familyName": "Thwaite", "additionalName": "J.", "givenName": "S.", "email": ""}, {"name": "Jaksch, D.", "sameAs": [], "familyName": "Jaksch", "additionalName": "", "givenName": "D.", "email": ""}], "title": "Walk-Sums, Continued Fractions and Unique Factorisation on Digraphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-02-24", "2015-01-09"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1202.5523", "oai:arXiv.org:1202.5523"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We show that the series of all walks between any two vertices of any\n(possibly weighted) directed graph $\\mathcal{G}$ is given by a universal\ncontinued fraction of finite depth and breadth involving the simple paths and\nsimple cycles of $\\mathcal{G}$. A simple path is a walk forbidden to visit any\nvertex more than once. We obtain an explicit formula giving this continued\nfraction. Our results are based on an equivalent to the fundamental theorem of\narithmetic: we demonstrate that arbitrary walks on $\\mathcal{G}$ factorize\nuniquely into nesting products of simple paths and simple cycles, where nesting\nis a product operation between walks that we define. We show that the simple\npaths and simple cycles are the prime elements of the set of all walks on\n$\\mathcal{G}$ equipped with the nesting product. We give an algorithm producing\nthe prime factorization of individual walks, and obtain a recursive formula\nproducing the prime factorization of sets of walks. Our results have already\nfound applications in machine learning, matrix computations and quantum\nmechanics.\n", "Comment: Updated with links between nesting and loop-erasing. Still under\n  review (!)"]}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "05c25", "05c22", "05c20", "05c38", "mathematics - representation theory"], "providerUpdatedDateTime": "2015-01-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1202.5523"}}, {"publisher": {"name": ""}, "description": "  We propose a Viterbi-type trellis-search algorithm to implement the FSO\nphoton-counting sequence receiver proposed in [1] more efficiently and a\nselective-store strategy to overcome the error floor problem observed therein.\n", "contributors": [{"name": "Song, Tianyu", "sameAs": [], "familyName": "Song", "additionalName": "", "givenName": "Tianyu", "email": ""}, {"name": "Kam, Pooi-Yuen", "sameAs": [], "familyName": "Kam", "additionalName": "", "givenName": "Pooi-Yuen", "email": ""}], "title": "A Robust and Efficient Detection Algorithm for The Photon-Counting\n  Free-Space Optical System", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6131", "oai:arXiv.org:1412.6131"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We propose a Viterbi-type trellis-search algorithm to implement the FSO\nphoton-counting sequence receiver proposed in [1] more efficiently and a\nselective-store strategy to overcome the error floor problem observed therein.\n", "Comment: 3 pages"]}}], "languages": [null], "subjects": ["physics - optics", "computer science - information theory"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6131"}}, {"publisher": {"name": ""}, "description": "  Clustering is typically measured by the ratio of triangles to all triples,\nopen or closed. Generating clustered networks, and how clustering affects\ndynamics on networks, is reasonably well understood for certain classes of\nnetworks \\cite{vmclust, karrerclust2010}, e.g., networks composed of lines and\nnon-overlapping triangles. In this paper we show that it is possible to\ngenerate networks which, despite having the same degree distribution and equal\nclustering, exhibit different higher-order structure, specifically, overlapping\ntriangles and other order-four (a closed network motif composed of four nodes)\nstructures. To distinguish and quantify these additional structural features,\nwe develop a new network metric capable of measuring order-four structure\nwhich, when used alongside traditional network metrics, allows us to more\naccurately describe a network's topology. Three network generation algorithms\nare considered: a modified configuration model and two rewiring algorithms. By\ngenerating homogeneous networks with equal clustering we study and quantify\ntheir structural differences, and using SIS (Susceptible-Infected-Susceptible)\nand SIR (Susceptible-Infected-Recovered) dynamics we investigate\ncomputationally how differences in higher-order structure impact on epidemic\nthreshold, final epidemic or prevalence levels and time evolution of epidemics.\nOur results suggest that characterising and measuring higher-order network\nstructure is needed to advance our understanding of the impact of network\ntopology on dynamics unfolding on the networks.\n", "contributors": [{"name": "Ritchie, Martin", "sameAs": [], "familyName": "Ritchie", "additionalName": "", "givenName": "Martin", "email": ""}, {"name": "Berthouze, Luc", "sameAs": [], "familyName": "Berthouze", "additionalName": "", "givenName": "Luc", "email": ""}, {"name": "House, Thomas", "sameAs": [], "familyName": "House", "additionalName": "", "givenName": "Thomas", "email": ""}, {"name": "Kiss, Istvan Z.", "sameAs": [], "familyName": "Kiss", "additionalName": "Z.", "givenName": "Istvan", "email": ""}], "title": "Higher-order structure and epidemic dynamics in clustered networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-10-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.5047", "Journal Theoretical Biology 2014, 348:21-32", "doi:10.1016/j.jtbi.2014.01.025", "oai:arXiv.org:1310.5047"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics", "q-bio"]}}, {"name": "description", "properties": {"description": "  Clustering is typically measured by the ratio of triangles to all triples,\nopen or closed. Generating clustered networks, and how clustering affects\ndynamics on networks, is reasonably well understood for certain classes of\nnetworks \\cite{vmclust, karrerclust2010}, e.g., networks composed of lines and\nnon-overlapping triangles. In this paper we show that it is possible to\ngenerate networks which, despite having the same degree distribution and equal\nclustering, exhibit different higher-order structure, specifically, overlapping\ntriangles and other order-four (a closed network motif composed of four nodes)\nstructures. To distinguish and quantify these additional structural features,\nwe develop a new network metric capable of measuring order-four structure\nwhich, when used alongside traditional network metrics, allows us to more\naccurately describe a network's topology. Three network generation algorithms\nare considered: a modified configuration model and two rewiring algorithms. By\ngenerating homogeneous networks with equal clustering we study and quantify\ntheir structural differences, and using SIS (Susceptible-Infected-Susceptible)\nand SIR (Susceptible-Infected-Recovered) dynamics we investigate\ncomputationally how differences in higher-order structure impact on epidemic\nthreshold, final epidemic or prevalence levels and time evolution of epidemics.\nOur results suggest that characterising and measuring higher-order network\nstructure is needed to advance our understanding of the impact of network\ntopology on dynamics unfolding on the networks.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "quantitative biology - populations and evolution", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-10-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.5047"}}, {"publisher": {"name": ""}, "description": "  The small sample universal hypothesis testing problem is investigated in this\npaper, in which the number of samples $n$ is smaller than the number of\npossible outcomes $m$. The goal of this work is to find an appropriate\ncriterion to analyze statistical tests in this setting. A suitable model for\nanalysis is the high-dimensional model in which both $n$ and $m$ increase to\ninfinity, and $n=o(m)$. A new performance criterion based on large deviations\nanalysis is proposed and it generalizes the classical error exponent applicable\nfor large sample problems (in which $m=O(n)$). This generalized error exponent\ncriterion provides insights that are not available from asymptotic consistency\nor central limit theorem analysis. The following results are established for\nthe uniform null distribution:\n  (i) The best achievable probability of error $P_e$ decays as\n$P_e=\\exp\\{-(n^2/m) J (1+o(1))\\}$ for some $J>0$.\n  (ii) A class of tests based on separable statistics, including the\ncoincidence-based test, attains the optimal generalized error exponents.\n  (iii) Pearson's chi-square test has a zero generalized error exponent and\nthus its probability of error is asymptotically larger than the optimal test.\n", "contributors": [{"name": "Huang, Dayu", "sameAs": [], "familyName": "Huang", "additionalName": "", "givenName": "Dayu", "email": ""}, {"name": "Meyn, Sean", "sameAs": [], "familyName": "Meyn", "additionalName": "", "givenName": "Sean", "email": ""}], "title": "Generalized Error Exponents For Small Sample Universal Hypothesis\n  Testing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-04-06", "2014-12-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1204.1563", "IEEE Transactions on Information Theory, vol.59, no.12,\n  pp.8157,8181, Dec. 2013", "doi:10.1109/TIT.2013.2283266", "oai:arXiv.org:1204.1563"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  The small sample universal hypothesis testing problem is investigated in this\npaper, in which the number of samples $n$ is smaller than the number of\npossible outcomes $m$. The goal of this work is to find an appropriate\ncriterion to analyze statistical tests in this setting. A suitable model for\nanalysis is the high-dimensional model in which both $n$ and $m$ increase to\ninfinity, and $n=o(m)$. A new performance criterion based on large deviations\nanalysis is proposed and it generalizes the classical error exponent applicable\nfor large sample problems (in which $m=O(n)$). This generalized error exponent\ncriterion provides insights that are not available from asymptotic consistency\nor central limit theorem analysis. The following results are established for\nthe uniform null distribution:\n  (i) The best achievable probability of error $P_e$ decays as\n$P_e=\\exp\\{-(n^2/m) J (1+o(1))\\}$ for some $J>0$.\n  (ii) A class of tests based on separable statistics, including the\ncoincidence-based test, attains the optimal generalized error exponents.\n  (iii) Pearson's chi-square test has a zero generalized error exponent and\nthus its probability of error is asymptotically larger than the optimal test.\n", "Comment: 43 pages, 4 figures"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "computer science - information theory"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1204.1563"}}, {"publisher": {"name": ""}, "description": "  A novel framework to construct an efficient sensing (measurement) matrix,\ncalled mixed adaptive-random (MAR) matrix, is introduced for directly acquiring\na compressed image representation. The mixed sampling (sensing) procedure\nhybridizes adaptive edge measurements extracted from a low-resolution image\nwith uniform random measurements predefined for the high-resolution image to be\nrecovered. The mixed sensing matrix seamlessly captures important information\nof an image, and meanwhile approximately satisfies the restricted isometry\nproperty. To recover the high-resolution image from MAR measurements, the total\nvariation algorithm based on the compressive sensing theory is employed for\nsolving the Lagrangian regularization problem. Both peak signal-to-noise ratio\nand structural similarity results demonstrate the MAR sensing framework shows\nmuch better recovery performance than the completely random sensing one. The\nwork is particularly helpful for high-performance and lost-cost data\nacquisition.\n", "contributors": [{"name": "Yang, Jun", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Jun", "email": ""}, {"name": "Sha, Wei E. I.", "sameAs": [], "familyName": "Sha", "additionalName": "E. I.", "givenName": "Wei", "email": ""}, {"name": "Chao, Hongyang", "sameAs": [], "familyName": "Chao", "additionalName": "", "givenName": "Hongyang", "email": ""}, {"name": "Jin, Zhu", "sameAs": [], "familyName": "Jin", "additionalName": "", "givenName": "Zhu", "email": ""}], "title": "High-quality Image Restoration from Partial Mixed Adaptive-Random\n  Measurements", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-03", "2015-04-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.1020", "doi:10.1007/s11042-015-2566-9", "oai:arXiv.org:1312.1020"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A novel framework to construct an efficient sensing (measurement) matrix,\ncalled mixed adaptive-random (MAR) matrix, is introduced for directly acquiring\na compressed image representation. The mixed sampling (sensing) procedure\nhybridizes adaptive edge measurements extracted from a low-resolution image\nwith uniform random measurements predefined for the high-resolution image to be\nrecovered. The mixed sensing matrix seamlessly captures important information\nof an image, and meanwhile approximately satisfies the restricted isometry\nproperty. To recover the high-resolution image from MAR measurements, the total\nvariation algorithm based on the compressive sensing theory is employed for\nsolving the Lagrangian regularization problem. Both peak signal-to-noise ratio\nand structural similarity results demonstrate the MAR sensing framework shows\nmuch better recovery performance than the completely random sensing one. The\nwork is particularly helpful for high-performance and lost-cost data\nacquisition.\n", "Comment: 16 pages, 8 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.1020"}}, {"publisher": {"name": ""}, "description": "  The growing complexity of real-world problems has motivated computer\nscientists to search for efficient problem-solving methods. Metaheuristics\nbased on evolutionary computation and swarm intelligence are outstanding\nexamples of nature-inspired solution techniques. Inspired by the social\nspiders, we propose a novel Social Spider Algorithm to solve global\noptimization problems. This algorithm is mainly based on the foraging strategy\nof social spiders, utilizing the vibrations on the spider web to determine the\npositions of preys. Different from the previously proposed swarm intelligence\nalgorithms, we introduce a new social animal foraging strategy model to solve\noptimization problems. In addition, we perform preliminary parameter\nsensitivity analysis for our proposed algorithm, developing guidelines for\nchoosing the parameter values. The Social Spider Algorithm is evaluated by a\nseries of widely-used benchmark functions, and our proposed algorithm has\nsuperior performance compared with other state-of-the-art metaheuristics.\n", "contributors": [{"name": "Yu, James J. Q.", "sameAs": [], "familyName": "Yu", "additionalName": "J. Q.", "givenName": "James", "email": ""}, {"name": "Li, Victor O. K.", "sameAs": [], "familyName": "Li", "additionalName": "O. K.", "givenName": "Victor", "email": ""}], "title": "A Social Spider Algorithm for Global Optimization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02407", "oai:arXiv.org:1502.02407"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The growing complexity of real-world problems has motivated computer\nscientists to search for efficient problem-solving methods. Metaheuristics\nbased on evolutionary computation and swarm intelligence are outstanding\nexamples of nature-inspired solution techniques. Inspired by the social\nspiders, we propose a novel Social Spider Algorithm to solve global\noptimization problems. This algorithm is mainly based on the foraging strategy\nof social spiders, utilizing the vibrations on the spider web to determine the\npositions of preys. Different from the previously proposed swarm intelligence\nalgorithms, we introduce a new social animal foraging strategy model to solve\noptimization problems. In addition, we perform preliminary parameter\nsensitivity analysis for our proposed algorithm, developing guidelines for\nchoosing the parameter values. The Social Spider Algorithm is evaluated by a\nseries of widely-used benchmark functions, and our proposed algorithm has\nsuperior performance compared with other state-of-the-art metaheuristics.\n"}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing"], "providerUpdatedDateTime": "2015-02-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02407"}}, {"publisher": {"name": "Blackwell publishing Ltd"}, "description": "Recent experimental work has described an elegant pattern of branching in the development of the lung. Multiple forms of branching have been identified, including side branching and tip bifurcation. A particularly interesting feature is the phenomenon of \u2018orthogonal rotation of the branching plane\u2019. The lung must fill 3D space with the essentially 2D phenomenon of branching. It accomplishes this by rotating the branching plane by 90\u00b0 with each generation. The mechanisms underlying this rotation are not understood. In general, the programmes that underlie branching have been hypothetically attributed to genetic \u2018subroutines\u2019 under the control of a \u2018global master routine\u2019 to invoke particular subroutines at the proper time and location, but the mechanisms of these routines are not known. Here, we demonstrate that fundamental mechanisms, the reaction and diffusion of biochemical morphogens, can create these patterns. We used a partial differential equation model that postulates three morphogens, which we identify with specific molecules in lung development. We found that cascades of branching events, including side branching, tip splitting and orthogonal rotation of the branching plane, all emerge immediately from the model, without further assumptions. In addition, we found that one branching mode can be easily switched to another, by increasing or decreasing the values of key parameters. This shows how a \u2018global master routine\u2019 could work by the alteration of a single parameter. Being able to simulate cascades of branching events is necessary to understand the critical features of branching, such as orthogonal rotation of the branching plane between successive generations, and branching mode switch during lung development. Thus, our model provides a paradigm for how genes could possibly act to produce these spatial structures. Our low-dimensional model gives a qualitative understanding of how generic physiological mechanisms can produce branching phenomena, and how the system can switch from one branching pattern to another using low-dimensional \u2018control knobs\u2019. The model provides a number of testable predictions, some of which have already been observed (though not explained) in experimental work.", "contributors": [{"name": "Guo, Yina", "sameAs": [], "familyName": "Guo", "additionalName": "", "givenName": "Yina", "email": ""}, {"name": "Chen, Ting-Hsuan", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Ting-Hsuan", "email": ""}, {"name": "Zeng, Xingjuan", "sameAs": [], "familyName": "Zeng", "additionalName": "", "givenName": "Xingjuan", "email": ""}, {"name": "Warburton, David", "sameAs": [], "familyName": "Warburton", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Bostr\u00f6m, Kristina I", "sameAs": [], "familyName": "Bostr\u00f6m", "additionalName": "I", "givenName": "Kristina", "email": ""}, {"name": "Ho, Chih-Ming", "sameAs": [], "familyName": "Ho", "additionalName": "", "givenName": "Chih-Ming", "email": ""}, {"name": "Zhao, Xin", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Xin", "email": ""}, {"name": "Garfinkel, Alan", "sameAs": [], "familyName": "Garfinkel", "additionalName": "", "givenName": "Alan", "email": ""}], "title": "Branching patterns emerge in a mathematical model of the dynamics of lung development", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["computational physiology and modelling"], "providerUpdatedDateTime": "2015-01-15T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3922496"}}, {"publisher": {"name": ""}, "description": "  Research on the so-called \"free-energy principle'' (FEP) in cognitive\nneuroscience is becoming increasingly high-profile. To date, introductions to\nthis theory have proved difficult for many readers to follow, but it depends\nmainly upon two relatively simple ideas: firstly that normative or teleological\nvalues can be expressed as probability distributions (active inference), and\nsecondly that approximate Bayesian reasoning can be effectively performed by\ngradient descent on model parameters (the free-energy principle). The notion of\nactive inference is of great interest for a number of disciplines including\ncognitive science and artificial intelligence, as well as cognitive\nneuroscience, and deserves to be more widely known.\n  This paper attempts to provide an accessible introduction to active inference\nand informational free-energy, for readers from a range of scientific\nbackgrounds. In this work introduce an agent-based model with an agent trying\nto make predictions about its position in a one-dimensional discretized world\nusing methods from the FEP.\n", "contributors": [{"name": "McGregor, Simon", "sameAs": [], "familyName": "McGregor", "additionalName": "", "givenName": "Simon", "email": ""}, {"name": "Baltieri, Manuel", "sameAs": [], "familyName": "Baltieri", "additionalName": "", "givenName": "Manuel", "email": ""}, {"name": "Buckley, Christopher L.", "sameAs": [], "familyName": "Buckley", "additionalName": "L.", "givenName": "Christopher", "email": ""}], "title": "A Minimal Active Inference Agent", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04187", "oai:arXiv.org:1503.04187"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Research on the so-called \"free-energy principle'' (FEP) in cognitive\nneuroscience is becoming increasingly high-profile. To date, introductions to\nthis theory have proved difficult for many readers to follow, but it depends\nmainly upon two relatively simple ideas: firstly that normative or teleological\nvalues can be expressed as probability distributions (active inference), and\nsecondly that approximate Bayesian reasoning can be effectively performed by\ngradient descent on model parameters (the free-energy principle). The notion of\nactive inference is of great interest for a number of disciplines including\ncognitive science and artificial intelligence, as well as cognitive\nneuroscience, and deserves to be more widely known.\n  This paper attempts to provide an accessible introduction to active inference\nand informational free-energy, for readers from a range of scientific\nbackgrounds. In this work introduce an agent-based model with an agent trying\nto make predictions about its position in a one-dimensional discretized world\nusing methods from the FEP.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2015-03-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04187"}}, {"publisher": {"name": ""}, "description": "  The random access problem for compressed strings is to build a data structure\nthat efficiently supports accessing the character in position $i$ of a string\ngiven in compressed form. Given a grammar of size $n$ compressing a string of\nsize $N$, we present a data structure using $O(n\\Delta \\log_\\Delta \\frac N n\n\\log N)$ bits of space that supports accessing position $i$ in $O(\\log_\\Delta\nN)$ time for $\\Delta \\leq \\log^{O(1)} N$. The query time is optimal for\npolynomially compressible strings, i.e., when $n=O(N^{1-\\epsilon})$.\n", "contributors": [{"name": "Cording, Patrick Hagge", "sameAs": [], "familyName": "Cording", "additionalName": "Hagge", "givenName": "Patrick", "email": ""}], "title": "Optimal Time Random Access to Grammar-Compressed Strings in Small Space", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-17", "2015-01-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4701", "oai:arXiv.org:1410.4701"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The random access problem for compressed strings is to build a data structure\nthat efficiently supports accessing the character in position $i$ of a string\ngiven in compressed form. Given a grammar of size $n$ compressing a string of\nsize $N$, we present a data structure using $O(n\\Delta \\log_\\Delta \\frac N n\n\\log N)$ bits of space that supports accessing position $i$ in $O(\\log_\\Delta\nN)$ time for $\\Delta \\leq \\log^{O(1)} N$. The query time is optimal for\npolynomially compressible strings, i.e., when $n=O(N^{1-\\epsilon})$.\n", "Comment: Withdrawn because of errors in proofs. Fixed versions will be\n  incorporated into a paper by other authors"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4701"}}, {"publisher": {"name": ""}, "description": "  Symbolic execution is an effective path oriented and constraint based program\nanalysis technique. Recently, there is a significant development in the\nresearch and application of symbolic execution. However, symbolic execution\nstill suffers from the scalability problem in practice, especially when applied\nto large-scale or very complex programs. In this paper, we propose a new\nfashion of symbolic execution, named Speculative Symbolic Execution (SSE), to\nspeed up symbolic execution by reducing the invocation times of constraint\nsolver. In SSE, when encountering a branch statement, the search procedure may\nspeculatively explore the branch without regard to the feasibility. Constraint\nsolver is invoked only when the speculated branches are accumulated to a\nspecified number. In addition, we present a key optimization technique that\nenhances SSE greatly. We have implemented SSE and the optimization technique on\nSymbolic Pathfinder (SPF). Experimental results on six programs show that, our\nmethod can reduce the invocation times of constraint solver by 21% to 49% (with\nan average of 30%), and save the search time from 23.6% to 43.6% (with an\naverage of 30%).\n", "contributors": [{"name": "Zhang, Yufeng", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Yufeng", "email": ""}, {"name": "Chen, Zhenbang", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Zhenbang", "email": ""}, {"name": "Wang, Ji", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Ji", "email": ""}], "title": "Speculative Symbolic Execution", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-05-22", "2012-05-31"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.4951", "oai:arXiv.org:1205.4951"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Symbolic execution is an effective path oriented and constraint based program\nanalysis technique. Recently, there is a significant development in the\nresearch and application of symbolic execution. However, symbolic execution\nstill suffers from the scalability problem in practice, especially when applied\nto large-scale or very complex programs. In this paper, we propose a new\nfashion of symbolic execution, named Speculative Symbolic Execution (SSE), to\nspeed up symbolic execution by reducing the invocation times of constraint\nsolver. In SSE, when encountering a branch statement, the search procedure may\nspeculatively explore the branch without regard to the feasibility. Constraint\nsolver is invoked only when the speculated branches are accumulated to a\nspecified number. In addition, we present a key optimization technique that\nenhances SSE greatly. We have implemented SSE and the optimization technique on\nSymbolic Pathfinder (SPF). Experimental results on six programs show that, our\nmethod can reduce the invocation times of constraint solver by 21% to 49% (with\nan average of 30%), and save the search time from 23.6% to 43.6% (with an\naverage of 30%).\n", "Comment: 14 pages, 15 figures"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.4951"}}, {"publisher": {"name": ""}, "description": "  This letter proposes an analytical approach to formulate the power system\noscillation frequency under a large disturbance. A fact is revealed that the\noscillation frequency is only the function of the oscillation amplitude when\nthe system's model and operating condition are fixed. Case studies also show\nthat this function is damping-insensitive and could be applied to an inter-area\nmodel of a multi-machine power system.\n", "contributors": [{"name": "Wang, Bin", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Bin", "email": ""}, {"name": "Sun, Kai", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Kai", "email": ""}], "title": "An Analytical Formulation of Power System Oscillation Frequency", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07554", "oai:arXiv.org:1503.07554"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This letter proposes an analytical approach to formulate the power system\noscillation frequency under a large disturbance. A fact is revealed that the\noscillation frequency is only the function of the oscillation amplitude when\nthe system's model and operating condition are fixed. Case studies also show\nthat this function is damping-insensitive and could be applied to an inter-area\nmodel of a multi-machine power system.\n", "Comment: 2 pages"]}}], "languages": [null], "subjects": ["computer science - systems and control"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07554"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Modeling of multiphase flow in fractured media plays an integral role in management and performance prediction of oil and gas reserves. Geological characterization and nmultiphase flow simulations in fractured media are challenging for several reasons, such as uncertainty in fracture location, complexity in fracture geometry. dynamic nature of fractures etc. There is a need for complex sinmulation models that resolve the flow dynamics along fractures and the interaction with the porous matrix. The unstructured finite volume model provides a tool for the numerical simulation of multiphase flow (inmmiscible and incompressible two-phase flow) in two-dimensional fractured media. We use a finite volume formulation, which is locally imass conservative and it allows the use of fully unstructured grids to represent the coimplex geometry of the fracture networks. Fractures are represented as objects of lower diniensionality than that of the domain (in this case, ID objects in a 2D domain). The model permits fine-scale simulation of multiphase transport through fractured media. The non-Fickian transport resulting due to the presence of heterogeneity (as fractures or inhomogeneous permeability distribution) is captured by the traditional advection-diffusion equation using a highly discretized system. Today. many macroscopic flow models are being developed which account for the non-Fickian. non-local flow more accurately and efficiently with less computation. The finite volume simulator niodel described in this thesis will be instrumental as a tool to train and validate the macroscopic flow models which account for anomialous transport behavior.", "contributors": [{"name": "Bajaj, Reena", "sameAs": [], "familyName": "Bajaj", "additionalName": "", "givenName": "Reena", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "Ruben Juanes.", "sameAs": [], "familyName": "Juanes.", "additionalName": "", "givenName": "Ruben", "email": ""}], "title": "An unstructured finite volume simulator for multiphase flow through fractured-porous media", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "78 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/54839", "586077607", "oai:dspace.mit.edu:1721.1/54839"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2010-05-25T19:19:27Z", "2010-05-25T19:19:27Z", "2009", "2009"]}}, {"name": "description", "properties": {"description": ["Modeling of multiphase flow in fractured media plays an integral role in management and performance prediction of oil and gas reserves. Geological characterization and nmultiphase flow simulations in fractured media are challenging for several reasons, such as uncertainty in fracture location, complexity in fracture geometry. dynamic nature of fractures etc. There is a need for complex sinmulation models that resolve the flow dynamics along fractures and the interaction with the porous matrix. The unstructured finite volume model provides a tool for the numerical simulation of multiphase flow (inmmiscible and incompressible two-phase flow) in two-dimensional fractured media. We use a finite volume formulation, which is locally imass conservative and it allows the use of fully unstructured grids to represent the coimplex geometry of the fracture networks. Fractures are represented as objects of lower diniensionality than that of the domain (in this case, ID objects in a 2D domain). The model permits fine-scale simulation of multiphase transport through fractured media. The non-Fickian transport resulting due to the presence of heterogeneity (as fractures or inhomogeneous permeability distribution) is captured by the traditional advection-diffusion equation using a highly discretized system. Today. many macroscopic flow models are being developed which account for the non-Fickian. non-local flow more accurately and efficiently with less computation. The finite volume simulator niodel described in this thesis will be instrumental as a tool to train and validate the macroscopic flow models which account for anomialous transport behavior.", "(cont.) We illustrate the performance of this simulator on several synthetic cases with different fracture geometries and conclude the model effectively captures the miiultiphase fluid flow pattern in fractured media.", "by Reena Bajaj.", "Thesis (S.M.)--Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2009.", "This electronic version was submitted by the student author.  The certified thesis is available in the Institute Archives and Special Collections.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (p. 77-78)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39115", "hdl_1721.1_39117"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:18", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/54839"}}, {"publisher": {"name": ""}, "description": "  Many probabilistic programming languages allow programs to be run under\nconstraints in order to carry out Bayesian inference. Running programs under\nconstraints could enable other uses such as rare event simulation and\nprobabilistic verification---except that all such probabilistic languages are\nnecessarily limited because they are defined or implemented in terms of an\nimpoverished theory of probability. Measure-theoretic probability provides a\nmore general foundation, but its generality makes finding computational content\ndifficult.\n  We develop a measure-theoretic semantics for a first-order probabilistic\nlanguage with recursion, which interprets programs as functions that compute\npreimages. Preimage functions are generally uncomputable, so we derive an\nabstract semantics. We implement the abstract semantics and use the\nimplementation to carry out Bayesian inference, stochastic ray tracing (a rare\nevent simulation), and probabilistic verification of floating-point error\nbounds.\n", "contributors": [{"name": "Toronto, Neil", "sameAs": [], "familyName": "Toronto", "additionalName": "", "givenName": "Neil", "email": ""}, {"name": "McCarthy, Jay", "sameAs": [], "familyName": "McCarthy", "additionalName": "", "givenName": "Jay", "email": ""}, {"name": "Van Horn, David", "sameAs": [], "familyName": "Van Horn", "additionalName": "", "givenName": "David", "email": ""}], "title": "Running Probabilistic Programs Backwards", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-12", "2015-01-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4053", "oai:arXiv.org:1412.4053"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Many probabilistic programming languages allow programs to be run under\nconstraints in order to carry out Bayesian inference. Running programs under\nconstraints could enable other uses such as rare event simulation and\nprobabilistic verification---except that all such probabilistic languages are\nnecessarily limited because they are defined or implemented in terms of an\nimpoverished theory of probability. Measure-theoretic probability provides a\nmore general foundation, but its generality makes finding computational content\ndifficult.\n  We develop a measure-theoretic semantics for a first-order probabilistic\nlanguage with recursion, which interprets programs as functions that compute\npreimages. Preimage functions are generally uncomputable, so we derive an\nabstract semantics. We implement the abstract semantics and use the\nimplementation to carry out Bayesian inference, stochastic ray tracing (a rare\nevent simulation), and probabilistic verification of floating-point error\nbounds.\n", "Comment: 26 pages, ESOP 2015 (to appear)"]}}], "languages": [null], "subjects": ["computer science - programming languages"], "providerUpdatedDateTime": "2015-01-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4053"}}, {"publisher": {"name": ""}, "description": "  Obtaining a good load balance is a significant challenge in scaling up\nlattice-Boltzmann simulations of realistic sparse problems to the exascale.\nHere we analyze the effect of weighted decomposition on the performance of the\nHemeLB lattice-Boltzmann simulation environment, when applied to sparse\ndomains. Prior to domain decomposition, we assign wall and in/outlet sites with\nincreased weights which reflect their increased computational cost. We combine\nour weighted decomposition with a second optimization, which is to sort the\nlattice sites according to a space filling curve. We tested these strategies on\na sparse bifurcation and very sparse aneurysm geometry, and find that using\nweights reduces calculation load imbalance by up to 85%, although the overall\ncommunication overhead is higher than some of our runs.\n", "contributors": [{"name": "Groen, Derek", "sameAs": [], "familyName": "Groen", "additionalName": "", "givenName": "Derek", "email": ""}, {"name": "Chacra, David Abou", "sameAs": [], "familyName": "Chacra", "additionalName": "Abou", "givenName": "David", "email": ""}, {"name": "Nash, Rupert W.", "sameAs": [], "familyName": "Nash", "additionalName": "W.", "givenName": "Rupert", "email": ""}, {"name": "Jaros, Jiri", "sameAs": [], "familyName": "Jaros", "additionalName": "", "givenName": "Jiri", "email": ""}, {"name": "Bernabeu, Miguel O.", "sameAs": [], "familyName": "Bernabeu", "additionalName": "O.", "givenName": "Miguel", "email": ""}, {"name": "Coveney, Peter V.", "sameAs": [], "familyName": "Coveney", "additionalName": "V.", "givenName": "Peter", "email": ""}], "title": "Weighted decomposition in high-performance lattice-Boltzmann\n  simulations: are some lattice sites more equal than others?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4713", "oai:arXiv.org:1410.4713"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat"]}}, {"name": "description", "properties": {"description": ["  Obtaining a good load balance is a significant challenge in scaling up\nlattice-Boltzmann simulations of realistic sparse problems to the exascale.\nHere we analyze the effect of weighted decomposition on the performance of the\nHemeLB lattice-Boltzmann simulation environment, when applied to sparse\ndomains. Prior to domain decomposition, we assign wall and in/outlet sites with\nincreased weights which reflect their increased computational cost. We combine\nour weighted decomposition with a second optimization, which is to sort the\nlattice sites according to a space filling curve. We tested these strategies on\na sparse bifurcation and very sparse aneurysm geometry, and find that using\nweights reduces calculation load imbalance by up to 85%, although the overall\ncommunication overhead is higher than some of our runs.\n", "Comment: 11 pages, 8 figures, 1 table, accepted for the EASC2014 conference"]}}], "languages": [null], "subjects": ["i.6.8", "g.4", "68w40", "i.6.3", "i.3.1", "condensed matter - mesoscale and nanoscale physics", "68n30", "and cluster computing", "65yxx", "computer science - distributed", "68w10", "68u20", "parallel", "g.1.0"], "providerUpdatedDateTime": "2014-10-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4713"}}, {"publisher": {"name": ""}, "description": "  The paper examines the learning mechanism of adaptive agents over\nweakly-connected graphs and reveals an interesting behavior on how information\nflows through such topologies. The results clarify how asymmetries in the\nexchange of data can mask local information at certain agents and make them\ntotally dependent on other agents. A leader-follower relationship develops with\nthe performance of some agents being fully determined by the performance of\nother agents that are outside their domain of influence. This scenario can\narise, for example, due to intruder attacks by malicious agents or as the\nresult of failures by some critical links. The findings in this work help\nexplain why strong-connectivity of the network topology, adaptation of the\ncombination weights, and clustering of agents are important ingredients to\nequalize the learning abilities of all agents against such disturbances. The\nresults also clarify how weak-connectivity can be helpful in reducing the\neffect of outlier data on learning performance.\n", "contributors": [{"name": "Ying, Bicheng", "sameAs": [], "familyName": "Ying", "additionalName": "", "givenName": "Bicheng", "email": ""}, {"name": "Sayed, Ali H.", "sameAs": [], "familyName": "Sayed", "additionalName": "H.", "givenName": "Ali", "email": ""}], "title": "Information Exchange and Learning Dynamics over Weakly-Connected\n  Adaptive Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1523", "oai:arXiv.org:1412.1523"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The paper examines the learning mechanism of adaptive agents over\nweakly-connected graphs and reveals an interesting behavior on how information\nflows through such topologies. The results clarify how asymmetries in the\nexchange of data can mask local information at certain agents and make them\ntotally dependent on other agents. A leader-follower relationship develops with\nthe performance of some agents being fully determined by the performance of\nother agents that are outside their domain of influence. This scenario can\narise, for example, due to intruder attacks by malicious agents or as the\nresult of failures by some critical links. The findings in this work help\nexplain why strong-connectivity of the network topology, adaptation of the\ncombination weights, and clustering of agents are important ingredients to\nequalize the learning abilities of all agents against such disturbances. The\nresults also clarify how weak-connectivity can be helpful in reducing the\neffect of outlier data on learning performance.\n", "Comment: 17 pages, 9 figures"]}}], "languages": [null], "subjects": ["computer science - information theory", "computer science - multiagent systems", "computer science - learning"], "providerUpdatedDateTime": "2014-12-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1523"}}, {"publisher": {"name": ""}, "description": "  In phase retrieval, the goal is to recover a signal\n$\\mathbf{x}\\in\\mathbb{C}^N$ from the magnitudes of linear measurements\n$\\mathbf{Ax}\\in\\mathbb{C}^M$. While recent theory has established that\n$M\\approx 4N$ intensity measurements are necessary and sufficient to recover\ngeneric $\\mathbf{x}$, there is great interest in reducing the number of\nmeasurements through the exploitation of sparse $\\mathbf{x}$, which is known as\ncompressive phase retrieval. In this work, we detail a novel, probabilistic\napproach to compressive phase retrieval based on the generalized approximate\nmessage passing (GAMP) algorithm. We then present a numerical study of the\nproposed PR-GAMP algorithm, demonstrating its excellent phase-transition\nbehavior, robustness to noise, and runtime. Our experiments suggest that\napproximately $M\\geq 2K\\log_2(N/K)$ intensity measurements suffice to recover\n$K$-sparse Bernoulli-Gaussian signals for $\\mathbf{A}$ with i.i.d Gaussian\nentries and $K\\ll N$. Meanwhile, when recovering a 6k-sparse 65k-pixel\ngrayscale image from 32k randomly masked and blurred Fourier intensity\nmeasurements at 30~dB measurement SNR, PR-GAMP achieved an output SNR of no\nless than 28~dB in all of 100 random trials, with a median runtime of only 7.3\nseconds. Compared to the recently proposed CPRL, sparse-Fienup, and GESPAR\nalgorithms, our experiments suggest that PR-GAMP has a superior phase\ntransition and orders-of-magnitude faster runtimes as the sparsity and problem\ndimensions increase.\n", "contributors": [{"name": "Schniter, Philip", "sameAs": [], "familyName": "Schniter", "additionalName": "", "givenName": "Philip", "email": ""}, {"name": "Rangan, Sundeep", "sameAs": [], "familyName": "Rangan", "additionalName": "", "givenName": "Sundeep", "email": ""}], "title": "Compressive Phase Retrieval via Generalized Approximate Message Passing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-21", "2014-10-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.5618", "oai:arXiv.org:1405.5618"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In phase retrieval, the goal is to recover a signal\n$\\mathbf{x}\\in\\mathbb{C}^N$ from the magnitudes of linear measurements\n$\\mathbf{Ax}\\in\\mathbb{C}^M$. While recent theory has established that\n$M\\approx 4N$ intensity measurements are necessary and sufficient to recover\ngeneric $\\mathbf{x}$, there is great interest in reducing the number of\nmeasurements through the exploitation of sparse $\\mathbf{x}$, which is known as\ncompressive phase retrieval. In this work, we detail a novel, probabilistic\napproach to compressive phase retrieval based on the generalized approximate\nmessage passing (GAMP) algorithm. We then present a numerical study of the\nproposed PR-GAMP algorithm, demonstrating its excellent phase-transition\nbehavior, robustness to noise, and runtime. Our experiments suggest that\napproximately $M\\geq 2K\\log_2(N/K)$ intensity measurements suffice to recover\n$K$-sparse Bernoulli-Gaussian signals for $\\mathbf{A}$ with i.i.d Gaussian\nentries and $K\\ll N$. Meanwhile, when recovering a 6k-sparse 65k-pixel\ngrayscale image from 32k randomly masked and blurred Fourier intensity\nmeasurements at 30~dB measurement SNR, PR-GAMP achieved an output SNR of no\nless than 28~dB in all of 100 random trials, with a median runtime of only 7.3\nseconds. Compared to the recently proposed CPRL, sparse-Fienup, and GESPAR\nalgorithms, our experiments suggest that PR-GAMP has a superior phase\ntransition and orders-of-magnitude faster runtimes as the sparsity and problem\ndimensions increase.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.5618"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Power monitoring is needed in most electrical systems, and is crucial for ensuring reliability in everything from industrial and telecom applications, to automotive and consumer electronics. Power monitoring of integrated circuits (ICs) is also essential, as today ICs exist in most electrical and electronic systems, in a vast range of applications. Many ICs, including power ICs, have functional blocks across the chip that are used for different purposes. Measuring circuit block currents in both analog and digital ICs is important in a wide range of applications, including power management as well as IC testing and fault detection and analysis. For example, the presence of different kinds of faults in IC circuit blocks during IC fabrication causes the currents flowing through these circuit blocks to change from the expected values. There has been general interest in monitoring currents through different circuit blocks in an attempt to identify the location and type of the faults. Previous works on non intrusive load monitoring as well as on power-line communications (PLCs) provide motivation for the work presented here. The techniques are extended and used to develop a new method for power monitoring in ICs. Most solutions to the challenge of measuring currents in different circuit blocks of the IC involve adding circuitry that is both costly and power consuming. In this work, a new method is proposed to enable individual measurement of current consumed in each circuit block within an IC while adding negligible area and power overhead. This method works by encoding the individual current signatures in the main supply current of the IC, which can then be sensed and sampled off-chip, and then disaggregated through signal processing. A demonstration of this power monitoring scheme is given on a modular discrete platform that is implemented based on the UC3842 current-mode controller IC, which can also be used for educational purposes.", "contributors": [{"name": "Al Bastami, Anas Ibrahim", "sameAs": [], "familyName": "Al Bastami", "additionalName": "Ibrahim", "givenName": "Anas", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Electrical Engineering and Computer Science.", "sameAs": [], "familyName": "Science.", "additionalName": "Institute of Technology. Department of Electrical Engineering and Computer", "givenName": "Massachusetts", "email": ""}, {"name": "Steven B. Leeb and Al-Thaddeus Avestruz.", "sameAs": [], "familyName": "Avestruz.", "additionalName": "B. Leeb and Al-Thaddeus", "givenName": "Steven", "email": ""}], "title": "Power monitoring in integrated circuits", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "203 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/92973", "900011753", "oai:dspace.mit.edu:1721.1/92973"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2015-01-20T15:31:23Z", "2015-01-20T15:31:23Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["Power monitoring is needed in most electrical systems, and is crucial for ensuring reliability in everything from industrial and telecom applications, to automotive and consumer electronics. Power monitoring of integrated circuits (ICs) is also essential, as today ICs exist in most electrical and electronic systems, in a vast range of applications. Many ICs, including power ICs, have functional blocks across the chip that are used for different purposes. Measuring circuit block currents in both analog and digital ICs is important in a wide range of applications, including power management as well as IC testing and fault detection and analysis. For example, the presence of different kinds of faults in IC circuit blocks during IC fabrication causes the currents flowing through these circuit blocks to change from the expected values. There has been general interest in monitoring currents through different circuit blocks in an attempt to identify the location and type of the faults. Previous works on non intrusive load monitoring as well as on power-line communications (PLCs) provide motivation for the work presented here. The techniques are extended and used to develop a new method for power monitoring in ICs. Most solutions to the challenge of measuring currents in different circuit blocks of the IC involve adding circuitry that is both costly and power consuming. In this work, a new method is proposed to enable individual measurement of current consumed in each circuit block within an IC while adding negligible area and power overhead. This method works by encoding the individual current signatures in the main supply current of the IC, which can then be sensed and sampled off-chip, and then disaggregated through signal processing. A demonstration of this power monitoring scheme is given on a modular discrete platform that is implemented based on the UC3842 current-mode controller IC, which can also be used for educational purposes.", "by Anas Ibrahim Al Bastami.", "Thesis: S.M., Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2014.", "This electronic version was submitted by the student author.  The certified thesis is available in the Institute Archives and Special Collections.", "Cataloged from student-submitted PDF version of thesis.", "Includes bibliographical references (pages 201-203)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7817", "hdl_1721.1_7663"]}}], "languages": [null], "subjects": ["electrical engineering and computer science."], "providerUpdatedDateTime": "2015-01-21T07:26:35", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/92973"}}, {"publisher": {"name": ""}, "description": "  It is well known that spatially coupled (SC) codes with erasure-BP decoding\nhave powerful error correcting capability over memoryless erasure channels.\nHowever, the decoding performance of SC-codes significantly degrades when they\nare used over burst erasure channels. In this paper, we propose band splitting\npermutations (BSP) suitable for $(l,r,L)$ SC-codes. The BSP splits a diagonal\nband in a base matrix into multiple bands in order to enhance the span of the\nstopping sets in the base matrix. As theoretical performance guarantees, lower\nand upper bounds on the maximal burst correctable length of the permuted\n$(l,r,L)$ SC-codes are presented. Those bounds indicate that the maximal\ncorrectable burst ratio of the permuted SC-codes converges to 1/k where k=r/l.\nThis implies the asymptotic optimality of the permuted SC-codes in terms of\nburst erasure correction.\n", "contributors": [{"name": "Mori, Hiroki", "sameAs": [], "familyName": "Mori", "additionalName": "", "givenName": "Hiroki", "email": ""}, {"name": "Wadayama, Tadashi", "sameAs": [], "familyName": "Wadayama", "additionalName": "", "givenName": "Tadashi", "email": ""}], "title": "Band Splitting Permutations for Spatially Coupled LDPC Codes Enhancing\n  Burst Erasure Immunity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04394", "oai:arXiv.org:1501.04394"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  It is well known that spatially coupled (SC) codes with erasure-BP decoding\nhave powerful error correcting capability over memoryless erasure channels.\nHowever, the decoding performance of SC-codes significantly degrades when they\nare used over burst erasure channels. In this paper, we propose band splitting\npermutations (BSP) suitable for $(l,r,L)$ SC-codes. The BSP splits a diagonal\nband in a base matrix into multiple bands in order to enhance the span of the\nstopping sets in the base matrix. As theoretical performance guarantees, lower\nand upper bounds on the maximal burst correctable length of the permuted\n$(l,r,L)$ SC-codes are presented. Those bounds indicate that the maximal\ncorrectable burst ratio of the permuted SC-codes converges to 1/k where k=r/l.\nThis implies the asymptotic optimality of the permuted SC-codes in terms of\nburst erasure correction.\n", "Comment: 5 pages, submitted to ISIT 2015"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04394"}}, {"publisher": {"name": ""}, "description": "  We propose a new static parameterization of the implied volatility surface\nwhich is constructed by using polynomials of sigmoid functions combined with\nsome other terms. This parameterization is flexible enough to fit market\nimplied volatilities which demonstrate smile or skew. An arbitrage-free\ncalibration algorithm is considered that constructs the implied volatility\nsurface as a grid in the strike-expiration space and guarantees a lack of\narbitrage at every node of this grid. We also demonstrate how to construct an\narbitrage-free interpolation and extrapolation in time, as well as build a\nlocal volatility and implied pdf surfaces. Asymptotic behavior of this\nparameterization is discussed, as well as results on stability of the\ncalibrated parameters are presented. Numerical examples show robustness of the\nproposed approach in building all these surfaces as well as demonstrate a\nbetter quality of the fit as compared with some known models.\n", "contributors": [{"name": "Itkin, Andrey", "sameAs": [], "familyName": "Itkin", "additionalName": "", "givenName": "Andrey", "email": ""}], "title": "To sigmoid-based functional description of the volatility smile", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-01", "2014-12-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.0256", "oai:arXiv.org:1407.0256"]}}, {"name": "setSpec", "properties": {"setSpec": "q-fin"}}, {"name": "description", "properties": {"description": ["  We propose a new static parameterization of the implied volatility surface\nwhich is constructed by using polynomials of sigmoid functions combined with\nsome other terms. This parameterization is flexible enough to fit market\nimplied volatilities which demonstrate smile or skew. An arbitrage-free\ncalibration algorithm is considered that constructs the implied volatility\nsurface as a grid in the strike-expiration space and guarantees a lack of\narbitrage at every node of this grid. We also demonstrate how to construct an\narbitrage-free interpolation and extrapolation in time, as well as build a\nlocal volatility and implied pdf surfaces. Asymptotic behavior of this\nparameterization is discussed, as well as results on stability of the\ncalibrated parameters are presented. Numerical examples show robustness of the\nproposed approach in building all these surfaces as well as demonstrate a\nbetter quality of the fit as compared with some known models.\n", "Comment: 32 pages, 18 figures, 5 tables"]}}], "languages": [null], "subjects": ["quantitative finance - mathematical finance", "quantitative finance - general finance", "quantitative finance - computational finance"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.0256"}}, {"publisher": {"name": ""}, "description": "  We describe and examine a framework for tomographic image reconstruction\nwhere prior knowledge about the solution is available in the form of training\nimages. We first construct a dictionary that contains prototype elements from\nthese images. Then by using the dictionary as a prior to regularize the inverse\nproblem, and looking for a solution with a sparse representation in the\ndictionary, we formulate the reconstruction problem in a convex optimization\nframework. Our computational experiments clarify the choice and interplay of\nthe model parameters and the regularization parameters, and they show that in\nfew-projection settings we are able to produce better images with more\nstructural features than the total variation approach.\n", "contributors": [{"name": "Soltani, Sara", "sameAs": [], "familyName": "Soltani", "additionalName": "", "givenName": "Sara", "email": ""}, {"name": "Andersen, Martin S.", "sameAs": [], "familyName": "Andersen", "additionalName": "S.", "givenName": "Martin", "email": ""}, {"name": "Hansen, Per Christian", "sameAs": [], "familyName": "Hansen", "additionalName": "Christian", "givenName": "Per", "email": ""}], "title": "Tomographic Image Reconstruction using Dictionary Priors", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01993", "oai:arXiv.org:1503.01993"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We describe and examine a framework for tomographic image reconstruction\nwhere prior knowledge about the solution is available in the form of training\nimages. We first construct a dictionary that contains prototype elements from\nthese images. Then by using the dictionary as a prior to regularize the inverse\nproblem, and looking for a solution with a sparse representation in the\ndictionary, we formulate the reconstruction problem in a convex optimization\nframework. Our computational experiments clarify the choice and interplay of\nthe model parameters and the regularization parameters, and they show that in\nfew-projection settings we are able to produce better images with more\nstructural features than the total variation approach.\n", "Comment: 25 pages, 12 figures"]}}], "languages": [null], "subjects": ["mathematics - numerical analysis", "65k10", "65f22", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01993"}}, {"publisher": {"name": ""}, "description": "  In this paper, we introduce new lower bounds on the distortion of scalar\nfixed-rate codes for lossy compression with side information available at the\nreceiver. These bounds are derived by presenting the relevant random variables\nas a Markov chain and applying generalized data processing inequalities a la\nZiv and Zakai. We show that by replacing the logarithmic function with other\nfunctions, in the data processing theorem we formulate, we obtain new lower\nbounds on the distortion of scalar coding with side information at the decoder.\nThe usefulness of these results is demonstrated for uniform sources and the\nconvex function $Q(t)=t^{1-\\alpha}$, $\\alpha>1$. The bounds in this case are\nshown to be better than one can obtain from the Wyner-Ziv rate-distortion\nfunction.\n", "contributors": [{"name": "Reani, Avraham", "sameAs": [], "familyName": "Reani", "additionalName": "", "givenName": "Avraham", "email": ""}, {"name": "Merhav, Neri", "sameAs": [], "familyName": "Merhav", "additionalName": "", "givenName": "Neri", "email": ""}], "title": "Data Processing Bounds for Scalar Lossy Source Codes with Side\n  Information at the Decoder", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-09-10", "2014-11-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1209.2066", "oai:arXiv.org:1209.2066"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we introduce new lower bounds on the distortion of scalar\nfixed-rate codes for lossy compression with side information available at the\nreceiver. These bounds are derived by presenting the relevant random variables\nas a Markov chain and applying generalized data processing inequalities a la\nZiv and Zakai. We show that by replacing the logarithmic function with other\nfunctions, in the data processing theorem we formulate, we obtain new lower\nbounds on the distortion of scalar coding with side information at the decoder.\nThe usefulness of these results is demonstrated for uniform sources and the\nconvex function $Q(t)=t^{1-\\alpha}$, $\\alpha>1$. The bounds in this case are\nshown to be better than one can obtain from the Wyner-Ziv rate-distortion\nfunction.\n", "Comment: 35 pages, 9 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1209.2066"}}, {"publisher": {"name": ""}, "description": "  We propose a new Write-Once-Memory (WOM) coding scheme based on source\npolarization. By applying a source polarization transformation on the\nto-be-determined codeword, the proposed WOM coding scheme encodes information\ninto the bits in the high-entropy set. We prove in this paper that the proposed\nWOM codes are capacity-achieving. WOM codes have found many applications in\nmodern data storage systems, such as flash memories.\n", "contributors": [{"name": "Ma, Xudong", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Xudong", "email": ""}], "title": "Write-Once-Memory Codes by Source Polarization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-23", "2014-10-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.6262", "oai:arXiv.org:1405.6262"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We propose a new Write-Once-Memory (WOM) coding scheme based on source\npolarization. By applying a source polarization transformation on the\nto-be-determined codeword, the proposed WOM coding scheme encodes information\ninto the bits in the high-entropy set. We prove in this paper that the proposed\nWOM codes are capacity-achieving. WOM codes have found many applications in\nmodern data storage systems, such as flash memories.\n", "Comment: 5 pages, Proceedings of the International Conference on Computing,\n  Networking and Communications (ICNC 2015), Anaheim, California, USA, February\n  16-19, 2015"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.6262"}}, {"publisher": {"name": ""}, "description": "  Alterations in brain connectivity have been associated with a variety of\nclinical disorders using functional magnetic resonance imaging (fMRI). We\ninvestigated empirically how the number of brain parcels (or scale) impacted\nthe results of a mass univariate general linear model (GLM) on connectomes. The\nbrain parcels used as nodes in the connectome analysis were functionnally\ndefined by a group cluster analysis. We first validated that a classic\nBenjamini-Hochberg procedure with parametric GLM tests did control\nappropriately the false-discovery rate (FDR) at a given scale. We then observed\non realistic simulations that there was no substantial inflation of the FDR\nacross scales, as long as the FDR was controlled independently within each\nscale, and the presence of true associations could be established using an\nomnibus permutation test combining all scales. Second, we observed both on\nsimulations and on three real resting-state fMRI datasets (schizophrenia,\ncongenital blindness, motor practice) that the rate of discovery varied\nmarkedly as a function of scales, and was relatively higher for low scales,\nbelow 25. Despite the differences in discovery rate, the statistical maps\nderived at different scales were generally very consistent in the three real\ndatasets. Some seeds still showed effects better observed around 50,\nillustrating the potential benefits of multiscale analysis. On real data, the\nstatistical maps agreed well with the existing literature. Overall, our results\nsupport that the multiscale GLM connectome analysis with FDR is statistically\nvalid and can capture biologically meaningful effects in a variety of\nexperimental conditions.\n", "contributors": [{"name": "Bellec, P.", "sameAs": [], "familyName": "Bellec", "additionalName": "", "givenName": "P.", "email": ""}, {"name": "Benhajali, Y.", "sameAs": [], "familyName": "Benhajali", "additionalName": "", "givenName": "Y.", "email": ""}, {"name": "Carbonell, F.", "sameAs": [], "familyName": "Carbonell", "additionalName": "", "givenName": "F.", "email": ""}, {"name": "Dansereau, C.", "sameAs": [], "familyName": "Dansereau", "additionalName": "", "givenName": "C.", "email": ""}, {"name": "Albouy, G.", "sameAs": [], "familyName": "Albouy", "additionalName": "", "givenName": "G.", "email": ""}, {"name": "Pelland, M.", "sameAs": [], "familyName": "Pelland", "additionalName": "", "givenName": "M.", "email": ""}, {"name": "Craddock, C.", "sameAs": [], "familyName": "Craddock", "additionalName": "", "givenName": "C.", "email": ""}, {"name": "Collignon, O.", "sameAs": [], "familyName": "Collignon", "additionalName": "", "givenName": "O.", "email": ""}, {"name": "Doyon, J.", "sameAs": [], "familyName": "Doyon", "additionalName": "", "givenName": "J.", "email": ""}, {"name": "Stip, E.", "sameAs": [], "familyName": "Stip", "additionalName": "", "givenName": "E.", "email": ""}, {"name": "Orban, P.", "sameAs": [], "familyName": "Orban", "additionalName": "", "givenName": "P.", "email": ""}], "title": "Multiscale statistical testing for connectome-wide association studies\n  in fMRI", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-07", "2015-01-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.2080", "oai:arXiv.org:1409.2080"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio", "stat"]}}, {"name": "description", "properties": {"description": ["  Alterations in brain connectivity have been associated with a variety of\nclinical disorders using functional magnetic resonance imaging (fMRI). We\ninvestigated empirically how the number of brain parcels (or scale) impacted\nthe results of a mass univariate general linear model (GLM) on connectomes. The\nbrain parcels used as nodes in the connectome analysis were functionnally\ndefined by a group cluster analysis. We first validated that a classic\nBenjamini-Hochberg procedure with parametric GLM tests did control\nappropriately the false-discovery rate (FDR) at a given scale. We then observed\non realistic simulations that there was no substantial inflation of the FDR\nacross scales, as long as the FDR was controlled independently within each\nscale, and the presence of true associations could be established using an\nomnibus permutation test combining all scales. Second, we observed both on\nsimulations and on three real resting-state fMRI datasets (schizophrenia,\ncongenital blindness, motor practice) that the rate of discovery varied\nmarkedly as a function of scales, and was relatively higher for low scales,\nbelow 25. Despite the differences in discovery rate, the statistical maps\nderived at different scales were generally very consistent in the three real\ndatasets. Some seeds still showed effects better observed around 50,\nillustrating the potential benefits of multiscale analysis. On real data, the\nstatistical maps agreed well with the existing literature. Overall, our results\nsupport that the multiscale GLM connectome analysis with FDR is statistically\nvalid and can capture biologically meaningful effects in a variety of\nexperimental conditions.\n", "Comment: 54 pages, 12 main figures, 1 main table, 10 supplementary figures, 1\n  supplementary table"]}}], "languages": [null], "subjects": ["statistics - applications", "computer science - computer vision and pattern recognition", "quantitative biology - quantitative methods"], "providerUpdatedDateTime": "2015-01-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.2080"}}, {"publisher": {"name": ""}, "description": "  We study the class of word-building games, where two players pick letters\nfrom a finite alphabet to construct a finite or infinite word. The outcome is\ndetermined by whether the resulting word lies in a prescribed set (a win for\nplayer $A$) or not (a win for player $B$). We focus on symbolic dynamical\ngames, where the target set is a subshift. We investigate the relation between\nthe target subshift and the set of turn orders for which $A$ has a winning\nstrategy.\n", "contributors": [{"name": "Salo, Ville", "sameAs": [], "familyName": "Salo", "additionalName": "", "givenName": "Ville", "email": ""}, {"name": "T\u00f6rm\u00e4, Ilkka", "sameAs": [], "familyName": "T\u00f6rm\u00e4", "additionalName": "", "givenName": "Ilkka", "email": ""}], "title": "Playing with Subshifts", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-10-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.0650", "doi:10.3233/FI-2014-1037", "oai:arXiv.org:1310.0650"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We study the class of word-building games, where two players pick letters\nfrom a finite alphabet to construct a finite or infinite word. The outcome is\ndetermined by whether the resulting word lies in a prescribed set (a win for\nplayer $A$) or not (a win for player $B$). We focus on symbolic dynamical\ngames, where the target set is a subshift. We investigate the relation between\nthe target subshift and the set of turn orders for which $A$ has a winning\nstrategy.\n", "Comment: 22 pages, 4 figures. To appear in Fundamenta Informaticae"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "mathematics - dynamical systems"], "providerUpdatedDateTime": "2015-01-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.0650"}}, {"publisher": {"name": ""}, "description": "  In this paper, we show that given a weighted, directed planar graph $G$, and\nany $\\epsilon >0$, there exists a polynomial time and\n$O(n^{\\frac{1}{2}+\\epsilon})$ space algorithm that computes the shortest path\nbetween two fixed vertices in $G$.\n  We also consider the {\\RB} problem, which states that given a graph $G$ whose\nedges are colored either red or blue and two fixed vertices $s$ and $t$ in $G$,\nis there a path from $s$ to $t$ in $G$ that alternates between red and blue\nedges. The {\\RB} problem in planar DAGs is {\\NL}-complete. We exhibit a\npolynomial time and $O(n^{\\frac{1}{2}+\\epsilon})$ space algorithm (for any\n$\\epsilon >0$) for the {\\RB} problem in planar DAG.\n  In the last part of this paper, we consider the problem of deciding and\nconstructing the perfect matching present in a planar bipartite graph and also\na similar problem which is to find a Hall-obstacle in a planar bipartite graph.\nWe show the time-space bound of these two problems are same as the bound of\nshortest path problem in a directed planar graph.\n", "contributors": [{"name": "Chakraborty, Diptarka", "sameAs": [], "familyName": "Chakraborty", "additionalName": "", "givenName": "Diptarka", "email": ""}, {"name": "Tewari, Raghunath", "sameAs": [], "familyName": "Tewari", "additionalName": "", "givenName": "Raghunath", "email": ""}], "title": "Simultaneous Time-Space Upper Bounds for Certain Problems in Planar\n  Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02135", "oai:arXiv.org:1502.02135"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we show that given a weighted, directed planar graph $G$, and\nany $\\epsilon >0$, there exists a polynomial time and\n$O(n^{\\frac{1}{2}+\\epsilon})$ space algorithm that computes the shortest path\nbetween two fixed vertices in $G$.\n  We also consider the {\\RB} problem, which states that given a graph $G$ whose\nedges are colored either red or blue and two fixed vertices $s$ and $t$ in $G$,\nis there a path from $s$ to $t$ in $G$ that alternates between red and blue\nedges. The {\\RB} problem in planar DAGs is {\\NL}-complete. We exhibit a\npolynomial time and $O(n^{\\frac{1}{2}+\\epsilon})$ space algorithm (for any\n$\\epsilon >0$) for the {\\RB} problem in planar DAG.\n  In the last part of this paper, we consider the problem of deciding and\nconstructing the perfect matching present in a planar bipartite graph and also\na similar problem which is to find a Hall-obstacle in a planar bipartite graph.\nWe show the time-space bound of these two problems are same as the bound of\nshortest path problem in a directed planar graph.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-02-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02135"}}, {"publisher": {"name": ""}, "description": "  A continuous-time Wiener phase noise channel with an integrate-and-dump\nmulti-sample receiver is studied.\n  A lower bound to the capacity with an average input power constraint is\nderived, and a high signal-to-noise ratio (SNR) analysis is performed.\n  The capacity pre-log depends on the oversampling factor, and amplitude and\nphase modulation do not equally contribute to capacity at high SNR.\n", "contributors": [{"name": "Barletta, Luca", "sameAs": [], "familyName": "Barletta", "additionalName": "", "givenName": "Luca", "email": ""}, {"name": "Kramer, Gerhard", "sameAs": [], "familyName": "Kramer", "additionalName": "", "givenName": "Gerhard", "email": ""}], "title": "Lower Bound on the Capacity of Continuous-Time Wiener Phase Noise\n  Channels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03223", "oai:arXiv.org:1503.03223"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A continuous-time Wiener phase noise channel with an integrate-and-dump\nmulti-sample receiver is studied.\n  A lower bound to the capacity with an average input power constraint is\nderived, and a high signal-to-noise ratio (SNR) analysis is performed.\n  The capacity pre-log depends on the oversampling factor, and amplitude and\nphase modulation do not equally contribute to capacity at high SNR.\n", "Comment: Extended version of a paper submitted to ISIT 2015. 9 pages and 1\n  figure. arXiv admin note: text overlap with arXiv:1411.0390"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03223"}}, {"publisher": {"name": ""}, "description": "  Advances in sensing and communication capabilities as well as power industry\nderegulation are driving the need for distributed state estimation in the smart\ngrid at the level of the regional transmission organizations (RTOs). This leads\nto a new competitive privacy problem amongst the RTOs since there is a tension\nbetween sharing data to ensure network reliability (utility/benefit to all\nRTOs) and withholding data for profitability and privacy reasons. The resulting\ntradeoff between utility, quantified via fidelity of its state estimate at each\nRTO, and privacy, quantified via the leakage of the state of one RTO at other\nRTOs, is captured precisely using a lossy source coding problem formulation for\na two RTO network. For a two-RTO model, it is shown that the set of all\nfeasible utility-privacy pairs can be achieved via a single round of\ncommunication when each RTO communicates taking into account the correlation\nbetween the measured data at both RTOs. The lossy source coding problem and\nsolution developed here is also of independent interest.\n", "contributors": [{"name": "Sankar, Lalitha", "sameAs": [], "familyName": "Sankar", "additionalName": "", "givenName": "Lalitha", "email": ""}, {"name": "Kar, Soummya", "sameAs": [], "familyName": "Kar", "additionalName": "", "givenName": "Soummya", "email": ""}, {"name": "Tandon, Ravi", "sameAs": [], "familyName": "Tandon", "additionalName": "", "givenName": "Ravi", "email": ""}, {"name": "Poor, H. Vincent", "sameAs": [], "familyName": "Poor", "additionalName": "Vincent", "givenName": "H.", "email": ""}], "title": "Competitive Privacy in the Smart Grid: An Information-theoretic Approach", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-08-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1108.2237", "oai:arXiv.org:1108.2237"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Advances in sensing and communication capabilities as well as power industry\nderegulation are driving the need for distributed state estimation in the smart\ngrid at the level of the regional transmission organizations (RTOs). This leads\nto a new competitive privacy problem amongst the RTOs since there is a tension\nbetween sharing data to ensure network reliability (utility/benefit to all\nRTOs) and withholding data for profitability and privacy reasons. The resulting\ntradeoff between utility, quantified via fidelity of its state estimate at each\nRTO, and privacy, quantified via the leakage of the state of one RTO at other\nRTOs, is captured precisely using a lossy source coding problem formulation for\na two RTO network. For a two-RTO model, it is shown that the set of all\nfeasible utility-privacy pairs can be achieved via a single round of\ncommunication when each RTO communicates taking into account the correlation\nbetween the measured data at both RTOs. The lossy source coding problem and\nsolution developed here is also of independent interest.\n", "Comment: Accepted for publication and presentation at the IEEE SmartGridComm\n  2011"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1108.2237"}}, {"publisher": {"name": ""}, "description": "  We propose a framework grounded in Logic Programming for representing and\nreasoning about business processes from both the procedural and ontological\npoint of views. In particular, our goal is threefold: (1) define a logical\nlanguage and a formal semantics for process models enriched with ontology-based\nannotations; (2) provide an effective inference mechanism that supports the\ncombination of reasoning services dealing with the structural definition of a\nprocess model, its behavior, and the domain knowledge related to the\nparticipating business entities; (3) implement such a theoretical framework\ninto a process modeling and reasoning platform. To this end we define a process\nontology coping with a relevant fragment of the popular BPMN modeling notation.\nThe behavioral semantics of a process is defined as a state transition system\nby following an approach similar to the Fluent Calculus, and allows us to\nspecify state change in terms of preconditions and effects of the enactment of\nactivities. Then we show how the procedural process knowledge can be seamlessly\nintegrated with the domain knowledge specified by using the OWL 2 RL rule-based\nontology language. Our framework provides a wide range of reasoning services,\nincluding CTL model checking, which can be performed by using standard Logic\nProgramming inference engines through a goal-oriented, efficient, sound and\ncomplete evaluation procedure. We also present a software environment\nimplementing the proposed framework, and we report on an experimental\nevaluation of the system, whose results are encouraging and show the viability\nof the approach.\n", "contributors": [{"name": "Smith, Fabrizio", "sameAs": [], "familyName": "Smith", "additionalName": "", "givenName": "Fabrizio", "email": ""}, {"name": "Proietti, Maurizio", "sameAs": [], "familyName": "Proietti", "additionalName": "", "givenName": "Maurizio", "email": ""}], "title": "Ontology-based Representation and Reasoning on Process Models: A Logic\n  Programming Approach", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1776", "oai:arXiv.org:1410.1776"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We propose a framework grounded in Logic Programming for representing and\nreasoning about business processes from both the procedural and ontological\npoint of views. In particular, our goal is threefold: (1) define a logical\nlanguage and a formal semantics for process models enriched with ontology-based\nannotations; (2) provide an effective inference mechanism that supports the\ncombination of reasoning services dealing with the structural definition of a\nprocess model, its behavior, and the domain knowledge related to the\nparticipating business entities; (3) implement such a theoretical framework\ninto a process modeling and reasoning platform. To this end we define a process\nontology coping with a relevant fragment of the popular BPMN modeling notation.\nThe behavioral semantics of a process is defined as a state transition system\nby following an approach similar to the Fluent Calculus, and allows us to\nspecify state change in terms of preconditions and effects of the enactment of\nactivities. Then we show how the procedural process knowledge can be seamlessly\nintegrated with the domain knowledge specified by using the OWL 2 RL rule-based\nontology language. Our framework provides a wide range of reasoning services,\nincluding CTL model checking, which can be performed by using standard Logic\nProgramming inference engines through a goal-oriented, efficient, sound and\ncomplete evaluation procedure. We also present a software environment\nimplementing the proposed framework, and we report on an experimental\nevaluation of the system, whose results are encouraging and show the viability\nof the approach.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2014-10-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1776"}}, {"publisher": {"name": ""}, "description": "  Heuristic Rating Estimation (HRE) is a newly proposed method supporting\ndecisions analysis based on the use of pairwise comparisons. It allows that the\nranking values of some alternatives (herein referred to as concepts) are\ninitially known, whilst the ranks for the other concepts have yet to be\nestimated. To calculate the missing ranks it is assumed that the priority of\nevery single concept can be determined as the weighted arithmetic mean of\npriorities of all the other concepts. It has been shown that the problem has\nadmissible solution if the inconsistency of pairwise comparisons is not too\nhigh. The proposed approach adopts the heuristics according to which to\ndetermine the missing priorities a weighted geometric mean is used. In this\napproach, despite an increased complexity, the solution always exists and their\nexistence does not depend on the inconsistency of the input matrix. Thus, the\npresented approach might be appropriate for a larger number of problems than\nthe previous method. The formal definition of the proposed geometric heuristics\nis accompanied by two numerical examples.\n", "contributors": [{"name": "Ku\u0142akowski, Konrad", "sameAs": [], "familyName": "Ku\u0142akowski", "additionalName": "", "givenName": "Konrad", "email": ""}, {"name": "Grobler-D\u0119bska, Katarzyna", "sameAs": [], "familyName": "Grobler-D\u0119bska", "additionalName": "", "givenName": "Katarzyna", "email": ""}, {"name": "W\u0105s, Jaros\u0142aw", "sameAs": [], "familyName": "W\u0105s", "additionalName": "", "givenName": "Jaros\u0142aw", "email": ""}], "title": "Heuristic rating estimation - geometric approach", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-04-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.6981", "doi:10.1007/s10898-014-0253-4", "oai:arXiv.org:1404.6981"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Heuristic Rating Estimation (HRE) is a newly proposed method supporting\ndecisions analysis based on the use of pairwise comparisons. It allows that the\nranking values of some alternatives (herein referred to as concepts) are\ninitially known, whilst the ranks for the other concepts have yet to be\nestimated. To calculate the missing ranks it is assumed that the priority of\nevery single concept can be determined as the weighted arithmetic mean of\npriorities of all the other concepts. It has been shown that the problem has\nadmissible solution if the inconsistency of pairwise comparisons is not too\nhigh. The proposed approach adopts the heuristics according to which to\ndetermine the missing priorities a weighted geometric mean is used. In this\napproach, despite an increased complexity, the solution always exists and their\nexistence does not depend on the inconsistency of the input matrix. Thus, the\npresented approach might be appropriate for a larger number of problems than\nthe previous method. The formal definition of the proposed geometric heuristics\nis accompanied by two numerical examples.\n", "Comment: 11 pages"]}}], "languages": [null], "subjects": ["computer science - discrete mathematics"], "providerUpdatedDateTime": "2014-11-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.6981"}}, {"publisher": {"name": ""}, "description": "  We consider the quantized consensus problem on undirected connected graphs\nwith n nodes, and devise a protocol with fast convergence time to the set of\nconsensus points. Specifically, we show that when the edges of a static network\nare activated based on Poisson processes with Metropolis rates, the expected\nconvergence time to the set of consensus points is at most O(n^2 log n). We\nfurther show an upper bound of O(n^2 log^2 n) for the expected convergence time\nof the same protocol over connected time-varying networks. These bounds are\nbetter than all previous convergence times for randomized quantized consensus.\n", "contributors": [{"name": "Basar, Tamer", "sameAs": [], "familyName": "Basar", "additionalName": "", "givenName": "Tamer", "email": ""}, {"name": "Etesami, Seyed Rasoul", "sameAs": [], "familyName": "Etesami", "additionalName": "Rasoul", "givenName": "Seyed", "email": ""}, {"name": "Olshevsky, Alex", "sameAs": [], "familyName": "Olshevsky", "additionalName": "", "givenName": "Alex", "email": ""}], "title": "Fast Convergence of Quantized Consensus Using Metropolis Chains Over\n  Static and Dynamic Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01438", "oai:arXiv.org:1504.01438"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We consider the quantized consensus problem on undirected connected graphs\nwith n nodes, and devise a protocol with fast convergence time to the set of\nconsensus points. Specifically, we show that when the edges of a static network\nare activated based on Poisson processes with Metropolis rates, the expected\nconvergence time to the set of consensus points is at most O(n^2 log n). We\nfurther show an upper bound of O(n^2 log^2 n) for the expected convergence time\nof the same protocol over connected time-varying networks. These bounds are\nbetter than all previous convergence times for randomized quantized consensus.\n"}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "computer science - multiagent systems", "and cluster computing", "computer science - distributed", "parallel", "mathematics - probability"], "providerUpdatedDateTime": "2015-04-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01438"}}, {"publisher": {"name": ""}, "description": "  In this paper, we analyze and compare general development and individual\nbehavior on two non-profit internet-based hospitality exchange services --\nbewelcome.org and warmshowers.org. We measure the effort needed to achieve a\nreal-life interaction, whereby the advantages of mutual altruism arise. The\neffort needed is the communication quantified in units of time. Since the\namount of effort is not obvious to individual users, the development of the\neffort investing strategy is investigated. The impact of individual behavior on\ngeneral development is discussed.\n", "contributors": [{"name": "Tagiew, Rustam", "sameAs": [], "familyName": "Tagiew", "additionalName": "", "givenName": "Rustam", "email": ""}], "title": "The Economy of Internet-Based Hospitality Exchange", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06941", "oai:arXiv.org:1501.06941"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  In this paper, we analyze and compare general development and individual\nbehavior on two non-profit internet-based hospitality exchange services --\nbewelcome.org and warmshowers.org. We measure the effort needed to achieve a\nreal-life interaction, whereby the advantages of mutual altruism arise. The\neffort needed is the communication quantified in units of time. Since the\namount of effort is not obvious to individual users, the development of the\neffort investing strategy is investigated. The impact of individual behavior on\ngeneral development is discussed.\n", "Comment: 6 pages, 8 figures and 4 tables"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06941"}}, {"publisher": {"name": ""}, "description": "  In this paper, we study the problem of cooperative communications in\ncognitive radio systems where the secondary user has limited relaying room for\nthe overheard primary packets. More specifically, we characterize the stable\nthroughput region of a cognitive radio network with a finite relaying buffer at\nthe secondary user. Towards this objective, we formulate a constrained\noptimization problem for maximizing the secondary user throughput while\nguaranteeing the stability of the primary user queue. We consider a general\ncooperation policy where the packet admission and queue selection\nprobabilities, at the secondary user, are both dependent on the state (length)\nof the finite relaying buffer. Despite the sheer complexity of the optimization\nproblem, attributed to its non-convexity, we transform it to a linear program.\nOur numerical results reveal a number of valuable insights, e.g., it is always\nmutually beneficial to cooperate in delivering the primary packets in terms of\nexpanding the stable throughput region. In addition, the stable throughput\nregion of the system, compared to the case of infinite relaying queue capacity,\nmarginally shrinks for limited relaying queue capacity.\n", "contributors": [{"name": "Elmahdy, Adel M.", "sameAs": [], "familyName": "Elmahdy", "additionalName": "M.", "givenName": "Adel", "email": ""}, {"name": "El-Keyi, Amr", "sameAs": [], "familyName": "El-Keyi", "additionalName": "", "givenName": "Amr", "email": ""}, {"name": "ElBatt, Tamer", "sameAs": [], "familyName": "ElBatt", "additionalName": "", "givenName": "Tamer", "email": ""}, {"name": "Seddik, Karim G.", "sameAs": [], "familyName": "Seddik", "additionalName": "G.", "givenName": "Karim", "email": ""}], "title": "On the Stable Throughput of Cooperative Cognitive Radio Networks with\n  Finite Relaying Buffer", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2419", "oai:arXiv.org:1410.2419"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we study the problem of cooperative communications in\ncognitive radio systems where the secondary user has limited relaying room for\nthe overheard primary packets. More specifically, we characterize the stable\nthroughput region of a cognitive radio network with a finite relaying buffer at\nthe secondary user. Towards this objective, we formulate a constrained\noptimization problem for maximizing the secondary user throughput while\nguaranteeing the stability of the primary user queue. We consider a general\ncooperation policy where the packet admission and queue selection\nprobabilities, at the secondary user, are both dependent on the state (length)\nof the finite relaying buffer. Despite the sheer complexity of the optimization\nproblem, attributed to its non-convexity, we transform it to a linear program.\nOur numerical results reveal a number of valuable insights, e.g., it is always\nmutually beneficial to cooperate in delivering the primary packets in terms of\nexpanding the stable throughput region. In addition, the stable throughput\nregion of the system, compared to the case of infinite relaying queue capacity,\nmarginally shrinks for limited relaying queue capacity.\n", "Comment: 5 pages, IEEE PIMRC 2014"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-10-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2419"}}, {"publisher": {"name": ""}, "description": "  Computing the topology of an algebraic plane curve $\\mathcal{C}$ means to\ncompute a combinatorial graph that is isotopic to $\\mathcal{C}$ and thus\nrepresents its topology in $\\mathbb{R}^2$. We prove that, for a polynomial of\ndegree $n$ with coefficients bounded by $2^\\rho$, the topology of the induced\ncurve can be computed with $\\tilde{O}(n^8(n+\\rho^2))$ bit operations\ndeterministically, and with $\\tilde{O}(n^8\\rho^2)$ bit operations with a\nrandomized algorithm in expectation. Our analysis improves previous best known\ncomplexity bounds by a factor of $n^2$. The improvement is based on new\ntechniques to compute and refine isolating intervals for the real roots of\npolynomials, and by the consequent amortized analysis of the critical fibers of\nthe algebraic curve.\n", "contributors": [{"name": "Kerber, Michael", "sameAs": [], "familyName": "Kerber", "additionalName": "", "givenName": "Michael", "email": ""}, {"name": "Sagraloff, Michael", "sameAs": [], "familyName": "Sagraloff", "additionalName": "", "givenName": "Michael", "email": ""}], "title": "A Worst-case Bound for Topology Computation of Algebraic Curves", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-04-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.1510", "oai:arXiv.org:1104.1510"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Computing the topology of an algebraic plane curve $\\mathcal{C}$ means to\ncompute a combinatorial graph that is isotopic to $\\mathcal{C}$ and thus\nrepresents its topology in $\\mathbb{R}^2$. We prove that, for a polynomial of\ndegree $n$ with coefficients bounded by $2^\\rho$, the topology of the induced\ncurve can be computed with $\\tilde{O}(n^8(n+\\rho^2))$ bit operations\ndeterministically, and with $\\tilde{O}(n^8\\rho^2)$ bit operations with a\nrandomized algorithm in expectation. Our analysis improves previous best known\ncomplexity bounds by a factor of $n^2$. The improvement is based on new\ntechniques to compute and refine isolating intervals for the real roots of\npolynomials, and by the consequent amortized analysis of the critical fibers of\nthe algebraic curve.\n"}}], "languages": [null], "subjects": ["computer science - symbolic computation"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.1510"}}, {"publisher": {"name": ""}, "description": "  Recently, a successful pose estimation algorithm, called Cascade Pose\nRegression (CPR), was proposed in the literature. Trained over Pose Index\nFeature, CPR is a regressor ensemble that is similar to Boosting. In this paper\nwe show how CPR can be represented as a Neural Network. Specifically, we adopt\na Graph Transformer Network (GTN) representation and accordingly train CPR with\nBack Propagation (BP) that permits globally tuning. In contrast, previous CPR\nliterature only took a layer wise training without any post fine tuning. We\nempirically show that global training with BP outperforms layer-wise\n(pre-)training. Our CPR-GTN adopts a Multi Layer Percetron as the regressor,\nwhich utilized sparse connection to learn local image feature representation.\nWe tested the proposed CPR-GTN on 2D face pose estimation problem as in\nprevious CPR literature. Besides, we also investigated the possibility of\nextending CPR-GTN to 3D pose estimation by doing experiments using 3D Computed\nTomography dataset for heart segmentation.\n", "contributors": [{"name": "Sun, Peng", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Peng", "email": ""}, {"name": "Min, James K.", "sameAs": [], "familyName": "Min", "additionalName": "K.", "givenName": "James", "email": ""}, {"name": "Xiong, Guanglei", "sameAs": [], "familyName": "Xiong", "additionalName": "", "givenName": "Guanglei", "email": ""}], "title": "Globally Tuned Cascade Pose Regression via Back Propagation with\n  Application in 2D Face Pose Estimation and Heart Segmentation in 3D CT Images", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08843", "oai:arXiv.org:1503.08843"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Recently, a successful pose estimation algorithm, called Cascade Pose\nRegression (CPR), was proposed in the literature. Trained over Pose Index\nFeature, CPR is a regressor ensemble that is similar to Boosting. In this paper\nwe show how CPR can be represented as a Neural Network. Specifically, we adopt\na Graph Transformer Network (GTN) representation and accordingly train CPR with\nBack Propagation (BP) that permits globally tuning. In contrast, previous CPR\nliterature only took a layer wise training without any post fine tuning. We\nempirically show that global training with BP outperforms layer-wise\n(pre-)training. Our CPR-GTN adopts a Multi Layer Percetron as the regressor,\nwhich utilized sparse connection to learn local image feature representation.\nWe tested the proposed CPR-GTN on 2D face pose estimation problem as in\nprevious CPR literature. Besides, we also investigated the possibility of\nextending CPR-GTN to 3D pose estimation by doing experiments using 3D Computed\nTomography dataset for heart segmentation.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08843"}}, {"publisher": {"name": ""}, "description": "  We consider concave minimization problems over non-convex sets.Optimization\nproblems with this structure arise in sparse principal component analysis. We\nanalyze both a gradient projection algorithm and an approximate Newton\nalgorithm where the Hessian approximation is a multiple of the identity.\nConvergence results are established. In numerical experiments arising in sparse\nprincipal component analysis, it is seen that the performance of the gradient\nprojection algorithm is very similar to that of the truncated power method and\nthe generalized power method. In some cases, the approximate Newton algorithm\nwith a Barzilai-Borwein (BB) Hessian approximation can be substantially faster\nthan the other algorithms, and can converge to a better solution.\n", "contributors": [{"name": "Hager, William W.", "sameAs": [], "familyName": "Hager", "additionalName": "W.", "givenName": "William", "email": ""}, {"name": "Zhu, Jiajie", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "Jiajie", "email": ""}], "title": "Projection algorithms for non-convex minimization, with application to\n  sparse principal component analysis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-15", "2015-03-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.4132", "oai:arXiv.org:1404.4132"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We consider concave minimization problems over non-convex sets.Optimization\nproblems with this structure arise in sparse principal component analysis. We\nanalyze both a gradient projection algorithm and an approximate Newton\nalgorithm where the Hessian approximation is a multiple of the identity.\nConvergence results are established. In numerical experiments arising in sparse\nprincipal component analysis, it is seen that the performance of the gradient\nprojection algorithm is very similar to that of the truncated power method and\nthe generalized power method. In some cases, the approximate Newton algorithm\nwith a Barzilai-Borwein (BB) Hessian approximation can be substantially faster\nthan the other algorithms, and can converge to a better solution.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - numerical analysis"], "providerUpdatedDateTime": "2015-03-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.4132"}}, {"publisher": {"name": ""}, "description": "  We describe an algorithm computing an optimal prefix free code from $N$\nunsorted positive integer weights in time linear in the number of machine words\nholding those weights. This algorithm takes advantage of common non-algebraic\ninstructions, and of specific results on optimal prefix free codes. This result\nimproves over the state of the art complexities of $O(N\\lg N)$ in the algebraic\ndecision tree model and $O(N\\lg\\lg N)$ in the RAM model for the computation of\nHuffman's codes, a landmark in compression and coding since 1952.\n", "contributors": [{"name": "Barbay, J\u00e9r\u00e9my", "sameAs": [], "familyName": "Barbay", "additionalName": "", "givenName": "J\u00e9r\u00e9my", "email": ""}], "title": "Optimal Prefix Free Code in Linear Time", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-04-25", "2014-02-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1204.5801", "oai:arXiv.org:1204.5801"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We describe an algorithm computing an optimal prefix free code from $N$\nunsorted positive integer weights in time linear in the number of machine words\nholding those weights. This algorithm takes advantage of common non-algebraic\ninstructions, and of specific results on optimal prefix free codes. This result\nimproves over the state of the art complexities of $O(N\\lg N)$ in the algebraic\ndecision tree model and $O(N\\lg\\lg N)$ in the RAM model for the computation of\nHuffman's codes, a landmark in compression and coding since 1952.\n", "Comment: The algorithm TopDown is incorrect, and it is not clear how to\n  correct it"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1204.5801"}}, {"publisher": {"name": ""}, "description": "  Matrices have become essential data representations for many large-scale\nproblems in data analytics, and hence matrix sketching is a critical task.\nAlthough much research has focused on improving the error/size tradeoff under\nvarious sketching paradigms, the many forms of error bounds make these\napproaches hard to compare in theory and in practice. This paper attempts to\ncategorize and compare most known methods under row-wise streaming updates with\nprovable guarantees, and then to tweak some of these methods to gain practical\nimprovements while retaining guarantees.\n  For instance, we observe that a simple heuristic iSVD, with no guarantees,\ntends to outperform all known approaches in terms of size/error trade-off. We\nmodify the best performing method with guarantees FrequentDirections under the\nsize/error trade-off to match the performance of iSVD and retain its\nguarantees. We also demonstrate some adversarial datasets where iSVD performs\nquite poorly. In comparing techniques in the time/error trade-off, techniques\nbased on hashing or sampling tend to perform better. In this setting we modify\nthe most studied sampling regime to retain error guarantee but obtain dramatic\nimprovements in the time/error trade-off.\n  Finally, we provide easy replication of our studies on APT, a new testbed\nwhich makes available not only code and datasets, but also a computing platform\nwith fixed environmental settings.\n", "contributors": [{"name": "Desai, Amey", "sameAs": [], "familyName": "Desai", "additionalName": "", "givenName": "Amey", "email": ""}, {"name": "Ghashami, Mina", "sameAs": [], "familyName": "Ghashami", "additionalName": "", "givenName": "Mina", "email": ""}, {"name": "Phillips, Jeff M.", "sameAs": [], "familyName": "Phillips", "additionalName": "M.", "givenName": "Jeff", "email": ""}], "title": "Improved Practical Matrix Sketching with Guarantees", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06561", "oai:arXiv.org:1501.06561"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Matrices have become essential data representations for many large-scale\nproblems in data analytics, and hence matrix sketching is a critical task.\nAlthough much research has focused on improving the error/size tradeoff under\nvarious sketching paradigms, the many forms of error bounds make these\napproaches hard to compare in theory and in practice. This paper attempts to\ncategorize and compare most known methods under row-wise streaming updates with\nprovable guarantees, and then to tweak some of these methods to gain practical\nimprovements while retaining guarantees.\n  For instance, we observe that a simple heuristic iSVD, with no guarantees,\ntends to outperform all known approaches in terms of size/error trade-off. We\nmodify the best performing method with guarantees FrequentDirections under the\nsize/error trade-off to match the performance of iSVD and retain its\nguarantees. We also demonstrate some adversarial datasets where iSVD performs\nquite poorly. In comparing techniques in the time/error trade-off, techniques\nbased on hashing or sampling tend to perform better. In this setting we modify\nthe most studied sampling regime to retain error guarantee but obtain dramatic\nimprovements in the time/error trade-off.\n  Finally, we provide easy replication of our studies on APT, a new testbed\nwhich makes available not only code and datasets, but also a computing platform\nwith fixed environmental settings.\n", "Comment: 27 pages"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "68w40"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06561"}}, {"publisher": {"name": ""}, "description": "  Simultaneous detection and estimation is important in many engineering\napplications. In particular, there are many applications where it is important\nto perform signal detection and Signal-to-Noise-Ratio (SNR) estimation jointly.\nApplication of existing frameworks in the literature that handle simultaneous\ndetection and estimation is not straightforward for this class of application.\nThis paper therefore aims at bridging the gap between an existing framework,\nspecifically the work by Middleton et al., and the mentioned application class\nby presenting a jointly optimal detector and signal and noise power estimators.\nThe detector and estimators are given for the Gaussian observation model with\nappropriate conjugate priors on the signal and noise power. Simulation results\naffirm the superior performance of the optimal solution compared to the\nseparate detection and estimation approaches.\n", "contributors": [{"name": "Le, Long", "sameAs": [], "familyName": "Le", "additionalName": "", "givenName": "Long", "email": ""}, {"name": "Jones, Douglas L.", "sameAs": [], "familyName": "Jones", "additionalName": "L.", "givenName": "Douglas", "email": ""}], "title": "Optimal Simultaneous Detection and Signal and Noise Power Estimation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4249", "oai:arXiv.org:1410.4249"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Simultaneous detection and estimation is important in many engineering\napplications. In particular, there are many applications where it is important\nto perform signal detection and Signal-to-Noise-Ratio (SNR) estimation jointly.\nApplication of existing frameworks in the literature that handle simultaneous\ndetection and estimation is not straightforward for this class of application.\nThis paper therefore aims at bridging the gap between an existing framework,\nspecifically the work by Middleton et al., and the mentioned application class\nby presenting a jointly optimal detector and signal and noise power estimators.\nThe detector and estimators are given for the Gaussian observation model with\nappropriate conjugate priors on the signal and noise power. Simulation results\naffirm the superior performance of the optimal solution compared to the\nseparate detection and estimation approaches.\n", "Comment: appears in 2014 IEEE International Symposium on Information Theory\n  (ISIT)"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4249"}}, {"publisher": {"name": ""}, "description": "  The organizer of a machine learning competition faces the problem of\nmaintaining an accurate leaderboard that faithfully represents the quality of\nthe best submission of each competing team. What makes this estimation problem\nparticularly challenging is its sequential and adaptive nature. As participants\nare allowed to repeatedly evaluate their submissions on the leaderboard, they\nmay begin to overfit to the holdout data that supports the leaderboard. Few\ntheoretical results give actionable advice on how to design a reliable\nleaderboard. Existing approaches therefore often resort to poorly understood\nheuristics such as limiting the bit precision of answers and the rate of\nre-submission.\n  In this work, we introduce a notion of \"leaderboard accuracy\" tailored to the\nformat of a competition. We introduce a natural algorithm called \"the Ladder\"\nand demonstrate that it simultaneously supports strong theoretical guarantees\nin a fully adaptive model of estimation, withstands practical adversarial\nattacks, and achieves high utility on real submission files from an actual\ncompetition hosted by Kaggle.\n  Notably, we are able to sidestep a powerful recent hardness result for\nadaptive risk estimation that rules out algorithms such as ours under a\nseemingly very similar notion of accuracy. On a practical note, we provide a\ncompletely parameter-free variant of our algorithm that can be deployed in a\nreal competition with no tuning required whatsoever.\n", "contributors": [{"name": "Blum, Avrim", "sameAs": [], "familyName": "Blum", "additionalName": "", "givenName": "Avrim", "email": ""}, {"name": "Hardt, Moritz", "sameAs": [], "familyName": "Hardt", "additionalName": "", "givenName": "Moritz", "email": ""}], "title": "The Ladder: A Reliable Leaderboard for Machine Learning Competitions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04585", "oai:arXiv.org:1502.04585"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The organizer of a machine learning competition faces the problem of\nmaintaining an accurate leaderboard that faithfully represents the quality of\nthe best submission of each competing team. What makes this estimation problem\nparticularly challenging is its sequential and adaptive nature. As participants\nare allowed to repeatedly evaluate their submissions on the leaderboard, they\nmay begin to overfit to the holdout data that supports the leaderboard. Few\ntheoretical results give actionable advice on how to design a reliable\nleaderboard. Existing approaches therefore often resort to poorly understood\nheuristics such as limiting the bit precision of answers and the rate of\nre-submission.\n  In this work, we introduce a notion of \"leaderboard accuracy\" tailored to the\nformat of a competition. We introduce a natural algorithm called \"the Ladder\"\nand demonstrate that it simultaneously supports strong theoretical guarantees\nin a fully adaptive model of estimation, withstands practical adversarial\nattacks, and achieves high utility on real submission files from an actual\ncompetition hosted by Kaggle.\n  Notably, we are able to sidestep a powerful recent hardness result for\nadaptive risk estimation that rules out algorithms such as ours under a\nseemingly very similar notion of accuracy. On a practical note, we provide a\ncompletely parameter-free variant of our algorithm that can be deployed in a\nreal competition with no tuning required whatsoever.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04585"}}, {"publisher": {"name": ""}, "description": "  Valiant's (2007) model of evolvability models the evolutionary process of\nacquiring useful functionality as a restricted form of learning from random\nexamples. Linear threshold functions and their various subclasses, such as\nconjunctions and decision lists, play a fundamental role in learning theory and\nhence their evolvability has been the primary focus of research on Valiant's\nframework (2007). One of the main open problems regarding the model is whether\nconjunctions are evolvable distribution-independently (Feldman and Valiant,\n2008). We show that the answer is negative. Our proof is based on a new\ncombinatorial parameter of a concept class that lower-bounds the complexity of\nlearning from correlations.\n  We contrast the lower bound with a proof that linear threshold functions\nhaving a non-negligible margin on the data points are evolvable\ndistribution-independently via a simple mutation algorithm. Our algorithm\nrelies on a non-linear loss function being used to select the hypotheses\ninstead of 0-1 loss in Valiant's (2007) original definition. The proof of\nevolvability requires that the loss function satisfies several mild conditions\nthat are, for example, satisfied by the quadratic loss function studied in\nseveral other works (Michael, 2007; Feldman, 2009; Valiant, 2010). An important\nproperty of our evolution algorithm is monotonicity, that is the algorithm\nguarantees evolvability without any decreases in performance. Previously,\nmonotone evolvability was only shown for conjunctions with quadratic loss\n(Feldman, 2009) or when the distribution on the domain is severely restricted\n(Michael, 2007; Feldman, 2009; Kanade et al., 2010)\n", "contributors": [{"name": "Feldman, Vitaly", "sameAs": [], "familyName": "Feldman", "additionalName": "", "givenName": "Vitaly", "email": ""}], "title": "Distribution-Independent Evolvability of Linear Threshold Functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-03-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1103.4904", "oai:arXiv.org:1103.4904"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Valiant's (2007) model of evolvability models the evolutionary process of\nacquiring useful functionality as a restricted form of learning from random\nexamples. Linear threshold functions and their various subclasses, such as\nconjunctions and decision lists, play a fundamental role in learning theory and\nhence their evolvability has been the primary focus of research on Valiant's\nframework (2007). One of the main open problems regarding the model is whether\nconjunctions are evolvable distribution-independently (Feldman and Valiant,\n2008). We show that the answer is negative. Our proof is based on a new\ncombinatorial parameter of a concept class that lower-bounds the complexity of\nlearning from correlations.\n  We contrast the lower bound with a proof that linear threshold functions\nhaving a non-negligible margin on the data points are evolvable\ndistribution-independently via a simple mutation algorithm. Our algorithm\nrelies on a non-linear loss function being used to select the hypotheses\ninstead of 0-1 loss in Valiant's (2007) original definition. The proof of\nevolvability requires that the loss function satisfies several mild conditions\nthat are, for example, satisfied by the quadratic loss function studied in\nseveral other works (Michael, 2007; Feldman, 2009; Valiant, 2010). An important\nproperty of our evolution algorithm is monotonicity, that is the algorithm\nguarantees evolvability without any decreases in performance. Previously,\nmonotone evolvability was only shown for conjunctions with quadratic loss\n(Feldman, 2009) or when the distribution on the domain is severely restricted\n(Michael, 2007; Feldman, 2009; Kanade et al., 2010)\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "computer science - neural and evolutionary computing", "computer science - learning"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1103.4904"}}, {"publisher": {"name": ""}, "description": "  Software testing involves identifying the test cases whichdiscover errors in\nthe program. However, exhaustive testing ofsoftware is very time consuming. In\nthis paper, a technique isproposed to prioritize test case scenarios by\nidentifying the critical path clusters using genetic algorithm. The test case\nscenarios are derived from the UML activity diagram and state chart diagram.\nThe testing efficiency is optimized by applying the genetic algorithm on the\ntest data. The information flow metric is adopted in this work for calculating\nthe information flow complexity associated with each node of the activity\ndiagram and state chart diagram.\n", "contributors": [{"name": "Sharma, Chayanika", "sameAs": [], "familyName": "Sharma", "additionalName": "", "givenName": "Chayanika", "email": ""}, {"name": "Sabharwal, Sangeeta", "sameAs": [], "familyName": "Sabharwal", "additionalName": "", "givenName": "Sangeeta", "email": ""}, {"name": "Sibal, Ritu", "sameAs": [], "familyName": "Sibal", "additionalName": "", "givenName": "Ritu", "email": ""}], "title": "Applying Genetic Algorithm for Prioritization of Test Case Scenarios\n  Derived from UML Diagrams", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4838", "oai:arXiv.org:1410.4838"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Software testing involves identifying the test cases whichdiscover errors in\nthe program. However, exhaustive testing ofsoftware is very time consuming. In\nthis paper, a technique isproposed to prioritize test case scenarios by\nidentifying the critical path clusters using genetic algorithm. The test case\nscenarios are derived from the UML activity diagram and state chart diagram.\nThe testing efficiency is optimized by applying the genetic algorithm on the\ntest data. The information flow metric is adopted in this work for calculating\nthe information flow complexity associated with each node of the activity\ndiagram and state chart diagram.\n", "Comment: 12 pages"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2014-10-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4838"}}, {"publisher": {"name": ""}, "description": "  Linking network flows is an important problem in intrusion detection as well\nas anonymity. Passive traffic analysis can link flows but requires long periods\nof observation to reduce errors. Active traffic analysis, also known as flow\nwatermarking, allows for better precision and is more scalable. Previous flow\nwatermarks introduce significant delays to the traffic flow as a side effect of\nusing a blind detection scheme; this enables attacks that detect and remove the\nwatermark, while at the same time slowing down legitimate traffic. We propose\nthe first non-blind approach for flow watermarking, called RAINBOW, that\nimproves watermark invisibility by inserting delays hundreds of times smaller\nthan previous blind watermarks, hence reduces the watermark interference on\nnetwork flows. We derive and analyze the optimum detectors for RAINBOW as well\nas the passive traffic analysis under different traffic models by using\nhypothesis testing. Comparing the detection performance of RAINBOW and the\npassive approach we observe that both RAINBOW and passive traffic analysis\nperform similarly good in the case of uncorrelated traffic, however, the\nRAINBOW detector drastically outperforms the optimum passive detector in the\ncase of correlated network flows. This justifies the use of non-blind\nwatermarks over passive traffic analysis even though both approaches have\nsimilar scalability constraints. We confirm our analysis by simulating the\ndetectors and testing them against large traces of real network flows.\n", "contributors": [{"name": "Houmansadr, Amir", "sameAs": [], "familyName": "Houmansadr", "additionalName": "", "givenName": "Amir", "email": ""}, {"name": "Kiyavash, Negar", "sameAs": [], "familyName": "Kiyavash", "additionalName": "", "givenName": "Negar", "email": ""}, {"name": "Borisov, Nikita", "sameAs": [], "familyName": "Borisov", "additionalName": "", "givenName": "Nikita", "email": ""}], "title": "Non-blind watermarking of network flows", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-03-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1203.2273", "oai:arXiv.org:1203.2273"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Linking network flows is an important problem in intrusion detection as well\nas anonymity. Passive traffic analysis can link flows but requires long periods\nof observation to reduce errors. Active traffic analysis, also known as flow\nwatermarking, allows for better precision and is more scalable. Previous flow\nwatermarks introduce significant delays to the traffic flow as a side effect of\nusing a blind detection scheme; this enables attacks that detect and remove the\nwatermark, while at the same time slowing down legitimate traffic. We propose\nthe first non-blind approach for flow watermarking, called RAINBOW, that\nimproves watermark invisibility by inserting delays hundreds of times smaller\nthan previous blind watermarks, hence reduces the watermark interference on\nnetwork flows. We derive and analyze the optimum detectors for RAINBOW as well\nas the passive traffic analysis under different traffic models by using\nhypothesis testing. Comparing the detection performance of RAINBOW and the\npassive approach we observe that both RAINBOW and passive traffic analysis\nperform similarly good in the case of uncorrelated traffic, however, the\nRAINBOW detector drastically outperforms the optimum passive detector in the\ncase of correlated network flows. This justifies the use of non-blind\nwatermarks over passive traffic analysis even though both approaches have\nsimilar scalability constraints. We confirm our analysis by simulating the\ndetectors and testing them against large traces of real network flows.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1203.2273"}}, {"publisher": {"name": ""}, "description": "  We analyze and improve low rank representation (LRR), the state-of-the-art\nalgorithm for subspace segmentation of data. We prove that for the noiseless\ncase, the optimization model of LRR has a unique solution, which is the shape\ninteraction matrix (SIM) of the data matrix. So in essence LRR is equivalent to\nfactorization methods. We also prove that the minimum value of the optimization\nmodel of LRR is equal to the rank of the data matrix. For the noisy case, we\nshow that LRR can be approximated as a factorization method that combines noise\nremoval by column sparse robust PCA. We further propose an improved version of\nLRR, called Robust Shape Interaction (RSI), which uses the corrected data as\nthe dictionary instead of the noisy data. RSI is more robust than LRR when the\ncorruption in data is heavy. Experiments on both synthetic and real data\ntestify to the improved robustness of RSI.\n", "contributors": [{"name": "Siming, Wei", "sameAs": [], "familyName": "Siming", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Zhouchen, Lin", "sameAs": [], "familyName": "Zhouchen", "additionalName": "", "givenName": "Lin", "email": ""}], "title": "Analysis and Improvement of Low Rank Representation for Subspace\n  segmentation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-07-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1107.1561", "oai:arXiv.org:1107.1561"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We analyze and improve low rank representation (LRR), the state-of-the-art\nalgorithm for subspace segmentation of data. We prove that for the noiseless\ncase, the optimization model of LRR has a unique solution, which is the shape\ninteraction matrix (SIM) of the data matrix. So in essence LRR is equivalent to\nfactorization methods. We also prove that the minimum value of the optimization\nmodel of LRR is equal to the rank of the data matrix. For the noisy case, we\nshow that LRR can be approximated as a factorization method that combines noise\nremoval by column sparse robust PCA. We further propose an improved version of\nLRR, called Robust Shape Interaction (RSI), which uses the corrected data as\nthe dictionary instead of the noisy data. RSI is more robust than LRR when the\ncorruption in data is heavy. Experiments on both synthetic and real data\ntestify to the improved robustness of RSI.\n", "Comment: Disclosed as Microsoft technical report on Auguat 25, 2010"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1107.1561"}}, {"publisher": {"name": ""}, "description": "  CitNetExplorer has been used to study the citation networks among the\nscientific publications on tribology during the 15 years period from 1998-2012.\nThree data sets from Web of Science have been analyzed: (1) Core publications\nof tribology research, (2) publications on nanotribology and (3) publications\nof Bharat Bhushan (a top-contributor to nanotribology research). Based on this\nstudy, some suggestions are made to improve the CitNetExplorer.\n", "contributors": [{"name": "Elango, Bakthavachalam", "sameAs": [], "familyName": "Elango", "additionalName": "", "givenName": "Bakthavachalam", "email": ""}, {"name": "Bornmann, Lutz", "sameAs": [], "familyName": "Bornmann", "additionalName": "", "givenName": "Lutz", "email": ""}, {"name": "Shankar, Subramaniam", "sameAs": [], "familyName": "Shankar", "additionalName": "", "givenName": "Subramaniam", "email": ""}], "title": "Study of Citation Networks in Tribology Research", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0100", "oai:arXiv.org:1411.0100"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  CitNetExplorer has been used to study the citation networks among the\nscientific publications on tribology during the 15 years period from 1998-2012.\nThree data sets from Web of Science have been analyzed: (1) Core publications\nof tribology research, (2) publications on nanotribology and (3) publications\nof Bharat Bhushan (a top-contributor to nanotribology research). Based on this\nstudy, some suggestions are made to improve the CitNetExplorer.\n", "Comment: Submitted to the journal Scientometrics"]}}], "languages": [null], "subjects": ["computer science - digital libraries"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0100"}}, {"publisher": {"name": ""}, "description": "  In computational biology, biological entities such as genes or proteins are\nusually annotated with terms extracted from Gene Ontology (GO). The functional\nsimilarity among terms of an ontology is evaluated by using Semantic Similarity\nMeasures (SSM). More recently, the extensive application of SSMs yielded to the\nSemantic Similarity Networks (SSNs). SSNs are edge-weighted graphs where the\nnodes are concepts (e.g. proteins) and each edge has an associated weight that\nrepresents the semantic similarity among related pairs of nodes. The analysis\nof SSNs may reveal biologically meaningful knowledge. For these aims, the need\nfor the introduction of tool able to manage and analyze SSN arises.\nConsequently we developed SSN-Analyzer a web based tool able to build and\npreprocess SSN. As proof of concept we demonstrate that community detection\nalgorithms applied to filtered (thresholded) networks, have better performances\nin terms of biological relevance of the results, with respect to the use of raw\nunfiltered networks.\n", "contributors": [{"name": "Cannataro, Mario", "sameAs": [], "familyName": "Cannataro", "additionalName": "", "givenName": "Mario", "email": ""}, {"name": "Guzzi, Pietro Hiram", "sameAs": [], "familyName": "Guzzi", "additionalName": "Hiram", "givenName": "Pietro", "email": ""}, {"name": "Milano, Marianna", "sameAs": [], "familyName": "Milano", "additionalName": "", "givenName": "Marianna", "email": ""}, {"name": "Veltri, Pierangelo", "sameAs": [], "familyName": "Veltri", "additionalName": "", "givenName": "Pierangelo", "email": ""}], "title": "A web-based tool to Analyze Semantic Similarity Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7386", "oai:arXiv.org:1412.7386"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": "  In computational biology, biological entities such as genes or proteins are\nusually annotated with terms extracted from Gene Ontology (GO). The functional\nsimilarity among terms of an ontology is evaluated by using Semantic Similarity\nMeasures (SSM). More recently, the extensive application of SSMs yielded to the\nSemantic Similarity Networks (SSNs). SSNs are edge-weighted graphs where the\nnodes are concepts (e.g. proteins) and each edge has an associated weight that\nrepresents the semantic similarity among related pairs of nodes. The analysis\nof SSNs may reveal biologically meaningful knowledge. For these aims, the need\nfor the introduction of tool able to manage and analyze SSN arises.\nConsequently we developed SSN-Analyzer a web based tool able to build and\npreprocess SSN. As proof of concept we demonstrate that community detection\nalgorithms applied to filtered (thresholded) networks, have better performances\nin terms of biological relevance of the results, with respect to the use of raw\nunfiltered networks.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - computational engineering", "finance", "and science", "quantitative biology - molecular networks"], "providerUpdatedDateTime": "2014-12-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7386"}}, {"publisher": {"name": ""}, "description": "  This report evaluates the new analytical capabilities of DataStax Enterprise\n(DSE) [1] through the use of standard Hadoop workloads. In particular, we run\nexperiments with CPU and I/O bound micro-benchmarks as well as OLAP-style\nanalytical query workloads. The performed tests should show that DSE is capable\nof successfully executing Hadoop applications without the need to adapt them\nfor the underlying Cassandra distributed storage system [2]. Due to the\nCassandra File System (CFS) [3], which supports the Hadoop Distributed File\nSystem API, Hadoop stack applications should seamlessly run in DSE. The report\nis structured as follows: Section 2 provides a brief description of the\ntechnologies involved in our study. An overview of our used hardware and\nsoftware components of the experimental environment is given in Section 3. Our\nbenchmark methodology is defined in Section 4. The performed experiments\ntogether with the evaluation of the results are presented in Section 5.\nFinally, Section 6 concludes with lessons learned.\n", "contributors": [{"name": "Ivanov, Todor", "sameAs": [], "familyName": "Ivanov", "additionalName": "", "givenName": "Todor", "email": ""}, {"name": "Niemann, Raik", "sameAs": [], "familyName": "Niemann", "additionalName": "", "givenName": "Raik", "email": ""}, {"name": "Izberovic, Sead", "sameAs": [], "familyName": "Izberovic", "additionalName": "", "givenName": "Sead", "email": ""}, {"name": "Rosselli, Marten", "sameAs": [], "familyName": "Rosselli", "additionalName": "", "givenName": "Marten", "email": ""}, {"name": "Tolle, Karsten", "sameAs": [], "familyName": "Tolle", "additionalName": "", "givenName": "Karsten", "email": ""}, {"name": "Zicari, Roberto V.", "sameAs": [], "familyName": "Zicari", "additionalName": "V.", "givenName": "Roberto", "email": ""}], "title": "Benchmarking DataStax Enterprise/Cassandra with HiBench", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4044", "oai:arXiv.org:1411.4044"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This report evaluates the new analytical capabilities of DataStax Enterprise\n(DSE) [1] through the use of standard Hadoop workloads. In particular, we run\nexperiments with CPU and I/O bound micro-benchmarks as well as OLAP-style\nanalytical query workloads. The performed tests should show that DSE is capable\nof successfully executing Hadoop applications without the need to adapt them\nfor the underlying Cassandra distributed storage system [2]. Due to the\nCassandra File System (CFS) [3], which supports the Hadoop Distributed File\nSystem API, Hadoop stack applications should seamlessly run in DSE. The report\nis structured as follows: Section 2 provides a brief description of the\ntechnologies involved in our study. An overview of our used hardware and\nsoftware components of the experimental environment is given in Section 3. Our\nbenchmark methodology is defined in Section 4. The performed experiments\ntogether with the evaluation of the results are presented in Section 5.\nFinally, Section 6 concludes with lessons learned.\n", "Comment: arXiv admin note: substantial text overlap with arXiv:1411.3811"]}}], "languages": [null], "subjects": ["computer science - distributed", "computer science - databases", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4044"}}, {"publisher": {"name": ""}, "description": "  Let C be a depth-3 circuit with n variables, degree d and top fanin k (called\nsps(k,d,n) circuits) over base field F. It is a major open problem to design a\ndeterministic polynomial time blackbox algorithm that tests if C is identically\nzero. Klivans & Spielman (STOC 2001) observed that the problem is open even\nwhen k is a constant. This case has been subjected to a serious study over the\npast few years, starting from the work of Dvir & Shpilka (STOC 2005).\n  We give the first polynomial time blackbox algorithm for this problem. Our\nalgorithm runs in time poly(nd^k), regardless of the base field. The only field\nfor which polynomial time algorithms were previously known is F=Q (Kayal &\nSaraf, FOCS 2009, and Saxena & Seshadhri, FOCS 2010). This is the first\nblackbox algorithm for depth-3 circuits that does not use the rank based\napproaches of Karnin & Shpilka (CCC 2008).\n  We prove an important tool for the study of depth-3 identities. We design a\nblackbox polynomial time transformation that reduces the number of variables in\na sps(k,d,n) circuit to k variables, but preserves the identity structure.\n", "contributors": [{"name": "Saxena, Nitin", "sameAs": [], "familyName": "Saxena", "additionalName": "", "givenName": "Nitin", "email": ""}, {"name": "Seshadhri, C.", "sameAs": [], "familyName": "Seshadhri", "additionalName": "", "givenName": "C.", "email": ""}], "title": "Blackbox identity testing for bounded top fanin depth-3 circuits: the\n  field doesn't matter", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-11-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1011.3234", "oai:arXiv.org:1011.3234"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Let C be a depth-3 circuit with n variables, degree d and top fanin k (called\nsps(k,d,n) circuits) over base field F. It is a major open problem to design a\ndeterministic polynomial time blackbox algorithm that tests if C is identically\nzero. Klivans & Spielman (STOC 2001) observed that the problem is open even\nwhen k is a constant. This case has been subjected to a serious study over the\npast few years, starting from the work of Dvir & Shpilka (STOC 2005).\n  We give the first polynomial time blackbox algorithm for this problem. Our\nalgorithm runs in time poly(nd^k), regardless of the base field. The only field\nfor which polynomial time algorithms were previously known is F=Q (Kayal &\nSaraf, FOCS 2009, and Saxena & Seshadhri, FOCS 2010). This is the first\nblackbox algorithm for depth-3 circuits that does not use the rank based\napproaches of Karnin & Shpilka (CCC 2008).\n  We prove an important tool for the study of depth-3 identities. We design a\nblackbox polynomial time transformation that reduces the number of variables in\na sps(k,d,n) circuit to k variables, but preserves the identity structure.\n", "Comment: 14 pages, 1 figure, preliminary version"]}}], "languages": [null], "subjects": ["mathematics - commutative algebra", "computer science - computational complexity", "13p25"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1011.3234"}}, {"publisher": {"name": ""}, "description": "  For overlay cognitive radio networks (CRNs), transform domain communication\nsystem (TDCS) has been proposed to support multiuser communications through\nspectrum bin nulling and frequency domain spreading. In TDCS-based CRNs, each\nuser is assigned a specific pseudorandom spreading sequence. However, the\nexistence of multiuser interference (MUI) is one of main concerns, due to the\nnon-zero cross-correlations between any pair of TDCS signals. In this paper, a\nnovel framework of TDCS-based CRNs with the joint design of sequences and\nmodulation schemes is presented to realize MUI avoidance. With the uncertainty\nof spectrum sensing results in CRNs, we first introduce a unique sequence\ndesign through two-dimensional time-frequency synthesis and obtain a class of\nalmost perfect sequences. That is, periodic auto-correlation and\ncross-correlations are identically zero for most circular shifts. These\ncorrelation properties are further exploited in conjunction with a\nspecially-designed cyclic code shift keying in order to achieve the advantage\nof MUI avoidance. Numerical results demonstrate that the proposed TDCS-based\nCRNs are considered as preferable candidates for decentralized networks against\nthe near-far problem.\n", "contributors": [{"name": "H, Su", "sameAs": [], "familyName": "H", "additionalName": "", "givenName": "Su", "email": ""}, {"name": "Bi, Guoan", "sameAs": [], "familyName": "Bi", "additionalName": "", "givenName": "Guoan", "email": ""}, {"name": "Guan, Yong Liang", "sameAs": [], "familyName": "Guan", "additionalName": "Liang", "givenName": "Yong", "email": ""}, {"name": "Li, Shaoqian", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Shaoqian", "email": ""}], "title": "TDCS-based Cognitive Radio Networks with Multiuser Interference\n  Avoidance", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-11-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1311.4964", "IEEE Transactions on Communications 61(12): 4828-4835, 2013", "oai:arXiv.org:1311.4964"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  For overlay cognitive radio networks (CRNs), transform domain communication\nsystem (TDCS) has been proposed to support multiuser communications through\nspectrum bin nulling and frequency domain spreading. In TDCS-based CRNs, each\nuser is assigned a specific pseudorandom spreading sequence. However, the\nexistence of multiuser interference (MUI) is one of main concerns, due to the\nnon-zero cross-correlations between any pair of TDCS signals. In this paper, a\nnovel framework of TDCS-based CRNs with the joint design of sequences and\nmodulation schemes is presented to realize MUI avoidance. With the uncertainty\nof spectrum sensing results in CRNs, we first introduce a unique sequence\ndesign through two-dimensional time-frequency synthesis and obtain a class of\nalmost perfect sequences. That is, periodic auto-correlation and\ncross-correlations are identically zero for most circular shifts. These\ncorrelation properties are further exploited in conjunction with a\nspecially-designed cyclic code shift keying in order to achieve the advantage\nof MUI avoidance. Numerical results demonstrate that the proposed TDCS-based\nCRNs are considered as preferable candidates for decentralized networks against\nthe near-far problem.\n", "Comment: to be appeared in IEEE Transaction on Communications, 2014"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1311.4964"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Recently, to solve large-scale lasso and group lasso problems, screening rules have been developed, the goal of which is to reduce the problem size by efficiently discarding zero coefficients using simple rules independently of the others. However, screening for overlapping group lasso remains an open challenge because the overlaps between groups make it infeasible to test each group independently. In this paper, we develop screening rules for overlapping group lasso. To address the challenge arising from groups with overlaps, we take into account overlapping groups only if they are inclusive of the group being tested, and then we derive screening rules, adopting the dual polytope projection approach. This strategy allows us to screen each group independently of each other. In our experiments, we demonstrate the efficiency of our screening rules on various datasets.", "contributors": [{"name": "Lee, Seunghak", "sameAs": [], "familyName": "Lee", "additionalName": "", "givenName": "Seunghak", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "Screening Rules for Overlapping Group Lasso", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-10-25T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/134", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1134&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1134"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Recently, to solve large-scale lasso and group lasso problems, screening rules have been developed, the goal of which is to reduce the problem size by efficiently discarding zero coefficients using simple rules independently of the others. However, screening for overlapping group lasso remains an open challenge because the overlaps between groups make it infeasible to test each group independently. In this paper, we develop screening rules for overlapping group lasso. To address the challenge arising from groups with overlaps, we take into account overlapping groups only if they are inclusive of the group being tested, and then we derive screening rules, adopting the dual polytope projection approach. This strategy allows us to screen each group independently of each other. In our experiments, we demonstrate the efficiency of our screening rules on various datasets."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-27T19:25:29", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/134"}}, {"publisher": {"name": ""}, "description": "  This paper addresses the design of a dedicated homophonic coding for a class\nof communication systems which, in order to provide both reliability and\nsecurity, first encode the data before encrypting it, which is referred to as\nthe encoding-encryption paradigm. The considered systems employ\nerror-correction coding for reliability, a stream cipher for encryption, and\nhomophonic coding to enhance the protection of the key used in the stream\ncipher, on which relies the security of all the system transmissions. This\npaper presents a security evaluation of such systems from a computational\ncomplexity point of view, which serves as a source for establishing dedicated\nhomophonic code design criteria. The security evaluation shows that the\ncomputational complexity of recovering the secret key, given all the\ninformation an attacker could gather during passive attacks he can mount, is\nlower bounded by the complexity of the related LPN (Learning Parity in Noise)\nproblem in both the average and worst case. This gives guidelines to construct\na dedicated homophonic encoder which maximizes the complexity of the underlying\nLPN problem for a given encoding overhead. Finally, this paper proposes a\ngeneric homophonic coding strategy that fulfills the proposed design criteria\nand thus both enhances security while minimizing the induced overhead.\n", "contributors": [{"name": "Mihaljevic, Miodrag J.", "sameAs": [], "familyName": "Mihaljevic", "additionalName": "J.", "givenName": "Miodrag", "email": ""}, {"name": "Oggier, Frederique", "sameAs": [], "familyName": "Oggier", "additionalName": "", "givenName": "Frederique", "email": ""}, {"name": "Imai, Hideki", "sameAs": [], "familyName": "Imai", "additionalName": "", "givenName": "Hideki", "email": ""}], "title": "Homophonic Coding Design for Communication Systems Employing the\n  Encoding-Encryption Paradigm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-12-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1012.5895", "oai:arXiv.org:1012.5895"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper addresses the design of a dedicated homophonic coding for a class\nof communication systems which, in order to provide both reliability and\nsecurity, first encode the data before encrypting it, which is referred to as\nthe encoding-encryption paradigm. The considered systems employ\nerror-correction coding for reliability, a stream cipher for encryption, and\nhomophonic coding to enhance the protection of the key used in the stream\ncipher, on which relies the security of all the system transmissions. This\npaper presents a security evaluation of such systems from a computational\ncomplexity point of view, which serves as a source for establishing dedicated\nhomophonic code design criteria. The security evaluation shows that the\ncomputational complexity of recovering the secret key, given all the\ninformation an attacker could gather during passive attacks he can mount, is\nlower bounded by the complexity of the related LPN (Learning Parity in Noise)\nproblem in both the average and worst case. This gives guidelines to construct\na dedicated homophonic encoder which maximizes the complexity of the underlying\nLPN problem for a given encoding overhead. Finally, this paper proposes a\ngeneric homophonic coding strategy that fulfills the proposed design criteria\nand thus both enhances security while minimizing the induced overhead.\n", "Comment: 16 pages, 1 figure"]}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1012.5895"}}, {"publisher": {"name": ""}, "description": "  In recent years, crowdfunding has become a popular method of funding new\ntechnology or entertainment products, or artistic projects. The idea is that\npeople or projects ask for many small donations from individuals who support\nthe proposed work, rather than a large amount from a single source.\nCrowdfunding is usually done via an online portal or platform which handles the\nfinancial transactions involved. The Universe Awareness (UNAWE) programme\ndecided to undertake a Kickstarter crowdfunding campaign centring on the\nresource Universe in a Box2. In this article we present the lessons learned and\nbest practices from that campaign.\n", "contributors": [{"name": "Ashton, Abi J.", "sameAs": [], "familyName": "Ashton", "additionalName": "J.", "givenName": "Abi", "email": ""}, {"name": "Russo, Pedro", "sameAs": [], "familyName": "Russo", "additionalName": "", "givenName": "Pedro", "email": ""}, {"name": "Heenatigala, Thilina", "sameAs": [], "familyName": "Heenatigala", "additionalName": "", "givenName": "Thilina", "email": ""}], "title": "Crowdfunding Astronomy Outreach Projects: Lessons Learned from the UNAWE\n  Crowdfunding Campaign", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2115", "oai:arXiv.org:1412.2115"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:astro-ph", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  In recent years, crowdfunding has become a popular method of funding new\ntechnology or entertainment products, or artistic projects. The idea is that\npeople or projects ask for many small donations from individuals who support\nthe proposed work, rather than a large amount from a single source.\nCrowdfunding is usually done via an online portal or platform which handles the\nfinancial transactions involved. The Universe Awareness (UNAWE) programme\ndecided to undertake a Kickstarter crowdfunding campaign centring on the\nresource Universe in a Box2. In this article we present the lessons learned and\nbest practices from that campaign.\n", "Comment: Published - Communicating Astronomy with the Public journal #16 (4\n  pages) (2014)"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - computers and society", "physics - physics education", "astrophysics - instrumentation and methods for astrophysics"], "providerUpdatedDateTime": "2014-12-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2115"}}, {"publisher": {"name": ""}, "description": "  In this paper, we address the problem of dense 3D reconstruction from\nmultiple view images subject to strong lighting variations. In this regard, a\nnew piecewise framework is proposed to explicitly take into account the change\nof illumination across several wide-baseline images. Unlike multi-view stereo\nand multi-view photometric stereo methods, this pipeline deals with\nwide-baseline images that are uncalibrated, in terms of both camera parameters\nand lighting conditions. Such a scenario is meant to avoid use of any specific\nimaging setup and provide a tool for normal users without any expertise. To the\nbest of our knowledge, this paper presents the first work that deals with such\nunconstrained setting. We propose a coarse-to-fine approach, in which a coarse\nmesh is first created using a set of geometric constraints and, then, fine\ndetails are recovered by exploiting photometric properties of the scene.\nAugmenting the fine details on the coarse mesh is done via a final optimization\nstep. Note that the method does not provide a generic solution for multi-view\nphotometric stereo problem but it relaxes several common assumptions of this\nproblem. The approach scales very well in size given its piecewise nature,\ndealing with large scale optimization and with severe missing data. Experiments\non a benchmark dataset Robot data-set show the method performance against 3D\nground truth.\n", "contributors": [{"name": "Sabzevari, Reza", "sameAs": [], "familyName": "Sabzevari", "additionalName": "", "givenName": "Reza", "email": ""}, {"name": "Murino, Vittori", "sameAs": [], "familyName": "Murino", "additionalName": "", "givenName": "Vittori", "email": ""}, {"name": "Del Bue, Alessio", "sameAs": [], "familyName": "Del Bue", "additionalName": "", "givenName": "Alessio", "email": ""}], "title": "PiMPeR: Piecewise Dense 3D Reconstruction from Multi-View and\n  Multi-Illumination Images", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-16", "2015-03-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04598", "oai:arXiv.org:1503.04598"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we address the problem of dense 3D reconstruction from\nmultiple view images subject to strong lighting variations. In this regard, a\nnew piecewise framework is proposed to explicitly take into account the change\nof illumination across several wide-baseline images. Unlike multi-view stereo\nand multi-view photometric stereo methods, this pipeline deals with\nwide-baseline images that are uncalibrated, in terms of both camera parameters\nand lighting conditions. Such a scenario is meant to avoid use of any specific\nimaging setup and provide a tool for normal users without any expertise. To the\nbest of our knowledge, this paper presents the first work that deals with such\nunconstrained setting. We propose a coarse-to-fine approach, in which a coarse\nmesh is first created using a set of geometric constraints and, then, fine\ndetails are recovered by exploiting photometric properties of the scene.\nAugmenting the fine details on the coarse mesh is done via a final optimization\nstep. Note that the method does not provide a generic solution for multi-view\nphotometric stereo problem but it relaxes several common assumptions of this\nproblem. The approach scales very well in size given its piecewise nature,\ndealing with large scale optimization and with severe missing data. Experiments\non a benchmark dataset Robot data-set show the method performance against 3D\nground truth.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04598"}}, {"publisher": {"name": ""}, "description": "  The existence of a polynomial kernel for Odd Cycle Transversal was a\nnotorious open problem in parameterized complexity. Recently, this was settled\nby the present authors (Kratsch and Wahlstr\\\"om, SODA 2012), with a randomized\npolynomial kernel for the problem, using matroid theory to encode flow\nquestions over a set of terminals in size polynomial in the number of\nterminals.\n  In the current work we further establish the usefulness of matroid theory to\nkernelization by showing applications of a result on representative sets due to\nLov\\'asz (Combinatorial Surveys 1977) and Marx (TCS 2009). We show how\nrepresentative sets can be used to give a polynomial kernel for the elusive\nAlmost 2-SAT problem. We further apply the representative sets tool to the\nproblem of finding irrelevant vertices in graph cut problems, i.e., vertices\nwhich can be made undeletable without affecting the status of the problem. This\ngives the first significant progress towards a polynomial kernel for the\nMultiway Cut problem; in particular, we get a kernel of O(k^{s+1}) vertices for\nMultiway Cut instances with at most s terminals. Both these kernelization\nresults have significant spin-off effects, producing the first polynomial\nkernels for a range of related problems.\n  More generally, the irrelevant vertex results have implications for covering\nmin-cuts in graphs. For a directed graph G=(V,E) and sets S, T \\subseteq V, let\nr be the size of a minimum (S,T)-vertex cut (which may intersect S and T). We\ncan find a set Z \\subseteq V of size O(|S|*|T|*r) which contains a minimum\n(A,B)-vertex cut for every A \\subseteq S, B \\subseteq T. Similarly, for an\nundirected graph G=(V,E), a set of terminals X \\subseteq V, and a constant s,\nwe can find a set Z\\subseteq V of size O(|X|^{s+1}) which contains a minimum\nmultiway cut for any partition of X into at most s pairwise disjoint subsets.\n", "contributors": [{"name": "Kratsch, Stefan", "sameAs": [], "familyName": "Kratsch", "additionalName": "", "givenName": "Stefan", "email": ""}, {"name": "Wahlstr\u00f6m, Magnus", "sameAs": [], "familyName": "Wahlstr\u00f6m", "additionalName": "", "givenName": "Magnus", "email": ""}], "title": "Representative sets and irrelevant vertices: New tools for kernelization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-09", "2012-06-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.2195", "oai:arXiv.org:1111.2195"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The existence of a polynomial kernel for Odd Cycle Transversal was a\nnotorious open problem in parameterized complexity. Recently, this was settled\nby the present authors (Kratsch and Wahlstr\\\"om, SODA 2012), with a randomized\npolynomial kernel for the problem, using matroid theory to encode flow\nquestions over a set of terminals in size polynomial in the number of\nterminals.\n  In the current work we further establish the usefulness of matroid theory to\nkernelization by showing applications of a result on representative sets due to\nLov\\'asz (Combinatorial Surveys 1977) and Marx (TCS 2009). We show how\nrepresentative sets can be used to give a polynomial kernel for the elusive\nAlmost 2-SAT problem. We further apply the representative sets tool to the\nproblem of finding irrelevant vertices in graph cut problems, i.e., vertices\nwhich can be made undeletable without affecting the status of the problem. This\ngives the first significant progress towards a polynomial kernel for the\nMultiway Cut problem; in particular, we get a kernel of O(k^{s+1}) vertices for\nMultiway Cut instances with at most s terminals. Both these kernelization\nresults have significant spin-off effects, producing the first polynomial\nkernels for a range of related problems.\n  More generally, the irrelevant vertex results have implications for covering\nmin-cuts in graphs. For a directed graph G=(V,E) and sets S, T \\subseteq V, let\nr be the size of a minimum (S,T)-vertex cut (which may intersect S and T). We\ncan find a set Z \\subseteq V of size O(|S|*|T|*r) which contains a minimum\n(A,B)-vertex cut for every A \\subseteq S, B \\subseteq T. Similarly, for an\nundirected graph G=(V,E), a set of terminals X \\subseteq V, and a constant s,\nwe can find a set Z\\subseteq V of size O(|X|^{s+1}) which contains a minimum\nmultiway cut for any partition of X into at most s pairwise disjoint subsets.\n", "Comment: 30 pages. To appear in FOCS 2012"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.2195"}}, {"publisher": {"name": ""}, "description": "  We propose TOPL automata as a new method for runtime verification of systems\nwith unbounded resource generation. Paradigmatic such systems are\nobject-oriented programs which can dynamically generate an unbounded number of\nfresh object identities during their execution. Our formalism is based on\nregister automata, a particularly successful approach in automata over infinite\nalphabets which administers a finite-state machine with boundedly many\ninput-storing registers. We show that TOPL automata are equally expressive to\nregister automata and yet suitable to express properties of programs. Compared\nto other runtime verification methods, our technique can handle a class of\nproperties beyond the reach of current tools. We show in particular that\nproperties which require value updates are not expressible with current\ntechniques yet are naturally captured by TOPL machines. On the practical side,\nwe present a tool for runtime verification of Java programs via TOPL\nproperties, where the trade-off between the coverage and the overhead of the\nmonitoring system is tunable by means of a number of parameters. We validate\nour technique by checking properties involving multiple objects and chaining of\nvalues on large open source projects.\n", "contributors": [{"name": "Grigore, Radu", "sameAs": [], "familyName": "Grigore", "additionalName": "", "givenName": "Radu", "email": ""}, {"name": "Distefano, Dino", "sameAs": [], "familyName": "Distefano", "additionalName": "", "givenName": "Dino", "email": ""}, {"name": "Petersen, Rasmus Lerchedahl", "sameAs": [], "familyName": "Petersen", "additionalName": "Lerchedahl", "givenName": "Rasmus", "email": ""}, {"name": "Tzevelekos, Nikos", "sameAs": [], "familyName": "Tzevelekos", "additionalName": "", "givenName": "Nikos", "email": ""}], "title": "Runtime Verification Based on Register Automata", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-09-24", "2015-01-20"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1209.5325", "oai:arXiv.org:1209.5325"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We propose TOPL automata as a new method for runtime verification of systems\nwith unbounded resource generation. Paradigmatic such systems are\nobject-oriented programs which can dynamically generate an unbounded number of\nfresh object identities during their execution. Our formalism is based on\nregister automata, a particularly successful approach in automata over infinite\nalphabets which administers a finite-state machine with boundedly many\ninput-storing registers. We show that TOPL automata are equally expressive to\nregister automata and yet suitable to express properties of programs. Compared\nto other runtime verification methods, our technique can handle a class of\nproperties beyond the reach of current tools. We show in particular that\nproperties which require value updates are not expressible with current\ntechniques yet are naturally captured by TOPL machines. On the practical side,\nwe present a tool for runtime verification of Java programs via TOPL\nproperties, where the trade-off between the coverage and the overhead of the\nmonitoring system is tunable by means of a number of parameters. We validate\nour technique by checking properties involving multiple objects and chaining of\nvalues on large open source projects.\n", "Comment: TACAS 2013 (plus proofs)"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "f.4.3", "computer science - software engineering", "d.2.5"], "providerUpdatedDateTime": "2015-01-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1209.5325"}}, {"publisher": {"name": ""}, "description": "  The Python programming language is becoming increasingly popular for\nscientific applications due to its simplicity, versatility, and the broad range\nof its libraries. A drawback of this dynamic language, however, is its low\nruntime performance which limits its applicability for large simulations and\nfor the analysis of large data sets, as is common in astrophysics and\ncosmology. While various frameworks have been developed to address this\nlimitation, most focus on covering the complete language set, and either force\nthe user to alter the code or are not able to reach the full speed of an\noptimised native compiled language. In order to combine the ease of Python and\nthe speed of C++, we developed HOPE, a specialised Python just-in-time (JIT)\ncompiler designed for numerical astrophysical applications. HOPE focuses on a\nsubset of the language and is able to translate Python code into C++ while\nperforming numerical optimisation on mathematical expressions at runtime. To\nenable the JIT compilation, the user only needs to add a decorator to the\nfunction definition. We assess the performance of HOPE by performing a series\nof benchmarks and compare its execution speed with that of plain Python, C++\nand the other existing frameworks. We find that HOPE improves the performance\ncompared to plain Python by a factor of 2 to 120, achieves speeds comparable to\nthat of C++, and often exceeds the speed of the existing solutions. We discuss\nthe differences between HOPE and the other frameworks, as well as future\nextensions of its capabilities. The fully documented HOPE package is available\nat http://hope.phys.ethz.ch and is published under the GPLv3 license on PyPI\nand GitHub.\n", "contributors": [{"name": "Akeret, Joel", "sameAs": [], "familyName": "Akeret", "additionalName": "", "givenName": "Joel", "email": ""}, {"name": "Gamper, Lukas", "sameAs": [], "familyName": "Gamper", "additionalName": "", "givenName": "Lukas", "email": ""}, {"name": "Amara, Adam", "sameAs": [], "familyName": "Amara", "additionalName": "", "givenName": "Adam", "email": ""}, {"name": "Refregier, Alexandre", "sameAs": [], "familyName": "Refregier", "additionalName": "", "givenName": "Alexandre", "email": ""}], "title": "HOPE: A Python Just-In-Time compiler for astrophysical computations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-16", "2014-12-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4345", "oai:arXiv.org:1410.4345"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:astro-ph", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The Python programming language is becoming increasingly popular for\nscientific applications due to its simplicity, versatility, and the broad range\nof its libraries. A drawback of this dynamic language, however, is its low\nruntime performance which limits its applicability for large simulations and\nfor the analysis of large data sets, as is common in astrophysics and\ncosmology. While various frameworks have been developed to address this\nlimitation, most focus on covering the complete language set, and either force\nthe user to alter the code or are not able to reach the full speed of an\noptimised native compiled language. In order to combine the ease of Python and\nthe speed of C++, we developed HOPE, a specialised Python just-in-time (JIT)\ncompiler designed for numerical astrophysical applications. HOPE focuses on a\nsubset of the language and is able to translate Python code into C++ while\nperforming numerical optimisation on mathematical expressions at runtime. To\nenable the JIT compilation, the user only needs to add a decorator to the\nfunction definition. We assess the performance of HOPE by performing a series\nof benchmarks and compare its execution speed with that of plain Python, C++\nand the other existing frameworks. We find that HOPE improves the performance\ncompared to plain Python by a factor of 2 to 120, achieves speeds comparable to\nthat of C++, and often exceeds the speed of the existing solutions. We discuss\nthe differences between HOPE and the other frameworks, as well as future\nextensions of its capabilities. The fully documented HOPE package is available\nat http://hope.phys.ethz.ch and is published under the GPLv3 license on PyPI\nand GitHub.\n", "Comment: Accepted for publication in Astronomy and Computing. 14 pages, 1\n  figure. The code is available at http://hope.phys.ethz.ch"]}}], "languages": [null], "subjects": ["physics - computational physics", "computer science - programming languages", "computer science - mathematical software", "astrophysics - instrumentation and methods for astrophysics"], "providerUpdatedDateTime": "2014-12-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4345"}}, {"publisher": {"name": ""}, "description": "  Recent years have demonstrated that using random feature maps can\nsignificantly decrease the training and testing times of kernel-based\nalgorithms without significantly lowering their accuracy. Regrettably, because\nrandom features are target-agnostic, typically thousands of such features are\nnecessary to achieve acceptable accuracies. In this work, we consider the\nproblem of learning a small number of explicit polynomial features. Our\napproach, named Tensor Machines, finds a parsimonious set of features by\noptimizing over the hypothesis class introduced by Kar and Karnick for random\nfeature maps in a target-specific manner. Exploiting a natural connection\nbetween polynomials and tensors, we provide bounds on the generalization error\nof Tensor Machines. Empirically, Tensor Machines behave favorably on several\nreal-world datasets compared to other state-of-the-art techniques for learning\npolynomial features, and deliver significantly more parsimonious models.\n", "contributors": [{"name": "Yang, Jiyan", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Jiyan", "email": ""}, {"name": "Gittens, Alex", "sameAs": [], "familyName": "Gittens", "additionalName": "", "givenName": "Alex", "email": ""}], "title": "Tensor machines for learning target-specific polynomial features", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01697", "oai:arXiv.org:1504.01697"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Recent years have demonstrated that using random feature maps can\nsignificantly decrease the training and testing times of kernel-based\nalgorithms without significantly lowering their accuracy. Regrettably, because\nrandom features are target-agnostic, typically thousands of such features are\nnecessary to achieve acceptable accuracies. In this work, we consider the\nproblem of learning a small number of explicit polynomial features. Our\napproach, named Tensor Machines, finds a parsimonious set of features by\noptimizing over the hypothesis class introduced by Kar and Karnick for random\nfeature maps in a target-specific manner. Exploiting a natural connection\nbetween polynomials and tensors, we provide bounds on the generalization error\nof Tensor Machines. Empirically, Tensor Machines behave favorably on several\nreal-world datasets compared to other state-of-the-art techniques for learning\npolynomial features, and deliver significantly more parsimonious models.\n", "Comment: 19 pages, 4 color figures, 2 tables. Submitted to ECML 2015"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01697"}}, {"publisher": {"name": ""}, "description": "  We present a metamodel for modeling control and data flows on subclass scales\nin object-oriented systems. UML Profiles were used as a representation mean and\na complete metamodel definition was provided with an example of a diagram\napplication.\n", "contributors": [{"name": "Reshytko, Alexander", "sameAs": [], "familyName": "Reshytko", "additionalName": "", "givenName": "Alexander", "email": ""}], "title": "The OCDF diagram. A metamodel for object-oriented systems visual design", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3947", "oai:arXiv.org:1412.3947"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We present a metamodel for modeling control and data flows on subclass scales\nin object-oriented systems. UML Profiles were used as a representation mean and\na complete metamodel definition was provided with an example of a diagram\napplication.\n"}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2014-12-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3947"}}, {"publisher": {"name": ""}, "description": "The following is a discussion between two distinguished comparative literature scholars, David Damrosch and Gayatri Chakravorty Spivak. This is a transcription of their dialogue, delivered orally before a large audience at the 2011 American Comparative Literature Conference in Vancouver, Canada, on 2 April. It has been lightly edited to remove the natural redundancy inherent to oral communication, to eliminate asides regarding technical aspects of the presentation, and to fill in gaps in the recording process, which left inaudible portions. They were introduced by then-president of the ACLA, Haun Saussy. (Biographical data on Damrosch and Spivak can be found in the \u201cContributors\u201d section at the end of this journal.)", "contributors": [{"name": "Damrosch, David", "sameAs": [], "familyName": "Damrosch", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Spivak, Gayatri C.", "sameAs": [], "familyName": "Spivak", "additionalName": "C.", "givenName": "Gayatri", "email": ""}], "title": "Comparative Literature/World Literature: A Discussion with Gayatri Chakravorty Spivak and David Damrosch", "shareProperties": {"source": "columbia"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011"}}, {"name": "identifier", "properties": {"identifier": ["http://dx.doi.org/10.7916/D8VX0FCD", "academiccommons.columbia.edu/ac:184261"]}}, {"name": "setSpec", "properties": {"setSpec": []}}], "languages": [null], "subjects": ["comparative literature"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://dx.doi.org/10.7916/D8VX0FCD"}}, {"publisher": {"name": ""}, "description": "  In this study we show that by the current state-of-the-art synthetically\ngenerated fingerprints can easily be discriminated from real fingerprints. We\npropose a method based on second order extended minutiae histograms (MHs) which\ncan distinguish between real and synthetic prints with very high accuracy. MHs\nprovide a fixed-length feature vector for a fingerprint which are invariant\nunder rotation and translation. This 'test of realness' can be applied to\nsynthetic fingerprints produced by any method. In this work, tests are\nconducted on the 12 publicly available databases of FVC2000, FVC2002 and\nFVC2004 which are well established benchmarks for evaluating the performance of\nfingerprint recognition algorithms; 3 of these 12 databases consist of\nartificial fingerprints generated by the SFinGe software. Additionally, we\nevaluate the discriminative performance on a database of synthetic fingerprints\ngenerated by the software of Bicz versus real fingerprint images. We conclude\nwith suggestions for the improvement of synthetic fingerprint generation.\n", "contributors": [{"name": "Gottschlich, Carsten", "sameAs": [], "familyName": "Gottschlich", "additionalName": "", "givenName": "Carsten", "email": ""}, {"name": "Huckemann, Stephan", "sameAs": [], "familyName": "Huckemann", "additionalName": "", "givenName": "Stephan", "email": ""}], "title": "Separating the Real from the Synthetic: Minutiae Histograms as\n  Fingerprints of Fingerprints", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-04-19", "2014-10-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1304.5409", "IET Biometrics, vol. 3, no. 4, pp. 291-301, Dec. 2014", "doi:10.1049/iet-bmt.2013.0065", "oai:arXiv.org:1304.5409"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this study we show that by the current state-of-the-art synthetically\ngenerated fingerprints can easily be discriminated from real fingerprints. We\npropose a method based on second order extended minutiae histograms (MHs) which\ncan distinguish between real and synthetic prints with very high accuracy. MHs\nprovide a fixed-length feature vector for a fingerprint which are invariant\nunder rotation and translation. This 'test of realness' can be applied to\nsynthetic fingerprints produced by any method. In this work, tests are\nconducted on the 12 publicly available databases of FVC2000, FVC2002 and\nFVC2004 which are well established benchmarks for evaluating the performance of\nfingerprint recognition algorithms; 3 of these 12 databases consist of\nartificial fingerprints generated by the SFinGe software. Additionally, we\nevaluate the discriminative performance on a database of synthetic fingerprints\ngenerated by the software of Bicz versus real fingerprint images. We conclude\nwith suggestions for the improvement of synthetic fingerprint generation.\n"}}], "languages": [null], "subjects": ["computer science - databases", "computer science - artificial intelligence", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1304.5409"}}, {"publisher": {"name": ""}, "description": "  Head Mounted Displays (HMDs) allow users to experience virtual reality with a\ngreat level of immersion. However, even simple physical tasks like drinking a\nbeverage can be difficult and awkward while in a virtual reality experience. We\nexplore mixed reality renderings that selectively incorporate the physical\nworld into the virtual world for interactions with physical objects. We\nconducted a user study comparing four rendering techniques that balances\nimmersion in a virtual world with ease of interaction with the physical world.\nFinally, we discuss the pros and cons of each approach, suggesting guidelines\nfor future rendering techniques that bring physical objects into virtual\nreality.\n", "contributors": [{"name": "Budhiraja, Pulkit", "sameAs": [], "familyName": "Budhiraja", "additionalName": "", "givenName": "Pulkit", "email": ""}, {"name": "Sodhi, Rajinder", "sameAs": [], "familyName": "Sodhi", "additionalName": "", "givenName": "Rajinder", "email": ""}, {"name": "Jones, Brett", "sameAs": [], "familyName": "Jones", "additionalName": "", "givenName": "Brett", "email": ""}, {"name": "Karsch, Kevin", "sameAs": [], "familyName": "Karsch", "additionalName": "", "givenName": "Kevin", "email": ""}, {"name": "Bailey, Brian", "sameAs": [], "familyName": "Bailey", "additionalName": "", "givenName": "Brian", "email": ""}, {"name": "Forsyth, David", "sameAs": [], "familyName": "Forsyth", "additionalName": "", "givenName": "David", "email": ""}], "title": "Where's My Drink? Enabling Peripheral Real World Interactions While\n  Using HMDs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04744", "oai:arXiv.org:1502.04744"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Head Mounted Displays (HMDs) allow users to experience virtual reality with a\ngreat level of immersion. However, even simple physical tasks like drinking a\nbeverage can be difficult and awkward while in a virtual reality experience. We\nexplore mixed reality renderings that selectively incorporate the physical\nworld into the virtual world for interactions with physical objects. We\nconducted a user study comparing four rendering techniques that balances\nimmersion in a virtual world with ease of interaction with the physical world.\nFinally, we discuss the pros and cons of each approach, suggesting guidelines\nfor future rendering techniques that bring physical objects into virtual\nreality.\n"}}], "languages": [null], "subjects": ["computer science - human-computer interaction"], "providerUpdatedDateTime": "2015-02-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04744"}}, {"publisher": {"name": ""}, "description": "  Although random sequences can be used to generate probability events, they\ncome with the risk of cheating in an unsupervised situation. In such cases, the\noblivious transfer protocol may be used and this paper presents a variation to\nthe DH key-exchange to serve as this protocol. A method to verify the\ncorrectness of the procedure, without revealing the random numbers used by the\ntwo parties, is also proposed.\n", "contributors": [{"name": "Kak, Subhash", "sameAs": [], "familyName": "Kak", "additionalName": "", "givenName": "Subhash", "email": ""}], "title": "Oblivious Transfer Protocol with Verification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.00601", "oai:arXiv.org:1504.00601"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Although random sequences can be used to generate probability events, they\ncome with the risk of cheating in an unsupervised situation. In such cases, the\noblivious transfer protocol may be used and this paper presents a variation to\nthe DH key-exchange to serve as this protocol. A method to verify the\ncorrectness of the procedure, without revealing the random numbers used by the\ntwo parties, is also proposed.\n", "Comment: 7 pages, 2 figures"]}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-04-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.00601"}}, {"publisher": {"name": ""}, "description": "  An effective procedure to determine the optimal parameters appearing in\nartificial flockings is proposed in terms of optimization problems. We\nnumerically examine genetic algorithms (GAs) to determine the optimal set of\nparameters such as the weights for three essential interactions in BOIDS by\nReynolds (1987) under `zero-collision' and `no-breaking-up' constraints. As a\nfitness function (the energy function) to be maximized by the GA, we choose the\nso-called the $\\gamma$-value of anisotropy which can be observed empirically in\ntypical flocks of starling. We confirm that the GA successfully finds the\nsolution having a large $\\gamma$-value leading-up to a strong anisotropy. The\nnumerical experience shows that the procedure might enable us to make more\nrealistic and efficient artificial flocking of starling even in our personal\ncomputers. We also evaluate two distinct types of interactions in agents,\nnamely, metric and topological definitions of interactions. We confirmed that\nthe topological definition can explain the empirical evidence much better than\nthe metric definition does.\n", "contributors": [{"name": "Makiguchi, Motohiro", "sameAs": [], "familyName": "Makiguchi", "additionalName": "", "givenName": "Motohiro", "email": ""}, {"name": "Inoue, Jun-ichi", "sameAs": [], "familyName": "Inoue", "additionalName": "", "givenName": "Jun-ichi", "email": ""}], "title": "Optimization of artificial flockings by means of anisotropy measurements", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-11-01", "2011-05-09"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1011.0362", "oai:arXiv.org:1011.0362"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:nlin", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  An effective procedure to determine the optimal parameters appearing in\nartificial flockings is proposed in terms of optimization problems. We\nnumerically examine genetic algorithms (GAs) to determine the optimal set of\nparameters such as the weights for three essential interactions in BOIDS by\nReynolds (1987) under `zero-collision' and `no-breaking-up' constraints. As a\nfitness function (the energy function) to be maximized by the GA, we choose the\nso-called the $\\gamma$-value of anisotropy which can be observed empirically in\ntypical flocks of starling. We confirm that the GA successfully finds the\nsolution having a large $\\gamma$-value leading-up to a strong anisotropy. The\nnumerical experience shows that the procedure might enable us to make more\nrealistic and efficient artificial flocking of starling even in our personal\ncomputers. We also evaluate two distinct types of interactions in agents,\nnamely, metric and topological definitions of interactions. We confirmed that\nthe topological definition can explain the empirical evidence much better than\nthe metric definition does.\n", "Comment: 41 pages, 28 figures, using elsart.cls"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "nonlinear sciences - adaptation and self-organizing systems", "physics - biological physics"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1011.0362"}}, {"publisher": {"name": ""}, "description": "  In previous work of the authors it is shown that various moduli spaces of\nsheaves can be related by a finite number of Thaddeus-flips. We build on this\nby giving a framework that makes it possible to identify the intermediate\nspaces that appear in these Thaddeus-flips as certain moduli spaces of sheaves.\nMore precisely, these intermediate spaces are moduli spaces of sheaves that are\nsemistable with respect to a generalised notion of Gieseker-stability that\ndepends on several polarisations and also on a choice of twistings. We show\nthat this framework applies to any two polarisations on a surface, recovering\nresults of Matsuki-Wentworth, and also to generic pairs of polarisations on\nthreefolds.\n", "contributors": [{"name": "Greb, Daniel", "sameAs": [], "familyName": "Greb", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Ross, Julius", "sameAs": [], "familyName": "Ross", "additionalName": "", "givenName": "Julius", "email": ""}, {"name": "Toma, Matei", "sameAs": [], "familyName": "Toma", "additionalName": "", "givenName": "Matei", "email": ""}], "title": "Variation of Gieseker Moduli Spaces via Quiver GIT, II", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04440", "oai:arXiv.org:1501.04440"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  In previous work of the authors it is shown that various moduli spaces of\nsheaves can be related by a finite number of Thaddeus-flips. We build on this\nby giving a framework that makes it possible to identify the intermediate\nspaces that appear in these Thaddeus-flips as certain moduli spaces of sheaves.\nMore precisely, these intermediate spaces are moduli spaces of sheaves that are\nsemistable with respect to a generalised notion of Gieseker-stability that\ndepends on several polarisations and also on a choice of twistings. We show\nthat this framework applies to any two polarisations on a surface, recovering\nresults of Matsuki-Wentworth, and also to generic pairs of polarisations on\nthreefolds.\n", "Comment: 37 pages"]}}], "languages": [null], "subjects": ["16g20", "mathematics - complex variables", "14j60", "14d20", "mathematics - differential geometry", "mathematics - algebraic geometry", "14l24", "32g13"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04440"}}, {"publisher": {"name": ""}, "description": "  In the study of networks, it is often insightful to use algorithms to\ndetermine mesoscale features such as \"community structure\", in which densely\nconnected sets of nodes constitute \"communities\" that have sparse connections\nto other communities. The most popular way of detecting communities\nalgorithmically is to optimize the quality function known as modularity. When\noptimizing modularity, one compares the actual connections in a (static or\ntime-dependent) network to the connections obtained from a random-graph\nensemble that acts as a null model. The communities are then the sets of nodes\nthat are connected to each other densely relative to what is expected from the\nnull model. Clearly, the process of community detection depends fundamentally\non the choice of null model, so it is important to develop and analyze novel\nnull models that take into account appropriate features of the system under\nstudy. In this paper, we investigate the effects of using null models that take\nincorporate spatial information, and we propose a novel null model based on the\nradiation model of population spread. We also develop novel synthetic spatial\nbenchmark networks in which the connections between entities are based on\ndistance or flux between nodes, and we compare the performance of both static\nand time-dependent radiation null models to the standard (\"Newman-Girvan\") null\nmodel for modularity optimization and a recently-proposed gravity null model.\nIn our comparisons, we use both the above synthetic benchmarks and\ntime-dependent correlation networks that we construct using countrywide dengue\nfever incidence data for Peru. We also evaluate a recently-proposed correlation\nnull model, which was developed specifically for correlation networks that are\nconstructed from time series, on the epidemic-correlation data.\n", "contributors": [{"name": "Sarzynska, Marta", "sameAs": [], "familyName": "Sarzynska", "additionalName": "", "givenName": "Marta", "email": ""}, {"name": "Leicht, Elizabeth A.", "sameAs": [], "familyName": "Leicht", "additionalName": "A.", "givenName": "Elizabeth", "email": ""}, {"name": "Chowell, Gerardo", "sameAs": [], "familyName": "Chowell", "additionalName": "", "givenName": "Gerardo", "email": ""}, {"name": "Porter, Mason A.", "sameAs": [], "familyName": "Porter", "additionalName": "A.", "givenName": "Mason", "email": ""}], "title": "Null Models for Community Detection in Spatially-Embedded, Temporal\n  Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-23", "2015-01-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.6297", "oai:arXiv.org:1407.6297"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:nlin", "physics:physics", "q-bio"]}}, {"name": "description", "properties": {"description": "  In the study of networks, it is often insightful to use algorithms to\ndetermine mesoscale features such as \"community structure\", in which densely\nconnected sets of nodes constitute \"communities\" that have sparse connections\nto other communities. The most popular way of detecting communities\nalgorithmically is to optimize the quality function known as modularity. When\noptimizing modularity, one compares the actual connections in a (static or\ntime-dependent) network to the connections obtained from a random-graph\nensemble that acts as a null model. The communities are then the sets of nodes\nthat are connected to each other densely relative to what is expected from the\nnull model. Clearly, the process of community detection depends fundamentally\non the choice of null model, so it is important to develop and analyze novel\nnull models that take into account appropriate features of the system under\nstudy. In this paper, we investigate the effects of using null models that take\nincorporate spatial information, and we propose a novel null model based on the\nradiation model of population spread. We also develop novel synthetic spatial\nbenchmark networks in which the connections between entities are based on\ndistance or flux between nodes, and we compare the performance of both static\nand time-dependent radiation null models to the standard (\"Newman-Girvan\") null\nmodel for modularity optimization and a recently-proposed gravity null model.\nIn our comparisons, we use both the above synthetic benchmarks and\ntime-dependent correlation networks that we construct using countrywide dengue\nfever incidence data for Peru. We also evaluate a recently-proposed correlation\nnull model, which was developed specifically for correlation networks that are\nconstructed from time series, on the epidemic-correlation data.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "quantitative biology - populations and evolution", "physics - biological physics", "nonlinear sciences - adaptation and self-organizing systems", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.6297"}}, {"publisher": {"name": ""}, "description": "  A motif-network search scheme is proposed to study the crystal structures of\nthe dilithium/disodium transition metal orthosilicates A2MSiO4. Using this fast\nand efficient method, the structures of all six combinations with A = Li or Na\nand M = Mn, Fe or Co were extensively explored. In addition to finding all\npreviously reported structures, we discovered many other different crystal\nstructures which are highly degenerate in energy. These\ntetrahedral-network-based structures can be classified into 1D, 2D and 3D types\nbased on M-Si-O frames. A clear trend of the structural preference in different\nsystems was revealed and possible indicators that affect the structure\nstabilities were introduced. For the case of Na systems which have been much\nless investigated in the literature relative to the Li systems, we predicted\ntheir ground state structures and found evidence for the existence of new\nstructural motifs.\n", "contributors": [{"name": "Zhao, Xin", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Xin", "email": ""}, {"name": "Wu, Shunqing", "sameAs": [], "familyName": "Wu", "additionalName": "", "givenName": "Shunqing", "email": ""}, {"name": "Lv, Xiaobao", "sameAs": [], "familyName": "Lv", "additionalName": "", "givenName": "Xiaobao", "email": ""}, {"name": "Nguyen, Manh Cuong", "sameAs": [], "familyName": "Nguyen", "additionalName": "Cuong", "givenName": "Manh", "email": ""}, {"name": "Wang, Cai-Zhuang", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Cai-Zhuang", "email": ""}, {"name": "Lin, Zijing", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Zijing", "email": ""}, {"name": "Zhu, Zi-Zhong", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "Zi-Zhong", "email": ""}, {"name": "Ho, Kai-Ming", "sameAs": [], "familyName": "Ho", "additionalName": "", "givenName": "Kai-Ming", "email": ""}], "title": "Fast motif-network scheme for extensive exploration of complex crystal\n  structures in silicate cathodes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.02070", "oai:arXiv.org:1504.02070"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  A motif-network search scheme is proposed to study the crystal structures of\nthe dilithium/disodium transition metal orthosilicates A2MSiO4. Using this fast\nand efficient method, the structures of all six combinations with A = Li or Na\nand M = Mn, Fe or Co were extensively explored. In addition to finding all\npreviously reported structures, we discovered many other different crystal\nstructures which are highly degenerate in energy. These\ntetrahedral-network-based structures can be classified into 1D, 2D and 3D types\nbased on M-Si-O frames. A clear trend of the structural preference in different\nsystems was revealed and possible indicators that affect the structure\nstabilities were introduced. For the case of Na systems which have been much\nless investigated in the literature relative to the Li systems, we predicted\ntheir ground state structures and found evidence for the existence of new\nstructural motifs.\n", "Comment: 19 pages, 7 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "condensed matter - materials science"], "providerUpdatedDateTime": "2015-04-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.02070"}}, {"publisher": {"name": ""}, "description": "  A Fortran 90 module (GammaCHI) for computing and inverting the gamma and\nchi-square cumulative distribution functions (central and noncentral) is\npresented. The main novelty of this package are the reliable and accurate\ninversion routines for the noncentral cumulative distribution functions.\nAdditionally, the package also provides routines for computing the gamma\nfunction, the error function and other functions related to the gamma function.\nThe module includes the routines cdfgamC, invcdfgamC, cdfgamNC, invcdfgamNC,\nerrorfunction, inverfc, gamma, loggam, gamstar and quotgamm for the computation\nof the central gamma distribution function (and its complementary function),\nthe inversion of the central gamma distribution function, the computation of\nthe noncentral gamma distribution function (and its complementary function),\nthe inversion of the noncentral gamma distribution function, the computation of\nthe error function and its complementary function, the inversion of the\ncomplementary error function, the computation of: the gamma function, the\nlogarithm of the gamma function, the regulated gamma function and the ratio of\ntwo gamma functions, respectively.\n", "contributors": [{"name": "Gil, A.", "sameAs": [], "familyName": "Gil", "additionalName": "", "givenName": "A.", "email": ""}, {"name": "Segura, J.", "sameAs": [], "familyName": "Segura", "additionalName": "", "givenName": "J.", "email": ""}, {"name": "Temme, N. M.", "sameAs": [], "familyName": "Temme", "additionalName": "M.", "givenName": "N.", "email": ""}], "title": "GammaCHI: a package for the inversion and computation of the gamma and\n  chi-square cumulative distribution functions (central and noncentral)", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.01578", "oai:arXiv.org:1501.01578"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A Fortran 90 module (GammaCHI) for computing and inverting the gamma and\nchi-square cumulative distribution functions (central and noncentral) is\npresented. The main novelty of this package are the reliable and accurate\ninversion routines for the noncentral cumulative distribution functions.\nAdditionally, the package also provides routines for computing the gamma\nfunction, the error function and other functions related to the gamma function.\nThe module includes the routines cdfgamC, invcdfgamC, cdfgamNC, invcdfgamNC,\nerrorfunction, inverfc, gamma, loggam, gamstar and quotgamm for the computation\nof the central gamma distribution function (and its complementary function),\nthe inversion of the central gamma distribution function, the computation of\nthe noncentral gamma distribution function (and its complementary function),\nthe inversion of the noncentral gamma distribution function, the computation of\nthe error function and its complementary function, the inversion of the\ncomplementary error function, the computation of: the gamma function, the\nlogarithm of the gamma function, the regulated gamma function and the ratio of\ntwo gamma functions, respectively.\n", "Comment: To appear in Computer Physics Communications"]}}], "languages": [null], "subjects": ["mathematics - numerical analysis", "computer science - mathematical software", "mathematics - classical analysis and odes"], "providerUpdatedDateTime": "2015-01-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.01578"}}, {"publisher": {"name": ""}, "description": "  Evolutionary algorithms (EAs) are heuristic algorithms inspired by natural\nevolution. They are often used to obtain satisficing solutions in practice. In\nthis paper, we investigate a largely underexplored issue: the approximation\nperformance of EAs in terms of how close the solution obtained is to an optimal\nsolution. We study an EA framework named simple EA with isolated population\n(SEIP) that can be implemented as a single- or multi-objective EA. We analyze\nthe approximation performance of SEIP using the partial ratio, which\ncharacterizes the approximation ratio that can be guaranteed. Specifically, we\nanalyze SEIP using a set cover problem that is NP-hard. We find that in a\nsimple configuration, SEIP efficiently achieves an $H_n$-approximation ratio,\nthe asymptotic lower bound, for the unbounded set cover problem. We also find\nthat SEIP efficiently achieves an $(H_k-\\frac{k-1}/{8k^9})$-approximation\nratio, the currently best-achievable result, for the k-set cover problem.\nMoreover, for an instance class of the k-set cover problem, we disclose how\nSEIP, using either one-bit or bit-wise mutation, can overcome the difficulty\nthat limits the greedy algorithm.\n", "contributors": [{"name": "Yu, Yang", "sameAs": [], "familyName": "Yu", "additionalName": "", "givenName": "Yang", "email": ""}, {"name": "Yao, Xin", "sameAs": [], "familyName": "Yao", "additionalName": "", "givenName": "Xin", "email": ""}, {"name": "Zhou, Zhi-Hua", "sameAs": [], "familyName": "Zhou", "additionalName": "", "givenName": "Zhi-Hua", "email": ""}], "title": "On the approximation ability of evolutionary optimization with\n  application to minimum set cover", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-11-17", "2012-01-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1011.4028", "doi:10.1016/j.artint.2012.01.001", "oai:arXiv.org:1011.4028"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Evolutionary algorithms (EAs) are heuristic algorithms inspired by natural\nevolution. They are often used to obtain satisficing solutions in practice. In\nthis paper, we investigate a largely underexplored issue: the approximation\nperformance of EAs in terms of how close the solution obtained is to an optimal\nsolution. We study an EA framework named simple EA with isolated population\n(SEIP) that can be implemented as a single- or multi-objective EA. We analyze\nthe approximation performance of SEIP using the partial ratio, which\ncharacterizes the approximation ratio that can be guaranteed. Specifically, we\nanalyze SEIP using a set cover problem that is NP-hard. We find that in a\nsimple configuration, SEIP efficiently achieves an $H_n$-approximation ratio,\nthe asymptotic lower bound, for the unbounded set cover problem. We also find\nthat SEIP efficiently achieves an $(H_k-\\frac{k-1}/{8k^9})$-approximation\nratio, the currently best-achievable result, for the k-set cover problem.\nMoreover, for an instance class of the k-set cover problem, we disclose how\nSEIP, using either one-bit or bit-wise mutation, can overcome the difficulty\nthat limits the greedy algorithm.\n"}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1011.4028"}}, {"publisher": {"name": ""}, "description": "  In this paper, we review and extend a family of log-det divergences for\nsymmetric positive definite (SPD) matrices and discuss their fundamental\nproperties. We show how to generate from parameterized Alpha-Beta (AB) and\nGamma Log-det divergences many well known divergences, for example, the Stein's\nloss, S-divergence, called also Jensen-Bregman LogDet (JBLD) divergence, the\nLogdet Zero (Bhattacharryya) divergence, Affine Invariant Riemannian Metric\n(AIRM) as well as some new divergences. Moreover, we establish links and\ncorrespondences among many log-det divergences and display them on alpha-beta\nplain for various set of parameters. Furthermore, this paper bridges these\ndivergences and shows also their links to divergences of multivariate and\nmultiway Gaussian distributions. Closed form formulas are derived for gamma\ndivergences of two multivariate Gaussian densities including as special cases\nthe Kullback-Leibler, Bhattacharryya, R\\'enyi and Cauchy-Schwartz divergences.\nSymmetrized versions of the log-det divergences are also discussed and\nreviewed. A class of divergences is extended to multiway divergences for\nseparable covariance (precision) matrices.\n", "contributors": [{"name": "Cichocki, Andrzej", "sameAs": [], "familyName": "Cichocki", "additionalName": "", "givenName": "Andrzej", "email": ""}, {"name": "Cruces, Sergio", "sameAs": [], "familyName": "Cruces", "additionalName": "", "givenName": "Sergio", "email": ""}, {"name": "Amari, Shun-Ichi", "sameAs": [], "familyName": "Amari", "additionalName": "", "givenName": "Shun-Ichi", "email": ""}], "title": "Log-Determinant Divergences Revisited: Alpha--Beta and Gamma Log-Det\n  Divergences", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7146", "oai:arXiv.org:1412.7146"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  In this paper, we review and extend a family of log-det divergences for\nsymmetric positive definite (SPD) matrices and discuss their fundamental\nproperties. We show how to generate from parameterized Alpha-Beta (AB) and\nGamma Log-det divergences many well known divergences, for example, the Stein's\nloss, S-divergence, called also Jensen-Bregman LogDet (JBLD) divergence, the\nLogdet Zero (Bhattacharryya) divergence, Affine Invariant Riemannian Metric\n(AIRM) as well as some new divergences. Moreover, we establish links and\ncorrespondences among many log-det divergences and display them on alpha-beta\nplain for various set of parameters. Furthermore, this paper bridges these\ndivergences and shows also their links to divergences of multivariate and\nmultiway Gaussian distributions. Closed form formulas are derived for gamma\ndivergences of two multivariate Gaussian densities including as special cases\nthe Kullback-Leibler, Bhattacharryya, R\\'enyi and Cauchy-Schwartz divergences.\nSymmetrized versions of the log-det divergences are also discussed and\nreviewed. A class of divergences is extended to multiway divergences for\nseparable covariance (precision) matrices.\n", "Comment: 36 pages, 4 figures"]}}], "languages": [null], "subjects": ["statistics - computation", "computer science - information theory"], "providerUpdatedDateTime": "2014-12-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7146"}}, {"publisher": {"name": ""}, "description": "  In Part I \\cite{Zhao13TSPasync1}, we introduced a fairly general model for\nasynchronous events over adaptive networks including random topologies, random\nlink failures, random data arrival times, and agents turning on and off\nrandomly. We performed a stability analysis and established the notable fact\nthat the network is still able to converge in the mean-square-error sense to\nthe desired solution. Once stable behavior is guaranteed, it becomes important\nto evaluate how fast the iterates converge and how close they get to the\noptimal solution. This is a demanding task due to the various asynchronous\nevents and due to the fact that agents influence each other. In this Part II,\nwe carry out a detailed analysis of the mean-square-error performance of\nasynchronous strategies for solving distributed optimization and adaptation\nproblems over networks. We derive analytical expressions for the mean-square\nconvergence rate and the steady-state mean-square-deviation. The expressions\nreveal how the various parameters of the asynchronous behavior influence\nnetwork performance. In the process, we establish the interesting conclusion\nthat even under the influence of asynchronous events, all agents in the\nadaptive network can still reach an $O(\\nu^{1 + \\gamma_o'})$ near-agreement\nwith some $\\gamma_o' > 0$ while approaching the desired solution within\n$O(\\nu)$ accuracy, where $\\nu$ is proportional to the small step-size parameter\nfor adaptation.\n", "contributors": [{"name": "Zhao, Xiaochuan", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Xiaochuan", "email": ""}, {"name": "Sayed, Ali H.", "sameAs": [], "familyName": "Sayed", "additionalName": "H.", "givenName": "Ali", "email": ""}], "title": "Asynchronous Adaptation and Learning over Networks - Part II:\n  Performance Analysis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-19", "2014-12-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.5438", "oai:arXiv.org:1312.5438"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In Part I \\cite{Zhao13TSPasync1}, we introduced a fairly general model for\nasynchronous events over adaptive networks including random topologies, random\nlink failures, random data arrival times, and agents turning on and off\nrandomly. We performed a stability analysis and established the notable fact\nthat the network is still able to converge in the mean-square-error sense to\nthe desired solution. Once stable behavior is guaranteed, it becomes important\nto evaluate how fast the iterates converge and how close they get to the\noptimal solution. This is a demanding task due to the various asynchronous\nevents and due to the fact that agents influence each other. In this Part II,\nwe carry out a detailed analysis of the mean-square-error performance of\nasynchronous strategies for solving distributed optimization and adaptation\nproblems over networks. We derive analytical expressions for the mean-square\nconvergence rate and the steady-state mean-square-deviation. The expressions\nreveal how the various parameters of the asynchronous behavior influence\nnetwork performance. In the process, we establish the interesting conclusion\nthat even under the influence of asynchronous events, all agents in the\nadaptive network can still reach an $O(\\nu^{1 + \\gamma_o'})$ near-agreement\nwith some $\\gamma_o' > 0$ while approaching the desired solution within\n$O(\\nu)$ accuracy, where $\\nu$ is proportional to the small step-size parameter\nfor adaptation.\n", "Comment: 43 pages, 5 figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "computer science - information theory", "computer science - learning"], "providerUpdatedDateTime": "2014-12-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.5438"}}, {"publisher": {"name": ""}, "description": "  We consider the signatures $\\Sigma_m=(0,1,-,+, \\cdot, \\ ^{-1})$ of meadows\nand $(\\Sigma_m, {\\mathbf s})$ of signed meadows. We give two complete\naxiomatizations of the equational theories of the real numbers with respect to\nthese signatures. In the first case, we extend the axiomatization of\nzero-totalized fields by a single axiom scheme expressing formal realness; the\nsecond axiomatization presupposes an ordering. We apply these completeness\nresults in order to obtain complete axiomatizations of the complex numbers.\n", "contributors": [{"name": "Bergstra, Jan A.", "sameAs": [], "familyName": "Bergstra", "additionalName": "A.", "givenName": "Jan", "email": ""}, {"name": "Bethke, Inge", "sameAs": [], "familyName": "Bethke", "additionalName": "", "givenName": "Inge", "email": ""}, {"name": "Ponse, Alban", "sameAs": [], "familyName": "Ponse", "additionalName": "", "givenName": "Alban", "email": ""}], "title": "Equations for formally real meadows", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-18", "2015-01-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.5011", "oai:arXiv.org:1310.5011"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider the signatures $\\Sigma_m=(0,1,-,+, \\cdot, \\ ^{-1})$ of meadows\nand $(\\Sigma_m, {\\mathbf s})$ of signed meadows. We give two complete\naxiomatizations of the equational theories of the real numbers with respect to\nthese signatures. In the first case, we extend the axiomatization of\nzero-totalized fields by a single axiom scheme expressing formal realness; the\nsecond axiomatization presupposes an ordering. We apply these completeness\nresults in order to obtain complete axiomatizations of the complex numbers.\n", "Comment: 24 pages, 14 tables, revised, new Theorem 3.7"]}}], "languages": [null], "subjects": ["mathematics - rings and algebras", "12d15", "computer science - logic in computer science"], "providerUpdatedDateTime": "2015-01-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.5011"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Recently a new dependence measure, the distance correlation, has been proposed to measure the dependence between continuous random variables. A nice property of this measure is that it can be consistently estimated with the empirical average of the products of certain distances between the sample points. Here we generalize this quantity to measure the conditional dependence between random variables, and show that this can also be estimated with a statistic using a weighted empirical average of the products of distances between the sample points. We demonstrate the applicability of the estimators with numerical experiments on real and simulated data sets.", "contributors": [{"name": "Poczos, Barnabas", "sameAs": [], "familyName": "Poczos", "additionalName": "", "givenName": "Barnabas", "email": ""}, {"name": "Schneider, Jeff", "sameAs": [], "familyName": "Schneider", "additionalName": "", "givenName": "Jeff", "email": ""}], "title": "Conditional Distance Variance and Correlation", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2012-01-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/93", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1090&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1090"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Recently a new dependence measure, the distance correlation, has been proposed to measure the dependence between continuous random variables. A nice property of this measure is that it can be consistently estimated with the empirical average of the products of certain distances between the sample points. Here we generalize this quantity to measure the conditional dependence between random variables, and show that this can also be estimated with a statistic using a weighted empirical average of the products of distances between the sample points. We demonstrate the applicability of the estimators with numerical experiments on real and simulated data sets."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-17T21:24:15", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/93"}}, {"publisher": {"name": ""}, "description": "  In this paper we present a numerical valuation of variable annuities with\ncombined Guaranteed Minimum Withdrawal Benefit (GMWB) and Guaranteed Minimum\nDeath Benefit (GMDB) under optimal policyholder behaviour solved as an optimal\nstochastic control problem. This product simultaneously deals with financial\nrisk, mortality risk and human behaviour. We assume that market is complete in\nfinancial risk and mortality risk is completely diversified by selling enough\npolicies and thus the annuity price can be expressed as appropriate\nexpectation. The computing engine employed to solve the optimal stochastic\ncontrol problem is based on a robust and efficient Gauss-Hermite quadrature\nmethod with cubic spline. We present results for three different types of death\nbenefit and show that, under the optimal policyholder behaviour, adding the\npremium for the death benefit on top of the GMWB can be problematic for\ncontracts with long maturities if the continuous fee structure is kept, which\nis ordinarily assumed for a GMWB contract. In fact for some long maturities it\ncan be shown that the fee cannot be charged as any proportion of the account\nvalue -- there is no solution to match the initial premium with the fair\nannuity price. On the other hand, the extra fee due to adding the death benefit\ncan be charged upfront or in periodic instalment of fixed amount, and it is\ncheaper than buying a separate life insurance.\n", "contributors": [{"name": "Luo, Xiaolin", "sameAs": [], "familyName": "Luo", "additionalName": "", "givenName": "Xiaolin", "email": ""}, {"name": "Shevchenko, Pavel V.", "sameAs": [], "familyName": "Shevchenko", "additionalName": "V.", "givenName": "Pavel", "email": ""}], "title": "Valuation of Variable Annuities with Guaranteed Minimum Withdrawal and\n  Death Benefits via Stochastic Control Optimization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-20", "2015-04-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5453", "oai:arXiv.org:1411.5453"]}}, {"name": "setSpec", "properties": {"setSpec": "q-fin"}}, {"name": "description", "properties": {"description": ["  In this paper we present a numerical valuation of variable annuities with\ncombined Guaranteed Minimum Withdrawal Benefit (GMWB) and Guaranteed Minimum\nDeath Benefit (GMDB) under optimal policyholder behaviour solved as an optimal\nstochastic control problem. This product simultaneously deals with financial\nrisk, mortality risk and human behaviour. We assume that market is complete in\nfinancial risk and mortality risk is completely diversified by selling enough\npolicies and thus the annuity price can be expressed as appropriate\nexpectation. The computing engine employed to solve the optimal stochastic\ncontrol problem is based on a robust and efficient Gauss-Hermite quadrature\nmethod with cubic spline. We present results for three different types of death\nbenefit and show that, under the optimal policyholder behaviour, adding the\npremium for the death benefit on top of the GMWB can be problematic for\ncontracts with long maturities if the continuous fee structure is kept, which\nis ordinarily assumed for a GMWB contract. In fact for some long maturities it\ncan be shown that the fee cannot be charged as any proportion of the account\nvalue -- there is no solution to match the initial premium with the fair\nannuity price. On the other hand, the extra fee due to adding the death benefit\ncan be charged upfront or in periodic instalment of fixed amount, and it is\ncheaper than buying a separate life insurance.\n", "Comment: arXiv admin note: substantial text overlap with arXiv:1410.8609"]}}], "languages": [null], "subjects": ["quantitative finance - computational finance"], "providerUpdatedDateTime": "2015-04-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5453"}}, {"publisher": {"name": ""}, "description": "  We present a high-rate $(n,k,d=n-1)$-MSR code with a sub-packetization level\nthat is polynomial in the dimension $k$ of the code. While polynomial\nsub-packetization level was achieved earlier for vector MDS codes that repair\nsystematic nodes optimally, no such MSR code construction is known. In the\nlow-rate regime (i. e., rates less than one-half), MSR code constructions with\na linear sub-packetization level are available. But in the high-rate regime (i.\ne., rates greater than one-half), the known MSR code constructions required a\nsub-packetization level that is exponential in $k$. In the present paper, we\nconstruct an MSR code for $d=n-1$ with a fixed rate $R=\\frac{t-1}{t}, \\ t \\geq\n2,$ achieveing a sub-packetization level $\\alpha = O(k^t)$. The code allows\nhelp-by-transfer repair, i. e., no computations are needed at the helper nodes\nduring repair of a failed node.\n", "contributors": [{"name": "Sasidharan, Birenjith", "sameAs": [], "familyName": "Sasidharan", "additionalName": "", "givenName": "Birenjith", "email": ""}, {"name": "Agarwal, Gaurav Kumar", "sameAs": [], "familyName": "Agarwal", "additionalName": "Kumar", "givenName": "Gaurav", "email": ""}, {"name": "Kumar, P. Vijay", "sameAs": [], "familyName": "Kumar", "additionalName": "Vijay", "givenName": "P.", "email": ""}], "title": "A High-Rate MSR Code With Polynomial Sub-Packetization Level", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06662", "oai:arXiv.org:1501.06662"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We present a high-rate $(n,k,d=n-1)$-MSR code with a sub-packetization level\nthat is polynomial in the dimension $k$ of the code. While polynomial\nsub-packetization level was achieved earlier for vector MDS codes that repair\nsystematic nodes optimally, no such MSR code construction is known. In the\nlow-rate regime (i. e., rates less than one-half), MSR code constructions with\na linear sub-packetization level are available. But in the high-rate regime (i.\ne., rates greater than one-half), the known MSR code constructions required a\nsub-packetization level that is exponential in $k$. In the present paper, we\nconstruct an MSR code for $d=n-1$ with a fixed rate $R=\\frac{t-1}{t}, \\ t \\geq\n2,$ achieveing a sub-packetization level $\\alpha = O(k^t)$. The code allows\nhelp-by-transfer repair, i. e., no computations are needed at the helper nodes\nduring repair of a failed node.\n", "Comment: Submitted to ISIT 2015"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06662"}}, {"publisher": {"name": ""}, "description": "  In this article we introduce the network histogram: a statistical summary of\nnetwork interactions, to be used as a tool for exploratory data analysis. A\nnetwork histogram is obtained by fitting a stochastic blockmodel to a single\nobservation of a network dataset. Blocks of edges play the role of histogram\nbins, and community sizes that of histogram bandwidths or bin sizes. Just as\nstandard histograms allow for varying bandwidths, different blockmodel\nestimates can all be considered valid representations of an underlying\nprobability model, subject to bandwidth constraints. Here we provide methods\nfor automatic bandwidth selection, by which the network histogram approximates\nthe generating mechanism that gives rise to exchangeable random graphs. This\nmakes the blockmodel a universal network representation for unlabeled graphs.\nWith this insight, we discuss the interpretation of network communities in\nlight of the fact that many different community assignments can all give an\nequally valid representation of such a network. To demonstrate the\nfidelity-versus-interpretability tradeoff inherent in considering different\nnumbers and sizes of communities, we analyze two publicly available networks -\npolitical weblogs and student friendships - and discuss how to interpret the\nnetwork histogram when additional information related to node and edge labeling\nis present.\n", "contributors": [{"name": "Olhede, Sofia C.", "sameAs": [], "familyName": "Olhede", "additionalName": "C.", "givenName": "Sofia", "email": ""}, {"name": "Wolfe, Patrick J.", "sameAs": [], "familyName": "Wolfe", "additionalName": "J.", "givenName": "Patrick", "email": ""}], "title": "Network histograms and universality of blockmodel approximation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-18", "2014-09-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.5306", "Proceedings of the National Academy of Sciences of the USA 2014,\n  Vol. 111, No. 41, 14722-14727", "doi:10.1073/pnas.1400374111", "oai:arXiv.org:1312.5306"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  In this article we introduce the network histogram: a statistical summary of\nnetwork interactions, to be used as a tool for exploratory data analysis. A\nnetwork histogram is obtained by fitting a stochastic blockmodel to a single\nobservation of a network dataset. Blocks of edges play the role of histogram\nbins, and community sizes that of histogram bandwidths or bin sizes. Just as\nstandard histograms allow for varying bandwidths, different blockmodel\nestimates can all be considered valid representations of an underlying\nprobability model, subject to bandwidth constraints. Here we provide methods\nfor automatic bandwidth selection, by which the network histogram approximates\nthe generating mechanism that gives rise to exchangeable random graphs. This\nmakes the blockmodel a universal network representation for unlabeled graphs.\nWith this insight, we discuss the interpretation of network communities in\nlight of the fact that many different community assignments can all give an\nequally valid representation of such a network. To demonstrate the\nfidelity-versus-interpretability tradeoff inherent in considering different\nnumbers and sizes of communities, we analyze two publicly available networks -\npolitical weblogs and student friendships - and discuss how to interpret the\nnetwork histogram when additional information related to node and edge labeling\nis present.\n", "Comment: 27 pages, 4 figures; revised version with link to software"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "mathematics - combinatorics", "statistics - methodology", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-10-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.5306"}}, {"publisher": {"name": ""}, "description": "  The recently-discovered polar codes are seen as a major breakthrough in\ncoding theory; they provably achieve the theoretical capacity of discrete\nmemoryless channels using the low complexity successive cancellation (SC)\ndecoding algorithm. Motivated by recent developments in polar coding theory, we\npropose a family of efficient hardware implementations for SC polar decoders.\nWe show that such decoders can be implemented with O(n) processing elements,\nO(n) memory elements, and can provide a constant throughput for a given target\nclock frequency. Furthermore, we show that SC decoding can be implemented in\nthe logarithm domain, thereby eliminating costly multiplication and division\noperations and reducing the complexity of each processing element greatly. We\nalso present a detailed architecture for an SC decoder and provide logic\nsynthesis results confirming the linear growth in complexity of the decoder as\nthe code length increases.\n", "contributors": [{"name": "Leroux, Camille", "sameAs": [], "familyName": "Leroux", "additionalName": "", "givenName": "Camille", "email": ""}, {"name": "Raymond, Alexandre J.", "sameAs": [], "familyName": "Raymond", "additionalName": "J.", "givenName": "Alexandre", "email": ""}, {"name": "Sarkis, Gabi", "sameAs": [], "familyName": "Sarkis", "additionalName": "", "givenName": "Gabi", "email": ""}, {"name": "Tal, Ido", "sameAs": [], "familyName": "Tal", "additionalName": "", "givenName": "Ido", "email": ""}, {"name": "Vardy, Alexander", "sameAs": [], "familyName": "Vardy", "additionalName": "", "givenName": "Alexander", "email": ""}, {"name": "Gross, Warren J.", "sameAs": [], "familyName": "Gross", "additionalName": "J.", "givenName": "Warren", "email": ""}], "title": "Hardware Implementation of Successive Cancellation Decoders for Polar\n  Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-11-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.4362", "oai:arXiv.org:1111.4362"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  The recently-discovered polar codes are seen as a major breakthrough in\ncoding theory; they provably achieve the theoretical capacity of discrete\nmemoryless channels using the low complexity successive cancellation (SC)\ndecoding algorithm. Motivated by recent developments in polar coding theory, we\npropose a family of efficient hardware implementations for SC polar decoders.\nWe show that such decoders can be implemented with O(n) processing elements,\nO(n) memory elements, and can provide a constant throughput for a given target\nclock frequency. Furthermore, we show that SC decoding can be implemented in\nthe logarithm domain, thereby eliminating costly multiplication and division\noperations and reducing the complexity of each processing element greatly. We\nalso present a detailed architecture for an SC decoder and provide logic\nsynthesis results confirming the linear growth in complexity of the decoder as\nthe code length increases.\n"}}], "languages": [null], "subjects": ["computer science - hardware architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.4362"}}, {"publisher": {"name": ""}, "description": "  Many deep neural networks trained on natural images exhibit a curious\nphenomenon in common: on the first layer they learn features similar to Gabor\nfilters and color blobs. Such first-layer features appear not to be specific to\na particular dataset or task, but general in that they are applicable to many\ndatasets and tasks. Features must eventually transition from general to\nspecific by the last layer of the network, but this transition has not been\nstudied extensively. In this paper we experimentally quantify the generality\nversus specificity of neurons in each layer of a deep convolutional neural\nnetwork and report a few surprising results. Transferability is negatively\naffected by two distinct issues: (1) the specialization of higher layer neurons\nto their original task at the expense of performance on the target task, which\nwas expected, and (2) optimization difficulties related to splitting networks\nbetween co-adapted neurons, which was not expected. In an example network\ntrained on ImageNet, we demonstrate that either of these two issues may\ndominate, depending on whether features are transferred from the bottom,\nmiddle, or top of the network. We also document that the transferability of\nfeatures decreases as the distance between the base task and target task\nincreases, but that transferring features even from distant tasks can be better\nthan using random features. A final surprising result is that initializing a\nnetwork with transferred features from almost any number of layers can produce\na boost to generalization that lingers even after fine-tuning to the target\ndataset.\n", "contributors": [{"name": "Yosinski, Jason", "sameAs": [], "familyName": "Yosinski", "additionalName": "", "givenName": "Jason", "email": ""}, {"name": "Clune, Jeff", "sameAs": [], "familyName": "Clune", "additionalName": "", "givenName": "Jeff", "email": ""}, {"name": "Bengio, Yoshua", "sameAs": [], "familyName": "Bengio", "additionalName": "", "givenName": "Yoshua", "email": ""}, {"name": "Lipson, Hod", "sameAs": [], "familyName": "Lipson", "additionalName": "", "givenName": "Hod", "email": ""}], "title": "How transferable are features in deep neural networks?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1792", "oai:arXiv.org:1411.1792"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Many deep neural networks trained on natural images exhibit a curious\nphenomenon in common: on the first layer they learn features similar to Gabor\nfilters and color blobs. Such first-layer features appear not to be specific to\na particular dataset or task, but general in that they are applicable to many\ndatasets and tasks. Features must eventually transition from general to\nspecific by the last layer of the network, but this transition has not been\nstudied extensively. In this paper we experimentally quantify the generality\nversus specificity of neurons in each layer of a deep convolutional neural\nnetwork and report a few surprising results. Transferability is negatively\naffected by two distinct issues: (1) the specialization of higher layer neurons\nto their original task at the expense of performance on the target task, which\nwas expected, and (2) optimization difficulties related to splitting networks\nbetween co-adapted neurons, which was not expected. In an example network\ntrained on ImageNet, we demonstrate that either of these two issues may\ndominate, depending on whether features are transferred from the bottom,\nmiddle, or top of the network. We also document that the transferability of\nfeatures decreases as the distance between the base task and target task\nincreases, but that transferring features even from distant tasks can be better\nthan using random features. A final surprising result is that initializing a\nnetwork with transferred features from almost any number of layers can produce\na boost to generalization that lingers even after fine-tuning to the target\ndataset.\n", "Comment: To appear in Advances in Neural Information Processing Systems 27\n  (NIPS 2014)"]}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - learning"], "providerUpdatedDateTime": "2014-11-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1792"}}, {"publisher": {"name": ""}, "description": "  Network virtualization is an efficient approach of solving the ossification\nproblem of the Internet. It has become a promising way of supporting lots of\nheterogeneous network onto substrate physical network. A major challenge in\nnetwork virtualization is how to map multiple virtual networks onto specific\nnodes and links in the shared substrate network, known as virtual network\nembedding problem. Due to its NPhardness, many heuristic approaches have been\nproposed. In this thesis, we propose hybrid VN embedding algorithms that map\nmultiple VN requests with node and link constraints with K-core decomposition\nusing path splitting. Based on network pruning, a virtual network is decomposed\nto core network and edge network. The mapping process is divided into two\nphases: core network mapping and edge network mapping. Path splitting enables\nbetter resource utilization by allowing the substrate to accept more VN\nrequests. It splits the available bandwidth of the path into small bandwidth to\nsatisfy the resource constraints. The proposed algorithm improves the\nperformance of the algorithm by splitting the path into small bandwidth. Due to\npath splitting proposed algorithm will accept many virtual network requests\nthat will increase the revenue and acceptance ratio of the algorithm.\n", "contributors": [{"name": "Mishra, Neha", "sameAs": [], "familyName": "Mishra", "additionalName": "", "givenName": "Neha", "email": ""}], "title": "Hybrid Virtual network Embedding Algorithm with K-core Decomposition\n  using Path Splitting", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-20", "2014-11-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.5049", "oai:arXiv.org:1403.5049"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Network virtualization is an efficient approach of solving the ossification\nproblem of the Internet. It has become a promising way of supporting lots of\nheterogeneous network onto substrate physical network. A major challenge in\nnetwork virtualization is how to map multiple virtual networks onto specific\nnodes and links in the shared substrate network, known as virtual network\nembedding problem. Due to its NPhardness, many heuristic approaches have been\nproposed. In this thesis, we propose hybrid VN embedding algorithms that map\nmultiple VN requests with node and link constraints with K-core decomposition\nusing path splitting. Based on network pruning, a virtual network is decomposed\nto core network and edge network. The mapping process is divided into two\nphases: core network mapping and edge network mapping. Path splitting enables\nbetter resource utilization by allowing the substrate to accept more VN\nrequests. It splits the available bandwidth of the path into small bandwidth to\nsatisfy the resource constraints. The proposed algorithm improves the\nperformance of the algorithm by splitting the path into small bandwidth. Due to\npath splitting proposed algorithm will accept many virtual network requests\nthat will increase the revenue and acceptance ratio of the algorithm.\n", "Comment: This paper has been withdrawn by the author due to a crucial sign\n  error in equation 1"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.5049"}}, {"publisher": {"name": ""}, "description": "  In this paper a wide family of identifying codes over regular Cayley graphs\nof degree four which are built over finite Abelian groups is presented. Some of\nthe codes in this construction are also perfect. The graphs considered include\nsome well-known graphs such as tori, twisted tori and Kronecker products of two\ncycles. Therefore, the codes can be used for identification in these graphs.\nFinally, an example of how these codes can be applied for adaptive\nidentification over these graphs is presented.\n", "contributors": [{"name": "Camarero, Crist\u00f3bal", "sameAs": [], "familyName": "Camarero", "additionalName": "", "givenName": "Crist\u00f3bal", "email": ""}, {"name": "Mart\u00ednez, Carmen", "sameAs": [], "familyName": "Mart\u00ednez", "additionalName": "", "givenName": "Carmen", "email": ""}, {"name": "Beivide, Ram\u00f3n", "sameAs": [], "familyName": "Beivide", "additionalName": "", "givenName": "Ram\u00f3n", "email": ""}], "title": "Identifying Codes of Degree 4 Cayley Graphs over Abelian Groups", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5830", "oai:arXiv.org:1412.5830"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this paper a wide family of identifying codes over regular Cayley graphs\nof degree four which are built over finite Abelian groups is presented. Some of\nthe codes in this construction are also perfect. The graphs considered include\nsome well-known graphs such as tori, twisted tori and Kronecker products of two\ncycles. Therefore, the codes can be used for identification in these graphs.\nFinally, an example of how these codes can be applied for adaptive\nidentification over these graphs is presented.\n"}}], "languages": [null], "subjects": ["primary: 94b25", "computer science - discrete mathematics", "secondary: 05c69", "94c12", "computer science - information theory", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5830"}}, {"publisher": {"name": ""}, "description": "  With the imminent slowing down of DRAM scaling, Phase Change Memory (PCM) is\nemerging as a lead alternative for main memory technology. While PCM achieves\nlow energy due to various technology-specific advantages, PCM is significantly\nslower than DRAM (especially for writes) and can endure far fewer writes before\nwearing out. Previous work has proposed to use a large, DRAM-based hardware\ncache to absorb writes and provide faster access. However, due to ineffectual\ncaching where blocks are evicted before sufficient number of accesses, hardware\ncaches incur significant overheads in energy and bandwidth, two key but scarce\nresources in modern multicores. Because using hardware for detecting and\nremoving such ineffectual caching would incur additional hardware cost and\ncomplexity, we leverage the OS virtual memory support for this purpose. We\npropose a DRAM-PCM hybrid memory architecture where the OS migrates pages on\ndemand from the PCM to DRAM. We call the DRAM part of our memory as\nMigrantStore which includes two ideas. First, to reduce the energy, bandwidth,\nand wear overhead of ineffectual migrations, we propose migration hysteresis.\nSecond, to reduce the software overhead of good replacement policies, we\npropose recently- accessed-page-id (RAPid) buffer, a hardware buffer to track\nthe addresses of recently-accessed MigrantStore pages.\n", "contributors": [{"name": "Sohail, Hamza Bin", "sameAs": [], "familyName": "Sohail", "additionalName": "Bin", "givenName": "Hamza", "email": ""}, {"name": "Vamanan, Balajee", "sameAs": [], "familyName": "Vamanan", "additionalName": "", "givenName": "Balajee", "email": ""}, {"name": "Vijaykumar, T. N.", "sameAs": [], "familyName": "Vijaykumar", "additionalName": "N.", "givenName": "T.", "email": ""}], "title": "MigrantStore: Leveraging Virtual Memory in DRAM-PCM Memory Architecture", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.04297", "oai:arXiv.org:1504.04297"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  With the imminent slowing down of DRAM scaling, Phase Change Memory (PCM) is\nemerging as a lead alternative for main memory technology. While PCM achieves\nlow energy due to various technology-specific advantages, PCM is significantly\nslower than DRAM (especially for writes) and can endure far fewer writes before\nwearing out. Previous work has proposed to use a large, DRAM-based hardware\ncache to absorb writes and provide faster access. However, due to ineffectual\ncaching where blocks are evicted before sufficient number of accesses, hardware\ncaches incur significant overheads in energy and bandwidth, two key but scarce\nresources in modern multicores. Because using hardware for detecting and\nremoving such ineffectual caching would incur additional hardware cost and\ncomplexity, we leverage the OS virtual memory support for this purpose. We\npropose a DRAM-PCM hybrid memory architecture where the OS migrates pages on\ndemand from the PCM to DRAM. We call the DRAM part of our memory as\nMigrantStore which includes two ideas. First, to reduce the energy, bandwidth,\nand wear overhead of ineffectual migrations, we propose migration hysteresis.\nSecond, to reduce the software overhead of good replacement policies, we\npropose recently- accessed-page-id (RAPid) buffer, a hardware buffer to track\nthe addresses of recently-accessed MigrantStore pages.\n"}}], "languages": [null], "subjects": ["computer science - hardware architecture"], "providerUpdatedDateTime": "2015-04-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.04297"}}, {"publisher": {"name": ""}, "description": "  We study the total current correlations for anharmonic chains in thermal\nequilibrium, putting forward predictions based on the second moment sum rule\nand on nonlinear fluctuating hydrodynamics. We compare with molecular dynamics\nsimulations for hard collision models. For the first time we investigate the\nfull statistics of time-integrated currents. Generically such a quantity has\nGaussian statistics on a scale $\\sqrt{t}$. But if the time integration has its\nendpoint at a moving sound peak, then the fluctuations are suppressed and only\nof order $t^{1/3}$. The statistics is governed by the Baik-Rains distribution,\nknown already from the fluctuating Burgers equation.\n", "contributors": [{"name": "Mendl, Christian B.", "sameAs": [], "familyName": "Mendl", "additionalName": "B.", "givenName": "Christian", "email": ""}, {"name": "Spohn, Herbert", "sameAs": [], "familyName": "Spohn", "additionalName": "", "givenName": "Herbert", "email": ""}], "title": "Current fluctuations for anharmonic chains in thermal equilibrium", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4609", "J. Stat. Mech. (2015) P03007", "doi:10.1088/1742-5468/2015/03/P03007", "oai:arXiv.org:1412.4609"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We study the total current correlations for anharmonic chains in thermal\nequilibrium, putting forward predictions based on the second moment sum rule\nand on nonlinear fluctuating hydrodynamics. We compare with molecular dynamics\nsimulations for hard collision models. For the first time we investigate the\nfull statistics of time-integrated currents. Generically such a quantity has\nGaussian statistics on a scale $\\sqrt{t}$. But if the time integration has its\nendpoint at a moving sound peak, then the fluctuations are suppressed and only\nof order $t^{1/3}$. The statistics is governed by the Baik-Rains distribution,\nknown already from the fluctuating Burgers equation.\n", "Comment: 27 pages, 8 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "condensed matter - statistical mechanics"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4609"}}, {"publisher": {"name": ""}, "description": "  A parallel implementation of an eigensolver designed for electronic structure\ncalculations is presented. The method is applicable to computational tasks that\nsolve a sequence of eigenvalue problems where the solution for a particular\niteration is similar but not identical to the solution from the previous\niteration. Such problems occur frequently when performing electronic structure\ncalculations in which the eigenvectors are solutions to the Kohn-Sham\nequations. The eigenvectors are represented in some type of basis but the\nproblem sizes are normally too large for direct diagonalization in that basis.\nInstead a subspace diagonalization procedure is employed in which matrix\nelements of the Hamiltonian operator are generated and the eigenvalues and\neigenvectors of the resulting reduced matrix are obtained using a standard\neigensolver from a package such as LAPACK or SCALAPACK. While this method works\nwell and is widely used, the standard eigensolvers scale poorly on massively\nparallel computer systems for the matrix sizes typical of electronic structure\ncalculations. We present a new method that utilizes a partitioned folded\nspectrum scheme (PFSM) that takes into account the iterative nature of the\nproblem and performs well on massively parallel systems. Test results for a\nrange of problems are presented that demonstrate an equivalent level of\naccuracy when compared to the standard eigensolvers, while also executing up to\nan order of magnitude faster. Unlike O(N) methods, the technique works equally\nwell for metals and systems with unoccupied orbitals as for insulators and\nsemiconductors. Timing and accuracy results are presented for a range of\nsystems, including a 512 atom diamond cell, a cluster of 13 C60 molecules, bulk\ncopper, a 216 atom silicon cell with a vacancy, using 40 unoccupied\nstates/atom, and a 4000 atom aluminum supercell.\n", "contributors": [{"name": "Briggs, E. L.", "sameAs": [], "familyName": "Briggs", "additionalName": "L.", "givenName": "E.", "email": ""}, {"name": "Kelley, C. T.", "sameAs": [], "familyName": "Kelley", "additionalName": "T.", "givenName": "C.", "email": ""}, {"name": "Bernholc, J.", "sameAs": [], "familyName": "Bernholc", "additionalName": "", "givenName": "J.", "email": ""}], "title": "Parallel implementation of electronic structure eigensolver using a\n  partitioned folded spectrum method", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07806", "oai:arXiv.org:1502.07806"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": "  A parallel implementation of an eigensolver designed for electronic structure\ncalculations is presented. The method is applicable to computational tasks that\nsolve a sequence of eigenvalue problems where the solution for a particular\niteration is similar but not identical to the solution from the previous\niteration. Such problems occur frequently when performing electronic structure\ncalculations in which the eigenvectors are solutions to the Kohn-Sham\nequations. The eigenvectors are represented in some type of basis but the\nproblem sizes are normally too large for direct diagonalization in that basis.\nInstead a subspace diagonalization procedure is employed in which matrix\nelements of the Hamiltonian operator are generated and the eigenvalues and\neigenvectors of the resulting reduced matrix are obtained using a standard\neigensolver from a package such as LAPACK or SCALAPACK. While this method works\nwell and is widely used, the standard eigensolvers scale poorly on massively\nparallel computer systems for the matrix sizes typical of electronic structure\ncalculations. We present a new method that utilizes a partitioned folded\nspectrum scheme (PFSM) that takes into account the iterative nature of the\nproblem and performs well on massively parallel systems. Test results for a\nrange of problems are presented that demonstrate an equivalent level of\naccuracy when compared to the standard eigensolvers, while also executing up to\nan order of magnitude faster. Unlike O(N) methods, the technique works equally\nwell for metals and systems with unoccupied orbitals as for insulators and\nsemiconductors. Timing and accuracy results are presented for a range of\nsystems, including a 512 atom diamond cell, a cluster of 13 C60 molecules, bulk\ncopper, a 216 atom silicon cell with a vacancy, using 40 unoccupied\nstates/atom, and a 4000 atom aluminum supercell.\n"}}], "languages": [null], "subjects": ["physics - computational physics"], "providerUpdatedDateTime": "2015-03-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07806"}}, {"publisher": {"name": ""}, "description": "  In this work we focus on a natural class of population protocols whose\ndynamics are modelled by the discrete version of Lotka-Volterra equations. In\nsuch protocols, when an agent $a$ of type (species) $i$ interacts with an agent\n$b$ of type (species) $j$ with $a$ as the initiator, then $b$'s type becomes\n$i$ with probability $P\\_{ij}$. In such an interaction, we think of $a$ as the\npredator, $b$ as the prey, and the type of the prey is either converted to that\nof the predator or stays as is. Such protocols capture the dynamics of some\nopinion spreading models and generalize the well-known Rock-Paper-Scissors\ndiscrete dynamics. We consider the pairwise interactions among agents that are\nscheduled uniformly at random. We start by considering the convergence time and\nshow that any Lotka-Volterra-type protocol on an $n$-agent population converges\nto some absorbing state in time polynomial in $n$, w.h.p., when any pair of\nagents is allowed to interact. By contrast, when the interaction graph is a\nstar, even the Rock-Paper-Scissors protocol requires exponential time to\nconverge. We then study threshold effects exhibited by Lotka-Volterra-type\nprotocols with 3 and more species under interactions between any pair of\nagents. We start by presenting a simple 4-type protocol in which the\nprobability difference of reaching the two possible absorbing states is\nstrongly amplified by the ratio of the initial populations of the two other\ntypes, which are transient, but \"control\" convergence. We then prove that the\nRock-Paper-Scissors protocol reaches each of its three possible absorbing\nstates with almost equal probability, starting from any configuration\nsatisfying some sub-linear lower bound on the initial size of each species.\nThat is, Rock-Paper-Scissors is a realization of a \"coin-flip consensus\" in a\ndistributed system. Some of our techniques may be of independent value.\n", "contributors": [{"name": "Czyzowicz, Jurek", "sameAs": [], "familyName": "Czyzowicz", "additionalName": "", "givenName": "Jurek", "email": ""}, {"name": "Gasieniec, Leszek", "sameAs": [], "familyName": "Gasieniec", "additionalName": "", "givenName": "Leszek", "email": ""}, {"name": "Kosowski, Adrian", "sameAs": [], "familyName": "Kosowski", "additionalName": "", "givenName": "Adrian", "email": ""}, {"name": "Kranakis, Evangelos", "sameAs": [], "familyName": "Kranakis", "additionalName": "", "givenName": "Evangelos", "email": ""}, {"name": "Spirakis, Paul G.", "sameAs": [], "familyName": "Spirakis", "additionalName": "G.", "givenName": "Paul", "email": ""}, {"name": "Uznanski, Przemyslaw", "sameAs": [], "familyName": "Uznanski", "additionalName": "", "givenName": "Przemyslaw", "email": ""}], "title": "On Convergence and Threshold Properties of Discrete Lotka-Volterra\n  Population Protocols", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.09168", "oai:arXiv.org:1503.09168"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this work we focus on a natural class of population protocols whose\ndynamics are modelled by the discrete version of Lotka-Volterra equations. In\nsuch protocols, when an agent $a$ of type (species) $i$ interacts with an agent\n$b$ of type (species) $j$ with $a$ as the initiator, then $b$'s type becomes\n$i$ with probability $P\\_{ij}$. In such an interaction, we think of $a$ as the\npredator, $b$ as the prey, and the type of the prey is either converted to that\nof the predator or stays as is. Such protocols capture the dynamics of some\nopinion spreading models and generalize the well-known Rock-Paper-Scissors\ndiscrete dynamics. We consider the pairwise interactions among agents that are\nscheduled uniformly at random. We start by considering the convergence time and\nshow that any Lotka-Volterra-type protocol on an $n$-agent population converges\nto some absorbing state in time polynomial in $n$, w.h.p., when any pair of\nagents is allowed to interact. By contrast, when the interaction graph is a\nstar, even the Rock-Paper-Scissors protocol requires exponential time to\nconverge. We then study threshold effects exhibited by Lotka-Volterra-type\nprotocols with 3 and more species under interactions between any pair of\nagents. We start by presenting a simple 4-type protocol in which the\nprobability difference of reaching the two possible absorbing states is\nstrongly amplified by the ratio of the initial populations of the two other\ntypes, which are transient, but \"control\" convergence. We then prove that the\nRock-Paper-Scissors protocol reaches each of its three possible absorbing\nstates with almost equal probability, starting from any configuration\nsatisfying some sub-linear lower bound on the initial size of each species.\nThat is, Rock-Paper-Scissors is a realization of a \"coin-flip consensus\" in a\ndistributed system. Some of our techniques may be of independent value.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.09168"}}, {"publisher": {"name": ""}, "description": "  In this paper we discuss combinatorial questions about lattice polytopes\nmotivated by recent results on minimum distance estimation for toric codes. We\nalso prove a new inductive bound for the minimum distance of generalized toric\ncodes. As an application, we give new formulas for the minimum distance of\ngeneralized toric codes for special lattice point configurations.\n", "contributors": [{"name": "Soprunov, Ivan", "sameAs": [], "familyName": "Soprunov", "additionalName": "", "givenName": "Ivan", "email": ""}], "title": "Lattice polytopes in coding theory", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0028", "oai:arXiv.org:1411.0028"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper we discuss combinatorial questions about lattice polytopes\nmotivated by recent results on minimum distance estimation for toric codes. We\nalso prove a new inductive bound for the minimum distance of generalized toric\ncodes. As an application, we give new formulas for the minimum distance of\ngeneralized toric codes for special lattice point configurations.\n", "Comment: 11 pages, 3 figures"]}}], "languages": [null], "subjects": ["computer science - information theory", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0028"}}, {"publisher": {"name": ""}, "description": "  Automatic License Plate Recognition (ALPR) is a challenging area of research\ndue to its importance to variety of commercial applications. The overall\nproblem may be subdivided into two key modules, firstly, localization of\nlicense plates from vehicle images, and secondly, optical character recognition\nof extracted license plates. In the current work, we have concentrated on the\nfirst part of the problem, i.e., localization of license plate regions from\nIndian commercial vehicles as a significant step towards development of a\ncomplete ALPR system for Indian vehicles. The technique is based on color based\nsegmentation of vehicle images and identification of potential license plate\nregions. True license plates are finally localized based on four spatial and\nhorizontal contrast features. The technique successfully localizes the actual\nlicense plates in 73.4% images.\n", "contributors": [{"name": "Saha, Satadal", "sameAs": [], "familyName": "Saha", "additionalName": "", "givenName": "Satadal", "email": ""}, {"name": "Basu, Subhadip", "sameAs": [], "familyName": "Basu", "additionalName": "", "givenName": "Subhadip", "email": ""}, {"name": "Nasipuri, Mita", "sameAs": [], "familyName": "Nasipuri", "additionalName": "", "givenName": "Mita", "email": ""}, {"name": "Basu, Dipak Kumar", "sameAs": [], "familyName": "Basu", "additionalName": "Kumar", "givenName": "Dipak", "email": ""}], "title": "An Offline Technique for Localization of License Plates for Indian\n  Commercial Vehicles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-03-04", "2015-01-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1003.1072", "oai:arXiv.org:1003.1072"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Automatic License Plate Recognition (ALPR) is a challenging area of research\ndue to its importance to variety of commercial applications. The overall\nproblem may be subdivided into two key modules, firstly, localization of\nlicense plates from vehicle images, and secondly, optical character recognition\nof extracted license plates. In the current work, we have concentrated on the\nfirst part of the problem, i.e., localization of license plate regions from\nIndian commercial vehicles as a significant step towards development of a\ncomplete ALPR system for Indian vehicles. The technique is based on color based\nsegmentation of vehicle images and identification of potential license plate\nregions. True license plates are finally localized based on four spatial and\nhorizontal contrast features. The technique successfully localizes the actual\nlicense plates in 73.4% images.\n", "Comment: National Conference on Computing and Communication Systems\n  (COCOSYS-09)"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1003.1072"}}, {"publisher": {"name": ""}, "description": "  In this work, we reveal the structure of global news coverage of disasters\nand its determinants by using a large-scale news coverage dataset collected by\nthe GDELT (Global Data on Events, Location, and Tone) project that monitors\nnews media in over 100 languages from the whole world. Significant variables in\nour hierarchical (mixed-effect) regression model, such as the number of\npopulation, the political stability, the damage, and more, are well aligned\nwith a series of previous research. Yet, strong regionalism we found in news\ngeography highlights the necessity of the comprehensive dataset for the study\nof global news coverage.\n", "contributors": [{"name": "Kwak, Haewoon", "sameAs": [], "familyName": "Kwak", "additionalName": "", "givenName": "Haewoon", "email": ""}, {"name": "An, Jisun", "sameAs": [], "familyName": "An", "additionalName": "", "givenName": "Jisun", "email": ""}], "title": "Understanding News Geography and Major Determinants of Global News\n  Coverage of Disasters", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.3710", "oai:arXiv.org:1410.3710"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  In this work, we reveal the structure of global news coverage of disasters\nand its determinants by using a large-scale news coverage dataset collected by\nthe GDELT (Global Data on Events, Location, and Tone) project that monitors\nnews media in over 100 languages from the whole world. Significant variables in\nour hierarchical (mixed-effect) regression model, such as the number of\npopulation, the political stability, the damage, and more, are well aligned\nwith a series of previous research. Yet, strong regionalism we found in news\ngeography highlights the necessity of the comprehensive dataset for the study\nof global news coverage.\n", "Comment: Presented at Computation+Jounalism Symposium (C+J Symposium) 2014"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - computers and society"], "providerUpdatedDateTime": "2014-10-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.3710"}}, {"publisher": {"name": ""}, "description": "  We present an algorithm for computing a holonomic system for a definite\nintegral of a holonomic function over a domain defined by polynomial\ninequalities. If the integrand satisfies a holonomic difference-differential\nsystem including parameters, then a holonomic difference-differential system\nfor the integral can also be computed. In the algorithm, holonomic\ndistributions (generalized functions in the sense of L. Schwartz) are\ninevitably involved even if the integrand is a usual function.\n", "contributors": [{"name": "Oaku, Toshinori", "sameAs": [], "familyName": "Oaku", "additionalName": "", "givenName": "Toshinori", "email": ""}], "title": "Algorithms for integrals of holonomic functions over domains defined by\n  polynomial inequalities", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-08-24", "2011-10-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1108.4853", "oai:arXiv.org:1108.4853"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We present an algorithm for computing a holonomic system for a definite\nintegral of a holonomic function over a domain defined by polynomial\ninequalities. If the integrand satisfies a holonomic difference-differential\nsystem including parameters, then a holonomic difference-differential system\nfor the integral can also be computed. In the algorithm, holonomic\ndistributions (generalized functions in the sense of L. Schwartz) are\ninevitably involved even if the integrand is a usual function.\n", "Comment: corrected typos; Sections 5 and 6 were slightly revised with results\n  unchanged"]}}], "languages": [null], "subjects": ["computer science - symbolic computation", "mathematics - classical analysis and odes"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1108.4853"}}, {"publisher": {"name": ""}, "description": "  We consider the logic MSO+U, which is monadic second-order logic extended\nwith the unbounding quantifier. The unbounding quantifier is used to say that a\nproperty of finite sets holds for sets of arbitrarily large size. We prove that\nthe logic is undecidable on infinite words, i.e. the \\msou theory of $(N,<)$ is\nundecidable. This settles an open problem about the logic, and improves a\nprevious undecidability result, which used infinite trees and additional axioms\nfrom set theory.\n", "contributors": [{"name": "Boja\u0144czyk, Miko\u0142aj", "sameAs": [], "familyName": "Boja\u0144czyk", "additionalName": "", "givenName": "Miko\u0142aj", "email": ""}, {"name": "Parys, Pawe\u0142", "sameAs": [], "familyName": "Parys", "additionalName": "", "givenName": "Pawe\u0142", "email": ""}, {"name": "Toru\u0144czyk, Szymon", "sameAs": [], "familyName": "Toru\u0144czyk", "additionalName": "", "givenName": "Szymon", "email": ""}], "title": "The MSO+U theory of (N, <) is undecidable", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04578", "oai:arXiv.org:1502.04578"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We consider the logic MSO+U, which is monadic second-order logic extended\nwith the unbounding quantifier. The unbounding quantifier is used to say that a\nproperty of finite sets holds for sets of arbitrarily large size. We prove that\nthe logic is undecidable on infinite words, i.e. the \\msou theory of $(N,<)$ is\nundecidable. This settles an open problem about the logic, and improves a\nprevious undecidability result, which used infinite trees and additional axioms\nfrom set theory.\n", "Comment: 9 pages, with 2 figures"]}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04578"}}, {"publisher": {"name": ""}, "description": "  This paper proposes a bisimulation theory based on multiparty session types\nwhere a choreography specification governs the behaviour of session typed\nprocesses and their observer. The bisimulation is defined with the observer\ncooperating with the observed process in order to form complete global session\nscenarios and usable for proving correctness of optimisations for globally\ncoordinating threads and processes. The induced bisimulation is strictly more\nfine-grained than the standard session bisimulation. The difference between the\ngoverned and standard bisimulations only appears when more than two interleaved\nmultiparty sessions exist. This distinct feature enables to reason real\nscenarios in the large-scale distributed system where multiple choreographic\nsessions need to be interleaved. The compositionality of the governed\nbisimilarity is proved through the soundness and completeness with respect to\nthe governed reduction-based congruence. Finally, its usage is demonstrated by\na thread transformation governed under multiple sessions in a real usecase in\nthe large-scale cyberinfrustracture.\n", "contributors": [{"name": "Kouzapas, Dimitrios", "sameAs": [], "familyName": "Kouzapas", "additionalName": "", "givenName": "Dimitrios", "email": ""}, {"name": "Yoshida, Nobuko", "sameAs": [], "familyName": "Yoshida", "additionalName": "", "givenName": "Nobuko", "email": ""}], "title": "Globally Governed Session Semantics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5943", "oai:arXiv.org:1412.5943"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper proposes a bisimulation theory based on multiparty session types\nwhere a choreography specification governs the behaviour of session typed\nprocesses and their observer. The bisimulation is defined with the observer\ncooperating with the observed process in order to form complete global session\nscenarios and usable for proving correctness of optimisations for globally\ncoordinating threads and processes. The induced bisimulation is strictly more\nfine-grained than the standard session bisimulation. The difference between the\ngoverned and standard bisimulations only appears when more than two interleaved\nmultiparty sessions exist. This distinct feature enables to reason real\nscenarios in the large-scale distributed system where multiple choreographic\nsessions need to be interleaved. The compositionality of the governed\nbisimilarity is proved through the soundness and completeness with respect to\nthe governed reduction-based congruence. Finally, its usage is demonstrated by\na thread transformation governed under multiple sessions in a real usecase in\nthe large-scale cyberinfrustracture.\n"}}], "languages": [null], "subjects": ["computer science - logic in computer science", "f.3.2", "d.3.1"], "providerUpdatedDateTime": "2014-12-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5943"}}, {"publisher": {"name": ""}, "description": "  In a scientific publishing environment that is increasingly moving online,\nidentifiers of scholarly work are gaining in importance. In this paper, we\nanalysed identifier distribution and coverage of articles from the discipline\nof quantitative biology using arXiv, Mendeley and CrossRef as data sources. The\nresults show that when retrieving arXiv articles from Mendeley, we were able to\nfind more papers using the DOI than the arXiv ID. This indicates that DOI may\nbe a better identifier with respect to findability. We also find that coverage\nof articles on Mendeley decreases in the most recent years, whereas the\ncoverage of DOIs does not decrease in the same order of magnitude. This hints\nat the fact that there is a certain time lag involved, before articles are\ncovered in crowd-sourced services on the scholarly web.\n", "contributors": [{"name": "Kraker, Peter", "sameAs": [], "familyName": "Kraker", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Enkhbayar, Asura", "sameAs": [], "familyName": "Enkhbayar", "additionalName": "", "givenName": "Asura", "email": ""}, {"name": "Lex, Elisabeth", "sameAs": [], "familyName": "Lex", "additionalName": "", "givenName": "Elisabeth", "email": ""}], "title": "Exploring Coverage and Distribution of Identifiers on the Scholarly Web", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.05096", "oai:arXiv.org:1503.05096"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In a scientific publishing environment that is increasingly moving online,\nidentifiers of scholarly work are gaining in importance. In this paper, we\nanalysed identifier distribution and coverage of articles from the discipline\nof quantitative biology using arXiv, Mendeley and CrossRef as data sources. The\nresults show that when retrieving arXiv articles from Mendeley, we were able to\nfind more papers using the DOI than the arXiv ID. This indicates that DOI may\nbe a better identifier with respect to findability. We also find that coverage\nof articles on Mendeley decreases in the most recent years, whereas the\ncoverage of DOIs does not decrease in the same order of magnitude. This hints\nat the fact that there is a certain time lag involved, before articles are\ncovered in crowd-sourced services on the scholarly web.\n", "Comment: Accepted for publication at the 14th International Symposium of\n  Information Science (ISI 2015)"]}}], "languages": [null], "subjects": ["computer science - digital libraries"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.05096"}}, {"publisher": {"name": ""}, "description": "  Inspired by recent work in machine translation and object detection, we\nintroduce an attention based model that automatically learns to describe the\ncontent of images. We describe how we can train this model in a deterministic\nmanner using standard backpropagation techniques and stochastically by\nmaximizing a variational lower bound. We also show through visualization how\nthe model is able to automatically learn to fix its gaze on salient objects\nwhile generating the corresponding words in the output sequence. We validate\nthe use of attention with state-of-the-art performance on three benchmark\ndatasets: Flickr8k, Flickr30k and MS COCO.\n", "contributors": [{"name": "Xu, Kelvin", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Kelvin", "email": ""}, {"name": "Ba, Jimmy", "sameAs": [], "familyName": "Ba", "additionalName": "", "givenName": "Jimmy", "email": ""}, {"name": "Kiros, Ryan", "sameAs": [], "familyName": "Kiros", "additionalName": "", "givenName": "Ryan", "email": ""}, {"name": "Cho, Kyunghyun", "sameAs": [], "familyName": "Cho", "additionalName": "", "givenName": "Kyunghyun", "email": ""}, {"name": "Courville, Aaron", "sameAs": [], "familyName": "Courville", "additionalName": "", "givenName": "Aaron", "email": ""}, {"name": "Salakhutdinov, Ruslan", "sameAs": [], "familyName": "Salakhutdinov", "additionalName": "", "givenName": "Ruslan", "email": ""}, {"name": "Zemel, Richard", "sameAs": [], "familyName": "Zemel", "additionalName": "", "givenName": "Richard", "email": ""}, {"name": "Bengio, Yoshua", "sameAs": [], "familyName": "Bengio", "additionalName": "", "givenName": "Yoshua", "email": ""}], "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual\n  Attention", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03044", "oai:arXiv.org:1502.03044"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Inspired by recent work in machine translation and object detection, we\nintroduce an attention based model that automatically learns to describe the\ncontent of images. We describe how we can train this model in a deterministic\nmanner using standard backpropagation techniques and stochastically by\nmaximizing a variational lower bound. We also show through visualization how\nthe model is able to automatically learn to fix its gaze on salient objects\nwhile generating the corresponding words in the output sequence. We validate\nthe use of attention with state-of-the-art performance on three benchmark\ndatasets: Flickr8k, Flickr30k and MS COCO.\n"}}], "languages": [null], "subjects": ["computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03044"}}, {"publisher": {"name": ""}, "description": "  Pain assessment through observational pain scales is necessary for special\ncategories of patients such as neonates, patients with dementia, critically ill\npatients, etc. The recently introduced Prkachin-Solomon score allows pain\nassessment directly from facial images opening the path for multiple assistive\napplications. In this paper, we introduce the Histograms of Topographical (HoT)\nfeatures, which are a generalization of the topographical primal sketch, for\nthe description of the face parts contributing to the mentioned score. We\npropose a semi-supervised, clustering oriented self--taught learning procedure\ndeveloped on the emotion oriented Cohn-Kanade database. We use this procedure\nto improve the discrimination between different pain intensity levels and the\ngeneralization with respect to the monitored persons, while testing on the UNBC\nMcMaster Shoulder Pain database.\n", "contributors": [{"name": "Florea, Corneliu", "sameAs": [], "familyName": "Florea", "additionalName": "", "givenName": "Corneliu", "email": ""}, {"name": "Florea, Laura", "sameAs": [], "familyName": "Florea", "additionalName": "", "givenName": "Laura", "email": ""}, {"name": "Boia, Raluca", "sameAs": [], "familyName": "Boia", "additionalName": "", "givenName": "Raluca", "email": ""}, {"name": "Bandrabur, Alessandra", "sameAs": [], "familyName": "Bandrabur", "additionalName": "", "givenName": "Alessandra", "email": ""}, {"name": "Vertan, Constantin", "sameAs": [], "familyName": "Vertan", "additionalName": "", "givenName": "Constantin", "email": ""}], "title": "Pain Intensity Estimation by a Self--Taught Selection of Histograms of\n  Topographical Features", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07706", "oai:arXiv.org:1503.07706"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Pain assessment through observational pain scales is necessary for special\ncategories of patients such as neonates, patients with dementia, critically ill\npatients, etc. The recently introduced Prkachin-Solomon score allows pain\nassessment directly from facial images opening the path for multiple assistive\napplications. In this paper, we introduce the Histograms of Topographical (HoT)\nfeatures, which are a generalization of the topographical primal sketch, for\nthe description of the face parts contributing to the mentioned score. We\npropose a semi-supervised, clustering oriented self--taught learning procedure\ndeveloped on the emotion oriented Cohn-Kanade database. We use this procedure\nto improve the discrimination between different pain intensity levels and the\ngeneralization with respect to the monitored persons, while testing on the UNBC\nMcMaster Shoulder Pain database.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07706"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Extracting useful knowledge from large network datasets has become a fundamental challenge in many domains, from scientific literature to social networks and the web. We introduce Apolo, a system that uses a mixed-initiative approach\u2014 combining visualization, rich user interaction and machine learning\u2014to guide the user to incrementally and interactively explore large network data and make sense of it. Apolo engages the user in bottom-up sensemaking to gradually build up an understanding over time by starting small, rather than starting big and drilling down. Apolo also helps users find relevant information by specifying exemplars, and then using a machine learning method called Belief Propagation to infer which other nodes may be of interest. We evaluated Apolo with twelve participants in a between-subjects study, with the task being to find relevant new papers to update an existing survey paper. Using expert judges, participants using Apolo found significantly more relevant papers. Subjective feedback of Apolo was also very positive.", "contributors": [{"name": "Chau, Duen Horng", "sameAs": [], "familyName": "Chau", "additionalName": "Horng", "givenName": "Duen", "email": ""}, {"name": "Kittur, Aniket", "sameAs": [], "familyName": "Kittur", "additionalName": "", "givenName": "Aniket", "email": ""}, {"name": "Hong, Jason I.", "sameAs": [], "familyName": "Hong", "additionalName": "I.", "givenName": "Jason", "email": ""}, {"name": "Faloutsos, Christos", "sameAs": [], "familyName": "Faloutsos", "additionalName": "", "givenName": "Christos", "email": ""}], "title": "Making Sense of Large Network Data: Combining Rich User Interaction and Machine Learning", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2011-01-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/hcii/285", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1283&amp;context=hcii", "oai:repository.cmu.edu:hcii-1283"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:hcii", "publication:scs"]}}, {"name": "description", "properties": {"description": "Extracting useful knowledge from large network datasets has become a fundamental challenge in many domains, from scientific literature to social networks and the web. We introduce Apolo, a system that uses a mixed-initiative approach\u2014 combining visualization, rich user interaction and machine learning\u2014to guide the user to incrementally and interactively explore large network data and make sense of it. Apolo engages the user in bottom-up sensemaking to gradually build up an understanding over time by starting small, rather than starting big and drilling down. Apolo also helps users find relevant information by specifying exemplars, and then using a machine learning method called Belief Propagation to infer which other nodes may be of interest. We evaluated Apolo with twelve participants in a between-subjects study, with the task being to find relevant new papers to update an existing survey paper. Using expert judges, participants using Apolo found significantly more relevant papers. Subjective feedback of Apolo was also very positive."}}], "languages": [null], "subjects": ["large network", "computer sciences", "sensemaking", "belief propagation"], "providerUpdatedDateTime": "2015-05-07T21:24:28", "uris": {"canonicalUri": "http://repository.cmu.edu/hcii/285"}}, {"publisher": {"name": ""}, "description": "  The effectiveness and simple implementation of physical layer jammers make\nthem an essential threat for wireless networks. In a multihop wireless network,\nwhere jammers can interfere with the transmission of user messages at every\nintermediate nodes along the path, one can employ jamming oblivious routing and\nthen employ physical-layer techniques (e.g. spread spectrum) to suppress\njamming. However, whereas these approaches can provide significant gains, the\nresidual jamming can still severely limit system performance. This motivates\nthe consideration of routing approaches that account for the differences in the\njamming environment between different paths. First, we take a straightforward\napproach where an equal outage probability is allocated to each of the links\nalong the path and develop a minimum energy routing solution. Next, we\ndemonstrate the shortcomings of this approach and then consider the optimal\noutage allocation along paths by employing an approximation to the link outage\nprobability. This yields an efficient and effective routing algorithm that only\nrequires knowledge of the measured jamming at each node. Numerical results\ndemonstrate that the amount of energy saved by the proposed methods with\nrespect to standard shortest path routing, especially for parameters\nappropriate for terrestrial wireless networks, is substantial.\n", "contributors": [{"name": "Sheikholeslami, Azadeh", "sameAs": [], "familyName": "Sheikholeslami", "additionalName": "", "givenName": "Azadeh", "email": ""}, {"name": "Ghaderi, Majid", "sameAs": [], "familyName": "Ghaderi", "additionalName": "", "givenName": "Majid", "email": ""}, {"name": "Pishro-Nik, Hossein", "sameAs": [], "familyName": "Pishro-Nik", "additionalName": "", "givenName": "Hossein", "email": ""}, {"name": "Goeckel, Dennis", "sameAs": [], "familyName": "Goeckel", "additionalName": "", "givenName": "Dennis", "email": ""}], "title": "Minimum Energy Routing in Wireless Networks in the Presence of Jamming", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-13", "2015-03-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3736", "oai:arXiv.org:1411.3736"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The effectiveness and simple implementation of physical layer jammers make\nthem an essential threat for wireless networks. In a multihop wireless network,\nwhere jammers can interfere with the transmission of user messages at every\nintermediate nodes along the path, one can employ jamming oblivious routing and\nthen employ physical-layer techniques (e.g. spread spectrum) to suppress\njamming. However, whereas these approaches can provide significant gains, the\nresidual jamming can still severely limit system performance. This motivates\nthe consideration of routing approaches that account for the differences in the\njamming environment between different paths. First, we take a straightforward\napproach where an equal outage probability is allocated to each of the links\nalong the path and develop a minimum energy routing solution. Next, we\ndemonstrate the shortcomings of this approach and then consider the optimal\noutage allocation along paths by employing an approximation to the link outage\nprobability. This yields an efficient and effective routing algorithm that only\nrequires knowledge of the measured jamming at each node. Numerical results\ndemonstrate that the amount of energy saved by the proposed methods with\nrespect to standard shortest path routing, especially for parameters\nappropriate for terrestrial wireless networks, is substantial.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3736"}}, {"publisher": {"name": ""}, "description": "  A number of methods have been proposed over the last decade for encoding\ninformation using deoxyribonucleic acid (DNA), giving rise to the emerging area\nof DNA data embedding. Since a DNA sequence is conceptually equivalent to a\nsequence of quaternary symbols (bases), DNA data embedding (diversely called\nDNA watermarking or DNA steganography) can be seen as a digital communications\nproblem where channel errors are tantamount to mutations of DNA bases.\nDepending on the use of coding or noncoding DNA hosts, which, respectively,\ndenote DNA segments that can or cannot be translated into proteins, DNA data\nembedding is essentially a problem of communications with or without side\ninformation at the encoder. In this paper the Shannon capacity of DNA data\nembedding is obtained for the case in which DNA sequences are subject to\nsubstitution mutations modelled using the Kimura model from molecular evolution\nstudies. Inferences are also drawn with respect to the biological implications\nof some of the results presented.\n", "contributors": [{"name": "Balado, F\u00e9lix", "sameAs": [], "familyName": "Balado", "additionalName": "", "givenName": "F\u00e9lix", "email": ""}], "title": "Capacity of DNA Data Embedding Under Substitution Mutations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-01-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.3457", "doi:10.1109/TIT.2012.2219495", "oai:arXiv.org:1101.3457"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "q-bio"]}}, {"name": "description", "properties": {"description": ["  A number of methods have been proposed over the last decade for encoding\ninformation using deoxyribonucleic acid (DNA), giving rise to the emerging area\nof DNA data embedding. Since a DNA sequence is conceptually equivalent to a\nsequence of quaternary symbols (bases), DNA data embedding (diversely called\nDNA watermarking or DNA steganography) can be seen as a digital communications\nproblem where channel errors are tantamount to mutations of DNA bases.\nDepending on the use of coding or noncoding DNA hosts, which, respectively,\ndenote DNA segments that can or cannot be translated into proteins, DNA data\nembedding is essentially a problem of communications with or without side\ninformation at the encoder. In this paper the Shannon capacity of DNA data\nembedding is obtained for the case in which DNA sequences are subject to\nsubstitution mutations modelled using the Kimura model from molecular evolution\nstudies. Inferences are also drawn with respect to the biological implications\nof some of the results presented.\n", "Comment: 22 pages, 13 figures; preliminary versions of this work were\n  presented at the SPIE Media Forensics and Security XII conference (January\n  2010) and at the IEEE ICASSP conference (March 2010)"]}}], "languages": [null], "subjects": ["computer science - information theory", "quantitative biology - populations and evolution", "quantitative biology - quantitative methods"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.3457"}}, {"publisher": {"name": ""}, "description": "  Based on ideas of K\\\"otter and Kschischang we use constant dimension\nsubspaces as codewords in a network. We show a connection to the theory of\nq-analogues of a combinatorial designs, which has been studied in Braun, Kerber\nand Laue as a purely combinatorial object. For the construction of network\ncodes we successfully modified methods (construction with prescribed\nautomorphisms) originally developed for the q-analogues of a combinatorial\ndesigns. We then give a special case of that method which allows the\nconstruction of network codes with a very large ambient space and we also show\nhow to decode such codes with a very small number of operations.\n", "contributors": [{"name": "Elsenhans, Andreas-Stephan", "sameAs": [], "familyName": "Elsenhans", "additionalName": "", "givenName": "Andreas-Stephan", "email": ""}, {"name": "Kohnert, Axel", "sameAs": [], "familyName": "Kohnert", "additionalName": "", "givenName": "Axel", "email": ""}, {"name": "Wassermann, Alfred", "sameAs": [], "familyName": "Wassermann", "additionalName": "", "givenName": "Alfred", "email": ""}], "title": "Construction of Codes for Network Coding", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-05-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.2839", "oai:arXiv.org:1005.2839"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Based on ideas of K\\\"otter and Kschischang we use constant dimension\nsubspaces as codewords in a network. We show a connection to the theory of\nq-analogues of a combinatorial designs, which has been studied in Braun, Kerber\nand Laue as a purely combinatorial object. For the construction of network\ncodes we successfully modified methods (construction with prescribed\nautomorphisms) originally developed for the q-analogues of a combinatorial\ndesigns. We then give a special case of that method which allows the\nconstruction of network codes with a very large ambient space and we also show\nhow to decode such codes with a very small number of operations.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.2839"}}, {"publisher": {"name": ""}, "description": "  We consider a system consisting of multiple mobile robots in which the user\ncan at any time issue relocation tasks ordering one of the robots to move from\nits current location to a given destination location. In this paper, we deal\nwith the problem of finding a trajectory for each such relocation task that\navoids collisions with other robots. The chosen robot plans its trajectory so\nas to avoid collision with other robots executing tasks that were issued\nearlier. We prove that if all possible destinations of the relocation tasks\nsatisfy so-called valid infrastructure property, then this mechanism is\nguaranteed to always succeed and provide a trajectory for the robot that\nreaches the destination without colliding with any other robot. The\ntime-complexity of the approach on a fixed space-time discretization is only\nquadratic in the number of robots. We demonstrate the applicability of the\npresented method on several real-world maps and compare its performance against\na popular reactive approach that attempts to solve the collisions locally.\nBesides being dead-lock free, the presented approach generates trajectories\nthat are significantly faster (up to 48% improvement) than the trajectories\nresulting from local collision avoidance.\n", "contributors": [{"name": "\u010c\u00e1p, Michal", "sameAs": [], "familyName": "\u010c\u00e1p", "additionalName": "", "givenName": "Michal", "email": ""}, {"name": "Vok\u0159\u00ednek, Ji\u0159\u00ed", "sameAs": [], "familyName": "Vok\u0159\u00ednek", "additionalName": "", "givenName": "Ji\u0159\u00ed", "email": ""}, {"name": "Kleiner, Alexander", "sameAs": [], "familyName": "Kleiner", "additionalName": "", "givenName": "Alexander", "email": ""}], "title": "Complete Decentralized Method for On-Line Multi-Robot Trajectory\n  Planning in Valid Infrastructures", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.07704", "oai:arXiv.org:1501.07704"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We consider a system consisting of multiple mobile robots in which the user\ncan at any time issue relocation tasks ordering one of the robots to move from\nits current location to a given destination location. In this paper, we deal\nwith the problem of finding a trajectory for each such relocation task that\navoids collisions with other robots. The chosen robot plans its trajectory so\nas to avoid collision with other robots executing tasks that were issued\nearlier. We prove that if all possible destinations of the relocation tasks\nsatisfy so-called valid infrastructure property, then this mechanism is\nguaranteed to always succeed and provide a trajectory for the robot that\nreaches the destination without colliding with any other robot. The\ntime-complexity of the approach on a fixed space-time discretization is only\nquadratic in the number of robots. We demonstrate the applicability of the\npresented method on several real-world maps and compare its performance against\na popular reactive approach that attempts to solve the collisions locally.\nBesides being dead-lock free, the presented approach generates trajectories\nthat are significantly faster (up to 48% improvement) than the trajectories\nresulting from local collision avoidance.\n", "Comment: Accepted to International Conference on Automated Planning and\n  Scheduling 2015"]}}], "languages": [null], "subjects": ["computer science - robotics"], "providerUpdatedDateTime": "2015-02-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.07704"}}, {"publisher": {"name": ""}, "description": "  We consider the largest number of minimal separators a graph on n vertices\ncan have at most.\n  We give a new proof that this number is in $O( ((1+\\sqrt{5})/2)^n n )$.\n  We prove that this number is in $\\omega( 1.4521^n )$, improving on the\nprevious best lower bound of $\\Omega(3^{n/3}) \\subseteq \\omega( 1.4422^n )$.\n  This gives also an improved lower bound on the number of potential maximal\ncliques in a graph. We would like to emphasize that our proofs are short,\nsimple, and elementary.\n", "contributors": [{"name": "Gaspers, Serge", "sameAs": [], "familyName": "Gaspers", "additionalName": "", "givenName": "Serge", "email": ""}, {"name": "Mackenzie, Simon", "sameAs": [], "familyName": "Mackenzie", "additionalName": "", "givenName": "Simon", "email": ""}], "title": "On the Number of Minimal Separators in Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-03", "2015-04-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01203", "oai:arXiv.org:1503.01203"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider the largest number of minimal separators a graph on n vertices\ncan have at most.\n  We give a new proof that this number is in $O( ((1+\\sqrt{5})/2)^n n )$.\n  We prove that this number is in $\\omega( 1.4521^n )$, improving on the\nprevious best lower bound of $\\Omega(3^{n/3}) \\subseteq \\omega( 1.4422^n )$.\n  This gives also an improved lower bound on the number of potential maximal\ncliques in a graph. We would like to emphasize that our proofs are short,\nsimple, and elementary.\n", "Comment: arXiv admin note: text overlap with arXiv:0909.5278 by other authors"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-04-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01203"}}, {"publisher": {"name": ""}, "description": "  Consider the problem of minimizing the expected value of a (possibly\nnonconvex) cost function parameterized by a random (vector) variable, when the\nexpectation cannot be computed accurately (e.g., because the statistics of the\nrandom variables are unknown and/or the computational complexity is\nprohibitive). Classical sample stochastic gradient methods for solving this\nproblem may empirically suffer from slow convergence. In this paper, we propose\nfor the first time a stochastic parallel Successive Convex Approximation-based\n(best-response) algorithmic framework for general nonconvex stochastic\nsum-utility optimization problems, which arise naturally in the design of\nmulti-agent systems. The proposed novel decomposition enables all users to\nupdate their optimization variables in parallel by solving a sequence of\nstrongly convex subproblems, one for each user. Almost surely convergence to\nstationary points is proved. We then customize our algorithmic framework to\nsolve the stochastic sum rate maximization problem over\nSingle-Input-Single-Output (SISO) frequency-selective interference channels,\nmultiple-input-multiple-output (MIMO) interference channels, and MIMO\nmultiple-access channels. Numerical results show that our algorithms are much\nfaster than state-of-the-art stochastic gradient schemes while achieving the\nsame (or better) sum-rates.\n", "contributors": [{"name": "Yang, Yang", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Yang", "email": ""}, {"name": "Scutari, Gesualdo", "sameAs": [], "familyName": "Scutari", "additionalName": "", "givenName": "Gesualdo", "email": ""}, {"name": "Palomar, Daniel P.", "sameAs": [], "familyName": "Palomar", "additionalName": "P.", "givenName": "Daniel", "email": ""}, {"name": "Pesavento, Marius", "sameAs": [], "familyName": "Pesavento", "additionalName": "", "givenName": "Marius", "email": ""}], "title": "A Parallel Stochastic Approximation Method for Nonconvex Multi-Agent\n  Optimization Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5076", "oai:arXiv.org:1410.5076"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Consider the problem of minimizing the expected value of a (possibly\nnonconvex) cost function parameterized by a random (vector) variable, when the\nexpectation cannot be computed accurately (e.g., because the statistics of the\nrandom variables are unknown and/or the computational complexity is\nprohibitive). Classical sample stochastic gradient methods for solving this\nproblem may empirically suffer from slow convergence. In this paper, we propose\nfor the first time a stochastic parallel Successive Convex Approximation-based\n(best-response) algorithmic framework for general nonconvex stochastic\nsum-utility optimization problems, which arise naturally in the design of\nmulti-agent systems. The proposed novel decomposition enables all users to\nupdate their optimization variables in parallel by solving a sequence of\nstrongly convex subproblems, one for each user. Almost surely convergence to\nstationary points is proved. We then customize our algorithmic framework to\nsolve the stochastic sum rate maximization problem over\nSingle-Input-Single-Output (SISO) frequency-selective interference channels,\nmultiple-input-multiple-output (MIMO) interference channels, and MIMO\nmultiple-access channels. Numerical results show that our algorithms are much\nfaster than state-of-the-art stochastic gradient schemes while achieving the\nsame (or better) sum-rates.\n", "Comment: Part of this work has been presented at IEEE SPAWC 2013"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - multiagent systems"], "providerUpdatedDateTime": "2014-10-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5076"}}, {"publisher": {"name": ""}, "description": "  Public health surveillance aims at lessening disease burden, e.g., in case of\ninfectious diseases by timely recognizing emerging outbreaks. Seen from a\nstatistical perspective, this implies the use of appropriate methods for\nmonitoring time series of aggregated case reports. This paper presents the\ntools for such automatic aberration detection offered by the R package\nsurveillance. We introduce the functionality for the visualization, modelling\nand monitoring of surveillance time series. With respect to modelling we focus\non univariate time series modelling based on generalized linear models (GLMs),\nmultivariate GLMs, generalized additive models and generalized additive models\nfor location, shape and scale. This ranges from illustrating implementational\nimprovements and extensions of the well-known Farrington algorithm, e.g, by\nspline-modelling or by treating it in a Bayesian context. Furthermore, we look\nat categorical time series and address overdispersion using beta-binomial or\nDirichlet-Multinomial modelling. With respect to monitoring we consider\ndetectors based on either a Shewhart-like single timepoint comparison between\nthe observed count and the predictive distribution or by likelihood-ratio based\ncumulative sum methods. Finally, we illustrate how surveillance can support\naberration detection in practice by integrating it into the monitoring workflow\nof a public health institution. Altogether, the present article shows how well\nsurveillance can support automatic aberration detection in a public health\nsurveillance context.\n", "contributors": [{"name": "Ma\u00eblle, Salmon", "sameAs": [], "familyName": "Ma\u00eblle", "additionalName": "", "givenName": "Salmon", "email": ""}, {"name": "Dirk, Schumacher", "sameAs": [], "familyName": "Dirk", "additionalName": "", "givenName": "Schumacher", "email": ""}, {"name": "Michael, H\u00f6hle", "sameAs": [], "familyName": "Michael", "additionalName": "", "givenName": "H\u00f6hle", "email": ""}], "title": "Monitoring Count Time Series in R: Aberration Detection in Public Health\n  Surveillance", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1292", "oai:arXiv.org:1411.1292"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  Public health surveillance aims at lessening disease burden, e.g., in case of\ninfectious diseases by timely recognizing emerging outbreaks. Seen from a\nstatistical perspective, this implies the use of appropriate methods for\nmonitoring time series of aggregated case reports. This paper presents the\ntools for such automatic aberration detection offered by the R package\nsurveillance. We introduce the functionality for the visualization, modelling\nand monitoring of surveillance time series. With respect to modelling we focus\non univariate time series modelling based on generalized linear models (GLMs),\nmultivariate GLMs, generalized additive models and generalized additive models\nfor location, shape and scale. This ranges from illustrating implementational\nimprovements and extensions of the well-known Farrington algorithm, e.g, by\nspline-modelling or by treating it in a Bayesian context. Furthermore, we look\nat categorical time series and address overdispersion using beta-binomial or\nDirichlet-Multinomial modelling. With respect to monitoring we consider\ndetectors based on either a Shewhart-like single timepoint comparison between\nthe observed count and the predictive distribution or by likelihood-ratio based\ncumulative sum methods. Finally, we illustrate how surveillance can support\naberration detection in practice by integrating it into the monitoring workflow\nof a public health institution. Altogether, the present article shows how well\nsurveillance can support automatic aberration detection in a public health\nsurveillance context.\n"}}], "languages": [null], "subjects": ["statistics - computation"], "providerUpdatedDateTime": "2014-11-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1292"}}, {"publisher": {"name": ""}, "description": "  In order to characterize the channel capacity of a wavelength channel in a\nwavelength-division multiplexed (WDM) system, statistical models are needed for\nthe transmitted signals on the other wavelengths. For example, one could assume\nthat the transmitters for all wavelengths are configured independently of each\nother, that they use the same signal power, or that they use the same\nmodulation format. In this paper, it is shown that these so-called behavioral\nmodels have a profound impact on the single-wavelength channel capacity. This\nis demonstrated by establishing, for the first time, upper and lower bounds on\nthe channel capacity under various behavioral models, for a rudimentary WDM\nchannel model.\n", "contributors": [{"name": "Agrell, Erik", "sameAs": [], "familyName": "Agrell", "additionalName": "", "givenName": "Erik", "email": ""}, {"name": "Karlsson, Magnus", "sameAs": [], "familyName": "Karlsson", "additionalName": "", "givenName": "Magnus", "email": ""}], "title": "Influence of Behavioral Models on Multiuser Channel Capacity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00950", "oai:arXiv.org:1501.00950"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:physics"]}}, {"name": "description", "properties": {"description": "  In order to characterize the channel capacity of a wavelength channel in a\nwavelength-division multiplexed (WDM) system, statistical models are needed for\nthe transmitted signals on the other wavelengths. For example, one could assume\nthat the transmitters for all wavelengths are configured independently of each\nother, that they use the same signal power, or that they use the same\nmodulation format. In this paper, it is shown that these so-called behavioral\nmodels have a profound impact on the single-wavelength channel capacity. This\nis demonstrated by establishing, for the first time, upper and lower bounds on\nthe channel capacity under various behavioral models, for a rudimentary WDM\nchannel model.\n"}}], "languages": [null], "subjects": ["physics - optics", "computer science - information theory"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00950"}}, {"publisher": {"name": ""}, "description": "  Motivation: Models of discrete concurrent systems often lead to huge and\ncomplex state transition graphs that represent their dynamics. This makes\ndifficult to analyse dynamical properties. In particular, for logical models of\nbiological regulatory networks, it is of real interest to study attractors and\ntheir reachability from specific initial conditions, i.e. to assess the\npotential asymptotical behaviours of the system. Beyond the identification of\nthe reachable attractors, we propose to quantify this reachability.\n  Results: Relying on the structure of the state transition graph, we estimate\nthe probability of each attractor reachable from a given initial condition or\nfrom a portion of the state space. First, we present a quasi-exact solution\nwith an original algorithm called Firefront, based on the exhaustive\nexploration of the reachable state space. Then, we introduce an adapted version\nof Monte Carlo simulation algorithm, termed Avatar, better suited to larger\nmodels. Firefront and Avatar methods are validated and compared to other\nrelated approaches, using as test cases logical models of synthetic and\nbiological networks.\n  Availability: Both algorithms are implemented as Perl scripts that can be\nfreely downloaded from http://compbio.igc.gulbenkian.pt/nmd/node/59 along with\nSupplementary Material.\n", "contributors": [{"name": "Mendes, Nuno D.", "sameAs": [], "familyName": "Mendes", "additionalName": "D.", "givenName": "Nuno", "email": ""}, {"name": "Monteiro, Pedro T.", "sameAs": [], "familyName": "Monteiro", "additionalName": "T.", "givenName": "Pedro", "email": ""}, {"name": "Carneiro, Jorge", "sameAs": [], "familyName": "Carneiro", "additionalName": "", "givenName": "Jorge", "email": ""}, {"name": "Remy, Elisabeth", "sameAs": [], "familyName": "Remy", "additionalName": "", "givenName": "Elisabeth", "email": ""}, {"name": "Chaouiya, Claudine", "sameAs": [], "familyName": "Chaouiya", "additionalName": "", "givenName": "Claudine", "email": ""}], "title": "Quantification of reachable attractors in asynchronous discrete dynamics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3539", "oai:arXiv.org:1411.3539"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": ["  Motivation: Models of discrete concurrent systems often lead to huge and\ncomplex state transition graphs that represent their dynamics. This makes\ndifficult to analyse dynamical properties. In particular, for logical models of\nbiological regulatory networks, it is of real interest to study attractors and\ntheir reachability from specific initial conditions, i.e. to assess the\npotential asymptotical behaviours of the system. Beyond the identification of\nthe reachable attractors, we propose to quantify this reachability.\n  Results: Relying on the structure of the state transition graph, we estimate\nthe probability of each attractor reachable from a given initial condition or\nfrom a portion of the state space. First, we present a quasi-exact solution\nwith an original algorithm called Firefront, based on the exhaustive\nexploration of the reachable state space. Then, we introduce an adapted version\nof Monte Carlo simulation algorithm, termed Avatar, better suited to larger\nmodels. Firefront and Avatar methods are validated and compared to other\nrelated approaches, using as test cases logical models of synthetic and\nbiological networks.\n  Availability: Both algorithms are implemented as Perl scripts that can be\nfreely downloaded from http://compbio.igc.gulbenkian.pt/nmd/node/59 along with\nSupplementary Material.\n", "Comment: 19 pages, 2 figures, 2 algorithms and 2 tables"]}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "quantitative biology - molecular networks"], "providerUpdatedDateTime": "2014-11-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3539"}}, {"publisher": {"name": ""}, "description": "  Deep learning can achieve outstanding results in various fields. However, it\nrequires so significant computational power that graphics processing units\n(GPUs) and/or numerous computers are often required for the practical\napplication. We have developed a new distributed calculation framework called\n\"Sashimi\" that allows any computer to be used as a distribution node only by\naccessing a website. We have also developed a new JavaScript neural network\nframework called \"Sukiyaki\" that uses general purpose GPUs with web browsers.\nSukiyaki performs 30 times faster than a conventional JavaScript library for\ndeep convolutional neural networks (deep CNNs) learning. The combination of\nSashimi and Sukiyaki, as well as new distribution algorithms, demonstrates the\ndistributed deep learning of deep CNNs only with web browsers on various\ndevices. The libraries that comprise the proposed methods are available under\nMIT license at http://mil-tokyo.github.io/.\n", "contributors": [{"name": "Miura, Ken", "sameAs": [], "familyName": "Miura", "additionalName": "", "givenName": "Ken", "email": ""}, {"name": "Harada, Tatsuya", "sameAs": [], "familyName": "Harada", "additionalName": "", "givenName": "Tatsuya", "email": ""}], "title": "Implementation of a Practical Distributed Calculation System with\n  Browsers and JavaScript, and Application to Distributed Deep Learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.05743", "oai:arXiv.org:1503.05743"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  Deep learning can achieve outstanding results in various fields. However, it\nrequires so significant computational power that graphics processing units\n(GPUs) and/or numerous computers are often required for the practical\napplication. We have developed a new distributed calculation framework called\n\"Sashimi\" that allows any computer to be used as a distribution node only by\naccessing a website. We have also developed a new JavaScript neural network\nframework called \"Sukiyaki\" that uses general purpose GPUs with web browsers.\nSukiyaki performs 30 times faster than a conventional JavaScript library for\ndeep convolutional neural networks (deep CNNs) learning. The combination of\nSashimi and Sukiyaki, as well as new distribution algorithms, demonstrates the\ndistributed deep learning of deep CNNs only with web browsers on various\ndevices. The libraries that comprise the proposed methods are available under\nMIT license at http://mil-tokyo.github.io/.\n"}}], "languages": [null], "subjects": ["computer science - learning", "computer science - mathematical software", "and cluster computing", "computer science - distributed", "computer science - neural and evolutionary computing", "parallel", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.05743"}}, {"publisher": {"name": ""}, "description": "  Dropout is a simple but effective technique for learning in neural networks\nand other settings. A sound theoretical understanding of dropout is needed to\ndetermine when dropout should be applied and how to use it most effectively. In\nthis paper we continue the exploration of dropout as a regularizer pioneered by\nWager, et.al. We focus on linear classification where a convex proxy to the\nmisclassification loss (i.e. the logistic loss used in logistic regression) is\nminimized. We show: (a) when the dropout-regularized criterion has a unique\nminimizer, (b) when the dropout-regularization penalty goes to infinity with\nthe weights, and when it remains bounded, (c) that the dropout regularization\ncan be non-monotonic as individual weights increase from 0, and (d) that the\ndropout regularization penalty may not be convex. This last point is\nparticularly surprising because the combination of dropout regularization with\nany convex loss proxy is always a convex function.\n  In order to contrast dropout regularization with $L_2$ regularization, we\nformalize the notion of when different sources are more compatible with\ndifferent regularizers. We then exhibit distributions that are provably more\ncompatible with dropout regularization than $L_2$ regularization, and vice\nversa. These sources provide additional insight into how the inductive biases\nof dropout and $L_2$ regularization differ. We provide some similar results for\n$L_1$ regularization.\n", "contributors": [{"name": "Helmbold, David P.", "sameAs": [], "familyName": "Helmbold", "additionalName": "P.", "givenName": "David", "email": ""}, {"name": "Long, Philip M.", "sameAs": [], "familyName": "Long", "additionalName": "M.", "givenName": "Philip", "email": ""}], "title": "On the Inductive Bias of Dropout", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-15", "2015-02-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4736", "oai:arXiv.org:1412.4736"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  Dropout is a simple but effective technique for learning in neural networks\nand other settings. A sound theoretical understanding of dropout is needed to\ndetermine when dropout should be applied and how to use it most effectively. In\nthis paper we continue the exploration of dropout as a regularizer pioneered by\nWager, et.al. We focus on linear classification where a convex proxy to the\nmisclassification loss (i.e. the logistic loss used in logistic regression) is\nminimized. We show: (a) when the dropout-regularized criterion has a unique\nminimizer, (b) when the dropout-regularization penalty goes to infinity with\nthe weights, and when it remains bounded, (c) that the dropout regularization\ncan be non-monotonic as individual weights increase from 0, and (d) that the\ndropout regularization penalty may not be convex. This last point is\nparticularly surprising because the combination of dropout regularization with\nany convex loss proxy is always a convex function.\n  In order to contrast dropout regularization with $L_2$ regularization, we\nformalize the notion of when different sources are more compatible with\ndifferent regularizers. We then exhibit distributions that are provably more\ncompatible with dropout regularization than $L_2$ regularization, and vice\nversa. These sources provide additional insight into how the inductive biases\nof dropout and $L_2$ regularization differ. We provide some similar results for\n$L_1$ regularization.\n"}}], "languages": [null], "subjects": ["mathematics - statistics theory", "computer science - artificial intelligence", "computer science - learning", "computer science - neural and evolutionary computing", "statistics - machine learning"], "providerUpdatedDateTime": "2015-02-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4736"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "On March 23rd 1969 Boston's public television station WGBH broadcast a program titled The Medium is the Medium. The program was a half-hour long compilation of short videos by six artists. The six pieces ranged from electronically manipulated imagery set to the music of the Beatles to an attempt at communication between four separate locations through audio-visual technology. As the narrator, David Oppenheim, the cultural executive producer for the Public Television Laboratory, intones at the beginning of the show, \"what happens when artists explore television?\" What happened was a program unlike anything seen before. The Medium is the Medium was the result of the pairing of artists with engineers. This pairing was the brainchild of the Rockefeller Foundation, which decided to bring these two together in what was the Artists-in-Television program. Founded in 1967 it gave seed grants to two public broadcasting stations, WGBH in Boston and KQED in San Francisco. These grants enabled the stations to begin residency programs matching artists with members of their production staffs. Several of the artists in the program had made films but most were coming to this type of time-based art work for the first time. The Artists-in Television program gave these artists the opportunity to expand their ideas into an art from involving television technologies. It offered those working in more traditional media the technology and expertise to try their hands at a nascent art form, video.", "contributors": [{"name": "Nadeau, James A. (James Andrew)", "sameAs": [], "familyName": "Nadeau", "additionalName": "A.", "givenName": "James", "email": ""}, {"name": "Massachusetts Institute of Technology. Dept. of Comparative Media Studies.", "sameAs": [], "familyName": "Studies.", "additionalName": "Institute of Technology. Dept. of Comparative Media", "givenName": "Massachusetts", "email": ""}, {"name": "William Uricchio.", "sameAs": [], "familyName": "Uricchio.", "additionalName": "", "givenName": "William", "email": ""}], "title": "The medium is the medium : the convergence of video, art and television at WGBH (1969)", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "77 leaves"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/39146", "123349020", "oai:dspace.mit.edu:1721.1/39146"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2007-10-19T20:23:11Z", "2007-10-19T20:23:11Z", "2006", "2006"]}}, {"name": "description", "properties": {"description": ["On March 23rd 1969 Boston's public television station WGBH broadcast a program titled The Medium is the Medium. The program was a half-hour long compilation of short videos by six artists. The six pieces ranged from electronically manipulated imagery set to the music of the Beatles to an attempt at communication between four separate locations through audio-visual technology. As the narrator, David Oppenheim, the cultural executive producer for the Public Television Laboratory, intones at the beginning of the show, \"what happens when artists explore television?\" What happened was a program unlike anything seen before. The Medium is the Medium was the result of the pairing of artists with engineers. This pairing was the brainchild of the Rockefeller Foundation, which decided to bring these two together in what was the Artists-in-Television program. Founded in 1967 it gave seed grants to two public broadcasting stations, WGBH in Boston and KQED in San Francisco. These grants enabled the stations to begin residency programs matching artists with members of their production staffs. Several of the artists in the program had made films but most were coming to this type of time-based art work for the first time. The Artists-in Television program gave these artists the opportunity to expand their ideas into an art from involving television technologies. It offered those working in more traditional media the technology and expertise to try their hands at a nascent art form, video.", "by James A. Nadeau.", "Thesis (S.M.)--Massachusetts Institute of Technology, Dept. of Comparative Media Studies, 2006.", "Leaf 77 blank.", "Includes bibliographical references (leaves 74-76)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39100", "hdl_1721.1_39097"]}}], "languages": [null], "subjects": ["comparative media studies."], "providerUpdatedDateTime": "2015-04-27T14:44:35", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/39146"}}, {"publisher": {"name": ""}, "description": "  Occlusion edges in images which correspond to range discontinuity in the\nscene from the point of view of the observer are an important prerequisite for\nmany vision and mobile robot tasks. Although they can be extracted from range\ndata however extracting them from images and videos would be extremely\nbeneficial. We trained a deep convolutional neural network (CNN) to identify\nocclusion edges in images and videos with both RGB-D and RGB inputs. The use of\nCNN avoids hand-crafting of features for automatically isolating occlusion\nedges and distinguishing them from appearance edges. Other than quantitative\nocclusion edge detection results, qualitative results are provided to\ndemonstrate the trade-off between high resolution analysis and frame-level\ncomputation time which is critical for real-time robotics applications.\n", "contributors": [{"name": "Sarkar, Soumik", "sameAs": [], "familyName": "Sarkar", "additionalName": "", "givenName": "Soumik", "email": ""}, {"name": "Venugopalan, Vivek", "sameAs": [], "familyName": "Venugopalan", "additionalName": "", "givenName": "Vivek", "email": ""}, {"name": "Reddy, Kishore", "sameAs": [], "familyName": "Reddy", "additionalName": "", "givenName": "Kishore", "email": ""}, {"name": "Giering, Michael", "sameAs": [], "familyName": "Giering", "additionalName": "", "givenName": "Michael", "email": ""}, {"name": "Ryde, Julian", "sameAs": [], "familyName": "Ryde", "additionalName": "", "givenName": "Julian", "email": ""}, {"name": "Jaitly, Navdeep", "sameAs": [], "familyName": "Jaitly", "additionalName": "", "givenName": "Navdeep", "email": ""}], "title": "Occlusion Edge Detection in RGB-D Frames using Deep Convolutional\n  Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7007", "oai:arXiv.org:1412.7007"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Occlusion edges in images which correspond to range discontinuity in the\nscene from the point of view of the observer are an important prerequisite for\nmany vision and mobile robot tasks. Although they can be extracted from range\ndata however extracting them from images and videos would be extremely\nbeneficial. We trained a deep convolutional neural network (CNN) to identify\nocclusion edges in images and videos with both RGB-D and RGB inputs. The use of\nCNN avoids hand-crafting of features for automatically isolating occlusion\nedges and distinguishing them from appearance edges. Other than quantitative\nocclusion edge detection results, qualitative results are provided to\ndemonstrate the trade-off between high resolution analysis and frame-level\ncomputation time which is critical for real-time robotics applications.\n", "Comment: 9 pages, v1"]}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7007"}}, {"publisher": {"name": ""}, "description": "  This paper is focused on the derivation of some universal properties of\ncapacity-approaching low-density parity-check (LDPC) code ensembles whose\ntransmission takes place over memoryless binary-input output-symmetric (MBIOS)\nchannels. Properties of the degree distributions, graphical complexity and the\nnumber of fundamental cycles in the bipartite graphs are considered via the\nderivation of information-theoretic bounds. These bounds are expressed in terms\nof the target block/ bit error probability and the gap (in rate) to capacity.\nMost of the bounds are general for any decoding algorithm, and some others are\nproved under belief propagation (BP) decoding. Proving these bounds under a\ncertain decoding algorithm, validates them automatically also under any\nsub-optimal decoding algorithm. A proper modification of these bounds makes\nthem universal for the set of all MBIOS channels which exhibit a given\ncapacity. Bounds on the degree distributions and graphical complexity apply to\nfinite-length LDPC codes and to the asymptotic case of an infinite block\nlength. The bounds are compared with capacity-approaching LDPC code ensembles\nunder BP decoding, and they are shown to be informative and are easy to\ncalculate. Finally, some interesting open problems are considered.\n", "contributors": [{"name": "Sason, Igal", "sameAs": [], "familyName": "Sason", "additionalName": "", "givenName": "Igal", "email": ""}], "title": "On Universal Properties of Capacity-Approaching LDPC Ensembles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2007-09-05", "2015-02-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/0709.0599", "oai:arXiv.org:0709.0599"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper is focused on the derivation of some universal properties of\ncapacity-approaching low-density parity-check (LDPC) code ensembles whose\ntransmission takes place over memoryless binary-input output-symmetric (MBIOS)\nchannels. Properties of the degree distributions, graphical complexity and the\nnumber of fundamental cycles in the bipartite graphs are considered via the\nderivation of information-theoretic bounds. These bounds are expressed in terms\nof the target block/ bit error probability and the gap (in rate) to capacity.\nMost of the bounds are general for any decoding algorithm, and some others are\nproved under belief propagation (BP) decoding. Proving these bounds under a\ncertain decoding algorithm, validates them automatically also under any\nsub-optimal decoding algorithm. A proper modification of these bounds makes\nthem universal for the set of all MBIOS channels which exhibit a given\ncapacity. Bounds on the degree distributions and graphical complexity apply to\nfinite-length LDPC codes and to the asymptotic case of an infinite block\nlength. The bounds are compared with capacity-approaching LDPC code ensembles\nunder BP decoding, and they are shown to be informative and are easy to\ncalculate. Finally, some interesting open problems are considered.\n", "Comment: Published in the IEEE Trans. on Information Theory, vol. 55, no. 7,\n  pp. 2956 - 2990, July 2009"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-02-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/0709.0599"}}, {"publisher": {"name": ""}, "description": "  Energy harvesting (EH) and network coding (NC) have emerged as two promising\ntechnologies for future wireless networks. In this paper, we combine them\ntogether in a single system and then present a time switching-based network\ncoding relaying (TSNCR) protocol for the two-way relay system, where an energy\nconstrained relay harvests energy from the transmitted radio frequency (RF)\nsignals from two sources, and then helps the two-way relay information exchange\nbetween the two sources with the consumption of the harvested energy. To\nevaluate the system performance, we derive an explicit expression of the outage\nprobability for the proposed TSNCR protocol. In order to explore the system\nperformance limit, we formulate an optimization problem to minimize the system\noutage probability. Since the problem is non-convex and cannot be directly\nsolved, we design a genetic algorithm (GA)-based optimization algorithm for it.\nNumerical results validate our theoretical analysis and show that in such an EH\ntwo-way relay system, if NC is applied, the system outage probability can be\ngreatly decreased. Moreover, it is shown that the relay position greatly\naffects the system performance of TSNCR, where relatively worse outage\nperformance is achieved when the relay is placed in the middle of the two\nsources. This is the first time to observe such a phenomena in EH two-way relay\nsystems.\n", "contributors": [{"name": "Du, Guanyao", "sameAs": [], "familyName": "Du", "additionalName": "", "givenName": "Guanyao", "email": ""}, {"name": "Xiong, Ke", "sameAs": [], "familyName": "Xiong", "additionalName": "", "givenName": "Ke", "email": ""}, {"name": "Zhang, Yu", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Yu", "email": ""}, {"name": "Qiu, Zhengding", "sameAs": [], "familyName": "Qiu", "additionalName": "", "givenName": "Zhengding", "email": ""}], "title": "Outage Analysis and Optimization for Time Switching-based Two-Way\n  Relaying with Energy Harvesting Relay Node", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7785", "oai:arXiv.org:1412.7785"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Energy harvesting (EH) and network coding (NC) have emerged as two promising\ntechnologies for future wireless networks. In this paper, we combine them\ntogether in a single system and then present a time switching-based network\ncoding relaying (TSNCR) protocol for the two-way relay system, where an energy\nconstrained relay harvests energy from the transmitted radio frequency (RF)\nsignals from two sources, and then helps the two-way relay information exchange\nbetween the two sources with the consumption of the harvested energy. To\nevaluate the system performance, we derive an explicit expression of the outage\nprobability for the proposed TSNCR protocol. In order to explore the system\nperformance limit, we formulate an optimization problem to minimize the system\noutage probability. Since the problem is non-convex and cannot be directly\nsolved, we design a genetic algorithm (GA)-based optimization algorithm for it.\nNumerical results validate our theoretical analysis and show that in such an EH\ntwo-way relay system, if NC is applied, the system outage probability can be\ngreatly decreased. Moreover, it is shown that the relay position greatly\naffects the system performance of TSNCR, where relatively worse outage\nperformance is achieved when the relay is placed in the middle of the two\nsources. This is the first time to observe such a phenomena in EH two-way relay\nsystems.\n", "Comment: 19 pages,7 figures,to appear in KSII Transactions on Internet and\n  Information System"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7785"}}, {"publisher": {"name": ""}, "description": "  We define the Cartesian product, composition, union and join on\ninterval-valued fuzzy graphs and investigate some of their properties. We also\nintroduce the notion of interval-valued fuzzy complete graphs and present some\nproperties of self complementary and self weak complementary interval-valued\nfuzzy complete graphs.\n", "contributors": [{"name": "Akram, Muhammad", "sameAs": [], "familyName": "Akram", "additionalName": "", "givenName": "Muhammad", "email": ""}, {"name": "Dudek, Wieslaw A.", "sameAs": [], "familyName": "Dudek", "additionalName": "A.", "givenName": "Wieslaw", "email": ""}], "title": "Interval-valued fuzzy graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-04-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.6123", "Computers and Mathematics with Applications 61 (2011), 289-299", "doi:10.1016/j.camwa.2010.11.004", "oai:arXiv.org:1205.6123"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We define the Cartesian product, composition, union and join on\ninterval-valued fuzzy graphs and investigate some of their properties. We also\nintroduce the notion of interval-valued fuzzy complete graphs and present some\nproperties of self complementary and self weak complementary interval-valued\nfuzzy complete graphs.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.6123"}}, {"publisher": {"name": ""}, "description": "  In this paper we report on an algorithm for aligning multiple protein\nstructures. The algorithm has been tested on a variety of inputs and it\nperforms well in comparison to well-known algorithms for this problem.\n", "contributors": [{"name": "Roy, Kaushik", "sameAs": [], "familyName": "Roy", "additionalName": "", "givenName": "Kaushik", "email": ""}, {"name": "Panigrahi, Satish Ch.", "sameAs": [], "familyName": "Panigrahi", "additionalName": "Ch.", "givenName": "Satish", "email": ""}, {"name": "Mukhopadhyay, Asish", "sameAs": [], "familyName": "Mukhopadhyay", "additionalName": "", "givenName": "Asish", "email": ""}], "title": "Multiple alignment of structures using center of proteins", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.8093", "oai:arXiv.org:1412.8093"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": "  In this paper we report on an algorithm for aligning multiple protein\nstructures. The algorithm has been tested on a variety of inputs and it\nperforms well in comparison to well-known algorithms for this problem.\n"}}], "languages": [null], "subjects": ["computer science - computational engineering", "finance", "and science", "quantitative biology - biomolecules"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.8093"}}, {"publisher": {"name": ""}, "description": "  We consider the incidence of text \"reuse\" by researchers, via a systematic\npairwise comparison of the text content of all articles deposited to arXiv.org\nfrom 1991--2012. We measure the global frequencies of three classes of text\nreuse, and measure how chronic text reuse is distributed among authors in the\ndataset. We infer a baseline for accepted practice, perhaps surprisingly\npermissive compared with other societal contexts, and a clearly delineated set\nof aberrant authors. We find a negative correlation between the amount of\nreused text in an article and its influence, as measured by subsequent\ncitations. Finally, we consider the distribution of countries of origin of\narticles containing large amounts of reused text.\n", "contributors": [{"name": "Citron, Daniel T.", "sameAs": [], "familyName": "Citron", "additionalName": "T.", "givenName": "Daniel", "email": ""}, {"name": "Ginsparg, Paul", "sameAs": [], "familyName": "Ginsparg", "additionalName": "", "givenName": "Paul", "email": ""}], "title": "Patterns of Text Reuse in a Scientific Corpus", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2716", "doi:10.1073/pnas.1415135111", "oai:arXiv.org:1412.2716"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We consider the incidence of text \"reuse\" by researchers, via a systematic\npairwise comparison of the text content of all articles deposited to arXiv.org\nfrom 1991--2012. We measure the global frequencies of three classes of text\nreuse, and measure how chronic text reuse is distributed among authors in the\ndataset. We infer a baseline for accepted practice, perhaps surprisingly\npermissive compared with other societal contexts, and a clearly delineated set\nof aberrant authors. We find a negative correlation between the amount of\nreused text in an article and its influence, as measured by subsequent\ncitations. Finally, we consider the distribution of countries of origin of\narticles containing large amounts of reused text.\n", "Comment: 6 pages, plus 10 pages of supplementary material. To appear in PNAS\n  (online 8 Dec 2014)"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - digital libraries"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2716"}}, {"publisher": {"name": ""}, "description": "  In this paper, we explore the physical-layer security of a multi-user\nwireless system that consists of multiple users intending to transmit to a base\nstation (BS), while multiple eavesdroppers attempt to tap the user\ntransmissions. We examine the employment of multi-user scheduling for improving\nthe transmission security against eavesdropping and propose a multi-user\nscheduling scheme, which only requires the channel state information (CSI) of\nBS without the need of the passive eavesdroppers' CSI. We also consider the\nround-robin scheduling for comparison purposes. The closed-form secrecy outage\nprobability expressions of the round-robin scheduling and proposed multi-user\nscheduling are derived over Rayleigh fading channels. Numerical results\ndemonstrate that the proposed multi-user scheduling outperforms the round-robin\nscheduling in terms of the secrecy outage probability. As the number of users\nincreases, the secrecy outage probability of round-robin scheduling keeps\nunchanged. By contrast, the secrecy outage performance of the proposed\nmulti-user scheduling improves significantly with an increasing number of\nusers.\n", "contributors": [{"name": "Zou, Yulong", "sameAs": [], "familyName": "Zou", "additionalName": "", "givenName": "Yulong", "email": ""}, {"name": "Zhu, Jia", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "Jia", "email": ""}, {"name": "Wang, Gongpu", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Gongpu", "email": ""}, {"name": "Shao, Hua", "sameAs": [], "familyName": "Shao", "additionalName": "", "givenName": "Hua", "email": ""}], "title": "Secrecy Outage Probability Analysis of Multi-User Multi-Eavesdropper\n  Wireless Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0220", "IEEE/CIC International Conference on Communications in China,\n  Shanghai, China, October 13-15, 2014", "oai:arXiv.org:1411.0220"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we explore the physical-layer security of a multi-user\nwireless system that consists of multiple users intending to transmit to a base\nstation (BS), while multiple eavesdroppers attempt to tap the user\ntransmissions. We examine the employment of multi-user scheduling for improving\nthe transmission security against eavesdropping and propose a multi-user\nscheduling scheme, which only requires the channel state information (CSI) of\nBS without the need of the passive eavesdroppers' CSI. We also consider the\nround-robin scheduling for comparison purposes. The closed-form secrecy outage\nprobability expressions of the round-robin scheduling and proposed multi-user\nscheduling are derived over Rayleigh fading channels. Numerical results\ndemonstrate that the proposed multi-user scheduling outperforms the round-robin\nscheduling in terms of the secrecy outage probability. As the number of users\nincreases, the secrecy outage probability of round-robin scheduling keeps\nunchanged. By contrast, the secrecy outage performance of the proposed\nmulti-user scheduling improves significantly with an increasing number of\nusers.\n", "Comment: 5 pages"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0220"}}, {"publisher": {"name": ""}, "description": "  This paper explores the process calculus $\\text{CLL}_R$ furtherly.\n  First, we prove that for any equation $X=_{RS} t_X$ such that $X$ is strongly\nguarded in $t_X$, $\\langle X|X=t_X \\rangle$ is the largest solution w.r.t\n$\\sqsubseteq_{RS}$.\n  Second, we encode a fragment of action-based CTL in $\\text{CLL}_R$.\n", "contributors": [{"name": "Zhang, Yan", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Yan", "email": ""}, {"name": "Zhu, Zhaohui", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "Zhaohui", "email": ""}, {"name": "Zhang, Jinjin", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Jinjin", "email": ""}], "title": "Greatest solutions of equations in $\\text{CLL}_R$ and its application", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0756", "oai:arXiv.org:1411.0756"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper explores the process calculus $\\text{CLL}_R$ furtherly.\n  First, we prove that for any equation $X=_{RS} t_X$ such that $X$ is strongly\nguarded in $t_X$, $\\langle X|X=t_X \\rangle$ is the largest solution w.r.t\n$\\sqsubseteq_{RS}$.\n  Second, we encode a fragment of action-based CTL in $\\text{CLL}_R$.\n", "Comment: 13 pages. arXiv admin note: text overlap with arXiv:1301.3350"]}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2014-11-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0756"}}, {"publisher": {"name": ""}, "description": "  Modern online social platforms enable their members to be involved in a broad\nrange of activities like getting friends, joining groups, posting/commenting\nresources and so on. In this paper we investigate whether a correlation emerges\nacross the different activities a user can take part in. To perform our\nanalysis we focused on aNobii, a social platform with a world-wide user base of\nbook readers, who like to post their readings, give ratings, review books and\ndiscuss them with friends and fellow readers. aNobii presents a heterogeneous\nstructure: i) part social network, with user-to-user interactions, ii) part\ninterest network, with the management of book collections, and iii) part\nfolksonomy, with books that are tagged by the users. We analyzed a complete and\nanonymized snapshot of aNobii and we focused on three specific activities a\nuser can perform, namely her tagging behavior, her tendency to join groups and\nher aptitude to compile a wishlist reporting the books she is planning to read.\nIn this way each user is associated with a tag-based, a group-based and a\nwishlist-based profile. Experimental analysis carried out by means of\nInformation Theory tools like entropy and mutual information suggests that\ntag-based and group-based profiles are in general more informative than\nwishlist-based ones. Furthermore, we discover that the degree of correlation\nbetween the three profiles associated with the same user tend to be small.\nHence, user profiling cannot be reduced to considering just any one type of\nuser activity (although important) but it is crucial to incorporate multiple\ndimensions to effectively describe users preferences and behavior.\n", "contributors": [{"name": "Agreste, Santa", "sameAs": [], "familyName": "Agreste", "additionalName": "", "givenName": "Santa", "email": ""}, {"name": "De Meo, Pasquale", "sameAs": [], "familyName": "De Meo", "additionalName": "", "givenName": "Pasquale", "email": ""}, {"name": "Ferrara, Emilio", "sameAs": [], "familyName": "Ferrara", "additionalName": "", "givenName": "Emilio", "email": ""}, {"name": "Piccolo, Sebastiano", "sameAs": [], "familyName": "Piccolo", "additionalName": "", "givenName": "Sebastiano", "email": ""}, {"name": "Provetti, Alessandro", "sameAs": [], "familyName": "Provetti", "additionalName": "", "givenName": "Alessandro", "email": ""}], "title": "Analysis of a heterogeneous social network of humans and cultural\n  objects", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-02-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.1778", "IEEE Transactions on Systems, Man, and Cybernetics: Systems,\n  vol.45, no.4, pp.559,570, April 2015", "doi:10.1109/TSMC.2014.2378215", "oai:arXiv.org:1402.1778"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Modern online social platforms enable their members to be involved in a broad\nrange of activities like getting friends, joining groups, posting/commenting\nresources and so on. In this paper we investigate whether a correlation emerges\nacross the different activities a user can take part in. To perform our\nanalysis we focused on aNobii, a social platform with a world-wide user base of\nbook readers, who like to post their readings, give ratings, review books and\ndiscuss them with friends and fellow readers. aNobii presents a heterogeneous\nstructure: i) part social network, with user-to-user interactions, ii) part\ninterest network, with the management of book collections, and iii) part\nfolksonomy, with books that are tagged by the users. We analyzed a complete and\nanonymized snapshot of aNobii and we focused on three specific activities a\nuser can perform, namely her tagging behavior, her tendency to join groups and\nher aptitude to compile a wishlist reporting the books she is planning to read.\nIn this way each user is associated with a tag-based, a group-based and a\nwishlist-based profile. Experimental analysis carried out by means of\nInformation Theory tools like entropy and mutual information suggests that\ntag-based and group-based profiles are in general more informative than\nwishlist-based ones. Furthermore, we discover that the degree of correlation\nbetween the three profiles associated with the same user tend to be small.\nHence, user profiling cannot be reduced to considering just any one type of\nuser activity (although important) but it is crucial to incorporate multiple\ndimensions to effectively describe users preferences and behavior.\n", "Comment: 12 pages, 9 figures - Transactions on Systems, Man and Cybernetics:\n  Systems - under review"]}}], "languages": [null], "subjects": ["physics - data analysis", "computer science - computers and society", "statistics and probability", "physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-04-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.1778"}}, {"publisher": {"name": ""}, "description": "  Existing MAP inference algorithms for determinantal point processes (DPPs)\nneed to calculate determinants or conduct eigenvalue decomposition generally at\nthe scale of the full kernel, which presents a great challenge for real-world\napplications. In this paper, we introduce a class of DPPs, called BwDPPs, that\nare characterized by an almost block diagonal kernel matrix and thus can allow\nefficient block-wise MAP inference. Furthermore, BwDPPs are successfully\napplied to address the difficulty of selecting change-points in the problem of\nchange-point detection (CPD), which results in a new BwDPP-based CPD method,\nnamed BwDppCpd. In BwDppCpd, a preliminary set of change-point candidates is\nfirst created based on existing well-studied metrics. Then, these change-point\ncandidates are treated as DPP items, and DPP-based subset selection is\nconducted to give the final estimate of the change-points that favours both\nquality and diversity. The effectiveness of BwDppCpd is demonstrated through\nextensive experiments on five real-world datasets.\n", "contributors": [{"name": "Zhang, Jinye", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Jinye", "email": ""}, {"name": "Ou, Zhijian", "sameAs": [], "familyName": "Ou", "additionalName": "", "givenName": "Zhijian", "email": ""}], "title": "Block-Wise MAP Inference for Determinantal Point Processes with\n  Application to Change-Point Detection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06239", "oai:arXiv.org:1503.06239"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  Existing MAP inference algorithms for determinantal point processes (DPPs)\nneed to calculate determinants or conduct eigenvalue decomposition generally at\nthe scale of the full kernel, which presents a great challenge for real-world\napplications. In this paper, we introduce a class of DPPs, called BwDPPs, that\nare characterized by an almost block diagonal kernel matrix and thus can allow\nefficient block-wise MAP inference. Furthermore, BwDPPs are successfully\napplied to address the difficulty of selecting change-points in the problem of\nchange-point detection (CPD), which results in a new BwDPP-based CPD method,\nnamed BwDppCpd. In BwDppCpd, a preliminary set of change-point candidates is\nfirst created based on existing well-studied metrics. Then, these change-point\ncandidates are treated as DPP items, and DPP-based subset selection is\nconducted to give the final estimate of the change-points that favours both\nquality and diversity. The effectiveness of BwDppCpd is demonstrated through\nextensive experiments on five real-world datasets.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - learning", "statistics - machine learning", "statistics - methodology"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06239"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Designing systems in a service-oriented manner, in which application features are decoupled and run as independently executing services over a network, is becoming more commonplace and popular. Service-oriented programming provides a natural way to model and manage many types of systems and allows software development teams to achieve operational flexibility, scalability, and reliability in a cost-effective manner. In particular, it has been used quite successfully for Web and mobile applications. However, building, deploying, and maintaining service-oriented systems is challenging and requires extensive planning, more effort during development, a detailed understanding of advanced networking techniques, and the use of complicated concurrent programming. This thesis presents a new programming language called Silo. Silo integrates features that address key conceptual and pragmatic needs of service-oriented systems that, holistically, are not easily satisfied by existing languages. Broadly, these needs include: a unified distributed programming model, a simple yet ecient construct for concurrency, a familiar yet extensible syntax, and the ability to interoperate with a rich ecosystem of libraries and tools. In this dissertation, I describe how Silo's features, constructs, and conventions satisfy these needs. Then, I present various compiler and runtime techniques used in Silo's implementation. Lastly, I provide a demonstration, through a variety of programming patterns and applications, of how Silo facilitates the design, implementation, and management of service-oriented systems.", "contributors": [{"name": "Ahmad, Salman Azeem", "sameAs": [], "familyName": "Ahmad", "additionalName": "Azeem", "givenName": "Salman", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Electrical Engineering and Computer Science.", "sameAs": [], "familyName": "Science.", "additionalName": "Institute of Technology. Department of Electrical Engineering and Computer", "givenName": "Massachusetts", "email": ""}, {"name": "Sepandar D. Kamvar.", "sameAs": [], "familyName": "Kamvar.", "additionalName": "D.", "givenName": "Sepandar", "email": ""}], "title": "Programming language design for service-oriented systems", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "187 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/92961", "899983837", "oai:dspace.mit.edu:1721.1/92961"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2015-01-20T15:30:04Z", "2015-01-20T15:30:04Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["Designing systems in a service-oriented manner, in which application features are decoupled and run as independently executing services over a network, is becoming more commonplace and popular. Service-oriented programming provides a natural way to model and manage many types of systems and allows software development teams to achieve operational flexibility, scalability, and reliability in a cost-effective manner. In particular, it has been used quite successfully for Web and mobile applications. However, building, deploying, and maintaining service-oriented systems is challenging and requires extensive planning, more effort during development, a detailed understanding of advanced networking techniques, and the use of complicated concurrent programming. This thesis presents a new programming language called Silo. Silo integrates features that address key conceptual and pragmatic needs of service-oriented systems that, holistically, are not easily satisfied by existing languages. Broadly, these needs include: a unified distributed programming model, a simple yet ecient construct for concurrency, a familiar yet extensible syntax, and the ability to interoperate with a rich ecosystem of libraries and tools. In this dissertation, I describe how Silo's features, constructs, and conventions satisfy these needs. Then, I present various compiler and runtime techniques used in Silo's implementation. Lastly, I provide a demonstration, through a variety of programming patterns and applications, of how Silo facilitates the design, implementation, and management of service-oriented systems.", "by Salman Azeem Ahmad.", "Thesis: Ph. D., Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2014.", "This electronic version was submitted by the student author.  The certified thesis is available in the Institute Archives and Special Collections.", "Cataloged from student-submitted PDF version of thesis.", "Includes bibliographical references (pages 179-187)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7815", "hdl_1721.1_7660"]}}], "languages": [null], "subjects": ["electrical engineering and computer science."], "providerUpdatedDateTime": "2015-01-20T15:30:04", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/92961"}}, {"publisher": {"name": ""}, "description": "  We apply signal processing analysis to the information spreading in\nscale-free network. To reproduce typical behaviors obtained from the analysis\nof information spreading in the world wide web we use a modified SIS model\nwhere synergy effects and influential nodes are taken into account. This model\ndepends on a single free parameter that characterize the memory-time of the\nspreading process. We show that by means of fractal analysis it is possible\n-from aggregated easily accessible data- to gain information on the memory time\nof the underlying mechanism driving the information spreading process.\n", "contributors": [{"name": "Zoller, J.", "sameAs": [], "familyName": "Zoller", "additionalName": "", "givenName": "J.", "email": ""}, {"name": "Montangero, S.", "sameAs": [], "familyName": "Montangero", "additionalName": "", "givenName": "S.", "email": ""}], "title": "Probing models of information spreading in social networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-08-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6718", "J. Phys. A: Math. Theor. 47 435102 (2014)", "oai:arXiv.org:1408.6718"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We apply signal processing analysis to the information spreading in\nscale-free network. To reproduce typical behaviors obtained from the analysis\nof information spreading in the world wide web we use a modified SIS model\nwhere synergy effects and influential nodes are taken into account. This model\ndepends on a single free parameter that characterize the memory-time of the\nspreading process. We show that by means of fractal analysis it is possible\n-from aggregated easily accessible data- to gain information on the memory time\nof the underlying mechanism driving the information spreading process.\n", "Comment: 6 pages, 6 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-10-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6718"}}, {"publisher": {"name": ""}, "description": "  Teachable Agent (TA) is a special type of pedagogical agent which\ninstantiates the educational theory of Learning by Teaching. Soon after its\nemergence, research of TA becomes an active field, as it can solve the over\nscaffolded problem in traditional pedagogical systems, and encourage students\nto take the responsibility of learning. Apart from the benefits, existing TA\ndesign also has limitations. One is the lack of enough proactive interactions\nwith students during the learning process, and the other is the lack of\nbelievability to arouse students empathy so as to offer students an immersive\nlearning experience. To solve these two problems, we propose a new type of TA,\nAffective Teachable Agent, and use a goal oriented approach to design and\nimplement the agent system allowing agents to proactively interact with\nstudents with affective expressions. The ATA model begins with the analysis of\npedagogical requirements and teaching goals, using Learning by Teaching theory\nto design interventions which can authentically promote the learning behaviors\nof students. Two crucial capabilities of ATA are highlighted Teachability, to\nlearn new knowledge and apply the knowledge to certain tasks, and\nAffectivability, to establish good relationship with students and encourage\nthem to teach well. Through executing a hierarchy of goals, the proposed TA can\ninteract with students by pursuing its own agenda. When a student teaches the\nagent, the agent is performed as a naive learning companion, and when an\neducator teaches the agent during the design and maintenance time, the agent\ncan perform as an authoring tool. To facilitate the involvement of educators\ninto the game design, we develop an authoring tool for proposed ATA system,\nwhich can encapsulate the technical details and provide educational experts a\nnatural way to convey domain knowledge to agent knowledge base.\n", "contributors": [{"name": "Borjigin, Ailiya", "sameAs": [], "familyName": "Borjigin", "additionalName": "", "givenName": "Ailiya", "email": ""}], "title": "Teachable Agent", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02370", "oai:arXiv.org:1502.02370"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Teachable Agent (TA) is a special type of pedagogical agent which\ninstantiates the educational theory of Learning by Teaching. Soon after its\nemergence, research of TA becomes an active field, as it can solve the over\nscaffolded problem in traditional pedagogical systems, and encourage students\nto take the responsibility of learning. Apart from the benefits, existing TA\ndesign also has limitations. One is the lack of enough proactive interactions\nwith students during the learning process, and the other is the lack of\nbelievability to arouse students empathy so as to offer students an immersive\nlearning experience. To solve these two problems, we propose a new type of TA,\nAffective Teachable Agent, and use a goal oriented approach to design and\nimplement the agent system allowing agents to proactively interact with\nstudents with affective expressions. The ATA model begins with the analysis of\npedagogical requirements and teaching goals, using Learning by Teaching theory\nto design interventions which can authentically promote the learning behaviors\nof students. Two crucial capabilities of ATA are highlighted Teachability, to\nlearn new knowledge and apply the knowledge to certain tasks, and\nAffectivability, to establish good relationship with students and encourage\nthem to teach well. Through executing a hierarchy of goals, the proposed TA can\ninteract with students by pursuing its own agenda. When a student teaches the\nagent, the agent is performed as a naive learning companion, and when an\neducator teaches the agent during the design and maintenance time, the agent\ncan perform as an authoring tool. To facilitate the involvement of educators\ninto the game design, we develop an authoring tool for proposed ATA system,\nwhich can encapsulate the technical details and provide educational experts a\nnatural way to convey domain knowledge to agent knowledge base.\n"}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-02-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02370"}}, {"publisher": {"name": ""}, "description": "  We analyze a class of distributed quantized consensus algorithms for\narbitrary static networks. In the initial setting, each node in the network has\nan integer value. Nodes exchange their current estimate of the mean value in\nthe network, and then update their estimation by communicating with their\nneighbors in a limited capacity channel in an asynchronous clock setting.\nEventually, all nodes reach consensus with quantized precision. We analyze the\nexpected convergence time for the general quantized consensus algorithm\nproposed by Kashyap et al \\cite{Kashyap}. We use the theory of electric\nnetworks, random walks, and couplings of Markov chains to derive an $O(N^3\\log\nN)$ upper bound for the expected convergence time on an arbitrary graph of size\n$N$, improving on the state of art bound of $O(N^5)$ for quantized consensus\nalgorithms. Our result is not dependent on graph topology. Example of complete\ngraphs is given to show how to extend the analysis to graphs of given topology.\n", "contributors": [{"name": "Shang, Shang", "sameAs": [], "familyName": "Shang", "additionalName": "", "givenName": "Shang", "email": ""}, {"name": "Cuff, Paul", "sameAs": [], "familyName": "Cuff", "additionalName": "", "givenName": "Paul", "email": ""}, {"name": "Hui, Pan", "sameAs": [], "familyName": "Hui", "additionalName": "", "givenName": "Pan", "email": ""}, {"name": "Kulkarni, Sanjeev", "sameAs": [], "familyName": "Kulkarni", "additionalName": "", "givenName": "Sanjeev", "email": ""}], "title": "An Upper Bound on the Convergence Time for Quantized Consensus of\n  Arbitrary Static Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-09-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.6828", "IEEE Trans. on Automatic Control, 60(4):1127-32, April, 2015", "oai:arXiv.org:1409.6828"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We analyze a class of distributed quantized consensus algorithms for\narbitrary static networks. In the initial setting, each node in the network has\nan integer value. Nodes exchange their current estimate of the mean value in\nthe network, and then update their estimation by communicating with their\nneighbors in a limited capacity channel in an asynchronous clock setting.\nEventually, all nodes reach consensus with quantized precision. We analyze the\nexpected convergence time for the general quantized consensus algorithm\nproposed by Kashyap et al \\cite{Kashyap}. We use the theory of electric\nnetworks, random walks, and couplings of Markov chains to derive an $O(N^3\\log\nN)$ upper bound for the expected convergence time on an arbitrary graph of size\n$N$, improving on the state of art bound of $O(N^5)$ for quantized consensus\nalgorithms. Our result is not dependent on graph topology. Example of complete\ngraphs is given to show how to extend the analysis to graphs of given topology.\n", "Comment: to appear in IEEE Trans. on Automatic Control, January, 2015. arXiv\n  admin note: substantial text overlap with arXiv:1208.0788"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.6828"}}, {"publisher": {"name": ""}, "description": "  Cognitive radio (CR) systems allow opportunistic, secondary users (SUs) to\naccess portions of the spectrum that are unused by the network's licensed\nprimary users (PUs), provided that the induced interference does not compromise\nthe primary users' performance guarantees. To account for interference\nconstraints of this type, we consider a flexible spectrum access pricing scheme\nthat charges secondary users based on the interference that they cause to the\nsystem's primary users (individually, globally, or both), and we examine how\nsecondary users can maximize their achievable transmission rate in this\nsetting. We show that the resulting non-cooperative game admits a unique Nash\nequilibrium under very mild assumptions on the pricing mechanism employed by\nthe network operator, and under both static and ergodic (fast-fading) channel\nconditions. In addition, we derive a dynamic power allocation policy that\nconverges to equilibrium within a few iterations (even for large numbers of\nusers), and which relies only on local signal-to-interference-and-noise\nmeasurements; importantly, the proposed algorithm retains its convergence\nproperties even in the ergodic channel regime, despite the inherent\nstochasticity thereof. Our theoretical analysis is complemented by extensive\nnumerical simulations which illustrate the performance and scalability\nproperties of the proposed pricing scheme under realistic network conditions.\n", "contributors": [{"name": "D'Oro, Salvatore", "sameAs": [], "familyName": "D'Oro", "additionalName": "", "givenName": "Salvatore", "email": ""}, {"name": "Mertikopoulos, Panayotis", "sameAs": [], "familyName": "Mertikopoulos", "additionalName": "", "givenName": "Panayotis", "email": ""}, {"name": "Moustakas, Aris L.", "sameAs": [], "familyName": "Moustakas", "additionalName": "L.", "givenName": "Aris", "email": ""}, {"name": "Palazzo, Sergio", "sameAs": [], "familyName": "Palazzo", "additionalName": "", "givenName": "Sergio", "email": ""}], "title": "Cost-Efficient Throughput Maximization in Multi-Carrier Cognitive Radio\n  Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.00588", "oai:arXiv.org:1502.00588"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Cognitive radio (CR) systems allow opportunistic, secondary users (SUs) to\naccess portions of the spectrum that are unused by the network's licensed\nprimary users (PUs), provided that the induced interference does not compromise\nthe primary users' performance guarantees. To account for interference\nconstraints of this type, we consider a flexible spectrum access pricing scheme\nthat charges secondary users based on the interference that they cause to the\nsystem's primary users (individually, globally, or both), and we examine how\nsecondary users can maximize their achievable transmission rate in this\nsetting. We show that the resulting non-cooperative game admits a unique Nash\nequilibrium under very mild assumptions on the pricing mechanism employed by\nthe network operator, and under both static and ergodic (fast-fading) channel\nconditions. In addition, we derive a dynamic power allocation policy that\nconverges to equilibrium within a few iterations (even for large numbers of\nusers), and which relies only on local signal-to-interference-and-noise\nmeasurements; importantly, the proposed algorithm retains its convergence\nproperties even in the ergodic channel regime, despite the inherent\nstochasticity thereof. Our theoretical analysis is complemented by extensive\nnumerical simulations which illustrate the performance and scalability\nproperties of the proposed pricing scheme under realistic network conditions.\n", "Comment: 24 pages, 9 figures"]}}], "languages": [null], "subjects": ["computer science - computer science and game theory", "computer science - information theory"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.00588"}}, {"publisher": {"name": ""}, "description": "  In this paper, we formulate an evolutionarymultiple access control game with\ncontinuousvariable actions and coupled constraints. We characterize equilibria\nof the game and show that the pure equilibria are Pareto optimal and also\nresilient to deviations by coalitions of any size, i.e., they are strong\nequilibria. We use the concepts of price of anarchy and strong price of anarchy\nto study the performance of the system. The paper also addresses how to select\none specific equilibrium solution using the concepts of normalized equilibrium\nand evolutionarily stable strategies. We examine the long-run behavior of these\nstrategies under several classes of evolutionary game dynamics, such as\nBrown-von Neumann-Nash dynamics, Smith dynamics and replicator dynamics. In\naddition, we examine correlated equilibrium for the single-receiver model.\nCorrelated strategies are based on signaling structures before making decisions\non rates. We then focus on evolutionary games for hybrid additive white\nGaussian noise multiple access channel with multiple users and multiple\nreceivers, where each user chooses a rate and splits it over the receivers.\nUsers have coupled constraints determined by the capacity regions. Building\nupon the static game, we formulate a system of hybrid evolutionary game\ndynamics using G-function dynamics and Smith dynamics on rate control and\nchannel selection, respectively. We show that the evolving game has an\nequilibrium and illustrate these dynamics with numerical examples.\n", "contributors": [{"name": "Zhu, Quanyan", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "Quanyan", "email": ""}, {"name": "Tembine, Hamidou", "sameAs": [], "familyName": "Tembine", "additionalName": "", "givenName": "Hamidou", "email": ""}, {"name": "Basar, Tamer", "sameAs": [], "familyName": "Basar", "additionalName": "", "givenName": "Tamer", "email": ""}], "title": "Evolutionary Games for Multiple Access Control", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-03-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1103.2496", "oai:arXiv.org:1103.2496"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this paper, we formulate an evolutionarymultiple access control game with\ncontinuousvariable actions and coupled constraints. We characterize equilibria\nof the game and show that the pure equilibria are Pareto optimal and also\nresilient to deviations by coalitions of any size, i.e., they are strong\nequilibria. We use the concepts of price of anarchy and strong price of anarchy\nto study the performance of the system. The paper also addresses how to select\none specific equilibrium solution using the concepts of normalized equilibrium\nand evolutionarily stable strategies. We examine the long-run behavior of these\nstrategies under several classes of evolutionary game dynamics, such as\nBrown-von Neumann-Nash dynamics, Smith dynamics and replicator dynamics. In\naddition, we examine correlated equilibrium for the single-receiver model.\nCorrelated strategies are based on signaling structures before making decisions\non rates. We then focus on evolutionary games for hybrid additive white\nGaussian noise multiple access channel with multiple users and multiple\nreceivers, where each user chooses a rate and splits it over the receivers.\nUsers have coupled constraints determined by the capacity regions. Building\nupon the static game, we formulate a system of hybrid evolutionary game\ndynamics using G-function dynamics and Smith dynamics on rate control and\nchannel selection, respectively. We show that the evolving game has an\nequilibrium and illustrate these dynamics with numerical examples.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory", "computer science - systems and control", "mathematics - optimization and control", "mathematics - dynamical systems"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1103.2496"}}, {"publisher": {"name": ""}, "description": "  In this paper we are concerned with fully automatic and locally adaptive\nestimation of functions in a \"signal + noise\"-model where the regression\nfunction may additionally be blurred by a linear operator, e.g. by a\nconvolution. To this end, we introduce a general class of statistical\nmultiresolution estimators and develop an algorithmic framework for computing\nthose. By this we mean estimators that are defined as solutions of convex\noptimization problems with supremum-type constraints. We employ a combination\nof the alternating direction method of multipliers with Dykstra's algorithm for\ncomputing orthogonal projections onto intersections of convex sets and prove\nnumerical convergence. The capability of the proposed method is illustrated by\nvarious examples from imaging and signal detection.\n", "contributors": [{"name": "Frick, Klaus", "sameAs": [], "familyName": "Frick", "additionalName": "", "givenName": "Klaus", "email": ""}, {"name": "Marnitz, Philipp", "sameAs": [], "familyName": "Marnitz", "additionalName": "", "givenName": "Philipp", "email": ""}, {"name": "Munk, Axel", "sameAs": [], "familyName": "Munk", "additionalName": "", "givenName": "Axel", "email": ""}], "title": "Statistical Multiresolution Dantzig Estimation in Imaging: Fundamental\n  Concepts and Algorithmic Framework", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-23", "2012-02-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.4373", "Electron. J. Stat. 6 (2012) 231-268", "doi:10.1214/12-EJS671", "oai:arXiv.org:1101.4373"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  In this paper we are concerned with fully automatic and locally adaptive\nestimation of functions in a \"signal + noise\"-model where the regression\nfunction may additionally be blurred by a linear operator, e.g. by a\nconvolution. To this end, we introduce a general class of statistical\nmultiresolution estimators and develop an algorithmic framework for computing\nthose. By this we mean estimators that are defined as solutions of convex\noptimization problems with supremum-type constraints. We employ a combination\nof the alternating direction method of multipliers with Dykstra's algorithm for\ncomputing orthogonal projections onto intersections of convex sets and prove\nnumerical convergence. The capability of the proposed method is illustrated by\nvarious examples from imaging and signal detection.\n"}}], "languages": [null], "subjects": ["statistics - applications", "computer science - systems and control", "statistics - computation", "mathematics - optimization and control", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.4373"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "This thesis attempts to look at how Chinese animation cinema has evolved over the years and how the Chinese nation is being constructed and contested through animation filmic texts and animation filmmaking practices as sites where national and transnational cultural and economic flows converge and contend. The unraveling of the intricate relations between animation cinema and nation is intended to shed light on the understanding of contemporary cultural, social and media scapes in China. The Introduction addresses motivations and goals, critical questions, and over-riding theoretical framework and methodology. Chapter One explores the origin of the pursuit of a national animation style by investigating early Chinese animation cinema of the pre-reform period. It also serves as a backdrop against which the present discourse of revitalizing national animation cinema is being articulated.", "contributors": [{"name": "Huang, He, S.M. Massachusetts Institute of Technology", "sameAs": [], "familyName": "Huang", "additionalName": "", "givenName": "He", "email": ""}, {"name": "Massachusetts Institute of Technology. Dept. of Comparative Media Studies.", "sameAs": [], "familyName": "Studies.", "additionalName": "Institute of Technology. Dept. of Comparative Media", "givenName": "Massachusetts", "email": ""}, {"name": "Jing Wang.", "sameAs": [], "familyName": "Wang.", "additionalName": "", "givenName": "Jing", "email": ""}], "title": "Journey to the East : the re(make) of Chinese animation", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "125 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/39153", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://dspace.mit.edu/handle/1721.1/39153", "http://hdl.handle.net/1721.1/39153", "166228117", "oai:dspace.mit.edu:1721.1/39153"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2009-01-30T18:33:22Z", "2009-01-30T18:33:22Z", "2007", "2007"]}}, {"name": "description", "properties": {"description": ["This thesis attempts to look at how Chinese animation cinema has evolved over the years and how the Chinese nation is being constructed and contested through animation filmic texts and animation filmmaking practices as sites where national and transnational cultural and economic flows converge and contend. The unraveling of the intricate relations between animation cinema and nation is intended to shed light on the understanding of contemporary cultural, social and media scapes in China. The Introduction addresses motivations and goals, critical questions, and over-riding theoretical framework and methodology. Chapter One explores the origin of the pursuit of a national animation style by investigating early Chinese animation cinema of the pre-reform period. It also serves as a backdrop against which the present discourse of revitalizing national animation cinema is being articulated.", "(cont.) Chapter Two closely examines a commercial 3D feature-length animation production - Thru the Moebius Strip, as a case of \"homemade\" in the era of global capitalism, to look into modern nation-building both at the industry level and the filmic text level. Chapter Three closely examines another recent feature production, Little Soldier Zhang Ga, which can be read as a new type of \"national\" film that inherited the heritages of the socialist cinema, but aims at revolutionizing the animation cinema. The Conclusion comes back to the core question of the national and the creative, which contemporary animation cinema centers on. I try to disentangle the relations between Chinese animation filmmaking and the state discourse of national, taking into account the broader political, institutional, economic and cultural situations.", "by He Huang.", "Thesis (S.M.)--Massachusetts Institute of Technology, Dept. of Comparative Media Studies, 2007.", "Includes bibliographical references (p. 115-123). Filmography: p. 124-125."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39100", "hdl_1721.1_39097"]}}], "languages": [null], "subjects": ["comparative media studies."], "providerUpdatedDateTime": "2015-04-27T14:44:37", "uris": {"canonicalUri": "http://dspace.mit.edu/handle/1721.1/39153"}}, {"publisher": {"name": ""}, "description": "  In this paper we introduce a polynomial time algorithm that solves both the\nconjugacy decision and search problems in free abelian-by-infinite cyclic\ngroups where the input is elements in normal form. We do this by adapting the\nwork of Bogopolski, Martino, Maslakova, and Ventura in\n\\cite{bogopolski2006conjugacy} and Bogopolski, Martino, and Ventura in\n\\cite{bogopolski2010orbit}, to free abelian-by-infinite cyclic groups, and in\ncertain cases apply a polynomial time algorithm for the orbit problem over\n$\\Z^n$ by Kannan and Lipton.\n", "contributors": [{"name": "Cavallo, Bren", "sameAs": [], "familyName": "Cavallo", "additionalName": "", "givenName": "Bren", "email": ""}, {"name": "Kahrobaei, Delaram", "sameAs": [], "familyName": "Kahrobaei", "additionalName": "", "givenName": "Delaram", "email": ""}], "title": "A Polynomial Time Algorithm For The Conjugacy Decision and Search\n  Problems in Free Abelian-by-Infinite Cyclic Groups", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5297", "oai:arXiv.org:1410.5297"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this paper we introduce a polynomial time algorithm that solves both the\nconjugacy decision and search problems in free abelian-by-infinite cyclic\ngroups where the input is elements in normal form. We do this by adapting the\nwork of Bogopolski, Martino, Maslakova, and Ventura in\n\\cite{bogopolski2006conjugacy} and Bogopolski, Martino, and Ventura in\n\\cite{bogopolski2010orbit}, to free abelian-by-infinite cyclic groups, and in\ncertain cases apply a polynomial time algorithm for the orbit problem over\n$\\Z^n$ by Kannan and Lipton.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "mathematics - group theory"], "providerUpdatedDateTime": "2014-10-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5297"}}, {"publisher": {"name": ""}, "description": "  \"This article describes software engineering techniques to be used in order\nto ensure the necessary quality of intelligent and therefore massive\nsoftware-based systems in vehicles. Quality assurance for intelligent software\nis achieved through a bundle of modern software engineering methods.\nArchitecture and design patterns for securing the software components are\nsupplemented by test concepts and frameworks for validation and checks of\nrobustness of the implementation. These patterns describe established and\ntherefore consolidated solutions for certain problems as for instance\nreliability or efficient execution.\n  --\n  Dieser Artikel skizziert, welche Software-Entwurfstechniken heute zum Einsatz\nkommen k\\\"onnen, um intelligente, Software-lastige Systeme im Fahrzeug\nabzusichern. Dabei spielt zun\\\"achst das Qualit\\\"atsmanagement durch\nSoftware-technische Ma{\\ss}nahmen eine zentrale Rolle. Architektur- und\nEntwurfmuster f\\\"ur die Software-technische Absicherung von Komponenten werden\nerg\\\"anzt um Test-Konzepte zur Validierung von Spezifikationen und der\nRobustheit der Implementierung. Architekturen und Entwurfs-Muster beschreiben\nerprobte und damit konsolidierte L\\\"osungen f\\\"ur bestimmte Problemklassen wie\netwa Zuverl\\\"assigkeit oder effiziente Ausf\\\"uhrung.\n", "contributors": [{"name": "Rumpe, Bernhard", "sameAs": [], "familyName": "Rumpe", "additionalName": "", "givenName": "Bernhard", "email": ""}, {"name": "Berger, Christian", "sameAs": [], "familyName": "Berger", "additionalName": "", "givenName": "Christian", "email": ""}, {"name": "Krahn, Holger", "sameAs": [], "familyName": "Krahn", "additionalName": "", "givenName": "Holger", "email": ""}], "title": "Softwaretechnische Absicherung intelligenter Systeme im Fahrzeug", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4078", "Proceedings der 21. VDI/VW-Gemeinschaftstagung - Integrierte\n  Sicherheit und Fahrerassistenzsysteme. 12.-13. Oktober 2006, Wolfsburg", "oai:arXiv.org:1410.4078"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  \"This article describes software engineering techniques to be used in order\nto ensure the necessary quality of intelligent and therefore massive\nsoftware-based systems in vehicles. Quality assurance for intelligent software\nis achieved through a bundle of modern software engineering methods.\nArchitecture and design patterns for securing the software components are\nsupplemented by test concepts and frameworks for validation and checks of\nrobustness of the implementation. These patterns describe established and\ntherefore consolidated solutions for certain problems as for instance\nreliability or efficient execution.\n  --\n  Dieser Artikel skizziert, welche Software-Entwurfstechniken heute zum Einsatz\nkommen k\\\"onnen, um intelligente, Software-lastige Systeme im Fahrzeug\nabzusichern. Dabei spielt zun\\\"achst das Qualit\\\"atsmanagement durch\nSoftware-technische Ma{\\ss}nahmen eine zentrale Rolle. Architektur- und\nEntwurfmuster f\\\"ur die Software-technische Absicherung von Komponenten werden\nerg\\\"anzt um Test-Konzepte zur Validierung von Spezifikationen und der\nRobustheit der Implementierung. Architekturen und Entwurfs-Muster beschreiben\nerprobte und damit konsolidierte L\\\"osungen f\\\"ur bestimmte Problemklassen wie\netwa Zuverl\\\"assigkeit oder effiziente Ausf\\\"uhrung.\n", "Comment: 14 pages, 1 figure in German"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2014-10-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4078"}}, {"publisher": {"name": ""}, "description": "  In this paper we explore the use of full-duplex radio to improve the spectrum\nefficiency in a two-way relay channel where two sources exchange information\nthrough an multi-antenna relay, and all nodes work in the full-duplex mode. The\nfull-duplex operation can reduce the overall communication to only one phase\nbut suffers from the self-interference. Instead of purely suppressing the\nself-interference, we aim to maximize the end-to-end performance by jointly\noptimizing the beamforming matrix at the relay which uses the\namplify-and-forward protocol as well as the power control at the sources. To be\nspecific, we propose iterative algorithms and 1-D search to solve two problems:\nfinding the achievable rate region and maximizing the sum rate. At each\niteration, either the analytical solution or convex formulation is obtained. We\ncompare the proposed full-duplex two-way relaying with the conventional\nhalf-duplex two-way relaying, a full-duplex one-way relaying and a performance\nupper bound. Numerical results show that the proposed full-duplex scheme\nsignificantly improves the achievable data rates over the conventional scheme.\n", "contributors": [{"name": "Zheng, Gan", "sameAs": [], "familyName": "Zheng", "additionalName": "", "givenName": "Gan", "email": ""}], "title": "Joint Beamforming Optimization and Power Control for Full-Duplex MIMO\n  Two-way Relay Channel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.6021", "oai:arXiv.org:1411.6021"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper we explore the use of full-duplex radio to improve the spectrum\nefficiency in a two-way relay channel where two sources exchange information\nthrough an multi-antenna relay, and all nodes work in the full-duplex mode. The\nfull-duplex operation can reduce the overall communication to only one phase\nbut suffers from the self-interference. Instead of purely suppressing the\nself-interference, we aim to maximize the end-to-end performance by jointly\noptimizing the beamforming matrix at the relay which uses the\namplify-and-forward protocol as well as the power control at the sources. To be\nspecific, we propose iterative algorithms and 1-D search to solve two problems:\nfinding the achievable rate region and maximizing the sum rate. At each\niteration, either the analytical solution or convex formulation is obtained. We\ncompare the proposed full-duplex two-way relaying with the conventional\nhalf-duplex two-way relaying, a full-duplex one-way relaying and a performance\nupper bound. Numerical results show that the proposed full-duplex scheme\nsignificantly improves the achievable data rates over the conventional scheme.\n", "Comment: 11 pages, 11 figures, accepted in The IEEE Transactions on Signal\n  Processing"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.6021"}}, {"publisher": {"name": ""}, "description": "  The Ronkin function plays a fundamental role in the theory of amoebas. We\nintroduce an analogue of the Ronkin function in the setting of coamoebas. It\nturns out to be closely related to a certain toric arrangement known as the\nshell of the coamoeba and we use our Ronkin type function to obtain some\nproperties of it.\n", "contributors": [{"name": "Johansson, Petter", "sameAs": [], "familyName": "Johansson", "additionalName": "", "givenName": "Petter", "email": ""}, {"name": "Kalm, H\u00e5kan Samuelsson", "sameAs": [], "familyName": "Kalm", "additionalName": "Samuelsson", "givenName": "H\u00e5kan", "email": ""}], "title": "A Ronkin type function for coamoebas", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1585", "oai:arXiv.org:1412.1585"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The Ronkin function plays a fundamental role in the theory of amoebas. We\nintroduce an analogue of the Ronkin function in the setting of coamoebas. It\nturns out to be closely related to a certain toric arrangement known as the\nshell of the coamoeba and we use our Ronkin type function to obtain some\nproperties of it.\n", "Comment: 2 figures. Comments are welcome!"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - combinatorics", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-12-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1585"}}, {"publisher": {"name": ""}, "description": "  Deep Neural Network (DNN) acoustic models have yielded many state-of-the-art\nresults in Automatic Speech Recognition (ASR) tasks. More recently, Recurrent\nNeural Network (RNN) models have been shown to outperform DNNs counterparts.\nHowever, state-of-the-art DNN and RNN models tend to be impractical to deploy\non embedded systems with limited computational capacity. Traditionally, the\napproach for embedded platforms is to either train a small DNN directly, or to\ntrain a small DNN that learns the output distribution of a large DNN. In this\npaper, we utilize a state-of-the-art RNN to transfer knowledge to small DNN. We\nuse the RNN model to generate soft alignments and minimize the Kullback-Leibler\ndivergence against the small DNN. The small DNN trained on the soft RNN\nalignments achieved a 3.93 WER on the Wall Street Journal (WSJ) eval92 task\ncompared to a baseline 4.54 WER or more than 13% relative improvement.\n", "contributors": [{"name": "Chan, William", "sameAs": [], "familyName": "Chan", "additionalName": "", "givenName": "William", "email": ""}, {"name": "Ke, Nan Rosemary", "sameAs": [], "familyName": "Ke", "additionalName": "Rosemary", "givenName": "Nan", "email": ""}, {"name": "Lane, Ian", "sameAs": [], "familyName": "Lane", "additionalName": "", "givenName": "Ian", "email": ""}], "title": "Transferring Knowledge from a RNN to a DNN", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01483", "oai:arXiv.org:1504.01483"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  Deep Neural Network (DNN) acoustic models have yielded many state-of-the-art\nresults in Automatic Speech Recognition (ASR) tasks. More recently, Recurrent\nNeural Network (RNN) models have been shown to outperform DNNs counterparts.\nHowever, state-of-the-art DNN and RNN models tend to be impractical to deploy\non embedded systems with limited computational capacity. Traditionally, the\napproach for embedded platforms is to either train a small DNN directly, or to\ntrain a small DNN that learns the output distribution of a large DNN. In this\npaper, we utilize a state-of-the-art RNN to transfer knowledge to small DNN. We\nuse the RNN model to generate soft alignments and minimize the Kullback-Leibler\ndivergence against the small DNN. The small DNN trained on the soft RNN\nalignments achieved a 3.93 WER on the Wall Street Journal (WSJ) eval92 task\ncompared to a baseline 4.54 WER or more than 13% relative improvement.\n"}}], "languages": [null], "subjects": ["statistics - machine learning", "computer science - computation and language", "computer science - learning", "computer science - neural and evolutionary computing"], "providerUpdatedDateTime": "2015-04-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01483"}}, {"publisher": {"name": ""}, "description": "  The engineering interest about dune fields is dictated by the their\ninteraction with a number of human infrastructures in arid environments. Sand\ndunes dynamics is dictated by wind and its ability to induce sand erosion,\ntransport and deposition. A deep understanding of dune aerodynamics serves then\nto ground effective strategies for the protection of human infrastructures from\nsand, the so-called sand mitigation. Because of their simple geometry and their\nfrequent occurrence in desert area, transverse sand dunes are usually adopted\nin literature as a benchmark to investigate dune aerodynamics by means of both\ncomputational or experimental approaches, usually in nominally 2D setups. The\npresent study aims at evaluating 3D flow features in the wake of a idealised\ntransverse dune, if any, under different nominally 2D setup conditions by means\nof computational simulations and to compare the obtained results with\nexperimental measurements available in literature.\n", "contributors": [{"name": "Bruno, Luca", "sameAs": [], "familyName": "Bruno", "additionalName": "", "givenName": "Luca", "email": ""}, {"name": "Fransos, Davide", "sameAs": [], "familyName": "Fransos", "additionalName": "", "givenName": "Davide", "email": ""}], "title": "Sand transverse dune aerodynamics: 3D Coherent Flow Structures from a\n  computational study", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-11", "2015-02-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.03396", "oai:arXiv.org:1501.03396"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  The engineering interest about dune fields is dictated by the their\ninteraction with a number of human infrastructures in arid environments. Sand\ndunes dynamics is dictated by wind and its ability to induce sand erosion,\ntransport and deposition. A deep understanding of dune aerodynamics serves then\nto ground effective strategies for the protection of human infrastructures from\nsand, the so-called sand mitigation. Because of their simple geometry and their\nfrequent occurrence in desert area, transverse sand dunes are usually adopted\nin literature as a benchmark to investigate dune aerodynamics by means of both\ncomputational or experimental approaches, usually in nominally 2D setups. The\npresent study aims at evaluating 3D flow features in the wake of a idealised\ntransverse dune, if any, under different nominally 2D setup conditions by means\nof computational simulations and to compare the obtained results with\nexperimental measurements available in literature.\n"}}], "languages": [null], "subjects": ["physics - geophysics", "finance", "and science", "computer science - computational engineering", "physics - fluid dynamics", "physics - atmospheric and oceanic physics"], "providerUpdatedDateTime": "2015-02-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.03396"}}, {"publisher": {"name": ""}, "description": "  We describe the first nearly linear-time approximation algorithms for\nexplicitly given mixed packing/covering linear programs, and for (non-metric)\nfractional facility location. We also describe the first parallel algorithms\nrequiring only near-linear total work and finishing in polylog time. The\nalgorithms compute $(1+\\epsilon)$-approximate solutions in time (and work)\n$O^*(N/\\epsilon^2)$, where $N$ is the number of non-zeros in the constraint\nmatrix. For facility location, $N$ is the number of eligible client/facility\npairs.\n", "contributors": [{"name": "Young, Neal E.", "sameAs": [], "familyName": "Young", "additionalName": "E.", "givenName": "Neal", "email": ""}], "title": "Nearly Linear-Work Algorithms for Mixed Packing/Covering and\n  Facility-Location Linear Programs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-10", "2014-11-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.3015", "oai:arXiv.org:1407.3015"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We describe the first nearly linear-time approximation algorithms for\nexplicitly given mixed packing/covering linear programs, and for (non-metric)\nfractional facility location. We also describe the first parallel algorithms\nrequiring only near-linear total work and finishing in polylog time. The\nalgorithms compute $(1+\\epsilon)$-approximate solutions in time (and work)\n$O^*(N/\\epsilon^2)$, where $N$ is the number of non-zeros in the constraint\nmatrix. For facility location, $N$ is the number of eligible client/facility\npairs.\n"}}], "languages": [null], "subjects": ["f.2.1", "49m29", "90c05", "90-08", "computer science - data structures and algorithms", "g.1.6", "65k05"], "providerUpdatedDateTime": "2014-11-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.3015"}}, {"publisher": {"name": ""}, "description": "  Random coding, along with various standard techniques such as coded\ntime-sharing, rate-splitting, superposition coding, and binning, are\ntraditionally used in obtaining achievable rate regions for multi-terminal\nnetworks. The error analysis of such an achievable scheme relies heavily on the\nproperties of strongly joint typical sequences and on bounds of the cardinality\nof typical sets. In this work, we obtain an achievable rate region for a\ngeneral (i.e. an arbitrary set of messages shared amongst encoding nodes, which\ntransmit to arbitrary decoding nodes) memoryless, single-hop, multi-terminal\nnetwork without feedback or cooperation by introducing a general framework and\nnotation, and carefully generalizing the derivation of the error analysis. We\nshow that this general inner bound may be obtained from a chain graph\nrepresentation of the encoding operations. This graph representation captures\nthe statistical relationship among codewords and allows one to readily obtain\nthe rate bounds that define the achievable rate region. The proposed graph\nrepresentation naturally leads to the derivation of all the achievable schemes\nthat can be generated by combining classic random coding techniques for any\nmemoryless network used without feedback or cooperation. We also re-derive a\nfew achievable regions for classic multi-terminal networks, such as the\nmulti-access channel, the broadcast channel, and the interference channel, to\nshow how this new representation allows one to quickly consider the possible\nchoices of encoding/decoding strategies for any given network and the\ndistribution of messages among the encoders and decoders.\n", "contributors": [{"name": "Rini, Stefano", "sameAs": [], "familyName": "Rini", "additionalName": "", "givenName": "Stefano", "email": ""}], "title": "An Achievable Region for a General Multi-terminal Network and the\n  corresponding Chain Graph Representation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-12-07", "2012-02-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1112.1497", "oai:arXiv.org:1112.1497"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Random coding, along with various standard techniques such as coded\ntime-sharing, rate-splitting, superposition coding, and binning, are\ntraditionally used in obtaining achievable rate regions for multi-terminal\nnetworks. The error analysis of such an achievable scheme relies heavily on the\nproperties of strongly joint typical sequences and on bounds of the cardinality\nof typical sets. In this work, we obtain an achievable rate region for a\ngeneral (i.e. an arbitrary set of messages shared amongst encoding nodes, which\ntransmit to arbitrary decoding nodes) memoryless, single-hop, multi-terminal\nnetwork without feedback or cooperation by introducing a general framework and\nnotation, and carefully generalizing the derivation of the error analysis. We\nshow that this general inner bound may be obtained from a chain graph\nrepresentation of the encoding operations. This graph representation captures\nthe statistical relationship among codewords and allows one to readily obtain\nthe rate bounds that define the achievable rate region. The proposed graph\nrepresentation naturally leads to the derivation of all the achievable schemes\nthat can be generated by combining classic random coding techniques for any\nmemoryless network used without feedback or cooperation. We also re-derive a\nfew achievable regions for classic multi-terminal networks, such as the\nmulti-access channel, the broadcast channel, and the interference channel, to\nshow how this new representation allows one to quickly consider the possible\nchoices of encoding/decoding strategies for any given network and the\ndistribution of messages among the encoders and decoders.\n", "Comment: arXiv admin note: substantial text overlap with arXiv:1107.4705"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1112.1497"}}, {"publisher": {"name": ""}, "description": "  Markov Chain Monte Carlo (MCMC) algorithms are often used for approximate\ninference inside learning, but their slow mixing can be difficult to diagnose\nand the approximations can seriously degrade learning. To alleviate these\nissues, we define a new model family using strong Doeblin Markov chains, whose\nmixing times can be precisely controlled by a parameter. We also develop an\nalgorithm to learn such models, which involves maximizing the data likelihood\nunder the induced stationary distribution of these chains. We show empirical\nimprovements on two challenging inference tasks.\n", "contributors": [{"name": "Steinhardt, Jacob", "sameAs": [], "familyName": "Steinhardt", "additionalName": "", "givenName": "Jacob", "email": ""}, {"name": "Liang, Percy", "sameAs": [], "familyName": "Liang", "additionalName": "", "givenName": "Percy", "email": ""}], "title": "Learning Fast-Mixing Models for Structured Prediction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06668", "oai:arXiv.org:1502.06668"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Markov Chain Monte Carlo (MCMC) algorithms are often used for approximate\ninference inside learning, but their slow mixing can be difficult to diagnose\nand the approximations can seriously degrade learning. To alleviate these\nissues, we define a new model family using strong Doeblin Markov chains, whose\nmixing times can be precisely controlled by a parameter. We also develop an\nalgorithm to learn such models, which involves maximizing the data likelihood\nunder the induced stationary distribution of these chains. We show empirical\nimprovements on two challenging inference tasks.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-02-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06668"}}, {"publisher": {"name": ""}, "description": "  Voronoi diagrams appear in many areas in science and technology and have\nnumerous applications. They have been the subject of extensive investigation\nduring the last decades. Roughly speaking, they are a certain decomposition of\na given space into cells, induced by a distance function and by a tuple of\nsubsets called the generators or the sites. Consider the following question:\ndoes a small change of the sites, e.g., of their position or shape, yield a\nsmall change in the corresponding Voronoi cells? This question is by all means\nnatural and fundamental, since in practice one approximates the sites either\nbecause of inexact information about them, because of inevitable numerical\nerrors in their representation, for simplification purposes and so on, and it\nis important to know whether the resulting Voronoi cells approximate the real\nones well. The traditional approach to Voronoi diagrams, and, in particular, to\n(variants of) this question, is combinatorial. However, it seems that there has\nbeen a very limited discussion in the geometric sense (the shape of the cells),\nmainly an intuitive one, without proofs, in Euclidean spaces. We formalize this\nquestion precisely, and then show that the answer is positive in the case of\nR^d, or, more generally, in (possibly infinite dimensional) uniformly convex\nnormed spaces, assuming there is a common positive lower bound on the distance\nbetween the sites. Explicit bounds are given, and we allow infinitely many\nsites of a general form. The relevance of this result is illustrated using\nseveral pictures and many real-world and theoretical examples and\ncounterexamples.\n", "contributors": [{"name": "Reem, Daniel", "sameAs": [], "familyName": "Reem", "additionalName": "", "givenName": "Daniel", "email": ""}], "title": "The geometric stability of Voronoi diagrams with respect to small\n  changes of the sites", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-03-21", "2011-04-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1103.4125", "Extended abstract in: Proceedings of the 27th Annual ACM Symposium\n  on Computational Geometry (SoCG 2011), pp. 254-263", "oai:arXiv.org:1103.4125"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Voronoi diagrams appear in many areas in science and technology and have\nnumerous applications. They have been the subject of extensive investigation\nduring the last decades. Roughly speaking, they are a certain decomposition of\na given space into cells, induced by a distance function and by a tuple of\nsubsets called the generators or the sites. Consider the following question:\ndoes a small change of the sites, e.g., of their position or shape, yield a\nsmall change in the corresponding Voronoi cells? This question is by all means\nnatural and fundamental, since in practice one approximates the sites either\nbecause of inexact information about them, because of inevitable numerical\nerrors in their representation, for simplification purposes and so on, and it\nis important to know whether the resulting Voronoi cells approximate the real\nones well. The traditional approach to Voronoi diagrams, and, in particular, to\n(variants of) this question, is combinatorial. However, it seems that there has\nbeen a very limited discussion in the geometric sense (the shape of the cells),\nmainly an intuitive one, without proofs, in Euclidean spaces. We formalize this\nquestion precisely, and then show that the answer is positive in the case of\nR^d, or, more generally, in (possibly infinite dimensional) uniformly convex\nnormed spaces, assuming there is a common positive lower bound on the distance\nbetween the sites. Explicit bounds are given, and we allow infinitely many\nsites of a general form. The relevance of this result is illustrated using\nseveral pictures and many real-world and theoretical examples and\ncounterexamples.\n", "Comment: 30 pages (13 pages in appendices); a few corrections and additions,\n  mainly regarding the references and the counterexamples; minor additional\n  modifications; Theorem 8.13 and the figures were slightly improved; a\n  modification of this paper will appear in SoCG 2011"]}}], "languages": [null], "subjects": ["g.0", "f.2.2", "46n99", "65d18", "i.3.5", "68u05", "mathematics - functional analysis", "46b20", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1103.4125"}}, {"publisher": {"name": ""}, "description": "  We study the problem of the generation of a continuous random variable when a\nsource of independent fair coins is available. We first motivate the choice of\na natural criterion for measuring accuracy, the Wasserstein $L_\\infty$ metric,\nand then show a universal lower bound for the expected number of required fair\ncoins as a function of the accuracy. In the case of an absolutely continuous\nrandom variable with finite differential entropy, several algorithms are\npresented that match the lower bound up to a constant, which can be eliminated\nby generating random variables in batches.\n", "contributors": [{"name": "Devroye, Luc", "sameAs": [], "familyName": "Devroye", "additionalName": "", "givenName": "Luc", "email": ""}, {"name": "Gravel, Claude", "sameAs": [], "familyName": "Gravel", "additionalName": "", "givenName": "Claude", "email": ""}], "title": "Sampling with arbitrary precision", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02539", "oai:arXiv.org:1502.02539"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We study the problem of the generation of a continuous random variable when a\nsource of independent fair coins is available. We first motivate the choice of\na natural criterion for measuring accuracy, the Wasserstein $L_\\infty$ metric,\nand then show a universal lower bound for the expected number of required fair\ncoins as a function of the accuracy. In the case of an absolutely continuous\nrandom variable with finite differential entropy, several algorithms are\npresented that match the lower bound up to a constant, which can be eliminated\nby generating random variables in batches.\n", "Comment: 3 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-02-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02539"}}, {"publisher": {"name": ""}, "description": "  Music prediction tasks range from predicting tags given a song or clip of\naudio, predicting the name of the artist, or predicting related songs given a\nsong, clip, artist name or tag. That is, we are interested in every semantic\nrelationship between the different musical concepts in our database. In\nrealistically sized databases, the number of songs is measured in the hundreds\nof thousands or more, and the number of artists in the tens of thousands or\nmore, providing a considerable challenge to standard machine learning\ntechniques. In this work, we propose a method that scales to such datasets\nwhich attempts to capture the semantic similarities between the database items\nby modeling audio, artist names, and tags in a single low-dimensional semantic\nspace. This choice of space is learnt by optimizing the set of prediction tasks\nof interest jointly using multi-task learning. Our method both outperforms\nbaseline methods and, in comparison to them, is faster and consumes less\nmemory. We then demonstrate how our method learns an interpretable model, where\nthe semantic space captures well the similarities of interest.\n", "contributors": [{"name": "Weston, Jason", "sameAs": [], "familyName": "Weston", "additionalName": "", "givenName": "Jason", "email": ""}, {"name": "Bengio, Samy", "sameAs": [], "familyName": "Bengio", "additionalName": "", "givenName": "Samy", "email": ""}, {"name": "Hamel, Philippe", "sameAs": [], "familyName": "Hamel", "additionalName": "", "givenName": "Philippe", "email": ""}], "title": "Large-Scale Music Annotation and Retrieval: Learning to Rank in Joint\n  Semantic Spaces", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.5196", "oai:arXiv.org:1105.5196"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Music prediction tasks range from predicting tags given a song or clip of\naudio, predicting the name of the artist, or predicting related songs given a\nsong, clip, artist name or tag. That is, we are interested in every semantic\nrelationship between the different musical concepts in our database. In\nrealistically sized databases, the number of songs is measured in the hundreds\nof thousands or more, and the number of artists in the tens of thousands or\nmore, providing a considerable challenge to standard machine learning\ntechniques. In this work, we propose a method that scales to such datasets\nwhich attempts to capture the semantic similarities between the database items\nby modeling audio, artist names, and tags in a single low-dimensional semantic\nspace. This choice of space is learnt by optimizing the set of prediction tasks\nof interest jointly using multi-task learning. Our method both outperforms\nbaseline methods and, in comparison to them, is faster and consumes less\nmemory. We then demonstrate how our method learns an interpretable model, where\nthe semantic space captures well the similarities of interest.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.5196"}}, {"publisher": {"name": ""}, "description": "  In this paper, we study spectrum allocation mechanisms in hierarchical\nmulti-layer markets which are expected to proliferate in the near future based\non the current spectrum policy reform proposals. We consider a setting where a\nstate agency sells spectrum channels to Primary Operators (POs) who\nsubsequently resell them to Secondary Operators (SOs) through auctions. We show\nthat these hierarchical markets do not result in a socially efficient spectrum\nallocation which is aimed by the agency, due to lack of coordination among the\nentities in different layers and the inherently selfish revenue-maximizing\nstrategy of POs. In order to reconcile these opposing objectives, we propose an\nincentive mechanism which aligns the strategy and the actions of the POs with\nthe objective of the agency, and thus leads to system performance improvement\nin terms of social welfare. This pricing-based scheme constitutes a method for\nhierarchical market regulation. A basic component of the proposed incentive\nmechanism is a novel auction scheme which enables POs to allocate their\nspectrum by balancing their derived revenue and the welfare of the SOs.\n", "contributors": [{"name": "Iosifidis, George", "sameAs": [], "familyName": "Iosifidis", "additionalName": "", "givenName": "George", "email": ""}, {"name": "Chorppath, Anil Kumar", "sameAs": [], "familyName": "Chorppath", "additionalName": "Kumar", "givenName": "Anil", "email": ""}, {"name": "Alpcan, Tansu", "sameAs": [], "familyName": "Alpcan", "additionalName": "", "givenName": "Tansu", "email": ""}, {"name": "Koutsopoulos, Iordanis", "sameAs": [], "familyName": "Koutsopoulos", "additionalName": "", "givenName": "Iordanis", "email": ""}], "title": "Incentive Mechanisms for Hierarchical Spectrum Markets", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-18", "2011-12-12"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.4350", "oai:arXiv.org:1111.4350"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we study spectrum allocation mechanisms in hierarchical\nmulti-layer markets which are expected to proliferate in the near future based\non the current spectrum policy reform proposals. We consider a setting where a\nstate agency sells spectrum channels to Primary Operators (POs) who\nsubsequently resell them to Secondary Operators (SOs) through auctions. We show\nthat these hierarchical markets do not result in a socially efficient spectrum\nallocation which is aimed by the agency, due to lack of coordination among the\nentities in different layers and the inherently selfish revenue-maximizing\nstrategy of POs. In order to reconcile these opposing objectives, we propose an\nincentive mechanism which aligns the strategy and the actions of the POs with\nthe objective of the agency, and thus leads to system performance improvement\nin terms of social welfare. This pricing-based scheme constitutes a method for\nhierarchical market regulation. A basic component of the proposed incentive\nmechanism is a novel auction scheme which enables POs to allocate their\nspectrum by balancing their derived revenue and the welfare of the SOs.\n", "Comment: 9 pages"]}}], "languages": [null], "subjects": ["computer science - computer science and game theory", "computer science - systems and control", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.4350"}}, {"publisher": {"name": ""}, "description": "  The Graph Pricing problem is among the fundamental problems whose\napproximability is not well-understood. While there is a simple combinatorial\n1/4-approximation algorithm, the best hardness result remains at 1/2 assuming\nthe Unique Games Conjecture (UGC). We show that it is NP-hard to approximate\nwithin a factor better than 1/4 under the UGC, so that the simple combinatorial\nalgorithm might be the best possible. We also prove that for any $\\epsilon >\n0$, there exists $\\delta > 0$ such that the integrality gap of\n$n^{\\delta}$-rounds of the Sherali-Adams hierarchy of linear programming for\nGraph Pricing is at most 1/2 + $\\epsilon$.\n  This work is based on the effort to view the Graph Pricing problem as a\nConstraint Satisfaction Problem (CSP) simpler than the standard and complicated\nformulation. We propose the problem called Generalized Max-Dicut($T$), which\nhas a domain size $T + 1$ for every $T \\geq 1$. Generalized Max-Dicut(1) is\nwell-known Max-Dicut. There is an approximation-preserving reduction from\nGeneralized Max-Dicut on directed acyclic graphs (DAGs) to Graph Pricing, and\nboth our results are achieved through this reduction. Besides its connection to\nGraph Pricing, the hardness of Generalized Max-Dicut is interesting in its own\nright since in most arity two CSPs studied in the literature, SDP-based\nalgorithms perform better than LP-based or combinatorial algorithms --- for\nthis arity two CSP, a simple combinatorial algorithm does the best.\n", "contributors": [{"name": "Lee, Euiwoong", "sameAs": [], "familyName": "Lee", "additionalName": "", "givenName": "Euiwoong", "email": ""}], "title": "Hardness of Graph Pricing through Generalized Max-Dicut", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-04", "2014-11-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.0740", "oai:arXiv.org:1405.0740"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The Graph Pricing problem is among the fundamental problems whose\napproximability is not well-understood. While there is a simple combinatorial\n1/4-approximation algorithm, the best hardness result remains at 1/2 assuming\nthe Unique Games Conjecture (UGC). We show that it is NP-hard to approximate\nwithin a factor better than 1/4 under the UGC, so that the simple combinatorial\nalgorithm might be the best possible. We also prove that for any $\\epsilon >\n0$, there exists $\\delta > 0$ such that the integrality gap of\n$n^{\\delta}$-rounds of the Sherali-Adams hierarchy of linear programming for\nGraph Pricing is at most 1/2 + $\\epsilon$.\n  This work is based on the effort to view the Graph Pricing problem as a\nConstraint Satisfaction Problem (CSP) simpler than the standard and complicated\nformulation. We propose the problem called Generalized Max-Dicut($T$), which\nhas a domain size $T + 1$ for every $T \\geq 1$. Generalized Max-Dicut(1) is\nwell-known Max-Dicut. There is an approximation-preserving reduction from\nGeneralized Max-Dicut on directed acyclic graphs (DAGs) to Graph Pricing, and\nboth our results are achieved through this reduction. Besides its connection to\nGraph Pricing, the hardness of Generalized Max-Dicut is interesting in its own\nright since in most arity two CSPs studied in the literature, SDP-based\nalgorithms perform better than LP-based or combinatorial algorithms --- for\nthis arity two CSP, a simple combinatorial algorithm does the best.\n", "Comment: 28 pages"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity"], "providerUpdatedDateTime": "2014-11-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.0740"}}, {"publisher": {"name": ""}, "description": "  In order to use persistence diagrams as a true statistical tool, it would be\nvery useful to have a good notion of mean and variance for a set of diagrams.\nIn 2011, Mileyko and his collaborators made the first study of the properties\nof the Fr\\'echet mean in $(\\mathcal{D}_p,W_p)$, the space of persistence\ndiagrams equipped with the p-th Wasserstein metric. In particular, they showed\nthat the Fr\\'echet mean of a finite set of diagrams always exists, but is not\nnecessarily unique. The means of a continuously-varying set of diagrams do not\nthemselves (necessarily) vary continuously, which presents obvious problems\nwhen trying to extend the Fr\\'echet mean definition to the realm of vineyards.\n  We fix this problem by altering the original definition of Fr\\'echet mean so\nthat it now becomes a probability measure on the set of persistence diagrams;\nin a nutshell, the mean of a set of diagrams will be a weighted sum of atomic\nmeasures, where each atom is itself a persistence diagram determined using a\nperturbation of the input diagrams. This definition gives for each $N$ a map\n$(\\mathcal{D}_p)^N \\to \\mathbb{P}(\\mathcal{D}_p)$. We show that this map is\nH\\\"older continuous on finite diagrams and thus can be used to build a useful\nstatistic on time-varying persistence diagrams, better known as vineyards.\n", "contributors": [{"name": "Munch, Elizabeth", "sameAs": [], "familyName": "Munch", "additionalName": "", "givenName": "Elizabeth", "email": ""}, {"name": "Turner, Katharine", "sameAs": [], "familyName": "Turner", "additionalName": "", "givenName": "Katharine", "email": ""}, {"name": "Bendich, Paul", "sameAs": [], "familyName": "Bendich", "additionalName": "", "givenName": "Paul", "email": ""}, {"name": "Mukherjee, Sayan", "sameAs": [], "familyName": "Mukherjee", "additionalName": "", "givenName": "Sayan", "email": ""}, {"name": "Mattingly, Jonathan", "sameAs": [], "familyName": "Mattingly", "additionalName": "", "givenName": "Jonathan", "email": ""}, {"name": "Harer, John", "sameAs": [], "familyName": "Harer", "additionalName": "", "givenName": "John", "email": ""}], "title": "Probabilistic Fr\\'echet Means for Time Varying Persistence Diagrams", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-07-24", "2014-11-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1307.6530", "oai:arXiv.org:1307.6530"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In order to use persistence diagrams as a true statistical tool, it would be\nvery useful to have a good notion of mean and variance for a set of diagrams.\nIn 2011, Mileyko and his collaborators made the first study of the properties\nof the Fr\\'echet mean in $(\\mathcal{D}_p,W_p)$, the space of persistence\ndiagrams equipped with the p-th Wasserstein metric. In particular, they showed\nthat the Fr\\'echet mean of a finite set of diagrams always exists, but is not\nnecessarily unique. The means of a continuously-varying set of diagrams do not\nthemselves (necessarily) vary continuously, which presents obvious problems\nwhen trying to extend the Fr\\'echet mean definition to the realm of vineyards.\n  We fix this problem by altering the original definition of Fr\\'echet mean so\nthat it now becomes a probability measure on the set of persistence diagrams;\nin a nutshell, the mean of a set of diagrams will be a weighted sum of atomic\nmeasures, where each atom is itself a persistence diagram determined using a\nperturbation of the input diagrams. This definition gives for each $N$ a map\n$(\\mathcal{D}_p)^N \\to \\mathbb{P}(\\mathcal{D}_p)$. We show that this map is\nH\\\"older continuous on finite diagrams and thus can be used to build a useful\nstatistic on time-varying persistence diagrams, better known as vineyards.\n"}}], "languages": [null], "subjects": ["computer science - computational geometry", "mathematics - algebraic topology", "mathematics - probability"], "providerUpdatedDateTime": "2014-11-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1307.6530"}}, {"publisher": {"name": ""}, "description": "  We classify the ODEs that correspond to elliptic CR-manifolds with maximal\nisotropy. It follows that the dimension of the isotropy group of an elliptic\nCR-manifold can be only 10 (for the quadric), 4 (for the listed examples) or\nless. This is in contrast with the situation of hyperbolic CR-manifolds, where\nthe dimension can be 10 (for the quadric), 6 or 5 (for semi-quadrics) or less\nthan 4. We also prove that, for all elliptic CR-manifolds with non-linearizable\nistropy group, except for two special manifolds, the points with\nnon-linearizable isotropy form exactly some complex curve on the manifold.\n", "contributors": [{"name": "Ezhov, Vladimir", "sameAs": [], "familyName": "Ezhov", "additionalName": "", "givenName": "Vladimir", "email": ""}, {"name": "Schmalz, Gerd", "sameAs": [], "familyName": "Schmalz", "additionalName": "", "givenName": "Gerd", "email": ""}], "title": "Elliptic CR-manifolds and shear invariant ODE with additional symmetries", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2005-09-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/math/0509173", "Arkiv f\\\"or Matematik, October 2007, Volume 45, Issue 2, pp\n  253-268", "doi:10.1007/s11512-007-0049-6", "oai:arXiv.org:math/0509173"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  We classify the ODEs that correspond to elliptic CR-manifolds with maximal\nisotropy. It follows that the dimension of the isotropy group of an elliptic\nCR-manifold can be only 10 (for the quadric), 4 (for the listed examples) or\nless. This is in contrast with the situation of hyperbolic CR-manifolds, where\nthe dimension can be 10 (for the quadric), 6 or 5 (for semi-quadrics) or less\nthan 4. We also prove that, for all elliptic CR-manifolds with non-linearizable\nistropy group, except for two special manifolds, the points with\nnon-linearizable isotropy form exactly some complex curve on the manifold.\n"}}], "languages": [null], "subjects": ["mathematics - classical analysis and odes", "34a26", "32v40", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-02-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/math/0509173"}}, {"publisher": {"name": ""}, "description": "  Regenerating codes are a class of recently developed codes for distributed\nstorage that, like Reed-Solomon codes, permit data recovery from any arbitrary\nk of n nodes. However regenerating codes possess in addition, the ability to\nrepair a failed node by connecting to any arbitrary d nodes and downloading an\namount of data that is typically far less than the size of the data file. This\namount of download is termed the repair bandwidth. Minimum storage regenerating\n(MSR) codes are a subclass of regenerating codes that require the least amount\nof network storage; every such code is a maximum distance separable (MDS) code.\nFurther, when a replacement node stores data identical to that in the failed\nnode, the repair is termed as exact.\n  The four principal results of the paper are (a) the explicit construction of\na class of MDS codes for d = n-1 >= 2k-1 termed the MISER code, that achieves\nthe cut-set bound on the repair bandwidth for the exact-repair of systematic\nnodes, (b) proof of the necessity of interference alignment in exact-repair MSR\ncodes, (c) a proof showing the impossibility of constructing linear,\nexact-repair MSR codes for d < 2k-3 in the absence of symbol extension, and (d)\nthe construction, also explicit, of MSR codes for d = k+1. Interference\nalignment (IA) is a theme that runs throughout the paper: the MISER code is\nbuilt on the principles of IA and IA is also a crucial component to the\nnon-existence proof for d < 2k-3. To the best of our knowledge, the\nconstructions presented in this paper are the first, explicit constructions of\nregenerating codes that achieve the cut-set bound.\n", "contributors": [{"name": "Shah, Nihar B.", "sameAs": [], "familyName": "Shah", "additionalName": "B.", "givenName": "Nihar", "email": ""}, {"name": "Rashmi, K. V.", "sameAs": [], "familyName": "Rashmi", "additionalName": "V.", "givenName": "K.", "email": ""}, {"name": "Kumar, P. Vijay", "sameAs": [], "familyName": "Kumar", "additionalName": "Vijay", "givenName": "P.", "email": ""}, {"name": "Ramchandran, Kannan", "sameAs": [], "familyName": "Ramchandran", "additionalName": "", "givenName": "Kannan", "email": ""}], "title": "Interference Alignment in Regenerating Codes for Distributed Storage:\n  Necessity and Code Constructions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-05-10", "2010-09-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.1634", "doi:10.1109/TIT.2011.2178588", "oai:arXiv.org:1005.1634"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Regenerating codes are a class of recently developed codes for distributed\nstorage that, like Reed-Solomon codes, permit data recovery from any arbitrary\nk of n nodes. However regenerating codes possess in addition, the ability to\nrepair a failed node by connecting to any arbitrary d nodes and downloading an\namount of data that is typically far less than the size of the data file. This\namount of download is termed the repair bandwidth. Minimum storage regenerating\n(MSR) codes are a subclass of regenerating codes that require the least amount\nof network storage; every such code is a maximum distance separable (MDS) code.\nFurther, when a replacement node stores data identical to that in the failed\nnode, the repair is termed as exact.\n  The four principal results of the paper are (a) the explicit construction of\na class of MDS codes for d = n-1 >= 2k-1 termed the MISER code, that achieves\nthe cut-set bound on the repair bandwidth for the exact-repair of systematic\nnodes, (b) proof of the necessity of interference alignment in exact-repair MSR\ncodes, (c) a proof showing the impossibility of constructing linear,\nexact-repair MSR codes for d < 2k-3 in the absence of symbol extension, and (d)\nthe construction, also explicit, of MSR codes for d = k+1. Interference\nalignment (IA) is a theme that runs throughout the paper: the MISER code is\nbuilt on the principles of IA and IA is also a crucial component to the\nnon-existence proof for d < 2k-3. To the best of our knowledge, the\nconstructions presented in this paper are the first, explicit constructions of\nregenerating codes that achieve the cut-set bound.\n", "Comment: 38 pages, 12 figures, submitted to the IEEE Transactions on\n  Information Theory;v3 - The title has been modified to better reflect the\n  contributions of the submission. The paper is extensively revised with\n  several carefully constructed figures and examples"]}}], "languages": [null], "subjects": ["computer science - distributed", "computer science - networking and internet architecture", "computer science - information theory", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.1634"}}, {"publisher": {"name": ""}, "description": "  In this paper, we investigate a largely extended version of classical MAB\nproblem, called networked combinatorial bandit problems. In particular, we\nconsider the setting of a decision maker over a networked bandits as follows:\neach time a combinatorial strategy, e.g., a group of arms, is chosen, and the\ndecision maker receives a reward resulting from her strategy and also receives\na side bonus resulting from that strategy for each arm's neighbor. This is\nmotivated by many real applications such as on-line social networks where\nfriends can provide their feedback on shared content, therefore if we promote a\nproduct to a user, we can also collect feedback from her friends on that\nproduct. To this end, we consider two types of side bonus in this study: side\nobservation and side reward. Upon the number of arms pulled at each time slot,\nwe study two cases: single-play and combinatorial-play. Consequently, this\nleaves us four scenarios to investigate in the presence of side bonus:\nSingle-play with Side Observation, Combinatorial-play with Side Observation,\nSingle-play with Side Reward, and Combinatorial-play with Side Reward. For each\ncase, we present and analyze a series of \\emph{zero regret} polices where the\nexpect of regret over time approaches zero as time goes to infinity. Extensive\nsimulations validate the effectiveness of our results.\n", "contributors": [{"name": "Tang, Shaojie", "sameAs": [], "familyName": "Tang", "additionalName": "", "givenName": "Shaojie", "email": ""}, {"name": "Zhou, Yaqin", "sameAs": [], "familyName": "Zhou", "additionalName": "", "givenName": "Yaqin", "email": ""}], "title": "Networked Stochastic Multi-Armed Bandits with Combinatorial Strategies", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06169", "oai:arXiv.org:1503.06169"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we investigate a largely extended version of classical MAB\nproblem, called networked combinatorial bandit problems. In particular, we\nconsider the setting of a decision maker over a networked bandits as follows:\neach time a combinatorial strategy, e.g., a group of arms, is chosen, and the\ndecision maker receives a reward resulting from her strategy and also receives\na side bonus resulting from that strategy for each arm's neighbor. This is\nmotivated by many real applications such as on-line social networks where\nfriends can provide their feedback on shared content, therefore if we promote a\nproduct to a user, we can also collect feedback from her friends on that\nproduct. To this end, we consider two types of side bonus in this study: side\nobservation and side reward. Upon the number of arms pulled at each time slot,\nwe study two cases: single-play and combinatorial-play. Consequently, this\nleaves us four scenarios to investigate in the presence of side bonus:\nSingle-play with Side Observation, Combinatorial-play with Side Observation,\nSingle-play with Side Reward, and Combinatorial-play with Side Reward. For each\ncase, we present and analyze a series of \\emph{zero regret} polices where the\nexpect of regret over time approaches zero as time goes to infinity. Extensive\nsimulations validate the effectiveness of our results.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-03-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06169"}}, {"publisher": {"name": ""}, "description": "  Surveillance applications require a collection of heterogeneous vehicles to\nvisit a set of targets. In this article, we consider a fundamental routing\nproblem that arises in these applications involving two vehicles. Specifically,\nwe consider a routing problem where there are two heterogeneous vehicles that\nstart from distinct initial locations, and a set of targets. The objective is\nto find a tour for each vehicle such that each of the targets is visited at\nleast once by a vehicle and the sum of the distances traveled by the vehicles\nis a minimum. We present a primal-dual algorithm for a variant of this routing\nproblem that provides an approximation ratio of 2.\n", "contributors": [{"name": "Bae, Jungyun", "sameAs": [], "familyName": "Bae", "additionalName": "", "givenName": "Jungyun", "email": ""}, {"name": "Rathinam, Sivakumar", "sameAs": [], "familyName": "Rathinam", "additionalName": "", "givenName": "Sivakumar", "email": ""}], "title": "A Primal Dual Algorithm for a Heterogeneous Traveling Salesman Problem", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-02", "2013-04-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.0567", "oai:arXiv.org:1111.0567"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Surveillance applications require a collection of heterogeneous vehicles to\nvisit a set of targets. In this article, we consider a fundamental routing\nproblem that arises in these applications involving two vehicles. Specifically,\nwe consider a routing problem where there are two heterogeneous vehicles that\nstart from distinct initial locations, and a set of targets. The objective is\nto find a tour for each vehicle such that each of the targets is visited at\nleast once by a vehicle and the sum of the distances traveled by the vehicles\nis a minimum. We present a primal-dual algorithm for a variant of this routing\nproblem that provides an approximation ratio of 2.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - robotics", "computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.0567"}}, {"publisher": {"name": ""}, "description": "  The advent of high performance computing (HPC) and graphics processing units\n(GPU), present an enormous computation resource for Large data transactions\n(big data) that require parallel processing for robust and prompt data\nanalysis. While a number of HPC frameworks have been proposed, parallel\nprogramming models present a number of challenges, for instance, how to fully\nutilize features in the different programming models to implement and manage\nparallelism via multi-threading in both CPUs and GPUs. In this paper, we take\nan overview of three parallel programming models, CUDA, MapReduce, and\nPthreads. The goal is to explore literature on the subject and provide a high\nlevel view of the features presented in the programming models to assist high\nperformance users with a concise understanding of parallel programming concepts\nand thus faster implementation of big data projects using high performance\ncomputing.\n", "contributors": [{"name": "Mivule, Kato", "sameAs": [], "familyName": "Mivule", "additionalName": "", "givenName": "Kato", "email": ""}, {"name": "Harvey, Benjamin", "sameAs": [], "familyName": "Harvey", "additionalName": "", "givenName": "Benjamin", "email": ""}, {"name": "Cobb, Crystal", "sameAs": [], "familyName": "Cobb", "additionalName": "", "givenName": "Crystal", "email": ""}, {"name": "Sayed, Hoda El", "sameAs": [], "familyName": "Sayed", "additionalName": "El", "givenName": "Hoda", "email": ""}], "title": "A Review of CUDA, MapReduce, and Pthreads Parallel Computing Models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4453", "oai:arXiv.org:1410.4453"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The advent of high performance computing (HPC) and graphics processing units\n(GPU), present an enormous computation resource for Large data transactions\n(big data) that require parallel processing for robust and prompt data\nanalysis. While a number of HPC frameworks have been proposed, parallel\nprogramming models present a number of challenges, for instance, how to fully\nutilize features in the different programming models to implement and manage\nparallelism via multi-threading in both CPUs and GPUs. In this paper, we take\nan overview of three parallel programming models, CUDA, MapReduce, and\nPthreads. The goal is to explore literature on the subject and provide a high\nlevel view of the features presented in the programming models to assist high\nperformance users with a concise understanding of parallel programming concepts\nand thus faster implementation of big data projects using high performance\ncomputing.\n", "Comment: 10 Pages, 18 Figures"]}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4453"}}, {"publisher": {"name": ""}, "description": "  A flaw in the greedy approximation algorithm proposed by Zhang et al. for\nminimum connected set cover problem is corrected, and a stronger result on the\napproximation ratio of the modified greedy algorithm is established. The\nresults are now consistent with the existing results on connected dominating\nset problem which is a special case of the minimum connected set cover problem.\n", "contributors": [{"name": "Ren, Wei", "sameAs": [], "familyName": "Ren", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Zhao, Qing", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Qing", "email": ""}], "title": "A Note on: `Algorithms for Connected Set Cover Problem and\n  Fault-Tolerant Connected Set Cover Problem'", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-04-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.0733", "oai:arXiv.org:1104.0733"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  A flaw in the greedy approximation algorithm proposed by Zhang et al. for\nminimum connected set cover problem is corrected, and a stronger result on the\napproximation ratio of the modified greedy algorithm is established. The\nresults are now consistent with the existing results on connected dominating\nset problem which is a special case of the minimum connected set cover problem.\n", "Comment: 6 pages, 1 figure, submitted to Theoretical Computer Science"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.0733"}}, {"publisher": {"name": ""}, "description": "  The security of public key validation protocols for web-based applications\nhas recently attracted attention because of weaknesses in the certificate\nauthority model, and consequent attacks.\n  Recent proposals using public logs have succeeded in making certificate\nmanagement more transparent and verifiable. How- ever, those proposals involve\na fixed set of authorities which create a monopoly, and they have heavy\nreliance on trusted parties that monitor the logs.\n  We propose a distributed transparent key infrastructure (DTKI), which greatly\nreduces the monopoly of service providers and removes the reliance on trusted\nparties. In addition, this paper formalises the public log data structure and\nprovides a formal analysis of the security that DTKI guarantees.\n", "contributors": [{"name": "Cheval, Vincent", "sameAs": [], "familyName": "Cheval", "additionalName": "", "givenName": "Vincent", "email": ""}, {"name": "Ryan, Mark", "sameAs": [], "familyName": "Ryan", "additionalName": "", "givenName": "Mark", "email": ""}, {"name": "Yu, Jiangshan", "sameAs": [], "familyName": "Yu", "additionalName": "", "givenName": "Jiangshan", "email": ""}], "title": "DTKI: a new formalized PKI with no trusted parties", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-05", "2015-02-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.1023", "oai:arXiv.org:1408.1023"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The security of public key validation protocols for web-based applications\nhas recently attracted attention because of weaknesses in the certificate\nauthority model, and consequent attacks.\n  Recent proposals using public logs have succeeded in making certificate\nmanagement more transparent and verifiable. How- ever, those proposals involve\na fixed set of authorities which create a monopoly, and they have heavy\nreliance on trusted parties that monitor the logs.\n  We propose a distributed transparent key infrastructure (DTKI), which greatly\nreduces the monopoly of service providers and removes the reliance on trusted\nparties. In addition, this paper formalises the public log data structure and\nprovides a formal analysis of the security that DTKI guarantees.\n", "Comment: 16 pages"]}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.1023"}}, {"publisher": {"name": ""}, "description": "  Mobile ad-hoc networks(MANET) is the collection of mobile nodes which are\nself organizing and are connected by wireless links where nodes which are not\nin the direct range communicate with each other relying on the intermediate\nnodes. As a result of trusting other nodes in the route, a malicious node can\neasily compromise the security of the network. A black-hole node is the\nmalicious node which drops the entire packet coming to it and always shows the\nfresh route to the destination, even if the route to destination doesn't exist.\nThis paper describes a scheme that will detect the intrusion in the network in\nthe presence of black-hole node and its performance is compared with the\nprevious technique. This novel technique helps to increase the network\nperformance by reducing the overhead in the network.\n", "contributors": [{"name": "Dua, Deepika", "sameAs": [], "familyName": "Dua", "additionalName": "", "givenName": "Deepika", "email": ""}, {"name": "Mishra, Atul", "sameAs": [], "familyName": "Mishra", "additionalName": "", "givenName": "Atul", "email": ""}], "title": "Selective Watchdog Technique for Intrusion Detection in Mobile Ad-Hoc\n  Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6150", "International Journal on Applications of Graph Theory in Wireless\n  Ad hoc Networks and Sensor Networks (GRAPH-HOC) Vol.6, No.3, September 2014", "oai:arXiv.org:1412.6150"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Mobile ad-hoc networks(MANET) is the collection of mobile nodes which are\nself organizing and are connected by wireless links where nodes which are not\nin the direct range communicate with each other relying on the intermediate\nnodes. As a result of trusting other nodes in the route, a malicious node can\neasily compromise the security of the network. A black-hole node is the\nmalicious node which drops the entire packet coming to it and always shows the\nfresh route to the destination, even if the route to destination doesn't exist.\nThis paper describes a scheme that will detect the intrusion in the network in\nthe presence of black-hole node and its performance is compared with the\nprevious technique. This novel technique helps to increase the network\nperformance by reducing the overhead in the network.\n", "Comment: 12 pages,8 figures"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6150"}}, {"publisher": {"name": ""}, "description": "  The exploitation of the mm-wave bands is one of the most promising solutions\nfor 5G mobile radio networks. However, the use of mm-wave technologies in\ncellular networks is not straightforward due to mm-wave severe propagation\nconditions that limit access availability. In order to overcome this obstacle,\nhybrid network architectures are being considered where mmwave small cells can\nexploit an overlay coverage layer based on legacy technology. The additional\nmm-wave layer can also take advantage of a functional split between control and\nuser plane, that allows to delegate most of the signaling functions to legacy\nbase stations and to gather context information from users for resource\noptimization. However, mm-wave technology requires multiple antennas and highly\ndirectional transmissions to compensate for high path loss and limited power.\nDirectional transmissions must be also used for the cell discovery and\nsynchronization process, and this can lead to a non negligible delay due to\nneed to scan the cell area with multiple transmissions in different angles. In\nthis paper, we propose to exploit the context information related to user\nposition, provided by the separated control plane, to improve the cell search\nprocedure and minimize delay. We investigate the fundamental trade-offs of the\ncell discovery process with directional antennas and the effects of the context\ninformation accuracy on its performance. Numerical results are provided to\nvalidate our observations.\n", "contributors": [{"name": "Capone, Antonio", "sameAs": [], "familyName": "Capone", "additionalName": "", "givenName": "Antonio", "email": ""}, {"name": "Filippini, Ilario", "sameAs": [], "familyName": "Filippini", "additionalName": "", "givenName": "Ilario", "email": ""}, {"name": "Sciancalepore, Vincenzo", "sameAs": [], "familyName": "Sciancalepore", "additionalName": "", "givenName": "Vincenzo", "email": ""}], "title": "Context-based Cell Search in Millimeter Wave 5G Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.02223", "oai:arXiv.org:1501.02223"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The exploitation of the mm-wave bands is one of the most promising solutions\nfor 5G mobile radio networks. However, the use of mm-wave technologies in\ncellular networks is not straightforward due to mm-wave severe propagation\nconditions that limit access availability. In order to overcome this obstacle,\nhybrid network architectures are being considered where mmwave small cells can\nexploit an overlay coverage layer based on legacy technology. The additional\nmm-wave layer can also take advantage of a functional split between control and\nuser plane, that allows to delegate most of the signaling functions to legacy\nbase stations and to gather context information from users for resource\noptimization. However, mm-wave technology requires multiple antennas and highly\ndirectional transmissions to compensate for high path loss and limited power.\nDirectional transmissions must be also used for the cell discovery and\nsynchronization process, and this can lead to a non negligible delay due to\nneed to scan the cell area with multiple transmissions in different angles. In\nthis paper, we propose to exploit the context information related to user\nposition, provided by the separated control plane, to improve the cell search\nprocedure and minimize delay. We investigate the fundamental trade-offs of the\ncell discovery process with directional antennas and the effects of the context\ninformation accuracy on its performance. Numerical results are provided to\nvalidate our observations.\n", "Comment: 5 pages, 5 figures, Submitted VTC2015-Spring - Massive MIMO and\n  Millimeter-waves for 5G Networks Workshop (mmW5G-WS)"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-01-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.02223"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "In order to better understand how humans acquire knowledge, one of the essential goals in cognitive science is to build a cognitive model of human learning. Moreover, a cognitive model that better matches student behavior will often yield better instruction in intelligent tutoring systems. However, manual construction of such cognitive models is time consuming, and requires domain expertise. Further, manually-constructed models may still miss distinctions in learning which are important for instruction. Our prior work proposed an approach that finds cognitive models using a state-of-the-art learning agent, SimStudent, and we demonstrated that, for algebra learning, the agent can find a better cognitive model than human experts. To ensure the generality of that proposed approach, we further apply it to three domains: algebra, stoichiometry, and fraction addition. To evaluate the quality of the cognitive models discovered, we measured how well the cognitive models fit to student learning curve data. In two of those domains, SimStudent directly discovers a cognitive model that predicts human student behavior better than the human-generated model. In fraction addition, SimStudent supported discovery of a better cognitive model in combination with another automated cognitive model discovery method.", "contributors": [{"name": "Li, Nan", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Nan", "email": ""}, {"name": "Stampfer, Eliane", "sameAs": [], "familyName": "Stampfer", "additionalName": "", "givenName": "Eliane", "email": ""}, {"name": "Cohen, William W.", "sameAs": [], "familyName": "Cohen", "additionalName": "W.", "givenName": "William", "email": ""}, {"name": "Koedinger, Kenneth R", "sameAs": [], "familyName": "Koedinger", "additionalName": "R", "givenName": "Kenneth", "email": ""}], "title": "General and Efficient Cognitive Model Discovery Using a Simulated Student", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2013-08-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/27", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1026&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1026"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "In order to better understand how humans acquire knowledge, one of the essential goals in cognitive science is to build a cognitive model of human learning. Moreover, a cognitive model that better matches student behavior will often yield better instruction in intelligent tutoring systems. However, manual construction of such cognitive models is time consuming, and requires domain expertise. Further, manually-constructed models may still miss distinctions in learning which are important for instruction. Our prior work proposed an approach that finds cognitive models using a state-of-the-art learning agent, SimStudent, and we demonstrated that, for algebra learning, the agent can find a better cognitive model than human experts. To ensure the generality of that proposed approach, we further apply it to three domains: algebra, stoichiometry, and fraction addition. To evaluate the quality of the cognitive models discovered, we measured how well the cognitive models fit to student learning curve data. In two of those domains, SimStudent directly discovers a cognitive model that predicts human student behavior better than the human-generated model. In fraction addition, SimStudent supported discovery of a better cognitive model in combination with another automated cognitive model discovery method."}}], "languages": [null], "subjects": ["theory and algorithms", "cognitive model", "computer sciences", "simulated student", "machine learning"], "providerUpdatedDateTime": "2015-03-05T22:10:56", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/27"}}, {"publisher": {"name": ""}, "description": "  We propose a new Bayesian tracking and parameter learning algorithm for\nnon-linear non-Gaussian multiple target tracking (MTT) models. We design a\nMarkov chain Monte Carlo (MCMC) algorithm to sample from the posterior\ndistribution of the target states, birth and death times, and association of\nobservations to targets, which constitutes the solution to the tracking\nproblem, as well as the model parameters. In the numerical section, we present\nperformance comparisons with several competing techniques and demonstrate\nsignificant performance improvements in all cases.\n", "contributors": [{"name": "Jiang, Lan", "sameAs": [], "familyName": "Jiang", "additionalName": "", "givenName": "Lan", "email": ""}, {"name": "Singh, Sumeetpal S.", "sameAs": [], "familyName": "Singh", "additionalName": "S.", "givenName": "Sumeetpal", "email": ""}, {"name": "Y\u0131ld\u0131r\u0131m, Sinan", "sameAs": [], "familyName": "Y\u0131ld\u0131r\u0131m", "additionalName": "", "givenName": "Sinan", "email": ""}], "title": "Bayesian tracking and parameter learning for non-linear multiple target\n  tracking models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2046", "oai:arXiv.org:1410.2046"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  We propose a new Bayesian tracking and parameter learning algorithm for\nnon-linear non-Gaussian multiple target tracking (MTT) models. We design a\nMarkov chain Monte Carlo (MCMC) algorithm to sample from the posterior\ndistribution of the target states, birth and death times, and association of\nobservations to targets, which constitutes the solution to the tracking\nproblem, as well as the model parameters. In the numerical section, we present\nperformance comparisons with several competing techniques and demonstrate\nsignificant performance improvements in all cases.\n"}}], "languages": [null], "subjects": ["statistics - applications", "statistics - computation", "statistics - machine learning"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2046"}}, {"publisher": {"name": ""}, "description": "  We study the complexity of quantum query algorithms that make p queries in\nparallel in each timestep. This model is in part motivated by the fact that\ndecoherence times of qubits are typically small, so it makes sense to\nparallelize quantum algorithms as much as possible. We show tight bounds for a\nnumber of problems, specifically Theta((n/p)^{2/3}) p-parallel queries for\nelement distinctness and Theta((n/p)^{k/(k+1)} for k-sum. Our upper bounds are\nobtained by parallelized quantum walk algorithms, and our lower bounds are\nbased on a relatively small modification of the adversary lower bound method,\ncombined with recent results of Belovs et al. on learning graphs. We also prove\nsome general bounds, in particular that quantum and classical p-parallel\ncomplexity are polynomially related for all total functions f when p is small\ncompared to f's block sensitivity.\n", "contributors": [{"name": "Jeffery, Stacey", "sameAs": [], "familyName": "Jeffery", "additionalName": "", "givenName": "Stacey", "email": ""}, {"name": "Magniez, Frederic", "sameAs": [], "familyName": "Magniez", "additionalName": "", "givenName": "Frederic", "email": ""}, {"name": "de Wolf, Ronald", "sameAs": [], "familyName": "de Wolf", "additionalName": "", "givenName": "Ronald", "email": ""}], "title": "Optimal parallel quantum query algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-09-24", "2015-02-20"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1309.6116", "oai:arXiv.org:1309.6116"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": ["  We study the complexity of quantum query algorithms that make p queries in\nparallel in each timestep. This model is in part motivated by the fact that\ndecoherence times of qubits are typically small, so it makes sense to\nparallelize quantum algorithms as much as possible. We show tight bounds for a\nnumber of problems, specifically Theta((n/p)^{2/3}) p-parallel queries for\nelement distinctness and Theta((n/p)^{k/(k+1)} for k-sum. Our upper bounds are\nobtained by parallelized quantum walk algorithms, and our lower bounds are\nbased on a relatively small modification of the adversary lower bound method,\ncombined with recent results of Belovs et al. on learning graphs. We also prove\nsome general bounds, in particular that quantum and classical p-parallel\ncomplexity are polynomially related for all total functions f when p is small\ncompared to f's block sensitivity.\n", "Comment: 19 pages LaTeX"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "quantum physics"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1309.6116"}}, {"publisher": {"name": ""}, "description": "  Dynamics and stability of average current-mode control of buck converters are\nanalyzed by sampled-data and harmonic balance analyses. An exact sampled-data\nmodel is derived. A new continuous-time model \"lifted\" from the sampled-data\nmodel is also derived, and has frequency response matched with experimental\ndata reported previously. Orbital stability is studied and it is found\nunrelated to the ripple size of the current-loop compensator output. An\nunstable window of the current-loop compensator pole is found by simulations,\nand it can be accurately predicted by sampled-data and harmonic balance\nanalyses. A new S plot accurately predicting the subharmonic oscillation is\nproposed. The S plot assists pole assignment and shows the required ramp slope\nto avoid instability.\n", "contributors": [{"name": "Fang, Chung-Chieh", "sameAs": [], "familyName": "Fang", "additionalName": "", "givenName": "Chung-Chieh", "email": ""}], "title": "Sampled-Data and Harmonic Balance Analyses of Average Current-Mode\n  Controlled Buck Converter", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-02-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1202.4537", "oai:arXiv.org:1202.4537"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:nlin"]}}, {"name": "description", "properties": {"description": ["  Dynamics and stability of average current-mode control of buck converters are\nanalyzed by sampled-data and harmonic balance analyses. An exact sampled-data\nmodel is derived. A new continuous-time model \"lifted\" from the sampled-data\nmodel is also derived, and has frequency response matched with experimental\ndata reported previously. Orbital stability is studied and it is found\nunrelated to the ripple size of the current-loop compensator output. An\nunstable window of the current-loop compensator pole is found by simulations,\nand it can be accurately predicted by sampled-data and harmonic balance\nanalyses. A new S plot accurately predicting the subharmonic oscillation is\nproposed. The S plot assists pole assignment and shows the required ramp slope\nto avoid instability.\n", "Comment: Submitted to International Journal of Circuit Theory and Applications\n  on August 9, 2011; Manuscript ID: CTA-11-0168"]}}], "languages": [null], "subjects": ["computer science - systems and control", "nonlinear sciences - chaotic dynamics", "mathematics - dynamical systems"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1202.4537"}}, {"publisher": {"name": ""}, "description": "  Ranking of agents competing with each other in complex systems may lead to\nparadoxes according to the pre-chosen different measures. A discussion is\npresented on such rank-rank, similar or not, correlations based on the case of\nEuropean countries ranked by UEFA and FIFA from different soccer competitions.\nThe first question to be answered is whether an empirical and simple law is\nobtained for such (self-) organizations of complex sociological systems with\nsuch different measuring schemes. It is found that the power law form is not\nthe best description contrary to many modern expectations. The stretched\nexponential is much more adequate. Moreover, it is found that the measuring\nrules lead to some inner structures, in both cases.\n", "contributors": [{"name": "Ausloos, Marcel", "sameAs": [], "familyName": "Ausloos", "additionalName": "", "givenName": "Marcel", "email": ""}, {"name": "Cloots, Rudi", "sameAs": [], "familyName": "Cloots", "additionalName": "", "givenName": "Rudi", "email": ""}, {"name": "Gadomski, Adam", "sameAs": [], "familyName": "Gadomski", "additionalName": "", "givenName": "Adam", "email": ""}, {"name": "Vitanov, Nikolay K.", "sameAs": [], "familyName": "Vitanov", "additionalName": "K.", "givenName": "Nikolay", "email": ""}], "title": "Ranking structures and Rank-Rank Correlations of Countries. The FIFA and\n  UEFA cases", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-03-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.5683", "Int. J. Mod. Phys. C 25 (11), 1450060 (2014)", "doi:10.1142/S0129183114500600", "oai:arXiv.org:1403.5683"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:nlin", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Ranking of agents competing with each other in complex systems may lead to\nparadoxes according to the pre-chosen different measures. A discussion is\npresented on such rank-rank, similar or not, correlations based on the case of\nEuropean countries ranked by UEFA and FIFA from different soccer competitions.\nThe first question to be answered is whether an empirical and simple law is\nobtained for such (self-) organizations of complex sociological systems with\nsuch different measuring schemes. It is found that the power law form is not\nthe best description contrary to many modern expectations. The stretched\nexponential is much more adequate. Moreover, it is found that the measuring\nrules lead to some inner structures, in both cases.\n", "Comment: 23 pages, 8 figures, 24 references, 3 tables; to be published in Int.\n  J. Mod. Phys. C"]}}], "languages": [null], "subjects": ["physics - physics and society", "physics - data analysis", "statistics and probability", "nonlinear sciences - adaptation and self-organizing systems", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-10-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.5683"}}, {"publisher": {"name": ""}, "description": "  We consider ideals and Boolean combinations of ideals. For the regular\nlanguages within these classes we give expressively complete automaton models.\nIn addition, we consider general properties of regular ideals and their Boolean\ncombinations. These properties include effective algebraic characterizations\nand lattice identities.\n  In the main part of this paper we consider the following deterministic\none-way automaton models: unions of flip automata, weak automata, and\nStaiger-Wagner automata. We show that each of these models is expressively\ncomplete for regular Boolean combination of right ideals. Right ideals over\nfinite words resemble the open sets in the Cantor topology over infinite words.\nAn omega-regular language is a Boolean combination of open sets if and only if\nit is recognizable by a deterministic Staiger-Wagner automaton; and our result\ncan be seen as a finitary version of this classical theorem. In addition, we\nalso consider the canonical automaton models for right ideals, prefix-closed\nlanguages, and factorial languages.\n  In the last section, we consider a two-way automaton model which is known to\nbe expressively complete for two-variable first-order logic. We show that the\nabove concepts can be adapted to these two-way automata such that the resulting\nlanguages are the right ideals (resp. prefix-closed languages, resp. Boolean\ncombinations of right ideals) definable in two-variable first-order logic.\n", "contributors": [{"name": "Jahn, Franz", "sameAs": [], "familyName": "Jahn", "additionalName": "", "givenName": "Franz", "email": ""}, {"name": "Kufleitner, Manfred", "sameAs": [], "familyName": "Kufleitner", "additionalName": "", "givenName": "Manfred", "email": ""}, {"name": "Lauser, Alexander", "sameAs": [], "familyName": "Lauser", "additionalName": "", "givenName": "Alexander", "email": ""}], "title": "Regular Ideal Languages and Their Boolean Combinations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-02-24", "2012-05-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1102.5013", "oai:arXiv.org:1102.5013"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We consider ideals and Boolean combinations of ideals. For the regular\nlanguages within these classes we give expressively complete automaton models.\nIn addition, we consider general properties of regular ideals and their Boolean\ncombinations. These properties include effective algebraic characterizations\nand lattice identities.\n  In the main part of this paper we consider the following deterministic\none-way automaton models: unions of flip automata, weak automata, and\nStaiger-Wagner automata. We show that each of these models is expressively\ncomplete for regular Boolean combination of right ideals. Right ideals over\nfinite words resemble the open sets in the Cantor topology over infinite words.\nAn omega-regular language is a Boolean combination of open sets if and only if\nit is recognizable by a deterministic Staiger-Wagner automaton; and our result\ncan be seen as a finitary version of this classical theorem. In addition, we\nalso consider the canonical automaton models for right ideals, prefix-closed\nlanguages, and factorial languages.\n  In the last section, we consider a two-way automaton model which is known to\nbe expressively complete for two-variable first-order logic. We show that the\nabove concepts can be adapted to these two-way automata such that the resulting\nlanguages are the right ideals (resp. prefix-closed languages, resp. Boolean\ncombinations of right ideals) definable in two-variable first-order logic.\n", "Comment: Presented at CIAA 2012"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "68q45", "f.4.1", "f.1.1"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1102.5013"}}, {"publisher": {"name": ""}, "description": "  Compression algorithms are important for data oriented tasks, especially in\nthe era of Big Data. Modern processors equipped with powerful SIMD instruction\nsets, provide us an opportunity for achieving better compression performance.\nPrevious research has shown that SIMD-based optimizations can multiply decoding\nspeeds. Following these pioneering studies, we propose a general approach to\naccelerate compression algorithms. By instantiating the approach, we have\ndeveloped several novel integer compression algorithms, called Group-Simple,\nGroup-Scheme, Group-AFOR, and Group-PFD, and implemented their corresponding\nvectorized versions. We evaluate the proposed algorithms on two public TREC\ndatasets, a Wikipedia dataset and a Twitter dataset. With competitive\ncompression ratios and encoding speeds, our SIMD-based algorithms outperform\nstate-of-the-art non-vectorized algorithms with respect to decoding speeds.\n", "contributors": [{"name": "Zhao, Wayne Xin", "sameAs": [], "familyName": "Zhao", "additionalName": "Xin", "givenName": "Wayne", "email": ""}, {"name": "Zhang, Xudong", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Xudong", "email": ""}, {"name": "Lemire, Daniel", "sameAs": [], "familyName": "Lemire", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Shan, Dongdong", "sameAs": [], "familyName": "Shan", "additionalName": "", "givenName": "Dongdong", "email": ""}, {"name": "Nie, Jian-Yun", "sameAs": [], "familyName": "Nie", "additionalName": "", "givenName": "Jian-Yun", "email": ""}, {"name": "Yan, Hongfei", "sameAs": [], "familyName": "Yan", "additionalName": "", "givenName": "Hongfei", "email": ""}, {"name": "Wen, Ji-Rong", "sameAs": [], "familyName": "Wen", "additionalName": "", "givenName": "Ji-Rong", "email": ""}], "title": "A General SIMD-based Approach to Accelerating Compression Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01916", "ACM Trans. Inf. Syst. 33, 3, Article 15 (March 2015)", "doi:10.1145/2735629", "oai:arXiv.org:1502.01916"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Compression algorithms are important for data oriented tasks, especially in\nthe era of Big Data. Modern processors equipped with powerful SIMD instruction\nsets, provide us an opportunity for achieving better compression performance.\nPrevious research has shown that SIMD-based optimizations can multiply decoding\nspeeds. Following these pioneering studies, we propose a general approach to\naccelerate compression algorithms. By instantiating the approach, we have\ndeveloped several novel integer compression algorithms, called Group-Simple,\nGroup-Scheme, Group-AFOR, and Group-PFD, and implemented their corresponding\nvectorized versions. We evaluate the proposed algorithms on two public TREC\ndatasets, a Wikipedia dataset and a Twitter dataset. With competitive\ncompression ratios and encoding speeds, our SIMD-based algorithms outperform\nstate-of-the-art non-vectorized algorithms with respect to decoding speeds.\n"}}], "languages": [null], "subjects": ["c.1.2", "computer science - information retrieval", "h.3.1", "e.4"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01916"}}, {"publisher": {"name": ""}, "description": "  Random sampling is an essential tool in the processing and transmission of\ndata. It is used to summarize data too large to store or manipulate and meet\nresource constraints on bandwidth or battery power. Estimators that are applied\nto the sample facilitate fast approximate processing of queries posed over the\noriginal data and the value of the sample hinges on the quality of these\nestimators.\n  Our work targets data sets such as request and traffic logs and sensor\nmeasurements, where data is repeatedly collected over multiple {\\em instances}:\ntime periods, locations, or snapshots.\n  We are interested in queries that span multiple instances, such as distinct\ncounts and distance measures over selected records. These queries are used for\napplications ranging from planning to anomaly and change detection.\n  Unbiased low-variance estimators are particularly effective as the relative\nerror decreases with the number of selected record keys.\n  The Horvitz-Thompson estimator, known to minimize variance for sampling with\n\"all or nothing\" outcomes (which reveals exacts value or no information on\nestimated quantity), is not optimal for multi-instance operations for which an\noutcome may provide partial information.\n  We present a general principled methodology for the derivation of (Pareto)\noptimal unbiased estimators over sampled instances and aim to understand its\npotential. We demonstrate significant improvement in estimate accuracy of\nfundamental queries for common sampling schemes.\n", "contributors": [{"name": "Cohen, Edith", "sameAs": [], "familyName": "Cohen", "additionalName": "", "givenName": "Edith", "email": ""}, {"name": "Kaplan, Haim", "sameAs": [], "familyName": "Kaplan", "additionalName": "", "givenName": "Haim", "email": ""}], "title": "Get the Most out of Your Sample: Optimal Unbiased Estimators using\n  Partial Information", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-09-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.1325", "oai:arXiv.org:1109.1325"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  Random sampling is an essential tool in the processing and transmission of\ndata. It is used to summarize data too large to store or manipulate and meet\nresource constraints on bandwidth or battery power. Estimators that are applied\nto the sample facilitate fast approximate processing of queries posed over the\noriginal data and the value of the sample hinges on the quality of these\nestimators.\n  Our work targets data sets such as request and traffic logs and sensor\nmeasurements, where data is repeatedly collected over multiple {\\em instances}:\ntime periods, locations, or snapshots.\n  We are interested in queries that span multiple instances, such as distinct\ncounts and distance measures over selected records. These queries are used for\napplications ranging from planning to anomaly and change detection.\n  Unbiased low-variance estimators are particularly effective as the relative\nerror decreases with the number of selected record keys.\n  The Horvitz-Thompson estimator, known to minimize variance for sampling with\n\"all or nothing\" outcomes (which reveals exacts value or no information on\nestimated quantity), is not optimal for multi-instance operations for which an\noutcome may provide partial information.\n  We present a general principled methodology for the derivation of (Pareto)\noptimal unbiased estimators over sampled instances and aim to understand its\npotential. We demonstrate significant improvement in estimate accuracy of\nfundamental queries for common sampling schemes.\n", "Comment: This is a full version of a PODS 2011 paper"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "g.3", "computer science - databases", "computer science - networking and internet architecture", "e.2", "computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.1325"}}, {"publisher": {"name": ""}, "description": "  Looping is one of the fundamental logical instructions used for repeating a\nblock of code. It is used in programs across all programming languages.\nTraditionally, in languages like C, the for loop is used extensively for\nrepeated execution of a block of code, due to its ease for use and simplified\nrepresentation. This paper proposes a new way of representing the for loop to\nimprove its runtime efficiency and compares the experimental statistics with\nthe traditional for loop representation. It is found that for small number of\niterations, the difference in computational time may not be considerable. But\ngiven any large number of iterations, the difference is noticeable.\n", "contributors": [{"name": "Jain, Rishabh", "sameAs": [], "familyName": "Jain", "additionalName": "", "givenName": "Rishabh", "email": ""}, {"name": "Gupta, Sakshi", "sameAs": [], "familyName": "Gupta", "additionalName": "", "givenName": "Sakshi", "email": ""}], "title": "Optimizing the For loop: Comparison of For loop and micro For loop", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.3772", "oai:arXiv.org:1410.3772"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Looping is one of the fundamental logical instructions used for repeating a\nblock of code. It is used in programs across all programming languages.\nTraditionally, in languages like C, the for loop is used extensively for\nrepeated execution of a block of code, due to its ease for use and simplified\nrepresentation. This paper proposes a new way of representing the for loop to\nimprove its runtime efficiency and compares the experimental statistics with\nthe traditional for loop representation. It is found that for small number of\niterations, the difference in computational time may not be considerable. But\ngiven any large number of iterations, the difference is noticeable.\n", "Comment: 3 pages, 2 figures, 2 tables"]}}], "languages": [null], "subjects": ["computer science - programming languages", "68-02"], "providerUpdatedDateTime": "2014-10-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.3772"}}, {"publisher": {"name": ""}, "description": "  There is a great need for accurate and autonomous spectral classification\nmethods in astrophysics. This thesis is about training a convolutional neural\nnetwork (ConvNet) to recognize an object class (quasar, star or galaxy) from\none-dimension spectra only. Author developed several scripts and C programs for\ndatasets preparation, preprocessing and postprocessing of the data. EBLearn\nlibrary (developed by Pierre Sermanet and Yann LeCun) was used to create\nConvNets. Application on dataset of more than 60000 spectra yielded success\nrate of nearly 95%. This thesis conclusively proved great potential of\nconvolutional neural networks and deep learning methods in astrophysics.\n", "contributors": [{"name": "H\u00e1la, Pavel", "sameAs": [], "familyName": "H\u00e1la", "additionalName": "", "givenName": "Pavel", "email": ""}], "title": "Spectral classification using convolutional neural networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.8341", "oai:arXiv.org:1412.8341"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:astro-ph"]}}, {"name": "description", "properties": {"description": ["  There is a great need for accurate and autonomous spectral classification\nmethods in astrophysics. This thesis is about training a convolutional neural\nnetwork (ConvNet) to recognize an object class (quasar, star or galaxy) from\none-dimension spectra only. Author developed several scripts and C programs for\ndatasets preparation, preprocessing and postprocessing of the data. EBLearn\nlibrary (developed by Pierre Sermanet and Yann LeCun) was used to create\nConvNets. Application on dataset of more than 60000 spectra yielded success\nrate of nearly 95%. This thesis conclusively proved great potential of\nconvolutional neural networks and deep learning methods in astrophysics.\n", "Comment: 71 pages, 50 figures, Master's thesis, Masaryk University"]}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "astrophysics - instrumentation and methods for astrophysics", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.8341"}}, {"publisher": {"name": ""}, "description": "  While high-dimensional search-by-similarity techniques reached their maturity\nand in overall provide good performance, most of them are unable to cope with\nvery large multimedia collections. The 'big data' challenge however has to be\naddressed as multimedia collections have been explosively growing and will grow\neven faster than ever within the next few years. Luckily, computational\nprocessing power has become more available to researchers due to easier access\nto distributed grid infrastructures. In this paper, we show how\nhigh-dimensional indexing and searching methods can be used on scientific grid\nenvironments and present a scalable workflow for indexing and searching over 30\nbillion SIFT descriptors using a cluster running Hadoop. Besides its\nscalability, the proposed scheme not only provides good search quality, but\nalso achieves a stable throughput of around 210ms per image when searching a\n100M image collection. Our findings could help other researchers and\npractitioners to cope with huge multimedia collections.\n", "contributors": [{"name": "Shestakov, Denis", "sameAs": [], "familyName": "Shestakov", "additionalName": "", "givenName": "Denis", "email": ""}, {"name": "Moise, Diana", "sameAs": [], "familyName": "Moise", "additionalName": "", "givenName": "Diana", "email": ""}], "title": "Scalable high-dimensional indexing and searching with Hadoop", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.02398", "oai:arXiv.org:1501.02398"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  While high-dimensional search-by-similarity techniques reached their maturity\nand in overall provide good performance, most of them are unable to cope with\nvery large multimedia collections. The 'big data' challenge however has to be\naddressed as multimedia collections have been explosively growing and will grow\neven faster than ever within the next few years. Luckily, computational\nprocessing power has become more available to researchers due to easier access\nto distributed grid infrastructures. In this paper, we show how\nhigh-dimensional indexing and searching methods can be used on scientific grid\nenvironments and present a scalable workflow for indexing and searching over 30\nbillion SIFT descriptors using a cluster running Hadoop. Besides its\nscalability, the proposed scheme not only provides good search quality, but\nalso achieves a stable throughput of around 210ms per image when searching a\n100M image collection. Our findings could help other researchers and\npractitioners to cope with huge multimedia collections.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "computer science - information retrieval", "computer science - multimedia", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-01-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.02398"}}, {"publisher": {"name": ""}, "description": "  Traditionally, object localization is cast as an image window classification\nproblem, where each window is considered independently and scored based on its\nappearance alone. Instead, we propose a method which scores each candidate\nwindow in the context of all other windows in the image, taking into account\ntheir similarity in appearance space as well as their spatial relations in the\nimage plane. We devise a fast and exact procedure to optimize our score\nfunction over all candidate windows in an image, and we learn its parameters\nusing structured output regression. We demonstrate on 92000 images from\nImageNet that this significantly improves localization over some of the best\nrecent techniques that score windows in isolation.\n", "contributors": [{"name": "Vezhnevets, Alexander", "sameAs": [], "familyName": "Vezhnevets", "additionalName": "", "givenName": "Alexander", "email": ""}, {"name": "Ferrari, Vittorio", "sameAs": [], "familyName": "Ferrari", "additionalName": "", "givenName": "Vittorio", "email": ""}], "title": "Looking out of the window: object localization by joint analysis of all\n  windows in the image", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.01181", "oai:arXiv.org:1501.01181"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Traditionally, object localization is cast as an image window classification\nproblem, where each window is considered independently and scored based on its\nappearance alone. Instead, we propose a method which scores each candidate\nwindow in the context of all other windows in the image, taking into account\ntheir similarity in appearance space as well as their spatial relations in the\nimage plane. We devise a fast and exact procedure to optimize our score\nfunction over all candidate windows in an image, and we learn its parameters\nusing structured output regression. We demonstrate on 92000 images from\nImageNet that this significantly improves localization over some of the best\nrecent techniques that score windows in isolation.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.01181"}}, {"publisher": {"name": ""}, "description": "  Human computation is a computing approach that draws upon human cognitive\nabilities to solve computational tasks for which there are so far no\nsatisfactory fully automated solutions even when using the most advanced\ncomputing technologies available. Human computation for citizen science\nprojects consists in designing systems that allow large crowds of volunteers to\ncontribute to scientific research by executing human computation tasks.\nExamples of successful projects are Galaxy Zoo and FoldIt. A key feature of\nthis kind of project is its capacity to engage volunteers. An important\nrequirement for the proposal and evaluation of new engagement strategies is\nhaving a clear understanding of the typical engagement of the volunteers;\nhowever, even though several projects of this kind have already been completed,\nlittle is known about this issue. In this paper, we investigate the engagement\npattern of the volunteers in their interactions in human computation for\ncitizen science projects, how they differ among themselves in terms of\nengagement, and how those volunteer engagement features should be taken into\naccount for establishing the engagement encouragement strategies that should be\nbrought into play in a given project. To this end, we define four quantitative\nengagement metrics to measure different aspects of volunteer engagement, and\nuse data mining algorithms to identify the different volunteer profiles in\nterms of the engagement metrics. Our study is based on data collected from two\nprojects: Galaxy Zoo and The Milky Way Project. The results show that the\nvolunteers in such projects can be grouped into five distinct engagement\nprofiles that we label as follows: hardworking, spasmodic, persistent, lasting,\nand moderate. The analysis of these profiles provides a deeper understanding of\nthe nature of volunteers' engagement in human computation for citizen science\nprojects\n", "contributors": [{"name": "Ponciano, Lesandro", "sameAs": [], "familyName": "Ponciano", "additionalName": "", "givenName": "Lesandro", "email": ""}, {"name": "Brasileiro, Francisco", "sameAs": [], "familyName": "Brasileiro", "additionalName": "", "givenName": "Francisco", "email": ""}], "title": "Finding Volunteers' Engagement Profiles in Human Computation for Citizen\n  Science Projects", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.02134", "Human Computation vol. 1, no. 2, pp. 245-264 (2014)", "doi:10.15346/hc.v1i2.12", "oai:arXiv.org:1501.02134"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Human computation is a computing approach that draws upon human cognitive\nabilities to solve computational tasks for which there are so far no\nsatisfactory fully automated solutions even when using the most advanced\ncomputing technologies available. Human computation for citizen science\nprojects consists in designing systems that allow large crowds of volunteers to\ncontribute to scientific research by executing human computation tasks.\nExamples of successful projects are Galaxy Zoo and FoldIt. A key feature of\nthis kind of project is its capacity to engage volunteers. An important\nrequirement for the proposal and evaluation of new engagement strategies is\nhaving a clear understanding of the typical engagement of the volunteers;\nhowever, even though several projects of this kind have already been completed,\nlittle is known about this issue. In this paper, we investigate the engagement\npattern of the volunteers in their interactions in human computation for\ncitizen science projects, how they differ among themselves in terms of\nengagement, and how those volunteer engagement features should be taken into\naccount for establishing the engagement encouragement strategies that should be\nbrought into play in a given project. To this end, we define four quantitative\nengagement metrics to measure different aspects of volunteer engagement, and\nuse data mining algorithms to identify the different volunteer profiles in\nterms of the engagement metrics. Our study is based on data collected from two\nprojects: Galaxy Zoo and The Milky Way Project. The results show that the\nvolunteers in such projects can be grouped into five distinct engagement\nprofiles that we label as follows: hardworking, spasmodic, persistent, lasting,\nand moderate. The analysis of these profiles provides a deeper understanding of\nthe nature of volunteers' engagement in human computation for citizen science\nprojects\n", "Comment: 3 tables, and 4 figures"]}}], "languages": [null], "subjects": ["computer science - human-computer interaction", "computer science - computers and society"], "providerUpdatedDateTime": "2015-01-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.02134"}}, {"publisher": {"name": ""}, "description": "  We survey the application of a relatively new branch of statistical\nphysics--\"community detection\"-- to data mining. In particular, we focus on the\ndiagnosis of materials and automated image segmentation. Community detection\ndescribes the quest of partitioning a complex system involving many elements\ninto optimally decoupled subsets or communities of such elements. We review a\nmultiresolution variant which is used to ascertain structures at different\nspatial and temporal scales. Significant patterns are obtained by examining the\ncorrelations between different independent solvers. Similar to other\ncombinatorial optimization problems in the NP complexity class, community\ndetection exhibits several phases. Typically, illuminating orders are revealed\nby choosing parameters that lead to extremal information theory correlations.\n", "contributors": [{"name": "Nussinov, Z.", "sameAs": [], "familyName": "Nussinov", "additionalName": "", "givenName": "Z.", "email": ""}, {"name": "Ronhovde, P.", "sameAs": [], "familyName": "Ronhovde", "additionalName": "", "givenName": "P.", "email": ""}, {"name": "Hu, Dandan", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Dandan", "email": ""}, {"name": "Chakrabarty, S.", "sameAs": [], "familyName": "Chakrabarty", "additionalName": "", "givenName": "S.", "email": ""}, {"name": "Sahu, M.", "sameAs": [], "familyName": "Sahu", "additionalName": "", "givenName": "M.", "email": ""}, {"name": "Sun, Bo", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Bo", "email": ""}, {"name": "Mauro, N. A.", "sameAs": [], "familyName": "Mauro", "additionalName": "A.", "givenName": "N.", "email": ""}, {"name": "Sahu, K. K.", "sameAs": [], "familyName": "Sahu", "additionalName": "K.", "givenName": "K.", "email": ""}], "title": "Inference of hidden structures in complex physical systems by\n  multi-scale clustering", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01626", "oai:arXiv.org:1503.01626"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We survey the application of a relatively new branch of statistical\nphysics--\"community detection\"-- to data mining. In particular, we focus on the\ndiagnosis of materials and automated image segmentation. Community detection\ndescribes the quest of partitioning a complex system involving many elements\ninto optimally decoupled subsets or communities of such elements. We review a\nmultiresolution variant which is used to ascertain structures at different\nspatial and temporal scales. Significant patterns are obtained by examining the\ncorrelations between different independent solvers. Similar to other\ncombinatorial optimization problems in the NP complexity class, community\ndetection exhibits several phases. Typically, illuminating orders are revealed\nby choosing parameters that lead to extremal information theory correlations.\n", "Comment: 25 pages, 16 Figures; a review of earlier works"]}}], "languages": [null], "subjects": ["physics - data analysis", "condensed matter - statistical mechanics", "statistics and probability", "computer science - computer vision and pattern recognition", "condensed matter - materials science"], "providerUpdatedDateTime": "2015-03-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01626"}}, {"publisher": {"name": ""}, "description": "  Gaussian fields (GFs) are frequently used in spatial statistics for their\nversatility. The associated computational cost can be a bottleneck, especially\nin realistic applications. It has been shown that computational efficiency can\nbe gained by doing the computations using Gaussian Markov random fields (GMRFs)\nas the GFs can be seen as weak solutions to corresponding stochastic partial\ndifferential equations (SPDEs) using piecewise linear finite elements. We\nintroduce a new class of representations of GFs with bivariate splines instead\nof finite elements. This allows an easier implementation of piecewise\npolynomial representations of various degrees. It leads to GMRFs that can be\ninferred efficiently and can be easily extended to non-stationary fields. The\nsolutions approximated with higher order bivariate splines converge faster,\nhence the computational cost can be alleviated. Numerical simulations using\nboth real and simulated data also demonstrate that our framework increases the\nflexibility and efficiency.\n", "contributors": [{"name": "Liu, Xiaoyu", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Xiaoyu", "email": ""}, {"name": "Guillas, Serge", "sameAs": [], "familyName": "Guillas", "additionalName": "", "givenName": "Serge", "email": ""}, {"name": "Lai, Ming-Jun", "sameAs": [], "familyName": "Lai", "additionalName": "", "givenName": "Ming-Jun", "email": ""}], "title": "Efficient spatial modelling using the SPDE approach with bivariate\n  splines", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03761", "oai:arXiv.org:1503.03761"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": ["  Gaussian fields (GFs) are frequently used in spatial statistics for their\nversatility. The associated computational cost can be a bottleneck, especially\nin realistic applications. It has been shown that computational efficiency can\nbe gained by doing the computations using Gaussian Markov random fields (GMRFs)\nas the GFs can be seen as weak solutions to corresponding stochastic partial\ndifferential equations (SPDEs) using piecewise linear finite elements. We\nintroduce a new class of representations of GFs with bivariate splines instead\nof finite elements. This allows an easier implementation of piecewise\npolynomial representations of various degrees. It leads to GMRFs that can be\ninferred efficiently and can be easily extended to non-stationary fields. The\nsolutions approximated with higher order bivariate splines converge faster,\nhence the computational cost can be alleviated. Numerical simulations using\nboth real and simulated data also demonstrate that our framework increases the\nflexibility and efficiency.\n", "Comment: 26 pages, 7 figures and 3 tables"]}}], "languages": [null], "subjects": ["statistics - computation", "statistics - methodology"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03761"}}, {"publisher": {"name": ""}, "description": "  We consider a Gaussian two-hop network where the source and the destination\ncan communicate only via a relay node who is both an eavesdropper and a\nByzantine adversary. Both the source and the destination nodes are allowed to\ntransmit, and the relay receives a superposition of their transmitted signals.\nWe propose a new coding scheme that satisfies two requirements simultaneously:\nthe transmitted message must be kept secret from the relay node, and the\ndestination must be able to detect any Byzantine attack that the relay node\nmight launch reliably and fast. The three main components of the scheme are the\nnested lattice code, the privacy amplification and the algebraic manipulation\ndetection (AMD)code. Specifically, for the Gaussian two-hop network, we show\nthat lattice coding can successfully pair with AMD codes enabling its first\napplication to a noisy channel model. We prove, using this new coding scheme,\nthat the probability that the Byzantine attack goes undetected decreases\nexponentially fast with respect to the number of channel uses, while the loss\nin the secrecy rate, compared to the rate achievable when the relay is honest,\ncan be made arbitrarily small. In addition, in contrast with prior work in\nGaussian channels, the notion of secrecy provided here is strong secrecy.\n", "contributors": [{"name": "He, Xiang", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Xiang", "email": ""}, {"name": "Yener, Aylin", "sameAs": [], "familyName": "Yener", "additionalName": "", "givenName": "Aylin", "email": ""}], "title": "Strong Secrecy and Reliable Byzantine Detection in the Presence of an\n  Untrusted Relay", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-04-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1004.1423", "oai:arXiv.org:1004.1423"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider a Gaussian two-hop network where the source and the destination\ncan communicate only via a relay node who is both an eavesdropper and a\nByzantine adversary. Both the source and the destination nodes are allowed to\ntransmit, and the relay receives a superposition of their transmitted signals.\nWe propose a new coding scheme that satisfies two requirements simultaneously:\nthe transmitted message must be kept secret from the relay node, and the\ndestination must be able to detect any Byzantine attack that the relay node\nmight launch reliably and fast. The three main components of the scheme are the\nnested lattice code, the privacy amplification and the algebraic manipulation\ndetection (AMD)code. Specifically, for the Gaussian two-hop network, we show\nthat lattice coding can successfully pair with AMD codes enabling its first\napplication to a noisy channel model. We prove, using this new coding scheme,\nthat the probability that the Byzantine attack goes undetected decreases\nexponentially fast with respect to the number of channel uses, while the loss\nin the secrecy rate, compared to the rate achievable when the relay is honest,\ncan be made arbitrarily small. In addition, in contrast with prior work in\nGaussian channels, the notion of secrecy provided here is strong secrecy.\n", "Comment: Submitted to IEEE Transactions on Information Theory, March 2010. 35\n  pages."]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1004.1423"}}, {"publisher": {"name": ""}, "description": "  This paper introduces Manhattan sampling in two and higher dimensions, and\nproves sampling theorems. In two dimensions, Manhattan sampling, which takes\nsamples densely along a Manhattan grid of lines, can be viewed as sampling on\nthe union of two rectangular lattices, one dense horizontally, being a multiple\nof the fine spacing of the other. The sampling theorem shows that images\nbandlimited to the union of the Nyquist regions of the two rectangular lattices\ncan be recovered from their Manhattan samples, and an efficient procedure for\ndoing so is given. Such recovery is possible even though there is overlap among\nthe spectral replicas induced by Manhattan sampling.\n  In three and higher dimensions, there are many possible configurations for\nManhattan sampling, each consisting of the union of special rectangular\nlattices called bi-step lattices. This paper identifies them, proves a sampling\ntheorem showing that images bandlimited to the union of the Nyquist regions of\nthe bi-step rectangular lattices are recoverable from Manhattan samples, and\npresents an efficient onion-peeling procedure for doing so. Furthermore, it\ndevelops a special representation for the bi-step lattices and an algebra with\nnice properties. It is also shown that the set of reconstructable images is\nmaximal in the Landau sense.\n  While most of the paper deals with continuous-space images, Manhattan\nsampling of discrete-space images is also considered, for infinite, as well as\nfinite, support images.\n", "contributors": [{"name": "Prelee, Matthew A.", "sameAs": [], "familyName": "Prelee", "additionalName": "A.", "givenName": "Matthew", "email": ""}, {"name": "Neuhoff, David L.", "sameAs": [], "familyName": "Neuhoff", "additionalName": "L.", "givenName": "David", "email": ""}], "title": "Multidimensional Manhattan Sampling and Reconstruction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01694", "oai:arXiv.org:1502.01694"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper introduces Manhattan sampling in two and higher dimensions, and\nproves sampling theorems. In two dimensions, Manhattan sampling, which takes\nsamples densely along a Manhattan grid of lines, can be viewed as sampling on\nthe union of two rectangular lattices, one dense horizontally, being a multiple\nof the fine spacing of the other. The sampling theorem shows that images\nbandlimited to the union of the Nyquist regions of the two rectangular lattices\ncan be recovered from their Manhattan samples, and an efficient procedure for\ndoing so is given. Such recovery is possible even though there is overlap among\nthe spectral replicas induced by Manhattan sampling.\n  In three and higher dimensions, there are many possible configurations for\nManhattan sampling, each consisting of the union of special rectangular\nlattices called bi-step lattices. This paper identifies them, proves a sampling\ntheorem showing that images bandlimited to the union of the Nyquist regions of\nthe bi-step rectangular lattices are recoverable from Manhattan samples, and\npresents an efficient onion-peeling procedure for doing so. Furthermore, it\ndevelops a special representation for the bi-step lattices and an algebra with\nnice properties. It is also shown that the set of reconstructable images is\nmaximal in the Landau sense.\n  While most of the paper deals with continuous-space images, Manhattan\nsampling of discrete-space images is also considered, for infinite, as well as\nfinite, support images.\n", "Comment: 36 pages"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01694"}}, {"publisher": {"name": ""}, "description": "  Recent literature on online learning has focused on developing adaptive\nalgorithms that take advantage of a regularity of the sequence of observations,\nyet retain worst-case performance guarantees. A complementary direction is to\ndevelop prediction methods that perform well against complex benchmarks. In\nthis paper, we address these two directions together. We present a fully\nadaptive method that competes with dynamic benchmarks in which regret guarantee\nscales with regularity of the sequence of cost functions and comparators.\nNotably, the regret bound adapts to the smaller complexity measure in the\nproblem environment. Finally, we apply our results to drifting zero-sum,\ntwo-player games where both players achieve no regret guarantees against best\nsequences of actions in hindsight.\n", "contributors": [{"name": "Jadbabaie, Ali", "sameAs": [], "familyName": "Jadbabaie", "additionalName": "", "givenName": "Ali", "email": ""}, {"name": "Rakhlin, Alexander", "sameAs": [], "familyName": "Rakhlin", "additionalName": "", "givenName": "Alexander", "email": ""}, {"name": "Shahrampour, Shahin", "sameAs": [], "familyName": "Shahrampour", "additionalName": "", "givenName": "Shahin", "email": ""}, {"name": "Sridharan, Karthik", "sameAs": [], "familyName": "Sridharan", "additionalName": "", "givenName": "Karthik", "email": ""}], "title": "Online Optimization : Competing with Dynamic Comparators", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06225", "oai:arXiv.org:1501.06225"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  Recent literature on online learning has focused on developing adaptive\nalgorithms that take advantage of a regularity of the sequence of observations,\nyet retain worst-case performance guarantees. A complementary direction is to\ndevelop prediction methods that perform well against complex benchmarks. In\nthis paper, we address these two directions together. We present a fully\nadaptive method that competes with dynamic benchmarks in which regret guarantee\nscales with regularity of the sequence of cost functions and comparators.\nNotably, the regret bound adapts to the smaller complexity measure in the\nproblem environment. Finally, we apply our results to drifting zero-sum,\ntwo-player games where both players achieve no regret guarantees against best\nsequences of actions in hindsight.\n", "Comment: 23 pages, To appear in International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2015"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06225"}}, {"publisher": {"name": ""}, "description": "  The idea of using compressed sensing as an acquisition protocol with some\nencryption properties has been envisioned, but never explored in depth since\nits security may seem doomed by the intrinsic linearity of the encoding\nprocess. In this investigation, we quantify some aspects of straightforward\nstatistical analysis and known-plaintext attacks showing that, although not\nperfectly secret, compressed sensing with universal encoding matrices grants a\nnoteworthy level of data hiding, that may come at almost-zero cost in\nlimited-resources applications. Moreover, the simplicity of the encoding method\nallows the definition of a general, lightweight scheme with which encoders may\ndistribute the same information to receivers of different \"classes\", the latter\nbeing able to retrieve it with provably different quality levels. The\neffectiveness of this multiclass data hiding strategy is also analyzed by\nquantifying the chances that a low-class decoder has to reconstruct the\nhigh-class decoding keys by means of known-plaintext attacks. Examples showing\nthe effect of multiclass encoding in a variety of settings (speech, images and\nelectrocardiographic signals) are reported.\n", "contributors": [{"name": "Cambareri, Valerio", "sameAs": [], "familyName": "Cambareri", "additionalName": "", "givenName": "Valerio", "email": ""}, {"name": "Mangia, Mauro", "sameAs": [], "familyName": "Mangia", "additionalName": "", "givenName": "Mauro", "email": ""}, {"name": "Pareschi, Fabio", "sameAs": [], "familyName": "Pareschi", "additionalName": "", "givenName": "Fabio", "email": ""}, {"name": "Rovatti, Riccardo", "sameAs": [], "familyName": "Rovatti", "additionalName": "", "givenName": "Riccardo", "email": ""}, {"name": "Setti, Gianluca", "sameAs": [], "familyName": "Setti", "additionalName": "", "givenName": "Gianluca", "email": ""}], "title": "Low-complexity Multiclass Encryption by Compressed Sensing, Part I:\n  Definition and Main Properties", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-07-12", "2013-11-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1307.3360", "oai:arXiv.org:1307.3360"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The idea of using compressed sensing as an acquisition protocol with some\nencryption properties has been envisioned, but never explored in depth since\nits security may seem doomed by the intrinsic linearity of the encoding\nprocess. In this investigation, we quantify some aspects of straightforward\nstatistical analysis and known-plaintext attacks showing that, although not\nperfectly secret, compressed sensing with universal encoding matrices grants a\nnoteworthy level of data hiding, that may come at almost-zero cost in\nlimited-resources applications. Moreover, the simplicity of the encoding method\nallows the definition of a general, lightweight scheme with which encoders may\ndistribute the same information to receivers of different \"classes\", the latter\nbeing able to retrieve it with provably different quality levels. The\neffectiveness of this multiclass data hiding strategy is also analyzed by\nquantifying the chances that a low-class decoder has to reconstruct the\nhigh-class decoding keys by means of known-plaintext attacks. Examples showing\nthe effect of multiclass encoding in a variety of settings (speech, images and\nelectrocardiographic signals) are reported.\n", "Comment: Draft of original submission to an IEEE journal publication"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1307.3360"}}, {"publisher": {"name": ""}, "description": "  We show that the default-all propagation scheme for database annotations is\ndangerous. Dangerous here means that it can propagate annotations to the query\noutput which are semantically irrelevant to the query the user asked. This is\nthe result of considering all relationally equivalent queries and returning the\nunion of their where-provenance in an attempt to define a propagation scheme\nthat is insensitive to query rewriting. We propose an alternative\nquery-rewrite-insensitive (QRI) where-provenance called minimum propagation. It\nis analogous to the minimum witness basis for why-provenance, straight-forward\nto evaluate, and returns all relevant and only relevant annotations.\n", "contributors": [{"name": "Gatterbauer, Wolfgang", "sameAs": [], "familyName": "Gatterbauer", "additionalName": "", "givenName": "Wolfgang", "email": ""}, {"name": "Meliou, Alexandra", "sameAs": [], "familyName": "Meliou", "additionalName": "", "givenName": "Alexandra", "email": ""}, {"name": "Suciu, Dan", "sameAs": [], "familyName": "Suciu", "additionalName": "", "givenName": "Dan", "email": ""}], "title": "Default-all is dangerous!", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.4395", "oai:arXiv.org:1105.4395"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We show that the default-all propagation scheme for database annotations is\ndangerous. Dangerous here means that it can propagate annotations to the query\noutput which are semantically irrelevant to the query the user asked. This is\nthe result of considering all relationally equivalent queries and returning the\nunion of their where-provenance in an attempt to define a propagation scheme\nthat is insensitive to query rewriting. We propose an alternative\nquery-rewrite-insensitive (QRI) where-provenance called minimum propagation. It\nis analogous to the minimum witness basis for why-provenance, straight-forward\nto evaluate, and returns all relevant and only relevant annotations.\n", "Comment: 4 pages, 6 figures, preprint of paper appearing in Proceedings of\n  TaPP '11 (3rd USENIX Workshop on the Theory and Practice of Provenance); for\n  details see the project page: http://db.cs.washington.edu/causality/"]}}], "languages": [null], "subjects": ["computer science - databases"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.4395"}}, {"publisher": {"name": ""}, "description": "  Regularized training of an autoencoder typically results in hidden unit\nbiases that take on large negative values. We show that negative biases are a\nnatural result of using a hidden layer whose responsibility is to both\nrepresent the input data and act as a selection mechanism that ensures sparsity\nof the representation. We then show that negative biases impede the learning of\ndata distributions whose intrinsic dimensionality is high. We also propose a\nnew activation function that decouples the two roles of the hidden layer and\nthat allows us to learn representations on data with very high intrinsic\ndimensionality, where standard autoencoders typically fail. Since the decoupled\nactivation function acts like an implicit regularizer, the model can be trained\nby minimizing the reconstruction error of training data, without requiring any\nadditional regularization.\n", "contributors": [{"name": "Konda, Kishore", "sameAs": [], "familyName": "Konda", "additionalName": "", "givenName": "Kishore", "email": ""}, {"name": "Memisevic, Roland", "sameAs": [], "familyName": "Memisevic", "additionalName": "", "givenName": "Roland", "email": ""}, {"name": "Krueger, David", "sameAs": [], "familyName": "Krueger", "additionalName": "", "givenName": "David", "email": ""}], "title": "Zero-bias autoencoders and the benefits of co-adapting features", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-13", "2015-04-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.3337", "oai:arXiv.org:1402.3337"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  Regularized training of an autoencoder typically results in hidden unit\nbiases that take on large negative values. We show that negative biases are a\nnatural result of using a hidden layer whose responsibility is to both\nrepresent the input data and act as a selection mechanism that ensures sparsity\nof the representation. We then show that negative biases impede the learning of\ndata distributions whose intrinsic dimensionality is high. We also propose a\nnew activation function that decouples the two roles of the hidden layer and\nthat allows us to learn representations on data with very high intrinsic\ndimensionality, where standard autoencoders typically fail. Since the decoupled\nactivation function acts like an implicit regularizer, the model can be trained\nby minimizing the reconstruction error of training data, without requiring any\nadditional regularization.\n"}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - learning", "statistics - machine learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-04-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.3337"}}, {"publisher": {"name": ""}, "description": "  Let $m^*(n)$ be the minimum number of edges in an $n$-uniform simple\nhypergraph that is not two colorable. We prove that\n$m^*(n)=\\Omega(4^n/\\ln^2(n))$. Our result generalizes to $r$-coloring of\n$b$-simple uniform hypergraphs. For fixed $r$ and $b$ we prove that a maximum\nvertex degree in $b$-simple $n$-uniform hypergraph that is not $r$-colorable\nmust be $\\Omega(r^n /\\ln(n))$. By trimming arguments it implies that every such\ngraph has $\\Omega((r^n /\\ln(n))^{b+1/b})$ edges. For any fixed $r \\geq 2$ our\ntechniques yield also a lower bound $\\Omega(r^n/\\ln(n))$ for van der Waerden\nnumbers $W(n,r)$.\n", "contributors": [{"name": "Kozik, Jakub", "sameAs": [], "familyName": "Kozik", "additionalName": "", "givenName": "Jakub", "email": ""}], "title": "Multipass greedy coloring of simple uniform hypergraphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-22", "2014-10-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.5984", "oai:arXiv.org:1310.5984"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Let $m^*(n)$ be the minimum number of edges in an $n$-uniform simple\nhypergraph that is not two colorable. We prove that\n$m^*(n)=\\Omega(4^n/\\ln^2(n))$. Our result generalizes to $r$-coloring of\n$b$-simple uniform hypergraphs. For fixed $r$ and $b$ we prove that a maximum\nvertex degree in $b$-simple $n$-uniform hypergraph that is not $r$-colorable\nmust be $\\Omega(r^n /\\ln(n))$. By trimming arguments it implies that every such\ngraph has $\\Omega((r^n /\\ln(n))^{b+1/b})$ edges. For any fixed $r \\geq 2$ our\ntechniques yield also a lower bound $\\Omega(r^n/\\ln(n))$ for van der Waerden\nnumbers $W(n,r)$.\n"}}], "languages": [null], "subjects": ["g.2.1", "g.2.2", "computer science - discrete mathematics", "05c65", "g.3", "05d40", "05c15", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-10-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.5984"}}, {"publisher": {"name": ""}, "description": "  The intricate network of interactions observed in RNA three-dimensional\nstructures is often described in terms of a multitude of geometrical\nproperties, including helical parameters, base pairing/stacking, hydrogen\nbonding and backbone conformation. We show that a simple molecular\nrepresentation consisting in one oriented bead per nucleotide can account for\nthe fundamental structural properties of RNA. In this framework, canonical\nWatson-Crick, non-Watson-Crick base-pairing and base-stacking interactions can\nbe unambiguously identified within a well-defined interaction shell. We\nvalidate this representation by performing two independent, complementary\ntests. First, we use it to construct a sequence-independent, knowledge-based\nscoring function for RNA structural prediction, which compares favorably to\nfully atomistic, state-of-the-art techniques. Second, we define a metric to\nmeasure deviation between RNA structures that directly reports on the\ndifferences in the base-base interaction network. The effectiveness of this\nmetric is tested with respect to the ability to discriminate between\nstructurally and kinetically distant RNA conformations, performing better\ncompared to standard techniques. Taken together, our results suggest that this\nminimalist, nucleobase-centric representation captures the main interactions\nthat are relevant for describing RNA structure and dynamics.\n", "contributors": [{"name": "Bottaro, Sandro", "sameAs": [], "familyName": "Bottaro", "additionalName": "", "givenName": "Sandro", "email": ""}, {"name": "Di Palma, Francesco", "sameAs": [], "familyName": "Di Palma", "additionalName": "", "givenName": "Francesco", "email": ""}, {"name": "Bussi, Giovanni", "sameAs": [], "familyName": "Bussi", "additionalName": "", "givenName": "Giovanni", "email": ""}], "title": "The Role of Nucleobase Interactions in RNA Structure and Dynamics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1271", "doi:10.1093/nar/gku972", "oai:arXiv.org:1410.1271"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:physics", "q-bio"]}}, {"name": "description", "properties": {"description": ["  The intricate network of interactions observed in RNA three-dimensional\nstructures is often described in terms of a multitude of geometrical\nproperties, including helical parameters, base pairing/stacking, hydrogen\nbonding and backbone conformation. We show that a simple molecular\nrepresentation consisting in one oriented bead per nucleotide can account for\nthe fundamental structural properties of RNA. In this framework, canonical\nWatson-Crick, non-Watson-Crick base-pairing and base-stacking interactions can\nbe unambiguously identified within a well-defined interaction shell. We\nvalidate this representation by performing two independent, complementary\ntests. First, we use it to construct a sequence-independent, knowledge-based\nscoring function for RNA structural prediction, which compares favorably to\nfully atomistic, state-of-the-art techniques. Second, we define a metric to\nmeasure deviation between RNA structures that directly reports on the\ndifferences in the base-base interaction network. The effectiveness of this\nmetric is tested with respect to the ability to discriminate between\nstructurally and kinetically distant RNA conformations, performing better\ncompared to standard techniques. Taken together, our results suggest that this\nminimalist, nucleobase-centric representation captures the main interactions\nthat are relevant for describing RNA structure and dynamics.\n", "Comment: Accepted for publication on Nucleic Acids Research"]}}], "languages": [null], "subjects": ["physics - computational physics", "physics - chemical physics", "quantitative biology - biomolecules", "physics - biological physics"], "providerUpdatedDateTime": "2014-10-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1271"}}, {"publisher": {"name": ""}, "description": "  For the study of citation networks, a challenging problem is modeling the\nhigh clustering. Existing studies indicate that the promising way to model the\nhigh clustering is a copying strategy, i.e., a paper copies the references of\nits neighbour as its own references. However, the line of models highly\nunderestimates the number of abundant triangles observed in real citation\nnetworks and thus cannot well model the high clustering. In this paper, we\npoint out that the failure of existing models lies in that they do not capture\nthe connecting patterns among existing papers. By leveraging the knowledge\nindicated by such connecting patterns, we further propose a new model for the\nhigh clustering in citation networks. Experiments on two real world citation\nnetworks, respectively from a special research area and a multidisciplinary\nresearch area, demonstrate that our model can reproduce not only the power-law\ndegree distribution as traditional models but also the number of triangles, the\nhigh clustering coefficient and the size distribution of co-citation clusters\nas observed in these real networks.\n", "contributors": [{"name": "Ren, Fu-Xin", "sameAs": [], "familyName": "Ren", "additionalName": "", "givenName": "Fu-Xin", "email": ""}, {"name": "Cheng, Xue-Qi", "sameAs": [], "familyName": "Cheng", "additionalName": "", "givenName": "Xue-Qi", "email": ""}, {"name": "Shen, Hua-Wei", "sameAs": [], "familyName": "Shen", "additionalName": "", "givenName": "Hua-Wei", "email": ""}], "title": "Modeling the clustering in citation networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-21", "2012-02-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.4209", "Physica A: Statistical Mechanics and its Applications, 391:\n  3533-3539, (2012)", "doi:10.1016/j.physa.2012.02.001", "oai:arXiv.org:1104.4209"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  For the study of citation networks, a challenging problem is modeling the\nhigh clustering. Existing studies indicate that the promising way to model the\nhigh clustering is a copying strategy, i.e., a paper copies the references of\nits neighbour as its own references. However, the line of models highly\nunderestimates the number of abundant triangles observed in real citation\nnetworks and thus cannot well model the high clustering. In this paper, we\npoint out that the failure of existing models lies in that they do not capture\nthe connecting patterns among existing papers. By leveraging the knowledge\nindicated by such connecting patterns, we further propose a new model for the\nhigh clustering in citation networks. Experiments on two real world citation\nnetworks, respectively from a special research area and a multidisciplinary\nresearch area, demonstrate that our model can reproduce not only the power-law\ndegree distribution as traditional models but also the number of triangles, the\nhigh clustering coefficient and the size distribution of co-citation clusters\nas observed in these real networks.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - digital libraries", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.4209"}}, {"publisher": {"name": ""}, "description": "  We analyze the problem of regression when both input covariates and output\nresponses are functions from a nonparametric function class. Function to\nfunction regression (FFR) covers a large range of interesting applications\nincluding time-series prediction problems, and also more general tasks like\nstudying a mapping between two separate types of distributions. However,\nprevious nonparametric estimators for FFR type problems scale badly\ncomputationally with the number of input/output pairs in a data-set. Given the\ncomplexity of a mapping between general functions it may be necessary to\nconsider large data-sets in order to achieve a low estimation risk. To address\nthis issue, we develop a novel scalable nonparametric estimator, the\nTriple-Basis Estimator (3BE), which is capable of operating over datasets with\nmany instances. To the best of our knowledge, the 3BE is the first\nnonparametric FFR estimator that can scale to massive datasets. We analyze the\n3BE's risk and derive an upperbound rate. Furthermore, we show an improvement\nof several orders of magnitude in terms of prediction speed and a reduction in\nerror over previous estimators in various real-world data-sets.\n", "contributors": [{"name": "Oliva, Junier", "sameAs": [], "familyName": "Oliva", "additionalName": "", "givenName": "Junier", "email": ""}, {"name": "Neiswanger, Willie", "sameAs": [], "familyName": "Neiswanger", "additionalName": "", "givenName": "Willie", "email": ""}, {"name": "Poczos, Barnabas", "sameAs": [], "familyName": "Poczos", "additionalName": "", "givenName": "Barnabas", "email": ""}, {"name": "Xing, Eric", "sameAs": [], "familyName": "Xing", "additionalName": "", "givenName": "Eric", "email": ""}, {"name": "Schneider, Jeff", "sameAs": [], "familyName": "Schneider", "additionalName": "", "givenName": "Jeff", "email": ""}], "title": "Fast Function to Function Regression", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.7414", "oai:arXiv.org:1410.7414"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  We analyze the problem of regression when both input covariates and output\nresponses are functions from a nonparametric function class. Function to\nfunction regression (FFR) covers a large range of interesting applications\nincluding time-series prediction problems, and also more general tasks like\nstudying a mapping between two separate types of distributions. However,\nprevious nonparametric estimators for FFR type problems scale badly\ncomputationally with the number of input/output pairs in a data-set. Given the\ncomplexity of a mapping between general functions it may be necessary to\nconsider large data-sets in order to achieve a low estimation risk. To address\nthis issue, we develop a novel scalable nonparametric estimator, the\nTriple-Basis Estimator (3BE), which is capable of operating over datasets with\nmany instances. To the best of our knowledge, the 3BE is the first\nnonparametric FFR estimator that can scale to massive datasets. We analyze the\n3BE's risk and derive an upperbound rate. Furthermore, we show an improvement\nof several orders of magnitude in terms of prediction speed and a reduction in\nerror over previous estimators in various real-world data-sets.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-10-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.7414"}}, {"publisher": {"name": ""}, "description": "  The increasing adoption of Cloud-based data processing and storage poses a\nnumber of privacy issues. Users wish to preserve full control over their\nsensitive data and cannot accept it to be fully accessible to an external\nstorage provider. Previous research in this area was mostly addressed at\ntechniques to protect data stored on untrusted database servers; however, I\nargue that the Cloud architecture presents a number of specific problems and\nissues. This dissertation contains a detailed analysis of open issues. To\nhandle them, I present a novel approach where confidential data is stored in a\nhighly distributed partitioned database, partly located on the Cloud and partly\non the clients. In my approach, data can be either private or shared; the\nlatter is shared in a secure manner by means of simple grant-and-revoke\npermissions. I have developed a proof-of-concept implementation using an\nin-memory RDBMS with row-level data encryption in order to achieve fine-grained\ndata access control. This type of approach is rarely adopted in conventional\noutsourced RDBMSs because it requires several complex steps. Benchmarks of my\nproofof-concept implementation show that my approach overcomes most of the\nproblems.\n", "contributors": [{"name": "Pagano, Francesco", "sameAs": [], "familyName": "Pagano", "additionalName": "", "givenName": "Francesco", "email": ""}], "title": "A Distributed Approach to Privacy on the Cloud", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08115", "oai:arXiv.org:1503.08115"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The increasing adoption of Cloud-based data processing and storage poses a\nnumber of privacy issues. Users wish to preserve full control over their\nsensitive data and cannot accept it to be fully accessible to an external\nstorage provider. Previous research in this area was mostly addressed at\ntechniques to protect data stored on untrusted database servers; however, I\nargue that the Cloud architecture presents a number of specific problems and\nissues. This dissertation contains a detailed analysis of open issues. To\nhandle them, I present a novel approach where confidential data is stored in a\nhighly distributed partitioned database, partly located on the Cloud and partly\non the clients. In my approach, data can be either private or shared; the\nlatter is shared in a secure manner by means of simple grant-and-revoke\npermissions. I have developed a proof-of-concept implementation using an\nin-memory RDBMS with row-level data encryption in order to achieve fine-grained\ndata access control. This type of approach is rarely adopted in conventional\noutsourced RDBMSs because it requires several complex steps. Benchmarks of my\nproofof-concept implementation show that my approach overcomes most of the\nproblems.\n", "Comment: PhD Thesis in Computer Science at University of Milan - Italy 2012\n  March 6th"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - databases"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08115"}}, {"publisher": {"name": ""}, "description": "  We generalize the notion of the density property for complex manifolds to\nholomorphic fibrations, and introduce the notion of the fibred density\nproperty. We prove that the natural fibration of the spectral ball over the\nsymmetrized polydisc enjoys the fibred density property and describe the\nautomorphism group of the spectral ball.\n", "contributors": [{"name": "Andrist, Rafael B.", "sameAs": [], "familyName": "Andrist", "additionalName": "B.", "givenName": "Rafael", "email": ""}, {"name": "Kutzschebauch, Frank", "sameAs": [], "familyName": "Kutzschebauch", "additionalName": "", "givenName": "Frank", "email": ""}], "title": "The fibred density property and the automorphism group of the spectral\n  ball", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.07475", "oai:arXiv.org:1501.07475"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We generalize the notion of the density property for complex manifolds to\nholomorphic fibrations, and introduce the notion of the fibred density\nproperty. We prove that the natural fibration of the spectral ball over the\nsymmetrized polydisc enjoys the fibred density property and describe the\nautomorphism group of the spectral ball.\n", "Comment: 21 pages"]}}], "languages": [null], "subjects": ["32a07", "primary 32m17", "32m10", "secondary 32m25", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.07475"}}, {"publisher": {"name": ""}, "description": "  We consider the problem of estimating the number of triangles in a graph.\nThis problem has been extensively studied in two models: Exact counting\nalgorithms, which require reading the entire graph, and streaming algorithms,\nwhere the edges are given in a stream and the memory is limited. In this work\nwe design a \\emph{sublinear-time\\/} algorithm for approximating the number of\ntriangles in a graph, where the algorithm is given query access to the graph.\nThe allowed queries are degree queries, vertex-pair queries and neighbor\nqueries.\n  We show that for any given approximation parameter $0<\\epsilon<1$, the\nalgorithm provides an estimate $\\widehat{\\Delta}$ such that with high constant\nprobability, $(1-\\epsilon)\\Delta(G)< \\widehat{\\Delta}<(1+\\epsilon)\\Delta(G)$,\nwhere $\\Delta(G)$ is the number of triangles in the graph $G$. The expected\nquery complexity of the algorithm is $O\\left(\\frac{n}{\\Delta(G)^{1/3}} +\n\\min\\left\\{m, \\frac{m^{3/2}}{\\Delta(G)}\\right\\}\\right)\\cdot {\\rm poly}(\\log n,\n1/\\epsilon)$, where $n$ is the number of vertices in the graph and $m$ is the\nnumber of edges, and the expected running time is\n$O\\left(\\frac{n}{\\Delta(G)^{1/3}} + \\frac{m^{3/2}}{\\Delta(G)}\\right)\\cdot {\\rm\npoly}(\\log n, 1/\\epsilon)$. We also prove that\n$\\Omega\\left(\\frac{n}{\\Delta(G)^{1/3}} + \\min\\left\\{m,\n\\frac{m^{3/2}}{\\Delta(G)}\\right\\}\\right)$ queries are necessary, thus\nestablishing that the query complexity of this algorithm is optimal up to\npolylogarithmic factors in $n$ (and the dependence on $1/\\epsilon$).\n", "contributors": [{"name": "Eden, Talya", "sameAs": [], "familyName": "Eden", "additionalName": "", "givenName": "Talya", "email": ""}, {"name": "Levi, Amit", "sameAs": [], "familyName": "Levi", "additionalName": "", "givenName": "Amit", "email": ""}, {"name": "Ron, Dana", "sameAs": [], "familyName": "Ron", "additionalName": "", "givenName": "Dana", "email": ""}], "title": "Approximately Counting Triangles in Sublinear Time", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.00954", "oai:arXiv.org:1504.00954"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We consider the problem of estimating the number of triangles in a graph.\nThis problem has been extensively studied in two models: Exact counting\nalgorithms, which require reading the entire graph, and streaming algorithms,\nwhere the edges are given in a stream and the memory is limited. In this work\nwe design a \\emph{sublinear-time\\/} algorithm for approximating the number of\ntriangles in a graph, where the algorithm is given query access to the graph.\nThe allowed queries are degree queries, vertex-pair queries and neighbor\nqueries.\n  We show that for any given approximation parameter $0<\\epsilon<1$, the\nalgorithm provides an estimate $\\widehat{\\Delta}$ such that with high constant\nprobability, $(1-\\epsilon)\\Delta(G)< \\widehat{\\Delta}<(1+\\epsilon)\\Delta(G)$,\nwhere $\\Delta(G)$ is the number of triangles in the graph $G$. The expected\nquery complexity of the algorithm is $O\\left(\\frac{n}{\\Delta(G)^{1/3}} +\n\\min\\left\\{m, \\frac{m^{3/2}}{\\Delta(G)}\\right\\}\\right)\\cdot {\\rm poly}(\\log n,\n1/\\epsilon)$, where $n$ is the number of vertices in the graph and $m$ is the\nnumber of edges, and the expected running time is\n$O\\left(\\frac{n}{\\Delta(G)^{1/3}} + \\frac{m^{3/2}}{\\Delta(G)}\\right)\\cdot {\\rm\npoly}(\\log n, 1/\\epsilon)$. We also prove that\n$\\Omega\\left(\\frac{n}{\\Delta(G)^{1/3}} + \\min\\left\\{m,\n\\frac{m^{3/2}}{\\Delta(G)}\\right\\}\\right)$ queries are necessary, thus\nestablishing that the query complexity of this algorithm is optimal up to\npolylogarithmic factors in $n$ (and the dependence on $1/\\epsilon$).\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.00954"}}, {"publisher": {"name": ""}, "description": "  The SINR model for the quality of wireless connections has been the subject\nof extensive recent study. It attempts to predict whether a particular\ntransmitter is heard at a specific location, in a setting consisting of $n$\nsimultaneous transmitters and background noise. The SINR model gives rise to a\nnatural geometric object, the SINR diagram, which partitions the space into $n$\nregions where each of the transmitters can be heard and the remaining space\nwhere no transmitter can be heard.\n  Efficient point location in the SINR diagram, i.e., being able to build a\ndata structure that facilitates determining, for a query point, whether any\ntransmitter is heard there, and if so, which one, has been recently\ninvestigated in several papers. These planar data structures are constructed in\ntime at least quadratic in $n$ and support logarithmic-time approximate\nqueries. Moreover, the performance of some of the proposed structures depends\nstrongly not only on the number $n$ of transmitters and on the approximation\nparameter $\\varepsilon$, but also on some geometric parameters that cannot be\nbounded a priori as a function of $n$ or $\\varepsilon$.\n  We address the question of batched point location queries, i.e., answering\nmany queries simultaneously. Specifically, in one dimension, we can answer $n$\nqueries exactly in amortized polylogarithmic time per query, while in the plane\nwe can do it approximately.\n  We also show how to answer $n^2$ queries exactly in amortized polylogarithmic\ntime per query, assuming the queries are located on a possibly non-uniform $n\n\\times n$ grid.\n  All these results can handle arbitrary power assignments to the transmitters.\nMoreover, the amortized query time in these results depends only on $n$ and\n$\\varepsilon$.\n  These results demonstrate the (so far underutilized) power of combining\nalgebraic tools with those of computational geometry and other fields.\n", "contributors": [{"name": "Aronov, Boris", "sameAs": [], "familyName": "Aronov", "additionalName": "", "givenName": "Boris", "email": ""}, {"name": "Katz, Matthew J.", "sameAs": [], "familyName": "Katz", "additionalName": "J.", "givenName": "Matthew", "email": ""}], "title": "Batched Point Location in SINR Diagrams via Algebraic Tools", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.0962", "oai:arXiv.org:1412.0962"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The SINR model for the quality of wireless connections has been the subject\nof extensive recent study. It attempts to predict whether a particular\ntransmitter is heard at a specific location, in a setting consisting of $n$\nsimultaneous transmitters and background noise. The SINR model gives rise to a\nnatural geometric object, the SINR diagram, which partitions the space into $n$\nregions where each of the transmitters can be heard and the remaining space\nwhere no transmitter can be heard.\n  Efficient point location in the SINR diagram, i.e., being able to build a\ndata structure that facilitates determining, for a query point, whether any\ntransmitter is heard there, and if so, which one, has been recently\ninvestigated in several papers. These planar data structures are constructed in\ntime at least quadratic in $n$ and support logarithmic-time approximate\nqueries. Moreover, the performance of some of the proposed structures depends\nstrongly not only on the number $n$ of transmitters and on the approximation\nparameter $\\varepsilon$, but also on some geometric parameters that cannot be\nbounded a priori as a function of $n$ or $\\varepsilon$.\n  We address the question of batched point location queries, i.e., answering\nmany queries simultaneously. Specifically, in one dimension, we can answer $n$\nqueries exactly in amortized polylogarithmic time per query, while in the plane\nwe can do it approximately.\n  We also show how to answer $n^2$ queries exactly in amortized polylogarithmic\ntime per query, assuming the queries are located on a possibly non-uniform $n\n\\times n$ grid.\n  All these results can handle arbitrary power assignments to the transmitters.\nMoreover, the amortized query time in these results depends only on $n$ and\n$\\varepsilon$.\n  These results demonstrate the (so far underutilized) power of combining\nalgebraic tools with those of computational geometry and other fields.\n"}}], "languages": [null], "subjects": ["computer science - computational geometry"], "providerUpdatedDateTime": "2014-12-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.0962"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose a realistic mathematical model taking into account\nthe mutual interference among the interacting populations. This model attempts\nto describe the control (vaccination) function as a function of the number of\ninfective individuals, which is an improvement over the existing susceptible\n?infective epidemic models. Regarding the growth of the epidemic as a nonlinear\nphenomenon we have developed a neural network architecture to estimate the\nvital parameters associated with this model. This architecture is based on a\nrecently developed new class of neural networks known as co-operative and\nsupportive neural networks. The application of this architecture to the present\nstudy involves preprocessing of the input data, and this renders an efficient\nestimation of the rate of spread of the epidemic. It is observed that the\nproposed new neural network outperforms a simple feed-forward neural network\nand polynomial regression.\n", "contributors": [{"name": "Rao, V. Sree Hari", "sameAs": [], "familyName": "Rao", "additionalName": "Sree Hari", "givenName": "V.", "email": ""}, {"name": "Kumar, M. Naresh", "sameAs": [], "familyName": "Kumar", "additionalName": "Naresh", "givenName": "M.", "email": ""}], "title": "Estimation of the parameters of an infectious disease model using neural\n  networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01847", "Nonlinear Analysis: Real World Applications 11(2010) 1810-1818", "doi:10.1016/j.nonrwa.2009.04.006", "oai:arXiv.org:1503.01847"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we propose a realistic mathematical model taking into account\nthe mutual interference among the interacting populations. This model attempts\nto describe the control (vaccination) function as a function of the number of\ninfective individuals, which is an improvement over the existing susceptible\n?infective epidemic models. Regarding the growth of the epidemic as a nonlinear\nphenomenon we have developed a neural network architecture to estimate the\nvital parameters associated with this model. This architecture is based on a\nrecently developed new class of neural networks known as co-operative and\nsupportive neural networks. The application of this architecture to the present\nstudy involves preprocessing of the input data, and this renders an efficient\nestimation of the rate of spread of the epidemic. It is observed that the\nproposed new neural network outperforms a simple feed-forward neural network\nand polynomial regression.\n", "Comment: 17 pages, 11 figures"]}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing"], "providerUpdatedDateTime": "2015-03-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01847"}}, {"publisher": {"name": ""}, "description": "  This paper presents a novel approach to the optimisation of structures using\na Tabu search (TS) method. TS is a metaheuristic which is used to guide local\nsearch methods towards a globally optimal solution by using flexible memory\ncycles of differing time spans. Results are presented for the well established\nten bar truss problem and compared to results published in the literature. In\nthe first example a truss is optimised to minimise mass and the results\ncompared to results obtained using an alternative TS implementation. In the\nsecond example, the problem has multiple objectives that are compounded into a\nsingle objective function value using game theory. In general the results\ndemonstrate that the TS method is capable of solving structural optimisation\nproblems at least as efficiently as other numerical optimisation approaches.\n", "contributors": [{"name": "Connor, Andy M.", "sameAs": [], "familyName": "Connor", "additionalName": "M.", "givenName": "Andy", "email": ""}, {"name": "Seffen, Keith A.", "sameAs": [], "familyName": "Seffen", "additionalName": "A.", "givenName": "Keith", "email": ""}, {"name": "Parks, Geoffrey T.", "sameAs": [], "familyName": "Parks", "additionalName": "T.", "givenName": "Geoffrey", "email": ""}, {"name": "Clarkson, P. John", "sameAs": [], "familyName": "Clarkson", "additionalName": "John", "givenName": "P.", "email": ""}], "title": "Efficient optimisation of structures using tabu search", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.7851", "Connor, A.M., Seffen, K.A., Clarkson, P.J. & Parks, G.T. (1999)\n  \"Efficient optimisation of structures using tabu search\" Proceedings of the\n  1st ASMO/ISSMO Conference on Engineering Design Optimization, 127-134", "oai:arXiv.org:1410.7851"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper presents a novel approach to the optimisation of structures using\na Tabu search (TS) method. TS is a metaheuristic which is used to guide local\nsearch methods towards a globally optimal solution by using flexible memory\ncycles of differing time spans. Results are presented for the well established\nten bar truss problem and compared to results published in the literature. In\nthe first example a truss is optimised to minimise mass and the results\ncompared to results obtained using an alternative TS implementation. In the\nsecond example, the problem has multiple objectives that are compounded into a\nsingle objective function value using game theory. In general the results\ndemonstrate that the TS method is capable of solving structural optimisation\nproblems at least as efficiently as other numerical optimisation approaches.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - computational engineering", "finance", "and science"], "providerUpdatedDateTime": "2014-10-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.7851"}}, {"publisher": {"name": ""}, "description": "  Research on human social interactions has traditionally relied on\nself-reports. Despite their widespread use, self-reported accounts of behaviour\nare prone to biases and necessarily reduce the range of behaviours, and the\nnumber of subjects, that may be studied simultaneously. The development of ever\nsmaller sensors makes it possible to study group-level human behaviour in\nnaturalistic settings outside research laboratories. We used such sensors,\nsociometers, to examine gender, talkativeness and interaction style in two\ndifferent contexts. Here, we find that in the collaborative context, women were\nmuch more likely to be physically proximate to other women and were also\nsignificantly more talkative than men, especially in small groups. In contrast,\nthere were no gender-based differences in the non-collaborative setting. Our\nresults highlight the importance of objective measurement in the study of human\nbehaviour, here enabling us to discern context specific, gender-based\ndifferences in interaction style.\n", "contributors": [{"name": "Onnela, Jukka-Pekka", "sameAs": [], "familyName": "Onnela", "additionalName": "", "givenName": "Jukka-Pekka", "email": ""}, {"name": "Waber, Benjamin N.", "sameAs": [], "familyName": "Waber", "additionalName": "N.", "givenName": "Benjamin", "email": ""}, {"name": "Alex", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Alex", "email": ""}, {"name": "Pentland", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Pentland", "email": ""}, {"name": "Schnorf, Sebastian", "sameAs": [], "familyName": "Schnorf", "additionalName": "", "givenName": "Sebastian", "email": ""}, {"name": "Lazer, David", "sameAs": [], "familyName": "Lazer", "additionalName": "", "givenName": "David", "email": ""}], "title": "Using sociometers to quantify social interaction patterns", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-23", "2014-10-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.6224", "oai:arXiv.org:1405.6224"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Research on human social interactions has traditionally relied on\nself-reports. Despite their widespread use, self-reported accounts of behaviour\nare prone to biases and necessarily reduce the range of behaviours, and the\nnumber of subjects, that may be studied simultaneously. The development of ever\nsmaller sensors makes it possible to study group-level human behaviour in\nnaturalistic settings outside research laboratories. We used such sensors,\nsociometers, to examine gender, talkativeness and interaction style in two\ndifferent contexts. Here, we find that in the collaborative context, women were\nmuch more likely to be physically proximate to other women and were also\nsignificantly more talkative than men, especially in small groups. In contrast,\nthere were no gender-based differences in the non-collaborative setting. Our\nresults highlight the importance of objective measurement in the study of human\nbehaviour, here enabling us to discern context specific, gender-based\ndifferences in interaction style.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-10-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.6224"}}, {"publisher": {"name": ""}, "description": "  We introduce the concept of associativity for string functions, where a\nstring function is a unary operation on the set of strings over a given\nalphabet. We discuss this new property and describe certain classes of\nassociative string functions. We also characterize the recently introduced\npreassociative functions as compositions of associative string functions with\ninjective unary maps. Finally, we provide descriptions of the classes of\nassociative and preassociative functions which depend only on the length of the\ninput.\n", "contributors": [{"name": "Lehtonen, Erkko", "sameAs": [], "familyName": "Lehtonen", "additionalName": "", "givenName": "Erkko", "email": ""}, {"name": "Marichal, Jean-Luc", "sameAs": [], "familyName": "Marichal", "additionalName": "", "givenName": "Jean-Luc", "email": ""}, {"name": "Teheux, Bruno", "sameAs": [], "familyName": "Teheux", "additionalName": "", "givenName": "Bruno", "email": ""}], "title": "Associative string functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-28", "2014-12-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.7540", "Asian-European Journal of Mathematics 7 (4) (2014) 1450059 (18\n  pages)", "doi:10.1142/S1793557114500594", "oai:arXiv.org:1403.7540"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We introduce the concept of associativity for string functions, where a\nstring function is a unary operation on the set of strings over a given\nalphabet. We discuss this new property and describe certain classes of\nassociative string functions. We also characterize the recently introduced\npreassociative functions as compositions of associative string functions with\ninjective unary maps. Finally, we provide descriptions of the classes of\nassociative and preassociative functions which depend only on the length of the\ninput.\n"}}], "languages": [null], "subjects": ["mathematics - rings and algebras", "mathematics - group theory", "39b72", "20m05", "computer science - discrete mathematics", "68r99", "20m32"], "providerUpdatedDateTime": "2014-12-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.7540"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "The off-line calibration is a crucial step for the successful application of Dynamic Traffic Assignment (DTA) models in transportation planning and real time traffic management. While traditional approaches focus on the separate or sequential estimation of demand and supply in a DTA system, a recently proposed framework calibrates the demand and supply models simultaneously by formulating the off-line calibration as a constrained optimization problem. Simultaneous Perturbation Stochastic Approximation (SPSA) has been reported in the literature to be the most suitable solution algorithm for this problem due to its highly efficient gradient estimation approach. However, it turns out that the performance of SPSA in terms of convergence rate and long run accuracy can deteriorate significantly when the physical network size and the number of considered time intervals increase. To overcome this problem, this thesis proposes a new algorithm, called Weighted SPSA, or W-SPSA. W-SPSA improves SPSA's gradient estimation process by effectively reducing the noise generated by irrelevant measurements. Synthetic tests are performed to systematically compare the performance of SPSA and W-SPSA. W-SPSA shows scalability and robustness in the tests and outperforms SPSA under different problem scales and characteristics. The application of W-SPSA in real world large-scale DTA systems is demonstrated with a case study of the entire Singapore expressway network. Results show that WSPSA is a more suitable algorithm than SPSA for the off-line calibration of large-scale DTA models. The contributions of the thesis include: 1) identifying limitations of a state-of-the- art solution algorithm for the DTA off-line calibration problem, 2) presenting rigorous definitions of an enhanced algorithm and proposing approaches to estimate the required algorithm parameters, 3) systematically comparing the performance of the new algorithm against the state-of-the-art, 4) demonstrating the characteristics of the new algorithm through experiments, and 5) discussing the general steps and empirical technical considerations when tackling real world DTA off-line calibration problems.", "contributors": [{"name": "Lu, Lu, S.M. Massachusetts Institute of Technology", "sameAs": [], "familyName": "Lu", "additionalName": "", "givenName": "Lu", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Electrical Engineering and Computer Science.", "sameAs": [], "familyName": "Science.", "additionalName": "Institute of Technology. Department of Electrical Engineering and Computer", "givenName": "Massachusetts", "email": ""}, {"name": "Moshe E. Ben-Akiva and Francisco C. Pereira.", "sameAs": [], "familyName": "Pereira.", "additionalName": "E. Ben-Akiva and Francisco C.", "givenName": "Moshe", "email": ""}], "title": "W-SPSA : an Efficient Stochastic Approximation Algorithm for the off-line calibration of Dynamic Traffic Assignment models", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "111 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/88395", "881815796", "oai:dspace.mit.edu:1721.1/88395"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2014-07-11T21:08:41Z", "2014-07-11T21:08:41Z", "2013", "2014"]}}, {"name": "description", "properties": {"description": ["The off-line calibration is a crucial step for the successful application of Dynamic Traffic Assignment (DTA) models in transportation planning and real time traffic management. While traditional approaches focus on the separate or sequential estimation of demand and supply in a DTA system, a recently proposed framework calibrates the demand and supply models simultaneously by formulating the off-line calibration as a constrained optimization problem. Simultaneous Perturbation Stochastic Approximation (SPSA) has been reported in the literature to be the most suitable solution algorithm for this problem due to its highly efficient gradient estimation approach. However, it turns out that the performance of SPSA in terms of convergence rate and long run accuracy can deteriorate significantly when the physical network size and the number of considered time intervals increase. To overcome this problem, this thesis proposes a new algorithm, called Weighted SPSA, or W-SPSA. W-SPSA improves SPSA's gradient estimation process by effectively reducing the noise generated by irrelevant measurements. Synthetic tests are performed to systematically compare the performance of SPSA and W-SPSA. W-SPSA shows scalability and robustness in the tests and outperforms SPSA under different problem scales and characteristics. The application of W-SPSA in real world large-scale DTA systems is demonstrated with a case study of the entire Singapore expressway network. Results show that WSPSA is a more suitable algorithm than SPSA for the off-line calibration of large-scale DTA models. The contributions of the thesis include: 1) identifying limitations of a state-of-the- art solution algorithm for the DTA off-line calibration problem, 2) presenting rigorous definitions of an enhanced algorithm and proposing approaches to estimate the required algorithm parameters, 3) systematically comparing the performance of the new algorithm against the state-of-the-art, 4) demonstrating the characteristics of the new algorithm through experiments, and 5) discussing the general steps and empirical technical considerations when tackling real world DTA off-line calibration problems.", "Thesis: S.M. in Transportation, Massachusetts Institute of Technology, Department of Civil and Environmental Engineering, February 2014.", "Thesis: S.M., Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, February 2014.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (pages 105-111)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7817", "hdl_1721.1_7663", "hdl_1721.1_7802", "hdl_1721.1_7652"]}}], "languages": [null], "subjects": ["electrical engineering and computer science.", "civil and environmental engineering."], "providerUpdatedDateTime": "2015-04-27T23:07:38", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/88395"}}, {"publisher": {"name": ""}, "description": "  Background/foreground segmentation has a lot of applications in image and\nvideo processing. In this paper, a segmentation algorithm is proposed which is\nmainly designed for text and line extraction in screen content. The proposed\nmethod makes use of the fact that the background in each block is usually\nsmoothly varying and can be modeled well by a linear combination of a few\nsmoothly varying basis functions, while the foreground text and graphics create\nsharp discontinuity. The algorithm separates the background and foreground\npixels by trying to fit pixel values in the block into a smooth function using\na robust regression method. The inlier pixels that can fit well will be\nconsidered as background, while remaining outlier pixels will be considered\nforeground. This algorithm has been extensively tested on several images from\nHEVC standard test sequences for screen content coding, and is shown to have\nsuperior performance over other methods, such as the k-means clustering based\nsegmentation algorithm in DjVu. This background/foreground segmentation can be\nused in different applications such as: text extraction, separate coding of\nbackground and foreground for compression of screen content and mixed content\ndocuments, principle line extraction from palmprint and crease detection in\nfingerprint images.\n", "contributors": [{"name": "Minaee, Shervin", "sameAs": [], "familyName": "Minaee", "additionalName": "", "givenName": "Shervin", "email": ""}, {"name": "Yu, Haoping", "sameAs": [], "familyName": "Yu", "additionalName": "", "givenName": "Haoping", "email": ""}, {"name": "Wang, Yao", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yao", "email": ""}], "title": "A Robust Regression Approach for Background/Foreground Segmentation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5126", "oai:arXiv.org:1412.5126"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Background/foreground segmentation has a lot of applications in image and\nvideo processing. In this paper, a segmentation algorithm is proposed which is\nmainly designed for text and line extraction in screen content. The proposed\nmethod makes use of the fact that the background in each block is usually\nsmoothly varying and can be modeled well by a linear combination of a few\nsmoothly varying basis functions, while the foreground text and graphics create\nsharp discontinuity. The algorithm separates the background and foreground\npixels by trying to fit pixel values in the block into a smooth function using\na robust regression method. The inlier pixels that can fit well will be\nconsidered as background, while remaining outlier pixels will be considered\nforeground. This algorithm has been extensively tested on several images from\nHEVC standard test sequences for screen content coding, and is shown to have\nsuperior performance over other methods, such as the k-means clustering based\nsegmentation algorithm in DjVu. This background/foreground segmentation can be\nused in different applications such as: text extraction, separate coding of\nbackground and foreground for compression of screen content and mixed content\ndocuments, principle line extraction from palmprint and crease detection in\nfingerprint images.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5126"}}, {"publisher": {"name": ""}, "description": "  The computational cost of quantum Monte Carlo (QMC) calculations of realistic\nperiodic systems depends strongly on the method of storing and evaluating the\nmany-particle wave function. Previous work [A. J. Williamson et al., Phys. Rev.\nLett. 87, 246406 (2001); D. Alf\\`e and M. J. Gillan, Phys. Rev. B 70, 161101\n(2004)] has demonstrated the reduction of the O(N^3) cost of evaluating the\nSlater determinant with planewaves to O(N^2) using localized basis functions.\nWe compare four polynomial approximations as basis functions -- interpolating\nLagrange polynomials, interpolating piecewise-polynomial-form (pp-) splines,\nand basis-form (B-) splines (interpolating and smoothing). All these basis\nfunctions provide a similar speedup relative to the planewave basis. The\npp-splines have eight times the memory requirement of the other methods. To\ntest the accuracy of the basis functions, we apply them to the ground state\nstructures of Si, Al, and MgO. The polynomial approximations differ in accuracy\nmost strongly for MgO and smoothing B-splines most closely reproduce the\nplanewave value for of the variational Monte Carlo energy. Using separate\napproximations for the Laplacian of the orbitals increases the accuracy\nsufficiently to justify the increased memory requirement, making smoothing\nB-splines, with separate approximation for the Laplacian, the preferred choice\nfor approximating planewave-represented orbitals in QMC calculations.\n", "contributors": [{"name": "Parker, William D.", "sameAs": [], "familyName": "Parker", "additionalName": "D.", "givenName": "William", "email": ""}, {"name": "Umrigar, C. J.", "sameAs": [], "familyName": "Umrigar", "additionalName": "J.", "givenName": "C.", "email": ""}, {"name": "Alf\u00e8, Dario", "sameAs": [], "familyName": "Alf\u00e8", "additionalName": "", "givenName": "Dario", "email": ""}, {"name": "Hennig, Richard G.", "sameAs": [], "familyName": "Hennig", "additionalName": "G.", "givenName": "Richard", "email": ""}, {"name": "Wilkins, John W.", "sameAs": [], "familyName": "Wilkins", "additionalName": "W.", "givenName": "John", "email": ""}], "title": "Comparison of polynomial approximations to speed up planewave-based\n  quantum Monte Carlo calculations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-09-24", "2014-10-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1309.6250", "oai:arXiv.org:1309.6250"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": "  The computational cost of quantum Monte Carlo (QMC) calculations of realistic\nperiodic systems depends strongly on the method of storing and evaluating the\nmany-particle wave function. Previous work [A. J. Williamson et al., Phys. Rev.\nLett. 87, 246406 (2001); D. Alf\\`e and M. J. Gillan, Phys. Rev. B 70, 161101\n(2004)] has demonstrated the reduction of the O(N^3) cost of evaluating the\nSlater determinant with planewaves to O(N^2) using localized basis functions.\nWe compare four polynomial approximations as basis functions -- interpolating\nLagrange polynomials, interpolating piecewise-polynomial-form (pp-) splines,\nand basis-form (B-) splines (interpolating and smoothing). All these basis\nfunctions provide a similar speedup relative to the planewave basis. The\npp-splines have eight times the memory requirement of the other methods. To\ntest the accuracy of the basis functions, we apply them to the ground state\nstructures of Si, Al, and MgO. The polynomial approximations differ in accuracy\nmost strongly for MgO and smoothing B-splines most closely reproduce the\nplanewave value for of the variational Monte Carlo energy. Using separate\napproximations for the Laplacian of the orbitals increases the accuracy\nsufficiently to justify the increased memory requirement, making smoothing\nB-splines, with separate approximation for the Laplacian, the preferred choice\nfor approximating planewave-represented orbitals in QMC calculations.\n"}}], "languages": [null], "subjects": ["physics - computational physics"], "providerUpdatedDateTime": "2014-10-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1309.6250"}}, {"publisher": {"name": ""}, "description": "  We study the problem of broadcasting packets in wireless networks. At each\ntime slot, a network controller activates non-interfering links and forwards\npackets to all nodes at a common rate; the maximum rate is referred to as the\nbroadcast capacity of the wireless network. Existing policies achieve the\nbroadcast capacity by balancing traffic over a set of spanning trees, which are\ndifficult to maintain in a large and time-varying wireless network. We propose\na new dynamic algorithm that achieves the broadcast capacity when the\nunderlying network topology is a directed acyclic graph (DAG). This algorithm\nutilizes local queue-length information, does not use any global topological\nstructures such as spanning trees, and uses the idea of in-order packet\ndelivery to all network nodes. Although the in-order packet delivery constraint\nleads to degraded throughput in cyclic graphs, we show that it is throughput\noptimal in DAGs and can be exploited to simplify the design and analysis of\noptimal algorithms. Our simulation results show that the proposed algorithm has\nsuperior delay performance as compared to tree-based approaches.\n", "contributors": [{"name": "Sinha, Abhishek", "sameAs": [], "familyName": "Sinha", "additionalName": "", "givenName": "Abhishek", "email": ""}, {"name": "Paschos, Georgios", "sameAs": [], "familyName": "Paschos", "additionalName": "", "givenName": "Georgios", "email": ""}, {"name": "Li, Chih-ping", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Chih-ping", "email": ""}, {"name": "Modiano, Eytan", "sameAs": [], "familyName": "Modiano", "additionalName": "", "givenName": "Eytan", "email": ""}], "title": "Throughput-Optimal Broadcast on Directed Acyclic Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.6172", "oai:arXiv.org:1411.6172"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study the problem of broadcasting packets in wireless networks. At each\ntime slot, a network controller activates non-interfering links and forwards\npackets to all nodes at a common rate; the maximum rate is referred to as the\nbroadcast capacity of the wireless network. Existing policies achieve the\nbroadcast capacity by balancing traffic over a set of spanning trees, which are\ndifficult to maintain in a large and time-varying wireless network. We propose\na new dynamic algorithm that achieves the broadcast capacity when the\nunderlying network topology is a directed acyclic graph (DAG). This algorithm\nutilizes local queue-length information, does not use any global topological\nstructures such as spanning trees, and uses the idea of in-order packet\ndelivery to all network nodes. Although the in-order packet delivery constraint\nleads to degraded throughput in cyclic graphs, we show that it is throughput\noptimal in DAGs and can be exploited to simplify the design and analysis of\noptimal algorithms. Our simulation results show that the proposed algorithm has\nsuperior delay performance as compared to tree-based approaches.\n", "Comment: To appear in the proceedings of INFOCOM, 2015"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.6172"}}, {"publisher": {"name": ""}, "description": "  The e-learning systems are designed to provide an easy and constant access to\neducational resources online. Indeed, E-learning systems have capacity to adapt\ncontent and learning process according to the learner profile. Adaptation\ntechniques using advanced behavioral analysis mechanisms, called \"Learner\nModeling\" or \"Profiling\". The latter require continuous tracking of the\nactivities of the learner to identify gaps and strengths in order to tailor\ncontent to their specific needs or advise and accompany him during his\napprenticeship. However, the disadvantage of these systems is that they cause\nlearners' discouragement, for learners, alone with his screen loses its\nmotivation to improve. Adding social extension to learning, to avoid isolation\nof learners and boost support and interaction between members of the learning\ncommunity, was able to increase learner's motivation. However, the tools to\nfacilitate social interactions integrated to E-learning platforms can be used\nfor purposes other than learning. These needs, which can be educational,\nprofessional or personal, create a mixture of data from the private life and\npublic life of learners. With the integration of these tools for e-learning\nsystems and the growth of the amount of personal data stored in the databases\nof these latter, protecting the privacy of students becomes a major concern.\nIndeed, the exchange of profiles between e-learning systems is done without the\npermission of their owners. Furthermore, the profiling behavior analysis\ncurrently represents a very cost-effective way to generate profits by selling\nthese profiles advertising companies. Today, the right to privacy is threatened\nfrom all sides. In addition to the threat from pirates, the source of the most\ndangerous threats is that from service providers online that users devote a\nblind trust. Control and centralized data storage and access privileges that\nhave suppliers are responsible for the threat. Our work is limited to the\nprotection of personal data in e-learning systems. We try to answer the\nquestion: How can we design a system that protects the privacy of users against\nthreats from the provider while benefiting from all the services, including\nanalysis of behavior? In the absence of solutions that take into account the\nprotection and respect of privacy in e-learning systems that integrate social\nlearning tools, we designed our own solution. Our \"ApprAide\" system uses a set\nof protocols based on security techniques to protect users' privacy. In\naddition, our system incorporates tools that promote social interactions as a\nsocial learning network, a chat tool and a virtual table. Our solution allows\nthe use of adaptation techniques and profiling to assist learners. Keywords:\nSocial learning, privacy, security, e-learning, agents\n", "contributors": [{"name": "Bekrar, Marwa", "sameAs": [], "familyName": "Bekrar", "additionalName": "", "givenName": "Marwa", "email": ""}], "title": "Protection de la vie priv\\'ee \\`a base d'agents dans un syst\\`eme\n  d'e-learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2261", "oai:arXiv.org:1412.2261"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The e-learning systems are designed to provide an easy and constant access to\neducational resources online. Indeed, E-learning systems have capacity to adapt\ncontent and learning process according to the learner profile. Adaptation\ntechniques using advanced behavioral analysis mechanisms, called \"Learner\nModeling\" or \"Profiling\". The latter require continuous tracking of the\nactivities of the learner to identify gaps and strengths in order to tailor\ncontent to their specific needs or advise and accompany him during his\napprenticeship. However, the disadvantage of these systems is that they cause\nlearners' discouragement, for learners, alone with his screen loses its\nmotivation to improve. Adding social extension to learning, to avoid isolation\nof learners and boost support and interaction between members of the learning\ncommunity, was able to increase learner's motivation. However, the tools to\nfacilitate social interactions integrated to E-learning platforms can be used\nfor purposes other than learning. These needs, which can be educational,\nprofessional or personal, create a mixture of data from the private life and\npublic life of learners. With the integration of these tools for e-learning\nsystems and the growth of the amount of personal data stored in the databases\nof these latter, protecting the privacy of students becomes a major concern.\nIndeed, the exchange of profiles between e-learning systems is done without the\npermission of their owners. Furthermore, the profiling behavior analysis\ncurrently represents a very cost-effective way to generate profits by selling\nthese profiles advertising companies. Today, the right to privacy is threatened\nfrom all sides. In addition to the threat from pirates, the source of the most\ndangerous threats is that from service providers online that users devote a\nblind trust. Control and centralized data storage and access privileges that\nhave suppliers are responsible for the threat. Our work is limited to the\nprotection of personal data in e-learning systems. We try to answer the\nquestion: How can we design a system that protects the privacy of users against\nthreats from the provider while benefiting from all the services, including\nanalysis of behavior? In the absence of solutions that take into account the\nprotection and respect of privacy in e-learning systems that integrate social\nlearning tools, we designed our own solution. Our \"ApprAide\" system uses a set\nof protocols based on security techniques to protect users' privacy. In\naddition, our system incorporates tools that promote social interactions as a\nsocial learning network, a chat tool and a virtual table. Our solution allows\nthe use of adaptation techniques and profiling to assist learners. Keywords:\nSocial learning, privacy, security, e-learning, agents\n", "Comment: M\\'emoire de fin d'\\'etudes, dipl\\^ome d'Ing\\'enieur d'Etat en\n  Informatique, Ecole Nationale Superieure d'Informatique, Algeria"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - computers and society"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2261"}}, {"publisher": {"name": ""}, "description": "  In the recent past, new enhancements based on the well established Aloha\ntechnique (CRDSA, CRDSA++, IRSA) have demonstrated the capability to reach\nhigher throughput than traditional SA, in bursty traffic conditions and without\nany need of coordination among terminals. In this paper, retransmissions and\nrelated stability for these new techniques are discussed. A model is also\nformulated in order to provide a basis for the analysis of the stability and\nthe performance both for finite and infinite users population. This model can\nbe used as a framework for the design of such a communication system.\n", "contributors": [{"name": "Meloni, Alessio", "sameAs": [], "familyName": "Meloni", "additionalName": "", "givenName": "Alessio", "email": ""}, {"name": "Murroni, Maurizio", "sameAs": [], "familyName": "Murroni", "additionalName": "", "givenName": "Maurizio", "email": ""}], "title": "CRDSA, CRDSA++ and IRSA: Stability and Performance Evaluation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05809", "doi:10.1109/ASMS-SPSC.2012.6333080", "oai:arXiv.org:1501.05809"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In the recent past, new enhancements based on the well established Aloha\ntechnique (CRDSA, CRDSA++, IRSA) have demonstrated the capability to reach\nhigher throughput than traditional SA, in bursty traffic conditions and without\nany need of coordination among terminals. In this paper, retransmissions and\nrelated stability for these new techniques are discussed. A model is also\nformulated in order to provide a basis for the analysis of the stability and\nthe performance both for finite and infinite users population. This model can\nbe used as a framework for the design of such a communication system.\n", "Comment: 6th Advanced Satellite Multimedia Systems Conference (ASMS) and 12th\n  Signal Processing for Space Communications Workshop (SPSC), 2012"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05809"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "With the advent of \"smart\" mobile phones and ubiquitous mobile applications, the pace at which people generate, access, and acquire data has accelerated significantly. In this thesis, we first examine how privacy issues in the mobile apps market compromise the well-being of both app consumers and developers, noting that one important problem is the lack of usable privacy policies. Subsequently, we propose a technical solution named PrivacyInformer that automatically generates mobile app privacy descriptions, thereby relieving developers the burden of manually creating them. This tool is implemented as an extension to the MIT App Inventor, a do-it-yourself mobile app building platform that has a vast international user base, as well as a growing impact on the democratizing of mobile app building. We show that by analyzing source code of mobile apps directly in App Inventor, PrivacyInformer can produce simple and useful privacy descriptions in both human-readable and machine-readable format. Specifically, these generated documents describe how mobile apps use private information, rather than simply enumerating a list of data access as done in the permissions system. Finally, we conduct an exploratory user study to evaluate the effectiveness of PrivacyInformer from the app developer's perspective, as well as discuss the policy impact of such a tool in the mobile app development community.", "contributors": [{"name": "Miao, Daniela Yidan", "sameAs": [], "familyName": "Miao", "additionalName": "Yidan", "givenName": "Daniela", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Electrical Engineering and Computer Science.", "sameAs": [], "familyName": "Science.", "additionalName": "Institute of Technology. Department of Electrical Engineering and Computer", "givenName": "Massachusetts", "email": ""}, {"name": "Lalana Kagal.", "sameAs": [], "familyName": "Kagal.", "additionalName": "", "givenName": "Lalana", "email": ""}], "title": "PrivacyInformer : an automated privacy description generator for the MIT App Inventor", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "73 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/95523", "903649516", "oai:dspace.mit.edu:1721.1/95523"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2015-02-25T16:43:31Z", "2015-02-25T16:43:31Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["With the advent of \"smart\" mobile phones and ubiquitous mobile applications, the pace at which people generate, access, and acquire data has accelerated significantly. In this thesis, we first examine how privacy issues in the mobile apps market compromise the well-being of both app consumers and developers, noting that one important problem is the lack of usable privacy policies. Subsequently, we propose a technical solution named PrivacyInformer that automatically generates mobile app privacy descriptions, thereby relieving developers the burden of manually creating them. This tool is implemented as an extension to the MIT App Inventor, a do-it-yourself mobile app building platform that has a vast international user base, as well as a growing impact on the democratizing of mobile app building. We show that by analyzing source code of mobile apps directly in App Inventor, PrivacyInformer can produce simple and useful privacy descriptions in both human-readable and machine-readable format. Specifically, these generated documents describe how mobile apps use private information, rather than simply enumerating a list of data access as done in the permissions system. Finally, we conduct an exploratory user study to evaluate the effectiveness of PrivacyInformer from the app developer's perspective, as well as discuss the policy impact of such a tool in the mobile app development community.", "by Daniela Yidan Miao.", "Thesis: S.M. in Technology and Policy, Massachusetts Institute of Technology, Engineering Systems Division, 2014.", "Thesis: S.M., Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2014.", "This electronic version was submitted by the student author.  The certified thesis is available in the Institute Archives and Special Collections.", "Cataloged from student-submitted PDF version of thesis.", "Includes bibliographical references (pages 71-73)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7817", "hdl_1721.1_7663", "hdl_1721.1_7888", "hdl_1721.1_7710"]}}], "languages": [null], "subjects": ["technology and policy program.", "electrical engineering and computer science.", "engineering systems division."], "providerUpdatedDateTime": "2015-02-26T07:19:28", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/95523"}}, {"publisher": {"name": ""}, "description": "  In this paper, we introduce a novel deep learning framework, termed Purine.\nIn Purine, a deep network is expressed as a bipartite graph (bi-graph), which\nis composed of interconnected operators and data tensors. With the bi-graph\nabstraction, networks are easily solvable with event-driven task dispatcher. We\nthen demonstrate that different parallelism schemes over GPUs and/or CPUs on\nsingle or multiple PCs can be universally implemented by graph composition.\nThis eases researchers from coding for various parallelization schemes, and the\nsame dispatcher can be used for solving variant graphs. Scheduled by the task\ndispatcher, memory transfers are fully overlapped with other computations,\nwhich greatly reduce the communication overhead and help us achieve approximate\nlinear acceleration.\n", "contributors": [{"name": "Lin, Min", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Min", "email": ""}, {"name": "Li, Shuo", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Shuo", "email": ""}, {"name": "Luo, Xuan", "sameAs": [], "familyName": "Luo", "additionalName": "", "givenName": "Xuan", "email": ""}, {"name": "Yan, Shuicheng", "sameAs": [], "familyName": "Yan", "additionalName": "", "givenName": "Shuicheng", "email": ""}], "title": "Purine: A bi-graph based deep learning framework", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-19", "2015-04-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6249", "oai:arXiv.org:1412.6249"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we introduce a novel deep learning framework, termed Purine.\nIn Purine, a deep network is expressed as a bipartite graph (bi-graph), which\nis composed of interconnected operators and data tensors. With the bi-graph\nabstraction, networks are easily solvable with event-driven task dispatcher. We\nthen demonstrate that different parallelism schemes over GPUs and/or CPUs on\nsingle or multiple PCs can be universally implemented by graph composition.\nThis eases researchers from coding for various parallelization schemes, and the\nsame dispatcher can be used for solving variant graphs. Scheduled by the task\ndispatcher, memory transfers are fully overlapped with other computations,\nwhich greatly reduce the communication overhead and help us achieve approximate\nlinear acceleration.\n", "Comment: Submitted to ICLR 2015 workshop"]}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - learning"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6249"}}, {"publisher": {"name": ""}, "description": "  Multi-Context Systems are an expressive formalism to model (possibly)\nnon-monotonic information exchange between heterogeneous knowledge bases. Such\ninformation exchange, however, often comes with unforseen side-effects leading\nto violation of constraints, making the system inconsistent, and thus unusable.\nAlthough there are many approaches to assess and repair a single inconsistent\nknowledge base, the heterogeneous nature of Multi-Context Systems poses\nproblems which have not yet been addressed in a satisfying way: How to identify\nand explain a inconsistency that spreads over multiple knowledge bases with\ndifferent logical formalisms (e.g., logic programs and ontologies)? What are\nthe causes of inconsistency if inference/information exchange is non-monotonic\n(e.g., absent information as cause)? How to deal with inconsistency if access\nto knowledge bases is restricted (e.g., companies exchange information, but do\nnot allow arbitrary modifications to their knowledge bases)? Many traditional\napproaches solely aim for a consistent system, but automatic removal of\ninconsistency is not always desireable. Therefore a human operator has to be\nsupported in finding the erroneous parts contributing to the inconsistency. In\nmy thesis those issues will be adressed mainly from a foundational perspective,\nwhile our research project also provides algorithms and prototype\nimplementations.\n", "contributors": [{"name": "Weinzierl, Antonius", "sameAs": [], "familyName": "Weinzierl", "additionalName": "", "givenName": "Antonius", "email": ""}], "title": "Advancing Multi-Context Systems by Inconsistency Management", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-07-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1107.2088", "oai:arXiv.org:1107.2088"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Multi-Context Systems are an expressive formalism to model (possibly)\nnon-monotonic information exchange between heterogeneous knowledge bases. Such\ninformation exchange, however, often comes with unforseen side-effects leading\nto violation of constraints, making the system inconsistent, and thus unusable.\nAlthough there are many approaches to assess and repair a single inconsistent\nknowledge base, the heterogeneous nature of Multi-Context Systems poses\nproblems which have not yet been addressed in a satisfying way: How to identify\nand explain a inconsistency that spreads over multiple knowledge bases with\ndifferent logical formalisms (e.g., logic programs and ontologies)? What are\nthe causes of inconsistency if inference/information exchange is non-monotonic\n(e.g., absent information as cause)? How to deal with inconsistency if access\nto knowledge bases is restricted (e.g., companies exchange information, but do\nnot allow arbitrary modifications to their knowledge bases)? Many traditional\napproaches solely aim for a consistent system, but automatic removal of\ninconsistency is not always desireable. Therefore a human operator has to be\nsupported in finding the erroneous parts contributing to the inconsistency. In\nmy thesis those issues will be adressed mainly from a foundational perspective,\nwhile our research project also provides algorithms and prototype\nimplementations.\n", "Comment: Proceedings of the Doctoral Consortium and Poster Session of the 5th\n  International Symposium on Rules (RuleML 2011@IJCAI), pages 17-24\n  (arXiv:1107.1686)"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1107.2088"}}, {"publisher": {"name": ""}, "description": "  The goal of hyperspectral unmixing is to decompose an electromagnetic\nspectral dataset measured over M spectral bands and T pixels into N constituent\nmaterial spectra (or \"end-members\") with corresponding spatial abundances. In\nthis paper, we propose a novel approach to hyperspectral unmixing based on\nloopy belief propagation (BP) that enables the exploitation of spectral\ncoherence in the endmembers and spatial coherence in the abundances. In\nparticular, we partition the factor graph into spectral coherence, spatial\ncoherence, and bilinear subgraphs, and pass messages between them using a\n\"turbo\" approach. To perform message passing within the bilinear subgraph, we\nemploy the bilinear generalized approximate message passing algorithm\n(BiG-AMP), a recently proposed belief-propagation-based approach to matrix\nfactorization. Furthermore, we propose an expectation-maximization (EM)\nstrategy to tune the prior parameters and a model-order selection strategy to\nselect the number of materials N. Numerical experiments conducted with both\nsynthetic and real-world data show favorable unmixing performance relative to\nexisting methods.\n", "contributors": [{"name": "Vila, Jeremy", "sameAs": [], "familyName": "Vila", "additionalName": "", "givenName": "Jeremy", "email": ""}, {"name": "Schniter, Philip", "sameAs": [], "familyName": "Schniter", "additionalName": "", "givenName": "Philip", "email": ""}, {"name": "Meola, Joseph", "sameAs": [], "familyName": "Meola", "additionalName": "", "givenName": "Joseph", "email": ""}], "title": "Hyperspectral Unmixing via Turbo Bilinear Approximate Message Passing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06435", "oai:arXiv.org:1502.06435"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  The goal of hyperspectral unmixing is to decompose an electromagnetic\nspectral dataset measured over M spectral bands and T pixels into N constituent\nmaterial spectra (or \"end-members\") with corresponding spatial abundances. In\nthis paper, we propose a novel approach to hyperspectral unmixing based on\nloopy belief propagation (BP) that enables the exploitation of spectral\ncoherence in the endmembers and spatial coherence in the abundances. In\nparticular, we partition the factor graph into spectral coherence, spatial\ncoherence, and bilinear subgraphs, and pass messages between them using a\n\"turbo\" approach. To perform message passing within the bilinear subgraph, we\nemploy the bilinear generalized approximate message passing algorithm\n(BiG-AMP), a recently proposed belief-propagation-based approach to matrix\nfactorization. Furthermore, we propose an expectation-maximization (EM)\nstrategy to tune the prior parameters and a model-order selection strategy to\nselect the number of materials N. Numerical experiments conducted with both\nsynthetic and real-world data show favorable unmixing performance relative to\nexisting methods.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06435"}}, {"publisher": {"name": ""}, "description": "  The spread of new ideas, behaviors or technologies has been extensively\nstudied using epidemic models. Here we consider a model of diffusion where the\nindividuals' behavior is the result of a strategic choice. We study a simple\ncoordination game with binary choice and give a condition for a new action to\nbecome widespread in a random network. We also analyze the possible equilibria\nof this game and identify conditions for the coexistence of both strategies in\nlarge connected sets. Finally we look at how can firms use social networks to\npromote their goals with limited information. Our results differ strongly from\nthe one derived with epidemic models and show that connectivity plays an\nambiguous role: while it allows the diffusion to spread, when the network is\nhighly connected, the diffusion is also limited by high-degree nodes which are\nvery stable.\n", "contributors": [{"name": "Lelarge, Marc", "sameAs": [], "familyName": "Lelarge", "additionalName": "", "givenName": "Marc", "email": ""}], "title": "Diffusion and Cascading Behavior in Random Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-12-09", "2011-10-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1012.2062", "oai:arXiv.org:1012.2062"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:physics"]}}, {"name": "description", "properties": {"description": "  The spread of new ideas, behaviors or technologies has been extensively\nstudied using epidemic models. Here we consider a model of diffusion where the\nindividuals' behavior is the result of a strategic choice. We study a simple\ncoordination game with binary choice and give a condition for a new action to\nbecome widespread in a random network. We also analyze the possible equilibria\nof this game and identify conditions for the coexistence of both strategies in\nlarge connected sets. Finally we look at how can firms use social networks to\npromote their goals with limited information. Our results differ strongly from\nthe one derived with epidemic models and show that connectivity plays an\nambiguous role: while it allows the diffusion to spread, when the network is\nhighly connected, the diffusion is also limited by high-degree nodes which are\nvery stable.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory", "physics - physics and society", "computer science - social and information networks", "computer science - discrete mathematics", "mathematics - probability"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1012.2062"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "by Rajesh Prasad.", "contributors": [{"name": "Prasad, Rajesh, 1966-", "sameAs": [], "familyName": "Prasad", "additionalName": "", "givenName": "Rajesh", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Civil and Environmental Engineering.", "sameAs": [], "familyName": "Engineering.", "additionalName": "Institute of Technology. Department of Civil and Environmental", "givenName": "Massachusetts", "email": ""}, {"name": "George Kocur.", "sameAs": [], "familyName": "Kocur.", "additionalName": "", "givenName": "George", "email": ""}], "title": "Pavement permit system infrastructure : UML based design", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "98 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/84297", "49521750", "oai:dspace.mit.edu:1721.1/84297"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2014-01-23T18:34:41Z", "2014-01-23T18:34:41Z", "2001", "2001"]}}, {"name": "description", "properties": {"description": ["by Rajesh Prasad.", "Thesis (M.Eng.)--Massachusetts Institute of Technology, Dept. of Civil and Environmental Engineering, 2001.", "Includes bibliographical references (p. 98)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7652", "hdl_1721.1_7802"]}}], "languages": [null], "subjects": ["uml (computer science)", "civil and environmental engineering."], "providerUpdatedDateTime": "2015-04-27T23:07:35", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/84297"}}, {"publisher": {"name": ""}, "description": "  Current fine-grained classification approaches often rely on a robust\nlocalization of object parts to extract localized feature representations\nsuitable for discrimination. However, part localization is a challenging task\ndue to the large variation of appearance and pose. In this paper, we show how\npre-trained convolutional neural networks can be used for robust and efficient\nobject part discovery and localization without the necessity to actually train\nthe network on the current dataset. Our approach called \"part detector\ndiscovery\" (PDD) is based on analyzing the gradient maps of the network outputs\nand finding activation centers spatially related to annotated semantic parts or\nbounding boxes.\n  This allows us not just to obtain excellent performance on the CUB200-2011\ndataset, but in contrast to previous approaches also to perform detection and\nbird classification jointly without requiring a given bounding box annotation\nduring testing and ground-truth parts during training. The code is available at\nhttp://www.inf-cv.uni-jena.de/part_discovery and\nhttps://github.com/cvjena/PartDetectorDisovery.\n", "contributors": [{"name": "Simon, Marcel", "sameAs": [], "familyName": "Simon", "additionalName": "", "givenName": "Marcel", "email": ""}, {"name": "Rodner, Erik", "sameAs": [], "familyName": "Rodner", "additionalName": "", "givenName": "Erik", "email": ""}, {"name": "Denzler, Joachim", "sameAs": [], "familyName": "Denzler", "additionalName": "", "givenName": "Joachim", "email": ""}], "title": "Part Detector Discovery in Deep Convolutional Neural Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-12", "2014-11-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3159", "oai:arXiv.org:1411.3159"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Current fine-grained classification approaches often rely on a robust\nlocalization of object parts to extract localized feature representations\nsuitable for discrimination. However, part localization is a challenging task\ndue to the large variation of appearance and pose. In this paper, we show how\npre-trained convolutional neural networks can be used for robust and efficient\nobject part discovery and localization without the necessity to actually train\nthe network on the current dataset. Our approach called \"part detector\ndiscovery\" (PDD) is based on analyzing the gradient maps of the network outputs\nand finding activation centers spatially related to annotated semantic parts or\nbounding boxes.\n  This allows us not just to obtain excellent performance on the CUB200-2011\ndataset, but in contrast to previous approaches also to perform detection and\nbird classification jointly without requiring a given bounding box annotation\nduring testing and ground-truth parts during training. The code is available at\nhttp://www.inf-cv.uni-jena.de/part_discovery and\nhttps://github.com/cvjena/PartDetectorDisovery.\n", "Comment: Accepted for publication on Asian Conference on Computer Vision\n  (ACCV) 2014"]}}], "languages": [null], "subjects": ["i.4.8", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3159"}}, {"publisher": {"name": ""}, "description": "  The number of publicly available Web services (WS) is continuously growing,\nand in parallel, we are witnessing a rapid development in semantic-related web\ntechnologies. The intersection of the semantic web and WS allows the\ndevelopment of semantic WS. In this work, we adopt a complex network\nperspective to perform a comparative analysis of the syntactic and semantic\napproaches used to describe WS. From a collection of publicly available WS\ndescriptions, we extract syntactic and semantic WS interaction networks. We\ntake advantage of tools from the complex network field to analyze them and\ndetermine their properties. We show that WS interaction networks exhibit some\nof the typical characteristics observed in real-world networks, such as short\naverage distance between nodes and community structure. By comparing syntactic\nand semantic networks through their properties, we show the introduction of\nsemantics in WS descriptions should improve the composition process.\n", "contributors": [{"name": "Cherifi, Chantal", "sameAs": [], "familyName": "Cherifi", "additionalName": "", "givenName": "Chantal", "email": ""}, {"name": "Labatut, Vincent", "sameAs": [], "familyName": "Labatut", "additionalName": "", "givenName": "Vincent", "email": ""}, {"name": "Santucci, Jean-Fran\u00e7ois", "sameAs": [], "familyName": "Santucci", "additionalName": "", "givenName": "Jean-Fran\u00e7ois", "email": ""}], "title": "Benefits of Semantics on Web Service Composition from a Complex Network\n  Perspective", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-05-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1305.0191", "In International Conference on Networked Digital Technologies, pp\n  80-90, Springer CCIS, Czech Republic (2010)", "doi:10.1007/978-3-642-14306-9_9", "oai:arXiv.org:1305.0191"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The number of publicly available Web services (WS) is continuously growing,\nand in parallel, we are witnessing a rapid development in semantic-related web\ntechnologies. The intersection of the semantic web and WS allows the\ndevelopment of semantic WS. In this work, we adopt a complex network\nperspective to perform a comparative analysis of the syntactic and semantic\napproaches used to describe WS. From a collection of publicly available WS\ndescriptions, we extract syntactic and semantic WS interaction networks. We\ntake advantage of tools from the complex network field to analyze them and\ndetermine their properties. We show that WS interaction networks exhibit some\nof the typical characteristics observed in real-world networks, such as short\naverage distance between nodes and community structure. By comparing syntactic\nand semantic networks through their properties, we show the introduction of\nsemantics in WS descriptions should improve the composition process.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - software engineering", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1305.0191"}}, {"publisher": {"name": ""}, "description": "  Consider an undirected graph modeling a social network, where the vertices\nrepresent users, and the edges do connections among them. In the competitive\ndiffusion game, each of a number of players chooses a vertex as a seed to\npropagate his/her opinion, and then it spreads along the edges in the graphs.\nThe objective of every player is to maximize the number of vertices the opinion\ninfects. In this paper, we investigate a computational problem of asking\nwhether a pure Nash equilibrium exists in the competitive diffusion game on\nunweighed and weighted graphs, and present several negative and positive\nresults. We first prove that the problem is W[1]-hard when parameterized by the\nnumber of players even for unweighted graphs. We also show that the problem is\nNP-hard even for series-parallel graphs with positive integer weights, and is\nNP-hard even for forests with arbitrary integer weights. Furthermore, we show\nthat the problem for forest of paths with arbitrary weights is solvable in\npseudo-polynomial time; and it is solvable in quadratic time if a given graph\nis unweighted. We also prove that the problem for chain, cochain, and threshold\ngraphs with arbitrary integer weights is solvable in polynomial time.\n", "contributors": [{"name": "Ito, Takehiro", "sameAs": [], "familyName": "Ito", "additionalName": "", "givenName": "Takehiro", "email": ""}, {"name": "Otachi, Yota", "sameAs": [], "familyName": "Otachi", "additionalName": "", "givenName": "Yota", "email": ""}, {"name": "Saitoh, Toshiki", "sameAs": [], "familyName": "Saitoh", "additionalName": "", "givenName": "Toshiki", "email": ""}, {"name": "Satoh, Hisayuki", "sameAs": [], "familyName": "Satoh", "additionalName": "", "givenName": "Hisayuki", "email": ""}, {"name": "Suzuki, Akira", "sameAs": [], "familyName": "Suzuki", "additionalName": "", "givenName": "Akira", "email": ""}, {"name": "Uchizawa, Kei", "sameAs": [], "familyName": "Uchizawa", "additionalName": "", "givenName": "Kei", "email": ""}, {"name": "Uehara, Ryuhei", "sameAs": [], "familyName": "Uehara", "additionalName": "", "givenName": "Ryuhei", "email": ""}, {"name": "Yamanaka, Katsuhisa", "sameAs": [], "familyName": "Yamanaka", "additionalName": "", "givenName": "Katsuhisa", "email": ""}, {"name": "Zhou, Xiao", "sameAs": [], "familyName": "Zhou", "additionalName": "", "givenName": "Xiao", "email": ""}], "title": "Computational Complexity of Competitive Diffusion on (Un)weighted Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3334", "oai:arXiv.org:1412.3334"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Consider an undirected graph modeling a social network, where the vertices\nrepresent users, and the edges do connections among them. In the competitive\ndiffusion game, each of a number of players chooses a vertex as a seed to\npropagate his/her opinion, and then it spreads along the edges in the graphs.\nThe objective of every player is to maximize the number of vertices the opinion\ninfects. In this paper, we investigate a computational problem of asking\nwhether a pure Nash equilibrium exists in the competitive diffusion game on\nunweighed and weighted graphs, and present several negative and positive\nresults. We first prove that the problem is W[1]-hard when parameterized by the\nnumber of players even for unweighted graphs. We also show that the problem is\nNP-hard even for series-parallel graphs with positive integer weights, and is\nNP-hard even for forests with arbitrary integer weights. Furthermore, we show\nthat the problem for forest of paths with arbitrary weights is solvable in\npseudo-polynomial time; and it is solvable in quadratic time if a given graph\nis unweighted. We also prove that the problem for chain, cochain, and threshold\ngraphs with arbitrary integer weights is solvable in polynomial time.\n", "Comment: 34 pages, 5 figures"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity", "computer science - computer science and game theory", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-12-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3334"}}, {"publisher": {"name": ""}, "description": "  We develop a preconditioner for the linear system arising from a finite\nelement discretization of the Phase Field Crystal (PFC) equation. The PFC model\nserves as an atomic description of crystalline materials on diffusive time\nscales and thus offers the opportunity to study long time behaviour of\nmaterials with atomic details. This requires adaptive time stepping and\nefficient time discretization schemes, for which we use an embedded Rosenbrock\nscheme. To resolve spatial scales of practical relevance, parallel algorithms\nare also required, which scale to large numbers of processors. The developed\npreconditioner provides such a tool. It is based on an approximate\nfactorization of the system matrix and can be implemented efficiently. The\npreconditioner is analyzed in detail and shown to speed up the computation\ndrastically.\n", "contributors": [{"name": "Praetorius, Simon", "sameAs": [], "familyName": "Praetorius", "additionalName": "", "givenName": "Simon", "email": ""}, {"name": "Voigt, Axel", "sameAs": [], "familyName": "Voigt", "additionalName": "", "givenName": "Axel", "email": ""}], "title": "Development and Analysis of a Block-Preconditioner for the Phase-Field\n  Crystal Equation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06852", "oai:arXiv.org:1501.06852"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "physics:physics"]}}, {"name": "description", "properties": {"description": "  We develop a preconditioner for the linear system arising from a finite\nelement discretization of the Phase Field Crystal (PFC) equation. The PFC model\nserves as an atomic description of crystalline materials on diffusive time\nscales and thus offers the opportunity to study long time behaviour of\nmaterials with atomic details. This requires adaptive time stepping and\nefficient time discretization schemes, for which we use an embedded Rosenbrock\nscheme. To resolve spatial scales of practical relevance, parallel algorithms\nare also required, which scale to large numbers of processors. The developed\npreconditioner provides such a tool. It is based on an approximate\nfactorization of the system matrix and can be implemented efficiently. The\npreconditioner is analyzed in detail and shown to speed up the computation\ndrastically.\n"}}], "languages": [null], "subjects": ["f.2.1", "g.1.3", "82c21", "65n22", "g.1.8", "mathematics - numerical analysis", "82d25", "65f08", "65z05", "physics - computational physics", "65y05", "65f10", "g.1.0"], "providerUpdatedDateTime": "2015-01-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06852"}}, {"publisher": {"name": ""}, "description": "  Social networks and their applications have become extremely popular during\nthe last years, mostly targeting users via the web. However, it has been\nrecently observed an interest to offer social network services to mobile users.\nTelecom operators attempt to integrate existing social networks to their\nsystems or develop new ones, in order to offer new services to their\nsubscribers. Subsequently, emphasis is given to the user-context modeling, as\nwell as to the integration of sources that leads to the summarized collection\nof information anchored to the user; such as its location or its mobile device\ntype, etc.\n  In this paper we discuss the most important factors and challenges\nencountered during the design of such a system on architectural, technological\nand tool level.\n", "contributors": [{"name": "Kallergis, Dimitrios N.", "sameAs": [], "familyName": "Kallergis", "additionalName": "N.", "givenName": "Dimitrios", "email": ""}, {"name": "Foukarakis, Ioannis E.", "sameAs": [], "familyName": "Foukarakis", "additionalName": "E.", "givenName": "Ioannis", "email": ""}, {"name": "Prezerakos, George N.", "sameAs": [], "familyName": "Prezerakos", "additionalName": "N.", "givenName": "George", "email": ""}], "title": "Design issues for distributed mobile social networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4972", "oai:arXiv.org:1410.4972"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Social networks and their applications have become extremely popular during\nthe last years, mostly targeting users via the web. However, it has been\nrecently observed an interest to offer social network services to mobile users.\nTelecom operators attempt to integrate existing social networks to their\nsystems or develop new ones, in order to offer new services to their\nsubscribers. Subsequently, emphasis is given to the user-context modeling, as\nwell as to the integration of sources that leads to the summarized collection\nof information anchored to the user; such as its location or its mobile device\ntype, etc.\n  In this paper we discuss the most important factors and challenges\nencountered during the design of such a system on architectural, technological\nand tool level.\n", "Comment: 6 pages, eRA 5th International Scientific Conference, September 15-18\n  2010, Piraeus, Greece"]}}], "languages": [null], "subjects": ["c.2.1", "h.3.4", "k.6.1", "computer science - social and information networks", "c.1.3", "68m10"], "providerUpdatedDateTime": "2014-10-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4972"}}, {"publisher": {"name": ""}, "description": "  Traditional association rule mining based on the support-confidence framework\nprovides the objective measure of the rules that are of interest to users.\nHowever, it does not reflect the utility of the rules. To extract non-redundant\nassociation rules in support-confidence framework frequent closed itemsets and\ntheir generators play an important role. To extract non-redundant association\nrules among high utility itemsets, high utility closed itemsets (HUCI) and\ntheir generators should be extracted in order to apply traditional\nsupport-confidence framework. However, no efficient method exists at present\nfor mining HUCIs with their generators. This paper addresses this issue. A\npost-processing algorithm, called the HUCI-Miner, is proposed to mine HUCIs\nwith their generators. The proposed algorithm is implemented using both\nsynthetic and real datasets.\n", "contributors": [{"name": "Sahoo, Jayakrushna", "sameAs": [], "familyName": "Sahoo", "additionalName": "", "givenName": "Jayakrushna", "email": ""}, {"name": "Das, Ashok Kumar", "sameAs": [], "familyName": "Das", "additionalName": "Kumar", "givenName": "Ashok", "email": ""}, {"name": "Goswami, A.", "sameAs": [], "familyName": "Goswami", "additionalName": "", "givenName": "A.", "email": ""}], "title": "An Algorithm for Mining High Utility Closed Itemsets and Generators", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2988", "oai:arXiv.org:1410.2988"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Traditional association rule mining based on the support-confidence framework\nprovides the objective measure of the rules that are of interest to users.\nHowever, it does not reflect the utility of the rules. To extract non-redundant\nassociation rules in support-confidence framework frequent closed itemsets and\ntheir generators play an important role. To extract non-redundant association\nrules among high utility itemsets, high utility closed itemsets (HUCI) and\ntheir generators should be extracted in order to apply traditional\nsupport-confidence framework. However, no efficient method exists at present\nfor mining HUCIs with their generators. This paper addresses this issue. A\npost-processing algorithm, called the HUCI-Miner, is proposed to mine HUCIs\nwith their generators. The proposed algorithm is implemented using both\nsynthetic and real datasets.\n"}}], "languages": [null], "subjects": ["computer science - databases"], "providerUpdatedDateTime": "2014-10-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2988"}}, {"publisher": {"name": ""}, "description": "  The production of a printed product involves three stages: prepress, the\nprinting process (press) itself, and finishing (post press). There are various\ntypes of equipments (printers, scanners) and various qualities image are\npresent in the market. These give different color rendering each time during\nreproduction. So, a color key tool has been developed keeping Color Management\nScheme (CMS) in mind so that during reproduction no color rendering takes place\nirrespective of use of any device and resolution level has also been improved.\n", "contributors": [{"name": "Dilawari, Jaswinder Singh", "sameAs": [], "familyName": "Dilawari", "additionalName": "Singh", "givenName": "Jaswinder", "email": ""}, {"name": "Khanna, Ravinder", "sameAs": [], "familyName": "Khanna", "additionalName": "", "givenName": "Ravinder", "email": ""}], "title": "An Implementation of Computer Graphics as Prepress Image Enhancement\n  Process", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-09-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1209.5041", "oai:arXiv.org:1209.5041"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The production of a printed product involves three stages: prepress, the\nprinting process (press) itself, and finishing (post press). There are various\ntypes of equipments (printers, scanners) and various qualities image are\npresent in the market. These give different color rendering each time during\nreproduction. So, a color key tool has been developed keeping Color Management\nScheme (CMS) in mind so that during reproduction no color rendering takes place\nirrespective of use of any device and resolution level has also been improved.\n", "Comment: 4 Pages,8 Figures"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1209.5041"}}, {"publisher": {"name": ""}, "description": "  The epidemic spreading on arbitrary complex networks is studied in SIR\n(Susceptible Infected Recovered) compartment model. We propose our\nimplementation of a Naive SIR algorithm for epidemic simulation spreading on\nnetworks that uses data structures efficiently to reduce running time. The\nNaive SIR algorithm models full epidemic dynamics and can be easily upgraded to\nparallel version. We also propose novel algorithm for epidemic simulation\nspreading on networks called the FastSIR algorithm that has better average case\nrunning time than the Naive SIR algorithm. The FastSIR algorithm uses novel\napproach to reduce average case running time by constant factor by using\nprobability distributions of the number of infected nodes. Moreover, the\nFastSIR algorithm does not follow epidemic dynamics in time, but still captures\nall infection transfers. Furthermore, we also propose an efficient recursive\nmethod for calculating probability distributions of the number of infected\nnodes. Average case running time of both algorithms has also been derived and\nexperimental analysis was made on five different empirical complex networks.\n", "contributors": [{"name": "Antulov-Fantulin, Nino", "sameAs": [], "familyName": "Antulov-Fantulin", "additionalName": "", "givenName": "Nino", "email": ""}, {"name": "Lancic, Alen", "sameAs": [], "familyName": "Lancic", "additionalName": "", "givenName": "Alen", "email": ""}, {"name": "Stefancic, Hrvoje", "sameAs": [], "familyName": "Stefancic", "additionalName": "", "givenName": "Hrvoje", "email": ""}, {"name": "Sikic, Mile", "sameAs": [], "familyName": "Sikic", "additionalName": "", "givenName": "Mile", "email": ""}], "title": "FastSIR Algorithm: A Fast Algorithm for simulation of epidemic spread in\n  large networks by using SIR compartment model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-02-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1202.1639", "doi:10.1016/j.ins.2013.03.036", "oai:arXiv.org:1202.1639"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The epidemic spreading on arbitrary complex networks is studied in SIR\n(Susceptible Infected Recovered) compartment model. We propose our\nimplementation of a Naive SIR algorithm for epidemic simulation spreading on\nnetworks that uses data structures efficiently to reduce running time. The\nNaive SIR algorithm models full epidemic dynamics and can be easily upgraded to\nparallel version. We also propose novel algorithm for epidemic simulation\nspreading on networks called the FastSIR algorithm that has better average case\nrunning time than the Naive SIR algorithm. The FastSIR algorithm uses novel\napproach to reduce average case running time by constant factor by using\nprobability distributions of the number of infected nodes. Moreover, the\nFastSIR algorithm does not follow epidemic dynamics in time, but still captures\nall infection transfers. Furthermore, we also propose an efficient recursive\nmethod for calculating probability distributions of the number of infected\nnodes. Average case running time of both algorithms has also been derived and\nexperimental analysis was made on five different empirical complex networks.\n", "Comment: 8 figures"]}}], "languages": [null], "subjects": ["g.3", "f.2", "i.6", "computer science - social and information networks", "physics - physics and society", "computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1202.1639"}}, {"publisher": {"name": ""}, "description": "  A correction to the specification of the mechanism proposed in \"An Efficient\nGame Form for Multi-rate Multicast Service Provisioning\" is given.\n", "contributors": [{"name": "Kakhbod, Ali", "sameAs": [], "familyName": "Kakhbod", "additionalName": "", "givenName": "Ali", "email": ""}, {"name": "Teneketzis, Demosthenis", "sameAs": [], "familyName": "Teneketzis", "additionalName": "", "givenName": "Demosthenis", "email": ""}], "title": "Correction to \"An Efficient Game Form for Multi-rate Multicast Service\n  Provisioning\"", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-29", "2013-05-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.7013", "oai:arXiv.org:1111.7013"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  A correction to the specification of the mechanism proposed in \"An Efficient\nGame Form for Multi-rate Multicast Service Provisioning\" is given.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - computer science and game theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.7013"}}, {"publisher": {"name": ""}, "description": "  The problem of matchmaking in electronic social networks is formulated as an\noptimization problem. In particular, a function measuring the matching degree\nof fields of interest of a search profile with those of an advertising profile\nis proposed.\n", "contributors": [{"name": "de Vries, Andreas", "sameAs": [], "familyName": "de Vries", "additionalName": "", "givenName": "Andreas", "email": ""}], "title": "Mathematical model of interest matchmaking in electronic social networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2007-03-23", "2007-03-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/cs/0703118", "Applied Mathematics 5 (16) 2014, 2619-2629", "doi:10.4236/am.2014.516250", "oai:arXiv.org:cs/0703118"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The problem of matchmaking in electronic social networks is formulated as an\noptimization problem. In particular, a function measuring the matching degree\nof fields of interest of a search profile with those of an advertising profile\nis proposed.\n", "Comment: 6 pages, 3 figures"]}}], "languages": [null], "subjects": ["c.2.4", "computer science - artificial intelligence", "j.4", "i.2.4", "h.3.5", "g.2.3", "computer science - computers and society"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/cs/0703118"}}, {"publisher": {"name": ""}, "description": "  This working paper unveils the crafting of a systematic literature review on\nopen-source platforms. The high-competitive mobile devices market, where\nseveral players such as Apple, Google, Nokia and Microsoft run a platforms- war\nwith constant shifts in their technological strategies, is gaining increasing\nattention from scholars. It matters, then, to review previous literature on\npast platforms-wars, such as the ones from the PC and game-console industries,\nand assess its implications to the current mobile devices platforms-war. The\npaper starts by justifying the purpose and rationale behind this literature\nreview on open-source platforms. The concepts of open-source software and\ncomputer-based platforms were then discussed both individually and in unison,\nin order to clarify the core-concept of 'open-source platform' that guides this\nliterature review. The detailed design of the employed methodological strategy\nis then presented as the central part of this paper. The paper concludes with\npreliminary findings organizing previous literature on open-source platforms\nfor the purpose of guiding future research in this area.\n", "contributors": [{"name": "Teixeira, Jose", "sameAs": [], "familyName": "Teixeira", "additionalName": "", "givenName": "Jose", "email": ""}, {"name": "Baiyere, Abayomi", "sameAs": [], "familyName": "Baiyere", "additionalName": "", "givenName": "Abayomi", "email": ""}], "title": "Crafting a Systematic Literature Review on Open-Source Platforms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.02482", "IFIP Advances in Information and Communication Technology vol 427\n  2014", "doi:10.1007/978-3-642-55128-4_16", "oai:arXiv.org:1501.02482"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This working paper unveils the crafting of a systematic literature review on\nopen-source platforms. The high-competitive mobile devices market, where\nseveral players such as Apple, Google, Nokia and Microsoft run a platforms- war\nwith constant shifts in their technological strategies, is gaining increasing\nattention from scholars. It matters, then, to review previous literature on\npast platforms-wars, such as the ones from the PC and game-console industries,\nand assess its implications to the current mobile devices platforms-war. The\npaper starts by justifying the purpose and rationale behind this literature\nreview on open-source platforms. The concepts of open-source software and\ncomputer-based platforms were then discussed both individually and in unison,\nin order to clarify the core-concept of 'open-source platform' that guides this\nliterature review. The detailed design of the employed methodological strategy\nis then presented as the central part of this paper. The paper concludes with\npreliminary findings organizing previous literature on open-source platforms\nfor the purpose of guiding future research in this area.\n", "Comment: As presented in 10th IFIP WG 2.13 International Conference on Open\n  Source Systems, OSS 2014, San Jos\\'e, Costa Rica, May 6-9, 2014"]}}], "languages": [null], "subjects": ["d.2.9", "computer science - software engineering"], "providerUpdatedDateTime": "2015-01-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.02482"}}, {"publisher": {"name": ""}, "description": "  We study in this paper provenance information for queries with aggregation.\nProvenance information was studied in the context of various query languages\nthat do not allow for aggregation, and recent work has suggested to capture\nprovenance by annotating the different database tuples with elements of a\ncommutative semiring and propagating the annotations through query evaluation.\nWe show that aggregate queries pose novel challenges rendering this approach\ninapplicable. Consequently, we propose a new approach, where we annotate with\nprovenance information not just tuples but also the individual values within\ntuples, using provenance to describe the values computation. We realize this\napproach in a concrete construction, first for \"simple\" queries where the\naggregation operator is the last one applied, and then for arbitrary (positive)\nrelational algebra queries with aggregation; the latter queries are shown to be\nmore challenging in this context. Finally, we use aggregation to encode queries\nwith difference, and study the semantics obtained for such queries on\nprovenance annotated databases.\n", "contributors": [{"name": "Amsterdamer, Yael", "sameAs": [], "familyName": "Amsterdamer", "additionalName": "", "givenName": "Yael", "email": ""}, {"name": "Deutch, Daniel", "sameAs": [], "familyName": "Deutch", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Tannen, Val", "sameAs": [], "familyName": "Tannen", "additionalName": "", "givenName": "Val", "email": ""}], "title": "Provenance for Aggregate Queries", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-01-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.1110", "oai:arXiv.org:1101.1110"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We study in this paper provenance information for queries with aggregation.\nProvenance information was studied in the context of various query languages\nthat do not allow for aggregation, and recent work has suggested to capture\nprovenance by annotating the different database tuples with elements of a\ncommutative semiring and propagating the annotations through query evaluation.\nWe show that aggregate queries pose novel challenges rendering this approach\ninapplicable. Consequently, we propose a new approach, where we annotate with\nprovenance information not just tuples but also the individual values within\ntuples, using provenance to describe the values computation. We realize this\napproach in a concrete construction, first for \"simple\" queries where the\naggregation operator is the last one applied, and then for arbitrary (positive)\nrelational algebra queries with aggregation; the latter queries are shown to be\nmore challenging in this context. Finally, we use aggregation to encode queries\nwith difference, and study the semantics obtained for such queries on\nprovenance annotated databases.\n"}}], "languages": [null], "subjects": ["computer science - databases"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.1110"}}, {"publisher": {"name": ""}, "description": "  We give a deterministic $O(hn^{1+1/h})$-time $(2h)$-approximation nonadaptive\nalgorithm for $1$-median selection in $n$-point metric spaces, where\n$h\\in\\mathbb{Z}^+\\setminus\\{1\\}$ is arbitrary. Our proof generalizes that of\nChang.\n", "contributors": [{"name": "Chang, Ching-Lueh", "sameAs": [], "familyName": "Chang", "additionalName": "", "givenName": "Ching-Lueh", "email": ""}], "title": "A deterministic sublinear-time nonadaptive algorithm for metric\n  $1$-median selection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06764", "oai:arXiv.org:1502.06764"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We give a deterministic $O(hn^{1+1/h})$-time $(2h)$-approximation nonadaptive\nalgorithm for $1$-median selection in $n$-point metric spaces, where\n$h\\in\\mathbb{Z}^+\\setminus\\{1\\}$ is arbitrary. Our proof generalizes that of\nChang.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-02-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06764"}}, {"publisher": {"name": ""}, "description": "  What parts of classical descriptive set theory done in Polish spaces still\nhold for more general topological spaces, possibly T0 or T1, but not T2 (i.e.\nnot Hausdorff)? This question has been addressed by Victor Selivanov in a\nseries of papers centered on algebraic domains. And recently it has been\nconsidered by Matthew de Brecht for quasi-Polish spaces, a framework that\ncontains both countably based continuous domains and Polish spaces. In this\npaper we present alternative unifying topological spaces, that we call\napproximation spaces. They are exactly the spaces for which player Nonempty has\na stationary strategy in the Choquet game. A natural proper subclass of\napproximation spaces coincides with the class of quasi-Polish spaces. We study\nthe Borel and Hausdorff difference hierarchies in approximation spaces,\nrevisiting the work done for the other topological spaces. We also consider the\nproblem of effectivization of these results.\n", "contributors": [{"name": "Becher, Ver\u00f3nica", "sameAs": [], "familyName": "Becher", "additionalName": "", "givenName": "Ver\u00f3nica", "email": ""}, {"name": "Grigorieff, Serge", "sameAs": [], "familyName": "Grigorieff", "additionalName": "", "givenName": "Serge", "email": ""}], "title": "Borel and Hausdorff Hierarchies in Topological Spaces of Choquet Games\n  and Their Effectivization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-11-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1311.0330", "doi:10.1017/S096012951300025X", "oai:arXiv.org:1311.0330"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  What parts of classical descriptive set theory done in Polish spaces still\nhold for more general topological spaces, possibly T0 or T1, but not T2 (i.e.\nnot Hausdorff)? This question has been addressed by Victor Selivanov in a\nseries of papers centered on algebraic domains. And recently it has been\nconsidered by Matthew de Brecht for quasi-Polish spaces, a framework that\ncontains both countably based continuous domains and Polish spaces. In this\npaper we present alternative unifying topological spaces, that we call\napproximation spaces. They are exactly the spaces for which player Nonempty has\na stationary strategy in the Choquet game. A natural proper subclass of\napproximation spaces coincides with the class of quasi-Polish spaces. We study\nthe Borel and Hausdorff difference hierarchies in approximation spaces,\nrevisiting the work done for the other topological spaces. We also consider the\nproblem of effectivization of these results.\n"}}], "languages": [null], "subjects": ["mathematics - logic", "computer science - logic in computer science"], "providerUpdatedDateTime": "2014-11-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1311.0330"}}, {"publisher": {"name": ""}, "description": "  Graph processing is used extensively in areas from social networking mining\nto web indexing. We demonstrate that the performance and dependability of such\napplications critically hinges on the graph data structure used, because a\nfixed, compile-time choice of data structure can lead to poor performance or\napplications unable to complete. To address this problem, we introduce an\napproach that helps programmers transform regular, off-the-shelf graph\napplications into adaptive, more dependable applications where adaptations are\nperformed via runtime selection from alternate data structure representations.\nUsing our approach, applications dynamically adapt to the input graph's\ncharacteristics and changes in available memory so they continue to run when\nfaced with adverse conditions such as low memory. Experiments with graph\nalgorithms on real-world (e.g., Wikipedia metadata, Gnutella topology) and\nsynthetic graph datasets show that our adaptive applications run to completion\nwith lower execution time and/or memory utilization in comparison to their\nnon-adaptive versions.\n", "contributors": [{"name": "Kusum, Amlan", "sameAs": [], "familyName": "Kusum", "additionalName": "", "givenName": "Amlan", "email": ""}, {"name": "Neamtiu, Iulian", "sameAs": [], "familyName": "Neamtiu", "additionalName": "", "givenName": "Iulian", "email": ""}, {"name": "Gupta, Rajiv", "sameAs": [], "familyName": "Gupta", "additionalName": "", "givenName": "Rajiv", "email": ""}], "title": "Adapting Graph Application Performance via Alternate Data Structure\n  Representation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.8120", "oai:arXiv.org:1412.8120"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Graph processing is used extensively in areas from social networking mining\nto web indexing. We demonstrate that the performance and dependability of such\napplications critically hinges on the graph data structure used, because a\nfixed, compile-time choice of data structure can lead to poor performance or\napplications unable to complete. To address this problem, we introduce an\napproach that helps programmers transform regular, off-the-shelf graph\napplications into adaptive, more dependable applications where adaptations are\nperformed via runtime selection from alternate data structure representations.\nUsing our approach, applications dynamically adapt to the input graph's\ncharacteristics and changes in available memory so they continue to run when\nfaced with adverse conditions such as low memory. Experiments with graph\nalgorithms on real-world (e.g., Wikipedia metadata, Gnutella topology) and\nsynthetic graph datasets show that our adaptive applications run to completion\nwith lower execution time and/or memory utilization in comparison to their\nnon-adaptive versions.\n", "Comment: Part of ADAPT Workshop proceedings, 2015 (arXiv:1412.2347)"]}}], "languages": [null], "subjects": ["computer science - programming languages"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.8120"}}, {"publisher": {"name": ""}, "description": "  We design a soft-in soft-out (SISO) decision feedback equalizer (DFE) that\nperforms better than its linear counterpart in turbo equalizer (TE) setting.\nUnlike previously developed SISO-DFEs, the present DFE scheme relies on\nextrinsic information formulation that directly takes into account the error\npropagation effect. With this new approach, both error rate simulation and the\nextrinsic information transfer (EXIT) chart analysis indicate that the proposed\nSISO-DFE is superior to the well-known SISO linear equalizer (LE). This result\nis in contrast with the general understanding today that the error propagation\neffect of the DFE degrades the overall TE performance below that of the TE\nbased on a LE. We also describe a new extrinsic information combining strategy\ninvolving the outputs of two DFEs running in opposite directions, that explores\nerror correlation between the two sets of DFE outputs. When this method is\ncombined with the new DFE extrinsic information formulation, the resulting\n\"bidirectional\" turbo-DFE achieves excellent performance-complexity tradeoffs\ncompared to the TE based on the BCJR algorithm or on the LE. Unlike turbo LE or\nturbo DFE, the turbo BiDFE's performance does not degrade significantly as the\nfeedforward and feedback filter taps are constrained to be time-invariant.\n", "contributors": [{"name": "Jeong, Seongwook", "sameAs": [], "familyName": "Jeong", "additionalName": "", "givenName": "Seongwook", "email": ""}, {"name": "Moon, Jaekyun", "sameAs": [], "familyName": "Moon", "additionalName": "", "givenName": "Jaekyun", "email": ""}], "title": "Soft-In Soft-Out DFE and Bi-directional DFE", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-18", "2011-04-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.3561", "oai:arXiv.org:1104.3561"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We design a soft-in soft-out (SISO) decision feedback equalizer (DFE) that\nperforms better than its linear counterpart in turbo equalizer (TE) setting.\nUnlike previously developed SISO-DFEs, the present DFE scheme relies on\nextrinsic information formulation that directly takes into account the error\npropagation effect. With this new approach, both error rate simulation and the\nextrinsic information transfer (EXIT) chart analysis indicate that the proposed\nSISO-DFE is superior to the well-known SISO linear equalizer (LE). This result\nis in contrast with the general understanding today that the error propagation\neffect of the DFE degrades the overall TE performance below that of the TE\nbased on a LE. We also describe a new extrinsic information combining strategy\ninvolving the outputs of two DFEs running in opposite directions, that explores\nerror correlation between the two sets of DFE outputs. When this method is\ncombined with the new DFE extrinsic information formulation, the resulting\n\"bidirectional\" turbo-DFE achieves excellent performance-complexity tradeoffs\ncompared to the TE based on the BCJR algorithm or on the LE. Unlike turbo LE or\nturbo DFE, the turbo BiDFE's performance does not degrade significantly as the\nfeedforward and feedback filter taps are constrained to be time-invariant.\n", "Comment: 22 pages, 13 figures. The material in this paper was presented in\n  part at ICC 2010, Cape Town, South Africa, May 2010"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.3561"}}, {"publisher": {"name": ""}, "description": "  The search for linear kernels for the Dominating Set problem on classes of\ngraphs of a topological nature has been one of the leading trends in\nkernelization in recent years. Following the fundamental work of Alber et al.\nthat established a linear kernel for the problem on planar graphs, linear\nkernels have been given for bounded-genus graphs, apex-minor-free graphs,\n$H$-minor-free graphs, and $H$-topological-minor-free graphs. These\ngeneralizations are based on bidimensionality and powerful decomposition\ntheorems for $H$-minor-free graphs and $H$-topological-minor-free graphs of\nRobertson and Seymour and of Grohe and Marx.\n  In this work we investigate a new approach to kernelization for Dominating\nSet on sparse graph classes. The approach is based on the theory of bounded\nexpansion and nowhere dense graph classes, developed in the recent years by\nNe\\v{s}et\\v{r}il and Ossona de Mendez, among others. More precisely, we prove\nthat Dominating Set admits a linear kernel on any hereditary graph class of\nbounded expansion and an almost linear kernel on any hereditary nowhere dense\ngraph class. Since the class of $H$-topological-minor-free graphs has bounded\nexpansion, our results strongly generalize all the above mentioned works on\nkernelization of Dominating Set. At the same time, our algorithms are based on\nrelatively short and self-contained combinatorial arguments, and do not depend\non bidimensionality or decomposition theorems.\n  Finally, we prove that for the closely related Connected Dominating Set\nproblem, the existence of such kernelization algorithms is unlikely, even\nthough the problem is known to admit a linear kernel on\n$H$-topological-minor-free graphs. Thus, it seems that whereas for Dominating\nSet sparsity is enough to guarantee the existence of an efficient kernelization\nalgorithm, for Connected Dominating Set stronger constraints of topological\nnature become necessary.\n", "contributors": [{"name": "Drange, P\u00e5l Gr\u00f8n\u00e5s", "sameAs": [], "familyName": "Drange", "additionalName": "Gr\u00f8n\u00e5s", "givenName": "P\u00e5l", "email": ""}, {"name": "Dregi, Markus S.", "sameAs": [], "familyName": "Dregi", "additionalName": "S.", "givenName": "Markus", "email": ""}, {"name": "Fomin, Fedor V.", "sameAs": [], "familyName": "Fomin", "additionalName": "V.", "givenName": "Fedor", "email": ""}, {"name": "Kreutzer, Stephan", "sameAs": [], "familyName": "Kreutzer", "additionalName": "", "givenName": "Stephan", "email": ""}, {"name": "Lokshtanov, Daniel", "sameAs": [], "familyName": "Lokshtanov", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Pilipczuk, Marcin", "sameAs": [], "familyName": "Pilipczuk", "additionalName": "", "givenName": "Marcin", "email": ""}, {"name": "Pilipczuk, Micha\u0142", "sameAs": [], "familyName": "Pilipczuk", "additionalName": "", "givenName": "Micha\u0142", "email": ""}, {"name": "Reidl, Felix", "sameAs": [], "familyName": "Reidl", "additionalName": "", "givenName": "Felix", "email": ""}, {"name": "Saurabh, Saket", "sameAs": [], "familyName": "Saurabh", "additionalName": "", "givenName": "Saket", "email": ""}, {"name": "Villaamil, Fernando S\u00e1nchez", "sameAs": [], "familyName": "Villaamil", "additionalName": "S\u00e1nchez", "givenName": "Fernando", "email": ""}, {"name": "Sikdar, Somnath", "sameAs": [], "familyName": "Sikdar", "additionalName": "", "givenName": "Somnath", "email": ""}], "title": "Kernelization and Sparseness: the case of Dominating Set", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4575", "oai:arXiv.org:1411.4575"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The search for linear kernels for the Dominating Set problem on classes of\ngraphs of a topological nature has been one of the leading trends in\nkernelization in recent years. Following the fundamental work of Alber et al.\nthat established a linear kernel for the problem on planar graphs, linear\nkernels have been given for bounded-genus graphs, apex-minor-free graphs,\n$H$-minor-free graphs, and $H$-topological-minor-free graphs. These\ngeneralizations are based on bidimensionality and powerful decomposition\ntheorems for $H$-minor-free graphs and $H$-topological-minor-free graphs of\nRobertson and Seymour and of Grohe and Marx.\n  In this work we investigate a new approach to kernelization for Dominating\nSet on sparse graph classes. The approach is based on the theory of bounded\nexpansion and nowhere dense graph classes, developed in the recent years by\nNe\\v{s}et\\v{r}il and Ossona de Mendez, among others. More precisely, we prove\nthat Dominating Set admits a linear kernel on any hereditary graph class of\nbounded expansion and an almost linear kernel on any hereditary nowhere dense\ngraph class. Since the class of $H$-topological-minor-free graphs has bounded\nexpansion, our results strongly generalize all the above mentioned works on\nkernelization of Dominating Set. At the same time, our algorithms are based on\nrelatively short and self-contained combinatorial arguments, and do not depend\non bidimensionality or decomposition theorems.\n  Finally, we prove that for the closely related Connected Dominating Set\nproblem, the existence of such kernelization algorithms is unlikely, even\nthough the problem is known to admit a linear kernel on\n$H$-topological-minor-free graphs. Thus, it seems that whereas for Dominating\nSet sparsity is enough to guarantee the existence of an efficient kernelization\nalgorithm, for Connected Dominating Set stronger constraints of topological\nnature become necessary.\n", "Comment: 42 pages, 6 figures"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4575"}}, {"publisher": {"name": ""}, "description": "  Virtual Sectorization (ViSn) aims at covering a confined area such as a\ntraffic hot-spot using a narrow beam. The beam is generated by a remote antenna\narray located at-or close to the Base Station (BS). This paper develops the\nViSn model and provides the guidelines for designing the Virtual Sector (ViS)\nantenna. In order to mitigate interference between the ViS and the traditional\nmacro sector covering the rest of the area, a Dynamic Spectrum Allocation (DSA)\nalgorithm that self-optimizes the frequency bandwidth split between the macro\ncell and the ViS is also proposed. The Self-Organizing Network (SON) algorithm\nis constructed to maximize the proportional fair utility of all the users\nthroughputs. Numerical simulations show the interest in deploying ViSn, and the\nsignificant capacity gain brought about by the self-optimized bandwidth sharing\nwith respect to a full reuse of the bandwidth by the ViS.\n", "contributors": [{"name": "TALL, Abdoulaye", "sameAs": [], "familyName": "TALL", "additionalName": "", "givenName": "Abdoulaye", "email": ""}, {"name": "Altman, Zwi", "sameAs": [], "familyName": "Altman", "additionalName": "", "givenName": "Zwi", "email": ""}, {"name": "Altman, Eitan", "sameAs": [], "familyName": "Altman", "additionalName": "", "givenName": "Eitan", "email": ""}], "title": "Virtual sectorization: design and self-optimization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04067", "oai:arXiv.org:1503.04067"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Virtual Sectorization (ViSn) aims at covering a confined area such as a\ntraffic hot-spot using a narrow beam. The beam is generated by a remote antenna\narray located at-or close to the Base Station (BS). This paper develops the\nViSn model and provides the guidelines for designing the Virtual Sector (ViS)\nantenna. In order to mitigate interference between the ViS and the traditional\nmacro sector covering the rest of the area, a Dynamic Spectrum Allocation (DSA)\nalgorithm that self-optimizes the frequency bandwidth split between the macro\ncell and the ViS is also proposed. The Self-Organizing Network (SON) algorithm\nis constructed to maximize the proportional fair utility of all the users\nthroughputs. Numerical simulations show the interest in deploying ViSn, and the\nsignificant capacity gain brought about by the self-optimized bandwidth sharing\nwith respect to a full reuse of the bandwidth by the ViS.\n", "Comment: VTC2015-Spring, 5th International Workshop on Self-Organizing\n  Networks (IWSON), May 2015, Glasgow, United Kingdom"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04067"}}, {"publisher": {"name": ""}, "description": "  Pool of knowledge available to the mankind depends on the source of learning\nresources, which can vary from ancient printed documents to present electronic\nmaterial. The rapid conversion of material available in traditional libraries\nto digital form needs a significant amount of work if we are to maintain the\nformat and the look of the electronic documents as same as their printed\ncounterparts. Most of the printed documents contain not only characters and its\nformatting but also some associated non text objects such as tables, charts and\ngraphical objects. It is challenging to detect them and to concentrate on the\nformat preservation of the contents while reproducing them. To address this\nissue, we propose an algorithm using local thresholds for word space and line\nheight to locate and extract all categories of tables from scanned document\nimages. From the experiments performed on 298 documents, we conclude that our\nalgorithm has an overall accuracy of about 75% in detecting tables from the\nscanned document images. Since the algorithm does not completely depend on rule\nlines, it can detect all categories of tables in a range of scanned documents\nwith different font types, styles and sizes to extract their formatting\nfeatures. Moreover, the algorithm can be applied to locate tables in multi\ncolumn layouts with small modification in layout analysis. Treating tables with\ntheir existing formatting features will tremendously help the reproducing of\nprinted documents for reprinting and updating purposes.\n", "contributors": [{"name": "Mac, Akmal Jahan", "sameAs": [], "familyName": "Mac", "additionalName": "Jahan", "givenName": "Akmal", "email": ""}, {"name": "Ragel, Roshan G", "sameAs": [], "familyName": "Ragel", "additionalName": "G", "givenName": "Roshan", "email": ""}], "title": "Locating Tables in Scanned Documents for Reconstructing and Republishing\n  (ICIAfS14)", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7689", "oai:arXiv.org:1412.7689"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Pool of knowledge available to the mankind depends on the source of learning\nresources, which can vary from ancient printed documents to present electronic\nmaterial. The rapid conversion of material available in traditional libraries\nto digital form needs a significant amount of work if we are to maintain the\nformat and the look of the electronic documents as same as their printed\ncounterparts. Most of the printed documents contain not only characters and its\nformatting but also some associated non text objects such as tables, charts and\ngraphical objects. It is challenging to detect them and to concentrate on the\nformat preservation of the contents while reproducing them. To address this\nissue, we propose an algorithm using local thresholds for word space and line\nheight to locate and extract all categories of tables from scanned document\nimages. From the experiments performed on 298 documents, we conclude that our\nalgorithm has an overall accuracy of about 75% in detecting tables from the\nscanned document images. Since the algorithm does not completely depend on rule\nlines, it can detect all categories of tables in a range of scanned documents\nwith different font types, styles and sizes to extract their formatting\nfeatures. Moreover, the algorithm can be applied to locate tables in multi\ncolumn layouts with small modification in layout analysis. Treating tables with\ntheir existing formatting features will tremendously help the reproducing of\nprinted documents for reprinting and updating purposes.\n", "Comment: The 7th International Conference on Information and Automation for\n  Sustainability (ICIAfS) 2014"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7689"}}, {"publisher": {"name": ""}, "description": "  The theory of universal Taylor series can be extended to the case of Pad\\'e\napproximants where the universal approximation is not realized by polynomials\nany more, but by rational functions, namely the Pad\\'e approximants of some\npower series. We present the first generic result in this direction, for Pad\\'e\napproximants corresponding to Taylor developments of holomorphic functions in\nsimply connected domains. The universal approximation is required only on\ncompact sets $K$ which lie outside the domain of definition and have connected\ncomplement. If the sets $K$ are additionally disjoint from the boundary of the\ndomain of definition, then the universal functions can be smooth on the\nboundary.\n", "contributors": [{"name": "Daras, N.", "sameAs": [], "familyName": "Daras", "additionalName": "", "givenName": "N.", "email": ""}, {"name": "Fournodavlos, G.", "sameAs": [], "familyName": "Fournodavlos", "additionalName": "", "givenName": "G.", "email": ""}, {"name": "Nestoridis, V.", "sameAs": [], "familyName": "Nestoridis", "additionalName": "", "givenName": "V.", "email": ""}], "title": "Universal Pad\\'e approximants on simply connected domains", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.02381", "oai:arXiv.org:1501.02381"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  The theory of universal Taylor series can be extended to the case of Pad\\'e\napproximants where the universal approximation is not realized by polynomials\nany more, but by rational functions, namely the Pad\\'e approximants of some\npower series. We present the first generic result in this direction, for Pad\\'e\napproximants corresponding to Taylor developments of holomorphic functions in\nsimply connected domains. The universal approximation is required only on\ncompact sets $K$ which lie outside the domain of definition and have connected\ncomplement. If the sets $K$ are additionally disjoint from the boundary of the\ndomain of definition, then the universal functions can be smooth on the\nboundary.\n"}}], "languages": [null], "subjects": ["mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.02381"}}, {"publisher": {"name": ""}, "description": "  Let $X$ be a compact generalized Sasakian CR manifold of dimension $2n-1$,\n$n\\geqslant2$, and let $L$ be a generalized Sasakian CR line bundle over $X$\nequipped with a rigid semi-positive Hermitian fiber metric $h^L$. In this paper\nwe prove that if $h^L$ is positive at some point of $X$ and conditions Y(0) and\nY(1) hold at each point of $X$, then $L$ is big.\n", "contributors": [{"name": "Hsiao, Chin-Yu", "sameAs": [], "familyName": "Hsiao", "additionalName": "", "givenName": "Chin-Yu", "email": ""}], "title": "Existence of CR sections for high power of semi-positive generalized\n  Sasakian CR line bundles over generalized Sasakian CR manifolds", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-04-21", "2013-05-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1204.4810", "Ann. Glob. Anal. Geom. (2015)", "doi:10.1007/s10455-014-9434-0.", "oai:arXiv.org:1204.4810"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Let $X$ be a compact generalized Sasakian CR manifold of dimension $2n-1$,\n$n\\geqslant2$, and let $L$ be a generalized Sasakian CR line bundle over $X$\nequipped with a rigid semi-positive Hermitian fiber metric $h^L$. In this paper\nwe prove that if $h^L$ is positive at some point of $X$ and conditions Y(0) and\nY(1) hold at each point of $X$, then $L$ is big.\n", "Comment: 46 pages"]}}], "languages": [null], "subjects": ["mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1204.4810"}}, {"publisher": {"name": ""}, "description": "  Spread-spectrum signals are increasingly adopted in fields including\ncommunications, testing of electronic systems, Electro-Magnetic Compatibility\n(EMC) enhancement, ultrasonic non-destructive testing. This paper considers the\nsynthesis of constant-envelope band-pass wave-forms with preassigned spectra\nvia an FM technique using only a limited number of frequencies. In particular,\nan optimization-based approach for the selection of appropriate modulation\nparameters and statistical features of the modulating waveform is proposed. By\nexample, it is shown that the design problem generally admits multiple local\noptima, but can still be managed with relative ease since the local optima can\ntypically be scanned by changing the initial setting of a single parameter.\n", "contributors": [{"name": "Callegari, Sergio", "sameAs": [], "familyName": "Callegari", "additionalName": "", "givenName": "Sergio", "email": ""}], "title": "Achievement of Preassigned Spectra in the Synthesis of Band-Pass\n  Constant-Envelope Signals by Rapidly Hopping through Discrete Frequencies", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6357", "Proceedings of the 2014 IEEE International Symposium on Circuits\n  and Systems (ISCAS), pp. 2776-2779, Jun. 2014", "doi:10.1109/ISCAS.2014.6865749", "oai:arXiv.org:1412.6357"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Spread-spectrum signals are increasingly adopted in fields including\ncommunications, testing of electronic systems, Electro-Magnetic Compatibility\n(EMC) enhancement, ultrasonic non-destructive testing. This paper considers the\nsynthesis of constant-envelope band-pass wave-forms with preassigned spectra\nvia an FM technique using only a limited number of frequencies. In particular,\nan optimization-based approach for the selection of appropriate modulation\nparameters and statistical features of the modulating waveform is proposed. By\nexample, it is shown that the design problem generally admits multiple local\noptima, but can still be managed with relative ease since the local optima can\ntypically be scanned by changing the initial setting of a single parameter.\n", "Comment: 4 pages, 5 figures. Pre-print from conference proceedings"]}}], "languages": [null], "subjects": ["statistics and probability", "computer science - information theory", "physics - data analysis"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6357"}}, {"publisher": {"name": ""}, "description": "  This paper investigates the effect of sub-Nyquist sampling upon the capacity\nof an analog channel. The channel is assumed to be a linear time-invariant\nGaussian channel, where perfect channel knowledge is available at both the\ntransmitter and the receiver. We consider a general class of right-invertible\ntime-preserving sampling methods which include irregular nonuniform sampling,\nand characterize in closed form the channel capacity achievable by this class\nof sampling methods, under a sampling rate and power constraint. Our results\nindicate that the optimal sampling structures extract out the set of\nfrequencies that exhibits the highest signal-to-noise ratio among all spectral\nsets of measure equal to the sampling rate. This can be attained through\nfilterbank sampling with uniform sampling at each branch with possibly\ndifferent rates, or through a single branch of modulation and filtering\nfollowed by uniform sampling. These results reveal that for a large class of\nchannels, employing irregular nonuniform sampling sets, while typically\ncomplicated to realize, does not provide capacity gain over uniform sampling\nsets with appropriate preprocessing. Our findings demonstrate that aliasing or\nscrambling of spectral components does not provide capacity gain, which is in\ncontrast to the benefits obtained from random mixing in spectrum-blind\ncompressive sampling schemes.\n", "contributors": [{"name": "Chen, Yuxin", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Yuxin", "email": ""}, {"name": "Goldsmith, Andrea J.", "sameAs": [], "familyName": "Goldsmith", "additionalName": "J.", "givenName": "Andrea", "email": ""}, {"name": "Eldar, Yonina C.", "sameAs": [], "familyName": "Eldar", "additionalName": "C.", "givenName": "Yonina", "email": ""}], "title": "Channel Capacity under Sub-Nyquist Nonuniform Sampling", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-04-26", "2014-03-21"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1204.6049", "IEEE Transactions on Information Theory, Vol. 60, No. 8, pp.\n  4739-4756, August 2014", "doi:10.1109/TIT.2014.2323406", "oai:arXiv.org:1204.6049"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper investigates the effect of sub-Nyquist sampling upon the capacity\nof an analog channel. The channel is assumed to be a linear time-invariant\nGaussian channel, where perfect channel knowledge is available at both the\ntransmitter and the receiver. We consider a general class of right-invertible\ntime-preserving sampling methods which include irregular nonuniform sampling,\nand characterize in closed form the channel capacity achievable by this class\nof sampling methods, under a sampling rate and power constraint. Our results\nindicate that the optimal sampling structures extract out the set of\nfrequencies that exhibits the highest signal-to-noise ratio among all spectral\nsets of measure equal to the sampling rate. This can be attained through\nfilterbank sampling with uniform sampling at each branch with possibly\ndifferent rates, or through a single branch of modulation and filtering\nfollowed by uniform sampling. These results reveal that for a large class of\nchannels, employing irregular nonuniform sampling sets, while typically\ncomplicated to realize, does not provide capacity gain over uniform sampling\nsets with appropriate preprocessing. Our findings demonstrate that aliasing or\nscrambling of spectral components does not provide capacity gain, which is in\ncontrast to the benefits obtained from random mixing in spectrum-blind\ncompressive sampling schemes.\n", "Comment: accepted to IEEE Transactions on Information Theory, 2014"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1204.6049"}}, {"publisher": {"name": ""}, "description": "  It is not known whether Thompson's group F is automatic. With the recent\nextensions of the notion of an automatic group to graph automatic by\nKharlampovich, Khoussainov and Miasnikov and then to C-graph automatic by the\nauthors, a compelling question is whether F is graph automatic or C-graph\nautomatic for an appropriate language class C. The extended definitions allow\nthe use of a symbol alphabet for the normal form language, replacing the\ndependence on generating set. In this paper we construct a 1-counter graph\nautomatic structure for F based on the standard infinite normal form for group\nelements.\n", "contributors": [{"name": "Elder, Murray", "sameAs": [], "familyName": "Elder", "additionalName": "", "givenName": "Murray", "email": ""}, {"name": "Taback, Jennifer", "sameAs": [], "familyName": "Taback", "additionalName": "", "givenName": "Jennifer", "email": ""}], "title": "Thompson's group F is 1-counter graph automatic", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04313", "oai:arXiv.org:1501.04313"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  It is not known whether Thompson's group F is automatic. With the recent\nextensions of the notion of an automatic group to graph automatic by\nKharlampovich, Khoussainov and Miasnikov and then to C-graph automatic by the\nauthors, a compelling question is whether F is graph automatic or C-graph\nautomatic for an appropriate language class C. The extended definitions allow\nthe use of a symbol alphabet for the normal form language, replacing the\ndependence on generating set. In this paper we construct a 1-counter graph\nautomatic structure for F based on the standard infinite normal form for group\nelements.\n"}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "mathematics - group theory", "68q45", "20f65"], "providerUpdatedDateTime": "2015-01-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04313"}}, {"publisher": {"name": ""}, "description": "  An algorithm and associated strategy for solving polynomial systems within\nthe optimization framework is presented. The algorithm and strategy are named,\nrespectively, the penetrating gradient algorithm and the deepest descent\nstrategy. The most prominent feature of penetrating gradient algorithm, after\nwhich it was named, is its ability to see and penetrate through the obstacles\nin error space along the line of search direction and to jump to the global\nminimizer in a single step. The ability to find the deepest point in an\narbitrary direction, no matter how distant the point is and regardless of the\nrelief of error space between the current and the best point, motivates\nmovements in directions in which cost function can be maximally reduced, rather\nthan in directions that seem to be the best locally (like, for instance, the\nsteepest descent, i.e., negative gradient direction). Therefore, the strategy\nis named the deepest descent, in contrast but alluding to the steepest descent.\nPenetrating gradient algorithm is derived and its properties are proven\nmathematically, while features of the deepest descent strategy are shown by\ncomparative simulations. Extensive benchmark tests confirm that the proposed\nalgorithm and strategy jointly form an effective solver of polynomial systems.\nIn addition, further theoretical considerations in Section 5 about solving\nlinear systems by the proposed method reveal a surprising and interesting\nrelation of proposed and Gauss-Seidel method.\n", "contributors": [{"name": "Hlupic, Nikica", "sameAs": [], "familyName": "Hlupic", "additionalName": "", "givenName": "Nikica", "email": ""}, {"name": "Beros, Ivo", "sameAs": [], "familyName": "Beros", "additionalName": "", "givenName": "Ivo", "email": ""}], "title": "Solving Polynomial Systems by Penetrating Gradient Algorithm Applying\n  Deepest Descent Strategy", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.03341", "oai:arXiv.org:1501.03341"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  An algorithm and associated strategy for solving polynomial systems within\nthe optimization framework is presented. The algorithm and strategy are named,\nrespectively, the penetrating gradient algorithm and the deepest descent\nstrategy. The most prominent feature of penetrating gradient algorithm, after\nwhich it was named, is its ability to see and penetrate through the obstacles\nin error space along the line of search direction and to jump to the global\nminimizer in a single step. The ability to find the deepest point in an\narbitrary direction, no matter how distant the point is and regardless of the\nrelief of error space between the current and the best point, motivates\nmovements in directions in which cost function can be maximally reduced, rather\nthan in directions that seem to be the best locally (like, for instance, the\nsteepest descent, i.e., negative gradient direction). Therefore, the strategy\nis named the deepest descent, in contrast but alluding to the steepest descent.\nPenetrating gradient algorithm is derived and its properties are proven\nmathematically, while features of the deepest descent strategy are shown by\ncomparative simulations. Extensive benchmark tests confirm that the proposed\nalgorithm and strategy jointly form an effective solver of polynomial systems.\nIn addition, further theoretical considerations in Section 5 about solving\nlinear systems by the proposed method reveal a surprising and interesting\nrelation of proposed and Gauss-Seidel method.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "mathematics - numerical analysis", "computer science - mathematical software"], "providerUpdatedDateTime": "2015-01-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.03341"}}, {"publisher": {"name": ""}, "description": "  We study the problem of detecting the presence of an underlying\nhigh-dimensional geometric structure in a random graph. Under the null\nhypothesis, the observed graph is a realization of an Erd{\\H{o}}s-R{\\'e}nyi\nrandom graph $G(n,p)$. Under the alternative, the graph is generated from the\n$G(n,p,d)$ model, where each vertex corresponds to a latent independent random\nvector uniformly distributed on the sphere $\\mathbb{S}^{d-1}$, and two vertices\nare connected if the corresponding latent vectors are close enough. In the\ndense regime (i.e., $p$ is a constant), we propose a near-optimal and\ncomputationally efficient testing procedure based on a new quantity which we\ncall signed triangles. The proof of the detection lower bound is based on a new\nbound on the total variation distance between a Wishart matrix and an\nappropriately normalized GOE matrix. In the sparse regime, we make a conjecture\nfor the optimal detection boundary. We conclude the paper with some preliminary\nsteps on the problem of estimating the dimension in $G(n,p,d)$.\n", "contributors": [{"name": "Bubeck, S\u00e9bastien", "sameAs": [], "familyName": "Bubeck", "additionalName": "", "givenName": "S\u00e9bastien", "email": ""}, {"name": "Ding, Jian", "sameAs": [], "familyName": "Ding", "additionalName": "", "givenName": "Jian", "email": ""}, {"name": "Eldan, Ronen", "sameAs": [], "familyName": "Eldan", "additionalName": "", "givenName": "Ronen", "email": ""}, {"name": "R\u00e1cz, Mikl\u00f3s", "sameAs": [], "familyName": "R\u00e1cz", "additionalName": "", "givenName": "Mikl\u00f3s", "email": ""}], "title": "Testing for high-dimensional geometry in random graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5713", "oai:arXiv.org:1411.5713"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  We study the problem of detecting the presence of an underlying\nhigh-dimensional geometric structure in a random graph. Under the null\nhypothesis, the observed graph is a realization of an Erd{\\H{o}}s-R{\\'e}nyi\nrandom graph $G(n,p)$. Under the alternative, the graph is generated from the\n$G(n,p,d)$ model, where each vertex corresponds to a latent independent random\nvector uniformly distributed on the sphere $\\mathbb{S}^{d-1}$, and two vertices\nare connected if the corresponding latent vectors are close enough. In the\ndense regime (i.e., $p$ is a constant), we propose a near-optimal and\ncomputationally efficient testing procedure based on a new quantity which we\ncall signed triangles. The proof of the detection lower bound is based on a new\nbound on the total variation distance between a Wishart matrix and an\nappropriately normalized GOE matrix. In the sparse regime, we make a conjecture\nfor the optimal detection boundary. We conclude the paper with some preliminary\nsteps on the problem of estimating the dimension in $G(n,p,d)$.\n", "Comment: 27 pages"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "mathematics - probability", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-11-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5713"}}, {"publisher": {"name": ""}, "description": "  Since the first appearance in Fridrich's design, the usage of\npermutation-diffusion structure for designing digital image cryptosystem has\nbeen receiving increasing research attention in the field of chaos-based\ncryptography. Recently, a novel chaotic Image Cipher using one round Modified\nPermutation-Diffusion pattern (ICMPD) was proposed. Unlike traditional\npermutation-diffusion structure, the permutation is operated on bit level\ninstead of pixel level and the diffusion is operated on masked pixels, which\nare obtained by carrying out the classical affine cipher, instead of plain\npixels in ICMPD. Following a \\textit{divide-and-conquer strategy}, this paper\nreports that ICMPD can be compromised by a chosen-plaintext attack efficiently\nand the involved data complexity is linear to the size of the plain-image.\nMoreover, the relationship between the cryptographic kernel at the diffusion\nstage of ICMPD and modulo addition then XORing is explored thoroughly.\n", "contributors": [{"name": "Liu, Yuansheng", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Yuansheng", "email": ""}, {"name": "Zhang, Leo Yu", "sameAs": [], "familyName": "Zhang", "additionalName": "Yu", "givenName": "Leo", "email": ""}, {"name": "Wang, Jia", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Jia", "email": ""}, {"name": "Zhang, Yushu", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Yushu", "email": ""}, {"name": "Wong, Kwok-wo", "sameAs": [], "familyName": "Wong", "additionalName": "", "givenName": "Kwok-wo", "email": ""}], "title": "Chosen-plaintext attack of an image encryption scheme based on modified\n  permutation-diffusion structure", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06638", "oai:arXiv.org:1503.06638"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Since the first appearance in Fridrich's design, the usage of\npermutation-diffusion structure for designing digital image cryptosystem has\nbeen receiving increasing research attention in the field of chaos-based\ncryptography. Recently, a novel chaotic Image Cipher using one round Modified\nPermutation-Diffusion pattern (ICMPD) was proposed. Unlike traditional\npermutation-diffusion structure, the permutation is operated on bit level\ninstead of pixel level and the diffusion is operated on masked pixels, which\nare obtained by carrying out the classical affine cipher, instead of plain\npixels in ICMPD. Following a \\textit{divide-and-conquer strategy}, this paper\nreports that ICMPD can be compromised by a chosen-plaintext attack efficiently\nand the involved data complexity is linear to the size of the plain-image.\nMoreover, the relationship between the cryptographic kernel at the diffusion\nstage of ICMPD and modulo addition then XORing is explored thoroughly.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06638"}}, {"publisher": {"name": ""}, "description": "  Thompson sampling provides a solution to bandit problems in which new\nobservations are allocated to arms with the posterior probability that an arm\nis optimal. While sometimes easy to implement and asymptotically optimal,\nThompson sampling can be computationally demanding in large scale bandit\nproblems, and its performance is dependent on the model fit to the observed\ndata. We introduce bootstrap Thompson sampling (BTS), a heuristic method for\nsolving bandit problems which modifies Thompson sampling by replacing the\nposterior distribution used in Thompson sampling by a bootstrap distribution.\nWe first explain BTS and show that the performance of BTS is competitive to\nThompson sampling in the well-studied Bernoulli bandit case. Subsequently, we\ndetail why BTS using the online bootstrap is more scalable than regular\nThompson sampling, and we show through simulation that BTS is more robust to a\nmisspecified error distribution. BTS is an appealing modification of Thompson\nsampling, especially when samples from the posterior are otherwise not\navailable or are costly.\n", "contributors": [{"name": "Eckles, Dean", "sameAs": [], "familyName": "Eckles", "additionalName": "", "givenName": "Dean", "email": ""}, {"name": "Kaptein, Maurits", "sameAs": [], "familyName": "Kaptein", "additionalName": "", "givenName": "Maurits", "email": ""}], "title": "Thompson sampling with the online bootstrap", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4009", "oai:arXiv.org:1410.4009"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Thompson sampling provides a solution to bandit problems in which new\nobservations are allocated to arms with the posterior probability that an arm\nis optimal. While sometimes easy to implement and asymptotically optimal,\nThompson sampling can be computationally demanding in large scale bandit\nproblems, and its performance is dependent on the model fit to the observed\ndata. We introduce bootstrap Thompson sampling (BTS), a heuristic method for\nsolving bandit problems which modifies Thompson sampling by replacing the\nposterior distribution used in Thompson sampling by a bootstrap distribution.\nWe first explain BTS and show that the performance of BTS is competitive to\nThompson sampling in the well-studied Bernoulli bandit case. Subsequently, we\ndetail why BTS using the online bootstrap is more scalable than regular\nThompson sampling, and we show through simulation that BTS is more robust to a\nmisspecified error distribution. BTS is an appealing modification of Thompson\nsampling, especially when samples from the posterior are otherwise not\navailable or are costly.\n", "Comment: 13 pages, 4 figures"]}}], "languages": [null], "subjects": ["g.3", "computer science - learning", "i.2.6", "statistics - computation", "68w27", "62l05", "statistics - machine learning"], "providerUpdatedDateTime": "2014-10-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4009"}}, {"publisher": {"name": ""}, "description": "  We consider secret key generation from relative localization information of a\npair of nodes in a mobile wireless network in the presence of a mobile\neavesdropper. Our problem can be categorized under the source models of\ninformation theoretic secrecy, where the distance between the legitimate nodes\nacts as the observed common randomness. We characterize the theoretical limits\non the achievable secret key bit rate, in terms of the observation noise\nvariance at the legitimate nodes and the eavesdropper. This work provides a\nframework that combines information theoretic secrecy and wireless\nlocalization, and proves that the localization information provides a\nsignificant additional resource for secret key generation in mobile wireless\nnetworks.\n", "contributors": [{"name": "Gungor, Onur", "sameAs": [], "familyName": "Gungor", "additionalName": "", "givenName": "Onur", "email": ""}, {"name": "Chen, Fangzhou", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Fangzhou", "email": ""}, {"name": "Koksal, C. Emre", "sameAs": [], "familyName": "Koksal", "additionalName": "Emre", "givenName": "C.", "email": ""}], "title": "Secret Key Generation Via Localization and Mobility", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-12-12", "2014-05-20"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1112.2793", "oai:arXiv.org:1112.2793"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We consider secret key generation from relative localization information of a\npair of nodes in a mobile wireless network in the presence of a mobile\neavesdropper. Our problem can be categorized under the source models of\ninformation theoretic secrecy, where the distance between the legitimate nodes\nacts as the observed common randomness. We characterize the theoretical limits\non the achievable secret key bit rate, in terms of the observation noise\nvariance at the legitimate nodes and the eavesdropper. This work provides a\nframework that combines information theoretic secrecy and wireless\nlocalization, and proves that the localization information provides a\nsignificant additional resource for secret key generation in mobile wireless\nnetworks.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1112.2793"}}, {"publisher": {"name": ""}, "description": "  We propose an analytic approach to the frequency bandwidth dimensioning\nproblem, faced by cellular network operators who deploy/upgrade their networks\nin various geographical regions (countries) with an inhomogeneous urbanization.\nWe present a model allowing one to capture fundamental relations between users'\nquality of service parameters (mean downlink throughput), traffic demand, the\ndensity of base station deployment, and the available frequency bandwidth.\nThese relations depend on the applied cellular technology (3G or 4G impacting\nuser peak bit-rate) and on the path-loss characteristics observed in different\n(urban, sub-urban and rural) areas. We observe that if the distance between\nbase stations is kept inversely proportional to the distance coefficient of the\npath-loss function, then the performance of the typical cells of these\ndifferent areas is similar when serving the same (per-cell) traffic demand. In\nthis case, the frequency bandwidth dimensioning problem can be solved uniformly\nacross the country applying the mean cell approach proposed in [Blaszczyszyn et\nal. WiOpt2014] http://dx.doi.org/10.1109/WIOPT.2014.6850355 . We validate our\napproach by comparing the analytical results to measurements in operational\nnetworks in various geographical zones of different countries.\n", "contributors": [{"name": "Blaszczyszyn, Bartlomiej", "sameAs": [], "familyName": "Blaszczyszyn", "additionalName": "", "givenName": "Bartlomiej", "email": ""}, {"name": "Karray, Mohamed Kadhem", "sameAs": [], "familyName": "Karray", "additionalName": "Kadhem", "givenName": "Mohamed", "email": ""}], "title": "What frequency bandwidth to run cellular network in a given country? - a\n  downlink dimensioning problem", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-30", "2015-03-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.0033", "oai:arXiv.org:1410.0033"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We propose an analytic approach to the frequency bandwidth dimensioning\nproblem, faced by cellular network operators who deploy/upgrade their networks\nin various geographical regions (countries) with an inhomogeneous urbanization.\nWe present a model allowing one to capture fundamental relations between users'\nquality of service parameters (mean downlink throughput), traffic demand, the\ndensity of base station deployment, and the available frequency bandwidth.\nThese relations depend on the applied cellular technology (3G or 4G impacting\nuser peak bit-rate) and on the path-loss characteristics observed in different\n(urban, sub-urban and rural) areas. We observe that if the distance between\nbase stations is kept inversely proportional to the distance coefficient of the\npath-loss function, then the performance of the typical cells of these\ndifferent areas is similar when serving the same (per-cell) traffic demand. In\nthis case, the frequency bandwidth dimensioning problem can be solved uniformly\nacross the country applying the mean cell approach proposed in [Blaszczyszyn et\nal. WiOpt2014] http://dx.doi.org/10.1109/WIOPT.2014.6850355 . We validate our\napproach by comparing the analytical results to measurements in operational\nnetworks in various geographical zones of different countries.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "mathematics - probability"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.0033"}}, {"publisher": {"name": ""}, "description": "  In this paper we propose two analytically tractable stochastic-geometric\nmodels of interference in ad-hoc networks using pure (non-slotted) Aloha as the\nmedium access. In contrast the slotted model, the interference in pure Aloha\nmay vary during the transmission of a tagged packet. We develop closed form\nexpressions for the Laplace transform of the empirical average of the\ninterference experienced during the transmission of a typical packet. Both\nmodels assume a power-law path-loss function with arbitrarily distributed\nfading and feature configurations of transmitters randomly located in the\nEuclidean plane according to a Poisson point process. Depending on the model,\nthese configurations vary over time or are static. We apply our analysis of the\ninterference to study the Signal-to-Interference-and-Noise Ratio (SINR) outage\nprobability for a typical transmission in pure Aloha. The results are used to\ncompare the performance of non-slotted Aloha to the slotted one, which has\nalmost exclusively been previously studied in the same context of mobile ad-hoc\nnetworks.\n", "contributors": [{"name": "Blaszczyszyn, Bartlomiej", "sameAs": [], "familyName": "Blaszczyszyn", "additionalName": "", "givenName": "Bartlomiej", "email": ""}, {"name": "Muhlethaler, Paul", "sameAs": [], "familyName": "Muhlethaler", "additionalName": "", "givenName": "Paul", "email": ""}], "title": "Interference and SINR coverage in spatial non-slotted Aloha networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3130", "oai:arXiv.org:1411.3130"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper we propose two analytically tractable stochastic-geometric\nmodels of interference in ad-hoc networks using pure (non-slotted) Aloha as the\nmedium access. In contrast the slotted model, the interference in pure Aloha\nmay vary during the transmission of a tagged packet. We develop closed form\nexpressions for the Laplace transform of the empirical average of the\ninterference experienced during the transmission of a typical packet. Both\nmodels assume a power-law path-loss function with arbitrarily distributed\nfading and feature configurations of transmitters randomly located in the\nEuclidean plane according to a Poisson point process. Depending on the model,\nthese configurations vary over time or are static. We apply our analysis of the\ninterference to study the Signal-to-Interference-and-Noise Ratio (SINR) outage\nprobability for a typical transmission in pure Aloha. The results are used to\ncompare the performance of non-slotted Aloha to the slotted one, which has\nalmost exclusively been previously studied in the same context of mobile ad-hoc\nnetworks.\n", "Comment: arXiv admin note: substantial text overlap with arXiv:1002.1629"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "mathematics - probability"], "providerUpdatedDateTime": "2014-11-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3130"}}, {"publisher": {"name": ""}, "description": "  By the nature of their construction, many statistical models for extremes\nresult in likelihood functions that are computationally prohibitive to\nevaluate. This is consequently problematic for the purposes of likelihood-based\ninference. With a focus on the Bayesian framework, this chapter examines the\nuse of approximate Bayesian computation (ABC) techniques for the fitting and\nanalysis of statistical models for extremes. After introducing the ideas behind\nABC algorithms and methods, we demonstrate their application to extremal models\nin stereology and spatial extremes.\n", "contributors": [{"name": "Erhardt, Robert", "sameAs": [], "familyName": "Erhardt", "additionalName": "", "givenName": "Robert", "email": ""}, {"name": "Sisson, Scott A.", "sameAs": [], "familyName": "Sisson", "additionalName": "A.", "givenName": "Scott", "email": ""}], "title": "Modelling extremes using approximate Bayesian Computation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1451", "oai:arXiv.org:1411.1451"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": ["  By the nature of their construction, many statistical models for extremes\nresult in likelihood functions that are computationally prohibitive to\nevaluate. This is consequently problematic for the purposes of likelihood-based\ninference. With a focus on the Bayesian framework, this chapter examines the\nuse of approximate Bayesian computation (ABC) techniques for the fitting and\nanalysis of statistical models for extremes. After introducing the ideas behind\nABC algorithms and methods, we demonstrate their application to extremal models\nin stereology and spatial extremes.\n", "Comment: To appear in Extreme Value Modelling and Risk Analysis: Methods and\n  Applications. Eds. D. Dey and J. Yan. Chapman & Hall/CRC Press"]}}], "languages": [null], "subjects": ["statistics - computation", "statistics - methodology"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1451"}}, {"publisher": {"name": ""}, "description": "  The interpolation step in the Guruswami-Sudan algorithm is a bivariate\ninterpolation problem with multiplicities commonly solved in the literature\nusing either structured linear algebra or basis reduction of polynomial\nlattices. This problem has been extended to three or more variables; for this\ngeneralization, all fast algorithms proposed so far rely on the lattice\napproach. In this paper, we reduce this multivariate interpolation problem to a\nproblem of simultaneous polynomial approximations, which we solve using fast\nstructured linear algebra. This improves the best known complexity bounds for\nthe interpolation step of the list-decoding of Reed-Solomon codes,\nParvaresh-Vardy codes, and folded Reed-Solomon codes. In particular, for\nReed-Solomon list-decoding with re-encoding, our approach has complexity\n$\\mathcal{O}\\tilde{~}(\\ell^{\\omega-1}m^2(n-k))$, where $\\ell,m,n,k$ are the\nlist size, the multiplicity, the number of sample points and the dimension of\nthe code, and $\\omega$ is the exponent of linear algebra; this accelerates the\npreviously fastest known algorithm by a factor of $\\ell / m$.\n", "contributors": [{"name": "Chowdhury, Muhammad F. I.", "sameAs": [], "familyName": "Chowdhury", "additionalName": "F. I.", "givenName": "Muhammad", "email": ""}, {"name": "Jeannerod, Claude-Pierre", "sameAs": [], "familyName": "Jeannerod", "additionalName": "", "givenName": "Claude-Pierre", "email": ""}, {"name": "Neiger, Vincent", "sameAs": [], "familyName": "Neiger", "additionalName": "", "givenName": "Vincent", "email": ""}, {"name": "Schost, Eric", "sameAs": [], "familyName": "Schost", "additionalName": "", "givenName": "Eric", "email": ""}, {"name": "Villard, Gilles", "sameAs": [], "familyName": "Villard", "additionalName": "", "givenName": "Gilles", "email": ""}], "title": "Faster Algorithms for Multivariate Interpolation with Multiplicities and\n  Simultaneous Polynomial Approximations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-04", "2015-02-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.0643", "oai:arXiv.org:1402.0643"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The interpolation step in the Guruswami-Sudan algorithm is a bivariate\ninterpolation problem with multiplicities commonly solved in the literature\nusing either structured linear algebra or basis reduction of polynomial\nlattices. This problem has been extended to three or more variables; for this\ngeneralization, all fast algorithms proposed so far rely on the lattice\napproach. In this paper, we reduce this multivariate interpolation problem to a\nproblem of simultaneous polynomial approximations, which we solve using fast\nstructured linear algebra. This improves the best known complexity bounds for\nthe interpolation step of the list-decoding of Reed-Solomon codes,\nParvaresh-Vardy codes, and folded Reed-Solomon codes. In particular, for\nReed-Solomon list-decoding with re-encoding, our approach has complexity\n$\\mathcal{O}\\tilde{~}(\\ell^{\\omega-1}m^2(n-k))$, where $\\ell,m,n,k$ are the\nlist size, the multiplicity, the number of sample points and the dimension of\nthe code, and $\\omega$ is the exponent of linear algebra; this accelerates the\npreviously fastest known algorithm by a factor of $\\ell / m$.\n", "Comment: Version 2: Generalized our results about Problem 1 to distinct\n  multiplicities. Added Section 4 which details several applications of our\n  results to the decoding of Reed-Solomon codes (list-decoding with re-encoding\n  technique, Wu algorithm, and soft-decoding). Reorganized the sections, added\n  references and corrected typos"]}}], "languages": [null], "subjects": ["computer science - information theory", "computer science - symbolic computation"], "providerUpdatedDateTime": "2015-02-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.0643"}}, {"publisher": {"name": ""}, "description": "  Stochastic Boolean Function Evaluation (SBFE) is the problem of determining\nthe value of a given Boolean function $f$ on an unknown input $x$, when each\nbit of $x_i$ of $x$ can only be determined by paying a given associated cost\n$c_i$. Further, $x$ is drawn from a given product distribution: for each $x_i$,\n$Prob[x_i=1] = p_i$, and the bits are independent. The goal is to minimize the\nexpected cost of evaluation. Stochastic Boolean Function Evaluation (SBFE) is\nthe problem of determining the value of a given Boolean function $f$ on an\nunknown input $x$, when each bit of $x_i$ of $x$ can only be determined by\npaying a given associated cost $c_i$. Further, $x$ is drawn from a given\nproduct distribution: for each $x_i$, $Prob[x_i=1] = p_i$, and the bits are\nindependent. The goal is to minimize the expected cost of evaluation. In this\npaper, we study the complexity of the SBFE problem for classes of DNF formulas.\nWe consider both exact and approximate versions of the problem for subclasses\nof DNF, for arbitrary costs and product distributions, and for unit costs\nand/or the uniform distribution.\n", "contributors": [{"name": "Allen, Sarah R.", "sameAs": [], "familyName": "Allen", "additionalName": "R.", "givenName": "Sarah", "email": ""}, {"name": "Hellerstein, Lisa", "sameAs": [], "familyName": "Hellerstein", "additionalName": "", "givenName": "Lisa", "email": ""}, {"name": "Kletenik, Devorah", "sameAs": [], "familyName": "Kletenik", "additionalName": "", "givenName": "Devorah", "email": ""}, {"name": "\u00dcnl\u00fcyurt, Tongu\u00e7", "sameAs": [], "familyName": "\u00dcnl\u00fcyurt", "additionalName": "", "givenName": "Tongu\u00e7", "email": ""}], "title": "Evaluation of DNF Formulas", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-14", "2014-10-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.3673", "oai:arXiv.org:1310.3673"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Stochastic Boolean Function Evaluation (SBFE) is the problem of determining\nthe value of a given Boolean function $f$ on an unknown input $x$, when each\nbit of $x_i$ of $x$ can only be determined by paying a given associated cost\n$c_i$. Further, $x$ is drawn from a given product distribution: for each $x_i$,\n$Prob[x_i=1] = p_i$, and the bits are independent. The goal is to minimize the\nexpected cost of evaluation. Stochastic Boolean Function Evaluation (SBFE) is\nthe problem of determining the value of a given Boolean function $f$ on an\nunknown input $x$, when each bit of $x_i$ of $x$ can only be determined by\npaying a given associated cost $c_i$. Further, $x$ is drawn from a given\nproduct distribution: for each $x_i$, $Prob[x_i=1] = p_i$, and the bits are\nindependent. The goal is to minimize the expected cost of evaluation. In this\npaper, we study the complexity of the SBFE problem for classes of DNF formulas.\nWe consider both exact and approximate versions of the problem for subclasses\nof DNF, for arbitrary costs and product distributions, and for unit costs\nand/or the uniform distribution.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.3673"}}, {"publisher": {"name": ""}, "description": "  In many practical applications of clustering, the objects to be clustered\nevolve over time, and a clustering result is desired at each time step. In such\napplications, evolutionary clustering typically outperforms traditional static\nclustering by producing clustering results that reflect long-term trends while\nbeing robust to short-term variations. Several evolutionary clustering\nalgorithms have recently been proposed, often by adding a temporal smoothness\npenalty to the cost function of a static clustering method. In this paper, we\nintroduce a different approach to evolutionary clustering by accurately\ntracking the time-varying proximities between objects followed by static\nclustering. We present an evolutionary clustering framework that adaptively\nestimates the optimal smoothing parameter using shrinkage estimation, a\nstatistical approach that improves a naive estimate using additional\ninformation. The proposed framework can be used to extend a variety of static\nclustering algorithms, including hierarchical, k-means, and spectral\nclustering, into evolutionary clustering algorithms. Experiments on synthetic\nand real data sets indicate that the proposed framework outperforms static\nclustering and existing evolutionary clustering algorithms in many scenarios.\n", "contributors": [{"name": "Xu, Kevin S.", "sameAs": [], "familyName": "Xu", "additionalName": "S.", "givenName": "Kevin", "email": ""}, {"name": "Kliger, Mark", "sameAs": [], "familyName": "Kliger", "additionalName": "", "givenName": "Mark", "email": ""}, {"name": "Hero III, Alfred O.", "sameAs": [], "familyName": "Hero", "additionalName": "O.", "givenName": "Alfred", "email": ""}], "title": "Adaptive Evolutionary Clustering", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-11", "2013-02-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.1990", "Data Mining and Knowledge Discovery 28 (2014) 304-336", "doi:10.1007/s10618-012-0302-x", "oai:arXiv.org:1104.1990"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  In many practical applications of clustering, the objects to be clustered\nevolve over time, and a clustering result is desired at each time step. In such\napplications, evolutionary clustering typically outperforms traditional static\nclustering by producing clustering results that reflect long-term trends while\nbeing robust to short-term variations. Several evolutionary clustering\nalgorithms have recently been proposed, often by adding a temporal smoothness\npenalty to the cost function of a static clustering method. In this paper, we\nintroduce a different approach to evolutionary clustering by accurately\ntracking the time-varying proximities between objects followed by static\nclustering. We present an evolutionary clustering framework that adaptively\nestimates the optimal smoothing parameter using shrinkage estimation, a\nstatistical approach that improves a naive estimate using additional\ninformation. The proposed framework can be used to extend a variety of static\nclustering algorithms, including hierarchical, k-means, and spectral\nclustering, into evolutionary clustering algorithms. Experiments on synthetic\nand real data sets indicate that the proposed framework outperforms static\nclustering and existing evolutionary clustering algorithms in many scenarios.\n", "Comment: To appear in Data Mining and Knowledge Discovery, MATLAB toolbox\n  available at http://tbayes.eecs.umich.edu/xukevin/affect"]}}], "languages": [null], "subjects": ["h.3.3", "g.3", "computer science - learning", "statistics - machine learning", "i.5.3"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.1990"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Patterns of alternation of hydrophobic and polar residues are a profound aspect of amino acid sequences, but a feature not easily interpreted for soluble proteins. Here we report statistics of hydrophobicity patterns in proteins of known structure in a current protein database as compared with results from earlier, more limited structure sets. Previous studies indicated that long hydrophobic runs, common in membrane proteins, are underrepresented in soluble proteins. Long runs of hydrophobic residues remain significantly underrepresented in soluble proteins, with none longer than 16 residues observed. These long runs most commonly occur as buried alpha helices, with extended hydrophobic strands less common. Avoiding aggregation of partially folded intermediates during intracellular folding remains a viable explanation for the rarity of long hydrophobic runs in soluble proteins. Comparison between database editions reveals robustness of statistics on aqueous proteins despite an approximately twofold increase in nonredundant sequences. The expanded database does now allow us to explain several deviations of hydrophobicity statistics from models of random sequence in terms of requirements of specific secondary structure elements. Comparison to prior membrane-bound protein sequences, however, shows significant qualitative changes, with the average hydrophobicity and frequency of long runs of hydrophobic residues noticeably increasing between the database editions. These results suggest that the aqueous proteins of solved structure may represent an essentially complete sample of the universe of aqueous sequences, while the membrane proteins of known structure are not yet representative of the universe of membrane-associated proteins, even by relatively simple measures of hydrophobic patterns.", "contributors": [{"name": "Schwartz, Russell S.", "sameAs": [], "familyName": "Schwartz", "additionalName": "S.", "givenName": "Russell", "email": ""}, {"name": "King, Jonathan", "sameAs": [], "familyName": "King", "additionalName": "", "givenName": "Jonathan", "email": ""}], "title": "Frequencies of hydrophobic and hydrophilic runs and alternations in proteins of known structure.", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2006-01-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/biology/434", "http://www.ncbi.nlm.nih.gov/pmc/articles/pmid/16373477/", "oai:repository.cmu.edu:biology-1456"]}}, {"name": "setSpec", "properties": {"setSpec": "publication:biology"}}, {"name": "description", "properties": {"description": "Patterns of alternation of hydrophobic and polar residues are a profound aspect of amino acid sequences, but a feature not easily interpreted for soluble proteins. Here we report statistics of hydrophobicity patterns in proteins of known structure in a current protein database as compared with results from earlier, more limited structure sets. Previous studies indicated that long hydrophobic runs, common in membrane proteins, are underrepresented in soluble proteins. Long runs of hydrophobic residues remain significantly underrepresented in soluble proteins, with none longer than 16 residues observed. These long runs most commonly occur as buried alpha helices, with extended hydrophobic strands less common. Avoiding aggregation of partially folded intermediates during intracellular folding remains a viable explanation for the rarity of long hydrophobic runs in soluble proteins. Comparison between database editions reveals robustness of statistics on aqueous proteins despite an approximately twofold increase in nonredundant sequences. The expanded database does now allow us to explain several deviations of hydrophobicity statistics from models of random sequence in terms of requirements of specific secondary structure elements. Comparison to prior membrane-bound protein sequences, however, shows significant qualitative changes, with the average hydrophobicity and frequency of long runs of hydrophobic residues noticeably increasing between the database editions. These results suggest that the aqueous proteins of solved structure may represent an essentially complete sample of the universe of aqueous sequences, while the membrane proteins of known structure are not yet representative of the universe of membrane-associated proteins, even by relatively simple measures of hydrophobic patterns."}}], "languages": [null], "subjects": ["biology", "protein structure", "computational biology", "models", "sequence analysis", "chemical", "structure-activity relationship", "hydrophobic and hydrophilic interactions", "statistical", "databases", "protein", "tertiary", "secondary"], "providerUpdatedDateTime": "2014-10-24T21:00:32", "uris": {"canonicalUri": "http://repository.cmu.edu/biology/434"}}, {"publisher": {"name": ""}, "description": "  The permanent vs. determinant problem is one of the most important problems\nin theoretical computer science, and is the main target of geometric complexity\ntheory proposed by Mulmuley and Sohoni. The current best lower bound for the\ndeterminantal complexity of the d by d permanent polynomial is d^2/2, due to\nMignon and Ressayre in 2004. Inspired by their proof method, we introduce a\nnatural rank concept of polynomials, called the bi-polynomial rank. The\nbi-polynomial rank is related to width of an arithmetic branching program. The\nbi-polynomial rank of a homogeneous polynomial p of even degree 2k is defined\nas the minimum n such that p can be written as a summation of n products of\npolynomials of degree k. We prove that the bi-polynomial rank gives a lower\nbound of the determinantal complexity. As a consequence, the above Mignon and\nRessayre bound is improved to (d-1)^2 + 1 over the field of reals. We show that\nthe computation of the bi-polynomial rank is formulated as a rank minimization\nproblem. Applying the concave minimization technique, we reduce the problem of\nlower-bounding determinantal complexity to that of proving the positive\nsemidefiniteness of matrices, and this is a new approach for the permanent vs.\ndeterminant problem. We propose a computational approach for giving a lower\nbound of this rank minimization, via techniques of the concave minimization.\nThis also yields a new strategy to attack the permanent vs. determinant\nproblem.\n", "contributors": [{"name": "Yabe, Akihiro", "sameAs": [], "familyName": "Yabe", "additionalName": "", "givenName": "Akihiro", "email": ""}], "title": "Bi-polynomial rank and determinantal complexity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.00151", "oai:arXiv.org:1504.00151"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The permanent vs. determinant problem is one of the most important problems\nin theoretical computer science, and is the main target of geometric complexity\ntheory proposed by Mulmuley and Sohoni. The current best lower bound for the\ndeterminantal complexity of the d by d permanent polynomial is d^2/2, due to\nMignon and Ressayre in 2004. Inspired by their proof method, we introduce a\nnatural rank concept of polynomials, called the bi-polynomial rank. The\nbi-polynomial rank is related to width of an arithmetic branching program. The\nbi-polynomial rank of a homogeneous polynomial p of even degree 2k is defined\nas the minimum n such that p can be written as a summation of n products of\npolynomials of degree k. We prove that the bi-polynomial rank gives a lower\nbound of the determinantal complexity. As a consequence, the above Mignon and\nRessayre bound is improved to (d-1)^2 + 1 over the field of reals. We show that\nthe computation of the bi-polynomial rank is formulated as a rank minimization\nproblem. Applying the concave minimization technique, we reduce the problem of\nlower-bounding determinantal complexity to that of proving the positive\nsemidefiniteness of matrices, and this is a new approach for the permanent vs.\ndeterminant problem. We propose a computational approach for giving a lower\nbound of this rank minimization, via techniques of the concave minimization.\nThis also yields a new strategy to attack the permanent vs. determinant\nproblem.\n", "Comment: 20 pages"]}}], "languages": [null], "subjects": ["computer science - computational complexity"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.00151"}}, {"publisher": {"name": ""}, "description": "  We study Doob's martingale convergence theorem for computable continuous time\nmartingales on Brownian motion, in the context of algorithmic randomness. A\ncharacterization of the class of sample points for which the theorem holds is\ngiven. Such points are given the name of Doob random points. It is shown that a\npoint is Doob random if its tail is computably random in a certain sense.\nMoreover, Doob randomness is strictly weaker than computable randomness and is\nincomparable with Schnorr randomness.\n", "contributors": [{"name": "Kjos-Hanssen, Bj\u00f8rn", "sameAs": [], "familyName": "Kjos-Hanssen", "additionalName": "", "givenName": "Bj\u00f8rn", "email": ""}, {"name": "Nguyen, Paul Kim Long V.", "sameAs": [], "familyName": "Nguyen", "additionalName": "Kim Long V.", "givenName": "Paul", "email": ""}, {"name": "Rute, Jason", "sameAs": [], "familyName": "Rute", "additionalName": "", "givenName": "Jason", "email": ""}], "title": "Algorithmic randomness for Doob's martingale convergence theorem in\n  continuous time", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-01", "2014-12-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0186", "LMCS 10 (4:12) 2014", "doi:10.2168/LMCS-10(4:12)2014", "oai:arXiv.org:1411.0186"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We study Doob's martingale convergence theorem for computable continuous time\nmartingales on Brownian motion, in the context of algorithmic randomness. A\ncharacterization of the class of sample points for which the theorem holds is\ngiven. Such points are given the name of Doob random points. It is shown that a\npoint is Doob random if its tail is computably random in a certain sense.\nMoreover, Doob randomness is strictly weaker than computable randomness and is\nincomparable with Schnorr randomness.\n"}}], "languages": [null], "subjects": ["mathematics - logic", "computer science - logic in computer science", "mathematics - probability"], "providerUpdatedDateTime": "2014-12-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0186"}}, {"publisher": {"name": ""}, "description": "  The application of Compressive sensing approach to the speech and musical\nsignals is considered in this paper. Compressive sensing (CS) is a new approach\nto the signal sampling that allows signal reconstruction from a small set of\nrandomly acquired samples. This method is developed for the signals that\nexhibit the sparsity in a certain domain. Here we have observed two sparsity\ndomains: discrete Fourier and discrete cosine transform domain. Furthermore,\ntwo different types of audio signals are analyzed in terms of sparsity and CS\nperformance - musical and speech signals. Comparative analysis of the CS\nreconstruction using different number of signal samples is performed in the two\ndomains of sparsity. It is shown that the CS can be successfully applied to\nboth, musical and speech signals, but the speech signals are more demanding in\nterms of the number of observations. Also, our results show that discrete\ncosine transform domain allows better reconstruction using lower number of\nobservations, compared to the Fourier transform domain, for both types of\nsignals.\n", "contributors": [{"name": "Savic, Trifun", "sameAs": [], "familyName": "Savic", "additionalName": "", "givenName": "Trifun", "email": ""}, {"name": "Albijanic, Radoje", "sameAs": [], "familyName": "Albijanic", "additionalName": "", "givenName": "Radoje", "email": ""}], "title": "CS reconstruction of the speech and musical signals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01707", "oai:arXiv.org:1502.01707"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The application of Compressive sensing approach to the speech and musical\nsignals is considered in this paper. Compressive sensing (CS) is a new approach\nto the signal sampling that allows signal reconstruction from a small set of\nrandomly acquired samples. This method is developed for the signals that\nexhibit the sparsity in a certain domain. Here we have observed two sparsity\ndomains: discrete Fourier and discrete cosine transform domain. Furthermore,\ntwo different types of audio signals are analyzed in terms of sparsity and CS\nperformance - musical and speech signals. Comparative analysis of the CS\nreconstruction using different number of signal samples is performed in the two\ndomains of sparsity. It is shown that the CS can be successfully applied to\nboth, musical and speech signals, but the speech signals are more demanding in\nterms of the number of observations. Also, our results show that discrete\ncosine transform domain allows better reconstruction using lower number of\nobservations, compared to the Fourier transform domain, for both types of\nsignals.\n"}}], "languages": [null], "subjects": ["computer science - multimedia", "computer science - sound"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01707"}}, {"publisher": {"name": ""}, "description": "  We describe a password generation scheme based on Markov models built from\nEnglish text (specifically, Charles Dickens' *A Tale Of Two Cities*). We show a\n(linear-running-time) bijection between random bitstrings of any desired length\nand generated text, ensuring that all passwords are generated with equal\nprobability. We observe that the generated passwords appear to strike a\nreasonable balance between memorability and security. Using the system, we get\n56-bit passwords like 'The cusay is wither?\" t', rather than passwords like\n'tQ$%Xc4Ef'.\n", "contributors": [{"name": "Clements, John", "sameAs": [], "familyName": "Clements", "additionalName": "", "givenName": "John", "email": ""}], "title": "Generating 56-bit passwords using Markov Models (and Charles Dickens)", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07786", "oai:arXiv.org:1502.07786"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We describe a password generation scheme based on Markov models built from\nEnglish text (specifically, Charles Dickens' *A Tale Of Two Cities*). We show a\n(linear-running-time) bijection between random bitstrings of any desired length\nand generated text, ensuring that all passwords are generated with equal\nprobability. We observe that the generated passwords appear to strike a\nreasonable balance between memorability and security. Using the system, we get\n56-bit passwords like 'The cusay is wither?\" t', rather than passwords like\n'tQ$%Xc4Ef'.\n", "Comment: 5 pages, 2 figures"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "k.6.5", "h.1.2", "e.4", "i.2.7", "k.4.2", "d.4.6"], "providerUpdatedDateTime": "2015-03-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07786"}}, {"publisher": {"name": ""}, "description": "  Dictionary learning algorithms have been successfully used in both\nreconstructive and discriminative tasks, where the input signal is represented\nby a linear combination of a few dictionary atoms. While these methods are\nusually developed under $\\ell_1$ sparsity constrain (prior) in the input\ndomain, recent studies have demonstrated the advantages of sparse\nrepresentation using structured sparsity priors in the kernel domain. In this\npaper, we propose a supervised dictionary learning algorithm in the kernel\ndomain for hyperspectral image classification. In the proposed formulation, the\ndictionary and classifier are obtained jointly for optimal classification\nperformance. The supervised formulation is task-driven and provides learned\nfeatures from the hyperspectral data that are well suited for the\nclassification task. Moreover, the proposed algorithm uses a joint\n($\\ell_{12}$) sparsity prior to enforce collaboration among the neighboring\npixels. The simulation results illustrate the efficiency of the proposed\ndictionary learning algorithm.\n", "contributors": [{"name": "Bahrampour, Soheil", "sameAs": [], "familyName": "Bahrampour", "additionalName": "", "givenName": "Soheil", "email": ""}, {"name": "Nasrabadi, Nasser M.", "sameAs": [], "familyName": "Nasrabadi", "additionalName": "M.", "givenName": "Nasser", "email": ""}, {"name": "Ray, Asok", "sameAs": [], "familyName": "Ray", "additionalName": "", "givenName": "Asok", "email": ""}, {"name": "Jenkins, Kenneth W.", "sameAs": [], "familyName": "Jenkins", "additionalName": "W.", "givenName": "Kenneth", "email": ""}], "title": "Kernel Task-Driven Dictionary Learning for Hyperspectral Image\n  Classification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03126", "oai:arXiv.org:1502.03126"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Dictionary learning algorithms have been successfully used in both\nreconstructive and discriminative tasks, where the input signal is represented\nby a linear combination of a few dictionary atoms. While these methods are\nusually developed under $\\ell_1$ sparsity constrain (prior) in the input\ndomain, recent studies have demonstrated the advantages of sparse\nrepresentation using structured sparsity priors in the kernel domain. In this\npaper, we propose a supervised dictionary learning algorithm in the kernel\ndomain for hyperspectral image classification. In the proposed formulation, the\ndictionary and classifier are obtained jointly for optimal classification\nperformance. The supervised formulation is task-driven and provides learned\nfeatures from the hyperspectral data that are well suited for the\nclassification task. Moreover, the proposed algorithm uses a joint\n($\\ell_{12}$) sparsity prior to enforce collaboration among the neighboring\npixels. The simulation results illustrate the efficiency of the proposed\ndictionary learning algorithm.\n", "Comment: 5 pages, IEEE International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), 2015"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03126"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "In recent years, online retailers (e-tailers) have started allowing manufacturers direct access to their customers while charging a fee for providing this access, a format commonly referred to as agency selling. In this paper, we use a stylized theoretical model to answer a key question that e-tailers are facing: When should they use an agency selling format instead of using the more conventional reselling format? We find that agency selling is more effecient than reselling and leads to lower retail prices; however, the e-tailers end up giving control over retail prices to the manufacturer. Therefore, the reaction by the manufacturer, who makes electronic channel pricing decisions based on their impact on demand in the traditional channel (brick-and-mortar retailing), is an important factor for e-tailers to consider. We find that when sales in the electronic channel lead to a negative effect on demand in the traditional channel, e-tailers prefer agency selling, whereas when sales in the electronic channel lead to substantial stimulation of demand in the traditional channel, e-tailers prefer reselling. This preference is mediated by competition between e-tailers \u2014 as competition between them increases, e-tailers prefer to use agency selling. We also find that when e-tailers benefit from positive externalities from the sales of the focal product (such as additional profits from sales of complementary products), retail prices may be lower under reselling than under agency selling, and the e-tailers prefer reselling under some conditions where they would prefer agency selling without the positive externalities.", "contributors": [{"name": "Abhishek, Vibhanshu", "sameAs": [], "familyName": "Abhishek", "additionalName": "", "givenName": "Vibhanshu", "email": ""}, {"name": "Jerath, Kinshuk", "sameAs": [], "familyName": "Jerath", "additionalName": "", "givenName": "Kinshuk", "email": ""}, {"name": "Zhang, Z. John", "sameAs": [], "familyName": "Zhang", "additionalName": "John", "givenName": "Z.", "email": ""}], "title": "Agency Selling or Reselling? Channel Structures in Electronic Retailing", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2015-01-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/heinzworks/387", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1398&amp;context=heinzworks", "oai:repository.cmu.edu:heinzworks-1398"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:heinz", "publication:heinzworks"]}}, {"name": "description", "properties": {"description": "In recent years, online retailers (e-tailers) have started allowing manufacturers direct access to their customers while charging a fee for providing this access, a format commonly referred to as agency selling. In this paper, we use a stylized theoretical model to answer a key question that e-tailers are facing: When should they use an agency selling format instead of using the more conventional reselling format? We find that agency selling is more effecient than reselling and leads to lower retail prices; however, the e-tailers end up giving control over retail prices to the manufacturer. Therefore, the reaction by the manufacturer, who makes electronic channel pricing decisions based on their impact on demand in the traditional channel (brick-and-mortar retailing), is an important factor for e-tailers to consider. We find that when sales in the electronic channel lead to a negative effect on demand in the traditional channel, e-tailers prefer agency selling, whereas when sales in the electronic channel lead to substantial stimulation of demand in the traditional channel, e-tailers prefer reselling. This preference is mediated by competition between e-tailers \u2014 as competition between them increases, e-tailers prefer to use agency selling. We also find that when e-tailers benefit from positive externalities from the sales of the focal product (such as additional profits from sales of complementary products), retail prices may be lower under reselling than under agency selling, and the e-tailers prefer reselling under some conditions where they would prefer agency selling without the positive externalities."}}], "languages": [null], "subjects": ["cross-channel spillovers", "agency model", "electronic commerce", "multi-channel retailing", "retail competition", "databases and information systems", "public policy", "game theory", "distribution channel"], "providerUpdatedDateTime": "2015-05-01T20:35:19", "uris": {"canonicalUri": "http://repository.cmu.edu/heinzworks/387"}}, {"publisher": {"name": ""}, "description": "  The structures for the expression of fault-tolerance provisions into the\napplication software are the central topic of this paper. Structuring\ntechniques answer the questions \"How to incorporate fault-tolerance in the\napplication layer of a computer program\" and \"How to manage the fault-tolerant\ncode\". As such, they provide means to control complexity, the latter being a\nrelevant factor for the introduction of design faults. This fact and the ever\nincreasing complexity of today's distributed software justify the need for\nsimple, coherent, and effective structures for the expression of\nfault-tolerance in the application software. In this text we first define a\n\"base\" of structural attributes with which application-level fault-tolerance\nstructures can be qualitatively assessed and compared with each other and with\nrespect to the above mentioned needs. This result is then used to provide an\nelaborated survey of the state-of-the-art of application-level fault-tolerance\nstructures.\n", "contributors": [{"name": "De Florio, Vincenzo", "sameAs": [], "familyName": "De Florio", "additionalName": "", "givenName": "Vincenzo", "email": ""}, {"name": "Blondia, Chris", "sameAs": [], "familyName": "Blondia", "additionalName": "", "givenName": "Chris", "email": ""}], "title": "A Survey of Linguistic Structures for Application-level Fault-Tolerance", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03256", "oai:arXiv.org:1504.03256"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The structures for the expression of fault-tolerance provisions into the\napplication software are the central topic of this paper. Structuring\ntechniques answer the questions \"How to incorporate fault-tolerance in the\napplication layer of a computer program\" and \"How to manage the fault-tolerant\ncode\". As such, they provide means to control complexity, the latter being a\nrelevant factor for the introduction of design faults. This fact and the ever\nincreasing complexity of today's distributed software justify the need for\nsimple, coherent, and effective structures for the expression of\nfault-tolerance in the application software. In this text we first define a\n\"base\" of structural attributes with which application-level fault-tolerance\nstructures can be qualitatively assessed and compared with each other and with\nrespect to the above mentioned needs. This result is then used to provide an\nelaborated survey of the state-of-the-art of application-level fault-tolerance\nstructures.\n", "Comment: Paper appeared in ACM Computing Surveys, Vol. 40, No. 2 (April 2008)"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03256"}}, {"publisher": {"name": "DigitalCommons@CalPoly"}, "description": "The goal of this project was to design and implement a graphical user interface which simulates TriTech's VisiCad Inform computer- aided dispatch well enough for trainees to learn how to efficiently and accurately use the software in a risk-free environment. The simulator should also allow the training proctor to actively create new incidents during training in order to ensure that the trainees are able to respond properly. The structure of this project allowed me to work with both more- and less-experienced programmers, particularly those who are far more experienced with networking and hardware than myself. It was my first time taking a lead role in development, as well as my first time developing a large-scale GUI. The interface involve fifteen panels that can be accessed using hotkeys or a Photoshop-like toolbar and contain a variety of different information - traffic collision reports, physical descriptions for persons of interest, emergency vehicle maintenance reports and data, and more.", "contributors": [{"name": "Heater, Stuart", "sameAs": [], "familyName": "Heater", "additionalName": "", "givenName": "Stuart", "email": ""}], "title": "TMC Simulator", "shareProperties": {"source": "calpoly"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "source", "properties": {"source": "Computer Science"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2013-06-01T07:00:00Z"}}, {"name": "setSpec", "properties": {"setSpec": ["publication:students", "publication:cscsp", "publication:seniorprojects"]}}], "languages": [null], "subjects": ["caltrans", "computer-aided dispatch", "california highway patrol", "digital communications and networking", "training simulator", "data storage systems"], "providerUpdatedDateTime": "2015-04-15T23:27:03", "uris": {"canonicalUri": "http://digitalcommons.calpoly.edu/cscsp/44"}}, {"publisher": {"name": ""}, "description": "  We give a new algorithmic solution to the well-known five-point relative pose\nproblem. Our approach does not deal with the famous cubic constraint on an\nessential matrix. Instead, we use the Cayley representation of rotations in\norder to obtain a polynomial system from epipolar constraints. Solving that\nsystem, we directly get relative rotation and translation parameters of the\ncameras in terms of roots of a 10th degree polynomial.\n", "contributors": [{"name": "Martyushev, Evgeniy", "sameAs": [], "familyName": "Martyushev", "additionalName": "", "givenName": "Evgeniy", "email": ""}], "title": "An Algorithmic Solution to the Five-Point Pose Problem Based on the\n  Cayley Representation of Rotations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-05-19", "2013-02-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.3828", "oai:arXiv.org:1105.3828"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We give a new algorithmic solution to the well-known five-point relative pose\nproblem. Our approach does not deal with the famous cubic constraint on an\nessential matrix. Instead, we use the Cayley representation of rotations in\norder to obtain a polynomial system from epipolar constraints. Solving that\nsystem, we directly get relative rotation and translation parameters of the\ncameras in terms of roots of a 10th degree polynomial.\n", "Comment: 9 pages, 5 figures"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.3828"}}, {"publisher": {"name": ""}, "description": "  In this paper, by characterizing the Leg Agility (LA) task, which contributes\nto the evaluation of the degree of severity of the Parkinson's Disease (PD),\nthrough kinematic variables (including the angular amplitude and speed of\nthighs' motion), we investigate the link between these variables and Unified\nParkinson's Disease Rating Scale (UPDRS) scores. Our investigation relies on\nthe use of a few body-worn wireless inertial nodes and represents a first step\nin the design of a portable system, amenable to be integrated in Internet of\nThings (IoT) scenarios, for automatic detection of the degree of severity (in\nterms of UPDRS score) of PD. The experimental investigation is carried out\nconsidering 24 PD patients.\n", "contributors": [{"name": "Giuberti, Matteo", "sameAs": [], "familyName": "Giuberti", "additionalName": "", "givenName": "Matteo", "email": ""}, {"name": "Ferrari, Gianluigi", "sameAs": [], "familyName": "Ferrari", "additionalName": "", "givenName": "Gianluigi", "email": ""}, {"name": "Contin, Laura", "sameAs": [], "familyName": "Contin", "additionalName": "", "givenName": "Laura", "email": ""}, {"name": "Cimolin, Veronica", "sameAs": [], "familyName": "Cimolin", "additionalName": "", "givenName": "Veronica", "email": ""}, {"name": "Azzaro, Corrado", "sameAs": [], "familyName": "Azzaro", "additionalName": "", "givenName": "Corrado", "email": ""}, {"name": "Albani, Giovanni", "sameAs": [], "familyName": "Albani", "additionalName": "", "givenName": "Giovanni", "email": ""}, {"name": "Mauro, Alessandro", "sameAs": [], "familyName": "Mauro", "additionalName": "", "givenName": "Alessandro", "email": ""}], "title": "Assigning UPDRS Scores in the Leg Agility Task of Parkinsonians: Can It\n  Be Done through BSN-based Kinematic Variables?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04100", "oai:arXiv.org:1502.04100"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, by characterizing the Leg Agility (LA) task, which contributes\nto the evaluation of the degree of severity of the Parkinson's Disease (PD),\nthrough kinematic variables (including the angular amplitude and speed of\nthighs' motion), we investigate the link between these variables and Unified\nParkinson's Disease Rating Scale (UPDRS) scores. Our investigation relies on\nthe use of a few body-worn wireless inertial nodes and represents a first step\nin the design of a portable system, amenable to be integrated in Internet of\nThings (IoT) scenarios, for automatic detection of the degree of severity (in\nterms of UPDRS score) of PD. The experimental investigation is carried out\nconsidering 24 PD patients.\n", "Comment: 10 pages"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-02-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04100"}}, {"publisher": {"name": ""}, "description": "  Several expressions for the $j$-th component $\\left( x_{k}\\right) _{j}$ of\nthe $k$-th eigenvector $x_{k}$ of a symmetric matrix $A$ belonging to\neigenvalue $\\lambda_{k}$ and normalized as $x_{k}^{T}x_{k}=1$ are presented. In\nparticular, the new expression \\[ \\left( x_{k}\\right)\n_{j}^{2}=-\\frac{1}{c_{A}^{\\prime}\\left( \\lambda _{k}\\right) }\\det\\left(\nA_{\\backslash\\left\\{ j\\right\\} }-\\lambda _{k}I\\right) \\] where $c_{A}\\left(\n\\lambda\\right) =\\det\\left( A-\\lambda I\\right) $ is the characteristic\npolynomial of $A$, $c_{A}^{\\prime}\\left( \\lambda\\right) =\\frac{dc_{A}\\left(\n\\lambda\\right) }{d\\lambda}$ and $A_{\\backslash\\left\\{ j\\right\\} }$ is obtained\nfrom $A$ by removal of row $j$ and column $j$, suggests us to consider the\nsquare eigenvector component as a graph centrality metric for node $j$ that\nreflects the impact of the removal of node $j$ from the graph at an\neigenfrequency/eigenvalue $\\lambda_{k}$ of a graph related matrix (such as the\nadjacency or Laplacian matrix). Removal of nodes in a graph relates to the\nrobustness of a graph. The set of such nodal centrality metrics is\n\\textquotedblleft ideal\\textquotedblright\\ in the sense of being complete,\nuncorrelated and mathematically precisely defined and computable. Fundamental\nweights and dual fundamental weights are introduced as spectral metrics with an\nalmost similar importance as eigenvalues.\n", "contributors": [{"name": "Van Mieghem, Piet", "sameAs": [], "familyName": "Van Mieghem", "additionalName": "", "givenName": "Piet", "email": ""}], "title": "Graph eigenvectors, fundamental weights and centrality metrics for nodes\n  in networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-01-18", "2014-12-12"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1401.4580", "oai:arXiv.org:1401.4580"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Several expressions for the $j$-th component $\\left( x_{k}\\right) _{j}$ of\nthe $k$-th eigenvector $x_{k}$ of a symmetric matrix $A$ belonging to\neigenvalue $\\lambda_{k}$ and normalized as $x_{k}^{T}x_{k}=1$ are presented. In\nparticular, the new expression \\[ \\left( x_{k}\\right)\n_{j}^{2}=-\\frac{1}{c_{A}^{\\prime}\\left( \\lambda _{k}\\right) }\\det\\left(\nA_{\\backslash\\left\\{ j\\right\\} }-\\lambda _{k}I\\right) \\] where $c_{A}\\left(\n\\lambda\\right) =\\det\\left( A-\\lambda I\\right) $ is the characteristic\npolynomial of $A$, $c_{A}^{\\prime}\\left( \\lambda\\right) =\\frac{dc_{A}\\left(\n\\lambda\\right) }{d\\lambda}$ and $A_{\\backslash\\left\\{ j\\right\\} }$ is obtained\nfrom $A$ by removal of row $j$ and column $j$, suggests us to consider the\nsquare eigenvector component as a graph centrality metric for node $j$ that\nreflects the impact of the removal of node $j$ from the graph at an\neigenfrequency/eigenvalue $\\lambda_{k}$ of a graph related matrix (such as the\nadjacency or Laplacian matrix). Removal of nodes in a graph relates to the\nrobustness of a graph. The set of such nodal centrality metrics is\n\\textquotedblleft ideal\\textquotedblright\\ in the sense of being complete,\nuncorrelated and mathematically precisely defined and computable. Fundamental\nweights and dual fundamental weights are introduced as spectral metrics with an\nalmost similar importance as eigenvalues.\n", "Comment: Besides the addition of new results, we have changed the style of the\n  previous version: from provocative to more scientific"]}}], "languages": [null], "subjects": ["physics - physics and society", "condensed matter - statistical mechanics", "computer science - discrete mathematics", "mathematics - spectral theory", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-12-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1401.4580"}}, {"publisher": {"name": ""}, "description": "  The second law of thermodynamics tells us which state transformations are so\nstatistically unlikely that they are effectively forbidden. Its original\nformulation, due to Clausius, states that \"Heat can never pass from a colder to\na warmer body without some other change, connected therewith, occurring at the\nsame time\". The second law applies to systems composed of many particles\ninteracting; however, we are seeing that one can make sense of thermodynamics\nin the regime where we only have a small number of particles interacting with a\nheat bath. Is there a second law of thermodynamics in this regime? Here, we\nfind that for processes which are cyclic or very close to cyclic, the second\nlaw for microscopic systems takes on a very di?erent form than it does at the\nmacroscopic scale, imposing not just one constraint on what state\ntransformations are possible, but an entire family of constraints. In\nparticular, we find a family of free energies which generalise the traditional\none, and show that they can never increase. We further find that there are\nthree regimes which determine which family of second laws govern state\ntransitions, depending on how cyclic the process is. In one regime one can\ncause an apparent violation of the usual second law, through a process of\nembezzling work from a large system which remains arbitrarily close to its\noriginal state. These second laws are not only relevant for small systems, but\nalso apply to individual macroscopic systems interacting via long-range\ninteractions, which only satisfy the ordinary second law on average. By making\nprecise the definition of thermal operations, the laws of thermodynamics take\non a simple form with the first law defining the class of thermal operations,\nthe zeroeth law emerging as a unique condition ensuring the theory is\nnontrivial, and the remaining laws being a monotonicity property of our\ngeneralised free energies.\n", "contributors": [{"name": "Brandao, Fernando G. S. L.", "sameAs": [], "familyName": "Brandao", "additionalName": "G. S. L.", "givenName": "Fernando", "email": ""}, {"name": "Horodecki, Micha\u0142", "sameAs": [], "familyName": "Horodecki", "additionalName": "", "givenName": "Micha\u0142", "email": ""}, {"name": "Ng, Nelly Huei Ying", "sameAs": [], "familyName": "Ng", "additionalName": "Huei Ying", "givenName": "Nelly", "email": ""}, {"name": "Oppenheim, Jonathan", "sameAs": [], "familyName": "Oppenheim", "additionalName": "", "givenName": "Jonathan", "email": ""}, {"name": "Wehner, Stephanie", "sameAs": [], "familyName": "Wehner", "additionalName": "", "givenName": "Stephanie", "email": ""}], "title": "The second laws of quantum thermodynamics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-05-22", "2014-09-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1305.5278", "PNAS 112, 3275 (2015)", "doi:10.1073/pnas.1411728112", "oai:arXiv.org:1305.5278"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:cond-mat", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": ["  The second law of thermodynamics tells us which state transformations are so\nstatistically unlikely that they are effectively forbidden. Its original\nformulation, due to Clausius, states that \"Heat can never pass from a colder to\na warmer body without some other change, connected therewith, occurring at the\nsame time\". The second law applies to systems composed of many particles\ninteracting; however, we are seeing that one can make sense of thermodynamics\nin the regime where we only have a small number of particles interacting with a\nheat bath. Is there a second law of thermodynamics in this regime? Here, we\nfind that for processes which are cyclic or very close to cyclic, the second\nlaw for microscopic systems takes on a very di?erent form than it does at the\nmacroscopic scale, imposing not just one constraint on what state\ntransformations are possible, but an entire family of constraints. In\nparticular, we find a family of free energies which generalise the traditional\none, and show that they can never increase. We further find that there are\nthree regimes which determine which family of second laws govern state\ntransitions, depending on how cyclic the process is. In one regime one can\ncause an apparent violation of the usual second law, through a process of\nembezzling work from a large system which remains arbitrarily close to its\noriginal state. These second laws are not only relevant for small systems, but\nalso apply to individual macroscopic systems interacting via long-range\ninteractions, which only satisfy the ordinary second law on average. By making\nprecise the definition of thermal operations, the laws of thermodynamics take\non a simple form with the first law defining the class of thermal operations,\nthe zeroeth law emerging as a unique condition ensuring the theory is\nnontrivial, and the remaining laws being a monotonicity property of our\ngeneralised free energies.\n", "Comment: v3: 39 pages, 2 figures. Substantial expansion of the previous text,\n  conditions in terms of generalised alpha free energies, addition on\n  discussion about the role of zeroeth and first laws of thermodynamics,\n  addition of two new figures"]}}], "languages": [null], "subjects": ["quantum physics", "computer science - information theory", "condensed matter - statistical mechanics"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1305.5278"}}, {"publisher": {"name": ""}, "description": "  Given a set $F$ of $n$ positive functions over a ground set $X$, we consider\nthe problem of computing $x^*$ that minimizes the expression $\\sum_{f\\in\nF}f(x)$, over $x\\in X$. A typical application is \\emph{shape fitting}, where we\nwish to approximate a set $P$ of $n$ elements (say, points) by a shape $x$ from\na (possibly infinite) family $X$ of shapes. Here, each point $p\\in P$\ncorresponds to a function $f$ such that $f(x)$ is the distance from $p$ to $x$,\nand we seek a shape $x$ that minimizes the sum of distances from each point in\n$P$. In the $k$-clustering variant, each $x\\in X$ is a tuple of $k$ shapes, and\n$f(x)$ is the distance from $p$ to its closest shape in $x$.\n  Our main result is a unified framework for constructing {\\em coresets} and\n{\\em approximate clustering} for such general sets of functions. To achieve our\nresults, we forge a link between the classic and well defined notion of\n$\\varepsilon$-approximations from the theory of PAC Learning and VC dimension,\nto the relatively new (and not so consistent) paradigm of coresets, which are\nsome kind of \"compressed representation\" of the input set $F$. Using\ntraditional techniques, a coreset usually implies an LTAS (linear time\napproximation scheme) for the corresponding optimization problem, which can be\ncomputed in parallel, via one pass over the data, and using only\npolylogarithmic space (i.e, in the streaming model).\n  We show how to generalize the results of our framework for squared distances\n(as in $k$-mean), distances to the $q$th power, and deterministic\nconstructions.\n", "contributors": [{"name": "Feldman, Dan", "sameAs": [], "familyName": "Feldman", "additionalName": "", "givenName": "Dan", "email": ""}, {"name": "Langberg, Michael", "sameAs": [], "familyName": "Langberg", "additionalName": "", "givenName": "Michael", "email": ""}], "title": "A Unified Framework for Approximating and Clustering Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-06-07", "2014-10-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1106.1379", "oai:arXiv.org:1106.1379"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Given a set $F$ of $n$ positive functions over a ground set $X$, we consider\nthe problem of computing $x^*$ that minimizes the expression $\\sum_{f\\in\nF}f(x)$, over $x\\in X$. A typical application is \\emph{shape fitting}, where we\nwish to approximate a set $P$ of $n$ elements (say, points) by a shape $x$ from\na (possibly infinite) family $X$ of shapes. Here, each point $p\\in P$\ncorresponds to a function $f$ such that $f(x)$ is the distance from $p$ to $x$,\nand we seek a shape $x$ that minimizes the sum of distances from each point in\n$P$. In the $k$-clustering variant, each $x\\in X$ is a tuple of $k$ shapes, and\n$f(x)$ is the distance from $p$ to its closest shape in $x$.\n  Our main result is a unified framework for constructing {\\em coresets} and\n{\\em approximate clustering} for such general sets of functions. To achieve our\nresults, we forge a link between the classic and well defined notion of\n$\\varepsilon$-approximations from the theory of PAC Learning and VC dimension,\nto the relatively new (and not so consistent) paradigm of coresets, which are\nsome kind of \"compressed representation\" of the input set $F$. Using\ntraditional techniques, a coreset usually implies an LTAS (linear time\napproximation scheme) for the corresponding optimization problem, which can be\ncomputed in parallel, via one pass over the data, and using only\npolylogarithmic space (i.e, in the streaming model).\n  We show how to generalize the results of our framework for squared distances\n(as in $k$-mean), distances to the $q$th power, and deterministic\nconstructions.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1106.1379"}}, {"publisher": {"name": ""}, "description": "  We present an efficient decoding algorithm for constant rate quantum\nhypergraph-product LDPC codes which provably corrects adversarial errors of\nweight $\\Omega(\\sqrt{n})$ for codes of length $n$. The algorithm runs in time\nlinear in the number of qubits, which makes its performance the strongest to\ndate for linear-time decoding of quantum codes. The algorithm relies on\nexpanding properties, not of the quantum code's factor graph directly, but of\nthe factor graph of the original classical code it is constructed from.\n", "contributors": [{"name": "Leverrier, Anthony", "sameAs": [], "familyName": "Leverrier", "additionalName": "", "givenName": "Anthony", "email": ""}, {"name": "Tillich, Jean-Pierre", "sameAs": [], "familyName": "Tillich", "additionalName": "", "givenName": "Jean-Pierre", "email": ""}, {"name": "Z\u00e9mor, Gilles", "sameAs": [], "familyName": "Z\u00e9mor", "additionalName": "", "givenName": "Gilles", "email": ""}], "title": "Quantum Expander Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.00822", "oai:arXiv.org:1504.00822"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": "  We present an efficient decoding algorithm for constant rate quantum\nhypergraph-product LDPC codes which provably corrects adversarial errors of\nweight $\\Omega(\\sqrt{n})$ for codes of length $n$. The algorithm runs in time\nlinear in the number of qubits, which makes its performance the strongest to\ndate for linear-time decoding of quantum codes. The algorithm relies on\nexpanding properties, not of the quantum code's factor graph directly, but of\nthe factor graph of the original classical code it is constructed from.\n"}}], "languages": [null], "subjects": ["quantum physics", "computer science - information theory"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.00822"}}, {"publisher": {"name": ""}, "description": "  The problem of designing physical-layer network coding (PNC) schemes via\nnested lattices is considered. Building on the compute-and-forward (C&F)\nrelaying strategy of Nazer and Gastpar, who demonstrated its asymptotic gain\nusing information-theoretic tools, an algebraic approach is taken to show its\npotential in practical, non-asymptotic, settings. A general framework is\ndeveloped for studying nested-lattice-based PNC schemes---called lattice\nnetwork coding (LNC) schemes for short---by making a direct connection between\nC&F and module theory. In particular, a generic LNC scheme is presented that\nmakes no assumptions on the underlying nested lattice code. C&F is\nre-interpreted in this framework, and several generalized constructions of LNC\nschemes are given. The generic LNC scheme naturally leads to a linear network\ncoding channel over modules, based on which non-coherent network coding can be\nachieved. Next, performance/complexity tradeoffs of LNC schemes are studied,\nwith a particular focus on hypercube-shaped LNC schemes. The error probability\nof this class of LNC schemes is largely determined by the minimum inter-coset\ndistances of the underlying nested lattice code. Several illustrative\nhypercube-shaped LNC schemes are designed based on Construction A and D,\nshowing that nominal coding gains of 3 to 7.5 dB can be obtained with\nreasonable decoding complexity. Finally, the possibility of decoding multiple\nlinear combinations is considered and related to the shortest independent\nvectors problem. A notion of dominant solutions is developed together with a\nsuitable lattice-reduction-based algorithm.\n", "contributors": [{"name": "Feng, Chen", "sameAs": [], "familyName": "Feng", "additionalName": "", "givenName": "Chen", "email": ""}, {"name": "Silva, Danilo", "sameAs": [], "familyName": "Silva", "additionalName": "", "givenName": "Danilo", "email": ""}, {"name": "Kschischang, Frank R.", "sameAs": [], "familyName": "Kschischang", "additionalName": "R.", "givenName": "Frank", "email": ""}], "title": "Algebraic Approach to Physical-Layer Network Coding", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-08-08", "2013-07-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1108.1695", "oai:arXiv.org:1108.1695"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The problem of designing physical-layer network coding (PNC) schemes via\nnested lattices is considered. Building on the compute-and-forward (C&F)\nrelaying strategy of Nazer and Gastpar, who demonstrated its asymptotic gain\nusing information-theoretic tools, an algebraic approach is taken to show its\npotential in practical, non-asymptotic, settings. A general framework is\ndeveloped for studying nested-lattice-based PNC schemes---called lattice\nnetwork coding (LNC) schemes for short---by making a direct connection between\nC&F and module theory. In particular, a generic LNC scheme is presented that\nmakes no assumptions on the underlying nested lattice code. C&F is\nre-interpreted in this framework, and several generalized constructions of LNC\nschemes are given. The generic LNC scheme naturally leads to a linear network\ncoding channel over modules, based on which non-coherent network coding can be\nachieved. Next, performance/complexity tradeoffs of LNC schemes are studied,\nwith a particular focus on hypercube-shaped LNC schemes. The error probability\nof this class of LNC schemes is largely determined by the minimum inter-coset\ndistances of the underlying nested lattice code. Several illustrative\nhypercube-shaped LNC schemes are designed based on Construction A and D,\nshowing that nominal coding gains of 3 to 7.5 dB can be obtained with\nreasonable decoding complexity. Finally, the possibility of decoding multiple\nlinear combinations is considered and related to the shortest independent\nvectors problem. A notion of dominant solutions is developed together with a\nsuitable lattice-reduction-based algorithm.\n", "Comment: Submitted to IEEE Transactions on Information Theory, July 21, 2011.\n  Revised version submitted Sept. 17, 2012. Final version submitted July 3,\n  2013"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1108.1695"}}, {"publisher": {"name": ""}, "description": "  Cylindrical algebraic decomposition (CAD) is an important tool for the\ninvestigation of semi-algebraic sets, with applications in algebraic geometry\nand beyond. We have previously reported on an implementation of CAD in Maple\nwhich offers the original projection and lifting algorithm of Collins along\nwith subsequent improvements.\n  Here we report on new functionality: specifically the ability to build\ncylindrical algebraic sub-decompositions (sub-CADs) where only certain cells\nare returned. We have implemented algorithms to return cells of a prescribed\ndimensions or higher (layered {\\scad}s), and an algorithm to return only those\ncells on which given polynomials are zero (variety {\\scad}s). These offer\nsubstantial savings in output size and computation time.\n  The code described and an introductory Maple worksheet / pdf demonstrating\nthe full functionality of the package are freely available online at\nhttp://opus.bath.ac.uk/43911/.\n", "contributors": [{"name": "England, Matthew", "sameAs": [], "familyName": "England", "additionalName": "", "givenName": "Matthew", "email": ""}, {"name": "Wilson, David", "sameAs": [], "familyName": "Wilson", "additionalName": "", "givenName": "David", "email": ""}], "title": "An implementation of Sub-CAD in Maple", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06599", "oai:arXiv.org:1503.06599"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Cylindrical algebraic decomposition (CAD) is an important tool for the\ninvestigation of semi-algebraic sets, with applications in algebraic geometry\nand beyond. We have previously reported on an implementation of CAD in Maple\nwhich offers the original projection and lifting algorithm of Collins along\nwith subsequent improvements.\n  Here we report on new functionality: specifically the ability to build\ncylindrical algebraic sub-decompositions (sub-CADs) where only certain cells\nare returned. We have implemented algorithms to return cells of a prescribed\ndimensions or higher (layered {\\scad}s), and an algorithm to return only those\ncells on which given polynomials are zero (variety {\\scad}s). These offer\nsubstantial savings in output size and computation time.\n  The code described and an introductory Maple worksheet / pdf demonstrating\nthe full functionality of the package are freely available online at\nhttp://opus.bath.ac.uk/43911/.\n", "Comment: 9 pages"]}}], "languages": [null], "subjects": ["i.1.2", "68w30", "computer science - symbolic computation"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06599"}}, {"publisher": {"name": ""}, "description": "  The binary adder is a two-user multiple access channel whose inputs are\nbinary and whose output is the real sum of the inputs. While the Shannon\ncapacity region of this channel is well known, little is known regarding its\nzero-error capacity region, and a large gap remains between the best inner and\nouter bounds. In this paper, we provide an improved outer bound for this\nproblem. To that end, we introduce a soft variation of the Saur-Perles-Shelah\nLemma, that is then used in conjunction with an outer bound for the Shannon\ncapacity region with an additional common message.\n", "contributors": [{"name": "Ordentlich, Or", "sameAs": [], "familyName": "Ordentlich", "additionalName": "", "givenName": "Or", "email": ""}, {"name": "Shayevitz, Ofer", "sameAs": [], "familyName": "Shayevitz", "additionalName": "", "givenName": "Ofer", "email": ""}], "title": "A VC-dimension-based Outer Bound on the Zero-Error Capacity of the\n  Binary Adder Channel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.8670", "oai:arXiv.org:1412.8670"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The binary adder is a two-user multiple access channel whose inputs are\nbinary and whose output is the real sum of the inputs. While the Shannon\ncapacity region of this channel is well known, little is known regarding its\nzero-error capacity region, and a large gap remains between the best inner and\nouter bounds. In this paper, we provide an improved outer bound for this\nproblem. To that end, we introduce a soft variation of the Saur-Perles-Shelah\nLemma, that is then used in conjunction with an outer bound for the Shannon\ncapacity region with an additional common message.\n", "Comment: Submitted to ISIT 2015. An extended version titled \"An Upper Bound on\n  the Sizes of Multiset-Union-Free Families\" is available online at\n  arXiv:1412.8415"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.8670"}}, {"publisher": {"name": ""}, "description": "  Any network studied in the literature is inevitably just a sampled\nrepresentative of its real-world analogue. Additionally, network sampling is\nlately often applied to large networks to allow for their faster and more\nefficient analysis. Nevertheless, the changes in network structure introduced\nby sampling are still far from understood. In this paper, we study the presence\nof characteristic groups of nodes in sampled social and information networks.\nWe consider different network sampling techniques including random node and\nlink selection, network exploration and expansion. We first observe that the\nstructure of social networks reveals densely linked groups like communities,\nwhile the structure of information networks is better described by modules of\nstructurally equivalent nodes. However, despite these notable differences, the\nstructure of sampled networks exhibits stronger characterization by\ncommunity-like groups than the original networks, irrespective of their type\nand consistently across various sampling techniques. Hence, rich community\nstructure commonly observed in social and information networks is to some\nextent merely an artifact of sampling.\n", "contributors": [{"name": "Blagus, Neli", "sameAs": [], "familyName": "Blagus", "additionalName": "", "givenName": "Neli", "email": ""}, {"name": "\u0160ubelj, Lovro", "sameAs": [], "familyName": "\u0160ubelj", "additionalName": "", "givenName": "Lovro", "email": ""}, {"name": "Weiss, Gregor", "sameAs": [], "familyName": "Weiss", "additionalName": "", "givenName": "Gregor", "email": ""}, {"name": "Bajec, Marko", "sameAs": [], "familyName": "Bajec", "additionalName": "", "givenName": "Marko", "email": ""}], "title": "Sampling promotes community structure in social and information networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03097", "Physica A 432, 206-215 (2015)", "doi:10.1016/j.physa.2015.03.048", "oai:arXiv.org:1504.03097"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Any network studied in the literature is inevitably just a sampled\nrepresentative of its real-world analogue. Additionally, network sampling is\nlately often applied to large networks to allow for their faster and more\nefficient analysis. Nevertheless, the changes in network structure introduced\nby sampling are still far from understood. In this paper, we study the presence\nof characteristic groups of nodes in sampled social and information networks.\nWe consider different network sampling techniques including random node and\nlink selection, network exploration and expansion. We first observe that the\nstructure of social networks reveals densely linked groups like communities,\nwhile the structure of information networks is better described by modules of\nstructurally equivalent nodes. However, despite these notable differences, the\nstructure of sampled networks exhibits stronger characterization by\ncommunity-like groups than the original networks, irrespective of their type\nand consistently across various sampling techniques. Hence, rich community\nstructure commonly observed in social and information networks is to some\nextent merely an artifact of sampling.\n", "Comment: 15 pages, 6 figures, 5 tables"]}}], "languages": [null], "subjects": ["statistics and probability", "physics - data analysis", "physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03097"}}, {"publisher": {"name": ""}, "description": "  We propose an efficient ADMM method with guarantees for high-dimensional\nproblems. We provide explicit bounds for the sparse optimization problem and\nthe noisy matrix decomposition problem. For sparse optimization, we establish\nthat the modified ADMM method has an optimal convergence rate of\n$\\mathcal{O}(s\\log d/T)$, where $s$ is the sparsity level, $d$ is the data\ndimension and $T$ is the number of steps. This matches with the minimax lower\nbounds for sparse estimation. For matrix decomposition into sparse and low rank\ncomponents, we provide the first guarantees for any online method, and prove a\nconvergence rate of $\\tilde{\\mathcal{O}}((s+r)\\beta^2(p) /T) +\n\\mathcal{O}(1/p)$ for a $p\\times p$ matrix, where $s$ is the sparsity level,\n$r$ is the rank and $\\Theta(\\sqrt{p})\\leq \\beta(p)\\leq \\Theta(p)$. Our\nguarantees match the minimax lower bound with respect to $s,r$ and $T$. In\naddition, we match the minimax lower bound with respect to the matrix dimension\n$p$, i.e. $\\beta(p)=\\Theta(\\sqrt{p})$, for many important statistical models\nincluding the independent noise model, the linear Bayesian network and the\nlatent Gaussian graphical model under some conditions. Our ADMM method is based\non epoch-based annealing and consists of inexpensive steps which involve\nprojections on to simple norm balls. Experiments show that for both sparse\noptimization and matrix decomposition problems, our algorithm outperforms the\nstate-of-the-art methods. In particular, we reach higher accuracy with same\ntime complexity.\n", "contributors": [{"name": "Sedghi, Hanie", "sameAs": [], "familyName": "Sedghi", "additionalName": "", "givenName": "Hanie", "email": ""}, {"name": "Anandkumar, Anima", "sameAs": [], "familyName": "Anandkumar", "additionalName": "", "givenName": "Anima", "email": ""}, {"name": "Jonckheere, Edmond", "sameAs": [], "familyName": "Jonckheere", "additionalName": "", "givenName": "Edmond", "email": ""}], "title": "Multi-Step Stochastic ADMM in High Dimensions: Applications to Sparse\n  Optimization and Noisy Matrix Decomposition", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-20", "2014-12-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.5131", "oai:arXiv.org:1402.5131"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  We propose an efficient ADMM method with guarantees for high-dimensional\nproblems. We provide explicit bounds for the sparse optimization problem and\nthe noisy matrix decomposition problem. For sparse optimization, we establish\nthat the modified ADMM method has an optimal convergence rate of\n$\\mathcal{O}(s\\log d/T)$, where $s$ is the sparsity level, $d$ is the data\ndimension and $T$ is the number of steps. This matches with the minimax lower\nbounds for sparse estimation. For matrix decomposition into sparse and low rank\ncomponents, we provide the first guarantees for any online method, and prove a\nconvergence rate of $\\tilde{\\mathcal{O}}((s+r)\\beta^2(p) /T) +\n\\mathcal{O}(1/p)$ for a $p\\times p$ matrix, where $s$ is the sparsity level,\n$r$ is the rank and $\\Theta(\\sqrt{p})\\leq \\beta(p)\\leq \\Theta(p)$. Our\nguarantees match the minimax lower bound with respect to $s,r$ and $T$. In\naddition, we match the minimax lower bound with respect to the matrix dimension\n$p$, i.e. $\\beta(p)=\\Theta(\\sqrt{p})$, for many important statistical models\nincluding the independent noise model, the linear Bayesian network and the\nlatent Gaussian graphical model under some conditions. Our ADMM method is based\non epoch-based annealing and consists of inexpensive steps which involve\nprojections on to simple norm balls. Experiments show that for both sparse\noptimization and matrix decomposition problems, our algorithm outperforms the\nstate-of-the-art methods. In particular, we reach higher accuracy with same\ntime complexity.\n", "Comment: appeared in Neural Information Processing Systems(NIPS) 2014"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.5131"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose a novel, effective and efficient probabilistic\npruning criterion for probabilistic similarity queries on uncertain data. Our\napproach supports a general uncertainty model using continuous probabilistic\ndensity functions to describe the (possibly correlated) uncertain attributes of\nobjects. In a nutshell, the problem to be solved is to compute the PDF of the\nrandom variable denoted by the probabilistic domination count: Given an\nuncertain database object B, an uncertain reference object R and a set D of\nuncertain database objects in a multi-dimensional space, the probabilistic\ndomination count denotes the number of uncertain objects in D that are closer\nto R than B. This domination count can be used to answer a wide range of\nprobabilistic similarity queries. Specifically, we propose a novel geometric\npruning filter and introduce an iterative filter-refinement strategy for\nconservatively and progressively estimating the probabilistic domination count\nin an efficient way while keeping correctness according to the possible world\nsemantics. In an experimental evaluation, we show that our proposed technique\nallows to acquire tight probability bounds for the probabilistic domination\ncount quickly, even for large uncertain databases.\n", "contributors": [{"name": "Bernecker, Thomas", "sameAs": [], "familyName": "Bernecker", "additionalName": "", "givenName": "Thomas", "email": ""}, {"name": "Emrich, Tobias", "sameAs": [], "familyName": "Emrich", "additionalName": "", "givenName": "Tobias", "email": ""}, {"name": "Kriegel, Hans-Peter", "sameAs": [], "familyName": "Kriegel", "additionalName": "", "givenName": "Hans-Peter", "email": ""}, {"name": "Mamoulis, Nikos", "sameAs": [], "familyName": "Mamoulis", "additionalName": "", "givenName": "Nikos", "email": ""}, {"name": "Renz, Matthias", "sameAs": [], "familyName": "Renz", "additionalName": "", "givenName": "Matthias", "email": ""}, {"name": "Zuefle, Andreas", "sameAs": [], "familyName": "Zuefle", "additionalName": "", "givenName": "Andreas", "email": ""}], "title": "A Novel Probabilistic Pruning Approach to Speed Up Similarity Queries in\n  Uncertain Databases", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-13", "2011-05-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.2613", "oai:arXiv.org:1101.2613"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we propose a novel, effective and efficient probabilistic\npruning criterion for probabilistic similarity queries on uncertain data. Our\napproach supports a general uncertainty model using continuous probabilistic\ndensity functions to describe the (possibly correlated) uncertain attributes of\nobjects. In a nutshell, the problem to be solved is to compute the PDF of the\nrandom variable denoted by the probabilistic domination count: Given an\nuncertain database object B, an uncertain reference object R and a set D of\nuncertain database objects in a multi-dimensional space, the probabilistic\ndomination count denotes the number of uncertain objects in D that are closer\nto R than B. This domination count can be used to answer a wide range of\nprobabilistic similarity queries. Specifically, we propose a novel geometric\npruning filter and introduce an iterative filter-refinement strategy for\nconservatively and progressively estimating the probabilistic domination count\nin an efficient way while keeping correctness according to the possible world\nsemantics. In an experimental evaluation, we show that our proposed technique\nallows to acquire tight probability bounds for the probabilistic domination\ncount quickly, even for large uncertain databases.\n"}}], "languages": [null], "subjects": ["computer science - databases"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.2613"}}, {"publisher": {"name": ""}, "description": "  This paper introduces some foundations of wavelets over Galois fields.\nStandard orthogonal finite-field wavelets (FF-Wavelets) including FF-Haar and\nFF-Daubechies are derived. Non-orthogonal FF-wavelets such as B-spline over\nGF(p) are also considered. A few examples of multiresolution analysis over\nFinite fields are presented showing how to perform Laplacian pyramid filtering\nof finite block lengths sequences. An application of FF-wavelets to design\nspread-spectrum sequences is presented.\n", "contributors": [{"name": "de Oliveira, H. M.", "sameAs": [], "familyName": "de Oliveira", "additionalName": "M.", "givenName": "H.", "email": ""}, {"name": "Falk, T. H.", "sameAs": [], "familyName": "Falk", "additionalName": "H.", "givenName": "T.", "email": ""}], "title": "On Wavelet Decomposition over Finite Fields", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01877", "oai:arXiv.org:1502.01877"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper introduces some foundations of wavelets over Galois fields.\nStandard orthogonal finite-field wavelets (FF-Wavelets) including FF-Haar and\nFF-Daubechies are derived. Non-orthogonal FF-wavelets such as B-spline over\nGF(p) are also considered. A few examples of multiresolution analysis over\nFinite fields are presented showing how to perform Laplacian pyramid filtering\nof finite block lengths sequences. An application of FF-wavelets to design\nspread-spectrum sequences is presented.\n", "Comment: 4 pages, 1 figure. conference: XIX Simposio Brasileiro de\n  Telecomunicacoes, 2001, Fortaleza, CE, Brazil"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01877"}}, {"publisher": {"name": ""}, "description": "  NeuCoin is a decentralized peer-to-peer cryptocurrency derived from Sunny\nKing's Peercoin, which itself was derived from Satoshi Nakamoto's Bitcoin. As\nwith Peercoin, proof-of-stake replaces proof-of-work as NeuCoin's security\nmodel, effectively replacing the operating costs of Bitcoin miners\n(electricity, computers) with the capital costs of holding the currency.\nProof-of-stake also avoids proof-of-work's inherent tendency towards\ncentralization resulting from competition for coinbase rewards among miners\nbased on lowest cost electricity and hash power.\n  NeuCoin increases security relative to Peercoin and other existing\nproof-of-stake currencies in numerous ways, including: (1) incentivizing nodes\nto continuously stake coins over time through substantially higher mining\nrewards and lower minimum stake age; (2) abandoning the use of coin age in the\nmining formula; (3) causing the stake modifier parameter to change over time\nfor each stake; and (4) utilizing a client that punishes nodes that attempt to\nmine on multiple branches with duplicate stakes.\n  This paper demonstrates how NeuCoin's proof-of-stake implementation addresses\nall commonly raised \"nothing at stake\" objections to generic proof-of-stake\nsystems. It also reviews many of the flaws of proof-of-work designs to\nhighlight the potential for an alternate cryptocurrency that solves these\nflaws.\n", "contributors": [{"name": "Davarpanah, Kourosh", "sameAs": [], "familyName": "Davarpanah", "additionalName": "", "givenName": "Kourosh", "email": ""}, {"name": "Kaufman, Dan", "sameAs": [], "familyName": "Kaufman", "additionalName": "", "givenName": "Dan", "email": ""}, {"name": "Pubellier, Ophelie", "sameAs": [], "familyName": "Pubellier", "additionalName": "", "givenName": "Ophelie", "email": ""}], "title": "NeuCoin: the First Secure, Cost-efficient and Decentralized\n  Cryptocurrency", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07768", "oai:arXiv.org:1503.07768"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  NeuCoin is a decentralized peer-to-peer cryptocurrency derived from Sunny\nKing's Peercoin, which itself was derived from Satoshi Nakamoto's Bitcoin. As\nwith Peercoin, proof-of-stake replaces proof-of-work as NeuCoin's security\nmodel, effectively replacing the operating costs of Bitcoin miners\n(electricity, computers) with the capital costs of holding the currency.\nProof-of-stake also avoids proof-of-work's inherent tendency towards\ncentralization resulting from competition for coinbase rewards among miners\nbased on lowest cost electricity and hash power.\n  NeuCoin increases security relative to Peercoin and other existing\nproof-of-stake currencies in numerous ways, including: (1) incentivizing nodes\nto continuously stake coins over time through substantially higher mining\nrewards and lower minimum stake age; (2) abandoning the use of coin age in the\nmining formula; (3) causing the stake modifier parameter to change over time\nfor each stake; and (4) utilizing a client that punishes nodes that attempt to\nmine on multiple branches with duplicate stakes.\n  This paper demonstrates how NeuCoin's proof-of-stake implementation addresses\nall commonly raised \"nothing at stake\" objections to generic proof-of-stake\nsystems. It also reviews many of the flaws of proof-of-work designs to\nhighlight the potential for an alternate cryptocurrency that solves these\nflaws.\n", "Comment: 39 pages, 10 figures"]}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07768"}}, {"publisher": {"name": ""}, "description": "abstract: Nowadays ports play a critic role in the supply chains of contemporary companies and global commerce. Since the ports' operational effectiveness is critical on the development of competitive supply chains, their contribution to regional economies is essential. With the globalization of markets, the traffic of containers flowing through the different ports has increased significantly in the last decades. In order to attract additional container traffic and improve their comparative advantages over the competition, ports serving same hinterlands explore ways to improve their operations to become more attractive to shippers. This research explores the hypothesis that lowering the variability of the service time observed in the handling of containers, a port reduces the total logistics costs of their customers, increase its competiveness and that of their customers. This thesis proposes a methodology that allows the quantification of the variability existing in the services of a port derived from factors like inefficient internal operations, vessel congestion or external disruptions scenarios. It focuses on assessing the impact of this variability on the user's logistic costs. The methodology also allows a port to define competitive strategies that take into account its variability and that of competing ports. These competitive strategies are also translated into specific parameters that can be used to design and adjust internal operations. The methodology includes (1) a definition of a proper economic model to measure the logistic impact of port's variability, (2) a network analysis approach to the defined problem and (3) a systematic procedure to determine competitive service time parameters for a port. After the methodology is developed, a case study is presented where it is applied to the Port of Guaymas. This is done by finding service time parameters for this port that yield lower logistic costs than the observed in other competing ports.", "contributors": [{"name": "Meneses Preciado, Cesar Vladimir (Author)", "sameAs": [], "familyName": "Meneses Preciado", "additionalName": "Vladimir", "givenName": "Cesar", "email": ""}, {"name": "Villalobos, Jesus R (Advisor)", "sameAs": [], "familyName": "Villalobos", "additionalName": "R", "givenName": "Jesus", "email": ""}, {"name": "Gel, Esma S (Committee member)", "sameAs": [], "familyName": "Gel", "additionalName": "S", "givenName": "Esma", "email": ""}, {"name": "Maltz, Arnold B (Committee member)", "sameAs": [], "familyName": "Maltz", "additionalName": "B", "givenName": "Arnold", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Competitive Positioning of Ports based on Total Landed Costs of Supply Chains", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Masters Thesis"}}, {"name": "format", "properties": {"format": "148 pages"}}, {"name": "date", "properties": {"date": "2011"}}, {"name": "description", "properties": {"description": ["abstract: Nowadays ports play a critic role in the supply chains of contemporary companies and global commerce. Since the ports' operational effectiveness is critical on the development of competitive supply chains, their contribution to regional economies is essential. With the globalization of markets, the traffic of containers flowing through the different ports has increased significantly in the last decades. In order to attract additional container traffic and improve their comparative advantages over the competition, ports serving same hinterlands explore ways to improve their operations to become more attractive to shippers. This research explores the hypothesis that lowering the variability of the service time observed in the handling of containers, a port reduces the total logistics costs of their customers, increase its competiveness and that of their customers. This thesis proposes a methodology that allows the quantification of the variability existing in the services of a port derived from factors like inefficient internal operations, vessel congestion or external disruptions scenarios. It focuses on assessing the impact of this variability on the user's logistic costs. The methodology also allows a port to define competitive strategies that take into account its variability and that of competing ports. These competitive strategies are also translated into specific parameters that can be used to design and adjust internal operations. The methodology includes (1) a definition of a proper economic model to measure the logistic impact of port's variability, (2) a network analysis approach to the defined problem and (3) a systematic procedure to determine competitive service time parameters for a port. After the methodology is developed, a case study is presented where it is applied to the Port of Guaymas. This is done by finding service time parameters for this port that yield lower logistic costs than the observed in other competing ports.", "Dissertation/Thesis", "M.S. Industrial Engineering 2011"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.9186", "item:9186"]}}], "languages": [null], "subjects": ["supply chain", "management", "transportation", "industrial engineering", "lead time variability", "port competitiveness", "total landed costs"], "providerUpdatedDateTime": "2015-02-12T01:08:47", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.9186"}}, {"publisher": {"name": ""}, "description": "  Future mobile communication networks will require enhanced network efficiency\nand reduced system overhead due to their user density and high data rate\ndemanding applications of the mobile devices. Research on Blind Interference\nAlignment (BIA) and Topological Interference Management (TIM) has shown that\noptimal Degrees of Freedom (DoF) can be achieved, in the absence of Channel\nState Information (CSI) at the transmitters, reducing the network's overhead.\nMoreover, the recently emerged Non-Orthogonal Multiple Access (NOMA) scheme\nsuggests a different multiple access approach, compared to the current\northogonal methods employed in 4G networks, resulting in high capacity gains.\nOur contribution is a hybrid TIM-NOMA scheme in Single-Input-Single-Output\n(SISO) K-user cells, in which users are divided into T groups, and 1/T DoF is\nachieved for each user. By superimposing users in the power domain, we\nintroduce a two-stage decoding process, managing 'inter-group' interference\nbased on the TIM principles, and 'intra-group' interference based on Successful\nInterference Cancellation (SIC), as proposed by NOMA. We show that for high SNR\nvalues the hybrid scheme can improve the sum rate by at least 100% when\ncompared to Time Division Multiple Access (TDMA).\n", "contributors": [{"name": "Kalokidou, Vaia", "sameAs": [], "familyName": "Kalokidou", "additionalName": "", "givenName": "Vaia", "email": ""}, {"name": "Johnson, Oliver", "sameAs": [], "familyName": "Johnson", "additionalName": "", "givenName": "Oliver", "email": ""}, {"name": "Piechocki, Robert", "sameAs": [], "familyName": "Piechocki", "additionalName": "", "givenName": "Robert", "email": ""}], "title": "A hybrid TIM-NOMA scheme for the SISO Broadcast Channel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.07723", "oai:arXiv.org:1501.07723"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Future mobile communication networks will require enhanced network efficiency\nand reduced system overhead due to their user density and high data rate\ndemanding applications of the mobile devices. Research on Blind Interference\nAlignment (BIA) and Topological Interference Management (TIM) has shown that\noptimal Degrees of Freedom (DoF) can be achieved, in the absence of Channel\nState Information (CSI) at the transmitters, reducing the network's overhead.\nMoreover, the recently emerged Non-Orthogonal Multiple Access (NOMA) scheme\nsuggests a different multiple access approach, compared to the current\northogonal methods employed in 4G networks, resulting in high capacity gains.\nOur contribution is a hybrid TIM-NOMA scheme in Single-Input-Single-Output\n(SISO) K-user cells, in which users are divided into T groups, and 1/T DoF is\nachieved for each user. By superimposing users in the power domain, we\nintroduce a two-stage decoding process, managing 'inter-group' interference\nbased on the TIM principles, and 'intra-group' interference based on Successful\nInterference Cancellation (SIC), as proposed by NOMA. We show that for high SNR\nvalues the hybrid scheme can improve the sum rate by at least 100% when\ncompared to Time Division Multiple Access (TDMA).\n", "Comment: 6 pages, 6 figures, submitted to IEEE ICC'15 - IEEE SCAN Workshop"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-02-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.07723"}}, {"publisher": {"name": ""}, "description": "  In the process of recording, storage and transmission of time-domain audio\nsignals, errors may be introduced that are difficult to correct in an\nunsupervised way. Here, we train a convolutional deep neural network to\nre-synthesize input time-domain speech signals at its output layer. We then use\nthis abstract transformation, which we call a deep transform (DT), to perform\nprobabilistic re-synthesis on further speech (of the same speaker) which has\nbeen degraded. Using the convolutive DT, we demonstrate the recovery of speech\naudio that has been subject to extreme degradation. This approach may be useful\nfor correction of errors in communications devices.\n", "contributors": [{"name": "Simpson, Andrew J. R.", "sameAs": [], "familyName": "Simpson", "additionalName": "J. R.", "givenName": "Andrew", "email": ""}], "title": "Deep Transform: Time-Domain Audio Error Correction via Probabilistic\n  Re-Synthesis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.05849", "oai:arXiv.org:1503.05849"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In the process of recording, storage and transmission of time-domain audio\nsignals, errors may be introduced that are difficult to correct in an\nunsupervised way. Here, we train a convolutional deep neural network to\nre-synthesize input time-domain speech signals at its output layer. We then use\nthis abstract transformation, which we call a deep transform (DT), to perform\nprobabilistic re-synthesis on further speech (of the same speaker) which has\nbeen degraded. Using the convolutive DT, we demonstrate the recovery of speech\naudio that has been subject to extreme degradation. This approach may be useful\nfor correction of errors in communications devices.\n"}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - sound", "68txx", "computer science - learning"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.05849"}}, {"publisher": {"name": ""}, "description": "  Clustering is an effective technique in data mining to generate groups that\nare the matter of interest. Among various clustering approaches, the family of\nk-means algorithms and min-cut algorithms gain most popularity due to their\nsimplicity and efficacy. The classical k-means algorithm partitions a number of\ndata points into several subsets by iteratively updating the clustering centers\nand the associated data points. By contrast, a weighted undirected graph is\nconstructed in min-cut algorithms which partition the vertices of the graph\ninto two sets. However, existing clustering algorithms tend to cluster minority\nof data points into a subset, which shall be avoided when the target dataset is\nbalanced. To achieve more accurate clustering for balanced dataset, we propose\nto leverage exclusive lasso on k-means and min-cut to regulate the balance\ndegree of the clustering results. By optimizing our objective functions that\nbuild atop the exclusive lasso, we can make the clustering result as much\nbalanced as possible. Extensive experiments on several large-scale datasets\nvalidate the advantage of the proposed algorithms compared to the\nstate-of-the-art clustering algorithms.\n", "contributors": [{"name": "Chang, Xiaojun", "sameAs": [], "familyName": "Chang", "additionalName": "", "givenName": "Xiaojun", "email": ""}, {"name": "Nie, Feiping", "sameAs": [], "familyName": "Nie", "additionalName": "", "givenName": "Feiping", "email": ""}, {"name": "Ma, Zhigang", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Zhigang", "email": ""}, {"name": "Yang, Yi", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Yi", "email": ""}], "title": "Balanced k-Means and Min-Cut Clustering", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.6235", "oai:arXiv.org:1411.6235"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Clustering is an effective technique in data mining to generate groups that\nare the matter of interest. Among various clustering approaches, the family of\nk-means algorithms and min-cut algorithms gain most popularity due to their\nsimplicity and efficacy. The classical k-means algorithm partitions a number of\ndata points into several subsets by iteratively updating the clustering centers\nand the associated data points. By contrast, a weighted undirected graph is\nconstructed in min-cut algorithms which partition the vertices of the graph\ninto two sets. However, existing clustering algorithms tend to cluster minority\nof data points into a subset, which shall be avoided when the target dataset is\nbalanced. To achieve more accurate clustering for balanced dataset, we propose\nto leverage exclusive lasso on k-means and min-cut to regulate the balance\ndegree of the clustering results. By optimizing our objective functions that\nbuild atop the exclusive lasso, we can make the clustering result as much\nbalanced as possible. Extensive experiments on several large-scale datasets\nvalidate the advantage of the proposed algorithms compared to the\nstate-of-the-art clustering algorithms.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.6235"}}, {"publisher": {"name": ""}, "description": "  Given a social network represented by a graph $G$, we consider the problem of\nfinding a bounded cardinality set of nodes $S$ with the property that the\ninfluence spreading from $S$ in $G$ is as large as possible. The dynamics that\ngovern the spread of influence is the following: initially only elements in $S$\nare influenced; subsequently at each round, the set of influenced elements is\naugmented by all nodes in the network that have a sufficiently large number of\nalready influenced neighbors. While it is known that the general problem is\nhard to solve --- even in the approximate sense --- we present exact polynomial\ntime algorithms for trees, paths, cycles, and complete graphs.\n", "contributors": [{"name": "Cicalese, Ferdinando", "sameAs": [], "familyName": "Cicalese", "additionalName": "", "givenName": "Ferdinando", "email": ""}, {"name": "Cordasco, Gennaro", "sameAs": [], "familyName": "Cordasco", "additionalName": "", "givenName": "Gennaro", "email": ""}, {"name": "Gargano, Luisa", "sameAs": [], "familyName": "Gargano", "additionalName": "", "givenName": "Luisa", "email": ""}, {"name": "Milanic, Martin", "sameAs": [], "familyName": "Milanic", "additionalName": "", "givenName": "Martin", "email": ""}, {"name": "Peters, Joseph", "sameAs": [], "familyName": "Peters", "additionalName": "", "givenName": "Joseph", "email": ""}, {"name": "Vaccaro, Ugo", "sameAs": [], "familyName": "Vaccaro", "additionalName": "", "givenName": "Ugo", "email": ""}], "title": "How to go Viral: Cheaply and Quickly", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-11", "2015-02-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.3033", "7th International Conference, FUN 2014, Lipari Island, Sicily,\n  Italy, July 1-3, 2014. Proceedings ISBN 978-3-319-07889-2", "doi:10.1007/978-3-319-07890-8_9", "oai:arXiv.org:1404.3033"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Given a social network represented by a graph $G$, we consider the problem of\nfinding a bounded cardinality set of nodes $S$ with the property that the\ninfluence spreading from $S$ in $G$ is as large as possible. The dynamics that\ngovern the spread of influence is the following: initially only elements in $S$\nare influenced; subsequently at each round, the set of influenced elements is\naugmented by all nodes in the network that have a sufficiently large number of\nalready influenced neighbors. While it is known that the general problem is\nhard to solve --- even in the approximate sense --- we present exact polynomial\ntime algorithms for trees, paths, cycles, and complete graphs.\n", "Comment: An extended abstract of this paper will appear in Proceedings of\n  Seventh International conference on Fun with Algorithms (FUN 2014), Lectures\n  Notes in Computer Science, Springer"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - combinatorics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.3033"}}, {"publisher": {"name": ""}, "description": "These are the R source codes for the algorithm proposed for fitting exponential random graph models (ERGMs) on large social networks in our paper \"Estimation of exponential random graph models for large social networks via graph limits\". Specifically, the ERGM model we implement is the one that consider homomorphism densities of edges, two-stars and triangles, the one we examine in the above paper.", "contributors": [{"name": "He, Ran", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Ran", "email": ""}], "title": "Source codes for GLMLE algorithm", "shareProperties": {"source": "columbia"}, "otherProperties": [{"name": "type", "properties": {"type": "software, multimedia"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014"}}, {"name": "identifier", "properties": {"identifier": ["http://dx.doi.org/10.7916/D8HH6HQR", "academiccommons.columbia.edu/ac:178966"]}}, {"name": "setSpec", "properties": {"setSpec": []}}], "languages": [null], "subjects": ["statistics", "computer science"], "providerUpdatedDateTime": "2014-10-24T16:03:53", "uris": {"canonicalUri": "http://dx.doi.org/10.7916/D8HH6HQR"}}, {"publisher": {"name": ""}, "description": "abstract: Microfluidics is the study of fluid flow at very small scales (micro -- one millionth of a meter) and is prevalent in many areas of science and engineering. Typical applications include lab-on-a-chip devices, microfluidic fuel cells, and DNA separation technologies. Many of these microfluidic devices rely on micron-resolution velocimetry measurements to improve microchannel design and characterize existing devices. Methods such as micro particle imaging velocimetry (microPIV) and micro particle tracking velocimetry (microPTV) are mature and established methods for characterization of steady 2D flow fields. Increasingly complex microdevices require techniques that measure unsteady and/or three dimensional velocity fields. This dissertation presents a method for three-dimensional velocimetry of unsteady microflows based on spinning disk confocal microscopy and depth scanning of a microvolume. High-speed 2D unsteady velocity fields are resolved by acquiring images of particle motion using a high-speed CMOS camera and confocal microscope. The confocal microscope spatially filters out of focus light using a rotating disk of pinholes placed in the imaging path, improving the ability of the system to resolve unsteady microPIV measurements by improving the image and correlation signal to noise ratio. For 3D3C measurements, a piezo-actuated objective positioner quickly scans the depth of the microvolume and collects 2D image slices, which are stacked into 3D images. Super resolution microPIV interrogates these 3D images using microPIV as a predictor field for tracking individual particles with microPTV. The 3D3C diagnostic is demonstrated by measuring a pressure driven flow in a three-dimensional expanding microchannel. The experimental velocimetry data acquired at 30 Hz with instantaneous spatial resolution of 4.5 by 4.5 by 4.5 microns agrees well with a computational model of the flow field. The technique allows for isosurface visualization of time resolved 3D3C particle motion and high spatial resolution velocity measurements without requiring a calibration step or reconstruction algorithms. Several applications are investigated, including 3D quantitative fluorescence imaging of isotachophoresis plugs advecting through a microchannel and the dynamics of reaction induced colloidal crystal deposition.", "contributors": [{"name": "Klein, Steven Adam (Author)", "sameAs": [], "familyName": "Klein", "additionalName": "Adam", "givenName": "Steven", "email": ""}, {"name": "Posner, Jonathan D (Advisor)", "sameAs": [], "familyName": "Posner", "additionalName": "D", "givenName": "Jonathan", "email": ""}, {"name": "Adrian, Ronald  (Committee member)", "sameAs": [], "familyName": "Adrian", "additionalName": "", "givenName": "Ronald", "email": ""}, {"name": "Chen, Kangping  (Committee member)", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Kangping", "email": ""}, {"name": "Devasenathipathy, Shankar  (Committee member)", "sameAs": [], "familyName": "Devasenathipathy", "additionalName": "", "givenName": "Shankar", "email": ""}, {"name": "Frakes, David  (Committee member)", "sameAs": [], "familyName": "Frakes", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Volumetric Particle Velocimetry for Microscale Flows", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "181 pages"}}, {"name": "date", "properties": {"date": "2011"}}, {"name": "description", "properties": {"description": ["abstract: Microfluidics is the study of fluid flow at very small scales (micro -- one millionth of a meter) and is prevalent in many areas of science and engineering. Typical applications include lab-on-a-chip devices, microfluidic fuel cells, and DNA separation technologies. Many of these microfluidic devices rely on micron-resolution velocimetry measurements to improve microchannel design and characterize existing devices. Methods such as micro particle imaging velocimetry (microPIV) and micro particle tracking velocimetry (microPTV) are mature and established methods for characterization of steady 2D flow fields. Increasingly complex microdevices require techniques that measure unsteady and/or three dimensional velocity fields. This dissertation presents a method for three-dimensional velocimetry of unsteady microflows based on spinning disk confocal microscopy and depth scanning of a microvolume. High-speed 2D unsteady velocity fields are resolved by acquiring images of particle motion using a high-speed CMOS camera and confocal microscope. The confocal microscope spatially filters out of focus light using a rotating disk of pinholes placed in the imaging path, improving the ability of the system to resolve unsteady microPIV measurements by improving the image and correlation signal to noise ratio. For 3D3C measurements, a piezo-actuated objective positioner quickly scans the depth of the microvolume and collects 2D image slices, which are stacked into 3D images. Super resolution microPIV interrogates these 3D images using microPIV as a predictor field for tracking individual particles with microPTV. The 3D3C diagnostic is demonstrated by measuring a pressure driven flow in a three-dimensional expanding microchannel. The experimental velocimetry data acquired at 30 Hz with instantaneous spatial resolution of 4.5 by 4.5 by 4.5 microns agrees well with a computational model of the flow field. The technique allows for isosurface visualization of time resolved 3D3C particle motion and high spatial resolution velocity measurements without requiring a calibration step or reconstruction algorithms. Several applications are investigated, including 3D quantitative fluorescence imaging of isotachophoresis plugs advecting through a microchannel and the dynamics of reaction induced colloidal crystal deposition.", "Dissertation/Thesis", "Ph.D. Mechanical Engineering 2011"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.9299", "item:9299"]}}], "languages": [null], "subjects": ["three dimensional", "mechanical engineering", "optics", "microfluidics", "three component", "super resolution", "particle image velocimetry", "particle tracking velocimetry", "physics"], "providerUpdatedDateTime": "2015-02-12T01:08:52", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.9299"}}, {"publisher": {"name": ""}, "description": "  We study compressed sensing (CS) signal reconstruction problems where an\ninput signal is measured via matrix multiplication under additive white\nGaussian noise. Our signals are assumed to be stationary and ergodic, but the\ninput statistics are unknown; the goal is to provide reconstruction algorithms\nthat are universal to the input statistics. We present a novel algorithm that\ncombines: (i) the approximate message passing (AMP) CS reconstruction\nframework, which converts the matrix channel recovery problem into scalar\nchannel denoising; (ii) a universal denoising scheme based on context\nquantization, which partitions the stationary ergodic signal denoising into\nindependent and identically distributed (i.i.d.) subsequence denoising; and\n(iii) a density estimation approach that approximates the probability\ndistribution of an i.i.d. sequence by fitting a Gaussian mixture (GM) model. In\naddition to the algorithmic framework, we provide three contributions: (i)\nnumerical results showing that state evolution holds for non-separable Bayesian\nsliding-window denoisers; (ii) a universal denoiser that does not require the\ninput signal to be bounded; and (iii) we modify the GM learning algorithm, and\nextend it to an i.i.d. denoiser. Our universal CS recovery algorithm compares\nfavorably with existing reconstruction algorithms in terms of both\nreconstruction quality and runtime, despite not knowing the input statistics of\nthe stationary ergodic signal.\n", "contributors": [{"name": "Ma, Yanting", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Yanting", "email": ""}, {"name": "Zhu, Junan", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "Junan", "email": ""}, {"name": "Baron, Dror", "sameAs": [], "familyName": "Baron", "additionalName": "", "givenName": "Dror", "email": ""}], "title": "Compressed Sensing via Universal Denoising and Approximate Message\n  Passing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-07", "2014-10-21"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.1944", "oai:arXiv.org:1407.1944"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We study compressed sensing (CS) signal reconstruction problems where an\ninput signal is measured via matrix multiplication under additive white\nGaussian noise. Our signals are assumed to be stationary and ergodic, but the\ninput statistics are unknown; the goal is to provide reconstruction algorithms\nthat are universal to the input statistics. We present a novel algorithm that\ncombines: (i) the approximate message passing (AMP) CS reconstruction\nframework, which converts the matrix channel recovery problem into scalar\nchannel denoising; (ii) a universal denoising scheme based on context\nquantization, which partitions the stationary ergodic signal denoising into\nindependent and identically distributed (i.i.d.) subsequence denoising; and\n(iii) a density estimation approach that approximates the probability\ndistribution of an i.i.d. sequence by fitting a Gaussian mixture (GM) model. In\naddition to the algorithmic framework, we provide three contributions: (i)\nnumerical results showing that state evolution holds for non-separable Bayesian\nsliding-window denoisers; (ii) a universal denoiser that does not require the\ninput signal to be bounded; and (iii) we modify the GM learning algorithm, and\nextend it to an i.i.d. denoiser. Our universal CS recovery algorithm compares\nfavorably with existing reconstruction algorithms in terms of both\nreconstruction quality and runtime, despite not knowing the input statistics of\nthe stationary ergodic signal.\n", "Comment: Appeared at 52'd annual Allerton Conference on Communication,\n  Control, and Computing"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.1944"}}, {"publisher": {"name": ""}, "description": "  Multibeam systems with hundreds of beams have been recently deployed in order\nto provide higher capacities by employing fractional frequency reuse.\nFurthermore, employing full frequency reuse and precoding over multiple beams\nhas shown great throughput potential in literature. However, feeding all this\ndata from a single gateway is not feasible based on the current frequency\nallocations. In this context, we investigate a range of scenarios involving\nbeam clusters where each cluster is managed by a single gateway. More\nspecifically, the following cases are considered for handling intercluster\ninterference: a) conventional frequency colouring, b) joint processing within\ncluster, c) partial CSI sharing among clusters, d) partial CSI and data sharing\namong clusters. CSI sharing does not provide considerable performance gains\nwith respect to b) but combined with data sharing offers roughly a 40%\nimprovement over a) and a 15% over b).\n", "contributors": [{"name": "Zheng, Gan", "sameAs": [], "familyName": "Zheng", "additionalName": "", "givenName": "Gan", "email": ""}, {"name": "Chatzinotas, Symeon", "sameAs": [], "familyName": "Chatzinotas", "additionalName": "", "givenName": "Symeon", "email": ""}, {"name": "Ottersten, Bjorn", "sameAs": [], "familyName": "Ottersten", "additionalName": "", "givenName": "Bjorn", "email": ""}], "title": "Multi-Gateway Cooperation in Multibeam Satellite Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-11-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.7094", "oai:arXiv.org:1111.7094"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Multibeam systems with hundreds of beams have been recently deployed in order\nto provide higher capacities by employing fractional frequency reuse.\nFurthermore, employing full frequency reuse and precoding over multiple beams\nhas shown great throughput potential in literature. However, feeding all this\ndata from a single gateway is not feasible based on the current frequency\nallocations. In this context, we investigate a range of scenarios involving\nbeam clusters where each cluster is managed by a single gateway. More\nspecifically, the following cases are considered for handling intercluster\ninterference: a) conventional frequency colouring, b) joint processing within\ncluster, c) partial CSI sharing among clusters, d) partial CSI and data sharing\namong clusters. CSI sharing does not provide considerable performance gains\nwith respect to b) but combined with data sharing offers roughly a 40%\nimprovement over a) and a 15% over b).\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.7094"}}, {"publisher": {"name": ""}, "description": "  Freehand sketches often contain sparse visual detail. In spite of the\nsparsity, they are easily and consistently recognized by humans across\ncultures, languages and age groups. Therefore, analyzing such sparse sketches\ncan aid our understanding of the neuro-cognitive processes involved in visual\nrepresentation and recognition. In the recent past, Convolutional Neural\nNetworks (CNNs) have emerged as a powerful framework for feature representation\nand recognition for a variety of image domains. However, the domain of sketch\nimages has not been explored. This paper introduces a freehand sketch\nrecognition framework based on \"deep\" features extracted from CNNs. We use two\npopular CNNs for our experiments -- Imagenet CNN and a modified version of\nLeNet CNN. We evaluate our recognition framework on a publicly available\nbenchmark database containing thousands of freehand sketches depicting everyday\nobjects. Our results are an improvement over the existing state-of-the-art\naccuracies by 3% - 11%. The effectiveness and relative compactness of our deep\nfeatures also make them an ideal candidate for related problems such as\nsketch-based image retrieval. In addition, we provide a preliminary glimpse of\nhow such features can help identify crucial attributes (e.g. object-parts) of\nthe sketched objects.\n", "contributors": [{"name": "Sarvadevabhatla, Ravi Kiran", "sameAs": [], "familyName": "Sarvadevabhatla", "additionalName": "Kiran", "givenName": "Ravi", "email": ""}, {"name": "Babu, R. Venkatesh", "sameAs": [], "familyName": "Babu", "additionalName": "Venkatesh", "givenName": "R.", "email": ""}], "title": "Freehand Sketch Recognition Using Deep Features", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.00254", "oai:arXiv.org:1502.00254"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Freehand sketches often contain sparse visual detail. In spite of the\nsparsity, they are easily and consistently recognized by humans across\ncultures, languages and age groups. Therefore, analyzing such sparse sketches\ncan aid our understanding of the neuro-cognitive processes involved in visual\nrepresentation and recognition. In the recent past, Convolutional Neural\nNetworks (CNNs) have emerged as a powerful framework for feature representation\nand recognition for a variety of image domains. However, the domain of sketch\nimages has not been explored. This paper introduces a freehand sketch\nrecognition framework based on \"deep\" features extracted from CNNs. We use two\npopular CNNs for our experiments -- Imagenet CNN and a modified version of\nLeNet CNN. We evaluate our recognition framework on a publicly available\nbenchmark database containing thousands of freehand sketches depicting everyday\nobjects. Our results are an improvement over the existing state-of-the-art\naccuracies by 3% - 11%. The effectiveness and relative compactness of our deep\nfeatures also make them an ideal candidate for related problems such as\nsketch-based image retrieval. In addition, we provide a preliminary glimpse of\nhow such features can help identify crucial attributes (e.g. object-parts) of\nthe sketched objects.\n", "Comment: Submitted to ICIP-2015, 5 pages, freehand sketch, object category\n  recognition, convolutional neural network, deep learning, Imagenet, LeNet"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.00254"}}, {"publisher": {"name": ""}, "description": "  In this paper, we present a novel approach for robust optimal resource\nallocation with joint carrier aggregation to allocate multiple carriers\nresources optimally among users with elastic and inelastic traffic in cellular\nnetworks. We use utility proportional fairness allocation policy, where the\nfairness among users is in utility percentage of the application running on the\nuser equipment (UE). Each UE is assigned an application utility function based\non the type of its application. Our objective is to allocate multiple carriers\nresources optimally among users subscribing for mobile services. In addition,\neach user is guaranteed a minimum quality of service (QoS) that varies based on\nthe user's application type. We present a robust algorithm that solves the\ndrawback in the algorithm presented in [1] by preventing the fluctuations in\nthe resource allocation process, in the case of scarce resources, and allocates\noptimal rates for both high-traffic and low-traffic situations. Our distributed\nresource allocation algorithm allocates an optimal rate to each user from all\ncarriers in its range while providing the minimum price for the allocated rate.\nIn addition, we analyze the convergence of the algorithm with different network\ntraffic densities and show that our algorithm provides traffic dependent\npricing for network providers. Finally, we present simulation results for the\nperformance of our resource allocation algorithm.\n", "contributors": [{"name": "Shajaiah, Haya", "sameAs": [], "familyName": "Shajaiah", "additionalName": "", "givenName": "Haya", "email": ""}, {"name": "Abdelhadi, Ahmed", "sameAs": [], "familyName": "Abdelhadi", "additionalName": "", "givenName": "Ahmed", "email": ""}, {"name": "Clancy, T. Charles", "sameAs": [], "familyName": "Clancy", "additionalName": "Charles", "givenName": "T.", "email": ""}], "title": "Robust Resource Allocation with Joint Carrier Aggregation for\n  Multi-Carrier Cellular Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08994", "oai:arXiv.org:1503.08994"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we present a novel approach for robust optimal resource\nallocation with joint carrier aggregation to allocate multiple carriers\nresources optimally among users with elastic and inelastic traffic in cellular\nnetworks. We use utility proportional fairness allocation policy, where the\nfairness among users is in utility percentage of the application running on the\nuser equipment (UE). Each UE is assigned an application utility function based\non the type of its application. Our objective is to allocate multiple carriers\nresources optimally among users subscribing for mobile services. In addition,\neach user is guaranteed a minimum quality of service (QoS) that varies based on\nthe user's application type. We present a robust algorithm that solves the\ndrawback in the algorithm presented in [1] by preventing the fluctuations in\nthe resource allocation process, in the case of scarce resources, and allocates\noptimal rates for both high-traffic and low-traffic situations. Our distributed\nresource allocation algorithm allocates an optimal rate to each user from all\ncarriers in its range while providing the minimum price for the allocated rate.\nIn addition, we analyze the convergence of the algorithm with different network\ntraffic densities and show that our algorithm provides traffic dependent\npricing for network providers. Finally, we present simulation results for the\nperformance of our resource allocation algorithm.\n", "Comment: Submitted to IEEE. arXiv admin note: text overlap with\n  arXiv:1405.6448"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08994"}}, {"publisher": {"name": ""}, "description": "  Distance bounding protocols are security countermeasures designed to thwart\nrelay attacks. Such attacks consist in relaying messages exchanged between two\nparties, making them believe they communicate directly with each other.\nAlthough distance bounding protocols have existed since the early nineties,\nthis research topic resurrected with the deployment of contactless systems,\nagainst which relay attacks are particularly impactful. Given the impressive\nnumber of distance bounding protocols that are designed every year, it becomes\nurgent to provide researchers and engineers with a methodology to fairly\ncompare the protocols in spite of their various properties. This paper\nintroduces such a methodology based on concepts from the decision making field.\nThe methodology allows for a multi-criteria comparison of distance bounding\nprotocols, thereby identifying the most appropriate protocols once the context\nis provided. As a side effect, this paper clearly identifies the protocols that\nshould no longer be considered, regardless of the considered scenario.\n", "contributors": [{"name": "Avoine, Gildas", "sameAs": [], "familyName": "Avoine", "additionalName": "", "givenName": "Gildas", "email": ""}, {"name": "Mauw, Sjouke", "sameAs": [], "familyName": "Mauw", "additionalName": "", "givenName": "Sjouke", "email": ""}, {"name": "Trujillo-Rasua, Rolando", "sameAs": [], "familyName": "Trujillo-Rasua", "additionalName": "", "givenName": "Rolando", "email": ""}], "title": "Comparing Distance Bounding Protocols: a Critical Mission Supported by\n  Decision Theory", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04593", "oai:arXiv.org:1503.04593"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Distance bounding protocols are security countermeasures designed to thwart\nrelay attacks. Such attacks consist in relaying messages exchanged between two\nparties, making them believe they communicate directly with each other.\nAlthough distance bounding protocols have existed since the early nineties,\nthis research topic resurrected with the deployment of contactless systems,\nagainst which relay attacks are particularly impactful. Given the impressive\nnumber of distance bounding protocols that are designed every year, it becomes\nurgent to provide researchers and engineers with a methodology to fairly\ncompare the protocols in spite of their various properties. This paper\nintroduces such a methodology based on concepts from the decision making field.\nThe methodology allows for a multi-criteria comparison of distance bounding\nprotocols, thereby identifying the most appropriate protocols once the context\nis provided. As a side effect, this paper clearly identifies the protocols that\nshould no longer be considered, regardless of the considered scenario.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04593"}}, {"publisher": {"name": ""}, "description": "  Wireless sensor networks are usually composed of a large number of nodes, and\nwith the increasing processing power and power consumption efficiency they are\nexpected to run more complex protocols in the future. These pose problems in\nthe field of verification and performance evaluation of wireless networks. In\nthis paper, we tailor the mean-field theory as a modeling technique to analyze\ntheir behavior. We apply this method to the slotted ALOHA protocol, and\nestablish results on the long term trends of the protocol within a very large\nnetwork, specially regarding the stability of ALOHA-type protocols.\n", "contributors": [{"name": "Talebi, Mahmoud", "sameAs": [], "familyName": "Talebi", "additionalName": "", "givenName": "Mahmoud", "email": ""}, {"name": "Groote, Jan Friso", "sameAs": [], "familyName": "Groote", "additionalName": "Friso", "givenName": "Jan", "email": ""}, {"name": "Linnartz, Jean-Paul", "sameAs": [], "familyName": "Linnartz", "additionalName": "", "givenName": "Jean-Paul", "email": ""}], "title": "Communication Patterns in Mean Field Models for Wireless Sensor Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-26", "2015-04-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07693", "oai:arXiv.org:1503.07693"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Wireless sensor networks are usually composed of a large number of nodes, and\nwith the increasing processing power and power consumption efficiency they are\nexpected to run more complex protocols in the future. These pose problems in\nthe field of verification and performance evaluation of wireless networks. In\nthis paper, we tailor the mean-field theory as a modeling technique to analyze\ntheir behavior. We apply this method to the slotted ALOHA protocol, and\nestablish results on the long term trends of the protocol within a very large\nnetwork, specially regarding the stability of ALOHA-type protocols.\n", "Comment: 22 pages, in LNCS format, Submitted to QEST'15"]}}], "languages": [null], "subjects": ["computer science - performance"], "providerUpdatedDateTime": "2015-04-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07693"}}, {"publisher": {"name": ""}, "description": "  WiMAX, Worldwide Interoperability for Microwave Access, is a developing\nwireless communication scheme that can provide broadband access to large-scale\ncoverage. WiMAX belongs to the family of standards of IEEE-802.16. To satisfy\nuser demands and support a new set of real time services and applications, a\nrealistic and dynamic resource allocation algorithm is mandatory. One of the\nmost efficient algorithm is EDF (earliest deadline first). But the problem is\nthat when the difference between deadlines is large enough, then lower priority\nqueues have to starve. So in this paper, we present a heuristic earliest\ndeadline first (H-EDF) approach of the uplink scheduler of the WiMAX real time\nsystem. This H-EDF presents a way for efficient allocation of the bandwidth for\nuplink, so that bandwidth utilization is proper and appropriate fairness is\nprovided to the system. We use Opnet simulator for implementing the WiMAX\nnetwork, which uses this H-EDF scheduling algorithm. We will analysis the\nperformance of the H-EDF algorithm in consideration with throughput as well as\ninvolvement of delay.\n", "contributors": [{"name": "Lal, Nidhi", "sameAs": [], "familyName": "Lal", "additionalName": "", "givenName": "Nidhi", "email": ""}, {"name": "Singh, Anurag Prakash", "sameAs": [], "familyName": "Singh", "additionalName": "Prakash", "givenName": "Anurag", "email": ""}, {"name": "Kumar, Shishupal", "sameAs": [], "familyName": "Kumar", "additionalName": "", "givenName": "Shishupal", "email": ""}, {"name": "Mittal, Shikha", "sameAs": [], "familyName": "Mittal", "additionalName": "", "givenName": "Shikha", "email": ""}, {"name": "Singh, Meenakshi", "sameAs": [], "familyName": "Singh", "additionalName": "", "givenName": "Meenakshi", "email": ""}], "title": "A Heuristic EDF Uplink Scheduler for Real Time Application in WiMAX\n  Communication", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04553", "oai:arXiv.org:1501.04553"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  WiMAX, Worldwide Interoperability for Microwave Access, is a developing\nwireless communication scheme that can provide broadband access to large-scale\ncoverage. WiMAX belongs to the family of standards of IEEE-802.16. To satisfy\nuser demands and support a new set of real time services and applications, a\nrealistic and dynamic resource allocation algorithm is mandatory. One of the\nmost efficient algorithm is EDF (earliest deadline first). But the problem is\nthat when the difference between deadlines is large enough, then lower priority\nqueues have to starve. So in this paper, we present a heuristic earliest\ndeadline first (H-EDF) approach of the uplink scheduler of the WiMAX real time\nsystem. This H-EDF presents a way for efficient allocation of the bandwidth for\nuplink, so that bandwidth utilization is proper and appropriate fairness is\nprovided to the system. We use Opnet simulator for implementing the WiMAX\nnetwork, which uses this H-EDF scheduling algorithm. We will analysis the\nperformance of the H-EDF algorithm in consideration with throughput as well as\ninvolvement of delay.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04553"}}, {"publisher": {"name": ""}, "description": "  In this work, we study the single machine scheduling problem with uncertain\nrelease times and processing times of jobs. We adopt a robust scheduling\napproach, in which the measure of robustness to be minimized for a given\nsequence of jobs is the worst-case objective function value from the set of all\npossible realizations of release and processing times. The objective function\nvalue is the total flow time of all jobs. We discuss some important properties\nof robust schedules for zero and non-zero release times, and illustrate the\nadded complexity in robust scheduling given non-zero release times. We propose\nheuristics based on variable neighborhood search and iterated local search to\nsolve the problem and generate robust schedules. The algorithms are tested and\ntheir solution performance is compared with optimal solutions or lower bounds\nthrough numerical experiments based on synthetic data.\n", "contributors": [{"name": "Umang, Nitish", "sameAs": [], "familyName": "Umang", "additionalName": "", "givenName": "Nitish", "email": ""}, {"name": "Erera, Alan L.", "sameAs": [], "familyName": "Erera", "additionalName": "L.", "givenName": "Alan", "email": ""}, {"name": "Bierlaire, Michel", "sameAs": [], "familyName": "Bierlaire", "additionalName": "", "givenName": "Michel", "email": ""}], "title": "The robust single machine scheduling problem with uncertain release and\n  processing times", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7101", "oai:arXiv.org:1411.7101"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this work, we study the single machine scheduling problem with uncertain\nrelease times and processing times of jobs. We adopt a robust scheduling\napproach, in which the measure of robustness to be minimized for a given\nsequence of jobs is the worst-case objective function value from the set of all\npossible realizations of release and processing times. The objective function\nvalue is the total flow time of all jobs. We discuss some important properties\nof robust schedules for zero and non-zero release times, and illustrate the\nadded complexity in robust scheduling given non-zero release times. We propose\nheuristics based on variable neighborhood search and iterated local search to\nsolve the problem and generate robust schedules. The algorithms are tested and\ntheir solution performance is compared with optimal solutions or lower bounds\nthrough numerical experiments based on synthetic data.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - data structures and algorithms"], "providerUpdatedDateTime": "2014-11-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7101"}}, {"publisher": {"name": ""}, "description": "  Massive Multiple-Input Multiple-Output (MIMO) is foreseen to be one of the\nmain technology components in next generation cellular communications (5G). In\nthis paper, fundamental limits on the performance of downlink massive MIMO\nsystems are investigated by means of simulations and analytical analysis.\nSignal-to-noise-and-interference ratio (SINR) and sum rate for a single-cell\nscenario multi-user MIMO are analyzed for different array sizes, channel\nmodels, and precoding schemes. The impact of hardware impairments on\nperformance is also investigated. Simple approximations are derived that show\nexplicitly how the number of antennas, number of served users, transmit power,\nand magnitude of hardware impairments affect performance.\n", "contributors": [{"name": "Athley, Fredrik", "sameAs": [], "familyName": "Athley", "additionalName": "", "givenName": "Fredrik", "email": ""}, {"name": "Durisi, Giuseppe", "sameAs": [], "familyName": "Durisi", "additionalName": "", "givenName": "Giuseppe", "email": ""}, {"name": "Gustavsson, Ulf", "sameAs": [], "familyName": "Gustavsson", "additionalName": "", "givenName": "Ulf", "email": ""}], "title": "Analysis of Massive MIMO With Hardware Impairments and Different Channel\n  Models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04200", "oai:arXiv.org:1501.04200"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Massive Multiple-Input Multiple-Output (MIMO) is foreseen to be one of the\nmain technology components in next generation cellular communications (5G). In\nthis paper, fundamental limits on the performance of downlink massive MIMO\nsystems are investigated by means of simulations and analytical analysis.\nSignal-to-noise-and-interference ratio (SINR) and sum rate for a single-cell\nscenario multi-user MIMO are analyzed for different array sizes, channel\nmodels, and precoding schemes. The impact of hardware impairments on\nperformance is also investigated. Simple approximations are derived that show\nexplicitly how the number of antennas, number of served users, transmit power,\nand magnitude of hardware impairments affect performance.\n", "Comment: 5 pages, 5 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04200"}}, {"publisher": {"name": ""}, "description": "abstract: Advancements in computer vision and machine learning have added a new dimension to remote sensing applications with the aid of imagery analysis techniques. Applications such as autonomous navigation and terrain classification which make use of image classification techniques are challenging problems and research is still being carried out to find better solutions. In this thesis, a novel method is proposed which uses image registration techniques to provide better image classification. This method reduces the error rate of classification by performing image registration of the images with the previously obtained images before performing classification. The motivation behind this is the fact that images that are obtained in the same region which need to be classified will not differ significantly in characteristics. Hence, registration will provide an image that matches closer to the previously obtained image, thus providing better classification. To illustrate that the proposed method works, na\u00efve Bayes and iterative closest point (ICP) algorithms are used for the image classification and registration stages respectively. This implementation was tested extensively in simulation using synthetic images and using a real life data set called the Defense Advanced Research Project Agency (DARPA) Learning Applied to Ground Robots (LAGR) dataset. The results show that the ICP algorithm does help in better classification with Na\u00efve Bayes by reducing the error rate by an average of about 10% in the synthetic data and by about 7% on the actual datasets used.", "contributors": [{"name": "Muralidhar, Ashwini  (Author)", "sameAs": [], "familyName": "Muralidhar", "additionalName": "", "givenName": "Ashwini", "email": ""}, {"name": "Saripalli, Srikanth  (Advisor)", "sameAs": [], "familyName": "Saripalli", "additionalName": "", "givenName": "Srikanth", "email": ""}, {"name": "Papandreou-Suppappola, Antonia  (Committee member)", "sameAs": [], "familyName": "Papandreou-Suppappola", "additionalName": "", "givenName": "Antonia", "email": ""}, {"name": "Turaga, Pavan  (Committee member)", "sameAs": [], "familyName": "Turaga", "additionalName": "", "givenName": "Pavan", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Augmented Image Classification using Image Registration Techniques", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Masters Thesis"}}, {"name": "format", "properties": {"format": "55 pages"}}, {"name": "date", "properties": {"date": "2011"}}, {"name": "description", "properties": {"description": ["abstract: Advancements in computer vision and machine learning have added a new dimension to remote sensing applications with the aid of imagery analysis techniques. Applications such as autonomous navigation and terrain classification which make use of image classification techniques are challenging problems and research is still being carried out to find better solutions. In this thesis, a novel method is proposed which uses image registration techniques to provide better image classification. This method reduces the error rate of classification by performing image registration of the images with the previously obtained images before performing classification. The motivation behind this is the fact that images that are obtained in the same region which need to be classified will not differ significantly in characteristics. Hence, registration will provide an image that matches closer to the previously obtained image, thus providing better classification. To illustrate that the proposed method works, na\u00efve Bayes and iterative closest point (ICP) algorithms are used for the image classification and registration stages respectively. This implementation was tested extensively in simulation using synthetic images and using a real life data set called the Defense Advanced Research Project Agency (DARPA) Learning Applied to Ground Robots (LAGR) dataset. The results show that the ICP algorithm does help in better classification with Na\u00efve Bayes by reducing the error rate by an average of about 10% in the synthetic data and by about 7% on the actual datasets used.", "Dissertation/Thesis", "M.S. Electrical Engineering 2011"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.14376", "item:14376"]}}], "languages": [null], "subjects": ["classification", "robotics", "terrain classification", "autonomous navigation", "computer science", "registration", "electrical engineering"], "providerUpdatedDateTime": "2015-02-12T01:13:08", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.14376"}}, {"publisher": {"name": ""}, "description": "  Copyless streaming string transducers (copyless SST) have been introduced by\nR. Alur and P. Cerny in 2010 as a one-way deterministic automata model to\ndefine transformations of finite strings. Copyless SST extend deterministic\nfinite state automata with a set of registers in which to store intermediate\noutput strings, and those registers can be combined and updated all along the\nrun, in a linear manner, i.e., no register content can be copied on\ntransitions. It is known that copyless SST capture exactly the class of\nMSO-definable string-to-string transformations, as defined by B. Courcelle, and\nare equi-expressive to deterministic two-way transducers. They enjoy good\nalgorithmic properties. Most notably, they have decidable equivalence problem\n(in PSpace). In this paper, we show that they still have decidable equivalence\nproblem even without the copyless restriction. The proof reduces to the HDT0L\nsequence equivalence problem, which is known to be decidable. We also show that\nthis latter problem is as difficult as the SST equivalence problem, modulo\nlinear time reduction.\n", "contributors": [{"name": "Filiot, Emmanuel", "sameAs": [], "familyName": "Filiot", "additionalName": "", "givenName": "Emmanuel", "email": ""}, {"name": "Reynier, Pierre-Alain", "sameAs": [], "familyName": "Reynier", "additionalName": "", "givenName": "Pierre-Alain", "email": ""}], "title": "On Streaming String Transducers and HDT0L Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.0537", "oai:arXiv.org:1412.0537"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Copyless streaming string transducers (copyless SST) have been introduced by\nR. Alur and P. Cerny in 2010 as a one-way deterministic automata model to\ndefine transformations of finite strings. Copyless SST extend deterministic\nfinite state automata with a set of registers in which to store intermediate\noutput strings, and those registers can be combined and updated all along the\nrun, in a linear manner, i.e., no register content can be copied on\ntransitions. It is known that copyless SST capture exactly the class of\nMSO-definable string-to-string transformations, as defined by B. Courcelle, and\nare equi-expressive to deterministic two-way transducers. They enjoy good\nalgorithmic properties. Most notably, they have decidable equivalence problem\n(in PSpace). In this paper, we show that they still have decidable equivalence\nproblem even without the copyless restriction. The proof reduces to the HDT0L\nsequence equivalence problem, which is known to be decidable. We also show that\nthis latter problem is as difficult as the SST equivalence problem, modulo\nlinear time reduction.\n"}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "computer science - logic in computer science"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.0537"}}, {"publisher": {"name": ""}, "description": "  Finite mixture models are statistical models which appear in many problems in\nstatistics and machine learning. In such models it is assumed that data are\ndrawn from random probability measures, called mixture components, which are\nthemselves drawn from a probability measure P over probability measures. When\nestimating mixture models, it is common to make assumptions on the mixture\ncomponents, such as parametric assumptions. In this paper, we make no\nassumption on the mixture components, and instead assume that observations from\nthe mixture model are grouped, such that observations in the same group are\nknown to be drawn from the same component. We show that any mixture of m\nprobability measures can be uniquely identified provided there are 2m-1\nobservations per group. Moreover we show that, for any m, there exists a\nmixture of m probability measures that cannot be uniquely identified when\ngroups have 2m-2 observations. Our results hold for any sample space with more\nthan one element.\n", "contributors": [{"name": "Vandermeulen, Robert A.", "sameAs": [], "familyName": "Vandermeulen", "additionalName": "A.", "givenName": "Robert", "email": ""}, {"name": "Scott, Clayton D.", "sameAs": [], "familyName": "Scott", "additionalName": "D.", "givenName": "Clayton", "email": ""}], "title": "On The Identifiability of Mixture Models from Grouped Samples", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06644", "oai:arXiv.org:1502.06644"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  Finite mixture models are statistical models which appear in many problems in\nstatistics and machine learning. In such models it is assumed that data are\ndrawn from random probability measures, called mixture components, which are\nthemselves drawn from a probability measure P over probability measures. When\nestimating mixture models, it is common to make assumptions on the mixture\ncomponents, such as parametric assumptions. In this paper, we make no\nassumption on the mixture components, and instead assume that observations from\nthe mixture model are grouped, such that observations in the same group are\nknown to be drawn from the same component. We show that any mixture of m\nprobability measures can be uniquely identified provided there are 2m-1\nobservations per group. Moreover we show that, for any m, there exists a\nmixture of m probability measures that cannot be uniquely identified when\ngroups have 2m-2 observations. Our results hold for any sample space with more\nthan one element.\n"}}], "languages": [null], "subjects": ["mathematics - statistics theory", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-02-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06644"}}, {"publisher": {"name": ""}, "description": "  Discovering the 3D atomic structure of molecules such as proteins and viruses\nis a fundamental research problem in biology and medicine. Electron\nCryomicroscopy (Cryo-EM) is a promising vision-based technique for structure\nestimation which attempts to reconstruct 3D structures from 2D images. This\npaper addresses the challenging problem of 3D reconstruction from 2D Cryo-EM\nimages. A new framework for estimation is introduced which relies on modern\nstochastic optimization techniques to scale to large datasets. We also\nintroduce a novel technique which reduces the cost of evaluating the objective\nfunction during optimization by over five orders or magnitude. The net result\nis an approach capable of estimating 3D molecular structure from large scale\ndatasets in about a day on a single workstation.\n", "contributors": [{"name": "Brubaker, Marcus A.", "sameAs": [], "familyName": "Brubaker", "additionalName": "A.", "givenName": "Marcus", "email": ""}, {"name": "Punjani, Ali", "sameAs": [], "familyName": "Punjani", "additionalName": "", "givenName": "Ali", "email": ""}, {"name": "Fleet, David J.", "sameAs": [], "familyName": "Fleet", "additionalName": "J.", "givenName": "David", "email": ""}], "title": "Building Proteins in a Day: Efficient 3D Molecular Reconstruction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03573", "oai:arXiv.org:1504.03573"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": ["  Discovering the 3D atomic structure of molecules such as proteins and viruses\nis a fundamental research problem in biology and medicine. Electron\nCryomicroscopy (Cryo-EM) is a promising vision-based technique for structure\nestimation which attempts to reconstruct 3D structures from 2D images. This\npaper addresses the challenging problem of 3D reconstruction from 2D Cryo-EM\nimages. A new framework for estimation is introduced which relies on modern\nstochastic optimization techniques to scale to large datasets. We also\nintroduce a novel technique which reduces the cost of evaluating the objective\nfunction during optimization by over five orders or magnitude. The net result\nis an approach capable of estimating 3D molecular structure from large scale\ndatasets in about a day on a single workstation.\n", "Comment: To be presented at IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2015"]}}], "languages": [null], "subjects": ["quantitative biology - quantitative methods", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-04-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03573"}}, {"publisher": {"name": ""}, "description": "  We give an algebraic characterization of when a $d$-dimensional periodic\nframework has no non-trivial, symmetry preserving, motion for any choice of\nperiodicity lattice. Our condition is decidable, and we provide a simple\nalgorithm that does not require complicated algebraic computations. In\ndimension $d = 2$, we give a combinatorial characterization in the special case\nwhen the the number of edge orbits is the minimum possible for ultrarigidity.\nAll our results apply to a fully flexible, fixed area, or fixed periodicity\nlattice.\n", "contributors": [{"name": "Malestein, Justin", "sameAs": [], "familyName": "Malestein", "additionalName": "", "givenName": "Justin", "email": ""}, {"name": "Theran, Louis", "sameAs": [], "familyName": "Theran", "additionalName": "", "givenName": "Louis", "email": ""}], "title": "Ultrarigid periodic frameworks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-08", "2015-03-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.2319", "oai:arXiv.org:1404.2319"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We give an algebraic characterization of when a $d$-dimensional periodic\nframework has no non-trivial, symmetry preserving, motion for any choice of\nperiodicity lattice. Our condition is decidable, and we provide a simple\nalgorithm that does not require complicated algebraic computations. In\ndimension $d = 2$, we give a combinatorial characterization in the special case\nwhen the the number of edge orbits is the minimum possible for ultrarigidity.\nAll our results apply to a fully flexible, fixed area, or fixed periodicity\nlattice.\n", "Comment: 34 pages, 3 figures (v4, updated references and discussion, author\n  contact data)"]}}], "languages": [null], "subjects": ["mathematics - metric geometry", "mathematics - combinatorics", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.2319"}}, {"publisher": {"name": ""}, "description": "  We present an algorithm that generates multiset permutations in O(1) time for\neach permutation, that is, by a loop-less algorithm with O(n) extra memory\nrequirement. There already exist several such algorithms that generate multiset\npermutations in various orders. For multiset permutations, we combine two\nloop-less algorithms that are designed in the same principle of tree traversal.\nOur order of generation is different from any existing order, and the algorithm\nis simpler and faster than the previous ones. We also apply the new algorithm\nto parking functions.\n", "contributors": [{"name": "Takaoka, Tadao", "sameAs": [], "familyName": "Takaoka", "additionalName": "", "givenName": "Tadao", "email": ""}], "title": "Multi-level Loop-less Algorithm for Multi-set Permutations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06062", "oai:arXiv.org:1502.06062"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We present an algorithm that generates multiset permutations in O(1) time for\neach permutation, that is, by a loop-less algorithm with O(n) extra memory\nrequirement. There already exist several such algorithms that generate multiset\npermutations in various orders. For multiset permutations, we combine two\nloop-less algorithms that are designed in the same principle of tree traversal.\nOur order of generation is different from any existing order, and the algorithm\nis simpler and faster than the previous ones. We also apply the new algorithm\nto parking functions.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06062"}}, {"publisher": {"name": ""}, "description": "  Given an analytic singular foliation $\\omega$ with $n$ first integrals\n$(f_1,...,f_n)$ such that $df_1 \\wedge ..., df_n \\not\\equiv 0$, we prove that\nthere exists a local monomialization of the system of first integrals, i.e.\nthere exist sequences of local blowings-up such that the strict transform of\n$\\omega$ has $n$ monomial first integrals $(\\mathbf{x}^{\\boldsymbol{\\alpha}_1},\n..., \\mathbf{x}^{\\boldsymbol{\\alpha}_n})$, where\n$\\mathbf{x}^{\\boldsymbol{\\alpha}_i} = x_1^{\\alpha_{i,1}} ...\nx_m^{\\alpha_{i,m}}$ and the set of multi-indexes $(\\boldsymbol{\\alpha}_1,\n...,\\boldsymbol{\\alpha}_n)$ is linearly independent.\n", "contributors": [{"name": "Belotto, Andr\u00e9", "sameAs": [], "familyName": "Belotto", "additionalName": "", "givenName": "Andr\u00e9", "email": ""}], "title": "Local monomialization of a system of first integrals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5333", "oai:arXiv.org:1411.5333"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Given an analytic singular foliation $\\omega$ with $n$ first integrals\n$(f_1,...,f_n)$ such that $df_1 \\wedge ..., df_n \\not\\equiv 0$, we prove that\nthere exists a local monomialization of the system of first integrals, i.e.\nthere exist sequences of local blowings-up such that the strict transform of\n$\\omega$ has $n$ monomial first integrals $(\\mathbf{x}^{\\boldsymbol{\\alpha}_1},\n..., \\mathbf{x}^{\\boldsymbol{\\alpha}_n})$, where\n$\\mathbf{x}^{\\boldsymbol{\\alpha}_i} = x_1^{\\alpha_{i,1}} ...\nx_m^{\\alpha_{i,m}}$ and the set of multi-indexes $(\\boldsymbol{\\alpha}_1,\n...,\\boldsymbol{\\alpha}_n)$ is linearly independent.\n", "Comment: arXiv admin note: text overlap with arXiv:1411.5009"]}}], "languages": [null], "subjects": ["mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5333"}}, {"publisher": {"name": ""}, "description": "  In the landscape of application ecosystems, today's cloud users wish to\npersonalize not only their browsers with various extensions or their\nsmartphones with various applications, but also the various extensions and\napplications themselves. The resulting personalization significantly raises the\nattractiveness for typical Web 2.0 users, but gives rise to various security\nrisks and privacy concerns, such as unforeseen access to certain critical\ncomponents, undesired information flow of personal information to untrusted\napplications, or emerging attack surfaces that were not possible before a\npersonalization has taken place.\n  In this paper, we propose a novel extensibility mechanism which is used for\nimplementing personalization of existing cloud applications towards (possibly\nuntrusted) components in a secure and privacy-friendly manner. Our model\nprovides a clean component abstraction, thereby in particular ruling out\nundesired component accesses and ensuring that no undesired information flow\ntakes place between application components -- either trusted from the base\napplication or untrusted from various extensions. We then instantiate our model\nin the SAFE web application framework (WWW 2012), resulting in a novel\nmethodology that is inspired by traditional access control and specifically\ndesigned for the newly emerging needs of extensibility in application\necosystems. We illustrate the convenient usage of our techniques by showing how\nto securely extend an existing social network application.\n", "contributors": [{"name": "Schr\u00f6der, Florian", "sameAs": [], "familyName": "Schr\u00f6der", "additionalName": "", "givenName": "Florian", "email": ""}, {"name": "Reischuk, Raphael M.", "sameAs": [], "familyName": "Reischuk", "additionalName": "M.", "givenName": "Raphael", "email": ""}, {"name": "Gehrke, Johannes", "sameAs": [], "familyName": "Gehrke", "additionalName": "", "givenName": "Johannes", "email": ""}], "title": "Balancing Isolation and Sharing of Data for Third-Party Extensible App\n  Ecosystems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-24", "2015-04-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7641", "oai:arXiv.org:1412.7641"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In the landscape of application ecosystems, today's cloud users wish to\npersonalize not only their browsers with various extensions or their\nsmartphones with various applications, but also the various extensions and\napplications themselves. The resulting personalization significantly raises the\nattractiveness for typical Web 2.0 users, but gives rise to various security\nrisks and privacy concerns, such as unforeseen access to certain critical\ncomponents, undesired information flow of personal information to untrusted\napplications, or emerging attack surfaces that were not possible before a\npersonalization has taken place.\n  In this paper, we propose a novel extensibility mechanism which is used for\nimplementing personalization of existing cloud applications towards (possibly\nuntrusted) components in a secure and privacy-friendly manner. Our model\nprovides a clean component abstraction, thereby in particular ruling out\nundesired component accesses and ensuring that no undesired information flow\ntakes place between application components -- either trusted from the base\napplication or untrusted from various extensions. We then instantiate our model\nin the SAFE web application framework (WWW 2012), resulting in a novel\nmethodology that is inspired by traditional access control and specifically\ndesigned for the newly emerging needs of extensibility in application\necosystems. We illustrate the convenient usage of our techniques by showing how\nto securely extend an existing social network application.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2014-12-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7641"}}, {"publisher": {"name": ""}, "description": "  Multi-target tracking is mainly challenged by the nonlinearity present in the\nmeasurement equation, and the difficulty in fast and accurate data association.\nTo overcome these challenges, the present paper introduces a grid-based model\nin which the state captures target signal strengths on a known spatial grid\n(TSSG). This model leads to \\emph{linear} state and measurement equations,\nwhich bypass data association and can afford state estimation via\nsparsity-aware Kalman filtering (KF). Leveraging the grid-induced sparsity of\nthe novel model, two types of sparsity-cognizant TSSG-KF trackers are\ndeveloped: one effects sparsity through $\\ell_1$-norm regularization, and the\nother invokes sparsity as an extra measurement. Iterative extended KF and\nGauss-Newton algorithms are developed for reduced-complexity tracking, along\nwith accurate error covariance updates for assessing performance of the\nresultant sparsity-aware state estimators. Based on TSSG state estimates, more\ninformative target position and track estimates can be obtained in a follow-up\nstep, ensuring that track association and position estimation errors do not\npropagate back into TSSG state estimates. The novel TSSG trackers do not\nrequire knowing the number of targets or their signal strengths, and exhibit\nconsiderably lower complexity than the benchmark hidden Markov model filter,\nespecially for a large number of targets. Numerical simulations demonstrate\nthat sparsity-cognizant trackers enjoy improved root mean-square error\nperformance at reduced complexity when compared to their sparsity-agnostic\ncounterparts.\n", "contributors": [{"name": "Farahmand, Shahrokh", "sameAs": [], "familyName": "Farahmand", "additionalName": "", "givenName": "Shahrokh", "email": ""}, {"name": "Giannakis, Georgios B.", "sameAs": [], "familyName": "Giannakis", "additionalName": "B.", "givenName": "Georgios", "email": ""}, {"name": "Leus, Geert", "sameAs": [], "familyName": "Leus", "additionalName": "", "givenName": "Geert", "email": ""}, {"name": "Tian, Zhi", "sameAs": [], "familyName": "Tian", "additionalName": "", "givenName": "Zhi", "email": ""}], "title": "Tracking Target Signal Strengths on a Grid using Sparsity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-04-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.5288", "oai:arXiv.org:1104.5288"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  Multi-target tracking is mainly challenged by the nonlinearity present in the\nmeasurement equation, and the difficulty in fast and accurate data association.\nTo overcome these challenges, the present paper introduces a grid-based model\nin which the state captures target signal strengths on a known spatial grid\n(TSSG). This model leads to \\emph{linear} state and measurement equations,\nwhich bypass data association and can afford state estimation via\nsparsity-aware Kalman filtering (KF). Leveraging the grid-induced sparsity of\nthe novel model, two types of sparsity-cognizant TSSG-KF trackers are\ndeveloped: one effects sparsity through $\\ell_1$-norm regularization, and the\nother invokes sparsity as an extra measurement. Iterative extended KF and\nGauss-Newton algorithms are developed for reduced-complexity tracking, along\nwith accurate error covariance updates for assessing performance of the\nresultant sparsity-aware state estimators. Based on TSSG state estimates, more\ninformative target position and track estimates can be obtained in a follow-up\nstep, ensuring that track association and position estimation errors do not\npropagate back into TSSG state estimates. The novel TSSG trackers do not\nrequire knowing the number of targets or their signal strengths, and exhibit\nconsiderably lower complexity than the benchmark hidden Markov model filter,\nespecially for a large number of targets. Numerical simulations demonstrate\nthat sparsity-cognizant trackers enjoy improved root mean-square error\nperformance at reduced complexity when compared to their sparsity-agnostic\ncounterparts.\n", "Comment: Submitted to IEEE Trans. on Signal Processing"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "statistics - applications"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.5288"}}, {"publisher": {"name": ""}, "description": "  A novel family of twelve mixture models with random covariates, nested in the\nlinear $t$ cluster-weighted model (CWM), is introduced for model-based\nclustering. The linear $t$ CWM was recently presented as a robust alternative\nto the better known linear Gaussian CWM. The proposed family of models provides\na unified framework that also includes the linear Gaussian CWM as a special\ncase. Maximum likelihood parameter estimation is carried out within the EM\nframework, and both the BIC and the ICL are used for model selection. A simple\nand effective hierarchical random initialization is also proposed for the EM\nalgorithm. The novel model-based clustering technique is illustrated in some\napplications to real data. Finally, a simulation study for evaluating the\nperformance of the BIC and the ICL is presented.\n", "contributors": [{"name": "Ingrassia, Salvatore", "sameAs": [], "familyName": "Ingrassia", "additionalName": "", "givenName": "Salvatore", "email": ""}, {"name": "Minotti, Simona C.", "sameAs": [], "familyName": "Minotti", "additionalName": "C.", "givenName": "Simona", "email": ""}, {"name": "Punzo, Antonio", "sameAs": [], "familyName": "Punzo", "additionalName": "", "givenName": "Antonio", "email": ""}], "title": "Model-based clustering via linear cluster-weighted models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-06-18", "2015-03-09"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1206.3974", "Computational Statistics and Data Analysis, 71(4): 159-182, 2014", "doi:10.1016/j.csda.2013.02.012", "oai:arXiv.org:1206.3974"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  A novel family of twelve mixture models with random covariates, nested in the\nlinear $t$ cluster-weighted model (CWM), is introduced for model-based\nclustering. The linear $t$ CWM was recently presented as a robust alternative\nto the better known linear Gaussian CWM. The proposed family of models provides\na unified framework that also includes the linear Gaussian CWM as a special\ncase. Maximum likelihood parameter estimation is carried out within the EM\nframework, and both the BIC and the ICL are used for model selection. A simple\nand effective hierarchical random initialization is also proposed for the EM\nalgorithm. The novel model-based clustering technique is illustrated in some\napplications to real data. Finally, a simulation study for evaluating the\nperformance of the BIC and the ICL is presented.\n"}}], "languages": [null], "subjects": ["statistics - computation"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1206.3974"}}, {"publisher": {"name": ""}, "description": "  In the space of holomorphic functions in a convex domain it is studied the\ninterpolation problem by means of sums of the series of exponentials converging\nuniformly on all compact sets of the domain. The discrete set of the\ninterpolation nodes with multiplicities is located on the real axis in the\ndomain and it has the only finite limit point. It is obtained a criterion for\nsolvability of the problem in the terms of distribution of limit directions of\nexponents of exponentials at infinity.\n", "contributors": [{"name": "Merzlyakov, S. G.", "sameAs": [], "familyName": "Merzlyakov", "additionalName": "G.", "givenName": "S.", "email": ""}, {"name": "Popenov, S. V.", "sameAs": [], "familyName": "Popenov", "additionalName": "V.", "givenName": "S.", "email": ""}], "title": "Interpolation by means of series of exponentials in H(D) with real nodes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3147", "oai:arXiv.org:1411.3147"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  In the space of holomorphic functions in a convex domain it is studied the\ninterpolation problem by means of sums of the series of exponentials converging\nuniformly on all compact sets of the domain. The discrete set of the\ninterpolation nodes with multiplicities is located on the real axis in the\ndomain and it has the only finite limit point. It is obtained a criterion for\nsolvability of the problem in the terms of distribution of limit directions of\nexponents of exponentials at infinity.\n", "Comment: 14 pages, in Russian"]}}], "languages": [null], "subjects": ["30e05", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3147"}}, {"publisher": {"name": ""}, "description": "  We consider high-dimensional sparse regression problems in which we observe\n$y = X \\beta + z$, where $X$ is an $n \\times p$ design matrix and $z$ is an\n$n$-dimensional vector of independent Gaussian errors, each with variance\n$\\sigma^2$. Our focus is on the recently introduced SLOPE estimator (Bogdan et\nal., 2014), which regularizes the least-squares estimates with the\nrank-dependent penalty $\\sum_{1 \\le i \\le p} \\lambda_i |\\hat \\beta|_{(i)}$,\nwhere $|\\hat \\beta|_{(i)}$ is the $i$th largest magnitude of the fitted\ncoefficients. Under Gaussian designs, where the entries of $X$ are i.i.d.\n$\\mathcal{N}(0, 1/n)$, we show that SLOPE, with weights $\\lambda_i$ just about\nequal to $\\sigma \\cdot \\Phi^{-1}(1-iq/(2p))$ ($\\Phi^{-1}(\\alpha)$ is the\n$\\alpha$th quantile of a standard normal and $q$ is a fixed number in $(0,1)$)\nachieves a squared error of estimation obeying \\[ \\sup_{\\|\\beta\\|_0 \\le k} \\,\\,\n\\mathbb{P}\\left(\\| \\hat\\beta_{SLOPE} - \\beta \\|^2 > (1+\\epsilon) \\, 2\\sigma^2 k\n\\log(p/k) \\right) \\longrightarrow 0 \\] as the dimension $p$ increases to\n$\\infty$, and where $\\epsilon > 0$ is an arbitrary small constant. This holds\nunder weak assumptions on the sparsity level $k$ and is sharp in the sense that\nthis is the best possible error {\\em any} estimator can achieve. A remarkable\nfeature is that SLOPE does not require any knowledge of the degree of sparsity,\nand yet automatically adapts to yield optimal total squared errors over a wide\nrange of sparsity classes. We are not aware of any other estimator with this\nproperty.\n", "contributors": [{"name": "Su, Weijie", "sameAs": [], "familyName": "Su", "additionalName": "", "givenName": "Weijie", "email": ""}, {"name": "Candes, Emmanuel", "sameAs": [], "familyName": "Candes", "additionalName": "", "givenName": "Emmanuel", "email": ""}], "title": "SLOPE is Adaptive to Unknown Sparsity and Asymptotically Minimax", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-29", "2015-04-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08393", "oai:arXiv.org:1503.08393"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  We consider high-dimensional sparse regression problems in which we observe\n$y = X \\beta + z$, where $X$ is an $n \\times p$ design matrix and $z$ is an\n$n$-dimensional vector of independent Gaussian errors, each with variance\n$\\sigma^2$. Our focus is on the recently introduced SLOPE estimator (Bogdan et\nal., 2014), which regularizes the least-squares estimates with the\nrank-dependent penalty $\\sum_{1 \\le i \\le p} \\lambda_i |\\hat \\beta|_{(i)}$,\nwhere $|\\hat \\beta|_{(i)}$ is the $i$th largest magnitude of the fitted\ncoefficients. Under Gaussian designs, where the entries of $X$ are i.i.d.\n$\\mathcal{N}(0, 1/n)$, we show that SLOPE, with weights $\\lambda_i$ just about\nequal to $\\sigma \\cdot \\Phi^{-1}(1-iq/(2p))$ ($\\Phi^{-1}(\\alpha)$ is the\n$\\alpha$th quantile of a standard normal and $q$ is a fixed number in $(0,1)$)\nachieves a squared error of estimation obeying \\[ \\sup_{\\|\\beta\\|_0 \\le k} \\,\\,\n\\mathbb{P}\\left(\\| \\hat\\beta_{SLOPE} - \\beta \\|^2 > (1+\\epsilon) \\, 2\\sigma^2 k\n\\log(p/k) \\right) \\longrightarrow 0 \\] as the dimension $p$ increases to\n$\\infty$, and where $\\epsilon > 0$ is an arbitrary small constant. This holds\nunder weak assumptions on the sparsity level $k$ and is sharp in the sense that\nthis is the best possible error {\\em any} estimator can achieve. A remarkable\nfeature is that SLOPE does not require any knowledge of the degree of sparsity,\nand yet automatically adapts to yield optimal total squared errors over a wide\nrange of sparsity classes. We are not aware of any other estimator with this\nproperty.\n", "Comment: Add citations"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08393"}}, {"publisher": {"name": ""}, "description": "  We propose a new speed and departure time optimization algorithm for the\nPollution-Routing Problem (PRP) which runs in quadratic time. This algorithm is\nembedded into an iterated local search-based metaheuristic to achieve a\ncombined speed, scheduling and routing optimization. Extensive computational\nexperiments are conducted on classic PRP benchmark instances. Allowing delayed\ndeparture times from the depot significantly increases the search space, and\ncontributes to reduce CO 2 emissions by 8.31% on the considered instances.\n", "contributors": [{"name": "Kramer, Raphael", "sameAs": [], "familyName": "Kramer", "additionalName": "", "givenName": "Raphael", "email": ""}, {"name": "Maculan, Nelson", "sameAs": [], "familyName": "Maculan", "additionalName": "", "givenName": "Nelson", "email": ""}, {"name": "Subramanian, Anand", "sameAs": [], "familyName": "Subramanian", "additionalName": "", "givenName": "Anand", "email": ""}, {"name": "Vidal, Thibaut", "sameAs": [], "familyName": "Vidal", "additionalName": "", "givenName": "Thibaut", "email": ""}], "title": "A speed and departure time optimization algorithm for the\n  Pollution-Routing Problem", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05354", "oai:arXiv.org:1501.05354"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We propose a new speed and departure time optimization algorithm for the\nPollution-Routing Problem (PRP) which runs in quadratic time. This algorithm is\nembedded into an iterated local search-based metaheuristic to achieve a\ncombined speed, scheduling and routing optimization. Extensive computational\nexperiments are conducted on classic PRP benchmark instances. Allowing delayed\ndeparture times from the depot significantly increases the search space, and\ncontributes to reduce CO 2 emissions by 8.31% on the considered instances.\n", "Comment: 8 pages"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-01-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05354"}}, {"publisher": {"name": ""}, "description": "  In this paper we use a logarithmic model for gray level image enhancement. We\nbegin with a short presentation of the model and then, we propose a new formula\nfor the mean dynamic range. After that we present two image transforms: one\nperforms an optimal enhancement of the mean dynamic range using the logarithmic\naddition, and the other does the same for positive and negative values using\nthe logarithmic scalar multiplication. We present the comparison of the results\nobtained by dynamic ranges optimization with the results obtained using\nclassical image enhancement methods like gamma correction and histogram\nequalization.\n", "contributors": [{"name": "Patrascu, Vasile", "sameAs": [], "familyName": "Patrascu", "additionalName": "", "givenName": "Vasile", "email": ""}], "title": "Image enhancement using the mean dynamic range maximization with\n  logarithmic operations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6092", "oai:arXiv.org:1412.6092"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper we use a logarithmic model for gray level image enhancement. We\nbegin with a short presentation of the model and then, we propose a new formula\nfor the mean dynamic range. After that we present two image transforms: one\nperforms an optimal enhancement of the mean dynamic range using the logarithmic\naddition, and the other does the same for positive and negative values using\nthe logarithmic scalar multiplication. We present the comparison of the results\nobtained by dynamic ranges optimization with the results obtained using\nclassical image enhancement methods like gamma correction and histogram\nequalization.\n", "Comment: Periodica Politechnica, Transactions on Automatic Control and\n  Computer Science, Vol.47 (61), 2002, ISSN 1224-600X, pp. 121-126, Timisoara,\n  Romania. arXiv admin note: text overlap with arXiv:1412.5764"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6092"}}, {"publisher": {"name": ""}, "description": "  Data traffic over wireless communication networks has experienced a\ntremendous growth in the last decade, and it is predicted to exponentially\nincrease in the next decades. Enabling future wireless networks to fulfill this\nexpectation is a challenging task both due to the scarcity of radio resources\n(e.g. spectrum and energy), and also the inherent characteristics of the\nwireless transmission medium. Wireless transmission is in general subject to\ntwo phenomena: fading and interference. The elegant interference alignment\nconcept reveals that with proper transmission signalling design, different\ninterference signals can in fact be aligned together, such that more radio\nresources can be assigned to the desired transmission. Although interference\nalignment can achieve a larger data rate compared to orthogonal transmission\nstrategies, several challenges should be addressed to enable the deployment of\nthis technique in future wireless networks For instance, to perform\ninterference alignment, normally, global channel state information (CSI) is\nrequired to be perfectly known at all terminals. Clearly, acquiring such\nchannel knowledge is a challenging problem in practice and proper channel\ntraining and channel state feedback techniques need to be deployed. In\naddition, since the channels are time-varying proper adaptive transmission is\nneeded. This chapter review recent advances in practical aspects of\ninterference alignment. It also presents recent test-bed implementations of\nsignal processing algorithms for the realization of interference alignment.\n", "contributors": [{"name": "Moghadam, Nima Najari", "sameAs": [], "familyName": "Moghadam", "additionalName": "Najari", "givenName": "Nima", "email": ""}, {"name": "Farhadi, Hamed", "sameAs": [], "familyName": "Farhadi", "additionalName": "", "givenName": "Hamed", "email": ""}, {"name": "Zetterberg, Per", "sameAs": [], "familyName": "Zetterberg", "additionalName": "", "givenName": "Per", "email": ""}, {"name": "Khormuji, Majid Nasiri", "sameAs": [], "familyName": "Khormuji", "additionalName": "Nasiri", "givenName": "Majid", "email": ""}, {"name": "Skoglund, Mikael", "sameAs": [], "familyName": "Skoglund", "additionalName": "", "givenName": "Mikael", "email": ""}], "title": "Interference Alignment: Practical Challenges and Test-bed Implementation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2529", "oai:arXiv.org:1411.2529"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Data traffic over wireless communication networks has experienced a\ntremendous growth in the last decade, and it is predicted to exponentially\nincrease in the next decades. Enabling future wireless networks to fulfill this\nexpectation is a challenging task both due to the scarcity of radio resources\n(e.g. spectrum and energy), and also the inherent characteristics of the\nwireless transmission medium. Wireless transmission is in general subject to\ntwo phenomena: fading and interference. The elegant interference alignment\nconcept reveals that with proper transmission signalling design, different\ninterference signals can in fact be aligned together, such that more radio\nresources can be assigned to the desired transmission. Although interference\nalignment can achieve a larger data rate compared to orthogonal transmission\nstrategies, several challenges should be addressed to enable the deployment of\nthis technique in future wireless networks For instance, to perform\ninterference alignment, normally, global channel state information (CSI) is\nrequired to be perfectly known at all terminals. Clearly, acquiring such\nchannel knowledge is a challenging problem in practice and proper channel\ntraining and channel state feedback techniques need to be deployed. In\naddition, since the channels are time-varying proper adaptive transmission is\nneeded. This chapter review recent advances in practical aspects of\ninterference alignment. It also presents recent test-bed implementations of\nsignal processing algorithms for the realization of interference alignment.\n", "Comment: to be appeared in N. N. Moghadam, H. Farhadi, P. Zetterberg, M.\n  Khormuji, and M. Skoglund, Interference alignment: Practical challenges and\n  test-bed implementation, in Contemporary Issues in Wireless Communications,\n  M. Khatib, Ed. InTech"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2529"}}, {"publisher": {"name": ""}, "description": "  Graph analysis is a critical component of applications such as online social\nnetworks, protein interactions in biological networks, and Internet traffic\nanalysis. The arrival of massive graphs with hundreds of millions of nodes,\ne.g. social graphs, presents a unique challenge to graph analysis applications.\nMost of these applications rely on computing distances between node pairs,\nwhich for large graphs can take minutes to compute using traditional algorithms\nsuch as breadth-first-search (BFS). In this paper, we study ways to enable\nscalable graph processing on today's massive graphs. We explore the design\nspace of graph coordinate systems, a new approach that accurately approximates\nnode distances in constant time by embedding graphs into coordinate spaces. We\nshow that a hyperbolic embedding produces relatively low distortion error, and\npropose Rigel, a hyperbolic graph coordinate system that lends itself to\nefficient parallelization across a compute cluster. Rigel produces\nsignificantly more accurate results than prior systems, and is naturally\nparallelizable across compute clusters, allowing it to provide accurate results\nfor graphs up to 43 million nodes. Finally, we show that Rigel's functionality\ncan be easily extended to locate (near-) shortest paths between node pairs.\nAfter a one- time preprocessing cost, Rigel answers node-distance queries in\n10's of microseconds, and also produces shortest path results up to 18 times\nfaster than prior shortest-path systems with similar levels of accuracy.\n", "contributors": [{"name": "Zhao, Xiaohan", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Xiaohan", "email": ""}, {"name": "Sala, Alessandra", "sameAs": [], "familyName": "Sala", "additionalName": "", "givenName": "Alessandra", "email": ""}, {"name": "Zheng, Haitao", "sameAs": [], "familyName": "Zheng", "additionalName": "", "givenName": "Haitao", "email": ""}, {"name": "Zhao, Ben Y.", "sameAs": [], "familyName": "Zhao", "additionalName": "Y.", "givenName": "Ben", "email": ""}], "title": "Fast and Scalable Analysis of Massive Social Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-07-26", "2011-07-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1107.5114", "oai:arXiv.org:1107.5114"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Graph analysis is a critical component of applications such as online social\nnetworks, protein interactions in biological networks, and Internet traffic\nanalysis. The arrival of massive graphs with hundreds of millions of nodes,\ne.g. social graphs, presents a unique challenge to graph analysis applications.\nMost of these applications rely on computing distances between node pairs,\nwhich for large graphs can take minutes to compute using traditional algorithms\nsuch as breadth-first-search (BFS). In this paper, we study ways to enable\nscalable graph processing on today's massive graphs. We explore the design\nspace of graph coordinate systems, a new approach that accurately approximates\nnode distances in constant time by embedding graphs into coordinate spaces. We\nshow that a hyperbolic embedding produces relatively low distortion error, and\npropose Rigel, a hyperbolic graph coordinate system that lends itself to\nefficient parallelization across a compute cluster. Rigel produces\nsignificantly more accurate results than prior systems, and is naturally\nparallelizable across compute clusters, allowing it to provide accurate results\nfor graphs up to 43 million nodes. Finally, we show that Rigel's functionality\ncan be easily extended to locate (near-) shortest paths between node pairs.\nAfter a one- time preprocessing cost, Rigel answers node-distance queries in\n10's of microseconds, and also produces shortest path results up to 18 times\nfaster than prior shortest-path systems with similar levels of accuracy.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1107.5114"}}, {"publisher": {"name": ""}, "description": "  We consider the problem of online nonparametric regression with arbitrary\ndeterministic sequences. Using ideas from the chaining technique, we design an\nalgorithm that achieves a Dudley-type regret bound similar to the one obtained\nin a non-constructive fashion by Rakhlin and Sridharan (2014). Our regret bound\nis expressed in terms of the metric entropy in the sup norm, which yields\noptimal guarantees when the metric and sequential entropies are of the same\norder of magnitude. In particular our algorithm is the first one that achieves\noptimal rates for online regression over H{\\\"o}lder balls. In addition we show\nfor this example how to adapt our chaining algorithm to get a reasonable\ncomputational efficiency with similar regret guarantees (up to a log factor).\n", "contributors": [{"name": "Gaillard, Pierre", "sameAs": [], "familyName": "Gaillard", "additionalName": "", "givenName": "Pierre", "email": ""}, {"name": "Gerchinovitz, S\u00e9bastien", "sameAs": [], "familyName": "Gerchinovitz", "additionalName": "", "givenName": "S\u00e9bastien", "email": ""}], "title": "A Chaining Algorithm for Online Nonparametric Regression", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07697", "oai:arXiv.org:1502.07697"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  We consider the problem of online nonparametric regression with arbitrary\ndeterministic sequences. Using ideas from the chaining technique, we design an\nalgorithm that achieves a Dudley-type regret bound similar to the one obtained\nin a non-constructive fashion by Rakhlin and Sridharan (2014). Our regret bound\nis expressed in terms of the metric entropy in the sup norm, which yields\noptimal guarantees when the metric and sequential entropies are of the same\norder of magnitude. In particular our algorithm is the first one that achieves\noptimal rates for online regression over H{\\\"o}lder balls. In addition we show\nfor this example how to adapt our chaining algorithm to get a reasonable\ncomputational efficiency with similar regret guarantees (up to a log factor).\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-02-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07697"}}, {"publisher": {"name": ""}, "description": "  The geographical location of Internet IP addresses has an importance both for\nacademic research and commercial applications. Thus, both commercial and\nacademic databases and tools are available for mapping IP addresses to\ngeographic locations. Evaluating the accuracy of these mapping services is\ncomplex since obtaining diverse large scale ground truth is very hard. In this\nwork we evaluate mapping services using an algorithm that groups IP addresses\nto PoPs, based on structure and delay. This way we are able to group close to\n100,000 IP addresses world wide into groups that are known to share a\ngeo-location with high confidence. We provide insight into the strength and\nweaknesses of IP geolocation databases, and discuss their accuracy and\nencountered anomalies.\n", "contributors": [{"name": "Shavitt, Yuval", "sameAs": [], "familyName": "Shavitt", "additionalName": "", "givenName": "Yuval", "email": ""}, {"name": "Zilberman, Noa", "sameAs": [], "familyName": "Zilberman", "additionalName": "", "givenName": "Noa", "email": ""}], "title": "A Study of Geolocation Databases", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-05-31", "2010-07-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.5674", "oai:arXiv.org:1005.5674"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The geographical location of Internet IP addresses has an importance both for\nacademic research and commercial applications. Thus, both commercial and\nacademic databases and tools are available for mapping IP addresses to\ngeographic locations. Evaluating the accuracy of these mapping services is\ncomplex since obtaining diverse large scale ground truth is very hard. In this\nwork we evaluate mapping services using an algorithm that groups IP addresses\nto PoPs, based on structure and delay. This way we are able to group close to\n100,000 IP addresses world wide into groups that are known to share a\ngeo-location with high confidence. We provide insight into the strength and\nweaknesses of IP geolocation databases, and discuss their accuracy and\nencountered anomalies.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.5674"}}, {"publisher": {"name": ""}, "description": "  We consider the problem of estimating parameters of stochastic differential\nequations (SDEs) with discrete-time observations that are either completely or\npartially observed. The transition density between two observations is\ngenerally unknown. We propose an importance sampling approach with an auxiliary\nparameter which improves the approximation of the transition density. We embed\nthe auxiliary importance sampler in a penalized maximum likelihood framework\nwhich produces more accurate and computationally efficient parameter estimates.\nSimulation studies in three different models illustrate promising improvements\nof the new penalized simulated maximum likelihood method. The new procedure is\ndesigned for the challenging case when some state variables are unobserved and\nmoreover, observed states are sparse over time, which commonly arises in\necological studies. We apply this new approach to two epidemics of chronic\nwasting disease in mule deer.\n", "contributors": [{"name": "Sun, Libo", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Libo", "email": ""}, {"name": "Lee, Chihoon", "sameAs": [], "familyName": "Lee", "additionalName": "", "givenName": "Chihoon", "email": ""}, {"name": "Hoeting, Jennifer A.", "sameAs": [], "familyName": "Hoeting", "additionalName": "A.", "givenName": "Jennifer", "email": ""}], "title": "A penalized simulated maximum likelihood approach in parameter\n  estimation for stochastic differential equations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-05-19", "2014-05-20"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1305.4390", "doi:10.1016/j.csda.2014.11.007", "oai:arXiv.org:1305.4390"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": ["  We consider the problem of estimating parameters of stochastic differential\nequations (SDEs) with discrete-time observations that are either completely or\npartially observed. The transition density between two observations is\ngenerally unknown. We propose an importance sampling approach with an auxiliary\nparameter which improves the approximation of the transition density. We embed\nthe auxiliary importance sampler in a penalized maximum likelihood framework\nwhich produces more accurate and computationally efficient parameter estimates.\nSimulation studies in three different models illustrate promising improvements\nof the new penalized simulated maximum likelihood method. The new procedure is\ndesigned for the challenging case when some state variables are unobserved and\nmoreover, observed states are sparse over time, which commonly arises in\necological studies. We apply this new approach to two epidemics of chronic\nwasting disease in mule deer.\n", "Comment: 22 pages, 4 figures, 3 tables, submitted to Computational Statistics\n  and Data Analysis"]}}], "languages": [null], "subjects": ["statistics - applications", "statistics - computation", "statistics - methodology"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1305.4390"}}, {"publisher": {"name": ""}, "description": "  Promising results have been achieved in image classification problems by\nexploiting the discriminative power of sparse representations for\nclassification (SRC). Recently, it has been shown that the use of\n\\emph{class-specific} spike-and-slab priors in conjunction with the\nclass-specific dictionaries from SRC is particularly effective in low training\nscenarios. As a logical extension, we build on this framework for multitask\nscenarios, wherein multiple representations of the same physical phenomena are\navailable. We experimentally demonstrate the benefits of mining joint\ninformation from different camera views for multi-view face recognition.\n", "contributors": [{"name": "Mousavi, Hojjat Seyed", "sameAs": [], "familyName": "Mousavi", "additionalName": "Seyed", "givenName": "Hojjat", "email": ""}, {"name": "Srinivas, Umamahesh", "sameAs": [], "familyName": "Srinivas", "additionalName": "", "givenName": "Umamahesh", "email": ""}, {"name": "Monga, Vishal", "sameAs": [], "familyName": "Monga", "additionalName": "", "givenName": "Vishal", "email": ""}, {"name": "Suo, Yuanming", "sameAs": [], "familyName": "Suo", "additionalName": "", "givenName": "Yuanming", "email": ""}, {"name": "Dao, Minh", "sameAs": [], "familyName": "Dao", "additionalName": "", "givenName": "Minh", "email": ""}, {"name": "Tran, Trac. D.", "sameAs": [], "familyName": "Tran", "additionalName": "D.", "givenName": "Trac.", "email": ""}], "title": "Multi-task Image Classification via Collaborative, Hierarchical\n  Spike-and-Slab Priors", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.07867", "oai:arXiv.org:1501.07867"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Promising results have been achieved in image classification problems by\nexploiting the discriminative power of sparse representations for\nclassification (SRC). Recently, it has been shown that the use of\n\\emph{class-specific} spike-and-slab priors in conjunction with the\nclass-specific dictionaries from SRC is particularly effective in low training\nscenarios. As a logical extension, we build on this framework for multitask\nscenarios, wherein multiple representations of the same physical phenomena are\navailable. We experimentally demonstrate the benefits of mining joint\ninformation from different camera views for multi-view face recognition.\n", "Comment: Accepted to International Conference in Image Processing (ICIP) 2014"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.07867"}}, {"publisher": {"name": ""}, "description": "  This paper presents an application with ROS, Aria and RosAria to control a\nModelSim simulated Pioneer 3-DX robot. The navigation applies a simple\nautonomous algorithm and a teleoperation control using an Android device\nsending the gyroscope generated information.\n", "contributors": [{"name": "Pinheiro, Eduardo G.", "sameAs": [], "familyName": "Pinheiro", "additionalName": "G.", "givenName": "Eduardo", "email": ""}, {"name": "Alberto, T\u00falio C.", "sameAs": [], "familyName": "Alberto", "additionalName": "C.", "givenName": "T\u00falio", "email": ""}], "title": "Teleoperando Rob\\^os Pioneer Utilizando Android", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.02475", "oai:arXiv.org:1501.02475"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper presents an application with ROS, Aria and RosAria to control a\nModelSim simulated Pioneer 3-DX robot. The navigation applies a simple\nautonomous algorithm and a teleoperation control using an Android device\nsending the gyroscope generated information.\n", "Comment: in Portuguese"]}}], "languages": [null], "subjects": ["computer science - robotics"], "providerUpdatedDateTime": "2015-01-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.02475"}}, {"publisher": {"name": ""}, "description": "  This paper makes three main contributions to the theory of communication\ncomplexity and stream computation. First, we present new bounds on the\ninformation complexity of AUGMENTED-INDEX. In contrast to analogous results for\nINDEX by Jain, Radhakrishnan and Sen [J. ACM, 2009], we have to overcome the\nsignificant technical challenge that protocols for AUGMENTED-INDEX may violate\nthe \"rectangle property\" due to the inherent input sharing. Second, we use\nthese bounds to resolve an open problem of Magniez, Mathieu and Nayak [STOC,\n2010] that asked about the multi-pass complexity of recognizing Dyck languages.\nThis results in a natural separation between the standard multi-pass model and\nthe multi-pass model that permits reverse passes. Third, we present the first\npassive memory checkers that verify the interaction transcripts of priority\nqueues, stacks, and double-ended queues. We obtain tight upper and lower bounds\nfor these problems, thereby addressing an important sub-class of the memory\nchecking framework of Blum et al. [Algorithmica, 1994].\n", "contributors": [{"name": "Chakrabarti, Amit", "sameAs": [], "familyName": "Chakrabarti", "additionalName": "", "givenName": "Amit", "email": ""}, {"name": "Cormode, Graham", "sameAs": [], "familyName": "Cormode", "additionalName": "", "givenName": "Graham", "email": ""}, {"name": "Kondapally, Ranganath", "sameAs": [], "familyName": "Kondapally", "additionalName": "", "givenName": "Ranganath", "email": ""}, {"name": "McGregor, Andrew", "sameAs": [], "familyName": "McGregor", "additionalName": "", "givenName": "Andrew", "email": ""}], "title": "Information Cost Tradeoffs for Augmented Index and Streaming Language\n  Recognition", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-04-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1004.3304", "oai:arXiv.org:1004.3304"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper makes three main contributions to the theory of communication\ncomplexity and stream computation. First, we present new bounds on the\ninformation complexity of AUGMENTED-INDEX. In contrast to analogous results for\nINDEX by Jain, Radhakrishnan and Sen [J. ACM, 2009], we have to overcome the\nsignificant technical challenge that protocols for AUGMENTED-INDEX may violate\nthe \"rectangle property\" due to the inherent input sharing. Second, we use\nthese bounds to resolve an open problem of Magniez, Mathieu and Nayak [STOC,\n2010] that asked about the multi-pass complexity of recognizing Dyck languages.\nThis results in a natural separation between the standard multi-pass model and\nthe multi-pass model that permits reverse passes. Third, we present the first\npassive memory checkers that verify the interaction transcripts of priority\nqueues, stacks, and double-ended queues. We obtain tight upper and lower bounds\nfor these problems, thereby addressing an important sub-class of the memory\nchecking framework of Blum et al. [Algorithmica, 1994].\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity"], "providerUpdatedDateTime": "2015-03-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1004.3304"}}, {"publisher": {"name": ""}, "description": "  Many auction settings implicitly or explicitly require that bidders are\ntreated equally ex-ante. This may be because discrimination is philosophically\nor legally impermissible, or because it is practically difficult to implement\nor impossible to enforce. We study so-called {\\em anonymous} auctions to\nunderstand the revenue tradeoffs and to develop simple anonymous auctions that\nare approximately optimal.\n  We consider digital goods settings and show that the optimal anonymous,\ndominant strategy incentive compatible auction has an intuitive structure ---\nimagine that bidders are randomly permuted before the auction, then infer a\nposterior belief about bidder i's valuation from the values of other bidders\nand set a posted price that maximizes revenue given this posterior.\n  We prove that no anonymous mechanism can guarantee an approximation better\nthan O(n) to the optimal revenue in the worst case (or O(log n) for regular\ndistributions) and that even posted price mechanisms match those guarantees.\nUnderstanding that the real power of anonymous mechanisms comes when the\nauctioneer can infer the bidder identities accurately, we show a tight O(k)\napproximation guarantee when each bidder can be confused with at most k \"higher\ntypes\". Moreover, we introduce a simple mechanism based on n target prices that\nis asymptotically optimal and build on this mechanism to extend our results to\nm-unit auctions and sponsored search.\n", "contributors": [{"name": "Tzamos, Christos", "sameAs": [], "familyName": "Tzamos", "additionalName": "", "givenName": "Christos", "email": ""}, {"name": "Wilkens, Christopher A.", "sameAs": [], "familyName": "Wilkens", "additionalName": "A.", "givenName": "Christopher", "email": ""}], "title": "The Value of Knowing Your Enemy", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1379", "oai:arXiv.org:1411.1379"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Many auction settings implicitly or explicitly require that bidders are\ntreated equally ex-ante. This may be because discrimination is philosophically\nor legally impermissible, or because it is practically difficult to implement\nor impossible to enforce. We study so-called {\\em anonymous} auctions to\nunderstand the revenue tradeoffs and to develop simple anonymous auctions that\nare approximately optimal.\n  We consider digital goods settings and show that the optimal anonymous,\ndominant strategy incentive compatible auction has an intuitive structure ---\nimagine that bidders are randomly permuted before the auction, then infer a\nposterior belief about bidder i's valuation from the values of other bidders\nand set a posted price that maximizes revenue given this posterior.\n  We prove that no anonymous mechanism can guarantee an approximation better\nthan O(n) to the optimal revenue in the worst case (or O(log n) for regular\ndistributions) and that even posted price mechanisms match those guarantees.\nUnderstanding that the real power of anonymous mechanisms comes when the\nauctioneer can infer the bidder identities accurately, we show a tight O(k)\napproximation guarantee when each bidder can be confused with at most k \"higher\ntypes\". Moreover, we introduce a simple mechanism based on n target prices that\nis asymptotically optimal and build on this mechanism to extend our results to\nm-unit auctions and sponsored search.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2014-11-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1379"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Thesis. 1978. M.S.--Massachusetts Institute of Technology. Dept. of Architecture.", "contributors": [{"name": "Stead, Lawrence Scarritt", "sameAs": [], "familyName": "Stead", "additionalName": "Scarritt", "givenName": "Lawrence", "email": ""}, {"name": "Nicholas P. Negroponte.", "sameAs": [], "familyName": "Negroponte.", "additionalName": "P.", "givenName": "Nicholas", "email": ""}], "title": "Personalized perspectives in 3-D assembly.", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "36 leaves"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/77850", "06380938", "oai:dspace.mit.edu:1721.1/77850"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2013-03-13T16:21:29Z", "2013-03-13T16:21:29Z", "1978", "1978"]}}, {"name": "description", "properties": {"description": ["Thesis. 1978. M.S.--Massachusetts Institute of Technology. Dept. of Architecture.", "MICROFICHE COPY AVAILABLE IN ARCHIVES AND ROTCH.", "Bibliography: leaf 35."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7635", "hdl_1721.1_7772"]}}], "languages": [null], "subjects": ["three-dimensional test of visualization skills", "computer graphics", "architecture"], "providerUpdatedDateTime": "2015-04-27T15:30:27", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/77850"}}, {"publisher": {"name": ""}, "description": "  The Internet of Things (IoT) is set to occupy a substantial component of\nfuture Internet. The IoT connects sensors and devices that record physical\nobservations to applications and services of the Internet. As a successor to\ntechnologies such as RFID and Wireless Sensor Networks (WSN), the IoT has\nstumbled into vertical silos of proprietary systems, providing little or no\ninteroperability with similar systems. As the IoT represents future state of\nthe Internet, an intelligent and scalable architecture is required to provide\nconnectivity between these silos, enabling discovery of physical sensors and\ninterpretation of messages between things. This paper proposes a gateway and\nSemantic Web enabled IoT architecture to provide interoperability between\nsystems using established communication and data standards. The Semantic\nGateway as Service (SGS) allows translation between messaging protocols such as\nXMPP, CoAP and MQTT via a multi-protocol proxy architecture. Utilization of\nbroadly accepted specifications such as W3C's Semantic Sensor Network (SSN)\nontology for semantic annotations of sensor data provide semantic\ninteroperability between messages and support semantic reasoning to obtain\nhigher-level actionable knowledge from low-level sensor data.\n", "contributors": [{"name": "Desai, Pratikkumar", "sameAs": [], "familyName": "Desai", "additionalName": "", "givenName": "Pratikkumar", "email": ""}, {"name": "Sheth, Amit", "sameAs": [], "familyName": "Sheth", "additionalName": "", "givenName": "Amit", "email": ""}, {"name": "Anantharam, Pramod", "sameAs": [], "familyName": "Anantharam", "additionalName": "", "givenName": "Pramod", "email": ""}], "title": "Semantic Gateway as a Service architecture for IoT Interoperability", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4977", "oai:arXiv.org:1410.4977"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The Internet of Things (IoT) is set to occupy a substantial component of\nfuture Internet. The IoT connects sensors and devices that record physical\nobservations to applications and services of the Internet. As a successor to\ntechnologies such as RFID and Wireless Sensor Networks (WSN), the IoT has\nstumbled into vertical silos of proprietary systems, providing little or no\ninteroperability with similar systems. As the IoT represents future state of\nthe Internet, an intelligent and scalable architecture is required to provide\nconnectivity between these silos, enabling discovery of physical sensors and\ninterpretation of messages between things. This paper proposes a gateway and\nSemantic Web enabled IoT architecture to provide interoperability between\nsystems using established communication and data standards. The Semantic\nGateway as Service (SGS) allows translation between messaging protocols such as\nXMPP, CoAP and MQTT via a multi-protocol proxy architecture. Utilization of\nbroadly accepted specifications such as W3C's Semantic Sensor Network (SSN)\nontology for semantic annotations of sensor data provide semantic\ninteroperability between messages and support semantic reasoning to obtain\nhigher-level actionable knowledge from low-level sensor data.\n", "Comment: 16 pages"]}}], "languages": [null], "subjects": ["computer science - distributed", "computer science - networking and internet architecture", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-10-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4977"}}, {"publisher": {"name": ""}, "description": "  We introduce NIFTY, \"Numerical Information Field Theory\", a software package\nfor the development of Bayesian signal inference algorithms that operate\nindependently from any underlying spatial grid and its resolution. A large\nnumber of Bayesian and Maximum Entropy methods for 1D signal reconstruction, 2D\nimaging, as well as 3D tomography, appear formally similar, but one often finds\nindividualized implementations that are neither flexible nor easily\ntransferable. Signal inference in the framework of NIFTY can be done in an\nabstract way, such that algorithms, prototyped in 1D, can be applied to real\nworld problems in higher-dimensional settings. NIFTY as a versatile library is\napplicable and already has been applied in 1D, 2D, 3D and spherical settings. A\nrecent application is the D3PO algorithm targeting the non-trivial task of\ndenoising, deconvolving, and decomposing photon observations in high energy\nastronomy.\n", "contributors": [{"name": "Selig, Marco", "sameAs": [], "familyName": "Selig", "additionalName": "", "givenName": "Marco", "email": ""}], "title": "The NIFTY way of Bayesian signal inference", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7160", "AIP Conf. Proc. 1636, 68 (2014)", "doi:10.1063/1.4903712", "oai:arXiv.org:1412.7160"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:astro-ph", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We introduce NIFTY, \"Numerical Information Field Theory\", a software package\nfor the development of Bayesian signal inference algorithms that operate\nindependently from any underlying spatial grid and its resolution. A large\nnumber of Bayesian and Maximum Entropy methods for 1D signal reconstruction, 2D\nimaging, as well as 3D tomography, appear formally similar, but one often finds\nindividualized implementations that are neither flexible nor easily\ntransferable. Signal inference in the framework of NIFTY can be done in an\nabstract way, such that algorithms, prototyped in 1D, can be applied to real\nworld problems in higher-dimensional settings. NIFTY as a versatile library is\napplicable and already has been applied in 1D, 2D, 3D and spherical settings. A\nrecent application is the D3PO algorithm targeting the non-trivial task of\ndenoising, deconvolving, and decomposing photon observations in high energy\nastronomy.\n", "Comment: 6 pages, 2 figures, refereed proceeding of the 33rd International\n  Workshop on Bayesian Inference and Maximum Entropy Methods in Science and\n  Engineering (MaxEnt 2013), software available at\n  http://www.mpa-garching.mpg.de/ift/nifty/ and\n  http://www.mpa-garching.mpg.de/ift/d3po/"]}}], "languages": [null], "subjects": ["statistics and probability", "computer science - mathematical software", "computer science - information theory", "astrophysics - instrumentation and methods for astrophysics", "physics - data analysis"], "providerUpdatedDateTime": "2014-12-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7160"}}, {"publisher": {"name": ""}, "description": "  In this paper, we present two practical ARQ-Based security schemes for Wi-Fi\nand RFID networks. Our proposed schemes enhance the confidentiality and\nauthenticity functions of these networks, respectively. Both schemes build on\nthe same idea; by exploiting the statistical independence between the multipath\nfading experienced by the legitimate nodes and potential adversaries, secret\nkeys are established and then are continuously updated. The continuous key\nupdate property of both schemes makes them capable of defending against all of\nthe passive eavesdropping attacks and most of the currently-known active\nattacks against either Wi-Fi or RFID networks. However, each scheme is tailored\nto best suit the requirements of its respective paradigm. In Wi-Fi networks, we\noverlay, rather than completely replace, the current Wi-Fi security protocols.\nThus, our Wi-Fi scheme can be readily implemented via only minor modifications\nover the IEEE 802.11 standards. On the other hand, the proposed RFID scheme\nintroduces the first provably secure low cost RFID authentication protocol. The\nproposed schemes impose a throughput-security tradeoff that is shown, through\nour analytical and experimental results, to be practically acceptable.\n", "contributors": [{"name": "Elsabagh, Mohamed", "sameAs": [], "familyName": "Elsabagh", "additionalName": "", "givenName": "Mohamed", "email": ""}, {"name": "Abdallah, Yara", "sameAs": [], "familyName": "Abdallah", "additionalName": "", "givenName": "Yara", "email": ""}, {"name": "Youssef, Moustafa", "sameAs": [], "familyName": "Youssef", "additionalName": "", "givenName": "Moustafa", "email": ""}, {"name": "Gamal, Hesham El", "sameAs": [], "familyName": "Gamal", "additionalName": "El", "givenName": "Hesham", "email": ""}], "title": "ARQ Security in Wi-Fi and RFID Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-10-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1010.3294", "oai:arXiv.org:1010.3294"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we present two practical ARQ-Based security schemes for Wi-Fi\nand RFID networks. Our proposed schemes enhance the confidentiality and\nauthenticity functions of these networks, respectively. Both schemes build on\nthe same idea; by exploiting the statistical independence between the multipath\nfading experienced by the legitimate nodes and potential adversaries, secret\nkeys are established and then are continuously updated. The continuous key\nupdate property of both schemes makes them capable of defending against all of\nthe passive eavesdropping attacks and most of the currently-known active\nattacks against either Wi-Fi or RFID networks. However, each scheme is tailored\nto best suit the requirements of its respective paradigm. In Wi-Fi networks, we\noverlay, rather than completely replace, the current Wi-Fi security protocols.\nThus, our Wi-Fi scheme can be readily implemented via only minor modifications\nover the IEEE 802.11 standards. On the other hand, the proposed RFID scheme\nintroduces the first provably secure low cost RFID authentication protocol. The\nproposed schemes impose a throughput-security tradeoff that is shown, through\nour analytical and experimental results, to be practically acceptable.\n", "Comment: 8 pages"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1010.3294"}}, {"publisher": {"name": ""}, "description": "  Most work in quantum circuit optimization has been performed in isolation\nfrom the results of quantum fault-tolerance. Here we present a polynomial-time\nalgorithm for optimizing quantum circuits that takes the actual implementation\nof fault-tolerant logical gates into consideration. Our algorithm\nre-synthesizes quantum circuits composed of Clifford group and T gates, the\nlatter being typically the most costly gate in fault-tolerant models, e.g.,\nthose based on the Steane or surface codes, with the purpose of minimizing both\nT-count and T-depth. A major feature of the algorithm is the ability to\nre-synthesize circuits with additional ancillae to reduce T-depth at\neffectively no cost. The tested benchmarks show up to 65.7% reduction in\nT-count and up to 87.6% reduction in T-depth without ancillae, or 99.7%\nreduction in T-depth using ancillae.\n", "contributors": [{"name": "Amy, Matthew", "sameAs": [], "familyName": "Amy", "additionalName": "", "givenName": "Matthew", "email": ""}, {"name": "Maslov, Dmitri", "sameAs": [], "familyName": "Maslov", "additionalName": "", "givenName": "Dmitri", "email": ""}, {"name": "Mosca, Michele", "sameAs": [], "familyName": "Mosca", "additionalName": "", "givenName": "Michele", "email": ""}], "title": "Polynomial-time T-depth Optimization of Clifford+T circuits via Matroid\n  Partitioning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-03-08", "2013-12-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1303.2042", "IEEE Transactions on Computer-Aided Design of Integrated Circuits\n  and Systems 33(10): 1476-1489, 2014", "doi:10.1109/TCAD.2014.2341953", "oai:arXiv.org:1303.2042"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": ["  Most work in quantum circuit optimization has been performed in isolation\nfrom the results of quantum fault-tolerance. Here we present a polynomial-time\nalgorithm for optimizing quantum circuits that takes the actual implementation\nof fault-tolerant logical gates into consideration. Our algorithm\nre-synthesizes quantum circuits composed of Clifford group and T gates, the\nlatter being typically the most costly gate in fault-tolerant models, e.g.,\nthose based on the Steane or surface codes, with the purpose of minimizing both\nT-count and T-depth. A major feature of the algorithm is the ability to\nre-synthesize circuits with additional ancillae to reduce T-depth at\neffectively no cost. The tested benchmarks show up to 65.7% reduction in\nT-count and up to 87.6% reduction in T-depth without ancillae, or 99.7%\nreduction in T-depth using ancillae.\n", "Comment: Version 2 contains substantial improvements and extensions to the\n  previous version. We describe a new, more robust algorithm and achieve\n  significantly improved experimental results"]}}], "languages": [null], "subjects": ["quantum physics", "computer science - emerging technologies"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1303.2042"}}, {"publisher": {"name": ""}, "description": "  Many information sources are considered into data fusion in order to improve\nthe decision in terms of uncertainty and imprecision. For each technique used\nfor data fusion, the asumption on independance is usually made. We propose in\nthis article an approach to take into acount an independance measure befor to\nmake the combination of information in the context of the theory of belief\nfunctions.\n", "contributors": [{"name": "Kharoune, Mouloud", "sameAs": [], "familyName": "Kharoune", "additionalName": "", "givenName": "Mouloud", "email": ""}, {"name": "Martin, Arnaud", "sameAs": [], "familyName": "Martin", "additionalName": "", "givenName": "Arnaud", "email": ""}], "title": "Int{\\'e}gration d'une mesure d'ind{\\'e}pendance pour la fusion\n  d'informations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05614", "oai:arXiv.org:1501.05614"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Many information sources are considered into data fusion in order to improve\nthe decision in terms of uncertainty and imprecision. For each technique used\nfor data fusion, the asumption on independance is usually made. We propose in\nthis article an approach to take into acount an independance measure befor to\nmake the combination of information in the context of the theory of belief\nfunctions.\n", "Comment: in French, appears in Atelier Fouille de donn{\\'e}es complexes,\n  Extraction et Gestion des Connaissances (EGC), Jan 2013, Toulouse, France.\n  arXiv admin note: substantial text overlap with arXiv:1501.04786"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2015-01-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05614"}}, {"publisher": {"name": ""}, "description": "  In laboratory experiments we demonstrate that protoplasmic tubes of acellular\nslime mould \\emph{Physarum polycephalum} show current versus voltage profiles\nconsistent with memristive systems and that the effect is due to the living\nprotoplasm of the mould. This complements previous findings on memristive\nproperties of other living systems (human skin and blood) and contributes to\ndevelopment of self-growing bio-electronic circuits. Distinctive asymmetric\n$V$-$I$ curves which were occasionally observed when the internal current is on\nthe same order as the driven current, are well-modelled by the concept of\nactive memristors.\n", "contributors": [{"name": "Gale, Ella", "sameAs": [], "familyName": "Gale", "additionalName": "", "givenName": "Ella", "email": ""}, {"name": "Adamatzky, Andrew", "sameAs": [], "familyName": "Adamatzky", "additionalName": "", "givenName": "Andrew", "email": ""}, {"name": "Costello, Ben de Lacy", "sameAs": [], "familyName": "Costello", "additionalName": "de Lacy", "givenName": "Ben", "email": ""}], "title": "Slime Mould Memristors", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-14", "2014-04-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.3414", "doi:10.1007/s12668-014-0156-3", "oai:arXiv.org:1306.3414"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  In laboratory experiments we demonstrate that protoplasmic tubes of acellular\nslime mould \\emph{Physarum polycephalum} show current versus voltage profiles\nconsistent with memristive systems and that the effect is due to the living\nprotoplasm of the mould. This complements previous findings on memristive\nproperties of other living systems (human skin and blood) and contributes to\ndevelopment of self-growing bio-electronic circuits. Distinctive asymmetric\n$V$-$I$ curves which were occasionally observed when the internal current is on\nthe same order as the driven current, are well-modelled by the concept of\nactive memristors.\n", "Comment: 14 pages, 6 figures"]}}], "languages": [null], "subjects": ["92fxx", "j.3", "68uxx", "physics - biological physics", "j.2", "condensed matter - other condensed matter", "c.1.m", "c.1.3", "b.6.1", "94cxx", "computer science - emerging technologies", "92cxx"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.3414"}}, {"publisher": {"name": ""}, "description": "  The linear shift deterministic Y-channel is studied. That is, we have three\nusers and one relay, where each user wishes to broadcast one message to each\nother user via the relay, resulting in a multi-way relaying setup. The cut-set\nbounds for this setup are shown to be not sufficient to characterize its\ncapacity region. New upper bounds are derived, which when combined with the\ncut-set bounds provide an outer bound on the capacity region. It is shown that\nthis outer bound is achievable, and as a result, the capacity region of the\nlinear shift deterministic Y-channel is characterized.\n", "contributors": [{"name": "Chaaban, Anas", "sameAs": [], "familyName": "Chaaban", "additionalName": "", "givenName": "Anas", "email": ""}, {"name": "Sezgin, Aydin", "sameAs": [], "familyName": "Sezgin", "additionalName": "", "givenName": "Aydin", "email": ""}], "title": "The Capacity Region of the Linear Shift Deterministic Y-Channel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-06-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1106.3402", "oai:arXiv.org:1106.3402"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The linear shift deterministic Y-channel is studied. That is, we have three\nusers and one relay, where each user wishes to broadcast one message to each\nother user via the relay, resulting in a multi-way relaying setup. The cut-set\nbounds for this setup are shown to be not sufficient to characterize its\ncapacity region. New upper bounds are derived, which when combined with the\ncut-set bounds provide an outer bound on the capacity region. It is shown that\nthis outer bound is achievable, and as a result, the capacity region of the\nlinear shift deterministic Y-channel is characterized.\n", "Comment: to appear in ISIT 2011"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1106.3402"}}, {"publisher": {"name": ""}, "description": "  Inspired by the Elitzur-Vaidman bomb testing problem [arXiv:hep-th/9305002],\nwe introduce a new query complexity model, which we call bomb query complexity\n$B(f)$. We investigate its relationship with the usual quantum query complexity\n$Q(f)$, and show that $B(f)=\\Theta(Q(f)^2)$.\n  This result gives a new method to upper bound the quantum query complexity:\nwe give a method of finding bomb query algorithms from classical algorithms,\nwhich then provide nonconstructive upper bounds on $Q(f)=\\Theta(\\sqrt{B(f)})$.\nWe subsequently were able to give explicit quantum algorithms matching our\nupper bound method. We apply this method on the single-source shortest paths\nproblem on unweighted graphs, obtaining an algorithm with $O(n^{1.5})$ quantum\nquery complexity, improving the best known algorithm of $O(n^{1.5}\\sqrt{\\log\nn})$ [arXiv:quant-ph/0606127]. Applying this method to the maximum bipartite\nmatching problem gives an $O(n^{1.75})$ algorithm, improving the best known\ntrivial $O(n^2)$ upper bound.\n", "contributors": [{"name": "Lin, Cedric Yen-Yu", "sameAs": [], "familyName": "Lin", "additionalName": "Yen-Yu", "givenName": "Cedric", "email": ""}, {"name": "Lin, Han-Hsuan", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Han-Hsuan", "email": ""}], "title": "Upper bounds on quantum query complexity inspired by the Elitzur-Vaidman\n  bomb tester", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-03", "2014-11-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.0932", "oai:arXiv.org:1410.0932"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": ["  Inspired by the Elitzur-Vaidman bomb testing problem [arXiv:hep-th/9305002],\nwe introduce a new query complexity model, which we call bomb query complexity\n$B(f)$. We investigate its relationship with the usual quantum query complexity\n$Q(f)$, and show that $B(f)=\\Theta(Q(f)^2)$.\n  This result gives a new method to upper bound the quantum query complexity:\nwe give a method of finding bomb query algorithms from classical algorithms,\nwhich then provide nonconstructive upper bounds on $Q(f)=\\Theta(\\sqrt{B(f)})$.\nWe subsequently were able to give explicit quantum algorithms matching our\nupper bound method. We apply this method on the single-source shortest paths\nproblem on unweighted graphs, obtaining an algorithm with $O(n^{1.5})$ quantum\nquery complexity, improving the best known algorithm of $O(n^{1.5}\\sqrt{\\log\nn})$ [arXiv:quant-ph/0606127]. Applying this method to the maximum bipartite\nmatching problem gives an $O(n^{1.75})$ algorithm, improving the best known\ntrivial $O(n^2)$ upper bound.\n", "Comment: 32 pages. Minor revisions and corrections. Regev and Schiff's proof\n  that P(OR) = \\Omega(N) removed"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "quantum physics"], "providerUpdatedDateTime": "2014-12-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.0932"}}, {"publisher": {"name": ""}, "description": "  This paper studies the Shannon regime for the random displacement of\nstationary point processes. Let each point of some initial stationary point\nprocess in $\\R^n$ give rise to one daughter point, the location of which is\nobtained by adding a random vector to the coordinates of the mother point, with\nall displacement vectors independently and identically distributed for all\npoints. The decoding problem is then the following one: the whole mother point\nprocess is known as well as the coordinates of some daughter point; the\ndisplacements are only known through their law; can one find the mother of this\ndaughter point? The Shannon regime is that where the dimension $n$ tends to\ninfinity and where the logarithm of the intensity of the point process is\nproportional to $n$. We show that this problem exhibits a sharp threshold: if\nthe sum of the proportionality factor and of the differential entropy rate of\nthe noise is positive, then the probability of finding the right mother point\ntends to 0 with $n$ for all point processes and decoding strategies. If this\nsum is negative, there exist mother point processes, for instance Poisson, and\ndecoding strategies, for instance maximum likelihood, for which the probability\nof finding the right mother tends to 1 with $n$. We then use large deviations\ntheory to show that in the latter case, if the entropy spectrum of the noise\nsatisfies a large deviation principle, then the error probability goes\nexponentially fast to 0 with an exponent that is given in closed form in terms\nof the rate function of the noise entropy spectrum. This is done for two\nclasses of mother point processes: Poisson and Mat\\'ern. The practical interest\nto information theory comes from the explicit connection that we also establish\nbetween this problem and the estimation of error exponents in Shannon's\nadditive noise channel with power constraints on the codewords.\n", "contributors": [{"name": "Anantharam, Venkat", "sameAs": [], "familyName": "Anantharam", "additionalName": "", "givenName": "Venkat", "email": ""}, {"name": "Baccelli, Francois", "sameAs": [], "familyName": "Baccelli", "additionalName": "", "givenName": "Francois", "email": ""}], "title": "Information-Theoretic Capacity and Error Exponents of Stationary Point\n  Processes under Random Additive Displacements", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-12-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1012.4924", "oai:arXiv.org:1012.4924"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  This paper studies the Shannon regime for the random displacement of\nstationary point processes. Let each point of some initial stationary point\nprocess in $\\R^n$ give rise to one daughter point, the location of which is\nobtained by adding a random vector to the coordinates of the mother point, with\nall displacement vectors independently and identically distributed for all\npoints. The decoding problem is then the following one: the whole mother point\nprocess is known as well as the coordinates of some daughter point; the\ndisplacements are only known through their law; can one find the mother of this\ndaughter point? The Shannon regime is that where the dimension $n$ tends to\ninfinity and where the logarithm of the intensity of the point process is\nproportional to $n$. We show that this problem exhibits a sharp threshold: if\nthe sum of the proportionality factor and of the differential entropy rate of\nthe noise is positive, then the probability of finding the right mother point\ntends to 0 with $n$ for all point processes and decoding strategies. If this\nsum is negative, there exist mother point processes, for instance Poisson, and\ndecoding strategies, for instance maximum likelihood, for which the probability\nof finding the right mother tends to 1 with $n$. We then use large deviations\ntheory to show that in the latter case, if the entropy spectrum of the noise\nsatisfies a large deviation principle, then the error probability goes\nexponentially fast to 0 with an exponent that is given in closed form in terms\nof the rate function of the noise entropy spectrum. This is done for two\nclasses of mother point processes: Poisson and Mat\\'ern. The practical interest\nto information theory comes from the explicit connection that we also establish\nbetween this problem and the estimation of error exponents in Shannon's\nadditive noise channel with power constraints on the codewords.\n"}}], "languages": [null], "subjects": ["computer science - information theory", "mathematics - probability"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1012.4924"}}, {"publisher": {"name": ""}, "description": "  This paper constructs presentations via finite complete rewriting systems for\nPlactic monoids of types $A_n$, $B_n$, $C_n$, $D_n$, and $G_2$, using a unified\nproof strategy that depends on Kashiwara's crystal bases and analogies of Young\ntableaux, and on Lecouvey's presentations for these monoids. As corollaries, we\ndeduce that Plactic monoids of these types have finite derivation type and\nsatisfy the homological finiteness properties left and right\n$\\mathrm{FP}_\\infty$. These rewriting systems are then applied to show that\nPlactic monoids of these types are biautomatic.\n", "contributors": [{"name": "Cain, Alan J.", "sameAs": [], "familyName": "Cain", "additionalName": "J.", "givenName": "Alan", "email": ""}, {"name": "Gray, Robert D.", "sameAs": [], "familyName": "Gray", "additionalName": "D.", "givenName": "Robert", "email": ""}, {"name": "Malheiro, Ant\u00f3nio", "sameAs": [], "familyName": "Malheiro", "additionalName": "", "givenName": "Ant\u00f3nio", "email": ""}], "title": "Crystal bases, finite complete rewriting systems, and biautomatic\n  structures for Plactic monoids of types $A_n$, $B_n$, $C_n$, $D_n$, and $G_2$", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7040", "oai:arXiv.org:1412.7040"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper constructs presentations via finite complete rewriting systems for\nPlactic monoids of types $A_n$, $B_n$, $C_n$, $D_n$, and $G_2$, using a unified\nproof strategy that depends on Kashiwara's crystal bases and analogies of Young\ntableaux, and on Lecouvey's presentations for these monoids. As corollaries, we\ndeduce that Plactic monoids of these types have finite derivation type and\nsatisfy the homological finiteness properties left and right\n$\\mathrm{FP}_\\infty$. These rewriting systems are then applied to show that\nPlactic monoids of these types are biautomatic.\n", "Comment: 50 pages"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "mathematics - group theory", "20m05 (primary) 17b10 68q42 68q45 (secondary)"], "providerUpdatedDateTime": "2014-12-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7040"}}, {"publisher": {"name": ""}, "description": "  Recently, a novel technique called coded cache have been proposed to\nfacilitate the wireless content distribution. Assuming the users have the\nidentical cache size, prior works have described the fundamental performance\nlimits of such scheme. However, when heterogenous user cache sizes is taken\ninto account, there remains open questions regarding the performance of the\ncache. In this work, for the heterogenous user cache sizes, we first derive the\ninformation-theoretical lower bound and show that although the traditional\ncoded caching scheme will cause miss of coding opportunities in this regime, it\nstill exhibits the constant gap 6 to the lower bound. To reveal the essence in\nthis result, we introduce the concept of the probabilistic cache set and find\nthe guarantee of such order optimality mainly comes from the intrinsic\ndegenerated efficiency of bottleneck caching network under the heterogenous\ncache sizes. Moreover, we point out such miss of coding opportunities is caused\nnot only by the heterogenous cache sizes but also by the group coded delivery,\nwhich divide users into groups and operate coded cache separately. And the\ncombination of above two schemes will not cumulate this effect, instead, they\ncancel each other out.\n", "contributors": [{"name": "Wang, Sinong", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Sinong", "email": ""}, {"name": "Li, Wenxin", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Wenxin", "email": ""}, {"name": "Tian, Xiaohua", "sameAs": [], "familyName": "Tian", "additionalName": "", "givenName": "Xiaohua", "email": ""}, {"name": "Liu, Hui", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Hui", "email": ""}], "title": "Fundamental Limits of Heterogenous Cache", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01123", "oai:arXiv.org:1504.01123"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Recently, a novel technique called coded cache have been proposed to\nfacilitate the wireless content distribution. Assuming the users have the\nidentical cache size, prior works have described the fundamental performance\nlimits of such scheme. However, when heterogenous user cache sizes is taken\ninto account, there remains open questions regarding the performance of the\ncache. In this work, for the heterogenous user cache sizes, we first derive the\ninformation-theoretical lower bound and show that although the traditional\ncoded caching scheme will cause miss of coding opportunities in this regime, it\nstill exhibits the constant gap 6 to the lower bound. To reveal the essence in\nthis result, we introduce the concept of the probabilistic cache set and find\nthe guarantee of such order optimality mainly comes from the intrinsic\ndegenerated efficiency of bottleneck caching network under the heterogenous\ncache sizes. Moreover, we point out such miss of coding opportunities is caused\nnot only by the heterogenous cache sizes but also by the group coded delivery,\nwhich divide users into groups and operate coded cache separately. And the\ncombination of above two schemes will not cumulate this effect, instead, they\ncancel each other out.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01123"}}, {"publisher": {"name": ""}, "description": "  After working for some time, developers commit their code changes to a\nversion control system. When doing so, they often bundle unrelated changes\n(e.g., bug fix and refactoring) in a single commit, thus creating a so-called\ntangled commit. Sharing tangled commits is problematic because it makes review,\nreversion, and integration of these commits harder and historical analyses of\nthe project less reliable. Researchers have worked at untangling existing\ncommits, i.e., finding which part of a commit relates to which task. In this\npaper, we contribute to this line of work in two ways: (1) A publicly available\ndataset of untangled code changes, created with the help of two developers who\naccurately split their code changes into self contained tasks over a period of\nfour months; (2) a novel approach, EpiceaUntangler, to help developers share\nuntangled commits (aka. atomic commits) by using fine-grained code change\ninformation. EpiceaUntangler is based and tested on the publicly available\ndataset, and further evaluated by deploying it to 7 developers, who used it for\n2 weeks. We recorded a median success rate of 91% and average one of 75%, in\nautomatically creating clusters of untangled fine-grained code changes.\n", "contributors": [{"name": "Dias, Mart\u00edn", "sameAs": [], "familyName": "Dias", "additionalName": "", "givenName": "Mart\u00edn", "email": ""}, {"name": "Bacchelli, Alberto", "sameAs": [], "familyName": "Bacchelli", "additionalName": "", "givenName": "Alberto", "email": ""}, {"name": "Gousios, Georgios", "sameAs": [], "familyName": "Gousios", "additionalName": "", "givenName": "Georgios", "email": ""}, {"name": "Cassou, Damien", "sameAs": [], "familyName": "Cassou", "additionalName": "", "givenName": "Damien", "email": ""}, {"name": "Ducasse, St\u00e9phane", "sameAs": [], "familyName": "Ducasse", "additionalName": "", "givenName": "St\u00e9phane", "email": ""}], "title": "Untangling Fine-Grained Code Changes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06757", "oai:arXiv.org:1502.06757"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  After working for some time, developers commit their code changes to a\nversion control system. When doing so, they often bundle unrelated changes\n(e.g., bug fix and refactoring) in a single commit, thus creating a so-called\ntangled commit. Sharing tangled commits is problematic because it makes review,\nreversion, and integration of these commits harder and historical analyses of\nthe project less reliable. Researchers have worked at untangling existing\ncommits, i.e., finding which part of a commit relates to which task. In this\npaper, we contribute to this line of work in two ways: (1) A publicly available\ndataset of untangled code changes, created with the help of two developers who\naccurately split their code changes into self contained tasks over a period of\nfour months; (2) a novel approach, EpiceaUntangler, to help developers share\nuntangled commits (aka. atomic commits) by using fine-grained code change\ninformation. EpiceaUntangler is based and tested on the publicly available\ndataset, and further evaluated by deploying it to 7 developers, who used it for\n2 weeks. We recorded a median success rate of 91% and average one of 75%, in\nautomatically creating clusters of untangled fine-grained code changes.\n"}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-02-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06757"}}, {"publisher": {"name": ""}, "description": "  The knowledge of end-to-end network distances is essential to many Internet\napplications. As active probing of all pairwise distances is infeasible in\nlarge-scale networks, a natural idea is to measure a few pairs and to predict\nthe other ones without actually measuring them. This paper formulates the\ndistance prediction problem as matrix completion where unknown entries of an\nincomplete matrix of pairwise distances are to be predicted. The problem is\nsolvable because strong correlations among network distances exist and cause\nthe constructed distance matrix to be low rank. The new formulation circumvents\nthe well-known drawbacks of existing approaches based on Euclidean embedding.\n  A new algorithm, so-called Decentralized Matrix Factorization by Stochastic\nGradient Descent (DMFSGD), is proposed to solve the network distance prediction\nproblem. By letting network nodes exchange messages with each other, the\nalgorithm is fully decentralized and only requires each node to collect and to\nprocess local measurements, with neither explicit matrix constructions nor\nspecial nodes such as landmarks and central servers. In addition, we compared\ncomprehensively matrix factorization and Euclidean embedding to demonstrate the\nsuitability of the former on network distance prediction. We further studied\nthe incorporation of a robust loss function and of non-negativity constraints.\nExtensive experiments on various publicly-available datasets of network delays\nshow not only the scalability and the accuracy of our approach but also its\nusability in real Internet applications.\n", "contributors": [{"name": "Liao, Yongjun", "sameAs": [], "familyName": "Liao", "additionalName": "", "givenName": "Yongjun", "email": ""}, {"name": "Du, Wei", "sameAs": [], "familyName": "Du", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Geurts, Pierre", "sameAs": [], "familyName": "Geurts", "additionalName": "", "givenName": "Pierre", "email": ""}, {"name": "Leduc, Guy", "sameAs": [], "familyName": "Leduc", "additionalName": "", "givenName": "Guy", "email": ""}], "title": "DMFSGD: A Decentralized Matrix Factorization Algorithm for Network\n  Distance Prediction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-01-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1201.1174", "oai:arXiv.org:1201.1174"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The knowledge of end-to-end network distances is essential to many Internet\napplications. As active probing of all pairwise distances is infeasible in\nlarge-scale networks, a natural idea is to measure a few pairs and to predict\nthe other ones without actually measuring them. This paper formulates the\ndistance prediction problem as matrix completion where unknown entries of an\nincomplete matrix of pairwise distances are to be predicted. The problem is\nsolvable because strong correlations among network distances exist and cause\nthe constructed distance matrix to be low rank. The new formulation circumvents\nthe well-known drawbacks of existing approaches based on Euclidean embedding.\n  A new algorithm, so-called Decentralized Matrix Factorization by Stochastic\nGradient Descent (DMFSGD), is proposed to solve the network distance prediction\nproblem. By letting network nodes exchange messages with each other, the\nalgorithm is fully decentralized and only requires each node to collect and to\nprocess local measurements, with neither explicit matrix constructions nor\nspecial nodes such as landmarks and central servers. In addition, we compared\ncomprehensively matrix factorization and Euclidean embedding to demonstrate the\nsuitability of the former on network distance prediction. We further studied\nthe incorporation of a robust loss function and of non-negativity constraints.\nExtensive experiments on various publicly-available datasets of network delays\nshow not only the scalability and the accuracy of our approach but also its\nusability in real Internet applications.\n", "Comment: submitted to IEEE/ACM Transactions on Networking on Nov. 2011"]}}], "languages": [null], "subjects": ["c.2.4", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1201.1174"}}, {"publisher": {"name": ""}, "description": "  Business rules represent the knowledge that guides the operations of a\nbusiness organization. They are implemented in software applications used by\norganizations, and the activity of extracting them from software is known as\nbusiness rule mining. It has various purposes amongst which migration and\ngenerating documentation are the most common. However, apart from conventional\nsoftware, organizations also use spreadsheets for a large part of their\noperations and decision-making activities. Therefore we believe that\nspreadsheets are also rich in business rules. We thus propose to develop an\nautomated system for extracting business rules from spreadsheets in a human\ncomprehensible natural language format. This position paper describes our\nmotivation, the problem description, related work, and challenges we foresee.\n", "contributors": [{"name": "Roy, Sohon", "sameAs": [], "familyName": "Roy", "additionalName": "", "givenName": "Sohon", "email": ""}], "title": "Business Rule Mining from Spreadsheets", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07737", "oai:arXiv.org:1503.07737"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Business rules represent the knowledge that guides the operations of a\nbusiness organization. They are implemented in software applications used by\norganizations, and the activity of extracting them from software is known as\nbusiness rule mining. It has various purposes amongst which migration and\ngenerating documentation are the most common. However, apart from conventional\nsoftware, organizations also use spreadsheets for a large part of their\noperations and decision-making activities. Therefore we believe that\nspreadsheets are also rich in business rules. We thus propose to develop an\nautomated system for extracting business rules from spreadsheets in a human\ncomprehensible natural language format. This position paper describes our\nmotivation, the problem description, related work, and challenges we foresee.\n", "Comment: In Proceedings of the 2nd Workshop on Software Engineering Methods in\n  Spreadsheets (http://spreadsheetlab.org/sems15/)"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07737"}}, {"publisher": {"name": ""}, "description": "  Let $f$ be a transcendental entire function and let $U$ be a univalent Baker\ndomain of $f$. We prove a new result about the boundary behaviour of conformal\nmaps and use this to show that the non-escaping boundary points of $U$ form a\nset of harmonic measure zero with respect to $U$. This leads to a new\nsufficient condition for the escaping set of $f$ to be connected, and also a\nnew general result on Eremenko's conjecture.\n", "contributors": [{"name": "Rippon, Phil", "sameAs": [], "familyName": "Rippon", "additionalName": "", "givenName": "Phil", "email": ""}, {"name": "Stallard, Gwyneth", "sameAs": [], "familyName": "Stallard", "additionalName": "", "givenName": "Gwyneth", "email": ""}], "title": "Boundaries of univalent Baker domains", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.6999", "oai:arXiv.org:1411.6999"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  Let $f$ be a transcendental entire function and let $U$ be a univalent Baker\ndomain of $f$. We prove a new result about the boundary behaviour of conformal\nmaps and use this to show that the non-escaping boundary points of $U$ form a\nset of harmonic measure zero with respect to $U$. This leads to a new\nsufficient condition for the escaping set of $f$ to be connected, and also a\nnew general result on Eremenko's conjecture.\n"}}], "languages": [null], "subjects": ["37f10", "30d05", "mathematics - dynamical systems", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.6999"}}, {"publisher": {"name": ""}, "description": "  The paper describes a novel approach to categorize users' reviews according\nto the three Quality in Use (QU) indicators defined in ISO: effectiveness,\nefficiency and freedom from risk. With the tremendous amount of reviews\npublished each day, there is a need to automatically summarize user reviews to\ninform us if any of the software able to meet requirement of a company\naccording to the quality requirements. We implemented the method of Latent\nSemantic Analysis (LSA) and its subspace to predict QU indicators. We build a\nreduced dimensionality universal semantic space from Information System\njournals and Amazon reviews. Next, we projected set of indicators' measurement\nscales into the universal semantic space and represent them as subspace. In the\nsubspace, we can map similar measurement scales to the unseen reviews and\npredict the QU indicators. Our preliminary study able to obtain the average of\nF-measure, 0.3627.\n", "contributors": [{"name": "Syn, Wendy Tan Wei", "sameAs": [], "familyName": "Syn", "additionalName": "Tan Wei", "givenName": "Wendy", "email": ""}, {"name": "How, Bong Chih", "sameAs": [], "familyName": "How", "additionalName": "Chih", "givenName": "Bong", "email": ""}, {"name": "Atoum, Issa", "sameAs": [], "familyName": "Atoum", "additionalName": "", "givenName": "Issa", "email": ""}], "title": "Using Latent Semantic Analysis to Identify Quality in Use (QU)\n  Indicators from User Reviews", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07294", "oai:arXiv.org:1503.07294"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The paper describes a novel approach to categorize users' reviews according\nto the three Quality in Use (QU) indicators defined in ISO: effectiveness,\nefficiency and freedom from risk. With the tremendous amount of reviews\npublished each day, there is a need to automatically summarize user reviews to\ninform us if any of the software able to meet requirement of a company\naccording to the quality requirements. We implemented the method of Latent\nSemantic Analysis (LSA) and its subspace to predict QU indicators. We build a\nreduced dimensionality universal semantic space from Information System\njournals and Amazon reviews. Next, we projected set of indicators' measurement\nscales into the universal semantic space and represent them as subspace. In the\nsubspace, we can map similar measurement scales to the unseen reviews and\npredict the QU indicators. Our preliminary study able to obtain the average of\nF-measure, 0.3627.\n", "Comment: 4 Figures in The International Conference on Artificial Intelligence\n  and Pattern Recognition (AIPR2014),2014"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - information retrieval", "computer science - computation and language"], "providerUpdatedDateTime": "2015-03-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07294"}}, {"publisher": {"name": ""}, "description": "  Given a polygon and a visibility range, the Myopic Watchman Problem with\nDiscrete Vision (MWPDV) asks for a closed path P and a set of scan points S,\nsuch that (i) every point of the polygon is within visibility range of a scan\npoint; and (ii) path length plus weighted sum of scan number along the tour is\nminimized. Alternatively, the bicriteria problem (ii') aims at minimizing both\nscan number and tour length. We consider both lawn mowing (in which tour and\nscan points may leave P) and milling (in which tour, scan points and visibility\nmust stay within P) variants for the MWPDV; even for simple special cases,\nthese problems are NP-hard.\n  We show that this problem is NP-hard, even for the special cases of\nrectilinear polygons and L_\\infty scan range 1, and negligible small travel\ncost or negligible travel cost. For rectilinear MWPDV milling in grid polygons\nwe present a 2.5-approximation with unit scan range; this holds for the\nbicriteria version, thus for any linear combination of travel cost and scan\ncost. For grid polygons and circular unit scan range, we describe a bicriteria\n4-approximation. These results serve as stepping stones for the general case of\ncircular scans with scan radius r and arbitrary polygons of feature size a, for\nwhich we extend the underlying ideas to a pi(r/a}+(r+1)/2) bicriteria\napproximation algorithm. Finally, we describe approximation schemes for MWPDV\nlawn mowing and milling of grid polygons, for fixed ratio between scan cost and\ntravel cost.\n", "contributors": [{"name": "Fekete, Sandor P.", "sameAs": [], "familyName": "Fekete", "additionalName": "P.", "givenName": "Sandor", "email": ""}, {"name": "Mitchell, Joseph S. B.", "sameAs": [], "familyName": "Mitchell", "additionalName": "S. B.", "givenName": "Joseph", "email": ""}, {"name": "Schmidt, Christiane", "sameAs": [], "familyName": "Schmidt", "additionalName": "", "givenName": "Christiane", "email": ""}], "title": "Minimum Covering with Travel Cost", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-01-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.2360", "oai:arXiv.org:1101.2360"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Given a polygon and a visibility range, the Myopic Watchman Problem with\nDiscrete Vision (MWPDV) asks for a closed path P and a set of scan points S,\nsuch that (i) every point of the polygon is within visibility range of a scan\npoint; and (ii) path length plus weighted sum of scan number along the tour is\nminimized. Alternatively, the bicriteria problem (ii') aims at minimizing both\nscan number and tour length. We consider both lawn mowing (in which tour and\nscan points may leave P) and milling (in which tour, scan points and visibility\nmust stay within P) variants for the MWPDV; even for simple special cases,\nthese problems are NP-hard.\n  We show that this problem is NP-hard, even for the special cases of\nrectilinear polygons and L_\\infty scan range 1, and negligible small travel\ncost or negligible travel cost. For rectilinear MWPDV milling in grid polygons\nwe present a 2.5-approximation with unit scan range; this holds for the\nbicriteria version, thus for any linear combination of travel cost and scan\ncost. For grid polygons and circular unit scan range, we describe a bicriteria\n4-approximation. These results serve as stepping stones for the general case of\ncircular scans with scan radius r and arbitrary polygons of feature size a, for\nwhich we extend the underlying ideas to a pi(r/a}+(r+1)/2) bicriteria\napproximation algorithm. Finally, we describe approximation schemes for MWPDV\nlawn mowing and milling of grid polygons, for fixed ratio between scan cost and\ntravel cost.\n", "Comment: 17 pages, 12 figures; extended abstract appears in ISAAC 2009, full\n  version to appear in Journal of Combinatorial Optimization"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "f.2.2", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.2360"}}, {"publisher": {"name": ""}, "description": "  Nevanlinna showed that two non-constant meromorphic functions on $\\mathbb C$\nmust be linked by a M\\\"{o}bius transformation if they have the same inverse\nimages counted with multiplicities for four distinct values. After that this\nresults is generalized by Gundersen to the case where two meromorphic functions\nshare two values ignoring multiplicity and share other two values with\nmultiplicities trucated by 2. Previously, the first author proved that for\n$n\\ge 2,$ there are at most two linearly nondegenerate meromorphic mappings of\n$\\mathbb C^m$ into $\\mathbb P^n(\\mathbb C)$ sharing $2n+2$ hyperplanes\ningeneral position ignoring multiplicity. In this article, we will show that if\ntwo meromorphic mappings $f$ and $g$ of $\\mathbb C^m$ into $\\mathbb P^n(\\mathbb\nC)$ share $2n+1$ hyperplanes ignoring multiplicity and another hyperplane with\nmultiplicities trucated by $n+1$ then the map $f\\times g$ is algebraically\ndegenerate.\n", "contributors": [{"name": "Quang, Si Duc", "sameAs": [], "familyName": "Quang", "additionalName": "Duc", "givenName": "Si", "email": ""}, {"name": "Quynh, Le Ngoc", "sameAs": [], "familyName": "Quynh", "additionalName": "", "givenName": "Le Ngoc", "email": ""}], "title": "Two meromorphic mappings sharing 2n + 2 hyperplanes regardless of\n  multiplicity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-02-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1302.2297", "Journal of Mathematical Analysis and Applications, Volume 410,\n  Issue 2, 15 February 2014, Pages 771-782", "doi:10.1016/j.jmaa.2013.09.003", "oai:arXiv.org:1302.2297"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Nevanlinna showed that two non-constant meromorphic functions on $\\mathbb C$\nmust be linked by a M\\\"{o}bius transformation if they have the same inverse\nimages counted with multiplicities for four distinct values. After that this\nresults is generalized by Gundersen to the case where two meromorphic functions\nshare two values ignoring multiplicity and share other two values with\nmultiplicities trucated by 2. Previously, the first author proved that for\n$n\\ge 2,$ there are at most two linearly nondegenerate meromorphic mappings of\n$\\mathbb C^m$ into $\\mathbb P^n(\\mathbb C)$ sharing $2n+2$ hyperplanes\ningeneral position ignoring multiplicity. In this article, we will show that if\ntwo meromorphic mappings $f$ and $g$ of $\\mathbb C^m$ into $\\mathbb P^n(\\mathbb\nC)$ share $2n+1$ hyperplanes ignoring multiplicity and another hyperplane with\nmultiplicities trucated by $n+1$ then the map $f\\times g$ is algebraically\ndegenerate.\n", "Comment: 16 pages"]}}], "languages": [null], "subjects": ["32h04", "32a22", "32a35", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1302.2297"}}, {"publisher": {"name": ""}, "description": "  We generalized a concept of index boundedness in the direction for analytic\nin an unit ball functions of several variables. The necessary and sufficient\nconditions of $L$-index boundedness of analytic functions and sufficient\nconditions of $L$-index boundedness in the direction for analytic solutions of\npartial differential equations are obtained.\n", "contributors": [{"name": "Bandura, A. I.", "sameAs": [], "familyName": "Bandura", "additionalName": "I.", "givenName": "A.", "email": ""}, {"name": "Skaskiv, O. B.", "sameAs": [], "familyName": "Skaskiv", "additionalName": "B.", "givenName": "O.", "email": ""}], "title": "Analytic in an unit ball functions of bounded $L$-index in direction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04166", "oai:arXiv.org:1501.04166"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  We generalized a concept of index boundedness in the direction for analytic\nin an unit ball functions of several variables. The necessary and sufficient\nconditions of $L$-index boundedness of analytic functions and sufficient\nconditions of $L$-index boundedness in the direction for analytic solutions of\npartial differential equations are obtained.\n"}}], "languages": [null], "subjects": ["32a17", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04166"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "The research documented in this report seeks to advance the understanding of the unintentional insider threat (UIT) that results from phishing and other social engineering cases, specifically those involving malicious software (malware). The research team collected and analyzed publicly reported phishing cases involving malware and performed an initial analysis of the industry sectors impacted by this type of incident. This report provides that analysis as well as case examples and potential recommendations for mitigating UITs stemming from phishing and other social engineering incidents. The report also compares security offices\u2019 current practice of UIT monitoring to the current manufacturing and healthcare industries\u2019 practice of tracking near misses of adverse events.", "contributors": [{"name": "CERT Insider Threat Team", "sameAs": [], "familyName": "Team", "additionalName": "Insider Threat", "givenName": "CERT", "email": ""}], "title": "Unintentional Insider Threats: A Review of Phishing and Malware Incidents by Economic Sector", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-07-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/sei/802", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1799&amp;context=sei", "oai:repository.cmu.edu:sei-1799"]}}, {"name": "setSpec", "properties": {"setSpec": "publication:sei"}}, {"name": "description", "properties": {"description": "The research documented in this report seeks to advance the understanding of the unintentional insider threat (UIT) that results from phishing and other social engineering cases, specifically those involving malicious software (malware). The research team collected and analyzed publicly reported phishing cases involving malware and performed an initial analysis of the industry sectors impacted by this type of incident. This report provides that analysis as well as case examples and potential recommendations for mitigating UITs stemming from phishing and other social engineering incidents. The report also compares security offices\u2019 current practice of UIT monitoring to the current manufacturing and healthcare industries\u2019 practice of tracking near misses of adverse events."}}], "languages": [null], "subjects": ["malware", "software engineering", "unintentional insider threat", "phishing", "computer sciences", "social threat vector", "cases"], "providerUpdatedDateTime": "2014-11-04T16:15:42", "uris": {"canonicalUri": "http://repository.cmu.edu/sei/802"}}, {"publisher": {"name": ""}, "description": "  In object recognition, Fisher vector (FV) representation is one of the\nstate-of-art image representations ways at the expense of dense, high\ndimensional features and increased computation time. A simplification of FV is\nattractive, so we propose Sparse Fisher vector (SFV). By incorporating locality\nstrategy, we can accelerate the Fisher coding step in image categorization\nwhich is implemented from a collective of local descriptors. Combining with\npooling step, we explore the relationship between coding step and pooling step\nto give a theoretical explanation about SFV. Experiments on benchmark datasets\nhave shown that SFV leads to a speedup of several-fold of magnitude compares\nwith FV, while maintaining the categorization performance. In addition, we\ndemonstrate how SFV preserves the consistence in representation of similar\nlocal features.\n", "contributors": [{"name": "Lu, Xiankai", "sameAs": [], "familyName": "Lu", "additionalName": "", "givenName": "Xiankai", "email": ""}, {"name": "Fang, Zheng", "sameAs": [], "familyName": "Fang", "additionalName": "", "givenName": "Zheng", "email": ""}, {"name": "Xu, Tao", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Tao", "email": ""}, {"name": "Zhang, Haiting", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Haiting", "email": ""}, {"name": "Tuo, Hongya", "sameAs": [], "familyName": "Tuo", "additionalName": "", "givenName": "Hongya", "email": ""}], "title": "Efficient Image Categorization with Sparse Fisher Vector", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.3905", "oai:arXiv.org:1410.3905"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In object recognition, Fisher vector (FV) representation is one of the\nstate-of-art image representations ways at the expense of dense, high\ndimensional features and increased computation time. A simplification of FV is\nattractive, so we propose Sparse Fisher vector (SFV). By incorporating locality\nstrategy, we can accelerate the Fisher coding step in image categorization\nwhich is implemented from a collective of local descriptors. Combining with\npooling step, we explore the relationship between coding step and pooling step\nto give a theoretical explanation about SFV. Experiments on benchmark datasets\nhave shown that SFV leads to a speedup of several-fold of magnitude compares\nwith FV, while maintaining the categorization performance. In addition, we\ndemonstrate how SFV preserves the consistence in representation of similar\nlocal features.\n", "Comment: 5pages,4 figures"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-10-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.3905"}}, {"publisher": {"name": ""}, "description": "  Software capable of improving itself has been a dream of computer scientists\nsince the inception of the field. In this work we provide definitions for\nRecursively Self-Improving software, survey different types of self-improving\nsoftware, review the relevant literature, analyze limits on computation\nrestricting recursive self-improvement and introduce RSI Convergence Theory\nwhich aims to predict general behavior of RSI systems. Finally, we address\nsecurity implications from self-improving intelligent software.\n", "contributors": [{"name": "Yampolskiy, Roman V.", "sameAs": [], "familyName": "Yampolskiy", "additionalName": "V.", "givenName": "Roman", "email": ""}], "title": "From Seed AI to Technological Singularity via Recursively Self-Improving\n  Software", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06512", "oai:arXiv.org:1502.06512"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Software capable of improving itself has been a dream of computer scientists\nsince the inception of the field. In this work we provide definitions for\nRecursively Self-Improving software, survey different types of self-improving\nsoftware, review the relevant literature, analyze limits on computation\nrestricting recursive self-improvement and introduce RSI Convergence Theory\nwhich aims to predict general behavior of RSI systems. Finally, we address\nsecurity implications from self-improving intelligent software.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06512"}}, {"publisher": {"name": ""}, "description": "  A nonlinear frequency response based adaptive vibration controller is\nproposed for a class of nonlinear mechanical systems. In order to obtain the\nnonlinear Frequency Response Function (FRF), the convergence properties of the\nsystem are studied by using the convergence (contraction) theory. If the system\nunder consideration is: 1) convergent, it directly enables to derive a\nnonlinear FRF for a band of excitation inputs, 2) non-convergent, first a\ncontroller is used to obtain the convergence and then the corresponding FRF for\na band of excitation inputs is derived. Now the gains of the proposed adaptive\ncontroller are tuned such that a desired closed-loop frequency response, in the\npresence of excitation inputs is achieved. Finally, a building structure with\nnonlinear cubic stiffness and a satellite system are considered to illustrate\nthe theoretical results.\n", "contributors": [{"name": "Thenozhi, Suresh", "sameAs": [], "familyName": "Thenozhi", "additionalName": "", "givenName": "Suresh", "email": ""}, {"name": "Tang, Yu", "sameAs": [], "familyName": "Tang", "additionalName": "", "givenName": "Yu", "email": ""}], "title": "Vibration Control Design for Nonlinear Systems using Frequency Response\n  Function", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08007", "oai:arXiv.org:1503.08007"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  A nonlinear frequency response based adaptive vibration controller is\nproposed for a class of nonlinear mechanical systems. In order to obtain the\nnonlinear Frequency Response Function (FRF), the convergence properties of the\nsystem are studied by using the convergence (contraction) theory. If the system\nunder consideration is: 1) convergent, it directly enables to derive a\nnonlinear FRF for a band of excitation inputs, 2) non-convergent, first a\ncontroller is used to obtain the convergence and then the corresponding FRF for\na band of excitation inputs is derived. Now the gains of the proposed adaptive\ncontroller are tuned such that a desired closed-loop frequency response, in the\npresence of excitation inputs is achieved. Finally, a building structure with\nnonlinear cubic stiffness and a satellite system are considered to illustrate\nthe theoretical results.\n"}}], "languages": [null], "subjects": ["computer science - systems and control"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08007"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Hidden Markov Models (HMMs) are important tools for modeling sequence data. However, they are restricted to discrete latent states, and are largely restricted to Gaussian and discrete observations. And, learning algorithms for HMMs have predominantly relied on local search heuristics, with the exception of spectral methods such as those described below. We propose a nonparametric HMM that extends traditional HMMs to structured and non-Gaussian continuous distributions. Furthermore, we derive a localminimum-free kernel spectral algorithm for learning these HMMs. We apply our method to robot vision data, slot car inertial sensor data and audio event classification data, and show that in these applications, embedded HMMs exceed the previous state-of-the-art performance.", "contributors": [{"name": "Song, Le", "sameAs": [], "familyName": "Song", "additionalName": "", "givenName": "Le", "email": ""}, {"name": "Boots, Byron", "sameAs": [], "familyName": "Boots", "additionalName": "", "givenName": "Byron", "email": ""}, {"name": "Siddiqi, Sajid M.", "sameAs": [], "familyName": "Siddiqi", "additionalName": "M.", "givenName": "Sajid", "email": ""}, {"name": "Gordon, Geoffrey J.", "sameAs": [], "familyName": "Gordon", "additionalName": "J.", "givenName": "Geoffrey", "email": ""}, {"name": "Smola, Alex", "sameAs": [], "familyName": "Smola", "additionalName": "", "givenName": "Alex", "email": ""}], "title": "Hilbert Space Embeddings of Hidden Markov Models", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2010-06-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/54", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1057&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1057"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Hidden Markov Models (HMMs) are important tools for modeling sequence data. However, they are restricted to discrete latent states, and are largely restricted to Gaussian and discrete observations. And, learning algorithms for HMMs have predominantly relied on local search heuristics, with the exception of spectral methods such as those described below. We propose a nonparametric HMM that extends traditional HMMs to structured and non-Gaussian continuous distributions. Furthermore, we derive a localminimum-free kernel spectral algorithm for learning these HMMs. We apply our method to robot vision data, slot car inertial sensor data and audio event classification data, and show that in these applications, embedded HMMs exceed the previous state-of-the-art performance."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-10T21:34:28", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/54"}}, {"publisher": {"name": ""}, "description": "  The Astrophysics Source Code Library (ASCL; ascl.net) is a free online\nregistry of codes used in astronomy research; it currently contains over 900\ncodes and is indexed by ADS. The ASCL has recently moved a new infrastructure\ninto production. The new site provides a true database for the code entries and\nintegrates the WordPress news and information pages and the discussion forum\ninto one site. Previous capabilities are retained and permalinks to ascl.net\ncontinue to work. This improvement offers more functionality and flexibility\nthan the previous site, is easier to maintain, and offers new possibilities for\ncollaboration. This presentation covers these recent changes to the ASCL.\n", "contributors": [{"name": "Hanisch, Robert J.", "sameAs": [], "familyName": "Hanisch", "additionalName": "J.", "givenName": "Robert", "email": ""}, {"name": "Allen, Alice", "sameAs": [], "familyName": "Allen", "additionalName": "", "givenName": "Alice", "email": ""}, {"name": "Berriman, G. Bruce", "sameAs": [], "familyName": "Berriman", "additionalName": "Bruce", "givenName": "G.", "email": ""}, {"name": "DuPrie, Kimberly", "sameAs": [], "familyName": "DuPrie", "additionalName": "", "givenName": "Kimberly", "email": ""}, {"name": "Mink, Jessica", "sameAs": [], "familyName": "Mink", "additionalName": "", "givenName": "Jessica", "email": ""}, {"name": "Nemiroff, Robert J.", "sameAs": [], "familyName": "Nemiroff", "additionalName": "J.", "givenName": "Robert", "email": ""}, {"name": "Schmidt, Judy", "sameAs": [], "familyName": "Schmidt", "additionalName": "", "givenName": "Judy", "email": ""}, {"name": "Shamir, Lior", "sameAs": [], "familyName": "Shamir", "additionalName": "", "givenName": "Lior", "email": ""}, {"name": "Shortridge, Keith", "sameAs": [], "familyName": "Shortridge", "additionalName": "", "givenName": "Keith", "email": ""}, {"name": "Taylor, Mark", "sameAs": [], "familyName": "Taylor", "additionalName": "", "givenName": "Mark", "email": ""}, {"name": "Teuben, Peter J.", "sameAs": [], "familyName": "Teuben", "additionalName": "J.", "givenName": "Peter", "email": ""}, {"name": "Wallin, John", "sameAs": [], "familyName": "Wallin", "additionalName": "", "givenName": "John", "email": ""}], "title": "Astrophysics Source Code Library Enhancements", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2031", "oai:arXiv.org:1411.2031"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:astro-ph"]}}, {"name": "description", "properties": {"description": ["  The Astrophysics Source Code Library (ASCL; ascl.net) is a free online\nregistry of codes used in astronomy research; it currently contains over 900\ncodes and is indexed by ADS. The ASCL has recently moved a new infrastructure\ninto production. The new site provides a true database for the code entries and\nintegrates the WordPress news and information pages and the discussion forum\ninto one site. Previous capabilities are retained and permalinks to ascl.net\ncontinue to work. This improvement offers more functionality and flexibility\nthan the previous site, is easier to maintain, and offers new possibilities for\ncollaboration. This presentation covers these recent changes to the ASCL.\n", "Comment: 4 pages; to be published in ADASS XXIV Proceedings. ASCL can be\n  accessed at http://ascl.net/"]}}], "languages": [null], "subjects": ["computer science - digital libraries", "astrophysics - instrumentation and methods for astrophysics"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2031"}}, {"publisher": {"name": ""}, "description": "  In wireless sensor networks (WSNs), security has a vital importance.\nRecently, there was a huge interest to propose security solutions in WSNs\nbecause of their applications in both civilian and military domains.\nAdversaries can launch different types of attacks, and cryptography is used to\ncountering these attacks. This paper presents challenges of security and a\nclassification of the different possible attacks in WSNs. The problems of\nsecurity in each layer of the network's OSI model are discussed.\n", "contributors": [{"name": "Messai, Mohamed-Lamine", "sameAs": [], "familyName": "Messai", "additionalName": "", "givenName": "Mohamed-Lamine", "email": ""}], "title": "Classification of Attacks in Wireless Sensor Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-17", "2014-11-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.4516", "oai:arXiv.org:1406.4516"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In wireless sensor networks (WSNs), security has a vital importance.\nRecently, there was a huge interest to propose security solutions in WSNs\nbecause of their applications in both civilian and military domains.\nAdversaries can launch different types of attacks, and cryptography is used to\ncountering these attacks. This paper presents challenges of security and a\nclassification of the different possible attacks in WSNs. The problems of\nsecurity in each layer of the network's OSI model are discussed.\n", "Comment: International Congress on Telecommunication and Application 2014"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "k.6.5"], "providerUpdatedDateTime": "2014-12-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.4516"}}, {"publisher": {"name": ""}, "description": "  The classic Gibbard-Satterthwaite theorem says that every strategy-proof\nvoting rule with at least three possible candidates must be dictatorial.\nSimilar impossibility results hold even if we consider a weaker notion of\nstrategy-proofness where voters believe that the other voters' preferences are\ni.i.d.~(independent and identically distributed). In this paper, we take a\nbounded-rationality approach to this problem and consider a setting where\nvoters have \"coarse\" beliefs (a notion that has gained popularity in the\nbehavioral economics literature). In particular, we construct good voting rules\nthat satisfy a notion of strategy-proofness with respect to coarse\ni.i.d.~beliefs, thus circumventing the above impossibility results.\n", "contributors": [{"name": "Leung, Samantha", "sameAs": [], "familyName": "Leung", "additionalName": "", "givenName": "Samantha", "email": ""}, {"name": "Lui, Edward", "sameAs": [], "familyName": "Lui", "additionalName": "", "givenName": "Edward", "email": ""}, {"name": "Pass, Rafael", "sameAs": [], "familyName": "Pass", "additionalName": "", "givenName": "Rafael", "email": ""}], "title": "Voting with Coarse Beliefs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-22", "2015-01-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.5827", "oai:arXiv.org:1405.5827"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The classic Gibbard-Satterthwaite theorem says that every strategy-proof\nvoting rule with at least three possible candidates must be dictatorial.\nSimilar impossibility results hold even if we consider a weaker notion of\nstrategy-proofness where voters believe that the other voters' preferences are\ni.i.d.~(independent and identically distributed). In this paper, we take a\nbounded-rationality approach to this problem and consider a setting where\nvoters have \"coarse\" beliefs (a notion that has gained popularity in the\nbehavioral economics literature). In particular, we construct good voting rules\nthat satisfy a notion of strategy-proofness with respect to coarse\ni.i.d.~beliefs, thus circumventing the above impossibility results.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2015-01-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.5827"}}, {"publisher": {"name": ""}, "description": "  Automated extraction of semantic information from a network of sensors for\ncognitive analysis and human-like reasoning is a desired capability in future\nground surveillance systems. We tackle the problem of complex decision making\nunder uncertainty in network information environment, where lack of effective\nvisual processing tools, incomplete domain knowledge frequently cause\nuncertainty in the visual primitives, leading to sub-optimal decisions. While\nstate-of-the-art vision techniques exist in detecting visual entities (humans,\nvehicles and scene elements) in an image, a missing functionality is the\nability to merge the information to reveal meaningful information for high\nlevel inference. In this work, we develop a probabilistic first order predicate\nlogic(FOPL) based reasoning system for recognizing complex events in\nsynchronized stream of videos, acquired from sensors with non-overlapping\nfields of view. We adopt Markov Logic Network(MLN) as a tool to model\nuncertainty in observations, and fuse information extracted from heterogeneous\ndata in a probabilistically consistent way. MLN overcomes strong dependence on\npure empirical learning by incorporating domain knowledge, in the form of\nuser-defined rules and confidences associated with them. This work demonstrates\nthat the MLN based decision control system can be made scalable to model\nstatistical relations between a variety of entities and over long video\nsequences. Experiments with real-world data, under a variety of settings,\nillustrate the mathematical soundness and wide-ranging applicability of our\napproach.\n", "contributors": [{"name": "Kanaujia, Atul", "sameAs": [], "familyName": "Kanaujia", "additionalName": "", "givenName": "Atul", "email": ""}, {"name": "Choe, Tae Eun", "sameAs": [], "familyName": "Choe", "additionalName": "Eun", "givenName": "Tae", "email": ""}, {"name": "Deng, Hongli", "sameAs": [], "familyName": "Deng", "additionalName": "", "givenName": "Hongli", "email": ""}], "title": "Complex Events Recognition under Uncertainty in a Sensor Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0085", "oai:arXiv.org:1411.0085"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Automated extraction of semantic information from a network of sensors for\ncognitive analysis and human-like reasoning is a desired capability in future\nground surveillance systems. We tackle the problem of complex decision making\nunder uncertainty in network information environment, where lack of effective\nvisual processing tools, incomplete domain knowledge frequently cause\nuncertainty in the visual primitives, leading to sub-optimal decisions. While\nstate-of-the-art vision techniques exist in detecting visual entities (humans,\nvehicles and scene elements) in an image, a missing functionality is the\nability to merge the information to reveal meaningful information for high\nlevel inference. In this work, we develop a probabilistic first order predicate\nlogic(FOPL) based reasoning system for recognizing complex events in\nsynchronized stream of videos, acquired from sensors with non-overlapping\nfields of view. We adopt Markov Logic Network(MLN) as a tool to model\nuncertainty in observations, and fuse information extracted from heterogeneous\ndata in a probabilistically consistent way. MLN overcomes strong dependence on\npure empirical learning by incorporating domain knowledge, in the form of\nuser-defined rules and confidences associated with them. This work demonstrates\nthat the MLN based decision control system can be made scalable to model\nstatistical relations between a variety of entities and over long video\nsequences. Experiments with real-world data, under a variety of settings,\nillustrate the mathematical soundness and wide-ranging applicability of our\napproach.\n", "Comment: 13 pages"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0085"}}, {"publisher": {"name": ""}, "description": "  In the standard testing theory of DeNicola-Hennessy one process is considered\nto be a refinement of another if every test guaranteed by the former is also\nguaranteed by the latter. In the domain of web services this has been recast,\nwith processes viewed as servers and tests as clients. In this way the standard\nrefinement preorder between servers is determined by their ability to satisfy\nclients. But in this setting there is also a natural refinement preorder\nbetween clients, determined by their ability to be satisfied by servers. In\nmore general settings where there is no distinction between clients and\nservers, but all processes are peers, there is a further refinement preorder\nbased on the mutual satisfaction of peers. We give a uniform account of these\nthree preorders. In particular we give two characterisations. The first is\nbehavioural, in terms of traces and ready sets. The second, for finite\nprocesses, is equational.\n", "contributors": [{"name": "Bernardi, Giovanni", "sameAs": [], "familyName": "Bernardi", "additionalName": "", "givenName": "Giovanni", "email": ""}, {"name": "Hennessy, Matthew", "sameAs": [], "familyName": "Hennessy", "additionalName": "", "givenName": "Matthew", "email": ""}], "title": "Mutually Testing Processes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-02-23", "2015-04-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06360", "LMCS 11 (2:1) 2015", "doi:10.2168/LMCS-11(2:1)2015", "oai:arXiv.org:1502.06360"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In the standard testing theory of DeNicola-Hennessy one process is considered\nto be a refinement of another if every test guaranteed by the former is also\nguaranteed by the latter. In the domain of web services this has been recast,\nwith processes viewed as servers and tests as clients. In this way the standard\nrefinement preorder between servers is determined by their ability to satisfy\nclients. But in this setting there is also a natural refinement preorder\nbetween clients, determined by their ability to be satisfied by servers. In\nmore general settings where there is no distinction between clients and\nservers, but all processes are peers, there is a further refinement preorder\nbased on the mutual satisfaction of peers. We give a uniform account of these\nthree preorders. In particular we give two characterisations. The first is\nbehavioural, in terms of traces and ready sets. The second, for finite\nprocesses, is equational.\n"}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06360"}}, {"publisher": {"name": ""}, "description": "  Devising an appropriate scheme that assigns the weights to share credits\namong multiple authors of a paper is a challenging task. This challenge comes\nfrom the fact that different types of conventions might be followed among\ndifferent research discipline or research groups. In this paper, we discuss\nthat for the purpose of evaluating the quality of research produced by authors,\none can resequence either authors or weights and can apply a weight assignment\npolicy which the evaluator deems fit for the particular research discipline or\nresearch group.\n", "contributors": [{"name": "Abbas, Ash Mohammad", "sameAs": [], "familyName": "Abbas", "additionalName": "Mohammad", "givenName": "Ash", "email": ""}], "title": "Resequencing: A Method for Conforming to Conventions for Sharing Credits\n  Among Multiple Authors", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-01-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.2985", "oai:arXiv.org:1101.2985"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Devising an appropriate scheme that assigns the weights to share credits\namong multiple authors of a paper is a challenging task. This challenge comes\nfrom the fact that different types of conventions might be followed among\ndifferent research discipline or research groups. In this paper, we discuss\nthat for the purpose of evaluating the quality of research produced by authors,\none can resequence either authors or weights and can apply a weight assignment\npolicy which the evaluator deems fit for the particular research discipline or\nresearch group.\n", "Comment: 3 pages, 2 figures"]}}], "languages": [null], "subjects": ["h.3.3", "h.3.1", "68m20", "h.3.7", "computer science - digital libraries", "computer science - information retrieval", "computer science - computers and society"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.2985"}}, {"publisher": {"name": ""}, "description": "  A theoretical analysis and a practical solution to the fundamental problem of\noptimum perfect universal steganography of finite memoryless sources with a\npassive warden are provided. The theoretical analysis rests on the fact that\nSlepian's Variant I permutation coding implements first-order perfect universal\nsteganography with maximum embedding rate. The practical solution underlines\nthe duality between perfect steganography with optimum embedding rate and\nlossless source coding with optimum compression rate, since it is shown that\npermutation coding can be implemented by means of adaptive arithmetic coding. A\ndistance constraint between host signal and information-carrying signal must be\nobserved in universal steganography, and thus an optimum tradeoff between\nembedding rate and embedding distortion must be achieved. Partitioned\npermutation coding is shown to be the solution to this problem. A practical\nimplementation of partitioned permutation coding is given that performs close\nto an unattainable upper bound on the rate-distortion function of the problem.\n", "contributors": [{"name": "Balado, F\u00e9lix", "sameAs": [], "familyName": "Balado", "additionalName": "", "givenName": "F\u00e9lix", "email": ""}, {"name": "Haughton, David", "sameAs": [], "familyName": "Haughton", "additionalName": "", "givenName": "David", "email": ""}], "title": "Optimum Perfect Universal Steganography of Finite Memoryless Sources", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-09", "2014-10-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2659", "oai:arXiv.org:1410.2659"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A theoretical analysis and a practical solution to the fundamental problem of\noptimum perfect universal steganography of finite memoryless sources with a\npassive warden are provided. The theoretical analysis rests on the fact that\nSlepian's Variant I permutation coding implements first-order perfect universal\nsteganography with maximum embedding rate. The practical solution underlines\nthe duality between perfect steganography with optimum embedding rate and\nlossless source coding with optimum compression rate, since it is shown that\npermutation coding can be implemented by means of adaptive arithmetic coding. A\ndistance constraint between host signal and information-carrying signal must be\nobserved in universal steganography, and thus an optimum tradeoff between\nembedding rate and embedding distortion must be achieved. Partitioned\npermutation coding is shown to be the solution to this problem. A practical\nimplementation of partitioned permutation coding is given that performs close\nto an unattainable upper bound on the rate-distortion function of the problem.\n", "Comment: 18 pages, 3 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2659"}}, {"publisher": {"name": ""}, "description": "  This paper proposes a fast and accurate method for sparse regression in the\npresence of missing data. The underlying statistical model encapsulates the\nlow-dimensional structure of the incomplete data matrix and the sparsity of the\nregression coefficients, and the proposed algorithm jointly learns the\nlow-dimensional structure of the data and a linear regressor with sparse\ncoefficients. The proposed stochastic optimization method, Sparse Linear\nRegression with Missing Data (SLRM), performs an alternating minimization\nprocedure and scales well with the problem size. Large deviation inequalities\nshed light on the impact of the various problem-dependent parameters on the\nexpected squared loss of the learned regressor. Extensive simulations on both\nsynthetic and real datasets show that SLRM performs better than competing\nalgorithms in a variety of contexts.\n", "contributors": [{"name": "Ganti, Ravi", "sameAs": [], "familyName": "Ganti", "additionalName": "", "givenName": "Ravi", "email": ""}, {"name": "Willett, Rebecca M.", "sameAs": [], "familyName": "Willett", "additionalName": "M.", "givenName": "Rebecca", "email": ""}], "title": "Sparse Linear Regression With Missing Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08348", "oai:arXiv.org:1503.08348"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  This paper proposes a fast and accurate method for sparse regression in the\npresence of missing data. The underlying statistical model encapsulates the\nlow-dimensional structure of the incomplete data matrix and the sparsity of the\nregression coefficients, and the proposed algorithm jointly learns the\nlow-dimensional structure of the data and a linear regressor with sparse\ncoefficients. The proposed stochastic optimization method, Sparse Linear\nRegression with Missing Data (SLRM), performs an alternating minimization\nprocedure and scales well with the problem size. Large deviation inequalities\nshed light on the impact of the various problem-dependent parameters on the\nexpected squared loss of the learned regressor. Extensive simulations on both\nsynthetic and real datasets show that SLRM performs better than competing\nalgorithms in a variety of contexts.\n", "Comment: 14 pages, 7 figures"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning", "statistics - methodology"], "providerUpdatedDateTime": "2015-03-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08348"}}, {"publisher": {"name": ""}, "description": "  In this report we review and discuss some theoretical aspects of Amari's\nnatural gradient method, provide a unifying picture of the many different\nversions of it which have appeared over the years, and offer some new insights\nand perspectives regarding the method and its relationship to other\noptimization methods. Among our various contributions is the identification of\na general condition under which the Fisher information matrix and Schraudolph's\ngeneralized Gauss-Newton matrix are equivalent. This equivalence implies that\noptimization methods which use the latter matrix, such as the Hessian-free\noptimization approach of Martens, are actually natural gradient methods in\ndisguise. It also lets us view natural gradient methods as approximate Newton\nmethods, justifying the application of various \"update damping\" techniques to\nthem, which are designed to compensate for break-downs in local quadratic\napproximations. Additionally, we analyze the parameterization invariance\npossessed by the natural gradient method in the idealized setting of\ninfinitesimally small update steps, and consider the extent to which it holds\nfor practical versions of the method which take large discrete steps. We go on\nto show that parameterization invariance is not possessed by the classical\nNewton-Raphson method (even in the idealized setting), and then give a general\ncharacterization of gradient-based methods which do possess it.\n", "contributors": [{"name": "Martens, James", "sameAs": [], "familyName": "Martens", "additionalName": "", "givenName": "James", "email": ""}], "title": "New perspectives on the natural gradient method", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-03", "2015-04-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1193", "oai:arXiv.org:1412.1193"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  In this report we review and discuss some theoretical aspects of Amari's\nnatural gradient method, provide a unifying picture of the many different\nversions of it which have appeared over the years, and offer some new insights\nand perspectives regarding the method and its relationship to other\noptimization methods. Among our various contributions is the identification of\na general condition under which the Fisher information matrix and Schraudolph's\ngeneralized Gauss-Newton matrix are equivalent. This equivalence implies that\noptimization methods which use the latter matrix, such as the Hessian-free\noptimization approach of Martens, are actually natural gradient methods in\ndisguise. It also lets us view natural gradient methods as approximate Newton\nmethods, justifying the application of various \"update damping\" techniques to\nthem, which are designed to compensate for break-downs in local quadratic\napproximations. Additionally, we analyze the parameterization invariance\npossessed by the natural gradient method in the idealized setting of\ninfinitesimally small update steps, and consider the extent to which it holds\nfor practical versions of the method which take large discrete steps. We go on\nto show that parameterization invariance is not possessed by the classical\nNewton-Raphson method (even in the idealized setting), and then give a general\ncharacterization of gradient-based methods which do possess it.\n", "Comment: Expanded the discussion of the empirical Fisher and added several new\n  sections discussing various recent diagonal methods that are based on it.\n  Also fixed a few typos and made other minor tweaks"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1193"}}, {"publisher": {"name": ""}, "description": "  Using nine months of access logs comprising 1.9 Billion sessions to BBC\niPlayer, we survey the UK ISP ecosystem to understand the factors affecting\nadoption and usage of a high bandwidth TV streaming application across\ndifferent providers. We find evidence that connection speeds are important and\nthat external events can have a huge impact for live TV usage. Then, through a\ntemporal analysis of the access logs, we demonstrate that data usage caps\nimposed by mobile ISPs significantly affect usage patterns, and look for\nsolutions. We show that product bundle discounts with a related fixed-line ISP,\na strategy already employed by some mobile providers, can better support user\nneeds and capture a bigger share of accesses. We observe that users regularly\nsplit their sessions between mobile and fixed-line connections, suggesting a\nstraightforward strategy for offloading by speculatively pre-fetching content\nfrom a fixed-line ISP before access on mobile devices.\n", "contributors": [{"name": "Karamshuk, Dmytro", "sameAs": [], "familyName": "Karamshuk", "additionalName": "", "givenName": "Dmytro", "email": ""}, {"name": "Sastry, Nishanth", "sameAs": [], "familyName": "Sastry", "additionalName": "", "givenName": "Nishanth", "email": ""}, {"name": "Secker, Andrew", "sameAs": [], "familyName": "Secker", "additionalName": "", "givenName": "Andrew", "email": ""}, {"name": "Chandaria, Jigna", "sameAs": [], "familyName": "Chandaria", "additionalName": "", "givenName": "Jigna", "email": ""}], "title": "On Factors Affecting the Usage and Adoption of a Nation-wide TV\n  Streaming Service", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03542", "oai:arXiv.org:1504.03542"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Using nine months of access logs comprising 1.9 Billion sessions to BBC\niPlayer, we survey the UK ISP ecosystem to understand the factors affecting\nadoption and usage of a high bandwidth TV streaming application across\ndifferent providers. We find evidence that connection speeds are important and\nthat external events can have a huge impact for live TV usage. Then, through a\ntemporal analysis of the access logs, we demonstrate that data usage caps\nimposed by mobile ISPs significantly affect usage patterns, and look for\nsolutions. We show that product bundle discounts with a related fixed-line ISP,\na strategy already employed by some mobile providers, can better support user\nneeds and capture a bigger share of accesses. We observe that users regularly\nsplit their sessions between mobile and fixed-line connections, suggesting a\nstraightforward strategy for offloading by speculatively pre-fetching content\nfrom a fixed-line ISP before access on mobile devices.\n", "Comment: In Proceedings of IEEE INFOCOM 2015"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-04-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03542"}}, {"publisher": {"name": ""}, "description": "  Expander graphs have been intensively studied in the last four decades. In\nrecent years a high dimensional theory of expanders has emerged, and several\nvariants have been studied. Among them stand out coboundary expansion and\ntopological expansion. It is known that for every $d$ there are unbounded\ndegree simplicial complexes of dimension $d$ with these properties. However, a\nmajor open problem, formulated by Gromov, is whether bounded degree high\ndimensional expanders exist for $d \\geq 2$.\n  We present an explicit construction of bounded degree complexes of dimension\n$d=2$ which are topological expanders, thus answering Gromov's question in the\naffirmative. Conditional on a conjecture of Serre on the congruence subgroup\nproperty, infinite sub-family of these give also a family of bounded degree\ncoboundary expanders.\n  The main technical tools are new isoperimetric inequalities for Ramanujan\nComplexes. We prove linear size bounds on $F_2$ systolic invariants of these\ncomplexes, which seem to be the first linear $F_2$ systolic bounds. The\nexpansion results are deduced from these isoperimetric inequalities.\n", "contributors": [{"name": "Kaufman, Tali", "sameAs": [], "familyName": "Kaufman", "additionalName": "", "givenName": "Tali", "email": ""}, {"name": "Kazhdan, David", "sameAs": [], "familyName": "Kazhdan", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Lubotzky, Alexander", "sameAs": [], "familyName": "Lubotzky", "additionalName": "", "givenName": "Alexander", "email": ""}], "title": "Isoperimetric Inequalities for Ramanujan Complexes and Topological\n  Expanders", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-09-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.1397", "oai:arXiv.org:1409.1397"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Expander graphs have been intensively studied in the last four decades. In\nrecent years a high dimensional theory of expanders has emerged, and several\nvariants have been studied. Among them stand out coboundary expansion and\ntopological expansion. It is known that for every $d$ there are unbounded\ndegree simplicial complexes of dimension $d$ with these properties. However, a\nmajor open problem, formulated by Gromov, is whether bounded degree high\ndimensional expanders exist for $d \\geq 2$.\n  We present an explicit construction of bounded degree complexes of dimension\n$d=2$ which are topological expanders, thus answering Gromov's question in the\naffirmative. Conditional on a conjecture of Serre on the congruence subgroup\nproperty, infinite sub-family of these give also a family of bounded degree\ncoboundary expanders.\n  The main technical tools are new isoperimetric inequalities for Ramanujan\nComplexes. We prove linear size bounds on $F_2$ systolic invariants of these\ncomplexes, which seem to be the first linear $F_2$ systolic bounds. The\nexpansion results are deduced from these isoperimetric inequalities.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "mathematics - group theory", "mathematics - geometric topology", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.1397"}}, {"publisher": {"name": ""}, "description": "  We view a distributed system as a graph of active locations with\nunidirectional channels between them, through which they pass messages. In this\ncontext, the graph structure of a system constrains the propagation of\ninformation through it.\n  Suppose a set of channels is a cut set between an information source and a\npotential sink. We prove that, if there is no disclosure from the source to the\ncut set, then there can be no disclosure to the sink. We introduce a new\nformalization of partial disclosure, called *blur operators*, and show that the\nsame cut property is preserved for disclosure to within a blur operator. This\ncut-blur property also implies a compositional principle, which ensures limited\ndisclosure for a class of systems that differ only beyond the cut.\n", "contributors": [{"name": "Guttman, Joshua D.", "sameAs": [], "familyName": "Guttman", "additionalName": "D.", "givenName": "Joshua", "email": ""}, {"name": "Rowe, Paul D.", "sameAs": [], "familyName": "Rowe", "additionalName": "D.", "givenName": "Paul", "email": ""}], "title": "A Cut Principle for Information Flow", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-16", "2015-03-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4617", "oai:arXiv.org:1410.4617"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We view a distributed system as a graph of active locations with\nunidirectional channels between them, through which they pass messages. In this\ncontext, the graph structure of a system constrains the propagation of\ninformation through it.\n  Suppose a set of channels is a cut set between an information source and a\npotential sink. We prove that, if there is no disclosure from the source to the\ncut set, then there can be no disclosure to the sink. We introduce a new\nformalization of partial disclosure, called *blur operators*, and show that the\nsame cut property is preserved for disclosure to within a blur operator. This\ncut-blur property also implies a compositional principle, which ensures limited\ndisclosure for a class of systems that differ only beyond the cut.\n", "Comment: 31 pages"]}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4617"}}, {"publisher": {"name": ""}, "description": "  The complexity of the graph isomorphism problem for trapezoid graphs has been\nopen over a decade. This paper shows that the problem is GI-complete. More\nprecisely, we show that the graph isomorphism problem is GI-complete for\ncomparability graphs of partially ordered sets with interval dimension 2 and\nheight 3. In contrast, the problem is known to be solvable in polynomial time\nfor comparability graphs of partially ordered sets with interval dimension at\nmost 2 and height at most 2.\n", "contributors": [{"name": "Takaoka, Asahi", "sameAs": [], "familyName": "Takaoka", "additionalName": "", "givenName": "Asahi", "email": ""}], "title": "Graph isomorphism completeness for trapezoid graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06929", "oai:arXiv.org:1503.06929"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The complexity of the graph isomorphism problem for trapezoid graphs has been\nopen over a decade. This paper shows that the problem is GI-complete. More\nprecisely, we show that the graph isomorphism problem is GI-complete for\ncomparability graphs of partially ordered sets with interval dimension 2 and\nheight 3. In contrast, the problem is known to be solvable in polynomial time\nfor comparability graphs of partially ordered sets with interval dimension at\nmost 2 and height at most 2.\n", "Comment: 4 pages, 3 Postscript figures"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "computer science - discrete mathematics"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06929"}}, {"publisher": {"name": ""}, "description": "  In this paper, we present an iterative soft-decision decoding algorithm for\nReed-Solomon codes offering both complexity and performance advantages over\npreviously known decoding algorithms. Our algorithm is a list decoding\nalgorithm which combines two powerful soft decision decoding techniques which\nwere previously regarded in the literature as competitive, namely, the\nKoetter-Vardy algebraic soft-decision decoding algorithm and belief-propagation\nbased on adaptive parity check matrices, recently proposed by Jiang and\nNarayanan. Building on the Jiang-Narayanan algorithm, we present a\nbelief-propagation based algorithm with a significant reduction in\ncomputational complexity. We introduce the concept of using a\nbelief-propagation based decoder to enhance the soft-input information prior to\ndecoding with an algebraic soft-decision decoder. Our algorithm can also be\nviewed as an interpolation multiplicity assignment scheme for algebraic\nsoft-decision decoding of Reed-Solomon codes.\n", "contributors": [{"name": "El-Khamy, Mostafa", "sameAs": [], "familyName": "El-Khamy", "additionalName": "", "givenName": "Mostafa", "email": ""}, {"name": "McEliece, Robert J.", "sameAs": [], "familyName": "McEliece", "additionalName": "J.", "givenName": "Robert", "email": ""}], "title": "Iterative Algebraic Soft-Decision List Decoding of Reed-Solomon Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2005-09-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/cs/0509097", "IEEE Journal on Selected Areas in Communications, Volume 24, Issue\n  3, March 2006 Page(s):481 - 490", "doi:10.1109/JSAC.2005.862399", "oai:arXiv.org:cs/0509097"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we present an iterative soft-decision decoding algorithm for\nReed-Solomon codes offering both complexity and performance advantages over\npreviously known decoding algorithms. Our algorithm is a list decoding\nalgorithm which combines two powerful soft decision decoding techniques which\nwere previously regarded in the literature as competitive, namely, the\nKoetter-Vardy algebraic soft-decision decoding algorithm and belief-propagation\nbased on adaptive parity check matrices, recently proposed by Jiang and\nNarayanan. Building on the Jiang-Narayanan algorithm, we present a\nbelief-propagation based algorithm with a significant reduction in\ncomputational complexity. We introduce the concept of using a\nbelief-propagation based decoder to enhance the soft-input information prior to\ndecoding with an algebraic soft-decision decoder. Our algorithm can also be\nviewed as an interpolation multiplicity assignment scheme for algebraic\nsoft-decision decoding of Reed-Solomon codes.\n", "Comment: Submitted to IEEE for publication in Jan 2005"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/cs/0509097"}}, {"publisher": {"name": ""}, "description": "  A spectrum-sharing communication system where the secondary user is aware of\nthe instantaneous channel state information (CSI) of the secondary link, but\nknows only the statistics and an estimated version of the secondary\ntransmitter-primary receiver (ST-PR) link, is investigated. The optimum power\nprofile and the ergodic capacity of the secondary link are derived for general\nfading channels (with continuous probability density function) under average\nand peak transmit-power constraints and with respect to two different\ninterference constraints: an interference outage constraint and a\nsignal-to-interference outage constraint. When applied to Rayleigh fading\nchannels, our results show, for instance, that the interference constraint is\nharmful at high-power regime in the sense that the capacity does not increase\nwith the power, whereas at low-power regime, it has a marginal impact and\nno-interference performance corresponding to the ergodic capacity under average\nor peak transmit power constraint in absence of the primary user, may be\nachieved.\n", "contributors": [{"name": "Rezk, Zouheir", "sameAs": [], "familyName": "Rezk", "additionalName": "", "givenName": "Zouheir", "email": ""}, {"name": "Alouini, Mohamed-Slim", "sameAs": [], "familyName": "Alouini", "additionalName": "", "givenName": "Mohamed-Slim", "email": ""}], "title": "Ergodic Capacity of Cognitive Radio under Imperfect Channel State\n  Information", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-04-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1204.2080", "IEEE Transactions on Vehicular Technology, 2012", "oai:arXiv.org:1204.2080"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A spectrum-sharing communication system where the secondary user is aware of\nthe instantaneous channel state information (CSI) of the secondary link, but\nknows only the statistics and an estimated version of the secondary\ntransmitter-primary receiver (ST-PR) link, is investigated. The optimum power\nprofile and the ergodic capacity of the secondary link are derived for general\nfading channels (with continuous probability density function) under average\nand peak transmit-power constraints and with respect to two different\ninterference constraints: an interference outage constraint and a\nsignal-to-interference outage constraint. When applied to Rayleigh fading\nchannels, our results show, for instance, that the interference constraint is\nharmful at high-power regime in the sense that the capacity does not increase\nwith the power, whereas at low-power regime, it has a marginal impact and\nno-interference performance corresponding to the ergodic capacity under average\nor peak transmit power constraint in absence of the primary user, may be\nachieved.\n", "Comment: To appear in IEEE TVT. 12 pages, 8 figures, 1 table. Matlab codes to\n  reproduce results are available upon request. Please contact one of the\n  authors for this purpose"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1204.2080"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose adding enzymes to the propagation environment of a\ndiffusive molecular communication system as a strategy for mitigating\nintersymbol interference. The enzymes form reaction intermediates with\ninformation molecules and then degrade them so that they have a smaller chance\nof interfering with future transmissions. We present the reaction-diffusion\ndynamics of this proposed system and derive a lower bound expression for the\nexpected number of molecules observed at the receiver. We justify a\nparticle-based simulation framework, and present simulation results that show\nboth the accuracy of our expression and the potential for enzymes to improve\ncommunication performance.\n", "contributors": [{"name": "Noel, Adam", "sameAs": [], "familyName": "Noel", "additionalName": "", "givenName": "Adam", "email": ""}, {"name": "Cheung, Karen C.", "sameAs": [], "familyName": "Cheung", "additionalName": "C.", "givenName": "Karen", "email": ""}, {"name": "Schober, Robert", "sameAs": [], "familyName": "Schober", "additionalName": "", "givenName": "Robert", "email": ""}], "title": "Improving Diffusion-Based Molecular Communication with Unanchored\n  Enzymes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-05-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1305.1783", "doi:10.1007/978-3-319-06944-9_13", "oai:arXiv.org:1305.1783"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "q-bio"]}}, {"name": "description", "properties": {"description": ["  In this paper, we propose adding enzymes to the propagation environment of a\ndiffusive molecular communication system as a strategy for mitigating\nintersymbol interference. The enzymes form reaction intermediates with\ninformation molecules and then degrade them so that they have a smaller chance\nof interfering with future transmissions. We present the reaction-diffusion\ndynamics of this proposed system and derive a lower bound expression for the\nexpected number of molecules observed at the receiver. We justify a\nparticle-based simulation framework, and present simulation results that show\nboth the accuracy of our expression and the potential for enzymes to improve\ncommunication performance.\n", "Comment: 15 pages, 4 figures, presented at the 7th International Conference on\n  Bio-Inspired Models of Network, Information, and Computing Systems (BIONETICS\n  2012) in Lugano, Switzerland"]}}], "languages": [null], "subjects": ["computer science - information theory", "quantitative biology - quantitative methods"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1305.1783"}}, {"publisher": {"name": ""}, "description": "  In this report, we describe three encodings of the multiple constant\nmultiplication (MCM) problem to pseudo-boolean satisfiability (PBS), and\nintroduce an algorithm to solve the MCM problem optimally. To the best of our\nknowledge, the proposed encodings and the optimization algorithm are the first\nformalization of the MCM problem in a PBS manner. This report evaluates the\ncomplexity of the problem size and the performance of several PBS solvers over\nthree encodings.\n", "contributors": [{"name": "Lopes, Nuno P.", "sameAs": [], "familyName": "Lopes", "additionalName": "P.", "givenName": "Nuno", "email": ""}, {"name": "Aksoy, Levent", "sameAs": [], "familyName": "Aksoy", "additionalName": "", "givenName": "Levent", "email": ""}, {"name": "Manquinho, Vasco", "sameAs": [], "familyName": "Manquinho", "additionalName": "", "givenName": "Vasco", "email": ""}, {"name": "Monteiro, Jos\u00e9", "sameAs": [], "familyName": "Monteiro", "additionalName": "", "givenName": "Jos\u00e9", "email": ""}], "title": "Optimally Solving the MCM Problem Using Pseudo-Boolean Satisfiability", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-11-11", "2011-05-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1011.2685", "oai:arXiv.org:1011.2685"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this report, we describe three encodings of the multiple constant\nmultiplication (MCM) problem to pseudo-boolean satisfiability (PBS), and\nintroduce an algorithm to solve the MCM problem optimally. To the best of our\nknowledge, the proposed encodings and the optimization algorithm are the first\nformalization of the MCM problem in a PBS manner. This report evaluates the\ncomplexity of the problem size and the performance of several PBS solvers over\nthree encodings.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "mathematics - logic", "computer science - logic in computer science"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1011.2685"}}, {"publisher": {"name": ""}, "description": "abstract: Typically, the complete loss or severe impairment of a sense such as vision and/or hearing is compensated through sensory substitution, i.e., the use of an alternative sense for receiving the same information. For individuals who are blind or visually impaired, the alternative senses have predominantly been hearing and touch. For movies, visual content has been made accessible to visually impaired viewers through audio descriptions -- an additional narration that describes scenes, the characters involved and other pertinent details. However, as audio descriptions should not overlap with dialogue, sound effects and musical scores, there is limited time to convey information, often resulting in stunted and abridged descriptions that leave out many important visual cues and concepts. This work proposes a promising multimodal approach to sensory substitution for movies by providing complementary information through haptics, pertaining to the positions and movements of actors, in addition to a film's audio description and audio content. In a ten-minute presentation of five movie clips to ten individuals who were visually impaired or blind, the novel methodology was found to provide an almost two time increase in the perception of actors' movements in scenes. Moreover, participants appreciated and found useful the overall concept of providing a visual perspective to film through haptics.", "contributors": [{"name": "Viswanathan, Lakshmie Narayan  (Author)", "sameAs": [], "familyName": "Viswanathan", "additionalName": "Narayan", "givenName": "Lakshmie", "email": ""}, {"name": "Panchanathan, Sethuraman  (Advisor)", "sameAs": [], "familyName": "Panchanathan", "additionalName": "", "givenName": "Sethuraman", "email": ""}, {"name": "Hedgpeth, Terri  (Committee member)", "sameAs": [], "familyName": "Hedgpeth", "additionalName": "", "givenName": "Terri", "email": ""}, {"name": "Li, Baoxin  (Committee member)", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Baoxin", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Enhancing Movie Comprehension  For Individuals Who Are Visually Impaired Or Blind", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Masters Thesis"}}, {"name": "format", "properties": {"format": "138 pages"}}, {"name": "date", "properties": {"date": "2011"}}, {"name": "description", "properties": {"description": ["abstract: Typically, the complete loss or severe impairment of a sense such as vision and/or hearing is compensated through sensory substitution, i.e., the use of an alternative sense for receiving the same information. For individuals who are blind or visually impaired, the alternative senses have predominantly been hearing and touch. For movies, visual content has been made accessible to visually impaired viewers through audio descriptions -- an additional narration that describes scenes, the characters involved and other pertinent details. However, as audio descriptions should not overlap with dialogue, sound effects and musical scores, there is limited time to convey information, often resulting in stunted and abridged descriptions that leave out many important visual cues and concepts. This work proposes a promising multimodal approach to sensory substitution for movies by providing complementary information through haptics, pertaining to the positions and movements of actors, in addition to a film's audio description and audio content. In a ten-minute presentation of five movie clips to ten individuals who were visually impaired or blind, the novel methodology was found to provide an almost two time increase in the perception of actors' movements in scenes. Moreover, participants appreciated and found useful the overall concept of providing a visual perspective to film through haptics.", "Dissertation/Thesis", "M.S. Computer Science 2011"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.9408", "item:9408"]}}], "languages": [null], "subjects": ["audio description", "haptics", "human factors", "assistive technology", "computer science", "vibrotactile communication", "tactile icon"], "providerUpdatedDateTime": "2015-02-12T01:08:57", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.9408"}}, {"publisher": {"name": ""}, "description": "  This article provides a completion to theories of information based on\nentropy, resolving a longstanding question in its axiomatization as proposed by\nShannon and pursued by Jaynes. We show that Shannon's entropy function has a\ncomplementary dual function which we call \"extropy.\" The entropy and the\nextropy of a binary distribution are identical. However, the measure bifurcates\ninto a pair of distinct measures for any quantity that is not merely an event\nindicator. As with entropy, the maximum extropy distribution is also the\nuniform distribution, and both measures are invariant with respect to\npermutations of their mass functions. However, they behave quite differently in\ntheir assessments of the refinement of a distribution, the axiom which\nconcerned Shannon and Jaynes. Their duality is specified via the relationship\namong the entropies and extropies of course and fine partitions. We also\nanalyze the extropy function for densities, showing that relative extropy\nconstitutes a dual to the Kullback-Leibler divergence, widely recognized as the\ncontinuous entropy measure. These results are unified within the general\nstructure of Bregman divergences. In this context they identify half the $L_2$\nmetric as the extropic dual to the entropic directed distance. We describe a\nstatistical application to the scoring of sequential forecast distributions\nwhich provoked the discovery.\n", "contributors": [{"name": "Lad, Frank", "sameAs": [], "familyName": "Lad", "additionalName": "", "givenName": "Frank", "email": ""}, {"name": "Sanfilippo, Giuseppe", "sameAs": [], "familyName": "Sanfilippo", "additionalName": "", "givenName": "Giuseppe", "email": ""}, {"name": "Agr\u00f2, Gianna", "sameAs": [], "familyName": "Agr\u00f2", "additionalName": "", "givenName": "Gianna", "email": ""}], "title": "Extropy: Complementary Dual of Entropy", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-09-29", "2015-04-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.6440", "Statistical Science 2015, Vol. 30, No. 1, 40-58", "doi:10.1214/14-STS430", "oai:arXiv.org:1109.6440"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:physics", "stat"]}}, {"name": "description", "properties": {"description": ["  This article provides a completion to theories of information based on\nentropy, resolving a longstanding question in its axiomatization as proposed by\nShannon and pursued by Jaynes. We show that Shannon's entropy function has a\ncomplementary dual function which we call \"extropy.\" The entropy and the\nextropy of a binary distribution are identical. However, the measure bifurcates\ninto a pair of distinct measures for any quantity that is not merely an event\nindicator. As with entropy, the maximum extropy distribution is also the\nuniform distribution, and both measures are invariant with respect to\npermutations of their mass functions. However, they behave quite differently in\ntheir assessments of the refinement of a distribution, the axiom which\nconcerned Shannon and Jaynes. Their duality is specified via the relationship\namong the entropies and extropies of course and fine partitions. We also\nanalyze the extropy function for densities, showing that relative extropy\nconstitutes a dual to the Kullback-Leibler divergence, widely recognized as the\ncontinuous entropy measure. These results are unified within the general\nstructure of Bregman divergences. In this context they identify half the $L_2$\nmetric as the extropic dual to the entropic directed distance. We describe a\nstatistical application to the scoring of sequential forecast distributions\nwhich provoked the discovery.\n", "Comment: Published at http://dx.doi.org/10.1214/14-STS430 in the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "statistics and probability", "physics - data analysis", "computer science - information theory", "mathematics - probability"], "providerUpdatedDateTime": "2015-04-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.6440"}}, {"publisher": {"name": ""}, "description": "  In various situations one is given only the predictions of multiple\nclassifiers over a large unlabeled test data. This scenario raises the\nfollowing questions: Without any labeled data and without any a-priori\nknowledge about the reliability of these different classifiers, is it possible\nto consistently and computationally efficiently estimate their accuracies?\nFurthermore, also in a completely unsupervised manner, can one construct a more\naccurate unsupervised ensemble classifier? In this paper, focusing on the\nbinary case, we present simple, computationally efficient algorithms to solve\nthese questions. Furthermore, under standard classifier independence\nassumptions, we prove our methods are consistent and study their asymptotic\nerror. Our approach is spectral, based on the fact that the off-diagonal\nentries of the classifiers' covariance matrix and 3-d tensor are rank-one. We\nillustrate the competitive performance of our algorithms via extensive\nexperiments on both artificial and real datasets.\n", "contributors": [{"name": "Jaffe, Ariel", "sameAs": [], "familyName": "Jaffe", "additionalName": "", "givenName": "Ariel", "email": ""}, {"name": "Nadler, Boaz", "sameAs": [], "familyName": "Nadler", "additionalName": "", "givenName": "Boaz", "email": ""}, {"name": "Kluger, Yuval", "sameAs": [], "familyName": "Kluger", "additionalName": "", "givenName": "Yuval", "email": ""}], "title": "Estimating the Accuracies of Multiple Classifiers Without Labeled Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-29", "2014-10-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.7644", "oai:arXiv.org:1407.7644"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  In various situations one is given only the predictions of multiple\nclassifiers over a large unlabeled test data. This scenario raises the\nfollowing questions: Without any labeled data and without any a-priori\nknowledge about the reliability of these different classifiers, is it possible\nto consistently and computationally efficiently estimate their accuracies?\nFurthermore, also in a completely unsupervised manner, can one construct a more\naccurate unsupervised ensemble classifier? In this paper, focusing on the\nbinary case, we present simple, computationally efficient algorithms to solve\nthese questions. Furthermore, under standard classifier independence\nassumptions, we prove our methods are consistent and study their asymptotic\nerror. Our approach is spectral, based on the fact that the off-diagonal\nentries of the classifiers' covariance matrix and 3-d tensor are rank-one. We\nillustrate the competitive performance of our algorithms via extensive\nexperiments on both artificial and real datasets.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-10-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.7644"}}, {"publisher": {"name": ""}, "description": "  Continued demand for accurate and computationally efficient transport methods\nto solve optically thick, fixed-source transport problems has inspired research\non variance-reduction (VR) techniques for Monte Carlo (MC). Methods that use\ndeterministic results to create VR maps for MC constitute a dominant branch of\nthis research, with Forward Weighted-Consistent Adjoint Driven Importance\nSampling (FW-CADIS) being a particularly successful example. However, locations\nin which energy and spatial self-shielding are combined, such as thin plates\nembedded in concrete, challenge FW-CADIS. In these cases the deterministic flux\ncannot appropriately capture transport behavior, and the associated VR\nparameters result in high variance in and following the plate.\n  This work presents a new method that improves performance in transport\ncalculations that contain regions of combined space and energy self-shielding\nwithout significant impact on the solution quality in other parts of the\nproblem. This method is based on FW-CADIS and applies a Resonance Factor\ncorrection to the adjoint source. The impact of the Resonance Factor method is\ninvestigated in this work through an example problem. It is clear that this new\nmethod dramatically improves performance in terms of lowering the maximum 95%\nconfidence interval relative error and reducing the compute time. Based on this\nwork, we recommend that the Resonance Factor method be used when the accuracy\nof the solution in the presence of combined space and energy self-shielding is\nimportant.\n", "contributors": [{"name": "Wilson, S. C.", "sameAs": [], "familyName": "Wilson", "additionalName": "C.", "givenName": "S.", "email": ""}, {"name": "Slaybaugh, R. N.", "sameAs": [], "familyName": "Slaybaugh", "additionalName": "N.", "givenName": "R.", "email": ""}], "title": "Improved Monte Carlo Variance Reduction for Space and Energy\n  Self-Shielding", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04749", "Nuclear Science and Engineering, 179, 22--41 (2015)", "oai:arXiv.org:1502.04749"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Continued demand for accurate and computationally efficient transport methods\nto solve optically thick, fixed-source transport problems has inspired research\non variance-reduction (VR) techniques for Monte Carlo (MC). Methods that use\ndeterministic results to create VR maps for MC constitute a dominant branch of\nthis research, with Forward Weighted-Consistent Adjoint Driven Importance\nSampling (FW-CADIS) being a particularly successful example. However, locations\nin which energy and spatial self-shielding are combined, such as thin plates\nembedded in concrete, challenge FW-CADIS. In these cases the deterministic flux\ncannot appropriately capture transport behavior, and the associated VR\nparameters result in high variance in and following the plate.\n  This work presents a new method that improves performance in transport\ncalculations that contain regions of combined space and energy self-shielding\nwithout significant impact on the solution quality in other parts of the\nproblem. This method is based on FW-CADIS and applies a Resonance Factor\ncorrection to the adjoint source. The impact of the Resonance Factor method is\ninvestigated in this work through an example problem. It is clear that this new\nmethod dramatically improves performance in terms of lowering the maximum 95%\nconfidence interval relative error and reducing the compute time. Based on this\nwork, we recommend that the Resonance Factor method be used when the accuracy\nof the solution in the presence of combined space and energy self-shielding is\nimportant.\n", "Comment: 20 pages, 22 figures, 7 tables"]}}], "languages": [null], "subjects": ["computer science - numerical analysis"], "providerUpdatedDateTime": "2015-02-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04749"}}, {"publisher": {"name": ""}, "description": "  The windows can be responsible for unnecessary energy consumption in a\nbuilding, if incorrectly designed, shadowed or oriented. Considering an annual\nthermal comfort assessment of a space, if windows are over-dimensioned, they\ncan contribute to the increase of the heating needs due to heat losses, and\nalso to the increase of cooling needs due to over-exposure to solar radiation.\nWhen under-dimensioned, the same space may benefit from reduced heat losses\nthrough the glazing surface but does not benefit from solar radiation gains.\nTherefore, it is important to find the optimum design that minimizes both the\nheating and cooling needs. This paper presents a parametric study of window\ntype (single, double and triple glazing), orientation and opening size, located\nin the city of Coimbra, Portugal. An annual and a seasonal assessment were\ndone, in order to obtain the set of optimum values around 360 degree\norientation.\n", "contributors": [{"name": "Amaral, Ana Rita", "sameAs": [], "familyName": "Amaral", "additionalName": "Rita", "givenName": "Ana", "email": ""}, {"name": "Rodrigues, Eug\u00e9nio", "sameAs": [], "familyName": "Rodrigues", "additionalName": "", "givenName": "Eug\u00e9nio", "email": ""}, {"name": "Gaspar, Ad\u00e9lio Rodrigues", "sameAs": [], "familyName": "Gaspar", "additionalName": "Rodrigues", "givenName": "Ad\u00e9lio", "email": ""}, {"name": "Gomes, \u00c1lvaro", "sameAs": [], "familyName": "Gomes", "additionalName": "", "givenName": "\u00c1lvaro", "email": ""}], "title": "A parametric study of window-to-floor ratio of three window types using\n  dynamic simulation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07016", "oai:arXiv.org:1503.07016"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The windows can be responsible for unnecessary energy consumption in a\nbuilding, if incorrectly designed, shadowed or oriented. Considering an annual\nthermal comfort assessment of a space, if windows are over-dimensioned, they\ncan contribute to the increase of the heating needs due to heat losses, and\nalso to the increase of cooling needs due to over-exposure to solar radiation.\nWhen under-dimensioned, the same space may benefit from reduced heat losses\nthrough the glazing surface but does not benefit from solar radiation gains.\nTherefore, it is important to find the optimum design that minimizes both the\nheating and cooling needs. This paper presents a parametric study of window\ntype (single, double and triple glazing), orientation and opening size, located\nin the city of Coimbra, Portugal. An annual and a seasonal assessment were\ndone, in order to obtain the set of optimum values around 360 degree\norientation.\n", "Comment: 7 pages, 2 figures, Proceedings of Energy for Sustainability 2015\n  Conference: Sustainable Cities: Designing for People and the Planet, Coimbra,\n  14-15 May, 2015"]}}], "languages": [null], "subjects": ["computer science - other computer science", "68u20"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07016"}}, {"publisher": {"name": ""}, "description": "  We uncover the global organization of clustering in real complex networks. As\nit happens with other fundamental properties of networks such as the degree\ndistribution, we find that real networks are neither completely random nor\nordered with respect to clustering, although they tend to be closer to\nmaximally random architectures. We reach this conclusion by comparing the\nglobal structure of clustering in real networks with that in maximally random\nand in maximally ordered clustered graphs. The former are produced with an\nexponential random graph model that maintains correlations among adjacent edges\nat the minimum needed to conform with the expected clustering spectrum; the\nlater with a random model that arranges triangles in cliques inducing highly\nordered structures. To compare the global organization of clustering in real\nand model networks, we compute $m$-core landscapes, where the $m$-core is\ndefined, akin to the $k$-core, as the maximal subgraph with edges participating\nat least in $m$ triangles. This property defines a set of nested subgraphs\nthat, contrarily to $k$-cores, is able to distinguish between hierarchical and\nmodular architectures. To visualize the $m$-core decomposition we developed the\nLaNet-vi 3.0 tool.\n", "contributors": [{"name": "Colomer-de-Simon, Pol", "sameAs": [], "familyName": "Colomer-de-Simon", "additionalName": "", "givenName": "Pol", "email": ""}, {"name": "Serrano, M. Angeles", "sameAs": [], "familyName": "Serrano", "additionalName": "Angeles", "givenName": "M.", "email": ""}, {"name": "Beiro, Mariano G.", "sameAs": [], "familyName": "Beiro", "additionalName": "G.", "givenName": "Mariano", "email": ""}, {"name": "Alvarez-Hamelin, J. Ignacio", "sameAs": [], "familyName": "Alvarez-Hamelin", "additionalName": "Ignacio", "givenName": "J.", "email": ""}, {"name": "Boguna, Marian", "sameAs": [], "familyName": "Boguna", "additionalName": "", "givenName": "Marian", "email": ""}], "title": "Deciphering the global organization of clustering in real complex\n  networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-06-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.0112", "Sci. Rep. 3, 2517 (2013)", "doi:10.1038/srep02517", "oai:arXiv.org:1306.0112"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": "  We uncover the global organization of clustering in real complex networks. As\nit happens with other fundamental properties of networks such as the degree\ndistribution, we find that real networks are neither completely random nor\nordered with respect to clustering, although they tend to be closer to\nmaximally random architectures. We reach this conclusion by comparing the\nglobal structure of clustering in real networks with that in maximally random\nand in maximally ordered clustered graphs. The former are produced with an\nexponential random graph model that maintains correlations among adjacent edges\nat the minimum needed to conform with the expected clustering spectrum; the\nlater with a random model that arranges triangles in cliques inducing highly\nordered structures. To compare the global organization of clustering in real\nand model networks, we compute $m$-core landscapes, where the $m$-core is\ndefined, akin to the $k$-core, as the maximal subgraph with edges participating\nat least in $m$ triangles. This property defines a set of nested subgraphs\nthat, contrarily to $k$-cores, is able to distinguish between hierarchical and\nmodular architectures. To visualize the $m$-core decomposition we developed the\nLaNet-vi 3.0 tool.\n"}}], "languages": [null], "subjects": ["condensed matter - disordered systems and neural networks", "physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-10-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.0112"}}, {"publisher": {"name": ""}, "description": "  In this paper, we present an analytical approach in obtaining the probability\ndensity function (pdf) of the random decision variable Y, formed at the output\nof power-cubic all-optical nonlinear preprocessor followed by the\nphotodetector. Our approach can be used to accurately evaluate the performance\nof ultrafast pulse detection in the presence of Gaussian noise. Through\nrigorous Monte-Carlo simulation, the accuracy of widely used Gaussian\napproximation of decision variable Y is refuted. However, in this paper we show\nthat the so called Log-Pearson type-3 probability density function (LP3 pdf) is\nan excellent representation for the decision variable Y . Three distinguishable\nparameters of the LP3 pdf are obtained through analytical derivation of three\nmoments of the decision variable Y . Furthermore, toward a more realistic\nmodel, in addition to ASE Gaussian noise, the effects of shot and thermal\nnoises are also included. Finally, using the presented analytical approach, it\nis shown that power-cubic preprocessor outperforms its quadratic counterparts,\ni.e., Second Harmonic Generation (SHG) and Two Photon Absorption (TPA) devices,\nin high power regime where shot and thermal noises can be neglected.\n", "contributors": [{"name": "Zefreh, Mahdi Ranjbar", "sameAs": [], "familyName": "Zefreh", "additionalName": "", "givenName": "Ranjbar", "email": ""}, {"name": "Salehi, Jawad A.", "sameAs": [], "familyName": "Salehi", "additionalName": "A.", "givenName": "Jawad", "email": ""}], "title": "Statistical Modeling and Performance Characterization of an Ultrafast\n  Digital Lightwave Communication System Using a Power-Cubic Optical Nonlinear\n  Preprocessor (Extended Version)", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5551", "oai:arXiv.org:1412.5551"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this paper, we present an analytical approach in obtaining the probability\ndensity function (pdf) of the random decision variable Y, formed at the output\nof power-cubic all-optical nonlinear preprocessor followed by the\nphotodetector. Our approach can be used to accurately evaluate the performance\nof ultrafast pulse detection in the presence of Gaussian noise. Through\nrigorous Monte-Carlo simulation, the accuracy of widely used Gaussian\napproximation of decision variable Y is refuted. However, in this paper we show\nthat the so called Log-Pearson type-3 probability density function (LP3 pdf) is\nan excellent representation for the decision variable Y . Three distinguishable\nparameters of the LP3 pdf are obtained through analytical derivation of three\nmoments of the decision variable Y . Furthermore, toward a more realistic\nmodel, in addition to ASE Gaussian noise, the effects of shot and thermal\nnoises are also included. Finally, using the presented analytical approach, it\nis shown that power-cubic preprocessor outperforms its quadratic counterparts,\ni.e., Second Harmonic Generation (SHG) and Two Photon Absorption (TPA) devices,\nin high power regime where shot and thermal noises can be neglected.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5551"}}, {"publisher": {"name": ""}, "description": "  Facebook pages offer an easy way to reach out to a very large audience as\nthey can easily be promoted using Facebook's advertising platform. Recently,\nthe number of likes of a Facebook page has become a measure of its popularity\nand profitability, and an underground market of services boosting page likes,\naka like farms, has emerged. Some reports have suggested that like farms use a\nnetwork of profiles that also like other pages to elude fraud protection\nalgorithms, however, to the best of our knowledge, there has been no systematic\nanalysis of Facebook pages' promotion methods.\n  This paper presents a comparative measurement study of page likes garnered\nvia Facebook ads and by a few like farms. We deploy a set of honeypot pages,\npromote them using both methods, and analyze garnered likes based on likers'\ndemographic, temporal, and social characteristics. We highlight a few\ninteresting findings, including that some farms seem to be operated by bots and\ndo not really try to hide the nature of their operations, while others follow a\nstealthier approach, mimicking regular users' behavior.\n", "contributors": [{"name": "De Cristofaro, Emiliano", "sameAs": [], "familyName": "De Cristofaro", "additionalName": "", "givenName": "Emiliano", "email": ""}, {"name": "Friedman, Arik", "sameAs": [], "familyName": "Friedman", "additionalName": "", "givenName": "Arik", "email": ""}, {"name": "Jourjon, Guillaume", "sameAs": [], "familyName": "Jourjon", "additionalName": "", "givenName": "Guillaume", "email": ""}, {"name": "Kaafar, Mohamed Ali", "sameAs": [], "familyName": "Kaafar", "additionalName": "Ali", "givenName": "Mohamed", "email": ""}, {"name": "Shafiq, M. Zubair", "sameAs": [], "familyName": "Shafiq", "additionalName": "Zubair", "givenName": "M.", "email": ""}], "title": "Paying for Likes? Understanding Facebook Like Fraud Using Honeypots", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-07", "2014-10-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.2097", "oai:arXiv.org:1409.2097"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Facebook pages offer an easy way to reach out to a very large audience as\nthey can easily be promoted using Facebook's advertising platform. Recently,\nthe number of likes of a Facebook page has become a measure of its popularity\nand profitability, and an underground market of services boosting page likes,\naka like farms, has emerged. Some reports have suggested that like farms use a\nnetwork of profiles that also like other pages to elude fraud protection\nalgorithms, however, to the best of our knowledge, there has been no systematic\nanalysis of Facebook pages' promotion methods.\n  This paper presents a comparative measurement study of page likes garnered\nvia Facebook ads and by a few like farms. We deploy a set of honeypot pages,\npromote them using both methods, and analyze garnered likes based on likers'\ndemographic, temporal, and social characteristics. We highlight a few\ninteresting findings, including that some farms seem to be operated by bots and\ndo not really try to hide the nature of their operations, while others follow a\nstealthier approach, mimicking regular users' behavior.\n", "Comment: To appear in IMC 2014"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.2097"}}, {"publisher": {"name": ""}, "description": "  For a positive integer $k$, a $k$-colouring of a graph $G=(V,E)$ is a mapping\n$c: V\\rightarrow\\{1,2,...,k\\}$ such that $c(u)\\neq c(v)$ whenever $uv\\in E$.\nThe Colouring problem is to decide, for a given $G$ and $k$, whether a\n$k$-colouring of $G$ exists. If $k$ is fixed (that is, it is not part of the\ninput), we have the decision problem $k$-Colouring instead. We survey known\nresults on the computational complexity of Colouring and $k$-Colouring for\ngraph classes that are characterized by one or two forbidden induced subgraphs.\nWe also consider a number of variants: for example, where the problem is to\nextend a partial colouring, or where lists of permissible colours are given for\neach vertex.\n", "contributors": [{"name": "Golovach, Petr A.", "sameAs": [], "familyName": "Golovach", "additionalName": "A.", "givenName": "Petr", "email": ""}, {"name": "Johnson, Matthew", "sameAs": [], "familyName": "Johnson", "additionalName": "", "givenName": "Matthew", "email": ""}, {"name": "Paulusma, Dani\u00ebl", "sameAs": [], "familyName": "Paulusma", "additionalName": "", "givenName": "Dani\u00ebl", "email": ""}, {"name": "Song, Jian", "sameAs": [], "familyName": "Song", "additionalName": "", "givenName": "Jian", "email": ""}], "title": "A Survey on the Computational Complexity of Colouring Graphs with\n  Forbidden Subgraphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-06", "2015-03-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.1482", "oai:arXiv.org:1407.1482"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  For a positive integer $k$, a $k$-colouring of a graph $G=(V,E)$ is a mapping\n$c: V\\rightarrow\\{1,2,...,k\\}$ such that $c(u)\\neq c(v)$ whenever $uv\\in E$.\nThe Colouring problem is to decide, for a given $G$ and $k$, whether a\n$k$-colouring of $G$ exists. If $k$ is fixed (that is, it is not part of the\ninput), we have the decision problem $k$-Colouring instead. We survey known\nresults on the computational complexity of Colouring and $k$-Colouring for\ngraph classes that are characterized by one or two forbidden induced subgraphs.\nWe also consider a number of variants: for example, where the problem is to\nextend a partial colouring, or where lists of permissible colours are given for\neach vertex.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.1482"}}, {"publisher": {"name": ""}, "description": "  In the recent years, many solutions for Vehicle to Vehicle (V2V)\ncommunication were proposed to overcome failure problems (also known as dead\nends). This paper proposes a novel framework for V2V failure recovery using\nDevice-to-Device (D2D) communications. Based on the unified Intelligent\nTransportation Systems (ITS) architecture, LTE-based D2D mechanisms can improve\nV2V dead ends failure recovery delays. This new paradigm of hybrid V2V-D2D\ncommunications overcomes the limitations of traditional V2V routing techniques.\nAccording to NS2 simulation results, the proposed hybrid model decreases the\nend to end delay (E2E) of messages delivery. A complete comparison of different\nD2D use cases (best & worst scenarios) is presented to show the enhancements\nbrought by our solution compared to traditional V2V techniques.\n", "contributors": [{"name": "Abd-Elrahman, Emad", "sameAs": [], "familyName": "Abd-Elrahman", "additionalName": "", "givenName": "Emad", "email": ""}, {"name": "Said, Adel Mounir", "sameAs": [], "familyName": "Said", "additionalName": "Mounir", "givenName": "Adel", "email": ""}, {"name": "Toukabri, Thouraya", "sameAs": [], "familyName": "Toukabri", "additionalName": "", "givenName": "Thouraya", "email": ""}, {"name": "Afifi, Hossam", "sameAs": [], "familyName": "Afifi", "additionalName": "", "givenName": "Hossam", "email": ""}, {"name": "Marot, Michel", "sameAs": [], "familyName": "Marot", "additionalName": "", "givenName": "Michel", "email": ""}], "title": "A Hybrid Model to Extend Vehicular Intercommunication V2V through D2D\n  Architecture", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.05817", "oai:arXiv.org:1502.05817"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In the recent years, many solutions for Vehicle to Vehicle (V2V)\ncommunication were proposed to overcome failure problems (also known as dead\nends). This paper proposes a novel framework for V2V failure recovery using\nDevice-to-Device (D2D) communications. Based on the unified Intelligent\nTransportation Systems (ITS) architecture, LTE-based D2D mechanisms can improve\nV2V dead ends failure recovery delays. This new paradigm of hybrid V2V-D2D\ncommunications overcomes the limitations of traditional V2V routing techniques.\nAccording to NS2 simulation results, the proposed hybrid model decreases the\nend to end delay (E2E) of messages delivery. A complete comparison of different\nD2D use cases (best & worst scenarios) is presented to show the enhancements\nbrought by our solution compared to traditional V2V techniques.\n", "Comment: 6 pages"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-02-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.05817"}}, {"publisher": {"name": ""}, "description": "  In this paper, we show that all fat Hoffman graphs with smallest eigenvalue\nat least -1-\\tau, where \\tau is the golden ratio, can be described by a finite\nset of fat (-1-\\tau)-irreducible Hoffman graphs. In the terminology of Woo and\nNeumaier, we mean that every fat Hoffman graph with smallest eigenvalue at\nleast -1-\\tau is an H-line graph, where H is the set of isomorphism classes of\nmaximal fat (-1-\\tau)-irreducible Hoffman graphs. It turns out that there are\n37 fat (-1-\\tau)-irreducible Hoffman graphs, up to isomorphism.\n", "contributors": [{"name": "Munemasa, Akihiro", "sameAs": [], "familyName": "Munemasa", "additionalName": "", "givenName": "Akihiro", "email": ""}, {"name": "Sano, Yoshio", "sameAs": [], "familyName": "Sano", "additionalName": "", "givenName": "Yoshio", "email": ""}, {"name": "Taniguchi, Tetsuji", "sameAs": [], "familyName": "Taniguchi", "additionalName": "", "givenName": "Tetsuji", "email": ""}], "title": "Fat Hoffman graphs with smallest eigenvalue at least $-1-\\tau$", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-30", "2013-04-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.7284", "Ars Mathematica Contemporanea 7 (2014) 247-262", "oai:arXiv.org:1111.7284"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we show that all fat Hoffman graphs with smallest eigenvalue\nat least -1-\\tau, where \\tau is the golden ratio, can be described by a finite\nset of fat (-1-\\tau)-irreducible Hoffman graphs. In the terminology of Woo and\nNeumaier, we mean that every fat Hoffman graph with smallest eigenvalue at\nleast -1-\\tau is an H-line graph, where H is the set of isomorphism classes of\nmaximal fat (-1-\\tau)-irreducible Hoffman graphs. It turns out that there are\n37 fat (-1-\\tau)-irreducible Hoffman graphs, up to isomorphism.\n", "Comment: 19 pages, 10 figures"]}}], "languages": [null], "subjects": ["05c75", "computer science - discrete mathematics", "mathematics - combinatorics", "05c50"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.7284"}}, {"publisher": {"name": ""}, "description": "  We study the problem of predicting the future, though only in the\nprobabilistic sense of estimating a future state of a time-varying probability\ndistribution. This is not only an interesting academic problem, but solving\nthis extrapolation problem also has many practical application, e.g. for\ntraining classifiers that have to operate under time-varying conditions. Our\nmain contribution is a method for predicting the next step of the time-varying\ndistribution from a given sequence of sample sets from earlier time steps. For\nthis we rely on two recent machine learning techniques: embedding probability\ndistributions into a reproducing kernel Hilbert space, and learning operators\nby vector-valued regression. We illustrate the working principles and the\npractical usefulness of our method by experiments on synthetic and real data.\nWe also highlight an exemplary application: training a classifier in a domain\nadaptation setting without having access to examples from the test time\ndistribution at training time.\n", "contributors": [{"name": "Lampert, Christoph H.", "sameAs": [], "familyName": "Lampert", "additionalName": "H.", "givenName": "Christoph", "email": ""}], "title": "Predicting the Future Behavior of a Time-Varying Probability\n  Distribution", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-20", "2014-11-20"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.5362", "oai:arXiv.org:1406.5362"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  We study the problem of predicting the future, though only in the\nprobabilistic sense of estimating a future state of a time-varying probability\ndistribution. This is not only an interesting academic problem, but solving\nthis extrapolation problem also has many practical application, e.g. for\ntraining classifiers that have to operate under time-varying conditions. Our\nmain contribution is a method for predicting the next step of the time-varying\ndistribution from a given sequence of sample sets from earlier time steps. For\nthis we rely on two recent machine learning techniques: embedding probability\ndistributions into a reproducing kernel Hilbert space, and learning operators\nby vector-valued regression. We illustrate the working principles and the\npractical usefulness of our method by experiments on synthetic and real data.\nWe also highlight an exemplary application: training a classifier in a domain\nadaptation setting without having access to examples from the test time\ndistribution at training time.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-11-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.5362"}}, {"publisher": {"name": ""}, "description": "  We have performed fully atomistic classical molecular dynamics (MD)\nsimulations to calculate the effective interaction between two polyamidoamine\n(PAMAM) dendrimers. Using the umbrella sampling (US) technique, we have\nobtained the potential of mean force (PMF) between the dendrimers and\ninvestigated the effects of protonation level and dendrimer size on the PMF.\nOur results show that the interaction between the dendrimers can be tuned from\npurely repulsive to partly attractive by changing the protonation level. The\nPMF profiles are well-fitted by the sum of an exponential and a Gaussian\nfunction with the weight of the exponential function dominating over that of\nthe Gaussian function. This observation is in disagreement with the results\nobtained in previous analytic [Macromolecules 34, 2914 (2001)] and\ncoarse-grained simulation [J. Chem. Phys. 120, 7761 (2004)] studies which\npredicted the effective interaction to be Gaussian.\n", "contributors": [{"name": "Mandal, Taraknath", "sameAs": [], "familyName": "Mandal", "additionalName": "", "givenName": "Taraknath", "email": ""}, {"name": "Dasgupta, Chandan", "sameAs": [], "familyName": "Dasgupta", "additionalName": "", "givenName": "Chandan", "email": ""}, {"name": "Maiti, Prabal K", "sameAs": [], "familyName": "Maiti", "additionalName": "K", "givenName": "Prabal", "email": ""}], "title": "Nature of the Effective Interaction Between Dendrimers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4443", "J. Chem. Phys. 141, 144901 (2014);", "oai:arXiv.org:1411.4443"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": "  We have performed fully atomistic classical molecular dynamics (MD)\nsimulations to calculate the effective interaction between two polyamidoamine\n(PAMAM) dendrimers. Using the umbrella sampling (US) technique, we have\nobtained the potential of mean force (PMF) between the dendrimers and\ninvestigated the effects of protonation level and dendrimer size on the PMF.\nOur results show that the interaction between the dendrimers can be tuned from\npurely repulsive to partly attractive by changing the protonation level. The\nPMF profiles are well-fitted by the sum of an exponential and a Gaussian\nfunction with the weight of the exponential function dominating over that of\nthe Gaussian function. This observation is in disagreement with the results\nobtained in previous analytic [Macromolecules 34, 2914 (2001)] and\ncoarse-grained simulation [J. Chem. Phys. 120, 7761 (2004)] studies which\npredicted the effective interaction to be Gaussian.\n"}}], "languages": [null], "subjects": ["physics - computational physics", "physics - chemical physics", "condensed matter - soft condensed matter"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4443"}}, {"publisher": {"name": ""}, "description": "  In this paper, we consider a homogenous multi-antenna downlink network where\na passive eavesdropper intends to intercept the communication between a base\nstation (BS) and multiple secure users (SU) over Rayleigh fading channels. In\norder to guarantee the security of information transfer, physical layer\nsecurity is employed accordingly. For such a multiple user (MU) secure network,\nthe number of accessing SUs, namely transmission mode, has a great impact on\nthe secrecy performance. Specifically, on the one hand, a large number of\naccessing SUs will arise high inter-user interference at SUs, resulting in a\nreduction of the capacity of the legitimate channel. On the other hand, high\ninter-user interference will interfere with the eavesdropper and thus degrades\nthe performance of the eavesdropper channel. Generally speaking, the harmful\ninter-user interference may be transformed as a useful tool of\nanti-eavesdropping. The focus of this paper is on selecting the optimal\ntransmission mode according to channel conditions and system parameters, so as\nto maximize the sum secrecy outage capacity. Moreover, through asymptotic\nanalysis, we present several simple mode selection schemes in some extreme\ncases. Finally, simulation results validate the effectiveness of the proposed\nmode selection schemes in MU secure communications.\n", "contributors": [{"name": "Chen, Xiaoming", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Xiaoming", "email": ""}, {"name": "Zhang, Yu", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Yu", "email": ""}], "title": "Mode Selection in MU-MIMO Downlink Networks: A Physical Layer Security\n  Perspective", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04668", "oai:arXiv.org:1503.04668"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we consider a homogenous multi-antenna downlink network where\na passive eavesdropper intends to intercept the communication between a base\nstation (BS) and multiple secure users (SU) over Rayleigh fading channels. In\norder to guarantee the security of information transfer, physical layer\nsecurity is employed accordingly. For such a multiple user (MU) secure network,\nthe number of accessing SUs, namely transmission mode, has a great impact on\nthe secrecy performance. Specifically, on the one hand, a large number of\naccessing SUs will arise high inter-user interference at SUs, resulting in a\nreduction of the capacity of the legitimate channel. On the other hand, high\ninter-user interference will interfere with the eavesdropper and thus degrades\nthe performance of the eavesdropper channel. Generally speaking, the harmful\ninter-user interference may be transformed as a useful tool of\nanti-eavesdropping. The focus of this paper is on selecting the optimal\ntransmission mode according to channel conditions and system parameters, so as\nto maximize the sum secrecy outage capacity. Moreover, through asymptotic\nanalysis, we present several simple mode selection schemes in some extreme\ncases. Finally, simulation results validate the effectiveness of the proposed\nmode selection schemes in MU secure communications.\n", "Comment: 9 pages, 5 figures and 3 tables"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04668"}}, {"publisher": {"name": ""}, "description": "  Lanford has shown that Feigenbaum's functional equation has an analytic\nsolution. We show that this solution is a polynomial time computable function.\nThis implies in particular that the so-called first Feigenbaum constant is a\npolynomial time computable real number.\n", "contributors": [{"name": "Hertling, Peter", "sameAs": [], "familyName": "Hertling", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Spandl, Christoph", "sameAs": [], "familyName": "Spandl", "additionalName": "", "givenName": "Christoph", "email": ""}], "title": "Computing a Solution of Feigenbaum's Functional Equation in Polynomial\n  Time", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.3277", "oai:arXiv.org:1410.3277"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Lanford has shown that Feigenbaum's functional equation has an analytic\nsolution. We show that this solution is a polynomial time computable function.\nThis implies in particular that the so-called first Feigenbaum constant is a\npolynomial time computable real number.\n", "Comment: CCA 2012, Cambridge, UK, 24-27 June 2012"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "computer science - numerical analysis", "mathematics - dynamical systems"], "providerUpdatedDateTime": "2014-10-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.3277"}}, {"publisher": {"name": ""}, "description": "  I show a simple expression of the Mill's ratio of the Student's\nt-Distribution. I use it to prove Conjecture 1 in P. Auer, N. Cesa-Bianchi, and\nP. Fischer. Finite-time analysis of the multiarmed bandit problem. Mach.\nLearn., 47(2-3):235--256, May 2002.\n", "contributors": [{"name": "Orabona, Francesco", "sameAs": [], "familyName": "Orabona", "additionalName": "", "givenName": "Francesco", "email": ""}], "title": "A Simple Expression for Mill's Ratio of the Student's $t$-Distribution", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01632", "oai:arXiv.org:1502.01632"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  I show a simple expression of the Mill's ratio of the Student's\nt-Distribution. I use it to prove Conjecture 1 in P. Auer, N. Cesa-Bianchi, and\nP. Fischer. Finite-time analysis of the multiarmed bandit problem. Mach.\nLearn., 47(2-3):235--256, May 2002.\n"}}], "languages": [null], "subjects": ["computer science - learning", "mathematics - probability"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01632"}}, {"publisher": {"name": ""}, "description": "  Query workloads and database schemas in OLAP applications are becoming\nincreasingly complex. Moreover, the queries and the schemas have to continually\n\\textit{evolve} to address business requirements. During such repetitive\ntransitions, the \\textit{order} of index deployment has to be considered while\ndesigning the physical schemas such as indexes and MVs.\n  An effective index deployment ordering can produce (1) a prompt query runtime\nimprovement and (2) a reduced total deployment time. Both of these are\nessential qualities of design tools for quickly evolving databases, but\noptimizing the problem is challenging because of complex index interactions and\na factorial number of possible solutions.\n  We formulate the problem in a mathematical model and study several techniques\nfor solving the index ordering problem. We demonstrate that Constraint\nProgramming (CP) is a more flexible and efficient platform to solve the problem\nthan other methods such as mixed integer programming and A* search. In addition\nto exact search techniques, we also studied local search algorithms to find\nnear optimal solution very quickly.\n  Our empirical analysis on the TPC-H dataset shows that our pruning techniques\ncan reduce the size of the search space by tens of orders of magnitude. Using\nthe TPC-DS dataset, we verify that our local search algorithm is a highly\nscalable and stable method for quickly finding a near-optimal solution.\n", "contributors": [{"name": "Kimura, Hideaki", "sameAs": [], "familyName": "Kimura", "additionalName": "", "givenName": "Hideaki", "email": ""}, {"name": "Coffrin, Carleton", "sameAs": [], "familyName": "Coffrin", "additionalName": "", "givenName": "Carleton", "email": ""}, {"name": "Rasin, Alexander", "sameAs": [], "familyName": "Rasin", "additionalName": "", "givenName": "Alexander", "email": ""}, {"name": "Zdonik, Stanley B.", "sameAs": [], "familyName": "Zdonik", "additionalName": "B.", "givenName": "Stanley", "email": ""}], "title": "Optimizing Index Deployment Order for Evolving OLAP (Extended Version)", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-07-18", "2012-02-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1107.3606", "oai:arXiv.org:1107.3606"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Query workloads and database schemas in OLAP applications are becoming\nincreasingly complex. Moreover, the queries and the schemas have to continually\n\\textit{evolve} to address business requirements. During such repetitive\ntransitions, the \\textit{order} of index deployment has to be considered while\ndesigning the physical schemas such as indexes and MVs.\n  An effective index deployment ordering can produce (1) a prompt query runtime\nimprovement and (2) a reduced total deployment time. Both of these are\nessential qualities of design tools for quickly evolving databases, but\noptimizing the problem is challenging because of complex index interactions and\na factorial number of possible solutions.\n  We formulate the problem in a mathematical model and study several techniques\nfor solving the index ordering problem. We demonstrate that Constraint\nProgramming (CP) is a more flexible and efficient platform to solve the problem\nthan other methods such as mixed integer programming and A* search. In addition\nto exact search techniques, we also studied local search algorithms to find\nnear optimal solution very quickly.\n  Our empirical analysis on the TPC-H dataset shows that our pruning techniques\ncan reduce the size of the search space by tens of orders of magnitude. Using\nthe TPC-DS dataset, we verify that our local search algorithm is a highly\nscalable and stable method for quickly finding a near-optimal solution.\n"}}], "languages": [null], "subjects": ["computer science - databases"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1107.3606"}}, {"publisher": {"name": ""}, "description": "  The recently-discovered polar codes are widely seen as a major breakthrough\nin coding theory. These codes achieve the capacity of many important channels\nunder successive cancellation decoding. Motivated by the rapid progress in the\ntheory of polar codes, we propose a family of architectures for efficient\nhardware implementation of successive cancellation decoders. We show that such\ndecoders can be implemented with O(n) processing elements and O(n) memory\nelements, while providing constant throughput. We also propose a technique for\noverlapping the decoding of several consecutive codewords, thereby achieving a\nsignificant speed-up factor. We furthermore show that successive cancellation\ndecoding can be implemented in the logarithmic domain, thereby eliminating the\nmultiplication and division operations and greatly reducing the complexity of\neach processing element.\n", "contributors": [{"name": "Leroux, Camille", "sameAs": [], "familyName": "Leroux", "additionalName": "", "givenName": "Camille", "email": ""}, {"name": "Tal, Ido", "sameAs": [], "familyName": "Tal", "additionalName": "", "givenName": "Ido", "email": ""}, {"name": "Vardy, Alexander", "sameAs": [], "familyName": "Vardy", "additionalName": "", "givenName": "Alexander", "email": ""}, {"name": "Gross, Warren J.", "sameAs": [], "familyName": "Gross", "additionalName": "J.", "givenName": "Warren", "email": ""}], "title": "Hardware architectures for Successive Cancellation Decoding of Polar\n  Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-11-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1011.2919", "oai:arXiv.org:1011.2919"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The recently-discovered polar codes are widely seen as a major breakthrough\nin coding theory. These codes achieve the capacity of many important channels\nunder successive cancellation decoding. Motivated by the rapid progress in the\ntheory of polar codes, we propose a family of architectures for efficient\nhardware implementation of successive cancellation decoders. We show that such\ndecoders can be implemented with O(n) processing elements and O(n) memory\nelements, while providing constant throughput. We also propose a technique for\noverlapping the decoding of several consecutive codewords, thereby achieving a\nsignificant speed-up factor. We furthermore show that successive cancellation\ndecoding can be implemented in the logarithmic domain, thereby eliminating the\nmultiplication and division operations and greatly reducing the complexity of\neach processing element.\n", "Comment: Submitted to ICASSP 2011"]}}], "languages": [null], "subjects": ["computer science - hardware architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1011.2919"}}, {"publisher": {"name": ""}, "description": "  In the literature, J.-P. Cheng et al. have proposed the MIMO-OFDM PHY\nintegrated (MOPI) scheme for achieving physical-layer security in practice\nwithout using any cryptographic ciphers. The MOPI scheme uses channel sounding\nand physical-layer network coding (PNC) to prevent eavesdroppers from learning\nthe channel state information (CSI). Nevertheless, due to the use of multiple\nantennas for PNC at transmitter and beamforming at receiver, it is not possible\nto have spatial multiplexing nor use space-time codes in our previous MOPI\nscheme. In this paper, we propose a variant of the MOPI scheme, called P-MOPI,\nthat works with a cryptographic cipher and utilizes precoding matrix index\n(PMI) as an efficient key-exchange mechanism. With channel sounding, the PMI is\nonly known between the transmitter and the legal receiver. The shared key can\nthen be used, e.g., as the seed to generate pseudo random bit sequences for\nsecuring subsequent transmissions using a stream cipher. By applying the same\ntechniques at independent subcarriers of the OFDM system, the P-MOPI scheme\neasily allows two communicating parties to exchange over 100 secret bits. As a\nresult, not only secure communication but also the MIMO gain can be guaranteed\nby using the P-MOPI scheme.\n", "contributors": [{"name": "Lan, Pang-Chang", "sameAs": [], "familyName": "Lan", "additionalName": "", "givenName": "Pang-Chang", "email": ""}, {"name": "Wu, Chih-Yao", "sameAs": [], "familyName": "Wu", "additionalName": "", "givenName": "Chih-Yao", "email": ""}, {"name": "Lee, Chia-Han", "sameAs": [], "familyName": "Lee", "additionalName": "", "givenName": "Chia-Han", "email": ""}, {"name": "Yeh, Ping-Cheng", "sameAs": [], "familyName": "Yeh", "additionalName": "", "givenName": "Ping-Cheng", "email": ""}, {"name": "Cheng, Chen-Mou", "sameAs": [], "familyName": "Cheng", "additionalName": "", "givenName": "Chen-Mou", "email": ""}], "title": "PMI-based MIMO OFDM PHY Integrated Key Exchange (P-MOPI) Scheme", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-01-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.4075", "oai:arXiv.org:1101.4075"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In the literature, J.-P. Cheng et al. have proposed the MIMO-OFDM PHY\nintegrated (MOPI) scheme for achieving physical-layer security in practice\nwithout using any cryptographic ciphers. The MOPI scheme uses channel sounding\nand physical-layer network coding (PNC) to prevent eavesdroppers from learning\nthe channel state information (CSI). Nevertheless, due to the use of multiple\nantennas for PNC at transmitter and beamforming at receiver, it is not possible\nto have spatial multiplexing nor use space-time codes in our previous MOPI\nscheme. In this paper, we propose a variant of the MOPI scheme, called P-MOPI,\nthat works with a cryptographic cipher and utilizes precoding matrix index\n(PMI) as an efficient key-exchange mechanism. With channel sounding, the PMI is\nonly known between the transmitter and the legal receiver. The shared key can\nthen be used, e.g., as the seed to generate pseudo random bit sequences for\nsecuring subsequent transmissions using a stream cipher. By applying the same\ntechniques at independent subcarriers of the OFDM system, the P-MOPI scheme\neasily allows two communicating parties to exchange over 100 secret bits. As a\nresult, not only secure communication but also the MIMO gain can be guaranteed\nby using the P-MOPI scheme.\n", "Comment: 6 pages, 4 figures, topic on physical layer security in information\n  theory"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.4075"}}, {"publisher": {"name": ""}, "description": "  Different geometric patterns and shapes are generated using groups of agents,\nand this needs formation control. In this paper, Centroid Based Transformation\n(CBT), has been applied to decompose the combined dynamics of nonholonomic\nWheeled Mobile Robots (WMRs) into three subsystems: intra and inter group shape\ndynamics, and the dynamics of the centroid. The intra group shape dynamics can\nfurther be partitioned into the shape dynamics of each group, giving the notion\nof multiple group. Thus separate controllers have been designed for each\nsubsystem. The gains of the controllers are such chosen that the overall system\nbecomes singularly perturbed system, and different subsystems converge to their\ndesired values at different times. Then multi-time scale convergence analysis\nhas been carried out in this paper. Negative gradient of a potential based\nfunction has been added to the controller to ensure collision avoidance among\nthe robots. Simulation results have been provided to demonstrate the\neffectiveness of the proposed controller.\n", "contributors": [{"name": "Sarkar, Soumic", "sameAs": [], "familyName": "Sarkar", "additionalName": "", "givenName": "Soumic", "email": ""}, {"name": "Kar, Indra Narayan", "sameAs": [], "familyName": "Kar", "additionalName": "Narayan", "givenName": "Indra", "email": ""}], "title": "Multi Time Scale Behaviour of The Formation of Multiple Groups of\n  Nonholonomic Wheeled Mobile Robots", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7824", "oai:arXiv.org:1412.7824"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Different geometric patterns and shapes are generated using groups of agents,\nand this needs formation control. In this paper, Centroid Based Transformation\n(CBT), has been applied to decompose the combined dynamics of nonholonomic\nWheeled Mobile Robots (WMRs) into three subsystems: intra and inter group shape\ndynamics, and the dynamics of the centroid. The intra group shape dynamics can\nfurther be partitioned into the shape dynamics of each group, giving the notion\nof multiple group. Thus separate controllers have been designed for each\nsubsystem. The gains of the controllers are such chosen that the overall system\nbecomes singularly perturbed system, and different subsystems converge to their\ndesired values at different times. Then multi-time scale convergence analysis\nhas been carried out in this paper. Negative gradient of a potential based\nfunction has been added to the controller to ensure collision avoidance among\nthe robots. Simulation results have been provided to demonstrate the\neffectiveness of the proposed controller.\n", "Comment: arXiv admin note: text overlap with arXiv:1412.6164"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - robotics", "computer science - multiagent systems"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7824"}}, {"publisher": {"name": ""}, "description": "  Let $X$ be an algebraic subvariety of $\\mathbb C^n$ and $\\bar X$ be its\nclosure in $\\mathbb P^n.$ In their paper \\cite{CGZ} Coman-Guedj-Zeriahi proved\nthat any plurisubharmonic function with logarithmic growth on $X$ extends to a\nplurisubharmonic function with logarithmic growth on $\\mathbb C^n$ when the\ngerms $(\\bar X,a)$ in $\\mathbb P^n$ are irreducible for all $a\\in \\bar\nX\\setminus X.$ In this paper we consider $X$ for which the germ $(\\bar X,a)$ is\nreducible for some $a\\in \\bar X\\setminus X$ and we give a necessary and\nsufficient condition for $X$ so that any plurisubharmonic function with\nlogarithmic growth on $X$ extends to a plurisubharmonic function with\nlogarithmic growth on $\\mathbb C^n.$\n", "contributors": [{"name": "Yazici, Ozcan", "sameAs": [], "familyName": "Yazici", "additionalName": "", "givenName": "Ozcan", "email": ""}], "title": "Extension of Plurisubharmonic Functions in the Lelong Class", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-07", "2015-04-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.1812", "Illinois J. Math. Volume 58, Number 1 (2014), 219-231", "oai:arXiv.org:1402.1812"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Let $X$ be an algebraic subvariety of $\\mathbb C^n$ and $\\bar X$ be its\nclosure in $\\mathbb P^n.$ In their paper \\cite{CGZ} Coman-Guedj-Zeriahi proved\nthat any plurisubharmonic function with logarithmic growth on $X$ extends to a\nplurisubharmonic function with logarithmic growth on $\\mathbb C^n$ when the\ngerms $(\\bar X,a)$ in $\\mathbb P^n$ are irreducible for all $a\\in \\bar\nX\\setminus X.$ In this paper we consider $X$ for which the germ $(\\bar X,a)$ is\nreducible for some $a\\in \\bar X\\setminus X$ and we give a necessary and\nsufficient condition for $X$ so that any plurisubharmonic function with\nlogarithmic growth on $X$ extends to a plurisubharmonic function with\nlogarithmic growth on $\\mathbb C^n.$\n", "Comment: Revised version of the paper with the same title"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.1812"}}, {"publisher": {"name": ""}, "description": "  We consider the complexity of problems related to the combinatorial game\nFree-Flood-It, in which players aim to make a coloured graph monochromatic with\nthe minimum possible number of flooding operations. Although computing the\nminimum number of moves required to flood an arbitrary graph is known to be\nNP-hard, we demonstrate a polynomial time algorithm to compute the minimum\nnumber of moves required to link each pair of vertices. We apply this result to\ncompute in polynomial time the minimum number of moves required to flood a\npath, and an additive approximation to this quantity for an arbitrary k x n\nboard, coloured with a bounded number of colours, for any fixed k. On the other\nhand, we show that, for k>=3, determining the minimum number of moves required\nto flood a k x n board coloured with at least four colours remains NP-hard.\n", "contributors": [{"name": "Meeks, Kitty", "sameAs": [], "familyName": "Meeks", "additionalName": "", "givenName": "Kitty", "email": ""}, {"name": "Scott, Alexander", "sameAs": [], "familyName": "Scott", "additionalName": "", "givenName": "Alexander", "email": ""}], "title": "The complexity of flood-filling games on graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-31", "2011-10-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.5876", "doi:10.1016/j.dam.2011.09.001", "oai:arXiv.org:1101.5876"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We consider the complexity of problems related to the combinatorial game\nFree-Flood-It, in which players aim to make a coloured graph monochromatic with\nthe minimum possible number of flooding operations. Although computing the\nminimum number of moves required to flood an arbitrary graph is known to be\nNP-hard, we demonstrate a polynomial time algorithm to compute the minimum\nnumber of moves required to link each pair of vertices. We apply this result to\ncompute in polynomial time the minimum number of moves required to flood a\npath, and an additive approximation to this quantity for an arbitrary k x n\nboard, coloured with a bounded number of colours, for any fixed k. On the other\nhand, we show that, for k>=3, determining the minimum number of moves required\nto flood a k x n board coloured with at least four colours remains NP-hard.\n", "Comment: More typos corrected!"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.5876"}}, {"publisher": {"name": ""}, "description": "  Using a recently developed model, inspired by mean field theory in\nstatistical physics, and data from the UK's Research Assessment Exercise, we\nanalyse the relationship between the quality of statistics and operational\nresearch groups and the quantity researchers in them. Similar to other academic\ndisciplines, we provide evidence for a linear dependency of quality on quantity\nup to an upper critical mass, which is interpreted as the average maximum\nnumber of colleagues with whom a researcher can communicate meaningfully within\na research group. The model also predicts a lower critical mass, which research\ngroups should strive to achieve to avoid extinction. For statistics and\noperational research, the lower critical mass is estimated to be 9 $\\pm$ 3. The\nupper critical mass, beyond which research quality does not significantly\ndepend on group size, is about twice this value.\n", "contributors": [{"name": "Kenna, Ralph", "sameAs": [], "familyName": "Kenna", "additionalName": "", "givenName": "Ralph", "email": ""}, {"name": "Berche, Bertrand", "sameAs": [], "familyName": "Berche", "additionalName": "", "givenName": "Bertrand", "email": ""}], "title": "Statistics of statisticians: Critical mass of statistics and operational\n  research groups in the UK", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-02-24", "2011-03-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1102.4914", "International Journal of Modern Physics: Conference Series 16\n  (2012) 29-40", "doi:10.1142/S2010194512007751", "oai:arXiv.org:1102.4914"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:physics", "stat"]}}, {"name": "description", "properties": {"description": "  Using a recently developed model, inspired by mean field theory in\nstatistical physics, and data from the UK's Research Assessment Exercise, we\nanalyse the relationship between the quality of statistics and operational\nresearch groups and the quantity researchers in them. Similar to other academic\ndisciplines, we provide evidence for a linear dependency of quality on quantity\nup to an upper critical mass, which is interpreted as the average maximum\nnumber of colleagues with whom a researcher can communicate meaningfully within\na research group. The model also predicts a lower critical mass, which research\ngroups should strive to achieve to avoid extinction. For statistics and\noperational research, the lower critical mass is estimated to be 9 $\\pm$ 3. The\nupper critical mass, beyond which research quality does not significantly\ndepend on group size, is about twice this value.\n"}}], "languages": [null], "subjects": ["mathematics - statistics theory", "physics - physics and society", "computer science - digital libraries"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1102.4914"}}, {"publisher": {"name": ""}, "description": "  In congested urban areas, it remains a pressing challenge to reduce\nunnecessary vehicle circling for parking while at the same time maximize\nparking space utilization. In observance of new information technologies that\nhave become readily accessible to drivers and parking agencies, we develop a\ndynamic non-cooperative bi-level model (i.e. Stackelberg leader-follower game)\nto set parking prices in real-time for effective parking access and space\nutilization. The model is expected to fit into an integrated parking pricing\nand management system, where parking reservations and transactions are\nfacilitated by sensing and informatics infrastructures, that ensures the\navailability of convenient spaces at equilibrium market prices. It is shown\nwith numerical examples that the proposed dynamic parking pricing model has the\npotential to virtually eliminate vehicle circling for parking, which results in\nsignificant reduction in adverse socioeconomic externalities such as traffic\ncongestion and emissions.\n", "contributors": [{"name": "Mackowski, Daniel", "sameAs": [], "familyName": "Mackowski", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Bai, Yun", "sameAs": [], "familyName": "Bai", "additionalName": "", "givenName": "Yun", "email": ""}, {"name": "Ouyang, Yanfeng", "sameAs": [], "familyName": "Ouyang", "additionalName": "", "givenName": "Yanfeng", "email": ""}], "title": "Parking Space Management via Dynamic Performance-Based Pricing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00638", "oai:arXiv.org:1501.00638"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In congested urban areas, it remains a pressing challenge to reduce\nunnecessary vehicle circling for parking while at the same time maximize\nparking space utilization. In observance of new information technologies that\nhave become readily accessible to drivers and parking agencies, we develop a\ndynamic non-cooperative bi-level model (i.e. Stackelberg leader-follower game)\nto set parking prices in real-time for effective parking access and space\nutilization. The model is expected to fit into an integrated parking pricing\nand management system, where parking reservations and transactions are\nfacilitated by sensing and informatics infrastructures, that ensures the\navailability of convenient spaces at equilibrium market prices. It is shown\nwith numerical examples that the proposed dynamic parking pricing model has the\npotential to virtually eliminate vehicle circling for parking, which results in\nsignificant reduction in adverse socioeconomic externalities such as traffic\ncongestion and emissions.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00638"}}, {"publisher": {"name": ""}, "description": "  For several semirings S, two weighted finite automata with multiplicities in\nS are equivalent if and only if they can be connected by a chain of\nsimulations. Such a semiring S is called \"proper\". It is known that the Boolean\nsemiring, the semiring of natural numbers, the ring of integers, all finite\ncommutative positively ordered semirings and all fields are proper. The\nsemiring S is Noetherian if every subsemimodule of a finitely generated\nS-semimodule is finitely generated. First, it is shown that all Noetherian\nsemirings and thus all commutative rings and all finite semirings are proper.\nSecond, the tropical semiring is shown not to be proper. So far there has not\nbeen any example of a semiring that is not proper.\n", "contributors": [{"name": "Esik, Zoltan", "sameAs": [], "familyName": "Esik", "additionalName": "", "givenName": "Zoltan", "email": ""}, {"name": "Maletti, Andreas", "sameAs": [], "familyName": "Maletti", "additionalName": "", "givenName": "Andreas", "email": ""}], "title": "Simulation vs. Equivalence", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-04-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1004.2426", "oai:arXiv.org:1004.2426"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  For several semirings S, two weighted finite automata with multiplicities in\nS are equivalent if and only if they can be connected by a chain of\nsimulations. Such a semiring S is called \"proper\". It is known that the Boolean\nsemiring, the semiring of natural numbers, the ring of integers, all finite\ncommutative positively ordered semirings and all fields are proper. The\nsemiring S is Noetherian if every subsemimodule of a finitely generated\nS-semimodule is finitely generated. First, it is shown that all Noetherian\nsemirings and thus all commutative rings and all finite semirings are proper.\nSecond, the tropical semiring is shown not to be proper. So far there has not\nbeen any example of a semiring that is not proper.\n"}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "68q45", "68q70"], "providerUpdatedDateTime": "2015-03-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1004.2426"}}, {"publisher": {"name": ""}, "description": "  Molecular communication between biological entities is a new paradigm in\ncommunications. Recently, we studied molecular communication between two nodes\nformed from synthetic bacteria. Due to high randomness in behavior of bacteria,\nwe used a population of them in each node. The reliability of such\ncommunication systems depends on both the maximum concentration of molecules\nthat a transmitter node is able to produce at the receiver node as well as the\nnumber of bacteria in each nodes. This maximum concentration of molecules falls\nwith distance which makes the communication to the far nodes nearly impossible.\nIn order to alleviate this problem, in this paper, we propose to use a\nmolecular relaying node. The relay node can resend the message either by the\ndifferent or the same type of molecules as the original signal from the\ntransmitter. We study two scenarios of relaying. In the first scenario, the\nrelay node simply senses the received concentration and forwards it to the\nreceiver. We show that this sense and forward scenario, depending on the type\nof molecules used for relaying, results in either increasing the range of\nconcentration of molecules at the receiver or increasing the effective number\nof bacteria in the receiver node. For both cases of sense and forward relaying,\nwe obtain the resulting improvement in channel capacity. We conclude that\nmulti-type molecular relaying outperforms the single-type relaying. In the\nsecond scenario, we study the decode and forward relaying for the M-ary\nsignaling scheme. We show that this relaying strategy increases the reliability\nof M-ary communication significantly.\n", "contributors": [{"name": "Einolghozati, Arash", "sameAs": [], "familyName": "Einolghozati", "additionalName": "", "givenName": "Arash", "email": ""}, {"name": "Sardari, Mohsen", "sameAs": [], "familyName": "Sardari", "additionalName": "", "givenName": "Mohsen", "email": ""}, {"name": "Fekri, Faramarz", "sameAs": [], "familyName": "Fekri", "additionalName": "", "givenName": "Faramarz", "email": ""}], "title": "Relaying in Diffusion-Based Molecular Communication", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1086", "oai:arXiv.org:1410.1086"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "q-bio"]}}, {"name": "description", "properties": {"description": "  Molecular communication between biological entities is a new paradigm in\ncommunications. Recently, we studied molecular communication between two nodes\nformed from synthetic bacteria. Due to high randomness in behavior of bacteria,\nwe used a population of them in each node. The reliability of such\ncommunication systems depends on both the maximum concentration of molecules\nthat a transmitter node is able to produce at the receiver node as well as the\nnumber of bacteria in each nodes. This maximum concentration of molecules falls\nwith distance which makes the communication to the far nodes nearly impossible.\nIn order to alleviate this problem, in this paper, we propose to use a\nmolecular relaying node. The relay node can resend the message either by the\ndifferent or the same type of molecules as the original signal from the\ntransmitter. We study two scenarios of relaying. In the first scenario, the\nrelay node simply senses the received concentration and forwards it to the\nreceiver. We show that this sense and forward scenario, depending on the type\nof molecules used for relaying, results in either increasing the range of\nconcentration of molecules at the receiver or increasing the effective number\nof bacteria in the receiver node. For both cases of sense and forward relaying,\nwe obtain the resulting improvement in channel capacity. We conclude that\nmulti-type molecular relaying outperforms the single-type relaying. In the\nsecond scenario, we study the decode and forward relaying for the M-ary\nsignaling scheme. We show that this relaying strategy increases the reliability\nof M-ary communication significantly.\n"}}], "languages": [null], "subjects": ["computer science - information theory", "computer science - emerging technologies", "quantitative biology - molecular networks"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1086"}}, {"publisher": {"name": ""}, "description": "  A 3-D spatiotemporal prediction-error filter (PEF), is used to enhance\nforeground/background contrast in (real and simulated) sensor image sequences.\nRelative velocity is utilized to extract point-targets that would otherwise be\nindistinguishable on spatial frequency alone. An optical-flow field is\ngenerated using local estimates of the 3-D autocorrelation function via the\napplication of the fast Fourier transform (FFT) and inverse FFT. Velocity\nestimates are then used to tune in a background-whitening PEF that is matched\nto the motion and texture of the local background. Finite-impulse-response\n(FIR) filters are designed and implemented in the frequency domain. An\nanalytical expression for the frequency response of velocity-tuned FIR filters,\nof odd or even dimension, with an arbitrary delay in each dimension, is\nderived.\n", "contributors": [{"name": "Kennedy, Hugh L.", "sameAs": [], "familyName": "Kennedy", "additionalName": "L.", "givenName": "Hugh", "email": ""}], "title": "Multidimensional Digital Filters for Point-Target Detection in Cluttered\n  Infrared Scenes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-11", "2015-01-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.2590", "J. Electron. Imaging. 23 (6), 063019 (December 17, 2014)", "doi:10.1117/1.JEI.23.6.063019", "oai:arXiv.org:1408.2590"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  A 3-D spatiotemporal prediction-error filter (PEF), is used to enhance\nforeground/background contrast in (real and simulated) sensor image sequences.\nRelative velocity is utilized to extract point-targets that would otherwise be\nindistinguishable on spatial frequency alone. An optical-flow field is\ngenerated using local estimates of the 3-D autocorrelation function via the\napplication of the fast Fourier transform (FFT) and inverse FFT. Velocity\nestimates are then used to tune in a background-whitening PEF that is matched\nto the motion and texture of the local background. Finite-impulse-response\n(FIR) filters are designed and implemented in the frequency domain. An\nanalytical expression for the frequency response of velocity-tuned FIR filters,\nof odd or even dimension, with an arbitrary delay in each dimension, is\nderived.\n", "Comment: Accepted version"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.2590"}}, {"publisher": {"name": ""}, "description": "  The goal of traffic management is efficiently utilizing network resources via\nadapting of source sending rates and routes selection. Traditionally, this\nproblem is formulated into a utilization maximization problem. The single-path\nrouting scheme fails to react to instantaneous network congestion. Multi-path\nrouting schemes thus have been proposed aiming at improving network efficiency.\nUnfortunately, the natural optimization problem to consider is concave but not\nstrictly concave. It thus brings a huge challenge to design stable multi-path\ncongestion control algorithms.\n  In this paper, we propose a generalized multi-path utility maximization model\nto consider the problem of routes selection and flow control, and derive a\nfamily of multi-path dual congestion control algorithms. We show that the\nproposed algorithms are stable in the absence of delays. We also derive\ndecentralized and scalable sufficient conditions for a particular scheme when\npropagation delays exist in networks. Simulations are implemented using both\nMatlab and NS2, on which evaluation of the proposed multi-path dual algorithms\nis exerted. The comparison results, between the proposed algorithms and the\nother two existing algorithms, show that the proposed multi-path dual\nalgorithms with appropriate parameter settings can achieve a stable aggregated\nthroughput while maintaining fairness among the involved users.\n", "contributors": [{"name": "Liu, Ying", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Ying", "email": ""}, {"name": "Liu, Hongying", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Hongying", "email": ""}, {"name": "Xu, Ke", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Ke", "email": ""}, {"name": "Shen, Meng", "sameAs": [], "familyName": "Shen", "additionalName": "", "givenName": "Meng", "email": ""}, {"name": "Zhong, Yifeng", "sameAs": [], "familyName": "Zhong", "additionalName": "", "givenName": "Yifeng", "email": ""}], "title": "A Large Family of Multi-path Dual Congestion Control Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-04-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.3636", "oai:arXiv.org:1104.3636"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The goal of traffic management is efficiently utilizing network resources via\nadapting of source sending rates and routes selection. Traditionally, this\nproblem is formulated into a utilization maximization problem. The single-path\nrouting scheme fails to react to instantaneous network congestion. Multi-path\nrouting schemes thus have been proposed aiming at improving network efficiency.\nUnfortunately, the natural optimization problem to consider is concave but not\nstrictly concave. It thus brings a huge challenge to design stable multi-path\ncongestion control algorithms.\n  In this paper, we propose a generalized multi-path utility maximization model\nto consider the problem of routes selection and flow control, and derive a\nfamily of multi-path dual congestion control algorithms. We show that the\nproposed algorithms are stable in the absence of delays. We also derive\ndecentralized and scalable sufficient conditions for a particular scheme when\npropagation delays exist in networks. Simulations are implemented using both\nMatlab and NS2, on which evaluation of the proposed multi-path dual algorithms\nis exerted. The comparison results, between the proposed algorithms and the\nother two existing algorithms, show that the proposed multi-path dual\nalgorithms with appropriate parameter settings can achieve a stable aggregated\nthroughput while maintaining fairness among the involved users.\n", "Comment: 11 page"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.3636"}}, {"publisher": {"name": ""}, "description": "  In this paper, we examine the fundamental trade-off between radiated power\nand achieved throughput in wireless multi-carrier, multiple-input and\nmultiple-output (MIMO) systems that vary with time in an unpredictable fashion\n(e.g. due to changes in the wireless medium or the users' QoS requirements).\nContrary to the static/stationary channel regime, there is no optimal power\nallocation profile to target (either static or in the mean), so the system's\nusers must adapt to changes in the environment \"on the fly\", without being able\nto predict the system's evolution ahead of time. In this dynamic context, we\nformulate the users' power/throughput trade-off as an online optimization\nproblem and we provide a matrix exponential learning algorithm that leads to no\nregret - i.e. the proposed transmit policy is asymptotically optimal in\nhindsight, irrespective of how the system evolves over time. Furthermore, we\nalso examine the robustness of the proposed algorithm under imperfect channel\nstate information (CSI) and we show that it retains its regret minimization\nproperties under very mild conditions on the measurement noise statistics. As a\nresult, users are able to track the evolution of their individually optimum\ntransmit profiles remarkably well, even under rapidly changing network\nconditions and high uncertainty. Our theoretical analysis is validated by\nextensive numerical simulations corresponding to a realistic network deployment\nand providing further insights in the practical implementation aspects of the\nproposed algorithm.\n", "contributors": [{"name": "Stiakogiannakis, Ioannis", "sameAs": [], "familyName": "Stiakogiannakis", "additionalName": "", "givenName": "Ioannis", "email": ""}, {"name": "Mertikopoulos, Panayotis", "sameAs": [], "familyName": "Mertikopoulos", "additionalName": "", "givenName": "Panayotis", "email": ""}, {"name": "Touati, Corinne", "sameAs": [], "familyName": "Touati", "additionalName": "", "givenName": "Corinne", "email": ""}], "title": "Adaptive Power Allocation and Control in Time-Varying Multi-Carrier MIMO\n  Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02155", "oai:arXiv.org:1503.02155"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we examine the fundamental trade-off between radiated power\nand achieved throughput in wireless multi-carrier, multiple-input and\nmultiple-output (MIMO) systems that vary with time in an unpredictable fashion\n(e.g. due to changes in the wireless medium or the users' QoS requirements).\nContrary to the static/stationary channel regime, there is no optimal power\nallocation profile to target (either static or in the mean), so the system's\nusers must adapt to changes in the environment \"on the fly\", without being able\nto predict the system's evolution ahead of time. In this dynamic context, we\nformulate the users' power/throughput trade-off as an online optimization\nproblem and we provide a matrix exponential learning algorithm that leads to no\nregret - i.e. the proposed transmit policy is asymptotically optimal in\nhindsight, irrespective of how the system evolves over time. Furthermore, we\nalso examine the robustness of the proposed algorithm under imperfect channel\nstate information (CSI) and we show that it retains its regret minimization\nproperties under very mild conditions on the measurement noise statistics. As a\nresult, users are able to track the evolution of their individually optimum\ntransmit profiles remarkably well, even under rapidly changing network\nconditions and high uncertainty. Our theoretical analysis is validated by\nextensive numerical simulations corresponding to a realistic network deployment\nand providing further insights in the practical implementation aspects of the\nproposed algorithm.\n", "Comment: 25 pages, 4 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02155"}}, {"publisher": {"name": ""}, "description": "  We study the parameterized complexity of domination-type problems.\n(sigma,rho)-domination is a general and unifying framework introduced by Telle:\na set D of vertices of a graph G is (sigma,rho)-dominating if for any v in D,\n|N(v)\\cap D| in sigma and for any $v\\notin D, |N(v)\\cap D| in rho. We mainly\nshow that for any sigma and rho the problem of (sigma,rho)-domination is W[2]\nwhen parameterized by the size of the dominating set. This general statement is\noptimal in the sense that several particular instances of\n(sigma,rho)-domination are W[2]-complete (e.g. Dominating Set). We also prove\nthat (sigma,rho)-domination is W[2] for the dual parameterization, i.e. when\nparameterized by the size of the dominated set. We extend this result to a\nclass of domination-type problems which do not fall into the\n(sigma,rho)-domination framework, including Connected Dominating Set. We also\nconsider problems of coding theory which are related to domination-type\nproblems with parity constraints. In particular, we prove that the problem of\nthe minimal distance of a linear code over Fq is W[2] for both standard and\ndual parameterizations, and W[1]-hard for the dual parameterization.\n  To prove W[2]-membership of the domination-type problems we extend the\nTuring-way to parameterized complexity by introducing a new kind of non\ndeterministic Turing machine with the ability to perform `blind' transitions,\ni.e. transitions which do not depend on the content of the tapes. We prove that\nthe corresponding problem Short Blind Multi-Tape Non-Deterministic Turing\nMachine is W[2]-complete. We believe that this new machine can be used to prove\nW[2]-membership of other problems, not necessarily related to domination\n", "contributors": [{"name": "Cattan\u00e9o, David", "sameAs": [], "familyName": "Cattan\u00e9o", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Perdrix, Simon", "sameAs": [], "familyName": "Perdrix", "additionalName": "", "givenName": "Simon", "email": ""}], "title": "The Parameterized Complexity of Domination-type Problems and Application\n  to Linear Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-09-24", "2015-01-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1209.5267", "TAMC'14, LNCS vol. 8402, pp.86-103, 2014", "doi:10.1007/978-3-319-06089-7_7", "oai:arXiv.org:1209.5267"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study the parameterized complexity of domination-type problems.\n(sigma,rho)-domination is a general and unifying framework introduced by Telle:\na set D of vertices of a graph G is (sigma,rho)-dominating if for any v in D,\n|N(v)\\cap D| in sigma and for any $v\\notin D, |N(v)\\cap D| in rho. We mainly\nshow that for any sigma and rho the problem of (sigma,rho)-domination is W[2]\nwhen parameterized by the size of the dominating set. This general statement is\noptimal in the sense that several particular instances of\n(sigma,rho)-domination are W[2]-complete (e.g. Dominating Set). We also prove\nthat (sigma,rho)-domination is W[2] for the dual parameterization, i.e. when\nparameterized by the size of the dominated set. We extend this result to a\nclass of domination-type problems which do not fall into the\n(sigma,rho)-domination framework, including Connected Dominating Set. We also\nconsider problems of coding theory which are related to domination-type\nproblems with parity constraints. In particular, we prove that the problem of\nthe minimal distance of a linear code over Fq is W[2] for both standard and\ndual parameterizations, and W[1]-hard for the dual parameterization.\n  To prove W[2]-membership of the domination-type problems we extend the\nTuring-way to parameterized complexity by introducing a new kind of non\ndeterministic Turing machine with the ability to perform `blind' transitions,\ni.e. transitions which do not depend on the content of the tapes. We prove that\nthe corresponding problem Short Blind Multi-Tape Non-Deterministic Turing\nMachine is W[2]-complete. We believe that this new machine can be used to prove\nW[2]-membership of other problems, not necessarily related to domination\n", "Comment: 19 pages, 2 figures"]}}], "languages": [null], "subjects": ["computer science - computational complexity"], "providerUpdatedDateTime": "2015-01-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1209.5267"}}, {"publisher": {"name": ""}, "description": "  We study how the C11 memory model can be simplified and how it can be\nextended. Our first contribution is to propose a mild strengthening of the\nmodel that enables the rules pertaining to sequentially-consistent (SC)\noperations to be significantly simplified. We eliminate one of the total orders\nthat candidate executions must range over, leading to a model that is\nsignificantly faster to simulate. Our endeavours to simplify the C11 memory\nmodel are particularly timely, now that it provides a foundation for memory\nmodels of more exotic languages - such as OpenCL 2.0, an extension of C for\nprogramming heterogeneous systems composed of CPUs, GPUs and other devices. Our\nsecond contribution is the first mechanised formalisation of the OpenCL 2.0\nmemory model, extending our simplified C11 model. Our C11 and OpenCL memory\nmodel formalisations are expressed in the .cat language of Alglave et al., the\nnative input format of the herd memory model simulator. Originally designed for\nthe efficient simulation of hardware memory models, we have extended herd to\nsupport language-level memory models.\n", "contributors": [{"name": "Wickerson, John", "sameAs": [], "familyName": "Wickerson", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Batty, Mark", "sameAs": [], "familyName": "Batty", "additionalName": "", "givenName": "Mark", "email": ""}], "title": "Taming the complexities of the C11 and OpenCL memory models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07073", "oai:arXiv.org:1503.07073"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study how the C11 memory model can be simplified and how it can be\nextended. Our first contribution is to propose a mild strengthening of the\nmodel that enables the rules pertaining to sequentially-consistent (SC)\noperations to be significantly simplified. We eliminate one of the total orders\nthat candidate executions must range over, leading to a model that is\nsignificantly faster to simulate. Our endeavours to simplify the C11 memory\nmodel are particularly timely, now that it provides a foundation for memory\nmodels of more exotic languages - such as OpenCL 2.0, an extension of C for\nprogramming heterogeneous systems composed of CPUs, GPUs and other devices. Our\nsecond contribution is the first mechanised formalisation of the OpenCL 2.0\nmemory model, extending our simplified C11 model. Our C11 and OpenCL memory\nmodel formalisations are expressed in the .cat language of Alglave et al., the\nnative input format of the herd memory model simulator. Originally designed for\nthe efficient simulation of hardware memory models, we have extended herd to\nsupport language-level memory models.\n", "Comment: 15 pages + 2 pages of references + 4 pages of appendices"]}}], "languages": [null], "subjects": ["computer science - programming languages"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07073"}}, {"publisher": {"name": ""}, "description": "  In this work, a multiple-expert binarization framework for multispectral\nimages is proposed. The framework is based on a constrained subspace selection\nlimited to the spectral bands combined with state-of-the-art gray-level\nbinarization methods. The framework uses a binarization wrapper to enhance the\nperformance of the gray-level binarization. Nonlinear preprocessing of the\nindividual spectral bands is used to enhance the textual information. An\nevolutionary optimizer is considered to obtain the optimal and some suboptimal\n3-band subspaces from which an ensemble of experts is then formed. The\nframework is applied to a ground truth multispectral dataset with promising\nresults. In addition, a generalization to the cross-validation approach is\ndeveloped that not only evaluates generalizability of the framework, it also\nprovides a practical instance of the selected experts that could be then\napplied to unseen inputs despite the small size of the given ground truth\ndataset.\n", "contributors": [{"name": "Moghaddam, Reza Farrahi", "sameAs": [], "familyName": "Moghaddam", "additionalName": "Farrahi", "givenName": "Reza", "email": ""}, {"name": "Cheriet, Mohamed", "sameAs": [], "familyName": "Cheriet", "additionalName": "", "givenName": "Mohamed", "email": ""}], "title": "A Multiple-Expert Binarization Framework for Multispectral Images", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-02-04", "2015-04-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01199", "oai:arXiv.org:1502.01199"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this work, a multiple-expert binarization framework for multispectral\nimages is proposed. The framework is based on a constrained subspace selection\nlimited to the spectral bands combined with state-of-the-art gray-level\nbinarization methods. The framework uses a binarization wrapper to enhance the\nperformance of the gray-level binarization. Nonlinear preprocessing of the\nindividual spectral bands is used to enhance the textual information. An\nevolutionary optimizer is considered to obtain the optimal and some suboptimal\n3-band subspaces from which an ensemble of experts is then formed. The\nframework is applied to a ground truth multispectral dataset with promising\nresults. In addition, a generalization to the cross-validation approach is\ndeveloped that not only evaluates generalizability of the framework, it also\nprovides a practical instance of the selected experts that could be then\napplied to unseen inputs despite the small size of the given ground truth\ndataset.\n", "Comment: 8 pages, 4 figures, 5 tables. Submitted to ICDAR'15"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01199"}}, {"publisher": {"name": ""}, "description": "  We introduce a new Markov chain Monte Carlo (MCMC) sampler that iterates by\nconstructing conditional importance sampling (IS) approximations to target\ndistributions. We present Markov interacting importance samplers (MIIS) in\ngeneral form, followed by examples to demonstrate their flexibility. A leading\napplication is when the exact Gibbs sampler is not available due to\ninfeasibility of direct simulation from the conditional distributions. The MIIS\nalgorithm uses conditional IS approximations to jointly sample the current\nstate of the Markov Chain and estimate conditional expectations (possibly by\nincorporating a full range of variance reduction techniques). We compute\nRao-Blackwellized estimates based on the conditional expectations to construct\ncontrol variates for estimating expectations under the target distribution. The\ncontrol variates are particularly efficient when there are substantial\ncorrelations in the target distribution, a challenging setting for MCMC. We\nalso introduce the MIIS random walk algorithm, designed to accelerate\nconvergence and improve upon the computational efficiency of standard random\nwalk samplers. Simulated and empirical illustrations for Bayesian analysis of\nthe mixed Logit model and Markov modulated Poisson processes show that the\nmethod significantly reduces the variance of Monte Carlo estimates compared to\nstandard MCMC approaches, at equivalent implementation and computational\neffort.\n", "contributors": [{"name": "Mendes, Eduardo F.", "sameAs": [], "familyName": "Mendes", "additionalName": "F.", "givenName": "Eduardo", "email": ""}, {"name": "Scharth, Marcel", "sameAs": [], "familyName": "Scharth", "additionalName": "", "givenName": "Marcel", "email": ""}, {"name": "Kohn, Robert", "sameAs": [], "familyName": "Kohn", "additionalName": "", "givenName": "Robert", "email": ""}], "title": "Markov Interacting Importance Samplers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07039", "oai:arXiv.org:1502.07039"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  We introduce a new Markov chain Monte Carlo (MCMC) sampler that iterates by\nconstructing conditional importance sampling (IS) approximations to target\ndistributions. We present Markov interacting importance samplers (MIIS) in\ngeneral form, followed by examples to demonstrate their flexibility. A leading\napplication is when the exact Gibbs sampler is not available due to\ninfeasibility of direct simulation from the conditional distributions. The MIIS\nalgorithm uses conditional IS approximations to jointly sample the current\nstate of the Markov Chain and estimate conditional expectations (possibly by\nincorporating a full range of variance reduction techniques). We compute\nRao-Blackwellized estimates based on the conditional expectations to construct\ncontrol variates for estimating expectations under the target distribution. The\ncontrol variates are particularly efficient when there are substantial\ncorrelations in the target distribution, a challenging setting for MCMC. We\nalso introduce the MIIS random walk algorithm, designed to accelerate\nconvergence and improve upon the computational efficiency of standard random\nwalk samplers. Simulated and empirical illustrations for Bayesian analysis of\nthe mixed Logit model and Markov modulated Poisson processes show that the\nmethod significantly reduces the variance of Monte Carlo estimates compared to\nstandard MCMC approaches, at equivalent implementation and computational\neffort.\n"}}], "languages": [null], "subjects": ["statistics - computation"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07039"}}], "time": 0.27}