{"count": 24749, "results": [{"publisher": {"name": ""}, "description": "  We present an unsupervised framework for simultaneous appearance-based object\ndiscovery, detection, tracking and reconstruction using RGBD cameras and a\nrobot manipulator. The system performs dense 3D simultaneous localization and\nmapping concurrently with unsupervised object discovery. Putative objects that\nare spatially and visually coherent are manipulated by the robot to gain\nadditional motion-cues. The robot uses appearance alone, followed by structure\nand motion cues, to jointly discover, verify, learn and improve models of\nobjects. Induced motion segmentation reinforces learned models which are\nrepresented implicitly as 2D and 3D level sets to capture both shape and\nappearance. We compare three different approaches for appearance-based object\ndiscovery and find that a novel form of spatio-temporal super-pixels gives the\nhighest quality candidate object models in terms of precision and recall. Live\nexperiments with a Baxter robot demonstrate a holistic pipeline capable of\nautomatic discovery, verification, detection, tracking and reconstruction of\nunknown objects.\n", "contributors": [{"name": "Ma, Lu", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Lu", "email": ""}, {"name": "Ghafarianzadeh, Mahsa", "sameAs": [], "familyName": "Ghafarianzadeh", "additionalName": "", "givenName": "Mahsa", "email": ""}, {"name": "Coleman, Dave", "sameAs": [], "familyName": "Coleman", "additionalName": "", "givenName": "Dave", "email": ""}, {"name": "Correll, Nikolaus", "sameAs": [], "familyName": "Correll", "additionalName": "", "givenName": "Nikolaus", "email": ""}, {"name": "Sibley, Gabe", "sameAs": [], "familyName": "Sibley", "additionalName": "", "givenName": "Gabe", "email": ""}], "title": "Simultaneous Localization, Mapping, and Manipulation for Unsupervised\n  Object Discovery", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0802", "oai:arXiv.org:1411.0802"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We present an unsupervised framework for simultaneous appearance-based object\ndiscovery, detection, tracking and reconstruction using RGBD cameras and a\nrobot manipulator. The system performs dense 3D simultaneous localization and\nmapping concurrently with unsupervised object discovery. Putative objects that\nare spatially and visually coherent are manipulated by the robot to gain\nadditional motion-cues. The robot uses appearance alone, followed by structure\nand motion cues, to jointly discover, verify, learn and improve models of\nobjects. Induced motion segmentation reinforces learned models which are\nrepresented implicitly as 2D and 3D level sets to capture both shape and\nappearance. We compare three different approaches for appearance-based object\ndiscovery and find that a novel form of spatio-temporal super-pixels gives the\nhighest quality candidate object models in terms of precision and recall. Live\nexperiments with a Baxter robot demonstrate a holistic pipeline capable of\nautomatic discovery, verification, detection, tracking and reconstruction of\nunknown objects.\n"}}], "languages": [null], "subjects": ["computer science - robotics", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0802"}}, {"publisher": {"name": ""}, "description": "  In contrast to today's IP-based host-oriented Internet architecture,\nInformation-Centric Networking (ICN) emphasizes content by making it directly\naddressable and routable. Named Data Networking (NDN) architecture is an\ninstance of ICN that is being developed as a candidate next-generation Internet\narchitecture. By opportunistically caching content within the network (in\nrouters), NDN appears to be well-suited for large-scale content distribution\nand for meeting the needs of increasingly mobile and bandwidth-hungry\napplications that dominate today's Internet.\n  One key feature of NDN is the requirement for each content object to be\ndigitally signed by its producer. Thus, NDN should be, in principle, immune to\ndistributing fake (aka \"poisoned\") content. However, in practice, this poses\ntwo challenges for detecting fake content in NDN routers: (1) overhead due to\nsignature verification and certificate chain traversal, and (2) lack of trust\ncontext, i.e., determining which public keys are trusted to verify which\ncontent. Because of these issues, NDN does not force routers to verify content\nsignatures, which makes the architecture susceptible to content poisoning\nattacks.\n  This paper explores root causes of, and some cures for, content poisoning\nattacks in NDN. In the process, it becomes apparent that meaningful mitigation\nof content poisoning is contingent upon a network-layer trust management\narchitecture, elements of which we construct while carefully justifying\nspecific design choices. This work represents the initial effort towards\ncomprehensive trust management for NDN.\n", "contributors": [{"name": "Ghali, Cesar", "sameAs": [], "familyName": "Ghali", "additionalName": "", "givenName": "Cesar", "email": ""}, {"name": "Tsudik, Gene", "sameAs": [], "familyName": "Tsudik", "additionalName": "", "givenName": "Gene", "email": ""}, {"name": "Uzun, Ersin", "sameAs": [], "familyName": "Uzun", "additionalName": "", "givenName": "Ersin", "email": ""}], "title": "Elements of Trust in Named-Data Networking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-13", "2014-10-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.3332", "ACM SIGCOMM Computer Communication Review, Volume 44 Issue 5,\n  October 2014", "doi:10.1145/2677046.2677049", "oai:arXiv.org:1402.3332"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In contrast to today's IP-based host-oriented Internet architecture,\nInformation-Centric Networking (ICN) emphasizes content by making it directly\naddressable and routable. Named Data Networking (NDN) architecture is an\ninstance of ICN that is being developed as a candidate next-generation Internet\narchitecture. By opportunistically caching content within the network (in\nrouters), NDN appears to be well-suited for large-scale content distribution\nand for meeting the needs of increasingly mobile and bandwidth-hungry\napplications that dominate today's Internet.\n  One key feature of NDN is the requirement for each content object to be\ndigitally signed by its producer. Thus, NDN should be, in principle, immune to\ndistributing fake (aka \"poisoned\") content. However, in practice, this poses\ntwo challenges for detecting fake content in NDN routers: (1) overhead due to\nsignature verification and certificate chain traversal, and (2) lack of trust\ncontext, i.e., determining which public keys are trusted to verify which\ncontent. Because of these issues, NDN does not force routers to verify content\nsignatures, which makes the architecture susceptible to content poisoning\nattacks.\n  This paper explores root causes of, and some cures for, content poisoning\nattacks in NDN. In the process, it becomes apparent that meaningful mitigation\nof content poisoning is contingent upon a network-layer trust management\narchitecture, elements of which we construct while carefully justifying\nspecific design choices. This work represents the initial effort towards\ncomprehensive trust management for NDN.\n", "Comment: 9 pages, 2 figures"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-10-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.3332"}}, {"publisher": {"name": ""}, "description": "  We consider channel/subspace tracking systems for temporally correlated\nmillimeter wave (e.g., E-band) multiple-input multiple-output (MIMO) channels.\nOur focus is given to the tracking algorithm in the non-line-of-sight (NLoS)\nenvironment, where the transmitter and the receiver are equipped with hybrid\nanalog/digital precoder and combiner, respectively. In the absence of\nstraightforward time-correlated channel model in the millimeter wave MIMO\nliterature, we present a temporal MIMO channel evolution model for NLoS\nmillimeter wave scenarios. Considering that conventional MIMO channel tracking\nalgorithms in microwave bands are not directly applicable, we propose a new\nchannel tracking technique based on sequentially updating the precoder and\ncombiner. Numerical results demonstrate the superior channel tracking ability\nof the proposed technique over independent sounding approach in the presented\nchannel model and the spatial channel model (SCM) adopted in 3GPP\nspecification.\n", "contributors": [{"name": "He, Jiguang", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Jiguang", "email": ""}, {"name": "Kim, Taejoon", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Taejoon", "email": ""}, {"name": "Ghauch, Hadi", "sameAs": [], "familyName": "Ghauch", "additionalName": "", "givenName": "Hadi", "email": ""}, {"name": "Liu, Kunpeng", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Kunpeng", "email": ""}, {"name": "Wang, Guangjian", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Guangjian", "email": ""}], "title": "Millimeter Wave MIMO Channel Tracking Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4224", "oai:arXiv.org:1412.4224"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider channel/subspace tracking systems for temporally correlated\nmillimeter wave (e.g., E-band) multiple-input multiple-output (MIMO) channels.\nOur focus is given to the tracking algorithm in the non-line-of-sight (NLoS)\nenvironment, where the transmitter and the receiver are equipped with hybrid\nanalog/digital precoder and combiner, respectively. In the absence of\nstraightforward time-correlated channel model in the millimeter wave MIMO\nliterature, we present a temporal MIMO channel evolution model for NLoS\nmillimeter wave scenarios. Considering that conventional MIMO channel tracking\nalgorithms in microwave bands are not directly applicable, we propose a new\nchannel tracking technique based on sequentially updating the precoder and\ncombiner. Numerical results demonstrate the superior channel tracking ability\nof the proposed technique over independent sounding approach in the presented\nchannel model and the spatial channel model (SCM) adopted in 3GPP\nspecification.\n", "Comment: 6 pages, 3 figures, conference"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4224"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "One of the primary problems in constructing risk-stratification models for medical applications is that the data are often noisy, incomplete, and suffer from high class-imbalance. This problem becomes more severe when the total amount of data relevant to the task of interest is small. We address this problem in the context of risk-stratifying patients receiving isolated surgical aortic valve replacements (isolated AVR) for the adverse outcomes of operative mortality and stroke. We work with data from two hospitals (Hospital 1 and Hospital 2) in the Society of Thoracic Surgeons (STS) Adult Cardiac Surgery Database. Because the data available for our application of interest (target data) are limited, developing an accurate model using only these data is infeasible. Instead, we investigate transfer learning approaches to utilize data from other cardiac surgery procedures as well as from other institutions (source data). We first evaluate the effectiveness of leveraging information across procedures within a single hospital. We achieve significant improvements over baseline: at Hospital 1, the average AUC for operative mortality increased from 0.58 to 0.70. However, not all source examples are equally useful. Next, we evaluate the effectiveness of leveraging data across hospitals. We show that leveraging information across hospitals has variable utility; although it can result in worse performance (average AUC for stroke at Hospital 1 dropped from 0.61 to 0.56), it can also lead to significant improvements (average AUC for operative mortality at Hospital 1 increased from 0.70 to 0.72). Finally, we present an automated approach to leveraging the available source data. We investigate how removing source data based on how far they are from the mean of the target data affects performance. We propose an instance-weighting scheme based on these distances. This automated instance-weighting approach can achieve small, but significant improvements over using all of the data without weights (average AUC for operative mortality at Hospital 1 increased from 0.72 to 0.73). Research on these methods can have an important impact on the development of clinical risk-stratification tools targeted towards specific patient populations.", "contributors": [{"name": "Gong, Jen J. (Jen Jian)", "sameAs": [], "familyName": "Gong", "additionalName": "J.", "givenName": "Jen", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Electrical Engineering and Computer Science.", "sameAs": [], "familyName": "Science.", "additionalName": "Institute of Technology. Department of Electrical Engineering and Computer", "givenName": "Massachusetts", "email": ""}, {"name": "John V. Guttag.", "sameAs": [], "familyName": "Guttag.", "additionalName": "V.", "givenName": "John", "email": ""}], "title": "Improving clinical risk-stratification tools : instance-transfer for selecting relevant training data", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "71 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/91090", "892724540", "oai:dspace.mit.edu:1721.1/91090"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2014-10-21T17:25:32Z", "2014-10-21T17:25:32Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["One of the primary problems in constructing risk-stratification models for medical applications is that the data are often noisy, incomplete, and suffer from high class-imbalance. This problem becomes more severe when the total amount of data relevant to the task of interest is small. We address this problem in the context of risk-stratifying patients receiving isolated surgical aortic valve replacements (isolated AVR) for the adverse outcomes of operative mortality and stroke. We work with data from two hospitals (Hospital 1 and Hospital 2) in the Society of Thoracic Surgeons (STS) Adult Cardiac Surgery Database. Because the data available for our application of interest (target data) are limited, developing an accurate model using only these data is infeasible. Instead, we investigate transfer learning approaches to utilize data from other cardiac surgery procedures as well as from other institutions (source data). We first evaluate the effectiveness of leveraging information across procedures within a single hospital. We achieve significant improvements over baseline: at Hospital 1, the average AUC for operative mortality increased from 0.58 to 0.70. However, not all source examples are equally useful. Next, we evaluate the effectiveness of leveraging data across hospitals. We show that leveraging information across hospitals has variable utility; although it can result in worse performance (average AUC for stroke at Hospital 1 dropped from 0.61 to 0.56), it can also lead to significant improvements (average AUC for operative mortality at Hospital 1 increased from 0.70 to 0.72). Finally, we present an automated approach to leveraging the available source data. We investigate how removing source data based on how far they are from the mean of the target data affects performance. We propose an instance-weighting scheme based on these distances. This automated instance-weighting approach can achieve small, but significant improvements over using all of the data without weights (average AUC for operative mortality at Hospital 1 increased from 0.72 to 0.73). Research on these methods can have an important impact on the development of clinical risk-stratification tools targeted towards specific patient populations.", "by Jen J. Gong.", "Thesis: S.M. in Computer Science and Engineering, Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2014.", "52", "Cataloged from PDF version of thesis.", "Includes bibliographical references (pages 66-71)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7817", "hdl_1721.1_7663"]}}], "languages": [null], "subjects": ["electrical engineering and computer science."], "providerUpdatedDateTime": "2015-04-09T06:21:41", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/91090"}}, {"publisher": {"name": ""}, "description": "  TCP and its variants have suffered from surprisingly poor performance for\ndecades. We argue the TCP family has little hope to achieve consistent high\nperformance due to a fundamental architectural deficiency: hardwiring\npacket-level events to control responses without understanding the real\nperformance result of its actions. We propose Performance-oriented Congestion\nControl (PCC), a new congestion control architecture in which each sender\ncontinuously observes the connection between its actions and empirically\nexperienced performance, enabling it to consistently adopt actions that result\nin high performance. We prove that PCC converges to a stable and fair\nequilibrium. Across many real-world and challenging environments, PCC shows\nconsistent and often 10x performance improvement, with better fairness and\nstability than TCP. PCC requires no router hardware support or new packet\nformat.\n", "contributors": [{"name": "Dong, Mo", "sameAs": [], "familyName": "Dong", "additionalName": "", "givenName": "Mo", "email": ""}, {"name": "Li, Qingxi", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Qingxi", "email": ""}, {"name": "Zarchy, Doron", "sameAs": [], "familyName": "Zarchy", "additionalName": "", "givenName": "Doron", "email": ""}, {"name": "Godfrey, Brighten", "sameAs": [], "familyName": "Godfrey", "additionalName": "", "givenName": "Brighten", "email": ""}, {"name": "Schapira, Michael", "sameAs": [], "familyName": "Schapira", "additionalName": "", "givenName": "Michael", "email": ""}], "title": "PCC: Re-architecting Congestion Control for Consistent High Performance", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-24", "2014-09-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.7092", "oai:arXiv.org:1409.7092"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  TCP and its variants have suffered from surprisingly poor performance for\ndecades. We argue the TCP family has little hope to achieve consistent high\nperformance due to a fundamental architectural deficiency: hardwiring\npacket-level events to control responses without understanding the real\nperformance result of its actions. We propose Performance-oriented Congestion\nControl (PCC), a new congestion control architecture in which each sender\ncontinuously observes the connection between its actions and empirically\nexperienced performance, enabling it to consistently adopt actions that result\nin high performance. We prove that PCC converges to a stable and fair\nequilibrium. Across many real-world and challenging environments, PCC shows\nconsistent and often 10x performance improvement, with better fairness and\nstability than TCP. PCC requires no router hardware support or new packet\nformat.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.7092"}}, {"publisher": {"name": ""}, "description": "  Mean Field Variational Bayes (MFVB) is a popular posterior approximation\nmethod due to its fast runtime on large-scale data sets. However, it is well\nknown that a major failing of MFVB is its (sometimes severe) underestimates of\nthe uncertainty of model variables and lack of information about model variable\ncovariance. We develop a fast, general methodology for exponential families\nthat augments MFVB to deliver accurate uncertainty estimates for model\nvariables -- both for individual variables and coherently across variables.\nMFVB for exponential families defines a fixed-point equation in the means of\nthe approximating posterior, and our approach yields a covariance estimate by\nperturbing this fixed point. Inspired by linear response theory, we call our\nmethod linear response variational Bayes (LRVB). We demonstrate the accuracy of\nour method on simulated data sets.\n", "contributors": [{"name": "Giordano, Ryan", "sameAs": [], "familyName": "Giordano", "additionalName": "", "givenName": "Ryan", "email": ""}, {"name": "Broderick, Tamara", "sameAs": [], "familyName": "Broderick", "additionalName": "", "givenName": "Tamara", "email": ""}], "title": "Covariance Matrices for Mean Field Variational Bayes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6853", "oai:arXiv.org:1410.6853"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Mean Field Variational Bayes (MFVB) is a popular posterior approximation\nmethod due to its fast runtime on large-scale data sets. However, it is well\nknown that a major failing of MFVB is its (sometimes severe) underestimates of\nthe uncertainty of model variables and lack of information about model variable\ncovariance. We develop a fast, general methodology for exponential families\nthat augments MFVB to deliver accurate uncertainty estimates for model\nvariables -- both for individual variables and coherently across variables.\nMFVB for exponential families defines a fixed-point equation in the means of\nthe approximating posterior, and our approach yields a covariance estimate by\nperturbing this fixed point. Inspired by linear response theory, we call our\nmethod linear response variational Bayes (LRVB). We demonstrate the accuracy of\nour method on simulated data sets.\n", "Comment: 12 pages, 2 figures"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning", "statistics - methodology"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6853"}}, {"publisher": {"name": ""}, "description": "  Based on the axiomatization of reversible computing RACP, we generalize it to\nquantum reversible computing which is called qRACP. By use of the framework of\nquantum configuration, we show that structural reversibility and quantum state\nreversibility must be satisfied simultaneously in quantum reversible\ncomputation. RACP and qRACP has the same axiomatization modulo the so-called\nquantum forward-reverse bisimularity, that is, classical reversible computing\nand quantum reversible computing are unified.\n", "contributors": [{"name": "Wang, Yong", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yong", "email": ""}], "title": "An Algebra of Reversible Quantum Computing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05260", "oai:arXiv.org:1501.05260"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Based on the axiomatization of reversible computing RACP, we generalize it to\nquantum reversible computing which is called qRACP. By use of the framework of\nquantum configuration, we show that structural reversibility and quantum state\nreversibility must be satisfied simultaneously in quantum reversible\ncomputation. RACP and qRACP has the same axiomatization modulo the so-called\nquantum forward-reverse bisimularity, that is, classical reversible computing\nand quantum reversible computing are unified.\n", "Comment: arXiv admin note: substantial text overlap with arXiv:1311.2960,\n  arXiv:1410.5131, arXiv:1312.0686, arXiv:1404.0665"]}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2015-01-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05260"}}, {"publisher": {"name": ""}, "description": "  Distributed Opportunistic Scheduling (DOS) is inherently harder than\nconventional opportunistic scheduling due to the absence of a central entity\nthat has knowledge of all the channel states. With DOS, stations contend for\nthe channel using random access; after a successful contention, they measure\nthe channel conditions and only transmit in case of a good channel, while\ngiving up the transmission opportunity when the channel conditions are poor.\nThe distributed nature of DOS systems makes them vulnerable to selfish users:\nby deviating from the protocol and using more transmission opportunities, a\nselfish user can gain a greater share of the wireless resources at the expense\nof the well-behaved users. In this paper, we address the selfishness problem in\nDOS from a game theoretic standpoint. We propose an algorithm that satisfies\nthe following properties: (i) when all stations implement the algorithm, the\nwireless network is driven to the optimal point of operation, and (ii) one or\nmore selfish stations cannot gain any profit by deviating from the algorithm.\nThe key idea of the algorithm is to react to a selfish station by using a more\naggressive configuration that (indirectly) punishes this station. We build on\nmultivariable control theory to design a mechanism for punishment that on the\none hand is sufficiently severe to prevent selfish behavior while on the other\nhand is light enough to guarantee that, in the absence of selfish behavior, the\nsystem is stable and converges to the optimum point of operation. We conduct a\ngame theoretic analysis based on repeated games to show the algorithm's\neffectiveness against selfish stations. These results are confirmed by\nextensive simulations.\n", "contributors": [{"name": "Banchs, Albert", "sameAs": [], "familyName": "Banchs", "additionalName": "", "givenName": "Albert", "email": ""}, {"name": "Garcia-Saavedra, Andres", "sameAs": [], "familyName": "Garcia-Saavedra", "additionalName": "", "givenName": "Andres", "email": ""}, {"name": "Serrano, Pablo", "sameAs": [], "familyName": "Serrano", "additionalName": "", "givenName": "Pablo", "email": ""}, {"name": "Widmer, Joerg", "sameAs": [], "familyName": "Widmer", "additionalName": "", "givenName": "Joerg", "email": ""}], "title": "A Game Theoretic Approach to Distributed Opportunistic Scheduling", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-07-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1107.4452", "oai:arXiv.org:1107.4452"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Distributed Opportunistic Scheduling (DOS) is inherently harder than\nconventional opportunistic scheduling due to the absence of a central entity\nthat has knowledge of all the channel states. With DOS, stations contend for\nthe channel using random access; after a successful contention, they measure\nthe channel conditions and only transmit in case of a good channel, while\ngiving up the transmission opportunity when the channel conditions are poor.\nThe distributed nature of DOS systems makes them vulnerable to selfish users:\nby deviating from the protocol and using more transmission opportunities, a\nselfish user can gain a greater share of the wireless resources at the expense\nof the well-behaved users. In this paper, we address the selfishness problem in\nDOS from a game theoretic standpoint. We propose an algorithm that satisfies\nthe following properties: (i) when all stations implement the algorithm, the\nwireless network is driven to the optimal point of operation, and (ii) one or\nmore selfish stations cannot gain any profit by deviating from the algorithm.\nThe key idea of the algorithm is to react to a selfish station by using a more\naggressive configuration that (indirectly) punishes this station. We build on\nmultivariable control theory to design a mechanism for punishment that on the\none hand is sufficiently severe to prevent selfish behavior while on the other\nhand is light enough to guarantee that, in the absence of selfish behavior, the\nsystem is stable and converges to the optimum point of operation. We conduct a\ngame theoretic analysis based on repeated games to show the algorithm's\neffectiveness against selfish stations. These results are confirmed by\nextensive simulations.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1107.4452"}}, {"publisher": {"name": ""}, "description": "  Security metrics serve as a powerful tool for organizations to understand the\neffectiveness of protecting computer networks. However majority of these\nmeasurement techniques don't adequately help corporations to make informed risk\nmanagement decisions. In this paper we present a stochastic security framework\nfor obtaining quantitative measures of security by taking into account the\ndynamic attributes associated with vulnerabilities that can change over time.\nOur model is novel as existing research in attack graph analysis do not\nconsider the temporal aspects associated with the vulnerabilities, such as the\navailability of exploits and patches which can affect the overall network\nsecurity based on how the vulnerabilities are interconnected and leveraged to\ncompromise the system. In order to have a more realistic representation of how\nthe security state of the network would vary over time, a nonhomogeneous model\nis developed which incorporates a time dependent covariate, namely the\nvulnerability age. The daily transition-probability matrices are estimated\nusing Frei's Vulnerability Lifecycle model. We also leverage the trusted CVSS\nmetric domain to analyze how the total exploitability and impact measures\nevolve over a time period for a given network.\n", "contributors": [{"name": "Abraham, Subil", "sameAs": [], "familyName": "Abraham", "additionalName": "", "givenName": "Subil", "email": ""}, {"name": "Nair, Suku", "sameAs": [], "familyName": "Nair", "additionalName": "", "givenName": "Suku", "email": ""}], "title": "A Predictive Framework for Cyber Security Analytics using Attack Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01240", "oai:arXiv.org:1502.01240"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Security metrics serve as a powerful tool for organizations to understand the\neffectiveness of protecting computer networks. However majority of these\nmeasurement techniques don't adequately help corporations to make informed risk\nmanagement decisions. In this paper we present a stochastic security framework\nfor obtaining quantitative measures of security by taking into account the\ndynamic attributes associated with vulnerabilities that can change over time.\nOur model is novel as existing research in attack graph analysis do not\nconsider the temporal aspects associated with the vulnerabilities, such as the\navailability of exploits and patches which can affect the overall network\nsecurity based on how the vulnerabilities are interconnected and leveraged to\ncompromise the system. In order to have a more realistic representation of how\nthe security state of the network would vary over time, a nonhomogeneous model\nis developed which incorporates a time dependent covariate, namely the\nvulnerability age. The daily transition-probability matrices are estimated\nusing Frei's Vulnerability Lifecycle model. We also leverage the trusted CVSS\nmetric domain to analyze how the total exploitability and impact measures\nevolve over a time period for a given network.\n", "Comment: 17 pages, 8 figures in International Journal of Computer Networks &\n  Communications (IJCNC) January 2015. ISSN:0974-9322 [Online]; 0975-2293\n  [Print]"]}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-02-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01240"}}, {"publisher": {"name": ""}, "description": "  Network control refers to a very large and diverse set of problems including\ncontrollability of linear time-invariant dynamical systems evolving over time\nthat have inputs and outputs. The network control problem in this setting is to\nselect the appropriate input to steer the network into a desired output state.\nExamples of the output state include the throughput of a communications\nnetwork, transcription factor concentration in a gene regulatory network,\ncustomer purchases in a marketing context subject to social influences and the\namount of flux flowing through a biochemical network.\n  We focus on control of linear dynamical systems under the notion of\nstructural controllability which is intimately connected to finding maximum\nmatchings. Hence, a natural objective is studying scalable and fast algorithms\nfor this task. We first show the convergence of matching algorithms for\ndifferent random networks and then analyze a popular, fast and practical\nheuristic due to Karp and Sipser. We establish the optimality of both the\nKarp-Sipser Algorithm as well as a simplification of it, and provide results\nconcerning the asymptotic size of maximum matchings for an extensive class of\nrandom networks.\n", "contributors": [{"name": "Faradonbeh, Mohamad Kazem Shirani", "sameAs": [], "familyName": "Faradonbeh", "additionalName": "Kazem Shirani", "givenName": "Mohamad", "email": ""}, {"name": "Tewari, Ambuj", "sameAs": [], "familyName": "Tewari", "additionalName": "", "givenName": "Ambuj", "email": ""}, {"name": "Michailidis, George", "sameAs": [], "familyName": "Michailidis", "additionalName": "", "givenName": "George", "email": ""}], "title": "Optimality of Fast Matching Algorithms for Random Networks with\n  Applications to Structural Controllability", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08019", "oai:arXiv.org:1503.08019"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  Network control refers to a very large and diverse set of problems including\ncontrollability of linear time-invariant dynamical systems evolving over time\nthat have inputs and outputs. The network control problem in this setting is to\nselect the appropriate input to steer the network into a desired output state.\nExamples of the output state include the throughput of a communications\nnetwork, transcription factor concentration in a gene regulatory network,\ncustomer purchases in a marketing context subject to social influences and the\namount of flux flowing through a biochemical network.\n  We focus on control of linear dynamical systems under the notion of\nstructural controllability which is intimately connected to finding maximum\nmatchings. Hence, a natural objective is studying scalable and fast algorithms\nfor this task. We first show the convergence of matching algorithms for\ndifferent random networks and then analyze a popular, fast and practical\nheuristic due to Karp and Sipser. We establish the optimality of both the\nKarp-Sipser Algorithm as well as a simplification of it, and provide results\nconcerning the asymptotic size of maximum matchings for an extensive class of\nrandom networks.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - systems and control", "statistics - other statistics"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08019"}}, {"publisher": {"name": "American Diabetes Association"}, "description": "", "contributors": [{"name": "D\u2019Addio, Francesca", "sameAs": [], "familyName": "D\u2019Addio", "additionalName": "", "givenName": "Francesca", "email": ""}, {"name": "Maffi, Paola", "sameAs": [], "familyName": "Maffi", "additionalName": "", "givenName": "Paola", "email": ""}, {"name": "Vezzulli, Paolo", "sameAs": [], "familyName": "Vezzulli", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Vergani, Andrea", "sameAs": [], "familyName": "Vergani", "additionalName": "", "givenName": "Andrea", "email": ""}, {"name": "Mello, Alessandra", "sameAs": [], "familyName": "Mello", "additionalName": "", "givenName": "Alessandra", "email": ""}, {"name": "Bassi, Roberto", "sameAs": [], "familyName": "Bassi", "additionalName": "", "givenName": "Roberto", "email": ""}, {"name": "Nano, Rita", "sameAs": [], "familyName": "Nano", "additionalName": "", "givenName": "Rita", "email": ""}, {"name": "Falautano, Monica", "sameAs": [], "familyName": "Falautano", "additionalName": "", "givenName": "Monica", "email": ""}, {"name": "Coppi, Elisabetta", "sameAs": [], "familyName": "Coppi", "additionalName": "", "givenName": "Elisabetta", "email": ""}, {"name": "Finzi, Giovanna", "sameAs": [], "familyName": "Finzi", "additionalName": "", "givenName": "Giovanna", "email": ""}, {"name": "D\u2019Angelo, Armando", "sameAs": [], "familyName": "D\u2019Angelo", "additionalName": "", "givenName": "Armando", "email": ""}, {"name": "Fermo, Isabella", "sameAs": [], "familyName": "Fermo", "additionalName": "", "givenName": "Isabella", "email": ""}, {"name": "Pellegatta, Fabio", "sameAs": [], "familyName": "Pellegatta", "additionalName": "", "givenName": "Fabio", "email": ""}, {"name": "La Rosa, Stefano", "sameAs": [], "familyName": "La Rosa", "additionalName": "", "givenName": "Stefano", "email": ""}, {"name": "Magnani, Giuseppe", "sameAs": [], "familyName": "Magnani", "additionalName": "", "givenName": "Giuseppe", "email": ""}, {"name": "Piemonti, Lorenzo", "sameAs": [], "familyName": "Piemonti", "additionalName": "", "givenName": "Lorenzo", "email": ""}, {"name": "Falini, Andrea", "sameAs": [], "familyName": "Falini", "additionalName": "", "givenName": "Andrea", "email": ""}, {"name": "Folli, Franco", "sameAs": [], "familyName": "Folli", "additionalName": "", "givenName": "Franco", "email": ""}, {"name": "Secchi, Antonio", "sameAs": [], "familyName": "Secchi", "additionalName": "", "givenName": "Antonio", "email": ""}, {"name": "Fiorina, Paolo", "sameAs": [], "familyName": "Fiorina", "additionalName": "", "givenName": "Paolo", "email": ""}], "title": "Islet Transplantation Stabilizes Hemostatic Abnormalities and Cerebral Metabolism in Individuals With Type 1 Diabetes", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["pathophysiology/complications"], "providerUpdatedDateTime": "2015-01-01T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3867995"}}, {"publisher": {"name": ""}, "description": "  The goal of this survey is to present various results concerning the\ncohomology of pseudoeffective line bundles on compact K{\\\"a}hler manifolds, and\nrelated properties of their multiplier ideal sheaves. In case the curvature is\nstrictly positive, the prototype is the well known Nadel vanishing theorem,\nwhich is itself a generalized analytic version of the fundamental\nKawamata-Viehweg vanishing theorem of algebraic geometry. We are interested\nhere in the case where the curvature is merely semipositive in the sense of\ncurrents, and the base manifold is not necessarily projective. In this\nsituation, one can still obtain interesting information on cohomology, e.g. a\nHard Lefschetz theorem with pseudoeffective coefficients, in the form of a\nsurjectivity statement for the Lefschetz map. More recently, Junyan Cao, in his\nPhD thesis defended in Grenoble, obtained a general K{\\\"a}hler vanishing\ntheorem that depends on the concept of numerical dimension of a given\npseudoeffective line bundle. The proof of these results depends in a crucial\nway on a general approximation result for closed (1,1)-currents, based on the\nuse of Bergman kernels, and the related intersection theory of currents.\nAnother important ingredient is the recent proof by Guan and Zhou of the strong\nopenness conjecture. As an application, we discuss a structure theorem for\ncompact K{\\\"a}hler threefolds without nontrivial subvarieties, following a\njoint work with F.Campana and M.Verbitsky. We hope that these notes will serve\nas a useful guide to the more detailed and more technical papers in the\nliterature; in some cases, we provide here substantially simplified proofs and\nunifying viewpoints.\n", "contributors": [{"name": "Demailly, Jean-Pierre", "sameAs": [], "familyName": "Demailly", "additionalName": "", "givenName": "Jean-Pierre", "email": ""}], "title": "On the cohomology of pseudoeffective line bundles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-01-21", "2015-01-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1401.5432", "oai:arXiv.org:1401.5432"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The goal of this survey is to present various results concerning the\ncohomology of pseudoeffective line bundles on compact K{\\\"a}hler manifolds, and\nrelated properties of their multiplier ideal sheaves. In case the curvature is\nstrictly positive, the prototype is the well known Nadel vanishing theorem,\nwhich is itself a generalized analytic version of the fundamental\nKawamata-Viehweg vanishing theorem of algebraic geometry. We are interested\nhere in the case where the curvature is merely semipositive in the sense of\ncurrents, and the base manifold is not necessarily projective. In this\nsituation, one can still obtain interesting information on cohomology, e.g. a\nHard Lefschetz theorem with pseudoeffective coefficients, in the form of a\nsurjectivity statement for the Lefschetz map. More recently, Junyan Cao, in his\nPhD thesis defended in Grenoble, obtained a general K{\\\"a}hler vanishing\ntheorem that depends on the concept of numerical dimension of a given\npseudoeffective line bundle. The proof of these results depends in a crucial\nway on a general approximation result for closed (1,1)-currents, based on the\nuse of Bergman kernels, and the related intersection theory of currents.\nAnother important ingredient is the recent proof by Guan and Zhou of the strong\nopenness conjecture. As an application, we discuss a structure theorem for\ncompact K{\\\"a}hler threefolds without nontrivial subvarieties, following a\njoint work with F.Campana and M.Verbitsky. We hope that these notes will serve\nas a useful guide to the more detailed and more technical papers in the\nliterature; in some cases, we provide here substantially simplified proofs and\nunifying viewpoints.\n", "Comment: 39 pages. This survey is a written account of a lecture given at the\n  Abel Symposium, Trondheim, July 2013"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1401.5432"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "It is important for companies to manage their revenues and -reduce their costs efficiently. These goals can be achieved through effective pricing and inventory control strategies. This thesis studies a joint multi-period pricing and inventory control problem for a make-to-stock manufacturing system. Multiple products are produced under shared production capacity over a finite time horizon. The demand for each product is a function of the prices and no back orders are allowed. Inventory and production costs are linear functions of the levels of inventory and production, respectively. In this thesis, we introduce an iterative gradient-based algorithm. A key idea is that given a demand realization, the cost minimization part of the problem becomes a linear transportation problem. Given this idea, if we knew the optimal demand, we could solve the production problem efficiently. At each iteration of the algorithm, given a demand vector we solve a linear transportation problem and use its dual variables in order to solve a quadratic optimization problem that optimizes the revenue part and generates a new pricing policy. We illustrate computationally that this algorithm obtains the optimal production and pricing policy over the finite time horizon efficiently. The computational experiments in this thesis use a wide range of simulated data. The results show that the algorithm we study in this thesis indeed computes the optimal solution for the joint pricing and inventory control problem and is efficient as compared to solving a reformulation of the problem directly using commercial software. The algorithm proposed in this thesis solves large scale problems and can handle a wide range of nonlinear demand functions.", "contributors": [{"name": "Rao, Tingting", "sameAs": [], "familyName": "Rao", "additionalName": "", "givenName": "Tingting", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "Retsef Levi and Georgia Perakis.", "sameAs": [], "familyName": "Perakis.", "additionalName": "Levi and Georgia", "givenName": "Retsef", "email": ""}], "title": "LP-based subgradient algorithm for joint pricing and inventory control problems", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "94 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/45282", "311815436", "oai:dspace.mit.edu:1721.1/45282"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2009-04-29T17:20:09Z", "2009-04-29T17:20:09Z", "2008", "2008"]}}, {"name": "description", "properties": {"description": ["It is important for companies to manage their revenues and -reduce their costs efficiently. These goals can be achieved through effective pricing and inventory control strategies. This thesis studies a joint multi-period pricing and inventory control problem for a make-to-stock manufacturing system. Multiple products are produced under shared production capacity over a finite time horizon. The demand for each product is a function of the prices and no back orders are allowed. Inventory and production costs are linear functions of the levels of inventory and production, respectively. In this thesis, we introduce an iterative gradient-based algorithm. A key idea is that given a demand realization, the cost minimization part of the problem becomes a linear transportation problem. Given this idea, if we knew the optimal demand, we could solve the production problem efficiently. At each iteration of the algorithm, given a demand vector we solve a linear transportation problem and use its dual variables in order to solve a quadratic optimization problem that optimizes the revenue part and generates a new pricing policy. We illustrate computationally that this algorithm obtains the optimal production and pricing policy over the finite time horizon efficiently. The computational experiments in this thesis use a wide range of simulated data. The results show that the algorithm we study in this thesis indeed computes the optimal solution for the joint pricing and inventory control problem and is efficient as compared to solving a reformulation of the problem directly using commercial software. The algorithm proposed in this thesis solves large scale problems and can handle a wide range of nonlinear demand functions.", "by Tingting Rao.", "Thesis (S.M.)--Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2008.", "Includes bibliographical references (p. 93-94)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39115", "hdl_1721.1_39117"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:17", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/45282"}}, {"publisher": {"name": ""}, "description": "  We study the fundamental algorithmic rigidity problems for generic frameworks\nperiodic with respect to a fixed lattice or a finite-order rotation in the\nplane. For fixed-lattice frameworks we give an $O(n^2)$ algorithm for deciding\ngeneric rigidity and an O(n^3) algorithm for computing rigid components. If the\norder of rotation is part of the input, we give an O(n^4) algorithm for\ndeciding rigidity; in the case where the rotation's order is 3, a more\nspecialized algorithm solves all the fundamental algorithmic rigidity problems\nin O(n^2) time.\n", "contributors": [{"name": "Berardi, Matthew", "sameAs": [], "familyName": "Berardi", "additionalName": "", "givenName": "Matthew", "email": ""}, {"name": "Heeringa, Brent", "sameAs": [], "familyName": "Heeringa", "additionalName": "", "givenName": "Brent", "email": ""}, {"name": "Malestein, Justin", "sameAs": [], "familyName": "Malestein", "additionalName": "", "givenName": "Justin", "email": ""}, {"name": "Theran, Louis", "sameAs": [], "familyName": "Theran", "additionalName": "", "givenName": "Louis", "email": ""}], "title": "Rigid components in fixed-lattice and cone frameworks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.3234", "oai:arXiv.org:1105.3234"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We study the fundamental algorithmic rigidity problems for generic frameworks\nperiodic with respect to a fixed lattice or a finite-order rotation in the\nplane. For fixed-lattice frameworks we give an $O(n^2)$ algorithm for deciding\ngeneric rigidity and an O(n^3) algorithm for computing rigid components. If the\norder of rotation is part of the input, we give an O(n^4) algorithm for\ndeciding rigidity; in the case where the rotation's order is 3, a more\nspecialized algorithm solves all the fundamental algorithmic rigidity problems\nin O(n^2) time.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.3234"}}, {"publisher": {"name": ""}, "description": "  Spreadsheets are widely used within companies and often form the basis for\nbusiness decisions. Numerous cases are known where incorrect information in\nspreadsheets has lead to incorrect decisions. Such cases underline the\nrelevance of research on the professional use of spreadsheets.\n  Recently a new dataset became available for research, containing over 15.000\nbusiness spreadsheets that were extracted from the Enron E-mail Archive. With\nthis dataset, we 1) aim to obtain a thorough understanding of the\ncharacteristics of spreadsheets used within companies, and 2) compare the\ncharacteristics of the Enron spreadsheets with the EUSES corpus which is the\nexisting state of the art set of spreadsheets that is frequently used in\nspreadsheet studies.\n  Our analysis shows that 1) the majority of spreadsheets are not large in\nterms of worksheets and formulas, do not have a high degree of coupling, and\ntheir formulas are relatively simple; 2) the spreadsheets from the EUSES corpus\nare, with respect to the measured characteristics, quite similar to the Enron\nspreadsheets.\n", "contributors": [{"name": "Jansen, Bas", "sameAs": [], "familyName": "Jansen", "additionalName": "", "givenName": "Bas", "email": ""}], "title": "Enron versus EUSES: A Comparison of Two Spreadsheet Corpora", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04055", "oai:arXiv.org:1503.04055"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Spreadsheets are widely used within companies and often form the basis for\nbusiness decisions. Numerous cases are known where incorrect information in\nspreadsheets has lead to incorrect decisions. Such cases underline the\nrelevance of research on the professional use of spreadsheets.\n  Recently a new dataset became available for research, containing over 15.000\nbusiness spreadsheets that were extracted from the Enron E-mail Archive. With\nthis dataset, we 1) aim to obtain a thorough understanding of the\ncharacteristics of spreadsheets used within companies, and 2) compare the\ncharacteristics of the Enron spreadsheets with the EUSES corpus which is the\nexisting state of the art set of spreadsheets that is frequently used in\nspreadsheet studies.\n  Our analysis shows that 1) the majority of spreadsheets are not large in\nterms of worksheets and formulas, do not have a high degree of coupling, and\ntheir formulas are relatively simple; 2) the spreadsheets from the EUSES corpus\nare, with respect to the measured characteristics, quite similar to the Enron\nspreadsheets.\n", "Comment: In Proceedings of the 2nd Workshop on Software Engineering Methods in\n  Spreadsheets"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-03-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04055"}}, {"publisher": {"name": ""}, "description": "  In this paper we study the automorphism groups of real curves admitting a\nregular meromorphic function $f$ of degree $p$, so called real cyclic $p$-gonal\ncurves. When $p=2$ the automorphism groups of real hyperelliptic curves where\ngiven by Bujalance et al. in \\cite{BCGG}.\n", "contributors": [{"name": "Izquierdo, Milagros", "sameAs": [], "familyName": "Izquierdo", "additionalName": "", "givenName": "Milagros", "email": ""}, {"name": "Shaska, Tony", "sameAs": [], "familyName": "Shaska", "additionalName": "", "givenName": "Tony", "email": ""}], "title": "Cyclic curves over the reals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.01559", "oai:arXiv.org:1501.01559"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  In this paper we study the automorphism groups of real curves admitting a\nregular meromorphic function $f$ of degree $p$, so called real cyclic $p$-gonal\ncurves. When $p=2$ the automorphism groups of real hyperelliptic curves where\ngiven by Bujalance et al. in \\cite{BCGG}.\n", "Comment: NATO Advanced Study Institute, 2014, Ohrid, Macedonia"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.01559"}}, {"publisher": {"name": ""}, "description": "  The wiretap channel models secure communication of two users in the presence\nof a non-legitimate eavesdropper who must be kept ignorant of transmitted\nmessages. The performance of such a system is usually characterized by its\nsecrecy capacity determining the maximum transmission rate of secure\ncommunication. In this paper, the issue of whether the secrecy capacity is a\ncontinuous function of the system parameters or not is examined. In particular,\nthis is done for channel uncertainty modeled via compound channels and\narbitrarily varying channels, in which the legitimate users know only that the\ntrue channel realization is from a pre-specified uncertainty set. In the former\nmodel, this realization remains constant for the whole duration of\ntransmission, while in the latter the realization varies from channel use to\nchannel use in an unknown and arbitrary manner. These models not only capture\nthe case of channel uncertainty, but are also suitable to model scenarios in\nwhich a malicious adversary influences or jams the legitimate transmission. The\nsecrecy capacity of the compound wiretap channel is shown to be robust in the\nsense that it is a continuous function of the uncertainty set. Thus, small\nvariations in the uncertainty set lead to small variations in secrecy capacity.\nOn the other hand, the deterministic secrecy capacity of the arbitrarily\nvarying wiretap channel is shown to be discontinuous in the uncertainty set\nmeaning that small variations can lead to dramatic losses in capacity.\n", "contributors": [{"name": "Boche, Holger", "sameAs": [], "familyName": "Boche", "additionalName": "", "givenName": "Holger", "email": ""}, {"name": "Schaefer, Rafael F.", "sameAs": [], "familyName": "Schaefer", "additionalName": "F.", "givenName": "Rafael", "email": ""}, {"name": "Poor, H. Vincent", "sameAs": [], "familyName": "Poor", "additionalName": "Vincent", "givenName": "H.", "email": ""}], "title": "On the Continuity of the Secrecy Capacity of Compound and Arbitrarily\n  Varying Wiretap Channels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-16", "2015-03-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.4752", "oai:arXiv.org:1409.4752"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The wiretap channel models secure communication of two users in the presence\nof a non-legitimate eavesdropper who must be kept ignorant of transmitted\nmessages. The performance of such a system is usually characterized by its\nsecrecy capacity determining the maximum transmission rate of secure\ncommunication. In this paper, the issue of whether the secrecy capacity is a\ncontinuous function of the system parameters or not is examined. In particular,\nthis is done for channel uncertainty modeled via compound channels and\narbitrarily varying channels, in which the legitimate users know only that the\ntrue channel realization is from a pre-specified uncertainty set. In the former\nmodel, this realization remains constant for the whole duration of\ntransmission, while in the latter the realization varies from channel use to\nchannel use in an unknown and arbitrary manner. These models not only capture\nthe case of channel uncertainty, but are also suitable to model scenarios in\nwhich a malicious adversary influences or jams the legitimate transmission. The\nsecrecy capacity of the compound wiretap channel is shown to be robust in the\nsense that it is a continuous function of the uncertainty set. Thus, small\nvariations in the uncertainty set lead to small variations in secrecy capacity.\nOn the other hand, the deterministic secrecy capacity of the arbitrarily\nvarying wiretap channel is shown to be discontinuous in the uncertainty set\nmeaning that small variations can lead to dramatic losses in capacity.\n", "Comment: revised. Section VI added"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.4752"}}, {"publisher": {"name": ""}, "description": "  The water uptake by roots of plants is examined for an ideal situation, with\nan approximation that resembles plants growing in pots, meaning that the total\nsoil volume is fixed. We propose a coupled water uptake-root growth model. A\none-dimensional model for water flux and water uptake by a root system growing\nuniformly distributed in the soil is presented, and the Van Genuchten model for\nthe transport of water in soil is used. The governing equations are represented\nby a moving boundary model for which the root length, as a function of time, is\nprescribed. The solution of the model is obtained by front-fixing and finite\nelement methods. Model predictions for water uptake by a same plant growing in\nloam, silt and clay soils are obtained and compared. A sensitivity analysis to\ndetermine relative effects on water uptake when system parameters are changed\nis also presented and shows that the model and numerical method proposed are\nmore sensitive to the root growth rate than to the rest of the parameters. This\nsensitivity decreases along time, reaching its maximum at thirty days. A\ncomparison of this model with a fixed boundary model with and without root\ngrowth is also made. The results show qualitative differences from the\nbeginning of the simulations, and quantitative differences after ten days of\nsimulations.\n", "contributors": [{"name": "Albrieu, J. L. Blengino", "sameAs": [], "familyName": "Albrieu", "additionalName": "L. Blengino", "givenName": "J.", "email": ""}, {"name": "Reginato, J. C.", "sameAs": [], "familyName": "Reginato", "additionalName": "C.", "givenName": "J.", "email": ""}, {"name": "Tarzia, D. A.", "sameAs": [], "familyName": "Tarzia", "additionalName": "A.", "givenName": "D.", "email": ""}], "title": "Modeling water uptake by a root system growing in a fixed soil volume", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03331", "doi:10.1016/j.apm.2014.11.042", "oai:arXiv.org:1503.03331"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:physics", "q-bio"]}}, {"name": "description", "properties": {"description": ["  The water uptake by roots of plants is examined for an ideal situation, with\nan approximation that resembles plants growing in pots, meaning that the total\nsoil volume is fixed. We propose a coupled water uptake-root growth model. A\none-dimensional model for water flux and water uptake by a root system growing\nuniformly distributed in the soil is presented, and the Van Genuchten model for\nthe transport of water in soil is used. The governing equations are represented\nby a moving boundary model for which the root length, as a function of time, is\nprescribed. The solution of the model is obtained by front-fixing and finite\nelement methods. Model predictions for water uptake by a same plant growing in\nloam, silt and clay soils are obtained and compared. A sensitivity analysis to\ndetermine relative effects on water uptake when system parameters are changed\nis also presented and shows that the model and numerical method proposed are\nmore sensitive to the root growth rate than to the rest of the parameters. This\nsensitivity decreases along time, reaching its maximum at thirty days. A\ncomparison of this model with a fixed boundary model with and without root\ngrowth is also made. The results show qualitative differences from the\nbeginning of the simulations, and quantitative differences after ten days of\nsimulations.\n", "Comment: To Appear in Applied mathematical modelling 23 pages, 10 figures"]}}], "languages": [null], "subjects": ["35r37", "35q92", "physics - biological physics", "76505", "quantitative biology - tissues and organs", "physics - computational physics", "65m60"], "providerUpdatedDateTime": "2015-03-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03331"}}, {"publisher": {"name": ""}, "description": "  This paper investigates the role of factorial speech processing models in\nnoise-robust automatic speech recognition tasks. Factorial models can embed\nnon-stationary noise models using Markov chains as one of its source chain. The\npaper proposes a modeling scheme for modeling state-conditional observation\ndistribution of factorial models based on weighted stereo samples. This scheme\nis an extension to previous single pass retraining for ideal model compensation\nand here we used it to construct ideal state-conditional observation\ndistributions. Experiments of this paper over the set A of the Aurora 2 dataset\nshows that by considering noise models with multiple states, system performance\ncan be improved especially in low SNR conditions up to 4% absolute word\nrecognition performance. In addition to its power in accurate representation of\nstate-conditional observation distribution, it has an important advantage over\nprevious methods by providing the opportunity to independently select feature\nspaces for both source and corrupted features. This opens a new window for\nseeking better feature spaces appropriate for noise-robust tasks independent\nfrom clean speech feature space.\n", "contributors": [{"name": "Khademian, Mahdi", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Khademian", "email": ""}, {"name": "Homayounpour, Mohammad Mehdi", "sameAs": [], "familyName": "Homayounpour", "additionalName": "Mehdi", "givenName": "Mohammad", "email": ""}], "title": "Modeling State-Conditional Observation Distribution using Weighted\n  Stereo Samples for Factorial Speech Processing Models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02578", "oai:arXiv.org:1503.02578"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper investigates the role of factorial speech processing models in\nnoise-robust automatic speech recognition tasks. Factorial models can embed\nnon-stationary noise models using Markov chains as one of its source chain. The\npaper proposes a modeling scheme for modeling state-conditional observation\ndistribution of factorial models based on weighted stereo samples. This scheme\nis an extension to previous single pass retraining for ideal model compensation\nand here we used it to construct ideal state-conditional observation\ndistributions. Experiments of this paper over the set A of the Aurora 2 dataset\nshows that by considering noise models with multiple states, system performance\ncan be improved especially in low SNR conditions up to 4% absolute word\nrecognition performance. In addition to its power in accurate representation of\nstate-conditional observation distribution, it has an important advantage over\nprevious methods by providing the opportunity to independently select feature\nspaces for both source and corrupted features. This opens a new window for\nseeking better feature spaces appropriate for noise-robust tasks independent\nfrom clean speech feature space.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - learning", "computer science - sound"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02578"}}, {"publisher": {"name": ""}, "description": "  The flow field and the heat transfer around six in-line iso-thermal circular\ncylinders has been studied by mean of numerical simulations. Two values of the\ncenter to center spacing ($s=3.6d$ and $4d$, where $d$ is the cylinder\ndiameter) at Reynolds number of $100$ and Prandtl number of $0.7$ has been\ninvestigated. Similarly to the in-line two cylinder configuration, in this\nrange a transition in the flow and in the heat transfer occurs. Two different\nflow patterns have been identified: the stable shear layer (SSL) mode and the\nshear layer secondary vortices (SLSV) mode, at $3.6$ and $4$ spacing ratio\n($s/d$), respectively. At $s/d=3.6$ the flow pattern causes the entrainment of\ncold fluid on the downstream cylinders enhancing the heat transfer. On the\nother hand at $s/d=4$ two stable opposite shear layer prevent the cold fluid\nentrainment over the downstream cylinders reducing their heat exchange. The\noverall time average heat transfer of the array is enhanced up to 25%\ndecreasing the spacing ratio from $4$ to $3.6$. Furthermore, it is found that\nthe increased heat transfer is related to the phase shift between the Nusselt\ntime series of successive cylinders.\n", "contributors": [{"name": "Fornarelli, Francesco", "sameAs": [], "familyName": "Fornarelli", "additionalName": "", "givenName": "Francesco", "email": ""}, {"name": "Oresta, Paolo", "sameAs": [], "familyName": "Oresta", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Lippolis, Antonio", "sameAs": [], "familyName": "Lippolis", "additionalName": "", "givenName": "Antonio", "email": ""}], "title": "Flow patterns and heat transfer around six in-line circular cylinders at\n  low Reynolds number", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5836", "oai:arXiv.org:1410.5836"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": ["  The flow field and the heat transfer around six in-line iso-thermal circular\ncylinders has been studied by mean of numerical simulations. Two values of the\ncenter to center spacing ($s=3.6d$ and $4d$, where $d$ is the cylinder\ndiameter) at Reynolds number of $100$ and Prandtl number of $0.7$ has been\ninvestigated. Similarly to the in-line two cylinder configuration, in this\nrange a transition in the flow and in the heat transfer occurs. Two different\nflow patterns have been identified: the stable shear layer (SSL) mode and the\nshear layer secondary vortices (SLSV) mode, at $3.6$ and $4$ spacing ratio\n($s/d$), respectively. At $s/d=3.6$ the flow pattern causes the entrainment of\ncold fluid on the downstream cylinders enhancing the heat transfer. On the\nother hand at $s/d=4$ two stable opposite shear layer prevent the cold fluid\nentrainment over the downstream cylinders reducing their heat exchange. The\noverall time average heat transfer of the array is enhanced up to 25%\ndecreasing the spacing ratio from $4$ to $3.6$. Furthermore, it is found that\nthe increased heat transfer is related to the phase shift between the Nusselt\ntime series of successive cylinders.\n", "Comment: Accepted by JP Journal of Heat and Mass Transfer (2015)"]}}], "languages": [null], "subjects": ["physics - computational physics", "physics - fluid dynamics"], "providerUpdatedDateTime": "2014-10-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5836"}}, {"publisher": {"name": ""}, "description": "  This paper looks into the problem of pedestrian tracking using a monocular,\npotentially moving, uncalibrated camera. The pedestrians are located in each\nframe using a standard human detector, which are then tracked in subsequent\nframes. This is a challenging problem as one has to deal with complex\nsituations like changing background, partial or full occlusion and camera\nmotion. In order to carry out successful tracking, it is necessary to resolve\nassociations between the detected windows in the current frame with those\nobtained from the previous frame. Compared to methods that use temporal windows\nincorporating past as well as future information, we attempt to make decision\non a frame-by-frame basis. An occlusion reasoning scheme is proposed to resolve\nthe association problem between a pair of consecutive frames by using an\naffinity matrix that defines the closeness between a pair of windows and then,\nuses a binary integer programming to obtain unique association between them. A\nsecond stage of verification based on SURF matching is used to deal with those\ncases where the above optimization scheme might yield wrong associations. The\nefficacy of the approach is demonstrated through experiments on several\nstandard pedestrian datasets.\n", "contributors": [{"name": "Garg, Sourav", "sameAs": [], "familyName": "Garg", "additionalName": "", "givenName": "Sourav", "email": ""}, {"name": "Kumar, Swagat", "sameAs": [], "familyName": "Kumar", "additionalName": "", "givenName": "Swagat", "email": ""}, {"name": "Ratnakaram, Rajesh", "sameAs": [], "familyName": "Ratnakaram", "additionalName": "", "givenName": "Rajesh", "email": ""}, {"name": "Guha, Prithwijit", "sameAs": [], "familyName": "Guha", "additionalName": "", "givenName": "Prithwijit", "email": ""}], "title": "An Occlusion Reasoning Scheme for Monocular Pedestrian Tracking in\n  Dynamic Scenes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06129", "oai:arXiv.org:1501.06129"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper looks into the problem of pedestrian tracking using a monocular,\npotentially moving, uncalibrated camera. The pedestrians are located in each\nframe using a standard human detector, which are then tracked in subsequent\nframes. This is a challenging problem as one has to deal with complex\nsituations like changing background, partial or full occlusion and camera\nmotion. In order to carry out successful tracking, it is necessary to resolve\nassociations between the detected windows in the current frame with those\nobtained from the previous frame. Compared to methods that use temporal windows\nincorporating past as well as future information, we attempt to make decision\non a frame-by-frame basis. An occlusion reasoning scheme is proposed to resolve\nthe association problem between a pair of consecutive frames by using an\naffinity matrix that defines the closeness between a pair of windows and then,\nuses a binary integer programming to obtain unique association between them. A\nsecond stage of verification based on SURF matching is used to deal with those\ncases where the above optimization scheme might yield wrong associations. The\nefficacy of the approach is demonstrated through experiments on several\nstandard pedestrian datasets.\n", "Comment: 8 pages"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06129"}}, {"publisher": {"name": ""}, "description": "  We study the problem of distributed coverage control in a network of mobile\nagents arranged on a line. The goal is to design distributed dynamics for the\nagents to achieve optimal coverage positions with respect to a scalar density\nfield that measures the relative importance of each point on the line. Unlike\nprevious work, which has implicitly assumed the agents know this density field,\nwe only assume that each agent can access noisy samples of the field at points\nclose to its current location. We provide a simple randomized protocol wherein\nevery agent samples the scalar field at three nearby points at each step and\nwhich guarantees convergence to the optimal positions. We further analyze the\nconvergence time of this protocol and show that, under suitable assumptions,\nthe squared distance to the optimal coverage configuration decays as $O(1/t)$\nwith the number of iterations $t$, where the constant scales polynomially with\nthe number of agents $n$. We illustrate these results with simulations.\n", "contributors": [{"name": "Davison, P.", "sameAs": [], "familyName": "Davison", "additionalName": "", "givenName": "P.", "email": ""}, {"name": "Leonard, N. E.", "sameAs": [], "familyName": "Leonard", "additionalName": "E.", "givenName": "N.", "email": ""}, {"name": "Olshevsky, A.", "sameAs": [], "familyName": "Olshevsky", "additionalName": "", "givenName": "A.", "email": ""}, {"name": "Schwemmer, M.", "sameAs": [], "familyName": "Schwemmer", "additionalName": "", "givenName": "M.", "email": ""}], "title": "Nonuniform Line Coverage from Noisy Scalar Measurements", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-15", "2014-11-21"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.4188", "oai:arXiv.org:1310.4188"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We study the problem of distributed coverage control in a network of mobile\nagents arranged on a line. The goal is to design distributed dynamics for the\nagents to achieve optimal coverage positions with respect to a scalar density\nfield that measures the relative importance of each point on the line. Unlike\nprevious work, which has implicitly assumed the agents know this density field,\nwe only assume that each agent can access noisy samples of the field at points\nclose to its current location. We provide a simple randomized protocol wherein\nevery agent samples the scalar field at three nearby points at each step and\nwhich guarantees convergence to the optimal positions. We further analyze the\nconvergence time of this protocol and show that, under suitable assumptions,\nthe squared distance to the optimal coverage configuration decays as $O(1/t)$\nwith the number of iterations $t$, where the constant scales polynomially with\nthe number of agents $n$. We illustrate these results with simulations.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - systems and control"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.4188"}}, {"publisher": {"name": ""}, "description": "  Generic matrix multiplication (GEMM) and one-dimensional\nconvolution/cross-correlation (CONV) kernels often constitute the bulk of the\ncompute- and memory-intensive processing within image/audio recognition and\nmatching systems. We propose a novel method to scale the energy and processing\nthroughput of GEMM and CONV kernels for such error-tolerant multimedia\napplications by adjusting the precision of computation. Our technique employs\nlinear projections to the input matrix or signal data during the top-level GEMM\nand CONV blocking and reordering. The GEMM and CONV kernel processing then uses\nthe projected inputs and the results are accumulated to form the final outputs.\nThroughput and energy scaling takes place by changing the number of projections\ncomputed by each kernel, which in turn produces approximate results, i.e.\nchanges the precision of the performed computation. Results derived from a\nvoltage- and frequency-scaled ARM Cortex A15 processor running face recognition\nand music matching algorithms demonstrate that the proposed approach allows for\n280%~440% increase of processing throughput and 75%~80% decrease of energy\nconsumption against optimized GEMM and CONV kernels without any impact in the\nobtained recognition or matching accuracy. Even higher gains can be obtained if\none is willing to tolerate some reduction in the accuracy of the recognition\nand matching applications.\n", "contributors": [{"name": "Anam, Mohammad Ashraful", "sameAs": [], "familyName": "Anam", "additionalName": "Ashraful", "givenName": "Mohammad", "email": ""}, {"name": "Whatmough, Paul N.", "sameAs": [], "familyName": "Whatmough", "additionalName": "N.", "givenName": "Paul", "email": ""}, {"name": "Andreopoulos, Yiannis", "sameAs": [], "familyName": "Andreopoulos", "additionalName": "", "givenName": "Yiannis", "email": ""}], "title": "Precision-Energy-Throughput Scaling Of Generic Matrix Multiplication and\n  Convolution Kernels Via Linear Projections", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2860", "IEEE Transactions on Circuits and Systems for Video Technology,\n  vol. 24, no. 11, pp. 1860-1873, Nov. 2014", "oai:arXiv.org:1411.2860"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Generic matrix multiplication (GEMM) and one-dimensional\nconvolution/cross-correlation (CONV) kernels often constitute the bulk of the\ncompute- and memory-intensive processing within image/audio recognition and\nmatching systems. We propose a novel method to scale the energy and processing\nthroughput of GEMM and CONV kernels for such error-tolerant multimedia\napplications by adjusting the precision of computation. Our technique employs\nlinear projections to the input matrix or signal data during the top-level GEMM\nand CONV blocking and reordering. The GEMM and CONV kernel processing then uses\nthe projected inputs and the results are accumulated to form the final outputs.\nThroughput and energy scaling takes place by changing the number of projections\ncomputed by each kernel, which in turn produces approximate results, i.e.\nchanges the precision of the performed computation. Results derived from a\nvoltage- and frequency-scaled ARM Cortex A15 processor running face recognition\nand music matching algorithms demonstrate that the proposed approach allows for\n280%~440% increase of processing throughput and 75%~80% decrease of energy\nconsumption against optimized GEMM and CONV kernels without any impact in the\nobtained recognition or matching accuracy. Even higher gains can be obtained if\none is willing to tolerate some reduction in the accuracy of the recognition\nand matching applications.\n"}}], "languages": [null], "subjects": ["computer science - mathematical software", "computer science - multimedia"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2860"}}, {"publisher": {"name": ""}, "description": "  We focus on designing combinatorial algorithms for the Capacitated Network\nDesign problem (Cap-SNDP). The Cap-SNDP is the problem of satisfying\nconnectivity requirements when edges have costs and hard capacities. We begin\nby showing that the Group Steiner tree problem (GST) is a special case of\nCap-SNDP even when there is connectivity requirement between only one\nsource-sink pair. This implies the first poly-logarithmic lower bound for the\nCap-SNDP. We next provide combinatorial algorithms for several special cases of\nthis problem. The Cap-SNDP is equivalent to its special case when every edge\nhas either zero cost or infinite capacity. We consider a special case, called\nConnected Cap-SNDP, where all infinite-capacity edges in the solution are\nrequired to form a connected component containing the sinks. This problem is\nmotivated by its similarity to the Connected Facility Location problem\n[G+01,SW04]. We solve this problem by reducing it to Submodular tree cover\nproblem, which is a common generalization of Connected Cap-SNDP and Group\nSteiner tree problem. We generalize the recursive greedy algorithm [CEK]\nachieving a poly-logarithmic approximation algorithm for Submodular tree cover\nproblem. This result is interesting in its own right and gives the first\npoly-logarithmic approximation algorithms for Connected hard capacities set\nmulti-cover and Connected source location.\n  We then study another special case of Cap-SNDP called Unbalanced\npoint-to-point connection problem. Besides its practical applications to shift\ndesign problems [EKS], it generalizes many problems such as k-MST, Steiner\nForest and Point-to-Point Connection. We give a combinatorial logarithmic\napproximation algorithm for this problem by reducing it to degree-bounded SNDP.\n", "contributors": [{"name": "Hajiaghayi, MohammadTaghi", "sameAs": [], "familyName": "Hajiaghayi", "additionalName": "", "givenName": "MohammadTaghi", "email": ""}, {"name": "Khandekar, Rohit", "sameAs": [], "familyName": "Khandekar", "additionalName": "", "givenName": "Rohit", "email": ""}, {"name": "Kortsarz, Guy", "sameAs": [], "familyName": "Kortsarz", "additionalName": "", "givenName": "Guy", "email": ""}, {"name": "Nutov, Zeev", "sameAs": [], "familyName": "Nutov", "additionalName": "", "givenName": "Zeev", "email": ""}], "title": "Combinatorial Algorithms for Capacitated Network Design", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-08-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1108.1176", "oai:arXiv.org:1108.1176"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We focus on designing combinatorial algorithms for the Capacitated Network\nDesign problem (Cap-SNDP). The Cap-SNDP is the problem of satisfying\nconnectivity requirements when edges have costs and hard capacities. We begin\nby showing that the Group Steiner tree problem (GST) is a special case of\nCap-SNDP even when there is connectivity requirement between only one\nsource-sink pair. This implies the first poly-logarithmic lower bound for the\nCap-SNDP. We next provide combinatorial algorithms for several special cases of\nthis problem. The Cap-SNDP is equivalent to its special case when every edge\nhas either zero cost or infinite capacity. We consider a special case, called\nConnected Cap-SNDP, where all infinite-capacity edges in the solution are\nrequired to form a connected component containing the sinks. This problem is\nmotivated by its similarity to the Connected Facility Location problem\n[G+01,SW04]. We solve this problem by reducing it to Submodular tree cover\nproblem, which is a common generalization of Connected Cap-SNDP and Group\nSteiner tree problem. We generalize the recursive greedy algorithm [CEK]\nachieving a poly-logarithmic approximation algorithm for Submodular tree cover\nproblem. This result is interesting in its own right and gives the first\npoly-logarithmic approximation algorithms for Connected hard capacities set\nmulti-cover and Connected source location.\n  We then study another special case of Cap-SNDP called Unbalanced\npoint-to-point connection problem. Besides its practical applications to shift\ndesign problems [EKS], it generalizes many problems such as k-MST, Steiner\nForest and Point-to-Point Connection. We give a combinatorial logarithmic\napproximation algorithm for this problem by reducing it to degree-bounded SNDP.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1108.1176"}}, {"publisher": {"name": ""}, "description": "  Subspace clustering is the problem of clustering data points into a union of\nlow-dimensional linear or affine subspaces. It is the mathematical abstraction\nof many important problems in computer vision, image processing and has been\ndrawing avid attention in machine learning and statistics recently. In\nparticular, a line of recent work (Elhamifar and Vidal, 2013; Soltanolkotabi et\nal., 2012; Wang and Xu, 2013; Soltanolkotabi et al., 2014) provided strong\ntheoretical guarantee for the seminal algorithm: Sparse Subspace Clustering\n(SSC) (Elhamifar and Vidal, 2013) under various settings, and to some extent,\njustified its state-of-the-art performance in applications such as motion\nsegmentation and face clustering. The focus of these work has been getting\nmilder conditions under which SSC obeys \"self-expressiveness property\", which\nensures that no two points from different subspaces can be clustered together.\nSuch guarantee however is not sufficient for the clustering to be correct,\nthanks to the notorious \"graph connectivity problem\" (Nasihatkon and Hartley,\n2011). In this paper, we show that this issue can be resolved by a very simple\npost-processing procedure under only a mild \"general position\" assumption. In\naddition, we show that the approach is robust to arbitrary bounded perturbation\nof the data whenever the \"general position\" assumption holds with a margin.\nThese results provide the first exact clustering guarantee of SSC for subspaces\nof dimension greater than 3.\n", "contributors": [{"name": "Wang, Yining", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yining", "email": ""}, {"name": "Wang, Yu-Xiang", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yu-Xiang", "email": ""}, {"name": "Singh, Aarti", "sameAs": [], "familyName": "Singh", "additionalName": "", "givenName": "Aarti", "email": ""}], "title": "Clustering Consistent Sparse Subspace Clustering", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01046", "oai:arXiv.org:1504.01046"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Subspace clustering is the problem of clustering data points into a union of\nlow-dimensional linear or affine subspaces. It is the mathematical abstraction\nof many important problems in computer vision, image processing and has been\ndrawing avid attention in machine learning and statistics recently. In\nparticular, a line of recent work (Elhamifar and Vidal, 2013; Soltanolkotabi et\nal., 2012; Wang and Xu, 2013; Soltanolkotabi et al., 2014) provided strong\ntheoretical guarantee for the seminal algorithm: Sparse Subspace Clustering\n(SSC) (Elhamifar and Vidal, 2013) under various settings, and to some extent,\njustified its state-of-the-art performance in applications such as motion\nsegmentation and face clustering. The focus of these work has been getting\nmilder conditions under which SSC obeys \"self-expressiveness property\", which\nensures that no two points from different subspaces can be clustered together.\nSuch guarantee however is not sufficient for the clustering to be correct,\nthanks to the notorious \"graph connectivity problem\" (Nasihatkon and Hartley,\n2011). In this paper, we show that this issue can be resolved by a very simple\npost-processing procedure under only a mild \"general position\" assumption. In\naddition, we show that the approach is robust to arbitrary bounded perturbation\nof the data whenever the \"general position\" assumption holds with a margin.\nThese results provide the first exact clustering guarantee of SSC for subspaces\nof dimension greater than 3.\n", "Comment: 14 pages"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01046"}}, {"publisher": {"name": ""}, "description": "  More and more scientific research shows that there is a close correlation\nbetween the Internet and brain science. This paper presents the idea of\nestablishing the Internet neurology, which means to make a cross-contrast\nbetween the two in terms of physiology and psychology, so that a complete\ninfrastructure system of the Internet is established, predicting the\ndevelopment trend of the Internet in the future as well as the brain structure\nand operation mechanism, and providing theoretical support for the generation\nprinciple of intelligence, cognition and emotion. It also proposes the\nviewpoint that the Internet can be divided into Internet neurophysiology,\nInternet neuropsychology, Brain Internet physiology, Brain Internet psychology\nand the Internet in cognitive science.\n", "contributors": [{"name": "Liu, Feng", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Feng", "email": ""}], "title": "Definition and Research of Internet Neurology", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.02842", "oai:arXiv.org:1504.02842"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  More and more scientific research shows that there is a close correlation\nbetween the Internet and brain science. This paper presents the idea of\nestablishing the Internet neurology, which means to make a cross-contrast\nbetween the two in terms of physiology and psychology, so that a complete\ninfrastructure system of the Internet is established, predicting the\ndevelopment trend of the Internet in the future as well as the brain structure\nand operation mechanism, and providing theoretical support for the generation\nprinciple of intelligence, cognition and emotion. It also proposes the\nviewpoint that the Internet can be divided into Internet neurophysiology,\nInternet neuropsychology, Brain Internet physiology, Brain Internet psychology\nand the Internet in cognitive science.\n"}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.02842"}}, {"publisher": {"name": ""}, "description": "  This paper considers the controllability analysis problem for a class of\nmultirotor systems subject to rotor failure/wear. It is shown that classical\ncontrollability theories of linear systems are not sufficient to test the\ncontrollability of the considered multirotors. Owing to this, an easy-to-use\nmeasurement index is introduced to assess the available control authority.\nBased on it, a new necessary and sufficient condition for the controllability\nof multirotors is derived. Furthermore, a controllability test procedure is\napproached. The proposed controllability test method is applied to a class of\nhexacopters with different rotor configurations and different rotor efficiency\nparameters to show its effectiveness. The analysis results show that\nhexacopters with different rotor configurations have different fault-tolerant\ncapabilities. It is therefore necessary to test the controllability of the\nmultirotors before any fault-tolerant control strategies are employed.\n", "contributors": [{"name": "Du, Guang-Xun", "sameAs": [], "familyName": "Du", "additionalName": "", "givenName": "Guang-Xun", "email": ""}, {"name": "Quan, Quan", "sameAs": [], "familyName": "Quan", "additionalName": "", "givenName": "Quan", "email": ""}, {"name": "Yang, Binxian", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Binxian", "email": ""}, {"name": "Cai, Kai-Yuan", "sameAs": [], "familyName": "Cai", "additionalName": "", "givenName": "Kai-Yuan", "email": ""}], "title": "Controllability Analysis for Multirotor Helicopter Rotor Degradation and\n  Failure", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-24", "2015-02-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.5986", "oai:arXiv.org:1403.5986"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper considers the controllability analysis problem for a class of\nmultirotor systems subject to rotor failure/wear. It is shown that classical\ncontrollability theories of linear systems are not sufficient to test the\ncontrollability of the considered multirotors. Owing to this, an easy-to-use\nmeasurement index is introduced to assess the available control authority.\nBased on it, a new necessary and sufficient condition for the controllability\nof multirotors is derived. Furthermore, a controllability test procedure is\napproached. The proposed controllability test method is applied to a class of\nhexacopters with different rotor configurations and different rotor efficiency\nparameters to show its effectiveness. The analysis results show that\nhexacopters with different rotor configurations have different fault-tolerant\ncapabilities. It is therefore necessary to test the controllability of the\nmultirotors before any fault-tolerant control strategies are employed.\n", "Comment: 21 pages, 4 figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - robotics"], "providerUpdatedDateTime": "2015-02-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.5986"}}, {"publisher": {"name": ""}, "description": "  We describe four algorithms for neural network training, each adapted to\ndifferent scalability constraints. These algorithms are mathematically\nprincipled and invariant under a number of transformations in data and network\nrepresentation, from which performance is thus independent. These algorithms\nare obtained from the setting of differential geometry, and are based on either\nthe natural gradient using the Fisher information matrix, or on Hessian\nmethods, scaled down in a specific way to allow for scalability while keeping\nsome of their key mathematical properties.\n", "contributors": [{"name": "Ollivier, Yann", "sameAs": [], "familyName": "Ollivier", "additionalName": "", "givenName": "Yann", "email": ""}], "title": "Riemannian metrics for neural networks I: feedforward networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-03-04", "2015-02-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1303.0818", "oai:arXiv.org:1303.0818"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We describe four algorithms for neural network training, each adapted to\ndifferent scalability constraints. These algorithms are mathematically\nprincipled and invariant under a number of transformations in data and network\nrepresentation, from which performance is thus independent. These algorithms\nare obtained from the setting of differential geometry, and are based on either\nthe natural gradient using the Fisher information matrix, or on Hessian\nmethods, scaled down in a specific way to allow for scalability while keeping\nsome of their key mathematical properties.\n", "Comment: (5th version, minor changes)"]}}], "languages": [null], "subjects": ["mathematics - differential geometry", "68t05", "computer science - neural and evolutionary computing", "computer science - information theory", "computer science - learning"], "providerUpdatedDateTime": "2015-02-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1303.0818"}}, {"publisher": {"name": ""}, "description": "  In this work, we propose and study optimal proactive resource allocation and\ndemand shaping for data networks. Motivated by the recent findings on the\npredictability of human behavior patterns in data networks, and the emergence\nof highly capable handheld devices, our design aims to smooth out the network\ntraffic over time and minimize the data delivery costs.\n  Our framework utilizes proactive data services as well as smart content\nrecommendation schemes for shaping the demand. Proactive data services take\nplace during the off-peak hours based on a statistical prediction of a demand\nprofile for each user, whereas smart content recommendation assigns modified\nvaluations to data items so as to render the users' demand less uncertain.\nHence, our recommendation scheme aims to boost the performance of proactive\nservices within the allowed flexibility of user requirements. We conduct\ntheoretical performance analysis that quantifies the leveraged cost reduction\nthrough the proposed framework. We show that the cost reduction scales at the\nsame rate as the cost function scales with the number of users. Further, we\nprove that \\emph{demand shaping} through smart recommendation strictly reduces\nthe incurred cost even below that of proactive downloads without\nrecommendation.\n", "contributors": [{"name": "Tadrous, John", "sameAs": [], "familyName": "Tadrous", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Eryilmaz, Atilla", "sameAs": [], "familyName": "Eryilmaz", "additionalName": "", "givenName": "Atilla", "email": ""}, {"name": "Gamal, Hesham El", "sameAs": [], "familyName": "Gamal", "additionalName": "El", "givenName": "Hesham", "email": ""}], "title": "Proactive Data Download and User Demand Shaping for Data Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-04-21", "2014-12-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1304.5745", "oai:arXiv.org:1304.5745"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this work, we propose and study optimal proactive resource allocation and\ndemand shaping for data networks. Motivated by the recent findings on the\npredictability of human behavior patterns in data networks, and the emergence\nof highly capable handheld devices, our design aims to smooth out the network\ntraffic over time and minimize the data delivery costs.\n  Our framework utilizes proactive data services as well as smart content\nrecommendation schemes for shaping the demand. Proactive data services take\nplace during the off-peak hours based on a statistical prediction of a demand\nprofile for each user, whereas smart content recommendation assigns modified\nvaluations to data items so as to render the users' demand less uncertain.\nHence, our recommendation scheme aims to boost the performance of proactive\nservices within the allowed flexibility of user requirements. We conduct\ntheoretical performance analysis that quantifies the leveraged cost reduction\nthrough the proposed framework. We show that the cost reduction scales at the\nsame rate as the cost function scales with the number of users. Further, we\nprove that \\emph{demand shaping} through smart recommendation strictly reduces\nthe incurred cost even below that of proactive downloads without\nrecommendation.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1304.5745"}}, {"publisher": {"name": ""}, "description": "  We provide a comprehensive view of various phase transitions in random\n$K$-satisfiability problems solved by stochastic-local-search algorithms. In\nparticular, we focus on the finite-size scaling (FSS) exponent, which is\nmathematically important and practically useful in analyzing finite systems.\nUsing the FSS theory of nonequilibrium absorbing phase transitions, we show\nthat the density of unsatisfied clauses clearly indicates the transition from\nthe solvable (absorbing) phase to the unsolvable (active) phase as varying the\nnoise parameter and the density of constraints. Based on the solution\nclustering (percolation-type) argument, we conjecture two possible values of\nthe FSS exponent, which are confirmed reasonably well in numerical simulations\nfor $2\\le K \\le 3$.\n", "contributors": [{"name": "Lee, Sang Hoon", "sameAs": [], "familyName": "Lee", "additionalName": "Hoon", "givenName": "Sang", "email": ""}, {"name": "Ha, Meesoon", "sameAs": [], "familyName": "Ha", "additionalName": "", "givenName": "Meesoon", "email": ""}, {"name": "Jeon, Chanil", "sameAs": [], "familyName": "Jeon", "additionalName": "", "givenName": "Chanil", "email": ""}, {"name": "Jeong, Hawoong", "sameAs": [], "familyName": "Jeong", "additionalName": "", "givenName": "Hawoong", "email": ""}], "title": "Finite-size scaling in random $K$-satisfiability problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-05-03", "2010-12-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.0251", "PRE v82, 061109 (2010)", "doi:10.1103/PhysRevE.82.061109", "oai:arXiv.org:1005.0251"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We provide a comprehensive view of various phase transitions in random\n$K$-satisfiability problems solved by stochastic-local-search algorithms. In\nparticular, we focus on the finite-size scaling (FSS) exponent, which is\nmathematically important and practically useful in analyzing finite systems.\nUsing the FSS theory of nonequilibrium absorbing phase transitions, we show\nthat the density of unsatisfied clauses clearly indicates the transition from\nthe solvable (absorbing) phase to the unsolvable (active) phase as varying the\nnoise parameter and the density of constraints. Based on the solution\nclustering (percolation-type) argument, we conjecture two possible values of\nthe FSS exponent, which are confirmed reasonably well in numerical simulations\nfor $2\\le K \\le 3$.\n", "Comment: 5 pages, 3 figures (6 eps files), 1 table; published version"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "physics - computational physics", "condensed matter - statistical mechanics"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.0251"}}, {"publisher": {"name": ""}, "description": "  Novel energy-aware cloud management methods dynamically reallocate\ncomputation across geographically distributed data centers to leverage regional\nelectricity price and temperature differences. As a result, a managed VM may\nsuffer occasional downtimes. Current cloud providers only offer high\navailability VMs, without enough flexibility to apply such energy-aware\nmanagement. In this paper we show how to analyse past traces of dynamic cloud\nmanagement actions based on electricity prices and temperatures to estimate VM\navailability and price values. We propose a novel SLA specification approach\nfor offering VMs with different availability and price values guaranteed over\nmultiple SLAs to enable flexible energy-aware cloud management. We determine\nthe optimal number of such SLAs as well as their availability and price\nguaranteed values. We evaluate our approach in a user SLA selection simulation\nusing Wikipedia and Grid'5000 workloads. The results show higher customer\nconversion and 39% average energy savings per VM.\n", "contributors": [{"name": "Lu\u010danin, Dra\u017een", "sameAs": [], "familyName": "Lu\u010danin", "additionalName": "", "givenName": "Dra\u017een", "email": ""}, {"name": "Jrad, Foued", "sameAs": [], "familyName": "Jrad", "additionalName": "", "givenName": "Foued", "email": ""}, {"name": "Brandic, Ivona", "sameAs": [], "familyName": "Brandic", "additionalName": "", "givenName": "Ivona", "email": ""}, {"name": "Streit, Achim", "sameAs": [], "familyName": "Streit", "additionalName": "", "givenName": "Achim", "email": ""}], "title": "Energy-Aware Cloud Management through Progressive SLA Specification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-09-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.0325", "doi:10.1007/978-3-319-14609-6", "oai:arXiv.org:1409.0325"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Novel energy-aware cloud management methods dynamically reallocate\ncomputation across geographically distributed data centers to leverage regional\nelectricity price and temperature differences. As a result, a managed VM may\nsuffer occasional downtimes. Current cloud providers only offer high\navailability VMs, without enough flexibility to apply such energy-aware\nmanagement. In this paper we show how to analyse past traces of dynamic cloud\nmanagement actions based on electricity prices and temperatures to estimate VM\navailability and price values. We propose a novel SLA specification approach\nfor offering VMs with different availability and price values guaranteed over\nmultiple SLAs to enable flexible energy-aware cloud management. We determine\nthe optimal number of such SLAs as well as their availability and price\nguaranteed values. We evaluate our approach in a user SLA selection simulation\nusing Wikipedia and Grid'5000 workloads. The results show higher customer\nconversion and 39% average energy savings per VM.\n", "Comment: 14 pages, conference"]}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.0325"}}, {"publisher": {"name": ""}, "description": "  The essential variables in a finite function $f$ are defined as variables\nwhich occur in $f$ and weigh with the values of that function.\n  The number of essential variables is an important measure of complexity for\ndiscrete functions.\n  When replacing some variables in a function with constants the resulting\nfunctions are called subfunctions, and when replacing all essential variables\nin a function with constants we obtain an implementation of this function.\n  Such an implementation corresponds with a path in an ordered decision diagram\n(ODD) of the function which connects the root with a leaf of the diagram. The\nsets of essential variables in subfunctions of $f$ are called separable in $f$.\nIn this paper we study several properties of separable sets of variables in\nfunctions which directly impact on the number of implementations and\nsubfunctions in these functions.\n  We define equivalence relations which classify the functions of $k$-valued\nlogic into classes with same number of implementations, subfunctions or\nseparable sets. These relations induce three transformation groups which are\ncompared with the lattice of all subgroups of restricted affine group (RAG).\nThis allows us to solve several important computational and combinatorial\nproblems.\n", "contributors": [{"name": "Shtrakov, Sl.", "sameAs": [], "familyName": "Shtrakov", "additionalName": "", "givenName": "Sl.", "email": ""}, {"name": "Damyanov, I.", "sameAs": [], "familyName": "Damyanov", "additionalName": "", "givenName": "I.", "email": ""}], "title": "On the complexity of finite valued functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00265", "oai:arXiv.org:1501.00265"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The essential variables in a finite function $f$ are defined as variables\nwhich occur in $f$ and weigh with the values of that function.\n  The number of essential variables is an important measure of complexity for\ndiscrete functions.\n  When replacing some variables in a function with constants the resulting\nfunctions are called subfunctions, and when replacing all essential variables\nin a function with constants we obtain an implementation of this function.\n  Such an implementation corresponds with a path in an ordered decision diagram\n(ODD) of the function which connects the root with a leaf of the diagram. The\nsets of essential variables in subfunctions of $f$ are called separable in $f$.\nIn this paper we study several properties of separable sets of variables in\nfunctions which directly impact on the number of implementations and\nsubfunctions in these functions.\n  We define equivalence relations which classify the functions of $k$-valued\nlogic into classes with same number of implementations, subfunctions or\nseparable sets. These relations induce three transformation groups which are\ncompared with the lattice of all subgroups of restricted affine group (RAG).\nThis allows us to solve several important computational and combinatorial\nproblems.\n", "Comment: 23 pages, 4 figures, 6 tables, Preprint of the article is submitted\n  for consideration in [WSPC (2015)]\n  [http://www.worldscientific.com/worldscinet/ijfcs]"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "03d15", "f.1.3"], "providerUpdatedDateTime": "2015-01-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00265"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Thesis. 1975. Ph.D.--Massachusetts Institute of Technology. Dept. of Chemistry.", "contributors": [{"name": "McDermott, Joseph Xavier", "sameAs": [], "familyName": "McDermott", "additionalName": "Xavier", "givenName": "Joseph", "email": ""}, {"name": "G.M. Whitesides.", "sameAs": [], "familyName": "Whitesides.", "additionalName": "", "givenName": "G.M.", "email": ""}], "title": "Platinum and titanium metallocycles.", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "135 leaves"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/80423", "01331355", "oai:dspace.mit.edu:1721.1/80423"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2013-09-12T19:00:09Z", "2013-09-12T19:00:09Z", "1975"]}}, {"name": "description", "properties": {"description": ["Thesis. 1975. Ph.D.--Massachusetts Institute of Technology. Dept. of Chemistry.", "Vita.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7646", "hdl_1721.1_7794"]}}], "languages": [null], "subjects": ["organoplatinum compounds", "chemistry", "transition metal compounds", "organotitanium compounds", "decomposition (chemistry)"], "providerUpdatedDateTime": "2015-04-27T22:56:24", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/80423"}}, {"publisher": {"name": ""}, "description": "  We consider two CSP problems: the first CSP encodes 2D Sperner's lemma for\nthe standard triangulation of the right triangle on $n^2$ small triangles; the\nsecond CSP encodes the fact that it is impossible to match cells of $n \\times\nn$ square to arrows (two horizontal, two vertical and four diagonal) such that\narrows in two cells with a common edge differ by at most $45^\\circ$, and all\narrows on the boundary of the square do not look outside (this fact is a\ncorollary of the Brower's fixed point theorem). We prove that the tree-like\nresolution complexities of these CSPs are $2^{\\Theta(n)}$. For Sperner's lemma\nour result implies $\\Omega(n)$ lower bound on the number of request to colors\nof vertices that is enough to make in order to find a trichromatic triangle;\nthis lower bound was originally proved by Crescenzi and Silvestri.\n  CSP based on Sperner's lemma is related with the $\\rm PPAD$-complete problem.\nWe show that CSP corresponding to arrows is also related with a $\\rm\nPPAD$-complete problem.\n", "contributors": [{"name": "Itsykson, Dmitry", "sameAs": [], "familyName": "Itsykson", "additionalName": "", "givenName": "Dmitry", "email": ""}, {"name": "Malova, Anna", "sameAs": [], "familyName": "Malova", "additionalName": "", "givenName": "Anna", "email": ""}, {"name": "Oparin, Vsevolod", "sameAs": [], "familyName": "Oparin", "additionalName": "", "givenName": "Vsevolod", "email": ""}, {"name": "Sokolov, Dmitry", "sameAs": [], "familyName": "Sokolov", "additionalName": "", "givenName": "Dmitry", "email": ""}], "title": "Tree-like resolution complexity of two planar problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1124", "oai:arXiv.org:1412.1124"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We consider two CSP problems: the first CSP encodes 2D Sperner's lemma for\nthe standard triangulation of the right triangle on $n^2$ small triangles; the\nsecond CSP encodes the fact that it is impossible to match cells of $n \\times\nn$ square to arrows (two horizontal, two vertical and four diagonal) such that\narrows in two cells with a common edge differ by at most $45^\\circ$, and all\narrows on the boundary of the square do not look outside (this fact is a\ncorollary of the Brower's fixed point theorem). We prove that the tree-like\nresolution complexities of these CSPs are $2^{\\Theta(n)}$. For Sperner's lemma\nour result implies $\\Omega(n)$ lower bound on the number of request to colors\nof vertices that is enough to make in order to find a trichromatic triangle;\nthis lower bound was originally proved by Crescenzi and Silvestri.\n  CSP based on Sperner's lemma is related with the $\\rm PPAD$-complete problem.\nWe show that CSP corresponding to arrows is also related with a $\\rm\nPPAD$-complete problem.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "f.2.2", "68q25"], "providerUpdatedDateTime": "2014-12-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1124"}}, {"publisher": {"name": ""}, "description": "  Implicit electron-density solvation models based on joint density-functional\ntheory offer a computationally efficient solution to the problem of calculating\nthermodynamic quantities of solvated systems from firstprinciples quantum\nmechanics. However, despite much recent interest in such models, to date the\napplicability of such models in the plane-wave context to non-aqueous solvents\nhas been limited because the determination of the model parameters requires\nfitting to a large database of experimental solvation energies for each new\nsolvent considered. This work presents an alternate approach which allows\ndevelopment of new iso-density models for a large class of protic and aprotic\nsolvents from only simple, single-molecule ab initio calculations and readily\navailable bulk thermodynamic data.\n", "contributors": [{"name": "Gunceler, Deniz", "sameAs": [], "familyName": "Gunceler", "additionalName": "", "givenName": "Deniz", "email": ""}, {"name": "Arias, T. A.", "sameAs": [], "familyName": "Arias", "additionalName": "A.", "givenName": "T.", "email": ""}], "title": "Universal iso-density polarizable continuum model for molecular solvents", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-25", "2015-02-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.6465", "oai:arXiv.org:1403.6465"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Implicit electron-density solvation models based on joint density-functional\ntheory offer a computationally efficient solution to the problem of calculating\nthermodynamic quantities of solvated systems from firstprinciples quantum\nmechanics. However, despite much recent interest in such models, to date the\napplicability of such models in the plane-wave context to non-aqueous solvents\nhas been limited because the determination of the model parameters requires\nfitting to a large database of experimental solvation energies for each new\nsolvent considered. This work presents an alternate approach which allows\ndevelopment of new iso-density models for a large class of protic and aprotic\nsolvents from only simple, single-molecule ab initio calculations and readily\navailable bulk thermodynamic data.\n"}}], "languages": [null], "subjects": ["physics - computational physics", "physics - chemical physics", "condensed matter - materials science"], "providerUpdatedDateTime": "2015-02-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.6465"}}, {"publisher": {"name": ""}, "description": "  Cloud Data centers aim to provide reliable, sustainable and scalable services\nfor all kinds of applications. Resource scheduling is one of keys to cloud\nservices. To model and evaluate different scheduling policies and algorithms,\nwe propose FlexCloud, a flexible and scalable simulator that enables users to\nsimulate the process of initializing cloud data centers, allocating virtual\nmachine requests and providing performance evaluation for various scheduling\nalgorithms. FlexCloud can be run on a single computer with JVM to simulate\nlarge scale cloud environments with focus on infrastructure as a service;\nadopts agile design patterns to assure the flexibility and extensibility;\nmodels virtual machine migrations which is lack in the existing tools; provides\nuser-friendly interfaces for customized configurations and replaying. Comparing\nto existing simulators, FlexCloud has combining features for supporting public\ncloud providers, load-balance and energy-efficiency scheduling. FlexCloud has\nadvantage in computing time and memory consumption to support large-scale\nsimulations. The detailed design of FlexCloud is introduced and performance\nevaluation is provided.\n", "contributors": [{"name": "Xu, Minxian", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Minxian", "email": ""}, {"name": "Tian, Wenhong", "sameAs": [], "familyName": "Tian", "additionalName": "", "givenName": "Wenhong", "email": ""}, {"name": "Wang, Xinyang", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Xinyang", "email": ""}, {"name": "Xiong, Qin", "sameAs": [], "familyName": "Xiong", "additionalName": "", "givenName": "Qin", "email": ""}], "title": "FlexCloud: A Flexible and Extendible Simulator for Performance\n  Evaluation of Virtual Machine Allocation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05789", "oai:arXiv.org:1501.05789"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Cloud Data centers aim to provide reliable, sustainable and scalable services\nfor all kinds of applications. Resource scheduling is one of keys to cloud\nservices. To model and evaluate different scheduling policies and algorithms,\nwe propose FlexCloud, a flexible and scalable simulator that enables users to\nsimulate the process of initializing cloud data centers, allocating virtual\nmachine requests and providing performance evaluation for various scheduling\nalgorithms. FlexCloud can be run on a single computer with JVM to simulate\nlarge scale cloud environments with focus on infrastructure as a service;\nadopts agile design patterns to assure the flexibility and extensibility;\nmodels virtual machine migrations which is lack in the existing tools; provides\nuser-friendly interfaces for customized configurations and replaying. Comparing\nto existing simulators, FlexCloud has combining features for supporting public\ncloud providers, load-balance and energy-efficiency scheduling. FlexCloud has\nadvantage in computing time and memory consumption to support large-scale\nsimulations. The detailed design of FlexCloud is introduced and performance\nevaluation is provided.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05789"}}, {"publisher": {"name": ""}, "description": "  Location and mobility patterns of individuals are important to environmental\nplanning, societal resilience, public health, and a host of commercial\napplications. Mining telecommunication traffic and transactions data for such\npurposes is controversial, in particular raising issues of privacy. However,\nour hypothesis is that privacy-sensitive uses are possible and often beneficial\nenough to warrant considerable research and development efforts. Our work\ncontends that peoples behavior can yield patterns of both significant\ncommercial, and research, value. For such purposes, methods and algorithms for\nmining telecommunication data to extract commonly used routes and locations,\narticulated through time-geographical constructs, are described in a case study\nwithin the area of transportation planning and analysis. From the outset, these\nwere designed to balance the privacy of subscribers and the added value of\nmobility patterns derived from their mobile communication traffic and\ntransactions data. Our work directly contrasts the current, commonly held\nnotion that value can only be added to services by directly monitoring the\nbehavior of individuals, such as in current attempts at location-based\nservices. We position our work within relevant legal frameworks for privacy and\ndata protection, and show that our methods comply with such requirements and\nalso follow best-practices\n", "contributors": [{"name": "Sanches, Pedro", "sameAs": [], "familyName": "Sanches", "additionalName": "", "givenName": "Pedro", "email": ""}, {"name": "Svee, Eric-Oluf", "sameAs": [], "familyName": "Svee", "additionalName": "", "givenName": "Eric-Oluf", "email": ""}, {"name": "Bylund, Markus", "sameAs": [], "familyName": "Bylund", "additionalName": "", "givenName": "Markus", "email": ""}, {"name": "Hirsch, Benjamin", "sameAs": [], "familyName": "Hirsch", "additionalName": "", "givenName": "Benjamin", "email": ""}, {"name": "Boman, Magnus", "sameAs": [], "familyName": "Boman", "additionalName": "", "givenName": "Magnus", "email": ""}], "title": "Knowing Your Population: Privacy-Sensitive Mining of Massive Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2247", "Network and Communication Technologies 2, no. 1 (2013): p34", "doi:10.5539/nct.v2n1p34", "oai:arXiv.org:1412.2247"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Location and mobility patterns of individuals are important to environmental\nplanning, societal resilience, public health, and a host of commercial\napplications. Mining telecommunication traffic and transactions data for such\npurposes is controversial, in particular raising issues of privacy. However,\nour hypothesis is that privacy-sensitive uses are possible and often beneficial\nenough to warrant considerable research and development efforts. Our work\ncontends that peoples behavior can yield patterns of both significant\ncommercial, and research, value. For such purposes, methods and algorithms for\nmining telecommunication data to extract commonly used routes and locations,\narticulated through time-geographical constructs, are described in a case study\nwithin the area of transportation planning and analysis. From the outset, these\nwere designed to balance the privacy of subscribers and the added value of\nmobility patterns derived from their mobile communication traffic and\ntransactions data. Our work directly contrasts the current, commonly held\nnotion that value can only be added to services by directly monitoring the\nbehavior of individuals, such as in current attempts at location-based\nservices. We position our work within relevant legal frameworks for privacy and\ndata protection, and show that our methods comply with such requirements and\nalso follow best-practices\n"}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2247"}}, {"publisher": {"name": ""}, "description": "  The $\\beta$-skeleton $\\{G_{\\beta}(V)\\}$ for a point set V is a family of\ngeometric graphs, defined by the notion of neighborhoods parameterized by real\nnumber $0 < \\beta < \\infty$. By using the distance-based version definition of\n$\\beta$-skeletons we study those graphs for a set of points in $\\mathbb{R}^d$\nspace with $l_1$ and $l_{\\infty}$ metrics. We present algorithms for the entire\nspectrum of $\\beta$ values and we discuss properties of lens-based and\ncircle-based $\\beta$-skeletons in those metrics.\n  Let $V \\in \\mathbb{R}^d$ in $L_{\\infty}$ metric be a set of $n$ points in\ngeneral position. Then, for $\\beta<2$ lens-based $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$\nthere exists an $O(n \\log^{d-1} n)$ time algorithm that constructs\n$\\beta$-skeleton for the set $V$. We show that in $\\mathbb{R}^d$ with\n$L_{\\infty}$ metric, for $\\beta<2$ $\\beta$-skeleton $G_{\\beta}(V)$ for $n$\npoints can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$ there\nexists an $O(n \\log^{d-1} n)$ time algorithm. In $\\mathbb{R}^d$ with $L_1$\nmetric for a set of $n$ points in arbitrary position $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^{d+2} n)$ time.\n", "contributors": [{"name": "Kowaluk, Miros\u0142aw", "sameAs": [], "familyName": "Kowaluk", "additionalName": "", "givenName": "Miros\u0142aw", "email": ""}, {"name": "Majewska, Gabriela", "sameAs": [], "familyName": "Majewska", "additionalName": "", "givenName": "Gabriela", "email": ""}], "title": "Multidimensional $\\beta$-skeletons in $L_1$ and $L_{\\infty}$ metric", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5472", "oai:arXiv.org:1411.5472"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The $\\beta$-skeleton $\\{G_{\\beta}(V)\\}$ for a point set V is a family of\ngeometric graphs, defined by the notion of neighborhoods parameterized by real\nnumber $0 < \\beta < \\infty$. By using the distance-based version definition of\n$\\beta$-skeletons we study those graphs for a set of points in $\\mathbb{R}^d$\nspace with $l_1$ and $l_{\\infty}$ metrics. We present algorithms for the entire\nspectrum of $\\beta$ values and we discuss properties of lens-based and\ncircle-based $\\beta$-skeletons in those metrics.\n  Let $V \\in \\mathbb{R}^d$ in $L_{\\infty}$ metric be a set of $n$ points in\ngeneral position. Then, for $\\beta<2$ lens-based $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$\nthere exists an $O(n \\log^{d-1} n)$ time algorithm that constructs\n$\\beta$-skeleton for the set $V$. We show that in $\\mathbb{R}^d$ with\n$L_{\\infty}$ metric, for $\\beta<2$ $\\beta$-skeleton $G_{\\beta}(V)$ for $n$\npoints can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$ there\nexists an $O(n \\log^{d-1} n)$ time algorithm. In $\\mathbb{R}^d$ with $L_1$\nmetric for a set of $n$ points in arbitrary position $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^{d+2} n)$ time.\n"}}], "languages": [null], "subjects": ["computer science - computational geometry"], "providerUpdatedDateTime": "2014-11-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5472"}}, {"publisher": {"name": ""}, "description": "  We show that very simple algorithms based on local search are polynomial-time\napproximation schemes for Maximum Independent Set, Minimum Vertex Cover and\nMinimum Dominating Set, when the input graphs have a fixed forbidden minor.\n", "contributors": [{"name": "Cabello, Sergio", "sameAs": [], "familyName": "Cabello", "additionalName": "", "givenName": "Sergio", "email": ""}, {"name": "Gajser, David", "sameAs": [], "familyName": "Gajser", "additionalName": "", "givenName": "David", "email": ""}], "title": "Simple PTAS's for families of graphs excluding a minor", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-21", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5778", "oai:arXiv.org:1410.5778"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We show that very simple algorithms based on local search are polynomial-time\napproximation schemes for Maximum Independent Set, Minimum Vertex Cover and\nMinimum Dominating Set, when the input graphs have a fixed forbidden minor.\n", "Comment: To appear in Discrete Applied Mathematics"]}}], "languages": [null], "subjects": ["05c83", "computer science - discrete mathematics", "68w40", "computer science - data structures and algorithms", "05c85", "68w25"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5778"}}, {"publisher": {"name": ""}, "description": "  In the case of ordinary identification coding, a code is devised to identify\na single object among $N$ objects. But, in this paper, we consider an\nidentification coding problem to identify $K$ objects at once among $N$ objects\nin the both cases that $K$ objects are ranked or not ranked. By combining\nKurosawa-Yoshida scheme with Moulin-Koetter scheme, an efficient identification\ncoding scheme is proposed, which can attain high coding rate and error\nexponents compared with the case that an ordinary identification code is used\n$K$ times. Furthermore, the achievable triplet of rate and error exponents of\ntype I and type II decoding error probabilities are derived for the proposed\ncoding scheme.\n", "contributors": [{"name": "Yamamoto, Hirosuke", "sameAs": [], "familyName": "Yamamoto", "additionalName": "", "givenName": "Hirosuke", "email": ""}, {"name": "Ueda, Masashi", "sameAs": [], "familyName": "Ueda", "additionalName": "", "givenName": "Masashi", "email": ""}], "title": "Identification Codes to Identify Multiple Objects", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4612", "oai:arXiv.org:1410.4612"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In the case of ordinary identification coding, a code is devised to identify\na single object among $N$ objects. But, in this paper, we consider an\nidentification coding problem to identify $K$ objects at once among $N$ objects\nin the both cases that $K$ objects are ranked or not ranked. By combining\nKurosawa-Yoshida scheme with Moulin-Koetter scheme, an efficient identification\ncoding scheme is proposed, which can attain high coding rate and error\nexponents compared with the case that an ordinary identification code is used\n$K$ times. Furthermore, the achievable triplet of rate and error exponents of\ntype I and type II decoding error probabilities are derived for the proposed\ncoding scheme.\n", "Comment: 14 pages, submitted to IEEE Transactions on Information Theory"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4612"}}, {"publisher": {"name": ""}, "description": "  In the present article, a new system architecture for the next generation of\nsatellite communication (SatComs) is presented. The key concept lies in the\ncollaboration between multibeam satellites that share one orbital position.\nMulti-satellite constellations in unique orbital slots offer gradual deployment\nto cover unpredictable traffic patterns and redundancy to hardware failure\nadvantages. They are also of high relevance during the satellite replacement\nphases or necessitated by constraints in the maximum communications payload\nthat a single satellite can bear. In this context, the potential gains of\nadvanced architectures, that is architectures enabled by the general class of\ncooperative and cognitive techniques, are exhibited via a simple paradigm. More\nspecifically, the scenario presented herein, involves two co-existing multibeam\nsatellites which illuminate overlapping coverage areas. Based on this scenario,\nspecific types of cooperative and cognitive techniques are herein considered as\ncandidate technologies that can boost the performance of multibeam satellite\nconstellations. These techniques are compared to conventional frequency\nsplitting configurations in terms of three different criteria, namely the\nspectral efficiency, the power efficiency and the fairness. Consequently,\ninsightful guidelines for the design of future high throughput constellations\nof multibeam satellites are given.\n", "contributors": [{"name": "Christopoulos, Dimitrios", "sameAs": [], "familyName": "Christopoulos", "additionalName": "", "givenName": "Dimitrios", "email": ""}, {"name": "Sharma, Shree Krishna", "sameAs": [], "familyName": "Sharma", "additionalName": "Krishna", "givenName": "Shree", "email": ""}, {"name": "Chatzinotas, Symeon", "sameAs": [], "familyName": "Chatzinotas", "additionalName": "", "givenName": "Symeon", "email": ""}, {"name": "Ottersten, Jens Krauseand Bjorn", "sameAs": [], "familyName": "Ottersten", "additionalName": "Krauseand Bjorn", "givenName": "Jens", "email": ""}], "title": "Coordinated Multibeam Satellite Co-location: The Dual Satellite Paradigm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06981", "oai:arXiv.org:1503.06981"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In the present article, a new system architecture for the next generation of\nsatellite communication (SatComs) is presented. The key concept lies in the\ncollaboration between multibeam satellites that share one orbital position.\nMulti-satellite constellations in unique orbital slots offer gradual deployment\nto cover unpredictable traffic patterns and redundancy to hardware failure\nadvantages. They are also of high relevance during the satellite replacement\nphases or necessitated by constraints in the maximum communications payload\nthat a single satellite can bear. In this context, the potential gains of\nadvanced architectures, that is architectures enabled by the general class of\ncooperative and cognitive techniques, are exhibited via a simple paradigm. More\nspecifically, the scenario presented herein, involves two co-existing multibeam\nsatellites which illuminate overlapping coverage areas. Based on this scenario,\nspecific types of cooperative and cognitive techniques are herein considered as\ncandidate technologies that can boost the performance of multibeam satellite\nconstellations. These techniques are compared to conventional frequency\nsplitting configurations in terms of three different criteria, namely the\nspectral efficiency, the power efficiency and the fairness. Consequently,\ninsightful guidelines for the design of future high throughput constellations\nof multibeam satellites are given.\n", "Comment: Submitted to the IEEE wirless. Comms. Magazine"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06981"}}, {"publisher": {"name": ""}, "description": "  The proliferation of online social networks in the last decade has not\nstopped short of pets, and many different online platforms now exist catering\nto owners of various pets such as cats and dogs. These online pet social\nnetworks provide a unique opportunity to study an online social network in\nwhich a single user manages multiple user profiles, i.e. one for each pet they\nown. These types of multi-profile networks allow us to investigate two\nquestions: (1) What is the relationship between the pet-level and human-level\nnetwork, and (2) what is the relationship between friendship links and family\nties? Concretely, we study the online social pet networks Catster, Dogster and\nHamsterster, the first two of which are the two largest online pet networks in\nexistence. We show how the networks on the two levels interact, and perform\nexperiments to find out whether knowledge about friendships on a profile-level\nalone can be used to predict which users are behind which profile. In order to\ndo so, we introduce the concept of multi-profile social network, extend a\npreviously defined spectral test of diagonality to multi-profile networks,\ndefine two new homophily measures for multi-profile social networks, perform a\ntwo-level social network analysis, and present an algorithm for predicting\nwhether two profiles were created by the same user. As a result, we are able to\npredict with very high precision whether two profiles were created by a same\nuser. Our work is thus relevant for the analysis of other online communities in\nwhich users may use multiple profiles.\n", "contributors": [{"name": "D\u00fcnker, Daniel", "sameAs": [], "familyName": "D\u00fcnker", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Kunegis, J\u00e9r\u00f4me", "sameAs": [], "familyName": "Kunegis", "additionalName": "", "givenName": "J\u00e9r\u00f4me", "email": ""}], "title": "Social Networking by Proxy: A Case Study of Catster, Dogster and\n  Hamsterster", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04527", "oai:arXiv.org:1501.04527"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The proliferation of online social networks in the last decade has not\nstopped short of pets, and many different online platforms now exist catering\nto owners of various pets such as cats and dogs. These online pet social\nnetworks provide a unique opportunity to study an online social network in\nwhich a single user manages multiple user profiles, i.e. one for each pet they\nown. These types of multi-profile networks allow us to investigate two\nquestions: (1) What is the relationship between the pet-level and human-level\nnetwork, and (2) what is the relationship between friendship links and family\nties? Concretely, we study the online social pet networks Catster, Dogster and\nHamsterster, the first two of which are the two largest online pet networks in\nexistence. We show how the networks on the two levels interact, and perform\nexperiments to find out whether knowledge about friendships on a profile-level\nalone can be used to predict which users are behind which profile. In order to\ndo so, we introduce the concept of multi-profile social network, extend a\npreviously defined spectral test of diagonality to multi-profile networks,\ndefine two new homophily measures for multi-profile social networks, perform a\ntwo-level social network analysis, and present an algorithm for predicting\nwhether two profiles were created by the same user. As a result, we are able to\npredict with very high precision whether two profiles were created by a same\nuser. Our work is thus relevant for the analysis of other online communities in\nwhich users may use multiple profiles.\n", "Comment: 10 pages"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04527"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Understanding the microbial world is key to understanding global biogeochemistry, human health and disease, yet this world is largely inaccessible. Microbial genomes, an increasingly accessible data source, provide an ideal entry point. The genome sequences of different microbes may be compared using the tools of population genetics to infer important genetic changes allowing them to diversify ecologically and adapt to distinct ecological niches. Yet the toolkit of population genetics was developed largely with sexual eukaryotes in mind. In this work, I assess and develop tools for inferring natural selection in microbial genomes. Many tools rely on population genetics theory, and thus require defining distinct populations, or species, of bacteria. Because sex (recombination) is not required for reproduction, some bacteria recombine only rarely, while others are extremely promiscuous, exchanging genes across great genetic distances. This behavior poses a challenge for defining microbial population boundaries. This thesis begins with a discussion of how recombination and positive selection interact to promote ecological adaptation. I then describe a general pipeline for quantifying the impacts of mutation, recombination and selection on microbial genomes, and apply it to two closely related, yet ecologically distinct populations of Vibrio splendidus, each with its own microhabitat preference. I introduce a new tool, STARRInIGHTS, for inferring homologous recombination events. By assessing rates of recombination within and between ecological populations, I conclude that ecological differentiation is driven by small number of habitat-specific alleles, while most loci are shared freely across habitats. The remainder of the thesis focuses on lineage-specific changes in natural selection among anciently diverged species of gamma proteobacteria. I develop two new metrics, selective signatures and slow:fast, for detecting deviations from the expected rate of evolution in 'core' proteins (present in single copy in most species). Because they rely on empirical distributions of evolutionary rates across species, these methods should become increasingly powerful as more and more microbial genomes are sampled. Overall, the methods described here significantly expand the repertoire of tools available for microbial population genomics, both for investigating the process of ecological differentiation at the finest of time scales, and over billions of years of microbial evolution.", "contributors": [{"name": "Shapiro, B. Jesse (Benjamin Jesse)", "sameAs": [], "familyName": "Shapiro", "additionalName": "Jesse", "givenName": "B.", "email": ""}, {"name": "Massachusetts Institute of Technology. Computational and Systems Biology Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computational and Systems Biology", "givenName": "Massachusetts", "email": ""}, {"name": "Eric J. Alm.", "sameAs": [], "familyName": "Alm.", "additionalName": "J.", "givenName": "Eric", "email": ""}], "title": "Genomic signatures of sex, selection and speciation in the microbial world", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "228 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/61788", "706715014", "oai:dspace.mit.edu:1721.1/61788"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2011-03-24T18:52:25Z", "2011-03-24T18:52:25Z", "2010", "2010"]}}, {"name": "description", "properties": {"description": ["Understanding the microbial world is key to understanding global biogeochemistry, human health and disease, yet this world is largely inaccessible. Microbial genomes, an increasingly accessible data source, provide an ideal entry point. The genome sequences of different microbes may be compared using the tools of population genetics to infer important genetic changes allowing them to diversify ecologically and adapt to distinct ecological niches. Yet the toolkit of population genetics was developed largely with sexual eukaryotes in mind. In this work, I assess and develop tools for inferring natural selection in microbial genomes. Many tools rely on population genetics theory, and thus require defining distinct populations, or species, of bacteria. Because sex (recombination) is not required for reproduction, some bacteria recombine only rarely, while others are extremely promiscuous, exchanging genes across great genetic distances. This behavior poses a challenge for defining microbial population boundaries. This thesis begins with a discussion of how recombination and positive selection interact to promote ecological adaptation. I then describe a general pipeline for quantifying the impacts of mutation, recombination and selection on microbial genomes, and apply it to two closely related, yet ecologically distinct populations of Vibrio splendidus, each with its own microhabitat preference. I introduce a new tool, STARRInIGHTS, for inferring homologous recombination events. By assessing rates of recombination within and between ecological populations, I conclude that ecological differentiation is driven by small number of habitat-specific alleles, while most loci are shared freely across habitats. The remainder of the thesis focuses on lineage-specific changes in natural selection among anciently diverged species of gamma proteobacteria. I develop two new metrics, selective signatures and slow:fast, for detecting deviations from the expected rate of evolution in 'core' proteins (present in single copy in most species). Because they rely on empirical distributions of evolutionary rates across species, these methods should become increasingly powerful as more and more microbial genomes are sampled. Overall, the methods described here significantly expand the repertoire of tools available for microbial population genomics, both for investigating the process of ecological differentiation at the finest of time scales, and over billions of years of microbial evolution.", "by B. Jesse Shapiro.", "Thesis (Ph. D.)--Massachusetts Institute of Technology, Computational and Systems Biology Program, 2010.", "This electronic version was submitted by the student author.  The certified thesis is available in the Institute Archives and Special Collections.", "Cataloged from student-submitted PDF version of thesis.", "Includes bibliographical references (p. 218-228)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_54823", "hdl_1721.1_54828"]}}], "languages": [null], "subjects": ["computational and systems biology program."], "providerUpdatedDateTime": "2015-04-27T14:53:05", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/61788"}}, {"publisher": {"name": ""}, "description": "  We study the problem of selling $n$ items to a number of buyers with additive\nvaluation functions. We consider the items to be correlated, i.e.,\ndesirabilities of buyers for the items are not drawn independently. Ideally,\nthe goal is to design a mechanism to maximize the revenue. However, it has been\nshown that the optimum-revenue mechanism might be very complicated and as a\nresult inapplicable to real-world auctions. Therefore, our focus is on\ndesigning a simple mechanism that gets a constant fraction of the optimal\nrevenue. This problem was posed by Babaioff et al. in paper \"A Simple and\nApproximately Optimal Mechanism for an Additive Buyer\" (FOCS 2014) as an open\nquestion. In their paper they show a constant approximation of the optimal\nrevenue can be achieved by either selling the items separately or as a whole\nbundle in the independent setting. We show a similar result for the correlated\nsetting when the desirabilities of buyers are drawn from a common-base\ncorrelation. It is worth mentioning that the core decomposition lemma which is\nmainly the heart of the proofs for efficiency of the mechanisms does not hold\nfor correlated settings. Therefore we proposed a modified version of this lemma\nwhich plays a key role in proving bounds on the approximation of the mechanism.\nIn addition, we introduce a generalized form of correlation for items and show\nthe same mechanism can achieve an approximation of the optimal revenue in that\nsetting.\n", "contributors": [{"name": "Bateni, MohammadHossein", "sameAs": [], "familyName": "Bateni", "additionalName": "", "givenName": "MohammadHossein", "email": ""}, {"name": "Dehghani, Sina", "sameAs": [], "familyName": "Dehghani", "additionalName": "", "givenName": "Sina", "email": ""}, {"name": "Hajiaghayi, MohammadTaghi", "sameAs": [], "familyName": "Hajiaghayi", "additionalName": "", "givenName": "MohammadTaghi", "email": ""}, {"name": "Seddighin, Saeed", "sameAs": [], "familyName": "Seddighin", "additionalName": "", "givenName": "Saeed", "email": ""}], "title": "Revenue Maximization for Selling Multiple Correlated Items", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3187", "oai:arXiv.org:1412.3187"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We study the problem of selling $n$ items to a number of buyers with additive\nvaluation functions. We consider the items to be correlated, i.e.,\ndesirabilities of buyers for the items are not drawn independently. Ideally,\nthe goal is to design a mechanism to maximize the revenue. However, it has been\nshown that the optimum-revenue mechanism might be very complicated and as a\nresult inapplicable to real-world auctions. Therefore, our focus is on\ndesigning a simple mechanism that gets a constant fraction of the optimal\nrevenue. This problem was posed by Babaioff et al. in paper \"A Simple and\nApproximately Optimal Mechanism for an Additive Buyer\" (FOCS 2014) as an open\nquestion. In their paper they show a constant approximation of the optimal\nrevenue can be achieved by either selling the items separately or as a whole\nbundle in the independent setting. We show a similar result for the correlated\nsetting when the desirabilities of buyers are drawn from a common-base\ncorrelation. It is worth mentioning that the core decomposition lemma which is\nmainly the heart of the proofs for efficiency of the mechanisms does not hold\nfor correlated settings. Therefore we proposed a modified version of this lemma\nwhich plays a key role in proving bounds on the approximation of the mechanism.\nIn addition, we introduce a generalized form of correlation for items and show\nthe same mechanism can achieve an approximation of the optimal revenue in that\nsetting.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2014-12-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3187"}}, {"publisher": {"name": ""}, "description": "  A good deal of current research in complex networks involves the\ncharacterization and/or classification of the topological properties of given\nstructures, which has motivated several respective measurements. This letter\nproposes a framework for evaluating the quality of complex network measurements\nin terms of their effective resolution, degree of degeneracy and\ndiscriminability. The potential of the suggested approach is illustrated with\nrespect to comparing the characterization of several model and real-world\nnetworks by using concentric and symmetry measurements. The results indicate a\nmarkedly superior performance for the latter type of mapping.\n", "contributors": [{"name": "Comin, Cesar H.", "sameAs": [], "familyName": "Comin", "additionalName": "H.", "givenName": "Cesar", "email": ""}, {"name": "Silva, Filipi N.", "sameAs": [], "familyName": "Silva", "additionalName": "N.", "givenName": "Filipi", "email": ""}, {"name": "Costa, Luciano da F.", "sameAs": [], "familyName": "Costa", "additionalName": "da F.", "givenName": "Luciano", "email": ""}], "title": "A Framework for Evaluating Complex Networks Measurements", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-23", "2015-02-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7367", "oai:arXiv.org:1412.7367"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  A good deal of current research in complex networks involves the\ncharacterization and/or classification of the topological properties of given\nstructures, which has motivated several respective measurements. This letter\nproposes a framework for evaluating the quality of complex network measurements\nin terms of their effective resolution, degree of degeneracy and\ndiscriminability. The potential of the suggested approach is illustrated with\nrespect to comparing the characterization of several model and real-world\nnetworks by using concentric and symmetry measurements. The results indicate a\nmarkedly superior performance for the latter type of mapping.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "physics - data analysis", "statistics and probability", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7367"}}, {"publisher": {"name": ""}, "description": "  Google Scholar allows merging multiple article versions into one. This\nmerging affects the H-index computed by Google Scholar. We analyze the\nparameterized complexity of maximizing the H-index using article merges.\nHerein, multiple possible measures for computing the citation count of a merged\narticle are considered. Among others, for the measure used by Google Scholar,\nwe give an algorithm that maximizes the H-index in linear time if there is only\na constant number of versions of the same article. In contrast, if we are\nallowed to merge arbitrary articles, then already increasing the H-index by one\nis NP-hard.\n", "contributors": [{"name": "van Bevern, Ren\u00e9", "sameAs": [], "familyName": "van Bevern", "additionalName": "", "givenName": "Ren\u00e9", "email": ""}, {"name": "Komusiewicz, Christian", "sameAs": [], "familyName": "Komusiewicz", "additionalName": "", "givenName": "Christian", "email": ""}, {"name": "Niedermeier, Rolf", "sameAs": [], "familyName": "Niedermeier", "additionalName": "", "givenName": "Rolf", "email": ""}, {"name": "Sorge, Manuel", "sameAs": [], "familyName": "Sorge", "additionalName": "", "givenName": "Manuel", "email": ""}, {"name": "Walsh, Toby", "sameAs": [], "familyName": "Walsh", "additionalName": "", "givenName": "Toby", "email": ""}], "title": "On Google Scholar H-Index Manipulation by Merging Articles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5498", "oai:arXiv.org:1412.5498"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Google Scholar allows merging multiple article versions into one. This\nmerging affects the H-index computed by Google Scholar. We analyze the\nparameterized complexity of maximizing the H-index using article merges.\nHerein, multiple possible measures for computing the citation count of a merged\narticle are considered. Among others, for the measure used by Google Scholar,\nwe give an algorithm that maximizes the H-index in linear time if there is only\na constant number of versions of the same article. In contrast, if we are\nallowed to merge arbitrary articles, then already increasing the H-index by one\nis NP-hard.\n"}}], "languages": [null], "subjects": ["g.2.1", "g.2.2", "f.2.2", "computer science - discrete mathematics", "h.3.7", "computer science - digital libraries", "computer science - social and information networks", "91d30", "computer science - data structures and algorithms"], "providerUpdatedDateTime": "2014-12-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5498"}}, {"publisher": {"name": ""}, "description": "  Visual media has always been the most enjoyed way of communication. From the\nadvent of television to the modern day hand held computers, we have witnessed\nthe exponential growth of images around us. Undoubtedly it's a fact that they\ncarry a lot of information in them which needs be utilized in an effective\nmanner. Hence intense need has been felt to efficiently index and store large\nimage collections for effective and on- demand retrieval. For this purpose\nlow-level features extracted from the image contents like color, texture and\nshape has been used. Content based image retrieval systems employing these\nfeatures has proven very successful. Image retrieval has promising applications\nin numerous fields and hence has motivated researchers all over the world. New\nand improved ways to represent visual content are being developed each day.\nTremendous amount of research has been carried out in the last decade. In this\npaper we will present a detailed overview of some of the powerful color,\ntexture and shape descriptors for content based image retrieval. A comparative\nanalysis will also be carried out for providing an insight into outstanding\nchallenges in this field.\n", "contributors": [{"name": "Ahmad, Jamil", "sameAs": [], "familyName": "Ahmad", "additionalName": "", "givenName": "Jamil", "email": ""}, {"name": "Sajjad, Muhammad", "sameAs": [], "familyName": "Sajjad", "additionalName": "", "givenName": "Muhammad", "email": ""}, {"name": "Mehmood, Irfan", "sameAs": [], "familyName": "Mehmood", "additionalName": "", "givenName": "Irfan", "email": ""}, {"name": "Rho, Seungmin", "sameAs": [], "familyName": "Rho", "additionalName": "", "givenName": "Seungmin", "email": ""}, {"name": "Baik, Sung Wook", "sameAs": [], "familyName": "Baik", "additionalName": "Wook", "givenName": "Sung", "email": ""}], "title": "Describing Colors, Textures and Shapes for Content Based Image Retrieval\n  - A Survey", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07041", "(2014), Journal of Platform Technology 2(4): 34-48", "oai:arXiv.org:1502.07041"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Visual media has always been the most enjoyed way of communication. From the\nadvent of television to the modern day hand held computers, we have witnessed\nthe exponential growth of images around us. Undoubtedly it's a fact that they\ncarry a lot of information in them which needs be utilized in an effective\nmanner. Hence intense need has been felt to efficiently index and store large\nimage collections for effective and on- demand retrieval. For this purpose\nlow-level features extracted from the image contents like color, texture and\nshape has been used. Content based image retrieval systems employing these\nfeatures has proven very successful. Image retrieval has promising applications\nin numerous fields and hence has motivated researchers all over the world. New\nand improved ways to represent visual content are being developed each day.\nTremendous amount of research has been carried out in the last decade. In this\npaper we will present a detailed overview of some of the powerful color,\ntexture and shape descriptors for content based image retrieval. A comparative\nanalysis will also be carried out for providing an insight into outstanding\nchallenges in this field.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07041"}}, {"publisher": {"name": ""}, "description": "  The aim of this article is to use generalized complex structures in order to\nextend the definition of twistor spaces given by Penrose. We will adapt the\nintegrability result of Atiyah, Hitchin and Singer. We will deduce new\ncorrespondences betwenn differential geometry and (generalized) complex\ngeometry. In the last section we will show how these results generalized\nBredthauer's work.\n", "contributors": [{"name": "Deschamps, Guillaume", "sameAs": [], "familyName": "Deschamps", "additionalName": "", "givenName": "Guillaume", "email": ""}], "title": "Espaces de twisteurs des structures complexes g\\'en\\'eralis\\'ees", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-09-26", "2015-02-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1209.5870", "oai:arXiv.org:1209.5870"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The aim of this article is to use generalized complex structures in order to\nextend the definition of twistor spaces given by Penrose. We will adapt the\nintegrability result of Atiyah, Hitchin and Singer. We will deduce new\ncorrespondences betwenn differential geometry and (generalized) complex\ngeometry. In the last section we will show how these results generalized\nBredthauer's work.\n", "Comment: 19 pages, in French"]}}], "languages": [null], "subjects": ["mathematics - differential geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-02-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1209.5870"}}, {"publisher": {"name": ""}, "description": "  We are interested in characterising pairs $S,T$ of $F$-linear subspaces in a\nfield extension $L/F$ such that the linear span $ST$ of the set of products of\nelements of $S$ and of elements of $T$ has small dimension. Our central result\nis a linear analogue of Vosper's Theorem, which gives the structure of vector\nspaces $S,T$ in a prime extension $L$ of a finite field $F$ for which\n$\\dim_F(ST) =\\dim_F(S)+\\dim_F(T)-1$, when $\\dim_F(S), \\dim_F(T) >1$ and\n$\\dim_F(ST) < [L:F]-1$.\n", "contributors": [{"name": "Bachoc, Christine", "sameAs": [], "familyName": "Bachoc", "additionalName": "", "givenName": "Christine", "email": ""}, {"name": "Serra, Oriol", "sameAs": [], "familyName": "Serra", "additionalName": "", "givenName": "Oriol", "email": ""}, {"name": "Zemor, Gilles", "sameAs": [], "familyName": "Zemor", "additionalName": "", "givenName": "Gilles", "email": ""}], "title": "An analogue of Vosper's Theorem for Extension Fields", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00602", "oai:arXiv.org:1501.00602"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We are interested in characterising pairs $S,T$ of $F$-linear subspaces in a\nfield extension $L/F$ such that the linear span $ST$ of the set of products of\nelements of $S$ and of elements of $T$ has small dimension. Our central result\nis a linear analogue of Vosper's Theorem, which gives the structure of vector\nspaces $S,T$ in a prime extension $L$ of a finite field $F$ for which\n$\\dim_F(ST) =\\dim_F(S)+\\dim_F(T)-1$, when $\\dim_F(S), \\dim_F(T) >1$ and\n$\\dim_F(ST) < [L:F]-1$.\n"}}], "languages": [null], "subjects": ["mathematics - number theory", "computer science - information theory", "mathematics - combinatorics", "11p70 (primary) 94b65 12f99 (secondary)"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00602"}}, {"publisher": {"name": ""}, "description": "  Reconstructing complex networks from measurable data is a fundamental problem\nfor understanding and controlling collective dynamics of complex networked\nsystems. However, a significant challenge arises when we attempt to decode\nstructural information hidden in limited amounts of data accompanied by noise\nand in the presence of inaccessible nodes. Here, we develop a general framework\nfor robust reconstruction of complex networks from sparse and noisy data.\nSpecifically, we decompose the task of reconstructing the whole network into\nrecovering local structures centered at each node. Thus, the natural sparsity\nof complex networks ensures a conversion from the local structure\nreconstruction into a sparse signal reconstruction problem that can be\naddressed by using the lasso, a convex optimization method. We apply our method\nto evolutionary games, transportation and communication processes taking place\nin a variety of model and real complex networks, finding that universal high\nreconstruction accuracy can be achieved from sparse data in spite of noise in\ntime series and missing data of partial nodes. Our approach opens new routes to\nthe network reconstruction problem and has potential applications in a wide\nrange of fields.\n", "contributors": [{"name": "Han, Xiao", "sameAs": [], "familyName": "Han", "additionalName": "", "givenName": "Xiao", "email": ""}, {"name": "Shen, Zhesi", "sameAs": [], "familyName": "Shen", "additionalName": "", "givenName": "Zhesi", "email": ""}, {"name": "Wang, Wen-Xu", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Wen-Xu", "email": ""}, {"name": "Di, Zengru", "sameAs": [], "familyName": "Di", "additionalName": "", "givenName": "Zengru", "email": ""}], "title": "Robust Reconstruction of Complex Networks from Sparse Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04731", "doi:10.1103/PhysRevLett.114.028701", "oai:arXiv.org:1501.04731"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Reconstructing complex networks from measurable data is a fundamental problem\nfor understanding and controlling collective dynamics of complex networked\nsystems. However, a significant challenge arises when we attempt to decode\nstructural information hidden in limited amounts of data accompanied by noise\nand in the presence of inaccessible nodes. Here, we develop a general framework\nfor robust reconstruction of complex networks from sparse and noisy data.\nSpecifically, we decompose the task of reconstructing the whole network into\nrecovering local structures centered at each node. Thus, the natural sparsity\nof complex networks ensures a conversion from the local structure\nreconstruction into a sparse signal reconstruction problem that can be\naddressed by using the lasso, a convex optimization method. We apply our method\nto evolutionary games, transportation and communication processes taking place\nin a variety of model and real complex networks, finding that universal high\nreconstruction accuracy can be achieved from sparse data in spite of noise in\ntime series and missing data of partial nodes. Our approach opens new routes to\nthe network reconstruction problem and has potential applications in a wide\nrange of fields.\n", "Comment: 5 pages, 2 figures, 2 tables"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04731"}}, {"publisher": {"name": ""}, "description": "  The main aim of this paper is to document the performance of $p$-refinement\nwith respect to maximum principles and the non-negative constraint. The model\nproblem is (steady-state) anisotropic diffusion with decay (which is a\nsecond-order elliptic partial differential equation). We considered the\nstandard single-field formulation (which is based on the Galerkin formalism)\nand two least-squares-based mixed formulations. We have employed non-uniform\nLagrange polynomials for altering the polynomial order in each element, and we\nhave used $p = 1, ..., 10$.\n  It will be shown that the violation of the non-negative constraint will not\nvanish with $p$-refinement for anisotropic diffusion. We shall illustrate the\nperformance of $p$-refinement using several representative problems. The\nintended outcome of the paper is twofold. Firstly, this study will caution the\nusers of high-order approximations about its performance with respect to\nmaximum principles and the non-negative constraint. Secondly, this study will\nhelp researchers to develop new methodologies for enforcing maximum principles\nand the non-negative constraint under high-order approximations.\n", "contributors": [{"name": "Payette, G. S.", "sameAs": [], "familyName": "Payette", "additionalName": "S.", "givenName": "G.", "email": ""}, {"name": "Nakshatrala, K. B.", "sameAs": [], "familyName": "Nakshatrala", "additionalName": "B.", "givenName": "K.", "email": ""}, {"name": "Reddy, J. N.", "sameAs": [], "familyName": "Reddy", "additionalName": "N.", "givenName": "J.", "email": ""}], "title": "On the performance of high-order finite elements with respect to maximum\n  principles and the non-negative constraint for diffusion-type equations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-08-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1108.0952", "oai:arXiv.org:1108.0952"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  The main aim of this paper is to document the performance of $p$-refinement\nwith respect to maximum principles and the non-negative constraint. The model\nproblem is (steady-state) anisotropic diffusion with decay (which is a\nsecond-order elliptic partial differential equation). We considered the\nstandard single-field formulation (which is based on the Galerkin formalism)\nand two least-squares-based mixed formulations. We have employed non-uniform\nLagrange polynomials for altering the polynomial order in each element, and we\nhave used $p = 1, ..., 10$.\n  It will be shown that the violation of the non-negative constraint will not\nvanish with $p$-refinement for anisotropic diffusion. We shall illustrate the\nperformance of $p$-refinement using several representative problems. The\nintended outcome of the paper is twofold. Firstly, this study will caution the\nusers of high-order approximations about its performance with respect to\nmaximum principles and the non-negative constraint. Secondly, this study will\nhelp researchers to develop new methodologies for enforcing maximum principles\nand the non-negative constraint under high-order approximations.\n"}}], "languages": [null], "subjects": ["mathematics - numerical analysis", "computer science - numerical analysis"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1108.0952"}}, {"publisher": {"name": ""}, "description": "  The article revisits spatial interaction and distance decay from the\nperspective of human mobility patterns and spatially-embedded networks based on\nan empirical data set. We extract nationwide inter-urban movements in China\nfrom a check-in data set that covers half million individuals and 370 cities to\nanalyze the underlying patterns of trips and spatial interactions. By fitting\nthe gravity model, we find that the observed spatial interactions are governed\nby a power law distance decay effect. The obtained gravity model also well\nreproduces the exponential trip displacement distribution. However, due to the\necological fallacy issue, the movement of an individual may not obey the same\ndistance decay effect. We also construct a spatial network where the edge\nweights denote the interaction strengths. The communities detected from the\nnetwork are spatially connected and roughly consistent with province\nboundaries. We attribute this pattern to different distance decay parameters\nbetween intra-province and inter-province trips.\n", "contributors": [{"name": "Liu, Yu", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Yu", "email": ""}, {"name": "Sui, Zhengwei", "sameAs": [], "familyName": "Sui", "additionalName": "", "givenName": "Zhengwei", "email": ""}, {"name": "Kang, Chaogui", "sameAs": [], "familyName": "Kang", "additionalName": "", "givenName": "Chaogui", "email": ""}, {"name": "Gao, Yong", "sameAs": [], "familyName": "Gao", "additionalName": "", "givenName": "Yong", "email": ""}], "title": "Uncovering patterns of inter-urban trip and spatial interaction from\n  social media check-in data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-01", "2013-11-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.0282", "PLoS ONE 9(1): e86026", "doi:10.1371/journal.pone.0086026", "oai:arXiv.org:1310.0282"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The article revisits spatial interaction and distance decay from the\nperspective of human mobility patterns and spatially-embedded networks based on\nan empirical data set. We extract nationwide inter-urban movements in China\nfrom a check-in data set that covers half million individuals and 370 cities to\nanalyze the underlying patterns of trips and spatial interactions. By fitting\nthe gravity model, we find that the observed spatial interactions are governed\nby a power law distance decay effect. The obtained gravity model also well\nreproduces the exponential trip displacement distribution. However, due to the\necological fallacy issue, the movement of an individual may not obey the same\ndistance decay effect. We also construct a spatial network where the edge\nweights denote the interaction strengths. The communities detected from the\nnetwork are spatially connected and roughly consistent with province\nboundaries. We attribute this pattern to different distance decay parameters\nbetween intra-province and inter-province trips.\n", "Comment: 20 pages, 10 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.0282"}}, {"publisher": {"name": ""}, "description": "  In a recent series of papers a surprisingly strong connection was discovered\nbetween standard models of evolution in mathematical biology and Multiplicative\nWeights Updates Algorithm, a ubiquitous model of online learning and\noptimization. These papers establish that mathematical models of biological\nevolution are tantamount to applying discrete Multiplicative Weights Updates\nAlgorithm, a close variant of MWUA, on coordination games. This connection\nallows for introducing insights from the study of game theoretic dynamics into\nthe field of mathematical biology. Using these results as a stepping stone, we\nshow that mathematical models of haploid evolution imply the extinction of\ngenetic diversity in the long term limit, a widely believed conjecture in\ngenetics. In game theoretic terms we show that in the case of coordination\ngames, under minimal genericity assumptions, discrete MWUA converges to pure\nNash equilibria for all but a zero measure of initial conditions. This result\nholds despite the fact that mixed Nash equilibria can be exponentially (or even\nuncountably) many, completely dominating in number the set of pure Nash\nequilibria. Thus, in haploid organisms the long term preservation of genetic\ndiversity needs to be safeguarded by other evolutionary mechanisms such as\nmutations and speciation.\n", "contributors": [{"name": "Mehta, Ruta", "sameAs": [], "familyName": "Mehta", "additionalName": "", "givenName": "Ruta", "email": ""}, {"name": "Panageas, Ioannis", "sameAs": [], "familyName": "Panageas", "additionalName": "", "givenName": "Ioannis", "email": ""}, {"name": "Piliouras, Georgios", "sameAs": [], "familyName": "Piliouras", "additionalName": "", "givenName": "Georgios", "email": ""}], "title": "Natural Selection as an Inhibitor of Genetic Diversity: Multiplicative\n  Weights Updates Algorithm and a Conjecture of Haploid Genetics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-26", "2014-10-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6270", "oai:arXiv.org:1408.6270"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "q-bio"]}}, {"name": "description", "properties": {"description": ["  In a recent series of papers a surprisingly strong connection was discovered\nbetween standard models of evolution in mathematical biology and Multiplicative\nWeights Updates Algorithm, a ubiquitous model of online learning and\noptimization. These papers establish that mathematical models of biological\nevolution are tantamount to applying discrete Multiplicative Weights Updates\nAlgorithm, a close variant of MWUA, on coordination games. This connection\nallows for introducing insights from the study of game theoretic dynamics into\nthe field of mathematical biology. Using these results as a stepping stone, we\nshow that mathematical models of haploid evolution imply the extinction of\ngenetic diversity in the long term limit, a widely believed conjecture in\ngenetics. In game theoretic terms we show that in the case of coordination\ngames, under minimal genericity assumptions, discrete MWUA converges to pure\nNash equilibria for all but a zero measure of initial conditions. This result\nholds despite the fact that mixed Nash equilibria can be exponentially (or even\nuncountably) many, completely dominating in number the set of pure Nash\nequilibria. Thus, in haploid organisms the long term preservation of genetic\ndiversity needs to be safeguarded by other evolutionary mechanisms such as\nmutations and speciation.\n", "Comment: 18 pages, 1 figure"]}}], "languages": [null], "subjects": ["quantitative biology - quantitative methods", "computer science - computational engineering", "finance", "mathematics - dynamical systems", "and science"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6270"}}, {"publisher": {"name": ""}, "description": "  XML-based communication governs most of today's systems communication, due to\nits capability of representing complex structural and hierarchical data.\nHowever, XML document structure is considered a huge and bulky data that can be\nreduced to minimize bandwidth usage, transmission time, and maximize\nperformance. This contributes to a more efficient and utilized resource usage.\nIn cloud environments, this affects the amount of money the consumer pays.\nSeveral techniques are used to achieve this goal. This paper discusses these\ntechniques and proposes a new XML Schema-based Minification technique. The\nproposed technique works on XML Structure reduction using minification. The\nproposed technique provides a separation between the meaningful names and the\nunderlying minified names, which enhances software/code readability. This\ntechnique is applied to Intrusion Detection Message Exchange Format (IDMEF)\nmessages, as part of Security Information and Event Management (SIEM) system\ncommunication hosted on Microsoft Azure Cloud. Test results show message size\nreduction ranging from 8.15% to 50.34% in the raw message, without using\ntime-consuming compression techniques. Adding GZip compression to the proposed\ntechnique produces 66.1% shorter message size compared to original XML\nmessages.\n", "contributors": [{"name": "Moussa, Bishoy", "sameAs": [], "familyName": "Moussa", "additionalName": "", "givenName": "Bishoy", "email": ""}, {"name": "Mostafa, Mahmoud", "sameAs": [], "familyName": "Mostafa", "additionalName": "", "givenName": "Mahmoud", "email": ""}, {"name": "El-Khouly, Mahmoud", "sameAs": [], "familyName": "El-Khouly", "additionalName": "", "givenName": "Mahmoud", "email": ""}], "title": "XML Schema-based Minification for Communication of Security Information\n  and Event Management (SIEM) Systems in Cloud Environments", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2553", "International Journal of Advanced Computer Science and\n  Applications (IJACSA), 5(9), 2014", "doi:10.14569/IJACSA.2014.050912", "oai:arXiv.org:1410.2553"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  XML-based communication governs most of today's systems communication, due to\nits capability of representing complex structural and hierarchical data.\nHowever, XML document structure is considered a huge and bulky data that can be\nreduced to minimize bandwidth usage, transmission time, and maximize\nperformance. This contributes to a more efficient and utilized resource usage.\nIn cloud environments, this affects the amount of money the consumer pays.\nSeveral techniques are used to achieve this goal. This paper discusses these\ntechniques and proposes a new XML Schema-based Minification technique. The\nproposed technique works on XML Structure reduction using minification. The\nproposed technique provides a separation between the meaningful names and the\nunderlying minified names, which enhances software/code readability. This\ntechnique is applied to Intrusion Detection Message Exchange Format (IDMEF)\nmessages, as part of Security Information and Event Management (SIEM) system\ncommunication hosted on Microsoft Azure Cloud. Test results show message size\nreduction ranging from 8.15% to 50.34% in the raw message, without using\ntime-consuming compression techniques. Adding GZip compression to the proposed\ntechnique produces 66.1% shorter message size compared to original XML\nmessages.\n", "Comment: XML, JSON, Minification, XML Schema, Cloud, Log, Communication,\n  Compression, XMill, GZip, Code Generation, Code Readability, 9 pages, 12\n  figures, 5 tables, Journal Article"]}}], "languages": [null], "subjects": ["computer science - distributed", "computer science - networking and internet architecture", "parallel", "and cluster computing", "computer science - cryptography and security"], "providerUpdatedDateTime": "2014-10-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2553"}}, {"publisher": {"name": ""}, "description": "  We consider the problems of finding optimal identifying codes, (open)\nlocating-dominating sets and resolving sets (denoted IDENTIFYING CODE, (OPEN)\nLOCATING-DOMINATING SET and METRIC DIMENSION) of an interval or a permutation\ngraph. In these problems, one asks to distinguish all vertices of a graph by a\nsubset of the vertices, using either the neighbourhood within the solution set\nor the distances to the solution vertices. Using a general reduction for this\nclass of problems, we prove that the decision problems associated to these four\nnotions are NP-complete, even for graphs that are at the same time interval\ngraphs and permutation graphs and have diameter 2. While IDENTIFYING CODE and\n(OPEN) LOCATING-DOMINATING SET are trivially fixed-parameter-tractable when\nparameterized by solution size, it is known that in the same setting METRIC\nDIMENSION is W[2]-hard. We show that for interval graphs, this parameterization\nof METRIC DIMENSION is fixed-parameter-tractable.\n", "contributors": [{"name": "Foucaud, Florent", "sameAs": [], "familyName": "Foucaud", "additionalName": "", "givenName": "Florent", "email": ""}, {"name": "Mertzios, George B.", "sameAs": [], "familyName": "Mertzios", "additionalName": "B.", "givenName": "George", "email": ""}, {"name": "Naserasr, Reza", "sameAs": [], "familyName": "Naserasr", "additionalName": "", "givenName": "Reza", "email": ""}, {"name": "Parreau, Aline", "sameAs": [], "familyName": "Parreau", "additionalName": "", "givenName": "Aline", "email": ""}, {"name": "Valicov, Petru", "sameAs": [], "familyName": "Valicov", "additionalName": "", "givenName": "Petru", "email": ""}], "title": "Identification, location-domination and metric dimension on interval and\n  permutation graphs. II. Algorithms and complexity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-10", "2015-02-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.2424", "oai:arXiv.org:1405.2424"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider the problems of finding optimal identifying codes, (open)\nlocating-dominating sets and resolving sets (denoted IDENTIFYING CODE, (OPEN)\nLOCATING-DOMINATING SET and METRIC DIMENSION) of an interval or a permutation\ngraph. In these problems, one asks to distinguish all vertices of a graph by a\nsubset of the vertices, using either the neighbourhood within the solution set\nor the distances to the solution vertices. Using a general reduction for this\nclass of problems, we prove that the decision problems associated to these four\nnotions are NP-complete, even for graphs that are at the same time interval\ngraphs and permutation graphs and have diameter 2. While IDENTIFYING CODE and\n(OPEN) LOCATING-DOMINATING SET are trivially fixed-parameter-tractable when\nparameterized by solution size, it is known that in the same setting METRIC\nDIMENSION is W[2]-hard. We show that for interval graphs, this parameterization\nof METRIC DIMENSION is fixed-parameter-tractable.\n", "Comment: 22 pages, 8 figures. The new version contains a new algorithm. The\n  combinatorial bounds of the original version have been removed and will be\n  included in another paper"]}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.2424"}}, {"publisher": {"name": ""}, "description": "  The novel STEVE (i.e., Space-Time-Enclosing Volume Extraction) algorithm is\ndescribed here for the very first time. It generates iso-valued hypersurfaces\nthat may be implicitly contained in four-dimensional (4D) data sets, such as\ntemporal sequences of three-dimensional images from time-varying computed\ntomography. Any final hypersurface that will be generated by STEVE is\nguaranteed to be free from accidental rifts, i.e., it always fully encloses a\nregion in the 4D space under consideration. Furthermore, the information of the\ninterior/exterior of the enclosed regions is propagated to each one of the\ntetrahedrons, which are embedded into 4D and which in their union represent the\nfinal, iso-valued hypersurface(s). We argue that STEVE - while using a minimum\nof data redundancy in representing the final results - is faster than other\ntechniques that generate simplex-based manifolds of codimension 1.\n", "contributors": [{"name": "Schlei, B. R.", "sameAs": [], "familyName": "Schlei", "additionalName": "R.", "givenName": "B.", "email": ""}], "title": "STEVE - Space-Time-Enclosing Volume Extraction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-02-22", "2015-02-23"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1302.5683", "oai:arXiv.org:1302.5683"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The novel STEVE (i.e., Space-Time-Enclosing Volume Extraction) algorithm is\ndescribed here for the very first time. It generates iso-valued hypersurfaces\nthat may be implicitly contained in four-dimensional (4D) data sets, such as\ntemporal sequences of three-dimensional images from time-varying computed\ntomography. Any final hypersurface that will be generated by STEVE is\nguaranteed to be free from accidental rifts, i.e., it always fully encloses a\nregion in the 4D space under consideration. Furthermore, the information of the\ninterior/exterior of the enclosed regions is propagated to each one of the\ntetrahedrons, which are embedded into 4D and which in their union represent the\nfinal, iso-valued hypersurface(s). We argue that STEVE - while using a minimum\nof data redundancy in representing the final results - is faster than other\ntechniques that generate simplex-based manifolds of codimension 1.\n", "Comment: 16 pages, 26 figures, 1 table"]}}], "languages": [null], "subjects": ["computer science - graphics", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1302.5683"}}, {"publisher": {"name": ""}, "description": "  Random tilings are interesting as idealizations of atomistic models of\nquasicrystals and for their connection to problems in combinatorics and\nalgorithms. Of particular interest is the tiling entropy density, which\nmeasures the relation of the number of distinct tilings to the number of\nconstituent tiles. Tilings by squares and 45 degree rhombi receive special\nattention as presumably the simplest model that has not yet been solved exactly\nin the thermodynamic limit. However, an exact enumeration formula can be\nevaluated for tilings in finite regions with fixed boundaries. We implement\nthis algorithm in an efficient manner, enabling the investigation of larger\nregions of parameter space than previously were possible. Our new results\nappear to yield monotone increasing and decreasing lower and upper bounds on\nthe fixed boundary entropy density that converge toward S = 0.36021(3).\n", "contributors": [{"name": "Hutchinson, Maxwell", "sameAs": [], "familyName": "Hutchinson", "additionalName": "", "givenName": "Maxwell", "email": ""}, {"name": "Widom, Michael", "sameAs": [], "familyName": "Widom", "additionalName": "", "givenName": "Michael", "email": ""}], "title": "Enumeration of octagonal tilings", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-24", "2015-03-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.5977", "doi:10.1016/j.tcs.2015.03.019", "oai:arXiv.org:1306.5977"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:math-ph"]}}, {"name": "description", "properties": {"description": "  Random tilings are interesting as idealizations of atomistic models of\nquasicrystals and for their connection to problems in combinatorics and\nalgorithms. Of particular interest is the tiling entropy density, which\nmeasures the relation of the number of distinct tilings to the number of\nconstituent tiles. Tilings by squares and 45 degree rhombi receive special\nattention as presumably the simplest model that has not yet been solved exactly\nin the thermodynamic limit. However, an exact enumeration formula can be\nevaluated for tilings in finite regions with fixed boundaries. We implement\nthis algorithm in an efficient manner, enabling the investigation of larger\nregions of parameter space than previously were possible. Our new results\nappear to yield monotone increasing and decreasing lower and upper bounds on\nthe fixed boundary entropy density that converge toward S = 0.36021(3).\n"}}], "languages": [null], "subjects": ["mathematical physics", "computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.5977"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose opportunistic interference alignment (OIA) schemes\nfor three-transmitter multiple-input multiple-output (MIMO) interference\nchannels (ICs). In the proposed OIA, each transmitter has its own user group\nand selects a single user who has the most aligned interference signals. The\nuser dimensions provided by multiple users are exploited to align interfering\nsignals. Contrary to conventional IA, perfect channel state information of all\nchannel links is not required at the transmitter, and each user just feeds back\none scalar value to indicate how well the interfering channels are aligned. We\nprove that each transmitter can achieve the same degrees of freedom (DoF) as\nthe interference free case via user selection in our system model that the\nnumber of receive antennas is twice of the number of transmit antennas. Using\nthe geometric interpretation, we find the required user scaling to obtain an\narbitrary non-zero DoF. Two OIA schemes are proposed and compared with various\nuser selection schemes in terms of achievable rate/DoF and complexity.\n", "contributors": [{"name": "Lee, Jung Hoon", "sameAs": [], "familyName": "Lee", "additionalName": "Hoon", "givenName": "Jung", "email": ""}, {"name": "Choi, Wan", "sameAs": [], "familyName": "Choi", "additionalName": "", "givenName": "Wan", "email": ""}], "title": "On the Achievable DoF and User Scaling Law of Opportunistic Interference\n  Alignment in 3-Transmitter MIMO Interference Channels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-09-29", "2013-03-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.6541", "doi:10.1109/TWC.2013.041713.120773", "oai:arXiv.org:1109.6541"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we propose opportunistic interference alignment (OIA) schemes\nfor three-transmitter multiple-input multiple-output (MIMO) interference\nchannels (ICs). In the proposed OIA, each transmitter has its own user group\nand selects a single user who has the most aligned interference signals. The\nuser dimensions provided by multiple users are exploited to align interfering\nsignals. Contrary to conventional IA, perfect channel state information of all\nchannel links is not required at the transmitter, and each user just feeds back\none scalar value to indicate how well the interfering channels are aligned. We\nprove that each transmitter can achieve the same degrees of freedom (DoF) as\nthe interference free case via user selection in our system model that the\nnumber of receive antennas is twice of the number of transmit antennas. Using\nthe geometric interpretation, we find the required user scaling to obtain an\narbitrary non-zero DoF. Two OIA schemes are proposed and compared with various\nuser selection schemes in terms of achievable rate/DoF and complexity.\n", "Comment: To appear in IEEE Transactions on Wireless Communications"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.6541"}}, {"publisher": {"name": ""}, "description": "  A self-organization of efficient and robust networks is important for a\nfuture design of communication or transportation systems, however both\ncharacteristics are incompatible in many real networks. Recently, it has been\nfound that the robustness of onion-like structure with positive degree-degree\ncorrelations is optimal against intentional attacks. We show that, by\nbiologically inspired copying, an onion-like network emerges in the incremental\ngrowth with functions of proxy access and reinforced connectivity on a space.\nThe proposed network consists of the backbone of tree-like structure by\ncopyings and the periphery by adding shortcut links between low degree nodes to\nenhance the connectivity. It has the fine properties of the statistically\nself-averaging unlike the conventional duplication-divergence model,\nexponential-like degree distribution without overloaded hubs, strong robustness\nagainst both malicious attacks and random failures, and the efficiency with\nshort paths counted by the number of hops as mediators and by the Euclidean\ndistances. The adaptivity to heal over and to recover the performance of\nnetworking is also discussed for a change of environment in such disasters or\nbattlefields on a geographical map. These properties will be useful for a\nresilient and scalable infrastructure of network systems even in emergent\nsituations or poor environments.\n", "contributors": [{"name": "Hayashi, Yukio", "sameAs": [], "familyName": "Hayashi", "additionalName": "", "givenName": "Yukio", "email": ""}], "title": "Growing Self-organized Design of Efficient and Robust Complex Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7719", "doi:10.1109/SASO.2014.17", "oai:arXiv.org:1411.7719"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:nlin", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  A self-organization of efficient and robust networks is important for a\nfuture design of communication or transportation systems, however both\ncharacteristics are incompatible in many real networks. Recently, it has been\nfound that the robustness of onion-like structure with positive degree-degree\ncorrelations is optimal against intentional attacks. We show that, by\nbiologically inspired copying, an onion-like network emerges in the incremental\ngrowth with functions of proxy access and reinforced connectivity on a space.\nThe proposed network consists of the backbone of tree-like structure by\ncopyings and the periphery by adding shortcut links between low degree nodes to\nenhance the connectivity. It has the fine properties of the statistically\nself-averaging unlike the conventional duplication-divergence model,\nexponential-like degree distribution without overloaded hubs, strong robustness\nagainst both malicious attacks and random failures, and the efficiency with\nshort paths counted by the number of hops as mediators and by the Euclidean\ndistances. The adaptivity to heal over and to recover the performance of\nnetworking is also discussed for a change of environment in such disasters or\nbattlefields on a geographical map. These properties will be useful for a\nresilient and scalable infrastructure of network systems even in emergent\nsituations or poor environments.\n", "Comment: 10 pages, 14 figures, 3 tables, Proc. of 2014 IEEE 8th Int. Conf. on\n  Self-Adaptive and Self-Organizing Systems, pp.50-59"]}}], "languages": [null], "subjects": ["physics - physics and society", "nonlinear sciences - adaptation and self-organizing systems", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-12-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7719"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Uncertainty in travel time is one of the key factors that could allow us to understand and manage congestion in transportation networks. Models that incorporate uncertainty in travel time need to specify two mechanisms: the mechanism through which travel time uncertainty is generated and the mechanism through which travel time uncertainty influences users' behavior. Existing traffic equilibrium models are not sufficient in capturing these two mechanisms in an integrated way. This thesis proposes a new stochastic traffic equilibrium model that incorporates travel time uncertainty in an integrated manner. We focus on how uncertainty in travel time induces uncertainty in the traffic flow and vice versa. Travelers independently make probabilistic path choice decisions, inducing stochastic traffic flows in the network, which in turn result in uncertain travel times. Our model, based on the distribution of the travel time, uses the mean-variance approach in order to evaluate travelers' travel times and subsequently induce a stochastic traffic equilibrium flow pattern. In this thesis, we also examine when the new model we present has a solution as well as when the solution is unique. We discuss algorithms for solving this new model, and compare the model with existing traffic equilibrium models in the literature. We find that existing models tend to overestimate traffic flows on links with high travel time variance-to-mean ratios. To benchmark the various traffic network equilibrium models in the literature relative to the model we introduce, we investigate the total system cost, namely the total travel time in the network, for all these models. We prove three bounds that allow us to compare the system cost for the new model relative to existing models. We discuss the tightness of these bounds but also test them through numerical experimentation on test networks.", "contributors": [{"name": "Chen, Daizhuo", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Daizhuo", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "Georgia Perakis.", "sameAs": [], "familyName": "Perakis.", "additionalName": "", "givenName": "Georgia", "email": ""}], "title": "Modeling travel time uncertainty in traffic networks", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "154 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/61889", "706802887", "oai:dspace.mit.edu:1721.1/61889"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2011-03-24T20:22:12Z", "2011-03-24T20:22:12Z", "2010", "2010"]}}, {"name": "description", "properties": {"description": ["Uncertainty in travel time is one of the key factors that could allow us to understand and manage congestion in transportation networks. Models that incorporate uncertainty in travel time need to specify two mechanisms: the mechanism through which travel time uncertainty is generated and the mechanism through which travel time uncertainty influences users' behavior. Existing traffic equilibrium models are not sufficient in capturing these two mechanisms in an integrated way. This thesis proposes a new stochastic traffic equilibrium model that incorporates travel time uncertainty in an integrated manner. We focus on how uncertainty in travel time induces uncertainty in the traffic flow and vice versa. Travelers independently make probabilistic path choice decisions, inducing stochastic traffic flows in the network, which in turn result in uncertain travel times. Our model, based on the distribution of the travel time, uses the mean-variance approach in order to evaluate travelers' travel times and subsequently induce a stochastic traffic equilibrium flow pattern. In this thesis, we also examine when the new model we present has a solution as well as when the solution is unique. We discuss algorithms for solving this new model, and compare the model with existing traffic equilibrium models in the literature. We find that existing models tend to overestimate traffic flows on links with high travel time variance-to-mean ratios. To benchmark the various traffic network equilibrium models in the literature relative to the model we introduce, we investigate the total system cost, namely the total travel time in the network, for all these models. We prove three bounds that allow us to compare the system cost for the new model relative to existing models. We discuss the tightness of these bounds but also test them through numerical experimentation on test networks.", "by Daizhuo Chen.", "Thesis (S.M.)--Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2010.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (p. 147-154)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39115", "hdl_1721.1_39117"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:18", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/61889"}}, {"publisher": {"name": ""}, "description": "  Multi-threading allows agents to pursue a heterogeneous collection of tasks\nin an orderly manner. The view of multi-threading that emerges from thread\nalgebra is applied to the case where a single agent, who may be human,\nmaintains a hierarchical multithread as an architecture of its own activities.\n", "contributors": [{"name": "Bergstra, Jan A.", "sameAs": [], "familyName": "Bergstra", "additionalName": "A.", "givenName": "Jan", "email": ""}], "title": "Personal Multi-threading", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3579", "oai:arXiv.org:1412.3579"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Multi-threading allows agents to pursue a heterogeneous collection of tasks\nin an orderly manner. The view of multi-threading that emerges from thread\nalgebra is applied to the case where a single agent, who may be human,\nmaintains a hierarchical multithread as an architecture of its own activities.\n"}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3579"}}, {"publisher": {"name": ""}, "description": "  In recent years the effectiveness of interactive theorem provers has\nincreased to an extent that the bottleneck in the interactive process shifted\nto efficiency: while in principle large and complex theorems are provable\n(effectiveness), it takes a lot of effort for the user interacting with the\nsystem (lack of efficiency). We conducted focus groups to evaluate the\nusability of Isabelle/HOL and the KeY system with two goals: (a) detect\nusability issues in the interaction between interactive theorem provers and\ntheir user, and (b) analyze how evaluation and survey methods commonly used in\nthe area of human-computer interaction, such as focus groups and co-operative\nevaluation, are applicable to the specific field of interactive theorem proving\n(ITP).\n  In this paper, we report on our experience using the evaluation method focus\ngroups and how we adapted this method to ITP. We describe our results and\nconclusions mainly on the \"meta-level,\" i.e., we focus on the impact that\nspecific characteristics of ITPs have on the setup and the results of focus\ngroups. On the concrete level, we briefly summarise insights into the usability\nof the ITPs used in our case study.\n", "contributors": [{"name": "Beckert, Bernhard", "sameAs": [], "familyName": "Beckert", "additionalName": "", "givenName": "Bernhard", "email": ""}, {"name": "Grebing, Sarah", "sameAs": [], "familyName": "Grebing", "additionalName": "", "givenName": "Sarah", "email": ""}, {"name": "B\u00f6hl, Florian", "sameAs": [], "familyName": "B\u00f6hl", "additionalName": "", "givenName": "Florian", "email": ""}], "title": "How to Put Usability into Focus: Using Focus Groups to Evaluate the\n  Usability of Interactive Theorem Provers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.8215", "EPTCS 167, 2014, pp. 4-13", "doi:10.4204/EPTCS.167.3", "oai:arXiv.org:1410.8215"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In recent years the effectiveness of interactive theorem provers has\nincreased to an extent that the bottleneck in the interactive process shifted\nto efficiency: while in principle large and complex theorems are provable\n(effectiveness), it takes a lot of effort for the user interacting with the\nsystem (lack of efficiency). We conducted focus groups to evaluate the\nusability of Isabelle/HOL and the KeY system with two goals: (a) detect\nusability issues in the interaction between interactive theorem provers and\ntheir user, and (b) analyze how evaluation and survey methods commonly used in\nthe area of human-computer interaction, such as focus groups and co-operative\nevaluation, are applicable to the specific field of interactive theorem proving\n(ITP).\n  In this paper, we report on our experience using the evaluation method focus\ngroups and how we adapted this method to ITP. We describe our results and\nconclusions mainly on the \"meta-level,\" i.e., we focus on the impact that\nspecific characteristics of ITPs have on the setup and the results of focus\ngroups. On the concrete level, we briefly summarise insights into the usability\nof the ITPs used in our case study.\n", "Comment: In Proceedings UITP 2014, arXiv:1410.7850"]}}], "languages": [null], "subjects": ["computer science - human-computer interaction", "computer science - logic in computer science"], "providerUpdatedDateTime": "2014-10-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.8215"}}, {"publisher": {"name": ""}, "description": "  WiMAX (Worldwide Interoperability for Microwave Access) technology has\nemerged in response to the increasing demand for multimedia services in the\ninternet broadband networks. WiMAX standard has defined five different\nscheduling services to meet the QoS (Quality of Service) requirement of\nmultimedia applications and this paper investigates one specific scheduling\nservice, i.e. UGS scheduling. In parallel, it was observed that in the\ndifference of the traditional quality assessment approaches, nowadays, current\nresearches are centered on the user perception of the quality, the existing\nscheduling approaches take into account the QoS, mobility and many other\nparameters, but do not consider the Quality of Experience (QoE). In order to\ncontrol the packet transmission rate so as to match with the minimum subjective\nrate requirements of each user and therefore reduce packet loss and delays, an\nefficient scheduling approach has been proposed in this paper. The solution has\nbeen implemented and evaluated in the WiMAX simulation platform developed based\non NS-2. Simulation results show that by applying various levels of MOS (Mean\nOpinion Score) the QoE provided to the users is enhanced in term of jitter,\npacket loss rate, throughput and delay.\n", "contributors": [{"name": "Anouari, Tarik", "sameAs": [], "familyName": "Anouari", "additionalName": "", "givenName": "Tarik", "email": ""}, {"name": "Haqiq, Abdelkrim", "sameAs": [], "familyName": "Haqiq", "additionalName": "", "givenName": "Abdelkrim", "email": ""}], "title": "An Improved UGS Scheduling with QoE Metrics in WiMAX Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5944", "(IJCSIS) International Journal of Computer Science and Information\n  Security, Vol. 12, No. 9, September 2014", "oai:arXiv.org:1410.5944"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  WiMAX (Worldwide Interoperability for Microwave Access) technology has\nemerged in response to the increasing demand for multimedia services in the\ninternet broadband networks. WiMAX standard has defined five different\nscheduling services to meet the QoS (Quality of Service) requirement of\nmultimedia applications and this paper investigates one specific scheduling\nservice, i.e. UGS scheduling. In parallel, it was observed that in the\ndifference of the traditional quality assessment approaches, nowadays, current\nresearches are centered on the user perception of the quality, the existing\nscheduling approaches take into account the QoS, mobility and many other\nparameters, but do not consider the Quality of Experience (QoE). In order to\ncontrol the packet transmission rate so as to match with the minimum subjective\nrate requirements of each user and therefore reduce packet loss and delays, an\nefficient scheduling approach has been proposed in this paper. The solution has\nbeen implemented and evaluated in the WiMAX simulation platform developed based\non NS-2. Simulation results show that by applying various levels of MOS (Mean\nOpinion Score) the QoE provided to the users is enhanced in term of jitter,\npacket loss rate, throughput and delay.\n", "Comment: 6 pages, 8 figures"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-10-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5944"}}, {"publisher": {"name": ""}, "description": "  This paper considers the distributed consensus problem of multi-agent systems\nwith general continuous-time linear dynamics. Two distributed adaptive dynamic\nconsensus protocols are proposed, based on the relative output information of\nneighboring agents. One protocol assigns an adaptive coupling weight to each\nedge in the communication graph while the other uses an adaptive coupling\nweight for each node. These two adaptive protocols are designed to ensure that\nconsensus is reached in a fully distributed fashion for any undirected\nconnected communication graphs without using any global information. A\nsufficient condition for the existence of these adaptive protocols is that each\nagent is stabilizable and detectable. The cases with leader-follower and\nswitching communication graphs are also studied.\n", "contributors": [{"name": "Li, Zhongkui", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Zhongkui", "email": ""}, {"name": "Liu, Xiangdong", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Xiangdong", "email": ""}, {"name": "Ren, Wei", "sameAs": [], "familyName": "Ren", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Xie, Lihua", "sameAs": [], "familyName": "Xie", "additionalName": "", "givenName": "Lihua", "email": ""}], "title": "Distributed Consensus of Linear Multi-Agent Systems with Adaptive\n  Dynamic Protocols", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-09-17", "2011-09-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.3838", "Automatica, 49: 1986-1995, 2013", "doi:10.1016/j.automatica.2013.03.015", "oai:arXiv.org:1109.3838"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper considers the distributed consensus problem of multi-agent systems\nwith general continuous-time linear dynamics. Two distributed adaptive dynamic\nconsensus protocols are proposed, based on the relative output information of\nneighboring agents. One protocol assigns an adaptive coupling weight to each\nedge in the communication graph while the other uses an adaptive coupling\nweight for each node. These two adaptive protocols are designed to ensure that\nconsensus is reached in a fully distributed fashion for any undirected\nconnected communication graphs without using any global information. A\nsufficient condition for the existence of these adaptive protocols is that each\nagent is stabilizable and detectable. The cases with leader-follower and\nswitching communication graphs are also studied.\n", "Comment: 17 pages, 5 figues"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.3838"}}, {"publisher": {"name": ""}, "description": "  This paper advocates the use of the emerging distributed compressed sensing\n(DCS) paradigm to deploy energy harvesting (EH) wireless sensor networks (WSN)\nwith practical network lifetime and data gathering rates that are substantially\nhigher than the state-of-the-art. The basis of our work is a centralized EH WSN\narchitecture where the sensors convey data to a fusion center, using stylized\nmodels that capture the fact that the signals collected by different nodes can\nexhibit correlation and that the energy harvested by different nodes can also\nexhibit some degree of correlation. Via the probability of incorrect data\nreconstruction, we characterize the performance of both a compressive sensing\n(CS) and a DCS based approach to data acquisition and reconstruction. Moreover,\nwe perform an in-depth comparison of the proposed DCS based approach against a\nstate-of-the-art distributed source coding (DSC) system in terms of decoded\ndata distortion versus harvested energy. These performance characterizations\nand comparisons embody the effect of various system phenomena and parameters\nsuch as signal correlation, EH correlation, network size, and energy\navailability level. Our results unveil that, for an EH WSN consisting of eight\nSNs with our simple signal correlation and EH models, a target probability of\nincorrect reconstruction of $10^{-2}$, and under the same EH capability as CS,\nthe proposed approach allows for a six-fold increase in data gathering\ncapability with respect to the baseline CS-based approach. Moreover, under the\nsame energy harvested level, the proposed solution offers a substantial\nreduction of the mean-squared error distortion (up to 66.67\\%) with respect to\nthe state-of-the-art DSC system.\n", "contributors": [{"name": "Chen, Wei", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Deligiannis, Nikos", "sameAs": [], "familyName": "Deligiannis", "additionalName": "", "givenName": "Nikos", "email": ""}, {"name": "Andreopoulos, Yiannis", "sameAs": [], "familyName": "Andreopoulos", "additionalName": "", "givenName": "Yiannis", "email": ""}, {"name": "Wassell, Ian J.", "sameAs": [], "familyName": "Wassell", "additionalName": "J.", "givenName": "Ian", "email": ""}, {"name": "Rodrigues, Miguel R. D.", "sameAs": [], "familyName": "Rodrigues", "additionalName": "R. D.", "givenName": "Miguel", "email": ""}], "title": "Unlocking Energy Neutrality in Energy Harvesting Wireless Sensor\n  Networks: An Approach Based on Distributed Compressed Sensing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-15", "2015-01-31"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.4207", "oai:arXiv.org:1312.4207"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  This paper advocates the use of the emerging distributed compressed sensing\n(DCS) paradigm to deploy energy harvesting (EH) wireless sensor networks (WSN)\nwith practical network lifetime and data gathering rates that are substantially\nhigher than the state-of-the-art. The basis of our work is a centralized EH WSN\narchitecture where the sensors convey data to a fusion center, using stylized\nmodels that capture the fact that the signals collected by different nodes can\nexhibit correlation and that the energy harvested by different nodes can also\nexhibit some degree of correlation. Via the probability of incorrect data\nreconstruction, we characterize the performance of both a compressive sensing\n(CS) and a DCS based approach to data acquisition and reconstruction. Moreover,\nwe perform an in-depth comparison of the proposed DCS based approach against a\nstate-of-the-art distributed source coding (DSC) system in terms of decoded\ndata distortion versus harvested energy. These performance characterizations\nand comparisons embody the effect of various system phenomena and parameters\nsuch as signal correlation, EH correlation, network size, and energy\navailability level. Our results unveil that, for an EH WSN consisting of eight\nSNs with our simple signal correlation and EH models, a target probability of\nincorrect reconstruction of $10^{-2}$, and under the same EH capability as CS,\nthe proposed approach allows for a six-fold increase in data gathering\ncapability with respect to the baseline CS-based approach. Moreover, under the\nsame energy harvested level, the proposed solution offers a substantial\nreduction of the mean-squared error distortion (up to 66.67\\%) with respect to\nthe state-of-the-art DSC system.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.4207"}}, {"publisher": {"name": ""}, "description": "  We present a linear-time algorithm for deciding first-order (FO) properties\nin classes of graphs with bounded expansion, a notion recently introduced by\nNesetril and Ossona de Mendez. This generalizes several results from the\nliterature, because many natural classes of graphs have bounded expansion:\ngraphs of bounded tree-width, all proper minor-closed classes of graphs, graphs\nof bounded degree, graphs with no subgraph isomorphic to a subdivision of a\nfixed graph, and graphs that can be drawn in a fixed surface in such a way that\neach edge crosses at most a constant number of other edges. We deduce that\nthere is an almost linear-time algorithm for deciding FO properties in classes\nof graphs with locally bounded expansion.\n  More generally, we design a dynamic data structure for graphs belonging to a\nfixed class of graphs of bounded expansion. After a linear-time initialization\nthe data structure allows us to test an FO property in constant time, and the\ndata structure can be updated in constant time after addition/deletion of an\nedge, provided the list of possible edges to be added is known in advance and\ntheir simultaneous addition results in a graph in the class. All our results\nalso hold for relational structures and are based on the seminal result of\nNesetril and Ossona de Mendez on the existence of low tree-depth colorings.\n", "contributors": [{"name": "Dvorak, Zdenek", "sameAs": [], "familyName": "Dvorak", "additionalName": "", "givenName": "Zdenek", "email": ""}, {"name": "Kral, Daniel", "sameAs": [], "familyName": "Kral", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Thomas, Robin", "sameAs": [], "familyName": "Thomas", "additionalName": "", "givenName": "Robin", "email": ""}], "title": "Testing first-order properties for subclasses of sparse graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-09-23", "2013-01-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.5036", "oai:arXiv.org:1109.5036"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We present a linear-time algorithm for deciding first-order (FO) properties\nin classes of graphs with bounded expansion, a notion recently introduced by\nNesetril and Ossona de Mendez. This generalizes several results from the\nliterature, because many natural classes of graphs have bounded expansion:\ngraphs of bounded tree-width, all proper minor-closed classes of graphs, graphs\nof bounded degree, graphs with no subgraph isomorphic to a subdivision of a\nfixed graph, and graphs that can be drawn in a fixed surface in such a way that\neach edge crosses at most a constant number of other edges. We deduce that\nthere is an almost linear-time algorithm for deciding FO properties in classes\nof graphs with locally bounded expansion.\n  More generally, we design a dynamic data structure for graphs belonging to a\nfixed class of graphs of bounded expansion. After a linear-time initialization\nthe data structure allows us to test an FO property in constant time, and the\ndata structure can be updated in constant time after addition/deletion of an\nedge, provided the list of possible edges to be added is known in advance and\ntheir simultaneous addition results in a graph in the class. All our results\nalso hold for relational structures and are based on the seminal result of\nNesetril and Ossona de Mendez on the existence of low tree-depth colorings.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - logic in computer science", "computer science - discrete mathematics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.5036"}}, {"publisher": {"name": ""}, "description": "  Paper-by-paper results make it easy to miss the forest for the trees.We\nanalyse the remarkable progress of the last decade by discussing the main ideas\nexplored in the 40+ detectors currently present in the Caltech pedestrian\ndetection benchmark. We observe that there exist three families of approaches,\nall currently reaching similar detection quality. Based on our analysis, we\nstudy the complementarity of the most promising ideas by combining multiple\npublished strategies. This new decision forest detector achieves the current\nbest known performance on the challenging Caltech-USA dataset.\n", "contributors": [{"name": "Benenson, Rodrigo", "sameAs": [], "familyName": "Benenson", "additionalName": "", "givenName": "Rodrigo", "email": ""}, {"name": "Omran, Mohamed", "sameAs": [], "familyName": "Omran", "additionalName": "", "givenName": "Mohamed", "email": ""}, {"name": "Hosang, Jan", "sameAs": [], "familyName": "Hosang", "additionalName": "", "givenName": "Jan", "email": ""}, {"name": "Schiele, Bernt", "sameAs": [], "familyName": "Schiele", "additionalName": "", "givenName": "Bernt", "email": ""}], "title": "Ten Years of Pedestrian Detection, What Have We Learned?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4304", "oai:arXiv.org:1411.4304"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Paper-by-paper results make it easy to miss the forest for the trees.We\nanalyse the remarkable progress of the last decade by discussing the main ideas\nexplored in the 40+ detectors currently present in the Caltech pedestrian\ndetection benchmark. We observe that there exist three families of approaches,\nall currently reaching similar detection quality. Based on our analysis, we\nstudy the complementarity of the most promising ideas by combining multiple\npublished strategies. This new decision forest detector achieves the current\nbest known performance on the challenging Caltech-USA dataset.\n", "Comment: To appear in ECCV 2014 CVRSUAD workshop proceedings"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4304"}}, {"publisher": {"name": ""}, "description": "  In this paper, we consider vector space interference alignment strategies\nover the $K$-user interference channel and derive an upper bound on the\nachievable degrees of freedom as a function of the channel diversity $L$. The\nchannel diversity $L$ is modeled by $L$ independently fading real-valued\nparallel channels. Existing results in the literature for $K=3$ show that the\noptimal $1/2$ degrees of freedom per user can be approached at the speed of\n$1/L$ (i.e., the gap to $1/2$ degrees of freedom per user decreases inversely\nproportional to $L$). In this paper, we show that when $K\\geq4$, the speed of\nconvergence is significantly slower. In particular, the gap to $1/2$ degrees of\nfreedom per user can decrease at most like $1/\\sqrt{L}$. Furthermore, when $K$\nis of the order of $\\sqrt{\\log L}$, we show that the speed of convergence is\nsmaller than $1/\\sqrt[4]{L}$ .\n", "contributors": [{"name": "Li, Cheuk Ting", "sameAs": [], "familyName": "Li", "additionalName": "Ting", "givenName": "Cheuk", "email": ""}, {"name": "\u00d6zg\u00fcr, Ayfer", "sameAs": [], "familyName": "\u00d6zg\u00fcr", "additionalName": "", "givenName": "Ayfer", "email": ""}], "title": "Channel Diversity needed for Vector Interference Alignment", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-21", "2014-11-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.5326", "oai:arXiv.org:1402.5326"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we consider vector space interference alignment strategies\nover the $K$-user interference channel and derive an upper bound on the\nachievable degrees of freedom as a function of the channel diversity $L$. The\nchannel diversity $L$ is modeled by $L$ independently fading real-valued\nparallel channels. Existing results in the literature for $K=3$ show that the\noptimal $1/2$ degrees of freedom per user can be approached at the speed of\n$1/L$ (i.e., the gap to $1/2$ degrees of freedom per user decreases inversely\nproportional to $L$). In this paper, we show that when $K\\geq4$, the speed of\nconvergence is significantly slower. In particular, the gap to $1/2$ degrees of\nfreedom per user can decrease at most like $1/\\sqrt{L}$. Furthermore, when $K$\nis of the order of $\\sqrt{\\log L}$, we show that the speed of convergence is\nsmaller than $1/\\sqrt[4]{L}$ .\n", "Comment: 19 pages, 4 figures, short version presented at the International\n  Symposium on Information Theory 2014"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.5326"}}, {"publisher": {"name": ""}, "description": "  From the moment astronomical observations are made the resulting data\nproducts begin to grow stale. Even if perfect binary copies are preserved\nthrough repeated timely migration to more robust storage media, data standards\nevolve and new tools are created that require different kinds of data or\nmetadata. The expectations of the astronomical community change even if the\ndata do not. We discuss data engineering to mitigate the ensuing risks with\nexamples from a recent project to refactor seven million archival images to new\nstandards of nomenclature, metadata, format, and compression.\n", "contributors": [{"name": "Seaman, Rob", "sameAs": [], "familyName": "Seaman", "additionalName": "", "givenName": "Rob", "email": ""}], "title": "Data engineering for archive evolution", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.3481", "oai:arXiv.org:1410.3481"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:astro-ph"]}}, {"name": "description", "properties": {"description": ["  From the moment astronomical observations are made the resulting data\nproducts begin to grow stale. Even if perfect binary copies are preserved\nthrough repeated timely migration to more robust storage media, data standards\nevolve and new tools are created that require different kinds of data or\nmetadata. The expectations of the astronomical community change even if the\ndata do not. We discuss data engineering to mitigate the ensuing risks with\nexamples from a recent project to refactor seven million archival images to new\nstandards of nomenclature, metadata, format, and compression.\n", "Comment: 11 pages, this is a longer version of a poster paper submitted to the\n  proceedings of ADASS XXIV"]}}], "languages": [null], "subjects": ["computer science - digital libraries", "astrophysics - instrumentation and methods for astrophysics"], "providerUpdatedDateTime": "2014-10-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.3481"}}, {"publisher": {"name": ""}, "description": "  Titanium dioxide (TiO2) memristors exhibit complex conduction mechanism.\nSeveral models of different complexity have been developed in order to mimic\nthe experimental results for physical behaviors observed in memristor devices.\nPickett's tunneling barrier model describes the TiO2 memristors, and utilizes\ncomplex derivative of tunnel barrier width. It attains a large error in the ON\nswitching region. Variety of research consider it as the reference model for\nthe TiO2 memristors. In this paper, we first analyze the theory of operation of\nthe memristor and discuss Pickett's model. Then, we propose a modification to\nits derivative functions to provide a lower error and closer agreement with\nphysical behavior. This modification is represented by two additional fitting\nparameters to damp or accelerate the tunnel width derivative. Also, we\nincorporate a hard limiter term to limit the tunnel width to its physical\nextremes 1 nm and 2 nm. We run simulations to test the model modifications and\nwe compare the results to the experimental and original Pickett's model\nresults. The modified model more closely resembles the experimental behavior of\nTiO2 memristors and potentially enables the memristor to be used as a\nmultilevel memory.\n", "contributors": [{"name": "Daoud, Ahmad", "sameAs": [], "familyName": "Daoud", "additionalName": "", "givenName": "Ahmad", "email": ""}, {"name": "Dessouki, Ahmed", "sameAs": [], "familyName": "Dessouki", "additionalName": "", "givenName": "Ahmed", "email": ""}, {"name": "Abuelenin, Sherif", "sameAs": [], "familyName": "Abuelenin", "additionalName": "", "givenName": "Sherif", "email": ""}], "title": "Accuracy Enhancement of Pickett Tunnelling Barrier Memristor Model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07267", "oai:arXiv.org:1502.07267"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Titanium dioxide (TiO2) memristors exhibit complex conduction mechanism.\nSeveral models of different complexity have been developed in order to mimic\nthe experimental results for physical behaviors observed in memristor devices.\nPickett's tunneling barrier model describes the TiO2 memristors, and utilizes\ncomplex derivative of tunnel barrier width. It attains a large error in the ON\nswitching region. Variety of research consider it as the reference model for\nthe TiO2 memristors. In this paper, we first analyze the theory of operation of\nthe memristor and discuss Pickett's model. Then, we propose a modification to\nits derivative functions to provide a lower error and closer agreement with\nphysical behavior. This modification is represented by two additional fitting\nparameters to damp or accelerate the tunnel width derivative. Also, we\nincorporate a hard limiter term to limit the tunnel width to its physical\nextremes 1 nm and 2 nm. We run simulations to test the model modifications and\nwe compare the results to the experimental and original Pickett's model\nresults. The modified model more closely resembles the experimental behavior of\nTiO2 memristors and potentially enables the memristor to be used as a\nmultilevel memory.\n", "Comment: 5 pages, 5 figures, presented at the ICITACEE 2014 conference;\n  http://icitacee.undip.ac.id/index.php/icitacee/2014/paper/view/89"]}}], "languages": [null], "subjects": ["computer science - emerging technologies"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07267"}}, {"publisher": {"name": ""}, "description": "  In this contribution, a Bayes Ying Yang(BYY) harmony based approach for\non-line signature verification is presented. In the proposed method, a simple\nbut effective Gaussian Mixture Models(GMMs) is used to represent for each\nuser's signature model based on the prior information collected. Different from\nthe early works, in this paper, we use the Bayes Ying Yang machine combined\nwith the harmony function to achieve Automatic Model Selection(AMS) during the\nparameter learning for the GMMs, so that a better approximation of the user\nmodel is assured. Experiments on a database from the First International\nSignature Verification Competition(SVC 2004) confirm that this combined\nalgorithm yields quite satisfactory results.\n", "contributors": [{"name": "Zhao, Xiaosha", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Xiaosha", "email": ""}, {"name": "Liu, Mandan", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Mandan", "email": ""}], "title": "The application of the Bayes Ying Yang harmony based GMMs in on-line\n  signature verification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4205", "oai:arXiv.org:1412.4205"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this contribution, a Bayes Ying Yang(BYY) harmony based approach for\non-line signature verification is presented. In the proposed method, a simple\nbut effective Gaussian Mixture Models(GMMs) is used to represent for each\nuser's signature model based on the prior information collected. Different from\nthe early works, in this paper, we use the Bayes Ying Yang machine combined\nwith the harmony function to achieve Automatic Model Selection(AMS) during the\nparameter learning for the GMMs, so that a better approximation of the user\nmodel is assured. Experiments on a database from the First International\nSignature Verification Competition(SVC 2004) confirm that this combined\nalgorithm yields quite satisfactory results.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4205"}}, {"publisher": {"name": ""}, "description": "  We establish the conditions under which several algorithmically exploitable\nstructural features hold for random intersection graphs, a natural model for\nmany real-world networks where edges correspond to shared attributes.\nSpecifically, we fully characterize the degeneracy of random intersection\ngraphs, and prove that the model asymptotically almost surely produces graphs\nwith hyperbolicity at least $\\log{n}$. Further, we prove that when degenerate,\nthe graphs generated by this model belong to a bounded-expansion graph class\nwith high probability.\n", "contributors": [{"name": "Farrell, Matthew", "sameAs": [], "familyName": "Farrell", "additionalName": "", "givenName": "Matthew", "email": ""}, {"name": "Goodrich, Timothy", "sameAs": [], "familyName": "Goodrich", "additionalName": "", "givenName": "Timothy", "email": ""}, {"name": "Lemons, Nathan", "sameAs": [], "familyName": "Lemons", "additionalName": "", "givenName": "Nathan", "email": ""}, {"name": "Reidl, Felix", "sameAs": [], "familyName": "Reidl", "additionalName": "", "givenName": "Felix", "email": ""}, {"name": "Villaamil, Fernando S\u00e1nchez", "sameAs": [], "familyName": "Villaamil", "additionalName": "S\u00e1nchez", "givenName": "Fernando", "email": ""}, {"name": "Sullivan, Blair D.", "sameAs": [], "familyName": "Sullivan", "additionalName": "D.", "givenName": "Blair", "email": ""}], "title": "Hyperbolicity, degeneracy, and expansion of random intersection graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-29", "2015-03-09"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.8196", "oai:arXiv.org:1409.8196"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We establish the conditions under which several algorithmically exploitable\nstructural features hold for random intersection graphs, a natural model for\nmany real-world networks where edges correspond to shared attributes.\nSpecifically, we fully characterize the degeneracy of random intersection\ngraphs, and prove that the model asymptotically almost surely produces graphs\nwith hyperbolicity at least $\\log{n}$. Further, we prove that when degenerate,\nthe graphs generated by this model belong to a bounded-expansion graph class\nwith high probability.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.8196"}}, {"publisher": {"name": ""}, "description": "  Next generation cellular networks will be heterogeneous with dense deployment\nof small cells in order to deliver high data rate per unit area. Traffic\nvariations are more pronounced in a small cell, which in turn lead to more\ndynamic interference to other cells. It is crucial to adapt radio resource\nmanagement to traffic conditions in such a heterogeneous network (HetNet). This\npaper studies the optimization of spectrum allocation in HetNets on a\nrelatively slow timescale based on average traffic and channel conditions\n(typically over seconds or minutes). Specifically, in a cluster with $n$ base\ntransceiver stations (BTSs), the optimal partition of the spectrum into $2^n$\nsegments is determined, corresponding to all possible spectrum reuse patterns\nin the downlink. Each BTS's traffic is modeled using a queue with Poisson\narrivals, the service rate of which is a linear function of the combined\nbandwidth of all assigned spectrum segments. With the system average packet\nsojourn time as the objective, a convex optimization problem is first\nformulated, where it is shown that the optimal allocation divides the spectrum\ninto at most $n$ segments. A second, refined model is then proposed to address\nqueue interactions due to interference, where the corresponding optimal\nallocation problem admits an efficient suboptimal solution. Both allocation\nschemes attain the entire throughput region of a given network. Simulation\nresults show the two schemes perform similarly in the heavy-traffic regime, in\nwhich case they significantly outperform both the orthogonal allocation and the\nfull-frequency-reuse allocation. The refined allocation shows the best\nperformance under all traffic conditions.\n", "contributors": [{"name": "Zhuang, Binnan", "sameAs": [], "familyName": "Zhuang", "additionalName": "", "givenName": "Binnan", "email": ""}, {"name": "Guo, Dongning", "sameAs": [], "familyName": "Guo", "additionalName": "", "givenName": "Dongning", "email": ""}, {"name": "Honig, Michael L.", "sameAs": [], "familyName": "Honig", "additionalName": "L.", "givenName": "Michael", "email": ""}], "title": "Traffic-Driven Spectrum Allocation in Heterogeneous Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-26", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6011", "oai:arXiv.org:1408.6011"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Next generation cellular networks will be heterogeneous with dense deployment\nof small cells in order to deliver high data rate per unit area. Traffic\nvariations are more pronounced in a small cell, which in turn lead to more\ndynamic interference to other cells. It is crucial to adapt radio resource\nmanagement to traffic conditions in such a heterogeneous network (HetNet). This\npaper studies the optimization of spectrum allocation in HetNets on a\nrelatively slow timescale based on average traffic and channel conditions\n(typically over seconds or minutes). Specifically, in a cluster with $n$ base\ntransceiver stations (BTSs), the optimal partition of the spectrum into $2^n$\nsegments is determined, corresponding to all possible spectrum reuse patterns\nin the downlink. Each BTS's traffic is modeled using a queue with Poisson\narrivals, the service rate of which is a linear function of the combined\nbandwidth of all assigned spectrum segments. With the system average packet\nsojourn time as the objective, a convex optimization problem is first\nformulated, where it is shown that the optimal allocation divides the spectrum\ninto at most $n$ segments. A second, refined model is then proposed to address\nqueue interactions due to interference, where the corresponding optimal\nallocation problem admits an efficient suboptimal solution. Both allocation\nschemes attain the entire throughput region of a given network. Simulation\nresults show the two schemes perform similarly in the heavy-traffic regime, in\nwhich case they significantly outperform both the orthogonal allocation and the\nfull-frequency-reuse allocation. The refined allocation shows the best\nperformance under all traffic conditions.\n", "Comment: 13 pages, 11 figures, accepted for publication by JSAC-HCN"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6011"}}, {"publisher": {"name": ""}, "description": "  This paper presents a novel approach to including non-instantaneous discrete\ncontrol transitions in the linear hybrid automaton approach to simulation and\nverification of hybrid control systems. In this paper we study the control of a\ncontinuously evolving analog plant using a controller programmed in a\nsynchronous programming language. We provide extensions to the synchronous\nsubset of the SystemJ programming language for modeling, implementation, and\nverification of such hybrid systems. We provide a sound rewrite semantics that\napproximate the evolution of the continuous variables in the discrete domain\ninspired from the classical supervisory control theory. The resultant discrete\ntime model can be verified using classical model-checking tools. Finally, we\nshow that systems designed using our approach have a higher fidelity than the\nones designed using the hybrid automaton approach.\n", "contributors": [{"name": "Malik, Avinash", "sameAs": [], "familyName": "Malik", "additionalName": "", "givenName": "Avinash", "email": ""}, {"name": "Roop, Partha", "sameAs": [], "familyName": "Roop", "additionalName": "", "givenName": "Partha", "email": ""}], "title": "A unified framework for modeling and implementation of hybrid systems\n  with synchronous controllers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05936", "oai:arXiv.org:1501.05936"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper presents a novel approach to including non-instantaneous discrete\ncontrol transitions in the linear hybrid automaton approach to simulation and\nverification of hybrid control systems. In this paper we study the control of a\ncontinuously evolving analog plant using a controller programmed in a\nsynchronous programming language. We provide extensions to the synchronous\nsubset of the SystemJ programming language for modeling, implementation, and\nverification of such hybrid systems. We provide a sound rewrite semantics that\napproximate the evolution of the continuous variables in the discrete domain\ninspired from the classical supervisory control theory. The resultant discrete\ntime model can be verified using classical model-checking tools. Finally, we\nshow that systems designed using our approach have a higher fidelity than the\nones designed using the hybrid automaton approach.\n", "Comment: 16 pages"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - programming languages"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05936"}}, {"publisher": {"name": ""}, "description": "  The annotation of the results of database transformations was shown to be\nvery effective for various applications. Until recently, most works in this\ncontext focused on positive query languages. The provenance semirings is a\nparticular approach that was proven effective for these languages, and it was\nshown that when propagating provenance with semirings, the expected equivalence\naxioms of the corresponding query languages are satisfied. There have been\nseveral attempts to extend the framework to account for relational algebra\nqueries with difference. We show here that these suggestions fail to satisfy\nsome expected equivalence axioms (that in particular hold for queries on\n\"standard\" set and bag databases). Interestingly, we show that this is not a\npitfall of these particular attempts, but rather every such attempt is bound to\nfail in satisfying these axioms, for some semirings. Finally, we show\nparticular semirings for which an extension for supporting difference is\n(im)possible.\n", "contributors": [{"name": "Amsterdamer, Yael", "sameAs": [], "familyName": "Amsterdamer", "additionalName": "", "givenName": "Yael", "email": ""}, {"name": "Deutch, Daniel", "sameAs": [], "familyName": "Deutch", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Tannen, Val", "sameAs": [], "familyName": "Tannen", "additionalName": "", "givenName": "Val", "email": ""}], "title": "On the Limitations of Provenance for Queries With Difference", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.2255", "oai:arXiv.org:1105.2255"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The annotation of the results of database transformations was shown to be\nvery effective for various applications. Until recently, most works in this\ncontext focused on positive query languages. The provenance semirings is a\nparticular approach that was proven effective for these languages, and it was\nshown that when propagating provenance with semirings, the expected equivalence\naxioms of the corresponding query languages are satisfied. There have been\nseveral attempts to extend the framework to account for relational algebra\nqueries with difference. We show here that these suggestions fail to satisfy\nsome expected equivalence axioms (that in particular hold for queries on\n\"standard\" set and bag databases). Interestingly, we show that this is not a\npitfall of these particular attempts, but rather every such attempt is bound to\nfail in satisfying these axioms, for some semirings. Finally, we show\nparticular semirings for which an extension for supporting difference is\n(im)possible.\n", "Comment: TAPP 2011"]}}], "languages": [null], "subjects": ["computer science - databases"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.2255"}}, {"publisher": {"name": "Department of Computer Science, Columbia University"}, "description": "Discovering code clones in a runtime environment helps software engineers identify hard to find logic-based bugs. Yet most research in the area of code clone discovery deals with source code due to the complexity of finding clones in a\ndynamic environment. KAMINO manipulates Java bytecode to track control and data flow dependencies at the methodlevel of Java programs during runtime. It then matches similar flows to find semantic code clones. With positive preliminary\nresults indicating code clones using KAMINO , future tests will compare the its robustness compared to existing code clones detection tools.", "contributors": [{"name": "Neubauer, Lindsay Anne", "sameAs": [], "familyName": "Neubauer", "additionalName": "Anne", "givenName": "Lindsay", "email": ""}], "title": "Kamino: Dynamic Approach to Semantic Code Clone Detection", "shareProperties": {"source": "columbia"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014"}}, {"name": "identifier", "properties": {"identifier": ["http://dx.doi.org/10.7916/D8542M79", "academiccommons.columbia.edu/ac:179003"]}}, {"name": "setSpec", "properties": {"setSpec": []}}], "languages": [null], "subjects": ["computer science"], "providerUpdatedDateTime": "2014-10-27T18:49:56", "uris": {"canonicalUri": "http://dx.doi.org/10.7916/D8542M79"}}, {"publisher": {"name": ""}, "description": "  We study the dynamics of majority automata networks when the vertices are\nupdated according to a block sequential updating scheme. In particular, we show\nthat the complexity of the problem of predicting an eventual state change in\nsome vertex, given an initial configuration, is PSPACE-complete.\n", "contributors": [{"name": "Goles, Eric", "sameAs": [], "familyName": "Goles", "additionalName": "", "givenName": "Eric", "email": ""}, {"name": "Montealegre, Pedro", "sameAs": [], "familyName": "Montealegre", "additionalName": "", "givenName": "Pedro", "email": ""}, {"name": "Salo, Ville", "sameAs": [], "familyName": "Salo", "additionalName": "", "givenName": "Ville", "email": ""}, {"name": "T\u00f6rm\u00e4, Ilkka", "sameAs": [], "familyName": "T\u00f6rm\u00e4", "additionalName": "", "givenName": "Ilkka", "email": ""}], "title": "PSPACE-Completeness of Majority Automata Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.03992", "oai:arXiv.org:1501.03992"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study the dynamics of majority automata networks when the vertices are\nupdated according to a block sequential updating scheme. In particular, we show\nthat the complexity of the problem of predicting an eventual state change in\nsome vertex, given an initial configuration, is PSPACE-complete.\n", "Comment: 14 pages, 8 figures"]}}], "languages": [null], "subjects": ["68r10", "f.2.2", "computer science - discrete mathematics", "g.2.2"], "providerUpdatedDateTime": "2015-01-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.03992"}}, {"publisher": {"name": ""}, "description": "  Due to the fact that quality of service requirements are not very strict for\nall traffic types, more calls of higher priority can be accommodated by\nreducing some bandwidth allocation for the bandwidth adaptive calls. The\nbandwidth adaptation to accept a higher priority call is more than that of a\nlower priority call. Therefore, the multi-level bandwidth adaptation technique\nimproves the overall forced call termination probability as well as provides\npriority of the traffic classes in terms of call blocking probability without\nreducing the bandwidth utilization. We propose a novel bandwidth adaptation\nmodel that releases multi-level of bandwidth from the existing multimedia\ntraffic calls. The amount of released bandwidth is decided based on the\npriority of the requesting traffic calls and the number of existing bandwidth\nadaptive calls. This prioritization of traffic classes does not reduce the\nbandwidth utilization. Moreover, our scheme reduces the overall forced call\ntermination probability significantly. The proposed scheme is modeled using the\nMarkov Chain. The numerical results show that the proposed scheme is able to\nprovide negligible handover call dropping probability as well as significantly\nreduced new call blocking probability of higher priority calls without\nincreasing the overall forced call termination probability.\n", "contributors": [{"name": "Chowdhury, Mostafa Zaman", "sameAs": [], "familyName": "Chowdhury", "additionalName": "Zaman", "givenName": "Mostafa", "email": ""}, {"name": "Jang, Yeong Min", "sameAs": [], "familyName": "Jang", "additionalName": "Min", "givenName": "Yeong", "email": ""}], "title": "Class-Based Service Connectivity using Multi-Level Bandwidth Adaptation\n  in Multimedia Wireless Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3625", "Wireless Personal Communications, vol. 77, no 4, pp. 2735-2745,\n  August 2014", "doi:10.1007/s11277-014-1665-7", "oai:arXiv.org:1412.3625"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Due to the fact that quality of service requirements are not very strict for\nall traffic types, more calls of higher priority can be accommodated by\nreducing some bandwidth allocation for the bandwidth adaptive calls. The\nbandwidth adaptation to accept a higher priority call is more than that of a\nlower priority call. Therefore, the multi-level bandwidth adaptation technique\nimproves the overall forced call termination probability as well as provides\npriority of the traffic classes in terms of call blocking probability without\nreducing the bandwidth utilization. We propose a novel bandwidth adaptation\nmodel that releases multi-level of bandwidth from the existing multimedia\ntraffic calls. The amount of released bandwidth is decided based on the\npriority of the requesting traffic calls and the number of existing bandwidth\nadaptive calls. This prioritization of traffic classes does not reduce the\nbandwidth utilization. Moreover, our scheme reduces the overall forced call\ntermination probability significantly. The proposed scheme is modeled using the\nMarkov Chain. The numerical results show that the proposed scheme is able to\nprovide negligible handover call dropping probability as well as significantly\nreduced new call blocking probability of higher priority calls without\nincreasing the overall forced call termination probability.\n", "Comment: Journal paper"]}}], "languages": [null], "subjects": ["computer science - performance", "computer science - networking and internet architecture", "computer science - multimedia"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3625"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "This thesis presents a new simple lightweight C++ thread based parallelization library, intended for use in numerical algorithms. It provides simple multitasking and task synchronization functions. The library hides all internal system calls from the developer and utilizes thread pooling to provide better performance and utilization of system time and resources. The library is lightweight and platform independent, and has been tested on Linux, and Windows. Experiments were conducted to verify the proper functionality of the library and to show that parallelized algorithms on a single machine are more efficient than using the Message Passing Interface (MPI) using shared memory. In the opinion of several researchers who have used this library, the parallelized code is more easily understood and debugged than MPI. The results of initial experiments show that algorithms are as efficient or better than those using MPI.", "contributors": [{"name": "Alhubail, Maitham Makki", "sameAs": [], "familyName": "Alhubail", "additionalName": "Makki", "givenName": "Maitham", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "John R. Williams.", "sameAs": [], "familyName": "Williams.", "additionalName": "R.", "givenName": "John", "email": ""}], "title": "A thread-based parallel programming library for numerical algorithms", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "47 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/90080", "890141986", "oai:dspace.mit.edu:1721.1/90080"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2014-09-19T21:38:32Z", "2014-09-19T21:38:32Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["This thesis presents a new simple lightweight C++ thread based parallelization library, intended for use in numerical algorithms. It provides simple multitasking and task synchronization functions. The library hides all internal system calls from the developer and utilizes thread pooling to provide better performance and utilization of system time and resources. The library is lightweight and platform independent, and has been tested on Linux, and Windows. Experiments were conducted to verify the proper functionality of the library and to show that parallelized algorithms on a single machine are more efficient than using the Message Passing Interface (MPI) using shared memory. In the opinion of several researchers who have used this library, the parallelized code is more easily understood and debugged than MPI. The results of initial experiments show that algorithms are as efficient or better than those using MPI.", "by Maitham Makki Alhubail.", "Thesis: S.M., Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2014.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (page 47)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39117", "hdl_1721.1_39115"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:20", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/90080"}}, {"publisher": {"name": ""}, "description": "  Orthogonal greedy learning (OGL) is a stepwise learning scheme that adds a\nnew atom from a dictionary via the steepest gradient descent and build the\nestimator via orthogonal projecting the target function to the space spanned by\nthe selected atoms in each greedy step. Here, \"greed\" means choosing a new atom\naccording to the steepest gradient descent principle. OGL then avoids the\noverfitting/underfitting by selecting an appropriate iteration number. In this\npaper, we point out that the overfitting/underfitting can also be avoided via\nredefining \"greed\" in OGL. To this end, we introduce a new greedy metric,\ncalled $\\delta$-greedy thresholds, to refine \"greed\" and theoretically verifies\nits feasibility. Furthermore, we reveals that such a greedy metric can bring an\nadaptive termination rule on the premise of maintaining the prominent learning\nperformance of OGL. Our results show that the steepest gradient descent is not\nthe unique greedy metric of OGL and some other more suitable metric may lessen\nthe hassle of model-selection of OGL.\n", "contributors": [{"name": "Xu, Lin", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Lin", "email": ""}, {"name": "Lin, Shaobo", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Shaobo", "email": ""}, {"name": "Zeng, Jinshan", "sameAs": [], "familyName": "Zeng", "additionalName": "", "givenName": "Jinshan", "email": ""}, {"name": "Xu, Zongben", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Zongben", "email": ""}], "title": "Greedy metrics in orthogonal greedy learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3553", "oai:arXiv.org:1411.3553"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Orthogonal greedy learning (OGL) is a stepwise learning scheme that adds a\nnew atom from a dictionary via the steepest gradient descent and build the\nestimator via orthogonal projecting the target function to the space spanned by\nthe selected atoms in each greedy step. Here, \"greed\" means choosing a new atom\naccording to the steepest gradient descent principle. OGL then avoids the\noverfitting/underfitting by selecting an appropriate iteration number. In this\npaper, we point out that the overfitting/underfitting can also be avoided via\nredefining \"greed\" in OGL. To this end, we introduce a new greedy metric,\ncalled $\\delta$-greedy thresholds, to refine \"greed\" and theoretically verifies\nits feasibility. Furthermore, we reveals that such a greedy metric can bring an\nadaptive termination rule on the premise of maintaining the prominent learning\nperformance of OGL. Our results show that the steepest gradient descent is not\nthe unique greedy metric of OGL and some other more suitable metric may lessen\nthe hassle of model-selection of OGL.\n", "Comment: 33 pages, 8 figures"]}}], "languages": [null], "subjects": ["f.2.2", "computer science - learning"], "providerUpdatedDateTime": "2014-11-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3553"}}, {"publisher": {"name": ""}, "description": "  Caching data files directly on mobile user devices combined with\ndevice-to-device (D2D) communications has recently been suggested to improve\nthe capacity of wireless net6works. We investigate the performance of\nregenerating codes in terms of the total energy consumption of a cellular\nnetwork. We show that regenerating codes can offer large performance gains. It\nturns out that using redundancy against storage node failures is only\nbeneficial if the popularity of the data is between certain thresholds. As our\nmajor contribution, we investigate under which circumstances regenerating codes\nwith multiple redundant data fragments outdo uncoded caching.\n", "contributors": [{"name": "P\u00e4\u00e4kk\u00f6nen, Joonas", "sameAs": [], "familyName": "P\u00e4\u00e4kk\u00f6nen", "additionalName": "", "givenName": "Joonas", "email": ""}, {"name": "Hollanti, Camilla", "sameAs": [], "familyName": "Hollanti", "additionalName": "", "givenName": "Camilla", "email": ""}, {"name": "Tirkkonen, Olav", "sameAs": [], "familyName": "Tirkkonen", "additionalName": "", "givenName": "Olav", "email": ""}], "title": "Device-to-Device Data Storage with Regenerating Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1608", "oai:arXiv.org:1411.1608"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Caching data files directly on mobile user devices combined with\ndevice-to-device (D2D) communications has recently been suggested to improve\nthe capacity of wireless net6works. We investigate the performance of\nregenerating codes in terms of the total energy consumption of a cellular\nnetwork. We show that regenerating codes can offer large performance gains. It\nturns out that using redundancy against storage node failures is only\nbeneficial if the popularity of the data is between certain thresholds. As our\nmajor contribution, we investigate under which circumstances regenerating codes\nwith multiple redundant data fragments outdo uncoded caching.\n", "Comment: 6 pages, 8 figures"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1608"}}, {"publisher": {"name": ""}, "description": "  The Locator/ID Separation Protocol (LISP) limits the growth of the\nDefault-Free Zone routing tables by creating a highly aggregatable and\nquasi-static Internet core. However, LISP pushes the forwarding state to edge\nrouters whose timely operation relies on caching of location to identity\nbindings. In this paper we develop an analytical model to study the asymptotic\nscalability of the LISP cache. Under the assumptions that (i) long-term\npopularity can be modeled as a constant Generalized Zipf distribution and (ii)\ntemporal locality is predominantly determined by long-term popularity, we find\nthat the scalability of the LISP cache is O(1) with respect to the amount of\nprefixes (Internet growth) and users (growth of the LISP site). We validate the\nmodel and discuss the accuracy of our assumptions using several one-day-long\npacket traces.\n", "contributors": [{"name": "Coras, Florin", "sameAs": [], "familyName": "Coras", "additionalName": "", "givenName": "Florin", "email": ""}, {"name": "Domingo-Pascual, Jordi", "sameAs": [], "familyName": "Domingo-Pascual", "additionalName": "", "givenName": "Jordi", "email": ""}, {"name": "Cabellos-Aparicio, Albert", "sameAs": [], "familyName": "Cabellos-Aparicio", "additionalName": "", "givenName": "Albert", "email": ""}], "title": "On the Scalability of LISP Mappings Caches", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-04-12", "2015-04-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03004", "oai:arXiv.org:1504.03004"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The Locator/ID Separation Protocol (LISP) limits the growth of the\nDefault-Free Zone routing tables by creating a highly aggregatable and\nquasi-static Internet core. However, LISP pushes the forwarding state to edge\nrouters whose timely operation relies on caching of location to identity\nbindings. In this paper we develop an analytical model to study the asymptotic\nscalability of the LISP cache. Under the assumptions that (i) long-term\npopularity can be modeled as a constant Generalized Zipf distribution and (ii)\ntemporal locality is predominantly determined by long-term popularity, we find\nthat the scalability of the LISP cache is O(1) with respect to the amount of\nprefixes (Internet growth) and users (growth of the LISP site). We validate the\nmodel and discuss the accuracy of our assumptions using several one-day-long\npacket traces.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03004"}}, {"publisher": {"name": ""}, "description": "  Traditionally, there are three species of classification: unsupervised,\nsupervised, and semi-supervised. Supervised and semi-supervised classification\ndiffer by whether or not weight is given to unlabelled observations in the\nclassification procedure. In unsupervised classification, or clustering, no\nlabels are known and hence full weight is given to unlabelled observations. A\npriori, it can be very difficult to choose the optimal level of supervision,\nand the consequences of a sub-optimal choice can be non-trivial. A flexible\nfractionally-supervised approach to classification is introduced, where any\nlevel of supervision --- ranging from unsupervised to supervised --- can be\nattained. Our approach uses a weighted likelihood, wherein weights control the\nlevel of supervision. This paper investigates several choices for the\nspecification of these weights. Gaussian mixture models are used as a vehicle\nto illustrate our fractionally-supervised classification approach; however, it\nis broadly applicable and variations on the postulated model can easily be\nmade. A comparison between our approach and the traditional species is\npresented using simulated and real data.\n", "contributors": [{"name": "Vrbik, Irene", "sameAs": [], "familyName": "Vrbik", "additionalName": "", "givenName": "Irene", "email": ""}, {"name": "McNicholas, Paul D.", "sameAs": [], "familyName": "McNicholas", "additionalName": "D.", "givenName": "Paul", "email": ""}], "title": "Fractionally-Supervised Classification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-07-12", "2015-01-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1307.3598", "oai:arXiv.org:1307.3598"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  Traditionally, there are three species of classification: unsupervised,\nsupervised, and semi-supervised. Supervised and semi-supervised classification\ndiffer by whether or not weight is given to unlabelled observations in the\nclassification procedure. In unsupervised classification, or clustering, no\nlabels are known and hence full weight is given to unlabelled observations. A\npriori, it can be very difficult to choose the optimal level of supervision,\nand the consequences of a sub-optimal choice can be non-trivial. A flexible\nfractionally-supervised approach to classification is introduced, where any\nlevel of supervision --- ranging from unsupervised to supervised --- can be\nattained. Our approach uses a weighted likelihood, wherein weights control the\nlevel of supervision. This paper investigates several choices for the\nspecification of these weights. Gaussian mixture models are used as a vehicle\nto illustrate our fractionally-supervised classification approach; however, it\nis broadly applicable and variations on the postulated model can easily be\nmade. A comparison between our approach and the traditional species is\npresented using simulated and real data.\n"}}], "languages": [null], "subjects": ["statistics - applications", "statistics - computation", "statistics - methodology", "statistics - machine learning"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1307.3598"}}, {"publisher": {"name": ""}, "description": "  In order to address the imprecision often introduced by widening operators,\npolicy iteration based on min-computations amounts to consider the\ncharacterization of reachable states of a program as an iterative computation\nof policies, starting from a post-fixpoint. Computing each policy and the\nassociated invariant relies on a sequence of numerical optimizations. While the\nearly papers rely on LP to address linear properties of linear programs, the\ncurrent state of the art is still limited to the analysis of linear programs\nwith at most quadratic invariant, relying on Semi-Definite Programming (SDP)\nsolvers to compute the next policy, and LP solvers to solve the selected\npolicy.\n  We propose here to extend the class of programs considered through the use of\nSums-of-Squares (SOS) optimizations. Our approach enables the precise analysis\nof switched systems with polynomial assigns and guards. The analysis presented\nhas been implemented in Matlab and applied on existing programs, improving both\nthe set of systems analyzable and the precision of analyzed ones.\n", "contributors": [{"name": "Adj\u00e9, Assal\u00e9", "sameAs": [], "familyName": "Adj\u00e9", "additionalName": "", "givenName": "Assal\u00e9", "email": ""}, {"name": "Garoche, Pierre-Lo\u00efc", "sameAs": [], "familyName": "Garoche", "additionalName": "", "givenName": "Pierre-Lo\u00efc", "email": ""}, {"name": "Magron, Victor", "sameAs": [], "familyName": "Magron", "additionalName": "", "givenName": "Victor", "email": ""}], "title": "A Sums-of-Squares Extension of Policy Iterations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08090", "oai:arXiv.org:1503.08090"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In order to address the imprecision often introduced by widening operators,\npolicy iteration based on min-computations amounts to consider the\ncharacterization of reachable states of a program as an iterative computation\nof policies, starting from a post-fixpoint. Computing each policy and the\nassociated invariant relies on a sequence of numerical optimizations. While the\nearly papers rely on LP to address linear properties of linear programs, the\ncurrent state of the art is still limited to the analysis of linear programs\nwith at most quadratic invariant, relying on Semi-Definite Programming (SDP)\nsolvers to compute the next policy, and LP solvers to solve the selected\npolicy.\n  We propose here to extend the class of programs considered through the use of\nSums-of-Squares (SOS) optimizations. Our approach enables the precise analysis\nof switched systems with polynomial assigns and guards. The analysis presented\nhas been implemented in Matlab and applied on existing programs, improving both\nthe set of systems analyzable and the precision of analyzed ones.\n", "Comment: 20 pages, 1 figure"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - logic in computer science"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08090"}}, {"publisher": {"name": ""}, "description": "  In this paper, analytic relations between the macroscopic variables and the\nmesoscopic variables are derived for lattice Boltzmann methods (LBM). The\nanalytic relations are achieved by two different methods for the exchange from\nvelocity fields of finite-type methods to the single particle distribution\nfunctions of LBM. The numerical errors of reconstructing the single particle\ndistribution functions and the non-equilibrium distribution function by\nmacroscopic fields are investigated. Results show that their accuracy is better\nthan the existing ones. The proposed reconstruction operator has been used to\nimplement the coupling computations of LBM and macro-numerical methods of FVM.\nThe lid-driven cavity flow is chosen to carry out the coupling computations\nbased on the numerical strategies of domain decomposition methods (DDM). The\nnumerical results show that the proposed lifting relations are accurate and\nrobust.\n", "contributors": [{"name": "Xu, Hui", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Hui", "email": ""}, {"name": "Luan, Huibao", "sameAs": [], "familyName": "Luan", "additionalName": "", "givenName": "Huibao", "email": ""}, {"name": "He, Yaling", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Yaling", "email": ""}, {"name": "Tao, Wenquan", "sameAs": [], "familyName": "Tao", "additionalName": "", "givenName": "Wenquan", "email": ""}], "title": "A Lifting Relation from Macroscopic Variables to Mesoscopic Variables in\n  Lattice Boltzmann Method: Derivation, Numerical Assessments and Coupling\n  Computations Validation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-20", "2011-10-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.3958", "Computers and Fluids 54 (2012): 92-104", "doi:10.1016/j.compfluid.2011.10.007", "oai:arXiv.org:1104.3958"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": "  In this paper, analytic relations between the macroscopic variables and the\nmesoscopic variables are derived for lattice Boltzmann methods (LBM). The\nanalytic relations are achieved by two different methods for the exchange from\nvelocity fields of finite-type methods to the single particle distribution\nfunctions of LBM. The numerical errors of reconstructing the single particle\ndistribution functions and the non-equilibrium distribution function by\nmacroscopic fields are investigated. Results show that their accuracy is better\nthan the existing ones. The proposed reconstruction operator has been used to\nimplement the coupling computations of LBM and macro-numerical methods of FVM.\nThe lid-driven cavity flow is chosen to carry out the coupling computations\nbased on the numerical strategies of domain decomposition methods (DDM). The\nnumerical results show that the proposed lifting relations are accurate and\nrobust.\n"}}], "languages": [null], "subjects": ["physics - computational physics", "physics - fluid dynamics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.3958"}}, {"publisher": {"name": ""}, "description": "  The equation in the title describes the number of bright images of a point\nsource under lensing by an elliptic object with isothermal density. We prove\nthat this equation has at most 6 solutions. Any number of solutions from 1 to 6\ncan actually occur.\n", "contributors": [{"name": "Bergweiler, Walter", "sameAs": [], "familyName": "Bergweiler", "additionalName": "", "givenName": "Walter", "email": ""}, {"name": "Eremenko, Alexandre", "sameAs": [], "familyName": "Eremenko", "additionalName": "", "givenName": "Alexandre", "email": ""}], "title": "On the number of solutions of a transcendental equation arising in the\n  theory of gravitational lensing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2009-08-31", "2010-01-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/0908.4595", "Comput.Meth.Funct.Theory 10:303-324,2010", "oai:arXiv.org:0908.4595"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "physics:astro-ph", "physics:math-ph"]}}, {"name": "description", "properties": {"description": ["  The equation in the title describes the number of bright images of a point\nsource under lensing by an elliptic object with isothermal density. We prove\nthat this equation has at most 6 solutions. Any number of solutions from 1 to 6\ncan actually occur.\n", "Comment: 26 pages, 12 figures"]}}], "languages": [null], "subjects": ["astrophysics - cosmology and nongalactic astrophysics", "mathematical physics", "30e99", "85a99", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/0908.4595"}}, {"publisher": {"name": ""}, "description": "  We present a fixed point theorem for a class of (potentially) non-monotonic\nfunctions over specially structured complete lattices. The theorem has as a\nspecial case the Knaster-Tarski fixed point theorem when restricted to the case\nof monotonic functions and Kleene's theorem when the functions are additionally\ncontinuous. From the practical side, the theorem has direct applications in the\nsemantics of negation in logic programming. In particular, it leads to a more\ndirect and elegant proof of the least fixed point result of [Rondogiannis and\nW.W.Wadge, ACM TOCL 6(2): 441-467 (2005)]. Moreover, the theorem appears to\nhave potential for possible applications outside the logic programming domain.\n", "contributors": [{"name": "\u00c9sik, Zolt\u00e1n", "sameAs": [], "familyName": "\u00c9sik", "additionalName": "", "givenName": "Zolt\u00e1n", "email": ""}, {"name": "Rondogiannis, Panos", "sameAs": [], "familyName": "Rondogiannis", "additionalName": "", "givenName": "Panos", "email": ""}], "title": "A Fixed Point Theorem for Non-Monotonic Functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-03", "2015-02-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.0299", "oai:arXiv.org:1402.0299"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We present a fixed point theorem for a class of (potentially) non-monotonic\nfunctions over specially structured complete lattices. The theorem has as a\nspecial case the Knaster-Tarski fixed point theorem when restricted to the case\nof monotonic functions and Kleene's theorem when the functions are additionally\ncontinuous. From the practical side, the theorem has direct applications in the\nsemantics of negation in logic programming. In particular, it leads to a more\ndirect and elegant proof of the least fixed point result of [Rondogiannis and\nW.W.Wadge, ACM TOCL 6(2): 441-467 (2005)]. Moreover, the theorem appears to\nhave potential for possible applications outside the logic programming domain.\n", "Comment: 34 pages. Accepted in: Theoretical Computer Science (to appear)"]}}], "languages": [null], "subjects": ["mathematics - logic", "computer science - logic in computer science"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.0299"}}, {"publisher": {"name": ""}, "description": "  The word2vec model and application by Mikolov et al. have attracted a great\namount of attention in recent two years. The vector representations of words\nlearned by word2vec models have been proven to be able to carry semantic\nmeanings and are useful in various NLP tasks. As an increasing number of\nresearchers would like to experiment with word2vec, I notice that there lacks a\nmaterial that comprehensively explains the parameter learning process of\nword2vec in details, thus preventing many people with less neural network\nexperience from understanding how exactly word2vec works.\n  This note provides detailed derivations and explanations of the parameter\nupdate equations for the word2vec models, including the original continuous\nbag-of-word (CBOW) and skip-gram models, as well as advanced tricks,\nhierarchical soft-max and negative sampling. In the appendix a review is given\non the basics of neuron network models and backpropagation.\n", "contributors": [{"name": "Rong, Xin", "sameAs": [], "familyName": "Rong", "additionalName": "", "givenName": "Xin", "email": ""}], "title": "word2vec Parameter Learning Explained", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2738", "oai:arXiv.org:1411.2738"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The word2vec model and application by Mikolov et al. have attracted a great\namount of attention in recent two years. The vector representations of words\nlearned by word2vec models have been proven to be able to carry semantic\nmeanings and are useful in various NLP tasks. As an increasing number of\nresearchers would like to experiment with word2vec, I notice that there lacks a\nmaterial that comprehensively explains the parameter learning process of\nword2vec in details, thus preventing many people with less neural network\nexperience from understanding how exactly word2vec works.\n  This note provides detailed derivations and explanations of the parameter\nupdate equations for the word2vec models, including the original continuous\nbag-of-word (CBOW) and skip-gram models, as well as advanced tricks,\nhierarchical soft-max and negative sampling. In the appendix a review is given\non the basics of neuron network models and backpropagation.\n"}}], "languages": [null], "subjects": ["computer science - computation and language"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2738"}}, {"publisher": {"name": ""}, "description": "  We propose a new data-augmentation strategy for fully Bayesian inference in\nmodels with binomial likelihoods. The approach appeals to a new class of\nPolya-Gamma distributions, which are constructed in detail. A variety of\nexamples are presented to show the versatility of the method, including\nlogistic regression, negative binomial regression, nonlinear mixed-effects\nmodels, and spatial models for count data. In each case, our data-augmentation\nstrategy leads to simple, effective methods for posterior inference that: (1)\ncircumvent the need for analytic approximations, numerical integration, or\nMetropolis-Hastings; and (2) outperform other known data-augmentation\nstrategies, both in ease of use and in computational efficiency. All methods,\nincluding an efficient sampler for the Polya-Gamma distribution, are\nimplemented in the R package BayesLogit.\n  In the technical supplement appended to the end of the paper, we provide\nfurther details regarding the generation of Polya-Gamma random variables; the\nempirical benchmarks reported in the main manuscript; and the extension of the\nbasic data-augmentation framework to contingency tables and multinomial\noutcomes.\n", "contributors": [{"name": "Polson, Nicholas G.", "sameAs": [], "familyName": "Polson", "additionalName": "G.", "givenName": "Nicholas", "email": ""}, {"name": "Scott, James G.", "sameAs": [], "familyName": "Scott", "additionalName": "G.", "givenName": "James", "email": ""}, {"name": "Windle, Jesse", "sameAs": [], "familyName": "Windle", "additionalName": "", "givenName": "Jesse", "email": ""}], "title": "Bayesian inference for logistic models using Polya-Gamma latent\n  variables", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-05-01", "2013-07-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.0310", "oai:arXiv.org:1205.0310"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  We propose a new data-augmentation strategy for fully Bayesian inference in\nmodels with binomial likelihoods. The approach appeals to a new class of\nPolya-Gamma distributions, which are constructed in detail. A variety of\nexamples are presented to show the versatility of the method, including\nlogistic regression, negative binomial regression, nonlinear mixed-effects\nmodels, and spatial models for count data. In each case, our data-augmentation\nstrategy leads to simple, effective methods for posterior inference that: (1)\ncircumvent the need for analytic approximations, numerical integration, or\nMetropolis-Hastings; and (2) outperform other known data-augmentation\nstrategies, both in ease of use and in computational efficiency. All methods,\nincluding an efficient sampler for the Polya-Gamma distribution, are\nimplemented in the R package BayesLogit.\n  In the technical supplement appended to the end of the paper, we provide\nfurther details regarding the generation of Polya-Gamma random variables; the\nempirical benchmarks reported in the main manuscript; and the extension of the\nbasic data-augmentation framework to contingency tables and multinomial\noutcomes.\n"}}], "languages": [null], "subjects": ["statistics - computation", "statistics - methodology", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.0310"}}, {"publisher": {"name": "Institute of Electrical and Electronics Engineers"}, "description": "Abbreviation Completion is a novel technique to improve the efficiency of code-writing by supporting code completion of multiple keywords based on non-predefined abbreviated input - a different approach from conventional code completion that finds one keyword at a time based on an exact character match. Abbreviated input is expanded into keywords by a Hidden Markov Model learned from a corpus of existing code. The technique does not require the user to memorize abbreviations and provides incremental feedback of the most likely completions. This paper presents the algorithm for abbreviation completion, integrated with a new user interface for multiple-keyword completion. We tested the system by sampling 3000 code lines from open source projects and found that more than 98% of the code lines could be resolved from acronym-like abbreviations. A user study found 30% reduction in time usage and 41% reduction of keystrokes over conventional code completion.", "contributors": [{"name": "Miller, Robert C.", "sameAs": [], "familyName": "Miller", "additionalName": "C.", "givenName": "Robert", "email": ""}, {"name": "Han, Sangmok", "sameAs": [], "familyName": "Han", "additionalName": "", "givenName": "Sangmok", "email": ""}, {"name": "Wallace, David Robert", "sameAs": [], "familyName": "Wallace", "additionalName": "Robert", "givenName": "David", "email": ""}], "title": "Code Completion From Abbreviated Input", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": ["Article", "http://purl.org/eprint/type/JournalArticle"]}}, {"name": "source", "properties": {"source": "IEEE"}}, {"name": "format", "properties": {"format": []}}, {"name": "rights", "properties": {"rights": "Article is made available in accordance with the publisher's policy and may be subject to US copyright law. Please refer to the publisher's site for terms of use."}}, {"name": "identifier", "properties": {"identifier": ["978-1-4244-5259-0", "1527-1366", "INSPEC Accession Number: 11205136", "http://hdl.handle.net/1721.1/59377", "Sangmok Han, D.R. Wallace, and R.C. Miller. \u201cCode Completion from Abbreviated Input.\u201d Automated Software Engineering, 2009. ASE '09. 24th IEEE/ACM International Conference on. 2009. 332-343. \u00a9 2010 Institute of Electrical and Electronics Engineers.", "PUBLISHER_POLICY", "oai:dspace.mit.edu:1721.1/59377"]}}, {"name": "relation", "properties": {"relation": ["http://dx.doi.org/10.1109/ase.2009.64", "24th IEEE/ACM International Conference on Automated Software Engineering"]}}, {"name": "date", "properties": {"date": ["2010-10-15T15:48:31Z", "2010-10-15T15:48:31Z", "2010-03", "2009-11"]}}, {"name": "description", "properties": {"description": ["Abbreviation Completion is a novel technique to improve the efficiency of code-writing by supporting code completion of multiple keywords based on non-predefined abbreviated input - a different approach from conventional code completion that finds one keyword at a time based on an exact character match. Abbreviated input is expanded into keywords by a Hidden Markov Model learned from a corpus of existing code. The technique does not require the user to memorize abbreviations and provides incremental feedback of the most likely completions. This paper presents the algorithm for abbreviation completion, integrated with a new user interface for multiple-keyword completion. We tested the system by sampling 3000 code lines from open source projects and found that more than 98% of the code lines could be resolved from acronym-like abbreviations. A user study found 30% reduction in time usage and 41% reduction of keystrokes over conventional code completion.", "Samsung Scholarship Foundation"]}}, {"name": "setSpec", "properties": {"setSpec": "hdl_1721.1_49433"}}], "languages": [null], "subjects": ["code assistants", "abbreviation", "code completion", "multiple keywords", "data mining", "hidden markov model"], "providerUpdatedDateTime": "2015-03-20T19:26:03", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/59377"}}, {"publisher": {"name": ""}, "description": "  We compare variants of Anderson Mixing with the Jacobian-Free Newton-Krylov\nand Broyden methods applied to an instance of the k-eigenvalue formulation of\nthe linear Boltzmann transport equation. We present evidence that one variant\nof Anderson Mixing finds solutions in the fewest number of iterations. We\nexamine and strengthen theoretical results of Anderson Mixing applied to linear\nproblems.\n", "contributors": [{"name": "Calef, Matthew T.", "sameAs": [], "familyName": "Calef", "additionalName": "T.", "givenName": "Matthew", "email": ""}, {"name": "Fichtl, Erin D.", "sameAs": [], "familyName": "Fichtl", "additionalName": "D.", "givenName": "Erin", "email": ""}, {"name": "Warsa, James S.", "sameAs": [], "familyName": "Warsa", "additionalName": "S.", "givenName": "James", "email": ""}, {"name": "Berndt, Markus", "sameAs": [], "familyName": "Berndt", "additionalName": "", "givenName": "Markus", "email": ""}, {"name": "Carlson, Neil N.", "sameAs": [], "familyName": "Carlson", "additionalName": "N.", "givenName": "Neil", "email": ""}], "title": "Nonlinear Krylov Acceleration Applied to a Discrete Ordinates\n  Formulation of the k-Eigenvalue Problem", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-12-15", "2013-01-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1112.3568", "doi:10.1016/j.jcp.2012.12.024", "oai:arXiv.org:1112.3568"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": ["  We compare variants of Anderson Mixing with the Jacobian-Free Newton-Krylov\nand Broyden methods applied to an instance of the k-eigenvalue formulation of\nthe linear Boltzmann transport equation. We present evidence that one variant\nof Anderson Mixing finds solutions in the fewest number of iterations. We\nexamine and strengthen theoretical results of Anderson Mixing applied to linear\nproblems.\n", "Comment: This final revision includes results of the C5G7-MOX problem;\n  Nonlinear Krylov Acceleration Applied to a Discrete Ordinates Formulation of\n  the k-Eigenvalue Problem, Accepted by the Journal of Computational Physics\n  December 2012"]}}], "languages": [null], "subjects": ["physics - computational physics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1112.3568"}}, {"publisher": {"name": ""}, "description": "  The spread of ideas across a social network can be studied using complex\ncontagion models, in which agents are activated by contact with multiple\nactivated neighbors. The investigation of complex contagions can provide\ncrucial insights into social influence and behavior-adoption cascades on\nnetworks. In this paper, we introduce a model of a multi-stage complex\ncontagion on networks. Agents at different stages --- which could, for example,\nrepresent differing levels of support for a social movement or differing levels\nof commitment to a certain product or idea --- exert different amounts of\ninfluence on their neighbors. We demonstrate that the presence of even one\nadditional stage introduces novel dynamical behavior, including interplay\nbetween multiple cascades, that cannot occur in single-stage contagion models.\nWe find that cascades --- and hence collective action --- can be driven not\nonly by high-stage influencers but also by low-stage influencers.\n", "contributors": [{"name": "Melnik, Sergey", "sameAs": [], "familyName": "Melnik", "additionalName": "", "givenName": "Sergey", "email": ""}, {"name": "Ward, Jonathan A.", "sameAs": [], "familyName": "Ward", "additionalName": "A.", "givenName": "Jonathan", "email": ""}, {"name": "Gleeson, James P.", "sameAs": [], "familyName": "Gleeson", "additionalName": "P.", "givenName": "James", "email": ""}, {"name": "Porter, Mason A.", "sameAs": [], "familyName": "Porter", "additionalName": "A.", "givenName": "Mason", "email": ""}], "title": "Multi-Stage Complex Contagions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-07", "2013-02-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.1596", "Chaos 23, 013124 (2013)", "doi:10.1063/1.4790836", "oai:arXiv.org:1111.1596"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:nlin", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The spread of ideas across a social network can be studied using complex\ncontagion models, in which agents are activated by contact with multiple\nactivated neighbors. The investigation of complex contagions can provide\ncrucial insights into social influence and behavior-adoption cascades on\nnetworks. In this paper, we introduce a model of a multi-stage complex\ncontagion on networks. Agents at different stages --- which could, for example,\nrepresent differing levels of support for a social movement or differing levels\nof commitment to a certain product or idea --- exert different amounts of\ninfluence on their neighbors. We demonstrate that the presence of even one\nadditional stage introduces novel dynamical behavior, including interplay\nbetween multiple cascades, that cannot occur in single-stage contagion models.\nWe find that cascades --- and hence collective action --- can be driven not\nonly by high-stage influencers but also by low-stage influencers.\n", "Comment: 12 pages, 10 figures. This version is accepted to appear in Chaos"]}}], "languages": [null], "subjects": ["physics - physics and society", "nonlinear sciences - adaptation and self-organizing systems", "mathematics - dynamical systems", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.1596"}}, {"publisher": {"name": ""}, "description": "abstract: As we migrate into an era of personalized medicine, understanding how bio-molecules interact with one another to form cellular systems is one of the key focus areas of systems biology. Several challenges such as the dynamic nature of cellular systems, uncertainty due to environmental influences, and the heterogeneity between individual patients render this a difficult task. In the last decade, several algorithms have been proposed to elucidate cellular systems from data, resulting in numerous data-driven hypotheses. However, due to the large number of variables involved in the process, many of which are unknown or not measurable, such computational approaches often lead to a high proportion of false positives. This renders interpretation of the data-driven hypotheses extremely difficult. Consequently, a dismal proportion of these hypotheses are subject to further experimental validation, eventually limiting their potential to augment existing biological knowledge. This dissertation develops a framework of computational methods for the analysis of such data-driven hypotheses leveraging existing biological knowledge. Specifically, I show how biological knowledge can be mapped onto these hypotheses and subsequently augmented through novel hypotheses. Biological hypotheses are learnt in three levels of abstraction -- individual interactions, functional modules and relationships between pathways, corresponding to three complementary aspects of biological systems. The computational methods developed in this dissertation are applied to high throughput cancer data, resulting in novel hypotheses with potentially significant biological impact.", "contributors": [{"name": "Ramesh, Archana  (Author)", "sameAs": [], "familyName": "Ramesh", "additionalName": "", "givenName": "Archana", "email": ""}, {"name": "Kim, Seungchan  (Advisor)", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Seungchan", "email": ""}, {"name": "Langley, Patrick W (Committee member)", "sameAs": [], "familyName": "Langley", "additionalName": "W", "givenName": "Patrick", "email": ""}, {"name": "Baral, Chitta  (Committee member)", "sameAs": [], "familyName": "Baral", "additionalName": "", "givenName": "Chitta", "email": ""}, {"name": "Kiefer, Jeffrey  (Committee member)", "sameAs": [], "familyName": "Kiefer", "additionalName": "", "givenName": "Jeffrey", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Computational Methods for Knowledge Integration in the Analysis of Large-scale Biological Networks", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "130 pages"}}, {"name": "date", "properties": {"date": "2012"}}, {"name": "description", "properties": {"description": ["abstract: As we migrate into an era of personalized medicine, understanding how bio-molecules interact with one another to form cellular systems is one of the key focus areas of systems biology. Several challenges such as the dynamic nature of cellular systems, uncertainty due to environmental influences, and the heterogeneity between individual patients render this a difficult task. In the last decade, several algorithms have been proposed to elucidate cellular systems from data, resulting in numerous data-driven hypotheses. However, due to the large number of variables involved in the process, many of which are unknown or not measurable, such computational approaches often lead to a high proportion of false positives. This renders interpretation of the data-driven hypotheses extremely difficult. Consequently, a dismal proportion of these hypotheses are subject to further experimental validation, eventually limiting their potential to augment existing biological knowledge. This dissertation develops a framework of computational methods for the analysis of such data-driven hypotheses leveraging existing biological knowledge. Specifically, I show how biological knowledge can be mapped onto these hypotheses and subsequently augmented through novel hypotheses. Biological hypotheses are learnt in three levels of abstraction -- individual interactions, functional modules and relationships between pathways, corresponding to three complementary aspects of biological systems. The computational methods developed in this dissertation are applied to high throughput cancer data, resulting in novel hypotheses with potentially significant biological impact.", "Dissertation/Thesis", "Ph.D. Computer Science 2012"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.15204", "item:15204"]}}], "languages": [null], "subjects": ["microarray data", "bioinformatics", "knowledge integration", "computer science", "data mining", "machine learning", "gene regulatory networks", "artificial intelligence"], "providerUpdatedDateTime": "2015-02-12T01:13:51", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.15204"}}, {"publisher": {"name": ""}, "description": "  Interdependent networks are ubiquitous in our society, ranging from\ninfrastructure to economics, and the study of their cascading behaviors using\npercolation theory has attracted much attention in the recent years. To analyze\nthe percolation phenomena of these systems, different mathematical frameworks\nhave been proposed including generating functions, eigenvalues among some\nothers. These different frameworks approach the phase transition behaviors from\ndifferent angles, and have been very successful in shaping the different\nquantities of interest including critical threshold, size of the giant\ncomponent, order of phase transition and the dynamics of cascading. These\nmethods also vary in their mathematical complexity in dealing with\ninterdependent networks that have additional complexity in terms of the\ncorrelation among different layers of networks or links. In this work, we\nreview a particular approach of simple self-consistent probability equations,\nand illustrate that it can greatly simplify the mathematical analysis for\nsystems ranging from single layer network to various different interdependent\nnetworks. We give an overview on the detailed framework to study the nature of\nthe critical phase transition, value of the critical threshold and size of the\ngiant component for these different systems.\n", "contributors": [{"name": "Feng, Ling", "sameAs": [], "familyName": "Feng", "additionalName": "", "givenName": "Ling", "email": ""}, {"name": "Monterola, Christopher Pineda", "sameAs": [], "familyName": "Monterola", "additionalName": "Pineda", "givenName": "Christopher", "email": ""}, {"name": "Hu, Yanqing", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Yanqing", "email": ""}], "title": "A Simplified Self-Consistent Probabilities Framework to Characterize\n  Percolation Phenomena on Interdependent Networks : An Overview", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01601", "oai:arXiv.org:1502.01601"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Interdependent networks are ubiquitous in our society, ranging from\ninfrastructure to economics, and the study of their cascading behaviors using\npercolation theory has attracted much attention in the recent years. To analyze\nthe percolation phenomena of these systems, different mathematical frameworks\nhave been proposed including generating functions, eigenvalues among some\nothers. These different frameworks approach the phase transition behaviors from\ndifferent angles, and have been very successful in shaping the different\nquantities of interest including critical threshold, size of the giant\ncomponent, order of phase transition and the dynamics of cascading. These\nmethods also vary in their mathematical complexity in dealing with\ninterdependent networks that have additional complexity in terms of the\ncorrelation among different layers of networks or links. In this work, we\nreview a particular approach of simple self-consistent probability equations,\nand illustrate that it can greatly simplify the mathematical analysis for\nsystems ranging from single layer network to various different interdependent\nnetworks. We give an overview on the detailed framework to study the nature of\nthe critical phase transition, value of the critical threshold and size of the\ngiant component for these different systems.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "condensed matter - statistical mechanics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01601"}}, {"publisher": {"name": ""}, "description": "  We propose adaptation strategies to modify the standard constrained model\npredictive controller scheme in order to guarantee a certain lower bound on the\ndegree of suboptimality. Within this analysis, the length of the optimization\nhorizon is the parameter we wish to adapt. We develop and prove several\nshortening and prolongation strategies which also allow for an effective\nimplementation. Moreover, extensions of stability results and suboptimality\nestimates to model predictive controllers with varying optimization horizon are\nshown.\n", "contributors": [{"name": "Pannek, J\u00fcrgen", "sameAs": [], "familyName": "Pannek", "additionalName": "", "givenName": "J\u00fcrgen", "email": ""}], "title": "Horizon Adaptation for Nonlinear Model Predictive Controllers with\n  guaranteed Degree of Suboptimality", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.3037", "oai:arXiv.org:1105.3037"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We propose adaptation strategies to modify the standard constrained model\npredictive controller scheme in order to guarantee a certain lower bound on the\ndegree of suboptimality. Within this analysis, the length of the optimization\nhorizon is the parameter we wish to adapt. We develop and prove several\nshortening and prolongation strategies which also allow for an effective\nimplementation. Moreover, extensions of stability results and suboptimality\nestimates to model predictive controllers with varying optimization horizon are\nshown.\n", "Comment: 20 pages, 3 figures"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - systems and control"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.3037"}}, {"publisher": {"name": ""}, "description": "  Background: Confirmation bias is the tendency to acquire or evaluate new\ninformation in a way that is consistent with one's preexisting beliefs. It is\nomnipresent in psychology, economics, and even scientific practices. Prior\ntheoretical research of this phenomenon has mainly focused on its economic\nimplications possibly missing its potential connections with broader notions of\ncognitive science. Methodology/Principal Findings: We formulate a\n(non-Bayesian) model for revising subjective probabilistic opinion of a\nconfirmationally-biased agent in the light of a persuasive opinion. The\nrevision rule ensures that the agent does not react to persuasion that is\neither far from his current opinion or coincides with it. We demonstrate that\nthe model accounts for the basic phenomenology of the social judgment theory,\nand allows to study various phenomena such as cognitive dissonance and\nboomerang effect. The model also displays the order of presentation effect|when\nconsecutively exposed to two opinions, the preference is given to the last\nopinion (recency) or the first opinion (primacy)|and relates recency to\nconfirmation bias. Finally, we study the model in the case of repeated\npersuasion and analyze its convergence properties. Conclusions: The standard\nBayesian approach to probabilistic opinion revision is inadequate for\ndescribing the observed phenomenology of persuasion process. The simple\nnon-Bayesian model proposed here does agree with this phenomenology and is\ncapable of reproducing a spectrum of effects observed in psychology:\nprimacy-recency phenomenon, boomerang effect and cognitive dissonance. We point\nout several limitations of the model that should motivate its future\ndevelopment.\n", "contributors": [{"name": "Allahverdyan, A. E.", "sameAs": [], "familyName": "Allahverdyan", "additionalName": "E.", "givenName": "A.", "email": ""}, {"name": "Galstyan, Aram", "sameAs": [], "familyName": "Galstyan", "additionalName": "", "givenName": "Aram", "email": ""}], "title": "Opinion Dynamics with Confirmation Bias", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4328", "PLoS ONE 9(7), e99557 (2014)", "doi:10.1371/journal.pone.0099557", "oai:arXiv.org:1411.4328"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Background: Confirmation bias is the tendency to acquire or evaluate new\ninformation in a way that is consistent with one's preexisting beliefs. It is\nomnipresent in psychology, economics, and even scientific practices. Prior\ntheoretical research of this phenomenon has mainly focused on its economic\nimplications possibly missing its potential connections with broader notions of\ncognitive science. Methodology/Principal Findings: We formulate a\n(non-Bayesian) model for revising subjective probabilistic opinion of a\nconfirmationally-biased agent in the light of a persuasive opinion. The\nrevision rule ensures that the agent does not react to persuasion that is\neither far from his current opinion or coincides with it. We demonstrate that\nthe model accounts for the basic phenomenology of the social judgment theory,\nand allows to study various phenomena such as cognitive dissonance and\nboomerang effect. The model also displays the order of presentation effect|when\nconsecutively exposed to two opinions, the preference is given to the last\nopinion (recency) or the first opinion (primacy)|and relates recency to\nconfirmation bias. Finally, we study the model in the case of repeated\npersuasion and analyze its convergence properties. Conclusions: The standard\nBayesian approach to probabilistic opinion revision is inadequate for\ndescribing the observed phenomenology of persuasion process. The simple\nnon-Bayesian model proposed here does agree with this phenomenology and is\ncapable of reproducing a spectrum of effects observed in psychology:\nprimacy-recency phenomenon, boomerang effect and cognitive dissonance. We point\nout several limitations of the model that should motivate its future\ndevelopment.\n", "Comment: 18 pages"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4328"}}, {"publisher": {"name": ""}, "description": "  We study the problem of maximizing constrained non-monotone submodular\nfunctions and provide approximation algorithms that improve existing algorithms\nin terms of either the approximation factor or simplicity. Our algorithms\ncombine existing local search and greedy based algorithms. Different\nconstraints that we study are exact cardinality and multiple knapsack\nconstraints. For the multiple-knapsack constraints we achieve a\n$(0.25-2\\epsilon)$-factor algorithm.\n  We also show, as our main contribution, how to use the continuous greedy\nprocess for non-monotone functions and, as a result, obtain a 0.13-factor\napproximation algorithm for maximization over any solvable down-monotone\npolytope. The continuous greedy process has been previously used for maximizing\nsmooth monotone submodular function over a down-monotone polytope\n\\cite{CCPV08}. This implies a 0.13-approximation for several discrete problems,\nsuch as maximizing a non-negative submodular function subject to a matroid\nconstraint and/or multiple knapsack constraints.\n", "contributors": [{"name": "Fadaei, Salman", "sameAs": [], "familyName": "Fadaei", "additionalName": "", "givenName": "Salman", "email": ""}, {"name": "Fazli, MohammadAmin", "sameAs": [], "familyName": "Fazli", "additionalName": "", "givenName": "MohammadAmin", "email": ""}, {"name": "Safari, MohammadAli", "sameAs": [], "familyName": "Safari", "additionalName": "", "givenName": "MohammadAli", "email": ""}], "title": "Maximizing Non-monotone Submodular Set Functions Subject to Different\n  Constraints: Combined Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-15", "2011-07-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.2973", "oai:arXiv.org:1101.2973"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We study the problem of maximizing constrained non-monotone submodular\nfunctions and provide approximation algorithms that improve existing algorithms\nin terms of either the approximation factor or simplicity. Our algorithms\ncombine existing local search and greedy based algorithms. Different\nconstraints that we study are exact cardinality and multiple knapsack\nconstraints. For the multiple-knapsack constraints we achieve a\n$(0.25-2\\epsilon)$-factor algorithm.\n  We also show, as our main contribution, how to use the continuous greedy\nprocess for non-monotone functions and, as a result, obtain a 0.13-factor\napproximation algorithm for maximization over any solvable down-monotone\npolytope. The continuous greedy process has been previously used for maximizing\nsmooth monotone submodular function over a down-monotone polytope\n\\cite{CCPV08}. This implies a 0.13-approximation for several discrete problems,\nsuch as maximizing a non-negative submodular function subject to a matroid\nconstraint and/or multiple knapsack constraints.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.2973"}}, {"publisher": {"name": ""}, "description": "  This paper aims to present the different aspects and characteristics of\nstrategic and operational information and propose a categorization pattern\nallowing to consider an information as strategic or operational. This\ncategorization is to be used in the two decision making processes to assist its\nmining, and usage by the two related decision support systems. This is\nconducted trough the results of an investigative study of information used as\nbasis for strategic decisions inside three different companies.\n", "contributors": [{"name": "Abahmane, Omar", "sameAs": [], "familyName": "Abahmane", "additionalName": "", "givenName": "Omar", "email": ""}, {"name": "Binkkour, Mohamed", "sameAs": [], "familyName": "Binkkour", "additionalName": "", "givenName": "Mohamed", "email": ""}], "title": "Strategic and Operational information support of decision making\n  processes and systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01803", "oai:arXiv.org:1502.01803"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper aims to present the different aspects and characteristics of\nstrategic and operational information and propose a categorization pattern\nallowing to consider an information as strategic or operational. This\ncategorization is to be used in the two decision making processes to assist its\nmining, and usage by the two related decision support systems. This is\nconducted trough the results of an investigative study of information used as\nbasis for strategic decisions inside three different companies.\n", "Comment: Proceedings of the Information Systems and Business Intelligence\n  Conference, (SIIE-2008) Hammamet, Tunisia, February, 2008"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01803"}}, {"publisher": {"name": ""}, "description": "  Inspired by the brain, deep neural networks (DNN) are thought to learn\nabstract representations through their hierarchical architecture. However, at\npresent, how this happens is not well understood. Here, we demonstrate that DNN\nlearn abstract representations by a process of demodulation. We introduce a\nbiased sigmoid activation function and use it to show that DNN learn and\nperform better when optimized for demodulation. Our findings constitute the\nfirst unambiguous evidence that DNN perform abstract learning in practical use.\nOur findings may also explain abstract learning in the human brain.\n", "contributors": [{"name": "Simpson, Andrew J. R.", "sameAs": [], "familyName": "Simpson", "additionalName": "J. R.", "givenName": "Andrew", "email": ""}], "title": "Abstract Learning via Demodulation in a Deep Neural Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04042", "oai:arXiv.org:1502.04042"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Inspired by the brain, deep neural networks (DNN) are thought to learn\nabstract representations through their hierarchical architecture. However, at\npresent, how this happens is not well understood. Here, we demonstrate that DNN\nlearn abstract representations by a process of demodulation. We introduce a\nbiased sigmoid activation function and use it to show that DNN learn and\nperform better when optimized for demodulation. Our findings constitute the\nfirst unambiguous evidence that DNN perform abstract learning in practical use.\nOur findings may also explain abstract learning in the human brain.\n"}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - learning", "68txx"], "providerUpdatedDateTime": "2015-02-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04042"}}, {"publisher": {"name": ""}, "description": "  Wikipedia is a community-created encyclopedia that contains information about\nnotable people from different countries, epochs and disciplines and aims to\ndocument the world's knowledge from a neutral point of view. However, the\nnarrow diversity of the Wikipedia editor community has the potential to\nintroduce systemic biases such as gender biases into the content of Wikipedia.\nIn this paper we aim to tackle a sub problem of this larger challenge by\npresenting and applying a computational method for assessing gender bias on\nWikipedia along multiple dimensions. We find that while women on Wikipedia are\ncovered and featured well in many Wikipedia language editions, the way women\nare portrayed starkly differs from the way men are portrayed. We hope our work\ncontributes to increasing awareness about gender biases online, and in\nparticular to raising attention to the different levels in which gender biases\ncan manifest themselves on the web.\n", "contributors": [{"name": "Wagner, Claudia", "sameAs": [], "familyName": "Wagner", "additionalName": "", "givenName": "Claudia", "email": ""}, {"name": "Garcia, David", "sameAs": [], "familyName": "Garcia", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Jadidi, Mohsen", "sameAs": [], "familyName": "Jadidi", "additionalName": "", "givenName": "Mohsen", "email": ""}, {"name": "Strohmaier, Markus", "sameAs": [], "familyName": "Strohmaier", "additionalName": "", "givenName": "Markus", "email": ""}], "title": "It's a Man's Wikipedia? Assessing Gender Inequality in an Online\n  Encyclopedia", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-26", "2015-03-23"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06307", "oai:arXiv.org:1501.06307"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Wikipedia is a community-created encyclopedia that contains information about\nnotable people from different countries, epochs and disciplines and aims to\ndocument the world's knowledge from a neutral point of view. However, the\nnarrow diversity of the Wikipedia editor community has the potential to\nintroduce systemic biases such as gender biases into the content of Wikipedia.\nIn this paper we aim to tackle a sub problem of this larger challenge by\npresenting and applying a computational method for assessing gender bias on\nWikipedia along multiple dimensions. We find that while women on Wikipedia are\ncovered and featured well in many Wikipedia language editions, the way women\nare portrayed starkly differs from the way men are portrayed. We hope our work\ncontributes to increasing awareness about gender biases online, and in\nparticular to raising attention to the different levels in which gender biases\ncan manifest themselves on the web.\n", "Comment: in The International AAAI Conference on Web and Social Media\n  (ICWSM2015), Oxford, May 2015"]}}], "languages": [null], "subjects": ["computer science - computers and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06307"}}, {"publisher": {"name": ""}, "description": "  Clustering analysis aims to discover the underlying clusters in the data\npoints according to their similarities. It has wide applications ranging from\nbioinformatics to astronomy. Here, we proposed a Generalized Affinity\nPropagation (G-AP) clustering algorithm. Data points are first organized in a\nsparsely connected in-tree (IT) structure by a physically inspired strategy.\nThen, additional edges are added to the IT structure for those reachable nodes.\nThis expanded structure is subsequently trimmed by affinity propagation method.\nConsequently, the underlying cluster structure, with separate clusters,\nemerges. In contrast to other IT-based methods, G-AP is fully automatic and\ntakes as input the pairs of similarities between data points only. Unlike\naffinity propagation, G-AP is capable of discovering nonspherical clusters.\n", "contributors": [{"name": "Qiu, Teng", "sameAs": [], "familyName": "Qiu", "additionalName": "", "givenName": "Teng", "email": ""}, {"name": "Li, Yongjie", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Yongjie", "email": ""}], "title": "A Generalized Affinity Propagation Clustering Algorithm for Nonspherical\n  Cluster Discovery", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04318", "oai:arXiv.org:1501.04318"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Clustering analysis aims to discover the underlying clusters in the data\npoints according to their similarities. It has wide applications ranging from\nbioinformatics to astronomy. Here, we proposed a Generalized Affinity\nPropagation (G-AP) clustering algorithm. Data points are first organized in a\nsparsely connected in-tree (IT) structure by a physically inspired strategy.\nThen, additional edges are added to the IT structure for those reachable nodes.\nThis expanded structure is subsequently trimmed by affinity propagation method.\nConsequently, the underlying cluster structure, with separate clusters,\nemerges. In contrast to other IT-based methods, G-AP is fully automatic and\ntakes as input the pairs of similarities between data points only. Unlike\naffinity propagation, G-AP is capable of discovering nonspherical clusters.\n", "Comment: G-AP: a new (7th) member of the in-tree clustering family. 11 pages:\n  1-7, texts and figures; 8-11, supplementary materials"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04318"}}, {"publisher": {"name": ""}, "description": "  This paper studies the problem of predicting the coding effort for a\nsubsequent year of development by analysing metrics extracted from project\nrepositories, with an emphasis on projects containing XML code. The study\nconsiders thirteen open source projects and applies machine learning algorithms\nto generate models to predict one-year coding effort, measured in terms of\nlines of code added, modified and deleted. Both organisational and code metrics\nassociated to revisions are taken into account. The results show that coding\neffort is highly determined by the expertise of developers while source code\nmetrics have little effect on improving the accuracy of estimations of coding\neffort. The study also shows that models trained on one project are unreliable\nat estimating effort in other projects.\n", "contributors": [{"name": "Karus, Siim", "sameAs": [], "familyName": "Karus", "additionalName": "", "givenName": "Siim", "email": ""}, {"name": "Dumas, Marlon", "sameAs": [], "familyName": "Dumas", "additionalName": "", "givenName": "Marlon", "email": ""}], "title": "Predicting Coding Effort in Projects Containing XML Code", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-10-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1010.2354", "oai:arXiv.org:1010.2354"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper studies the problem of predicting the coding effort for a\nsubsequent year of development by analysing metrics extracted from project\nrepositories, with an emphasis on projects containing XML code. The study\nconsiders thirteen open source projects and applies machine learning algorithms\nto generate models to predict one-year coding effort, measured in terms of\nlines of code added, modified and deleted. Both organisational and code metrics\nassociated to revisions are taken into account. The results show that coding\neffort is highly determined by the expertise of developers while source code\nmetrics have little effect on improving the accuracy of estimations of coding\neffort. The study also shows that models trained on one project are unreliable\nat estimating effort in other projects.\n"}}], "languages": [null], "subjects": ["d.2.9", "d.2.8", "d.2.7", "computer science - software engineering"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1010.2354"}}, {"publisher": {"name": ""}, "description": "  In a currently ongoing project, we investigate a new possibility for solving\nthe k-labelled spanning forest (kLSF) problem by an intelligent Variable\nNeighbourhood Search (Int-VNS) metaheuristic. In the kLSF problem we are given\nan undirected input graph G and an integer positive value k, and the aim is to\nfind a spanning forest of G having the minimum number of connected components\nand the upper bound k on the number of labels to use. The problem is related to\nthe minimum labelling spanning tree (MLST) problem, whose goal is to get the\nspanning tree of the input graph with the minimum number of labels, and has\nseveral applications in the real world, where one aims to ensure connectivity\nby means of homogeneous connections. The Int-VNS metaheuristic that we propose\nfor the kLSF problem is derived from the promising intelligent VNS strategy\nrecently proposed for the MLST problem, and integrates the basic VNS for the\nkLSF problem with other complementary approaches from machine learning,\nstatistics and experimental algorithmics, in order to produce high-quality\nperformance and to completely automate the resulting strategy.\n", "contributors": [{"name": "Consoli, Sergio", "sameAs": [], "familyName": "Consoli", "additionalName": "", "givenName": "Sergio", "email": ""}, {"name": "P\u00e8rez, Jos\u00e8 Andr\u00e8s Moreno", "sameAs": [], "familyName": "P\u00e8rez", "additionalName": "Andr\u00e8s Moreno", "givenName": "Jos\u00e8", "email": ""}, {"name": "Mladenovic, Nenad", "sameAs": [], "familyName": "Mladenovic", "additionalName": "", "givenName": "Nenad", "email": ""}], "title": "Towards an intelligent VNS heuristic for the k-labelled spanning forest\n  problem", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02009", "Computer Aided Systems Theory, pages 79-80 (2015)", "oai:arXiv.org:1503.02009"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In a currently ongoing project, we investigate a new possibility for solving\nthe k-labelled spanning forest (kLSF) problem by an intelligent Variable\nNeighbourhood Search (Int-VNS) metaheuristic. In the kLSF problem we are given\nan undirected input graph G and an integer positive value k, and the aim is to\nfind a spanning forest of G having the minimum number of connected components\nand the upper bound k on the number of labels to use. The problem is related to\nthe minimum labelling spanning tree (MLST) problem, whose goal is to get the\nspanning tree of the input graph with the minimum number of labels, and has\nseveral applications in the real world, where one aims to ensure connectivity\nby means of homogeneous connections. The Int-VNS metaheuristic that we propose\nfor the kLSF problem is derived from the promising intelligent VNS strategy\nrecently proposed for the MLST problem, and integrates the basic VNS for the\nkLSF problem with other complementary approaches from machine learning,\nstatistics and experimental algorithmics, in order to produce high-quality\nperformance and to completely automate the resulting strategy.\n", "Comment: 2 pages, Fifteenth International Conference on Computer Aided Systems\n  Theory (EUROCAST 2015), Las Palmas de Gran Canaria, Spain"]}}], "languages": [null], "subjects": ["computer science - other computer science", "computer science - artificial intelligence"], "providerUpdatedDateTime": "2015-03-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02009"}}, {"publisher": {"name": ""}, "description": "  Gibbs random fields play an important role in statistics, however, the\nresulting likelihood is typically unavailable due to an intractable normalizing\nconstant. Composite likelihoods offer a principled means to construct useful\napproximations. This paper provides a mean to calibrate the posterior\ndistribution resulting from using a composite likelihood and illustrate its\nperformance in several examples.\n", "contributors": [{"name": "Stoehr, Julien", "sameAs": [], "familyName": "Stoehr", "additionalName": "", "givenName": "Julien", "email": ""}, {"name": "Friel, Nial", "sameAs": [], "familyName": "Friel", "additionalName": "", "givenName": "Nial", "email": ""}], "title": "Calibration of conditional composite likelihood for Bayesian inference\n  on Gibbs random fields", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01997", "oai:arXiv.org:1502.01997"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "stat"]}}, {"name": "description", "properties": {"description": "  Gibbs random fields play an important role in statistics, however, the\nresulting likelihood is typically unavailable due to an intractable normalizing\nconstant. Composite likelihoods offer a principled means to construct useful\napproximations. This paper provides a mean to calibrate the posterior\ndistribution resulting from using a composite likelihood and illustrate its\nperformance in several examples.\n"}}], "languages": [null], "subjects": ["mathematics - statistics theory", "statistics - computation"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01997"}}, {"publisher": {"name": ""}, "description": "  Mean Shift today, is widely used for mode detection and clustering. The\ntechnique though, is challenged in practice due to assumptions of isotropicity\nand homoscedasticity. We present an adaptive Mean Shift methodology that allows\nfor full anisotropic clustering, through unsupervised local bandwidth\nselection. The bandwidth matrices evolve naturally, adapting locally through\nagglomeration, and in turn guiding further agglomeration. The online\nmethodology is practical and effecive for low-dimensional feature spaces,\npreserving better detail and clustering salience. Additionally, conventional\nMean Shift either critically depends on a per instance choice of bandwidth, or\nrelies on offline methods which are inflexible and/or again data instance\nspecific. The presented approach, due to its adaptive design, also alleviates\nthis issue - with a default form performing generally well. The methodology\nthough, allows for effective tuning of results.\n", "contributors": [{"name": "Sawhney, Rahul", "sameAs": [], "familyName": "Sawhney", "additionalName": "", "givenName": "Rahul", "email": ""}, {"name": "Christensen, Henrik I.", "sameAs": [], "familyName": "Christensen", "additionalName": "I.", "givenName": "Henrik", "email": ""}, {"name": "Bradski, Gary R.", "sameAs": [], "familyName": "Bradski", "additionalName": "R.", "givenName": "Gary", "email": ""}], "title": "Anisotropic Agglomerative Adaptive Mean-Shift", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4102", "oai:arXiv.org:1411.4102"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Mean Shift today, is widely used for mode detection and clustering. The\ntechnique though, is challenged in practice due to assumptions of isotropicity\nand homoscedasticity. We present an adaptive Mean Shift methodology that allows\nfor full anisotropic clustering, through unsupervised local bandwidth\nselection. The bandwidth matrices evolve naturally, adapting locally through\nagglomeration, and in turn guiding further agglomeration. The online\nmethodology is practical and effecive for low-dimensional feature spaces,\npreserving better detail and clustering salience. Additionally, conventional\nMean Shift either critically depends on a per instance choice of bandwidth, or\nrelies on offline methods which are inflexible and/or again data instance\nspecific. The presented approach, due to its adaptive design, also alleviates\nthis issue - with a default form performing generally well. The methodology\nthough, allows for effective tuning of results.\n", "Comment: British Machine Vision Conference, 2014"]}}], "languages": [null], "subjects": ["computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4102"}}, {"publisher": {"name": ""}, "description": "  Erasure coding is a storage-efficient alternative to replication for\nachieving reliable data backup in distributed storage systems. During the\nstorage process, traditional erasure codes require a unique source node to\ncreate and upload all the redundant data to the different storage nodes.\nHowever, such a source node may have limited communication and computation\ncapabilities, which constrain the storage process throughput. Moreover, the\nsource node and the different storage nodes might not be able to send and\nreceive data simultaneously -- e.g., nodes might be busy in a datacenter\nsetting, or simply be offline in a peer-to-peer setting -- which can further\nthreaten the efficacy of the overall storage process. In this paper we propose\nan \"in-network\" redundancy generation process which distributes the data\ninsertion load among the source and storage nodes by allowing the storage nodes\nto generate new redundant data by exchanging partial information among\nthemselves, improving the throughput of the storage process. The process is\ncarried out asynchronously, utilizing spare bandwidth and computing resources\nfrom the storage nodes. The proposed approach leverages on the local\nrepairability property of newly proposed erasure codes tailor made for the\nneeds of distributed storage systems. We analytically show that the performance\nof this technique relies on an efficient usage of the spare node resources, and\nwe derive a set of scheduling algorithms to maximize the same. We\nexperimentally show, using availability traces from real peer-to-peer\napplications as well as Google data center availability and workload traces,\nthat our algorithms can, depending on the environment characteristics, increase\nthe throughput of the storage process significantly (up to 90% in data centers,\nand 60% in peer-to-peer settings) with respect to the classical naive data\ninsertion approach.\n", "contributors": [{"name": "Pamies-Juarez, Lluis", "sameAs": [], "familyName": "Pamies-Juarez", "additionalName": "", "givenName": "Lluis", "email": ""}, {"name": "Datta, Anwitaman", "sameAs": [], "familyName": "Datta", "additionalName": "", "givenName": "Anwitaman", "email": ""}, {"name": "Oggier, Fr\u00e9d\u00e9rique", "sameAs": [], "familyName": "Oggier", "additionalName": "", "givenName": "Fr\u00e9d\u00e9rique", "email": ""}], "title": "In-Network Redundancy Generation for Opportunistic Speedup of Backup", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-18", "2013-02-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.4533", "Future Generation Computer Systems (Volume 29, Issue 6, August\n  2013, Pages 1353-1362)", "doi:10.1016/j.future.2013.02.009", "oai:arXiv.org:1111.4533"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Erasure coding is a storage-efficient alternative to replication for\nachieving reliable data backup in distributed storage systems. During the\nstorage process, traditional erasure codes require a unique source node to\ncreate and upload all the redundant data to the different storage nodes.\nHowever, such a source node may have limited communication and computation\ncapabilities, which constrain the storage process throughput. Moreover, the\nsource node and the different storage nodes might not be able to send and\nreceive data simultaneously -- e.g., nodes might be busy in a datacenter\nsetting, or simply be offline in a peer-to-peer setting -- which can further\nthreaten the efficacy of the overall storage process. In this paper we propose\nan \"in-network\" redundancy generation process which distributes the data\ninsertion load among the source and storage nodes by allowing the storage nodes\nto generate new redundant data by exchanging partial information among\nthemselves, improving the throughput of the storage process. The process is\ncarried out asynchronously, utilizing spare bandwidth and computing resources\nfrom the storage nodes. The proposed approach leverages on the local\nrepairability property of newly proposed erasure codes tailor made for the\nneeds of distributed storage systems. We analytically show that the performance\nof this technique relies on an efficient usage of the spare node resources, and\nwe derive a set of scheduling algorithms to maximize the same. We\nexperimentally show, using availability traces from real peer-to-peer\napplications as well as Google data center availability and workload traces,\nthat our algorithms can, depending on the environment characteristics, increase\nthe throughput of the storage process significantly (up to 90% in data centers,\nand 60% in peer-to-peer settings) with respect to the classical naive data\ninsertion approach.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "computer science - networking and internet architecture", "computer science - information theory", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.4533"}}, {"publisher": {"name": ""}, "description": "  The use of partial geometries to construct parity-check matrices for LDPC\ncodes has resulted in the design of successful codes with a probability of\nerror close to the Shannon capacity at bit error rates down to $10^{-15}$. Such\nconsiderations have motivated this further investigation. A new and simple\nconstruction of a type of partial geometries with quasi-cyclic structure is\ngiven and their properties are investigated. The trapping sets of the partial\ngeometry codes were considered previously using the geometric aspects of the\nunderlying structure to derive information on the size of allowable trapping\nsets. This topic is further considered here. Finally, there is a natural\nrelationship between partial geometries and strongly regular graphs. The\neigenvalues of the adjacency matrices of such graphs are well known and it is\nof interest to determine if any of the Tanner graphs derived from the partial\ngeometries are good expanders for certain parameter sets, since it can be\nargued that codes with good geometric and expansion properties might perform\nwell under message-passing decoding.\n", "contributors": [{"name": "Diao, Qiuju", "sameAs": [], "familyName": "Diao", "additionalName": "", "givenName": "Qiuju", "email": ""}, {"name": "Li, Juane", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Juane", "email": ""}, {"name": "Lin, Shu", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Shu", "email": ""}, {"name": "Blake, Ian", "sameAs": [], "familyName": "Blake", "additionalName": "", "givenName": "Ian", "email": ""}], "title": "New Classes of Partial Geometries and Their Associated LDPC Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06900", "oai:arXiv.org:1503.06900"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The use of partial geometries to construct parity-check matrices for LDPC\ncodes has resulted in the design of successful codes with a probability of\nerror close to the Shannon capacity at bit error rates down to $10^{-15}$. Such\nconsiderations have motivated this further investigation. A new and simple\nconstruction of a type of partial geometries with quasi-cyclic structure is\ngiven and their properties are investigated. The trapping sets of the partial\ngeometry codes were considered previously using the geometric aspects of the\nunderlying structure to derive information on the size of allowable trapping\nsets. This topic is further considered here. Finally, there is a natural\nrelationship between partial geometries and strongly regular graphs. The\neigenvalues of the adjacency matrices of such graphs are well known and it is\nof interest to determine if any of the Tanner graphs derived from the partial\ngeometries are good expanders for certain parameter sets, since it can be\nargued that codes with good geometric and expansion properties might perform\nwell under message-passing decoding.\n", "Comment: 34 pages with single column, 6 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06900"}}, {"publisher": {"name": "Lippincott Williams & Wilkins"}, "description": "", "contributors": [{"name": "deKleijn, Miriam", "sameAs": [], "familyName": "deKleijn", "additionalName": "", "givenName": "Miriam", "email": ""}, {"name": "Lagro-Janssen, Antoine L.M.", "sameAs": [], "familyName": "Lagro-Janssen", "additionalName": "L.M.", "givenName": "Antoine", "email": ""}, {"name": "Canelo, Ismelda", "sameAs": [], "familyName": "Canelo", "additionalName": "", "givenName": "Ismelda", "email": ""}, {"name": "Yano, Elizabeth M.", "sameAs": [], "familyName": "Yano", "additionalName": "M.", "givenName": "Elizabeth", "email": ""}], "title": "Creating a Roadmap for Delivering Gender-sensitive Comprehensive Care for Women Veterans: Results of a National Expert Panel", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["transforming comprehensive care"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4379113"}}, {"publisher": {"name": ""}, "description": "  The problem of optimal switching between nonlinear autonomous subsystems is\ninvestigated in this study where the objective is not only bringing the states\nto close to the desired point, but also adjusting the switching pattern, in the\nsense of penalizing switching occurrences and assigning different preferences\nto utilization of different modes. The mode sequence is unspecified and a\nswitching cost term is used in the cost function for penalizing each switching.\nIt is shown that once a switching cost is incorporated, the optimal cost-to-go\nfunction depends on the already active subsystem, i.e., the subsystem which was\nengaged in the previous time step. Afterwards, an approximate dynamic\nprogramming based method is developed which provides an approximation of the\noptimal solution to the problem in a feedback form and for different initial\nconditions. Finally, the performance of the method is analyzed through\nnumerical examples.\n", "contributors": [{"name": "Heydari, Ali", "sameAs": [], "familyName": "Heydari", "additionalName": "", "givenName": "Ali", "email": ""}], "title": "Feedback Solution to Optimal Switching Problems with Switching Cost", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4695", "oai:arXiv.org:1411.4695"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  The problem of optimal switching between nonlinear autonomous subsystems is\ninvestigated in this study where the objective is not only bringing the states\nto close to the desired point, but also adjusting the switching pattern, in the\nsense of penalizing switching occurrences and assigning different preferences\nto utilization of different modes. The mode sequence is unspecified and a\nswitching cost term is used in the cost function for penalizing each switching.\nIt is shown that once a switching cost is incorporated, the optimal cost-to-go\nfunction depends on the already active subsystem, i.e., the subsystem which was\nengaged in the previous time step. Afterwards, an approximate dynamic\nprogramming based method is developed which provides an approximation of the\noptimal solution to the problem in a feedback form and for different initial\nconditions. Finally, the performance of the method is analyzed through\nnumerical examples.\n"}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "statistics - machine learning"], "providerUpdatedDateTime": "2014-11-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4695"}}, {"publisher": {"name": ""}, "description": "  We consider the question of defining interleaving metrics on generalized\npersistence modules over arbitrary preordered sets. Our constructions are\nfunctorial, which implies a form of stability for these metrics. We describe a\nlarge class of examples, inverse-image persistence modules, which occur\nwhenever a topological space is mapped to a metric space. Several standard\ntheories of persistence and their stability can be described in this framework.\nThis includes the classical case of sublevelset persistent homology. We\nintroduce a distinction between `soft' and `hard' stability theorems. While our\ntreatment is direct and elementary, the approach can be explained abstractly in\nterms of monoidal functors.\n", "contributors": [{"name": "Bubenik, Peter", "sameAs": [], "familyName": "Bubenik", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "de Silva, Vin", "sameAs": [], "familyName": "de Silva", "additionalName": "", "givenName": "Vin", "email": ""}, {"name": "Scott, Jonathan", "sameAs": [], "familyName": "Scott", "additionalName": "", "givenName": "Jonathan", "email": ""}], "title": "Metrics for generalized persistence modules", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-13", "2014-08-21"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.3829", "doi:10.1007/s10208-014-9229-5", "oai:arXiv.org:1312.3829"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider the question of defining interleaving metrics on generalized\npersistence modules over arbitrary preordered sets. Our constructions are\nfunctorial, which implies a form of stability for these metrics. We describe a\nlarge class of examples, inverse-image persistence modules, which occur\nwhenever a topological space is mapped to a metric space. Several standard\ntheories of persistence and their stability can be described in this framework.\nThis includes the classical case of sublevelset persistent homology. We\nintroduce a distinction between `soft' and `hard' stability theorems. While our\ntreatment is direct and elementary, the approach can be explained abstractly in\nterms of monoidal functors.\n", "Comment: 29 pages"]}}], "languages": [null], "subjects": ["68u05", "55u99", "mathematics - algebraic topology", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-01-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.3829"}}, {"publisher": {"name": ""}, "description": "  The success of many machine learning and pattern recognition methods relies\nheavily upon the identification of an appropriate distance metric on the input\ndata. It is often beneficial to learn such a metric from the input training\ndata, instead of using a default one such as the Euclidean distance. In this\nwork, we propose a boosting-based technique, termed BoostMetric, for learning a\nquadratic Mahalanobis distance metric. Learning a valid Mahalanobis distance\nmetric requires enforcing the constraint that the matrix parameter to the\nmetric remains positive definite. Semidefinite programming is often used to\nenforce this constraint, but does not scale well and easy to implement.\nBoostMetric is instead based on the observation that any positive semidefinite\nmatrix can be decomposed into a linear combination of trace-one rank-one\nmatrices. BoostMetric thus uses rank-one positive semidefinite matrices as weak\nlearners within an efficient and scalable boosting-based learning process. The\nresulting methods are easy to implement, efficient, and can accommodate various\ntypes of constraints. We extend traditional boosting algorithms in that its\nweak learner is a positive semidefinite matrix with trace and rank being one\nrather than a classifier or regressor. Experiments on various datasets\ndemonstrate that the proposed algorithms compare favorably to those\nstate-of-the-art methods in terms of classification accuracy and running time.\n", "contributors": [{"name": "Shen, Chunhua", "sameAs": [], "familyName": "Shen", "additionalName": "", "givenName": "Chunhua", "email": ""}, {"name": "Kim, Junae", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Junae", "email": ""}, {"name": "Wang, Lei", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Lei", "email": ""}, {"name": "Hengel, Anton van den", "sameAs": [], "familyName": "Hengel", "additionalName": "van den", "givenName": "Anton", "email": ""}], "title": "Positive Semidefinite Metric Learning Using Boosting-like Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-25", "2012-04-12"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.4704", "oai:arXiv.org:1104.4704"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The success of many machine learning and pattern recognition methods relies\nheavily upon the identification of an appropriate distance metric on the input\ndata. It is often beneficial to learn such a metric from the input training\ndata, instead of using a default one such as the Euclidean distance. In this\nwork, we propose a boosting-based technique, termed BoostMetric, for learning a\nquadratic Mahalanobis distance metric. Learning a valid Mahalanobis distance\nmetric requires enforcing the constraint that the matrix parameter to the\nmetric remains positive definite. Semidefinite programming is often used to\nenforce this constraint, but does not scale well and easy to implement.\nBoostMetric is instead based on the observation that any positive semidefinite\nmatrix can be decomposed into a linear combination of trace-one rank-one\nmatrices. BoostMetric thus uses rank-one positive semidefinite matrices as weak\nlearners within an efficient and scalable boosting-based learning process. The\nresulting methods are easy to implement, efficient, and can accommodate various\ntypes of constraints. We extend traditional boosting algorithms in that its\nweak learner is a positive semidefinite matrix with trace and rank being one\nrather than a classifier or regressor. Experiments on various datasets\ndemonstrate that the proposed algorithms compare favorably to those\nstate-of-the-art methods in terms of classification accuracy and running time.\n", "Comment: 30 pages, appearing in Journal of Machine Learning Research"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.4704"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "We give a comprehensive theoretical characterization of a nonparametric estimator for the L_2^2 divergence between two continuous distributions. We first bound the rate of convergence of our estimator, showing that it is \u221an-consistent provided the densities are sufficiently smooth. In this smooth regime, we then show that our estimator is asymptotically normal, construct asymptotic confidence intervals, and establish a Berry-Ess\\'{e}en style inequality characterizing the rate of convergence to normality. We also show that this estimator is minimax optimal.", "contributors": [{"name": "Krishnamurthy, Akshay", "sameAs": [], "familyName": "Krishnamurthy", "additionalName": "", "givenName": "Akshay", "email": ""}, {"name": "Kandasamy, Kirthevasan", "sameAs": [], "familyName": "Kandasamy", "additionalName": "", "givenName": "Kirthevasan", "email": ""}, {"name": "Poczos, Barnabas", "sameAs": [], "familyName": "Poczos", "additionalName": "", "givenName": "Barnabas", "email": ""}, {"name": "Wasserman, Larry", "sameAs": [], "familyName": "Wasserman", "additionalName": "", "givenName": "Larry", "email": ""}], "title": "On Estimating L_2^2 Divergence", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-10-31T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/84", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1076&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1076"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "We give a comprehensive theoretical characterization of a nonparametric estimator for the L_2^2 divergence between two continuous distributions. We first bound the rate of convergence of our estimator, showing that it is \u221an-consistent provided the densities are sufficiently smooth. In this smooth regime, we then show that our estimator is asymptotically normal, construct asymptotic confidence intervals, and establish a Berry-Ess\\'{e}en style inequality characterizing the rate of convergence to normality. We also show that this estimator is minimax optimal."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-13T21:23:49", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/84"}}, {"publisher": {"name": "DigitalCommons@CalPoly"}, "description": "This project includes the imagining, design, build, and test of a web application that creates and tracks a user\u2019s progress on completing tasks that an administrator has created for the user. The goal of this project is to have a functioning webpage that is robust and scalable to support many users and many tasks. The application will be developed for use on all modern web browsers, and will have a persistent server to access from any platform. This project was designed to be an exercise in building a modern web application, and as such is written using many different languages, APIs and libraries. The front-end is setup in HTML and CSS, with an approach that a web-designer might update the aesthetic of the application. MySQL is utilized for the server databasing implementation, and PHP, JavaScript and JQuery are used as the bridge between the database and the front-end of the application.", "contributors": [{"name": "Green, Ryan", "sameAs": [], "familyName": "Green", "additionalName": "", "givenName": "Ryan", "email": ""}], "title": "Badge Web Application", "shareProperties": {"source": "calpoly"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "source", "properties": {"source": "Computer Engineering"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-12-01T08:00:00Z"}}, {"name": "setSpec", "properties": {"setSpec": "publication:cpesp"}}], "languages": [null], "subjects": ["web application", "data storage systems", "other computer engineering", "software"], "providerUpdatedDateTime": "2014-12-17T20:09:38", "uris": {"canonicalUri": "http://digitalcommons.calpoly.edu/cpesp/143"}}, {"publisher": {"name": ""}, "description": "  We generalize a well-known algorithm for the generation of all subsets of a\nset in lexicographic order with respect to the sets as lists of elements\n(subset-lex order). We obtain algorithms for various combinatorial objects such\nas the subsets of a multiset, compositions and partitions represented as lists\nof parts, and for certain restricted growth strings. The algorithms are often\nloopless and require at most one extra variable for the computation of the next\nobject. The performance of the algorithms is very competitive even when not\nloopless. A Gray code corresponding to the subset-lex order and a Gray code for\ncompositions that was found during this work are described.\n", "contributors": [{"name": "Arndt, J\u00f6rg", "sameAs": [], "familyName": "Arndt", "additionalName": "", "givenName": "J\u00f6rg", "email": ""}], "title": "Subset-lex: did we miss an order?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-26", "2014-12-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.6503", "oai:arXiv.org:1405.6503"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We generalize a well-known algorithm for the generation of all subsets of a\nset in lexicographic order with respect to the sets as lists of elements\n(subset-lex order). We obtain algorithms for various combinatorial objects such\nas the subsets of a multiset, compositions and partitions represented as lists\nof parts, and for certain restricted growth strings. The algorithms are often\nloopless and require at most one extra variable for the computation of the next\nobject. The performance of the algorithms is very competitive even when not\nloopless. A Gray code corresponding to the subset-lex order and a Gray code for\ncompositions that was found during this work are described.\n", "Comment: Two obvious errors corrected (indicated by \"Correction:\" in the LaTeX\n  source)"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.6503"}}, {"publisher": {"name": ""}, "description": "  One of the most efficient ways of generating goal-directed walking motions is\nsynthesising the final motion based on footprints. Nevertheless, current\nimplementations have not examined the generation of continuous motion based on\nfootprints, where different behaviours can be generated automatically.\nTherefore, in this paper a flexible approach for footprint-driven locomotion\ncomposition is presented. The presented solution is based on the ability to\ngenerate footprint-driven locomotion, with flexible features like jumping,\nrunning, and stair stepping. In addition, the presented system examines the\nability of generating the desired motion of the character based on predefined\nfootprint patterns that determine which behaviour should be performed. Finally,\nit is examined the generation of transition patterns based on the velocity of\nthe root and the number of footsteps required to achieve the target behaviour\nsmoothly and naturally.\n", "contributors": [{"name": "Mousas, Christos", "sameAs": [], "familyName": "Mousas", "additionalName": "", "givenName": "Christos", "email": ""}, {"name": "Newbury, Paul", "sameAs": [], "familyName": "Newbury", "additionalName": "", "givenName": "Paul", "email": ""}, {"name": "Anagnostopoulos, Christos-Nikolaos", "sameAs": [], "familyName": "Anagnostopoulos", "additionalName": "", "givenName": "Christos-Nikolaos", "email": ""}], "title": "Footprint-Driven Locomotion Composition", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1906", "International Journal of Computer Graphics & Animation (IJCGA)\n  Vol.4, No.4, pp. 27-42, October 2014", "doi:10.5121/ijcga.2014.4403", "oai:arXiv.org:1411.1906"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  One of the most efficient ways of generating goal-directed walking motions is\nsynthesising the final motion based on footprints. Nevertheless, current\nimplementations have not examined the generation of continuous motion based on\nfootprints, where different behaviours can be generated automatically.\nTherefore, in this paper a flexible approach for footprint-driven locomotion\ncomposition is presented. The presented solution is based on the ability to\ngenerate footprint-driven locomotion, with flexible features like jumping,\nrunning, and stair stepping. In addition, the presented system examines the\nability of generating the desired motion of the character based on predefined\nfootprint patterns that determine which behaviour should be performed. Finally,\nit is examined the generation of transition patterns based on the velocity of\nthe root and the number of footsteps required to achieve the target behaviour\nsmoothly and naturally.\n"}}], "languages": [null], "subjects": ["computer science - graphics"], "providerUpdatedDateTime": "2014-11-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1906"}}, {"publisher": {"name": ""}, "description": "  A disk graph is the intersection graph of disks in the plane, a unit disk\ngraph is the intersection graph of same radius disks in the plane, and a\nsegment graph is an intersection graph of line segments in the plane. It can be\nseen that every disk graph can be realized by disks with centers on the integer\ngrid and with integer radii; and similarly every unit disk graph can be\nrealized by disks with centers on the integer grid and equal (integer) radius;\nand every segment graph can be realized by segments whose endpoints lie on the\ninteger grid. Here we show that there exist disk graphs on $n$ vertices such\nthat in every realization by integer disks at least one coordinate or radius is\n$2^{2^{\\Omega(n)}}$ and on the other hand every disk graph can be realized by\ndisks with integer coordinates and radii that are at most $2^{2^{O(n)}}$; and\nwe show the analogous results for unit disk graphs and segment graphs. For\n(unit) disk graphs this answers a question of Spinrad, and for segment graphs\nthis improves over a previous result by Kratochv\\'{\\i}l and Matou{\\v{s}}ek.\n", "contributors": [{"name": "McDiarmid, Colin", "sameAs": [], "familyName": "McDiarmid", "additionalName": "", "givenName": "Colin", "email": ""}, {"name": "Muller, Tobias", "sameAs": [], "familyName": "Muller", "additionalName": "", "givenName": "Tobias", "email": ""}], "title": "Integer realizations of disk and segment graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-12", "2011-11-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.2931", "oai:arXiv.org:1111.2931"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A disk graph is the intersection graph of disks in the plane, a unit disk\ngraph is the intersection graph of same radius disks in the plane, and a\nsegment graph is an intersection graph of line segments in the plane. It can be\nseen that every disk graph can be realized by disks with centers on the integer\ngrid and with integer radii; and similarly every unit disk graph can be\nrealized by disks with centers on the integer grid and equal (integer) radius;\nand every segment graph can be realized by segments whose endpoints lie on the\ninteger grid. Here we show that there exist disk graphs on $n$ vertices such\nthat in every realization by integer disks at least one coordinate or radius is\n$2^{2^{\\Omega(n)}}$ and on the other hand every disk graph can be realized by\ndisks with integer coordinates and radii that are at most $2^{2^{O(n)}}$; and\nwe show the analogous results for unit disk graphs and segment graphs. For\n(unit) disk graphs this answers a question of Spinrad, and for segment graphs\nthis improves over a previous result by Kratochv\\'{\\i}l and Matou{\\v{s}}ek.\n", "Comment: 35 pages, 14 figures, corrected a typo"]}}], "languages": [null], "subjects": ["mathematics - metric geometry", "mathematics - combinatorics", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.2931"}}, {"publisher": {"name": ""}, "description": "  In this paper, we generalize Huber's criterion to multichannel sparse\nrecovery problem of complex-valued measurements where the objective is to find\ngood recovery of jointly sparse unknown signal vectors from the given multiple\nmeasurement vectors which are different linear combinations of the same known\nelementary vectors. This requires careful characterization of robust\ncomplex-valued loss functions as well as Huber's criterion function for the\nmultivariate sparse regression problem. We devise a greedy algorithm based on\nsimultaneous normalized iterative hard thresholding (SNIHT) algorithm. Unlike\nthe conventional SNIHT method, our algorithm, referred to as HUB-SNIHT, is\nrobust under heavy-tailed non-Gaussian noise conditions, yet has a negligible\nperformance loss compared to SNIHT under Gaussian noise. Usefulness of the\nmethod is illustrated in source localization application with sensor arrays.\n", "contributors": [{"name": "Ollila, Esa", "sameAs": [], "familyName": "Ollila", "additionalName": "", "givenName": "Esa", "email": ""}], "title": "Multichannel sparse recovery of complex-valued signals using Huber's\n  criterion", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.04184", "oai:arXiv.org:1504.04184"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  In this paper, we generalize Huber's criterion to multichannel sparse\nrecovery problem of complex-valued measurements where the objective is to find\ngood recovery of jointly sparse unknown signal vectors from the given multiple\nmeasurement vectors which are different linear combinations of the same known\nelementary vectors. This requires careful characterization of robust\ncomplex-valued loss functions as well as Huber's criterion function for the\nmultivariate sparse regression problem. We devise a greedy algorithm based on\nsimultaneous normalized iterative hard thresholding (SNIHT) algorithm. Unlike\nthe conventional SNIHT method, our algorithm, referred to as HUB-SNIHT, is\nrobust under heavy-tailed non-Gaussian noise conditions, yet has a negligible\nperformance loss compared to SNIHT under Gaussian noise. Usefulness of the\nmethod is illustrated in source localization application with sensor arrays.\n", "Comment: To appear in CoSeRa'15 (Pisa, Italy, June 16-19, 2015). arXiv admin\n  note: text overlap with arXiv:1502.02441"]}}], "languages": [null], "subjects": ["statistics - computation", "computer science - information theory", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.04184"}}, {"publisher": {"name": ""}, "description": "  In this paper, we describe a new vector similarity measure associated with a\nconvex cost function. Given two vectors, we determine the surface normals of\nthe convex function at the vectors. The angle between the two surface normals\nis the similarity measure. Convex cost function can be the negative entropy\nfunction, total variation (TV) function and filtered variation function. The\nconvex cost function need not be differentiable everywhere. In general, we need\nto compute the gradient of the cost function to compute the surface normals. If\nthe gradient does not exist at a given vector, it is possible to use the\nsubgradients and the normal producing the smallest angle between the two\nvectors is used to compute the similarity measure.\n", "contributors": [{"name": "Gunay, Osman", "sameAs": [], "familyName": "Gunay", "additionalName": "", "givenName": "Osman", "email": ""}, {"name": "Akbas, Cem Emre", "sameAs": [], "familyName": "Akbas", "additionalName": "Emre", "givenName": "Cem", "email": ""}, {"name": "Cetin, A. Enis", "sameAs": [], "familyName": "Cetin", "additionalName": "Enis", "givenName": "A.", "email": ""}], "title": "Cosine Similarity Measure According to a Convex Cost Function", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6093", "oai:arXiv.org:1410.6093"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we describe a new vector similarity measure associated with a\nconvex cost function. Given two vectors, we determine the surface normals of\nthe convex function at the vectors. The angle between the two surface normals\nis the similarity measure. Convex cost function can be the negative entropy\nfunction, total variation (TV) function and filtered variation function. The\nconvex cost function need not be differentiable everywhere. In general, we need\nto compute the gradient of the cost function to compute the surface normals. If\nthe gradient does not exist at a given vector, it is possible to use the\nsubgradients and the normal producing the smallest angle between the two\nvectors is used to compute the similarity measure.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2014-10-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6093"}}, {"publisher": {"name": ""}, "description": "  Wireless sensor networks have profound effects on many application fields\nlike security management which need an immediate and fast system reaction.\nIndeed, the monitoring of a dangerous product warehouse is a major issue in\nchemical industry field. This paper describes the design of chemical warehouse\nsecurity system using the concept of active products and wireless sensor\nnetworks. A security application layer is developed to supervise and exchange\nmessages between nodes and the control center to prevent industrial accident.\nDifferent security rules are proposed on this layer to monitor the internal\nstate and incompatible products distance. If a critical event is detected, the\napplication generates alert message which need a short end to end delay and low\npacket loss rate constraints by network layer. Thus, a QoS routing protocol is\nalso developed in the network layer. The proposed solution is implemented in\nCastalia/OMNeT++ simulator. Simulation results show that the system reacts\nperfectly for critical event and can meet the QoS constraints of alert message.\n", "contributors": [{"name": "Zouinkhi, Ahmed", "sameAs": [], "familyName": "Zouinkhi", "additionalName": "", "givenName": "Ahmed", "email": ""}, {"name": "Mekki, Kais", "sameAs": [], "familyName": "Mekki", "additionalName": "", "givenName": "Kais", "email": ""}, {"name": "Abdelkrim, Mohamed Naceur", "sameAs": [], "familyName": "Abdelkrim", "additionalName": "Naceur", "givenName": "Mohamed", "email": ""}], "title": "Application and network layers design for wireless sensor network to\n  supervise chemical active product warehouse", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.01193", "doi:10.5121/ijcsea.2014.4605", "oai:arXiv.org:1501.01193"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Wireless sensor networks have profound effects on many application fields\nlike security management which need an immediate and fast system reaction.\nIndeed, the monitoring of a dangerous product warehouse is a major issue in\nchemical industry field. This paper describes the design of chemical warehouse\nsecurity system using the concept of active products and wireless sensor\nnetworks. A security application layer is developed to supervise and exchange\nmessages between nodes and the control center to prevent industrial accident.\nDifferent security rules are proposed on this layer to monitor the internal\nstate and incompatible products distance. If a critical event is detected, the\napplication generates alert message which need a short end to end delay and low\npacket loss rate constraints by network layer. Thus, a QoS routing protocol is\nalso developed in the network layer. The proposed solution is implemented in\nCastalia/OMNeT++ simulator. Simulation results show that the system reacts\nperfectly for critical event and can meet the QoS constraints of alert message.\n", "Comment: 20 pages in International Journal of Computer Science, Engineering\n  and Applications (IJCSEA), Vol.4, No.6, December 2014, pp. 53-72"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-01-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.01193"}}, {"publisher": {"name": ""}, "description": "  A K-quasiconformal selfmap of the unit disk with identity boundary values\nsatisfies the H\\\"older estimate $|f(z)-f(w)| \\leq 4^{1-1/K} |z-w|^{1/K}$. The\nconstant $4^{1-\\frac{1}{K}}$ is sharp.\n", "contributors": [{"name": "Prause, Istv\u00e1n", "sameAs": [], "familyName": "Prause", "additionalName": "", "givenName": "Istv\u00e1n", "email": ""}], "title": "On a H\\\"older constant in the theory of quasiconformal mappings", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-09-26", "2014-03-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1309.6748", "Comput. Methods. Funct. Theory 14 (2014) 483-486", "doi:10.1007/s40315-014-0060-4", "oai:arXiv.org:1309.6748"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  A K-quasiconformal selfmap of the unit disk with identity boundary values\nsatisfies the H\\\"older estimate $|f(z)-f(w)| \\leq 4^{1-1/K} |z-w|^{1/K}$. The\nconstant $4^{1-\\frac{1}{K}}$ is sharp.\n", "Comment: 3 pages, typos corrected, to appear in F.W. Gehring memorial volume\n  in CMFT"]}}], "languages": [null], "subjects": ["mathematics - complex variables"], "providerUpdatedDateTime": "2014-10-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1309.6748"}}, {"publisher": {"name": ""}, "description": "  In Social Science research, multimedia documents are often collected to\nanswer particular research questions like: \"Which of the aesthetic properties\nof a photo are considered important on the web\" or \"How has Street Art\ndeveloped over the past 50 years\". Therefore, a researcher generally issues\nmultiple queries to a number of search engines. This activity may span over\nlong time intervals and results in a collection which can be further analyzed.\nDocumenting the collection building process which includes the context of the\ncarried out searches is imperative for social scientists to reproduce their\nresearch. Such context documentation consists of several user actions and\nsearch attributes like: the issued queries; the results clicked and saved;\nduration a particular result was viewed for; the set of results that was\ndisplayed but neither clicked, nor saved; as well as user annotations like\ncomments or tags. In this work we will describe a search process tracking\nmodule and a search history visualization module. These modules can be\nintegrated into keyword based search systems through a REST API which was\ndeveloped to help capture, document and revisit past search contexts while\nbuilding a web corpora. Finally, we detail the implementation of how the module\nwas integrated into the LearnWeb2.0 platform - a multimedia web2.0 search and\nsharing application which can obtain resources from various web2.0 tools such\nas Youtube, Bing, Flickr, etc using keyword search.\n", "contributors": [{"name": "Fernando, Zeon Trevor", "sameAs": [], "familyName": "Fernando", "additionalName": "Trevor", "givenName": "Zeon", "email": ""}], "title": "Capturing, Documenting and Visualizing Search Contexts for building\n  Multimedia Corpora", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03660", "oai:arXiv.org:1503.03660"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In Social Science research, multimedia documents are often collected to\nanswer particular research questions like: \"Which of the aesthetic properties\nof a photo are considered important on the web\" or \"How has Street Art\ndeveloped over the past 50 years\". Therefore, a researcher generally issues\nmultiple queries to a number of search engines. This activity may span over\nlong time intervals and results in a collection which can be further analyzed.\nDocumenting the collection building process which includes the context of the\ncarried out searches is imperative for social scientists to reproduce their\nresearch. Such context documentation consists of several user actions and\nsearch attributes like: the issued queries; the results clicked and saved;\nduration a particular result was viewed for; the set of results that was\ndisplayed but neither clicked, nor saved; as well as user annotations like\ncomments or tags. In this work we will describe a search process tracking\nmodule and a search history visualization module. These modules can be\nintegrated into keyword based search systems through a REST API which was\ndeveloped to help capture, document and revisit past search contexts while\nbuilding a web corpora. Finally, we detail the implementation of how the module\nwas integrated into the LearnWeb2.0 platform - a multimedia web2.0 search and\nsharing application which can obtain resources from various web2.0 tools such\nas Youtube, Bing, Flickr, etc using keyword search.\n", "Comment: Undergraduate (B.Tech Hons, Computer Science) Thesis Report, 2014,\n  Vellore Institute of Technology, India"]}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - computers and society", "computer science - human-computer interaction", "computer science - software engineering"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03660"}}, {"publisher": {"name": ""}, "description": "  We give upper and lower bounds on the maximum and minimum number of geometric\nconfigurations of various kinds present (as subgraphs) in a triangulation of\n$n$ points in the plane. Configurations of interest include \\emph{convex\npolygons}, \\emph{star-shaped polygons} and \\emph{monotone paths}. We also\nconsider related problems for \\emph{directed} planar straight-line graphs.\n", "contributors": [{"name": "Dumitrescu, Adrian", "sameAs": [], "familyName": "Dumitrescu", "additionalName": "", "givenName": "Adrian", "email": ""}, {"name": "L\u00f6ffler, Maarten", "sameAs": [], "familyName": "L\u00f6ffler", "additionalName": "", "givenName": "Maarten", "email": ""}, {"name": "Schulz, Andr\u00e9", "sameAs": [], "familyName": "Schulz", "additionalName": "", "givenName": "Andr\u00e9", "email": ""}, {"name": "T\u00f3th, Csaba D.", "sameAs": [], "familyName": "T\u00f3th", "additionalName": "D.", "givenName": "Csaba", "email": ""}], "title": "Counting Carambolas", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1579", "oai:arXiv.org:1410.1579"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We give upper and lower bounds on the maximum and minimum number of geometric\nconfigurations of various kinds present (as subgraphs) in a triangulation of\n$n$ points in the plane. Configurations of interest include \\emph{convex\npolygons}, \\emph{star-shaped polygons} and \\emph{monotone paths}. We also\nconsider related problems for \\emph{directed} planar straight-line graphs.\n", "Comment: 16 pages, 13 figures"]}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-10-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1579"}}, {"publisher": {"name": ""}, "description": "  Polyhedral Omega is a new algorithm for solving linear Diophantine systems\n(LDS), i.e., for computing a multivariate rational function representation of\nthe set of all non-negative integer solutions to a system of linear equations\nand inequalities. Polyhedral Omega combines methods from partition analysis\nwith methods from polyhedral geometry. In particular, we combine MacMahon's\niterative approach based on the Omega operator and explicit formulas for its\nevaluation with geometric tools such as Brion decompositions and Barvinok's\nshort rational function representations. In this way, we connect two recent\nbranches of research that have so far remained separate, unified by the concept\nof symbolic cones which we introduce. The resulting LDS solver Polyhedral Omega\nis significantly faster than previous solvers based on partition analysis and\nit is competitive with state-of-the-art LDS solvers based on geometric methods.\nMost importantly, this synthesis of ideas makes Polyhedral Omega the simplest\nalgorithm for solving linear Diophantine systems available to date. Moreover,\nwe provide an illustrated geometric interpretation of partition analysis, with\nthe aim of making ideas from both areas accessible to readers from a wide range\nof backgrounds.\n", "contributors": [{"name": "Breuer, Felix", "sameAs": [], "familyName": "Breuer", "additionalName": "", "givenName": "Felix", "email": ""}, {"name": "Zafeirakopoulos, Zafeirakis", "sameAs": [], "familyName": "Zafeirakopoulos", "additionalName": "", "givenName": "Zafeirakis", "email": ""}], "title": "Polyhedral Omega: A New Algorithm for Solving Linear Diophantine Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.07773", "oai:arXiv.org:1501.07773"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Polyhedral Omega is a new algorithm for solving linear Diophantine systems\n(LDS), i.e., for computing a multivariate rational function representation of\nthe set of all non-negative integer solutions to a system of linear equations\nand inequalities. Polyhedral Omega combines methods from partition analysis\nwith methods from polyhedral geometry. In particular, we combine MacMahon's\niterative approach based on the Omega operator and explicit formulas for its\nevaluation with geometric tools such as Brion decompositions and Barvinok's\nshort rational function representations. In this way, we connect two recent\nbranches of research that have so far remained separate, unified by the concept\nof symbolic cones which we introduce. The resulting LDS solver Polyhedral Omega\nis significantly faster than previous solvers based on partition analysis and\nit is competitive with state-of-the-art LDS solvers based on geometric methods.\nMost importantly, this synthesis of ideas makes Polyhedral Omega the simplest\nalgorithm for solving linear Diophantine systems available to date. Moreover,\nwe provide an illustrated geometric interpretation of partition analysis, with\nthe aim of making ideas from both areas accessible to readers from a wide range\nof backgrounds.\n", "Comment: 49 pages, 17 figures"]}}], "languages": [null], "subjects": ["mathematics - number theory", "mathematics - combinatorics", "computer science - symbolic computation"], "providerUpdatedDateTime": "2015-02-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.07773"}}, {"publisher": {"name": ""}, "description": "  We solve a problem, stated in [CGP10], showing that Sticky Datalog, defined\nin the cited paper as an element of the Datalog\\pm project, has the finite\ncontrollability property. In order to do that, we develop a technique, which we\nbelieve can have further applications, of approximating Chase(D, T), for a\ndatabase instance D and some sets of tuple generating dependencies T, by an\ninfinite sequence of finite structures, all of them being models of T.\n", "contributors": [{"name": "Gogacz, T.", "sameAs": [], "familyName": "Gogacz", "additionalName": "", "givenName": "T.", "email": ""}, {"name": "Marcinkowski, J.", "sameAs": [], "familyName": "Marcinkowski", "additionalName": "", "givenName": "J.", "email": ""}], "title": "Converging to the Chase - a Tool for Finite Controllability", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-04-16", "2014-11-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1204.3432", "oai:arXiv.org:1204.3432"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We solve a problem, stated in [CGP10], showing that Sticky Datalog, defined\nin the cited paper as an element of the Datalog\\pm project, has the finite\ncontrollability property. In order to do that, we develop a technique, which we\nbelieve can have further applications, of approximating Chase(D, T), for a\ndatabase instance D and some sets of tuple generating dependencies T, by an\ninfinite sequence of finite structures, all of them being models of T.\n"}}], "languages": [null], "subjects": ["68p15", "computer science - databases"], "providerUpdatedDateTime": "2014-11-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1204.3432"}}, {"publisher": {"name": ""}, "description": "  With the advent of digital images the problem of keeping picture\nvisualization uniformity arises because each printing or scanning device has\nits own color chart. So, universal color profiles are made by ICC to bring\nuniformity in various types of devices. Keeping that color profile in mind\nvarious new color charts are created and calibrated with the help of standard\nIT8 test charts available in the market. The main objective to color\nreproduction is to produce the identical picture at device output. For that\nprinciples for gamut mapping has been designed\n", "contributors": [{"name": "Dilawari, Jaswinder Singh", "sameAs": [], "familyName": "Dilawari", "additionalName": "Singh", "givenName": "Jaswinder", "email": ""}, {"name": "Khanna, Ravinder", "sameAs": [], "familyName": "Khanna", "additionalName": "", "givenName": "Ravinder", "email": ""}], "title": "Reproduction of Images by Gamut Mapping and Creation of New Test Charts\n  in Prepress Process", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-09-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1209.6037", "oai:arXiv.org:1209.6037"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  With the advent of digital images the problem of keeping picture\nvisualization uniformity arises because each printing or scanning device has\nits own color chart. So, universal color profiles are made by ICC to bring\nuniformity in various types of devices. Keeping that color profile in mind\nvarious new color charts are created and calibrated with the help of standard\nIT8 test charts available in the market. The main objective to color\nreproduction is to produce the identical picture at device output. For that\nprinciples for gamut mapping has been designed\n", "Comment: 5 Pages,10 Figures; International Journal of Scientific and\n  Engineering Research,Volume 3, Issue 10, October 2012 Edition"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1209.6037"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose a new max-margin based discriminative feature\nlearning method. Specifically, we aim at learning a low-dimensional feature\nrepresentation, so as to maximize the global margin of the data and make the\nsamples from the same class as close as possible. In order to enhance the\nrobustness to noise, a $l_{2,1}$ norm constraint is introduced to make the\ntransformation matrix in group sparsity. In addition, for multi-class\nclassification tasks, we further intend to learn and leverage the correlation\nrelationships among multiple class tasks for assisting in learning\ndiscriminative features. The experimental results demonstrate the power of the\nproposed method against the related state-of-the-art methods.\n", "contributors": [{"name": "Li, Changsheng", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Changsheng", "email": ""}, {"name": "Liu, Qingshan", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Qingshan", "email": ""}, {"name": "Dong, Weishan", "sameAs": [], "familyName": "Dong", "additionalName": "", "givenName": "Weishan", "email": ""}, {"name": "Zhang, Xin", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Xin", "email": ""}, {"name": "Yang, Lin", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Lin", "email": ""}], "title": "Max-Margin based Discriminative Feature Learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4863", "oai:arXiv.org:1412.4863"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we propose a new max-margin based discriminative feature\nlearning method. Specifically, we aim at learning a low-dimensional feature\nrepresentation, so as to maximize the global margin of the data and make the\nsamples from the same class as close as possible. In order to enhance the\nrobustness to noise, a $l_{2,1}$ norm constraint is introduced to make the\ntransformation matrix in group sparsity. In addition, for multi-class\nclassification tasks, we further intend to learn and leverage the correlation\nrelationships among multiple class tasks for assisting in learning\ndiscriminative features. The experimental results demonstrate the power of the\nproposed method against the related state-of-the-art methods.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2014-12-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4863"}}, {"publisher": {"name": ""}, "description": "  We present new constructions of codes for asymmetric channels for both binary\nand nonbinary alphabets, based on methods of generalized code concatenation.\nFor the binary asymmetric channel, our methods construct nonlinear\nsingle-error-correcting codes from ternary outer codes. We show that some of\nthe Varshamov-Tenengol'ts-Constantin-Rao codes, a class of binary nonlinear\ncodes for this channel, have a nice structure when viewed as ternary codes. In\nmany cases, our ternary construction yields even better codes. For the\nnonbinary asymmetric channel, our methods construct linear codes for many\nlengths and distances which are superior to the linear codes of the same length\ncapable of correcting the same number of symmetric errors.\n  In the binary case, Varshamov has shown that almost all good linear codes for\nthe asymmetric channel are also good for the symmetric channel. Our results\nindicate that Varshamov's argument does not extend to the nonbinary case, i.e.,\none can find better linear codes for asymmetric channels than for symmetric\nones.\n", "contributors": [{"name": "Grassl, Markus", "sameAs": [], "familyName": "Grassl", "additionalName": "", "givenName": "Markus", "email": ""}, {"name": "Shor, Peter", "sameAs": [], "familyName": "Shor", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Smith, Graeme", "sameAs": [], "familyName": "Smith", "additionalName": "", "givenName": "Graeme", "email": ""}, {"name": "Smolin, John", "sameAs": [], "familyName": "Smolin", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Zeng, Bei", "sameAs": [], "familyName": "Zeng", "additionalName": "", "givenName": "Bei", "email": ""}], "title": "New Constructions of Codes for Asymmetric Channels via Concatenation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-10-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.7536", "IEEE Transactions on Information Theory, vol. 61, no. 4, pp.\n  1879-1886, 2015", "doi:10.1109/TIT.2015.2401567", "oai:arXiv.org:1310.7536"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We present new constructions of codes for asymmetric channels for both binary\nand nonbinary alphabets, based on methods of generalized code concatenation.\nFor the binary asymmetric channel, our methods construct nonlinear\nsingle-error-correcting codes from ternary outer codes. We show that some of\nthe Varshamov-Tenengol'ts-Constantin-Rao codes, a class of binary nonlinear\ncodes for this channel, have a nice structure when viewed as ternary codes. In\nmany cases, our ternary construction yields even better codes. For the\nnonbinary asymmetric channel, our methods construct linear codes for many\nlengths and distances which are superior to the linear codes of the same length\ncapable of correcting the same number of symmetric errors.\n  In the binary case, Varshamov has shown that almost all good linear codes for\nthe asymmetric channel are also good for the symmetric channel. Our results\nindicate that Varshamov's argument does not extend to the nonbinary case, i.e.,\none can find better linear codes for asymmetric channels than for symmetric\nones.\n", "Comment: 9 pages, 3 figures, 4 tables"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.7536"}}, {"publisher": {"name": ""}, "description": "  Feature selection with specific multivariate performance measures is the key\nto the success of many applications, such as image retrieval and text\nclassification. The existing feature selection methods are usually designed for\nclassification error. In this paper, we propose a generalized sparse\nregularizer. Based on the proposed regularizer, we present a unified feature\nselection framework for general loss functions. In particular, we study the\nnovel feature selection paradigm by optimizing multivariate performance\nmeasures. The resultant formulation is a challenging problem for\nhigh-dimensional data. Hence, a two-layer cutting plane algorithm is proposed\nto solve this problem, and the convergence is presented. In addition, we adapt\nthe proposed method to optimize multivariate measures for multiple instance\nlearning problems. The analyses by comparing with the state-of-the-art feature\nselection methods show that the proposed method is superior to others.\nExtensive experiments on large-scale and high-dimensional real world datasets\nshow that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a\nsmall subset of features, and achieves significantly improved performances over\nSVM$^{perf}$ in terms of $F_1$-score.\n", "contributors": [{"name": "Mao, Qi", "sameAs": [], "familyName": "Mao", "additionalName": "", "givenName": "Qi", "email": ""}, {"name": "Tsang, Ivor W.", "sameAs": [], "familyName": "Tsang", "additionalName": "W.", "givenName": "Ivor", "email": ""}], "title": "A Feature Selection Method for Multivariate Performance Measures", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-03-05", "2013-05-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1103.1013", "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2012", "doi:10.1109/TPAMI.2012.266", "oai:arXiv.org:1103.1013"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Feature selection with specific multivariate performance measures is the key\nto the success of many applications, such as image retrieval and text\nclassification. The existing feature selection methods are usually designed for\nclassification error. In this paper, we propose a generalized sparse\nregularizer. Based on the proposed regularizer, we present a unified feature\nselection framework for general loss functions. In particular, we study the\nnovel feature selection paradigm by optimizing multivariate performance\nmeasures. The resultant formulation is a challenging problem for\nhigh-dimensional data. Hence, a two-layer cutting plane algorithm is proposed\nto solve this problem, and the convergence is presented. In addition, we adapt\nthe proposed method to optimize multivariate measures for multiple instance\nlearning problems. The analyses by comparing with the state-of-the-art feature\nselection methods show that the proposed method is superior to others.\nExtensive experiments on large-scale and high-dimensional real world datasets\nshow that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a\nsmall subset of features, and achieves significantly improved performances over\nSVM$^{perf}$ in terms of $F_1$-score.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1103.1013"}}, {"publisher": {"name": ""}, "description": "  Feature selection is an essential problem in computer vision, important for\ncategory learning and recognition. Along with the rapid development of a wide\nvariety of visual features and classifiers, there is a growing need for\nefficient feature selection and combination methods, to construct powerful\nclassifiers for more complex and higher-level recognition tasks. We propose an\nalgorithm that efficiently discovers sparse, compact representations of input\nfeatures or classifiers, from a vast sea of candidates, with important\noptimality properties, low computational cost and excellent accuracy in\npractice. Different from boosting, we start with a discriminant linear\nclassification formulation that encourages sparse solutions. Then we obtain an\nequivalent unsupervised clustering problem that jointly discovers ensembles of\ndiverse features. They are independently valuable but even more powerful when\nunited in a cluster of classifiers. We evaluate our method on the task of\nlarge-scale recognition in video and show that it significantly outperforms\nclassical selection approaches, such as AdaBoost and greedy forward-backward\nselection, and powerful classifiers such as SVMs, in speed of training and\nperformance, especially in the case of limited training data.\n", "contributors": [{"name": "Leordeanu, Marius", "sameAs": [], "familyName": "Leordeanu", "additionalName": "", "givenName": "Marius", "email": ""}, {"name": "Radu, Alexandra", "sameAs": [], "familyName": "Radu", "additionalName": "", "givenName": "Alexandra", "email": ""}, {"name": "Sukthankar, Rahul", "sameAs": [], "familyName": "Sukthankar", "additionalName": "", "givenName": "Rahul", "email": ""}], "title": "Features in Concert: Discriminative Feature Selection meets Unsupervised\n  Clustering", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7714", "oai:arXiv.org:1411.7714"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Feature selection is an essential problem in computer vision, important for\ncategory learning and recognition. Along with the rapid development of a wide\nvariety of visual features and classifiers, there is a growing need for\nefficient feature selection and combination methods, to construct powerful\nclassifiers for more complex and higher-level recognition tasks. We propose an\nalgorithm that efficiently discovers sparse, compact representations of input\nfeatures or classifiers, from a vast sea of candidates, with important\noptimality properties, low computational cost and excellent accuracy in\npractice. Different from boosting, we start with a discriminant linear\nclassification formulation that encourages sparse solutions. Then we obtain an\nequivalent unsupervised clustering problem that jointly discovers ensembles of\ndiverse features. They are independently valuable but even more powerful when\nunited in a cluster of classifiers. We evaluate our method on the task of\nlarge-scale recognition in video and show that it significantly outperforms\nclassical selection approaches, such as AdaBoost and greedy forward-backward\nselection, and powerful classifiers such as SVMs, in speed of training and\nperformance, especially in the case of limited training data.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7714"}}, {"publisher": {"name": ""}, "description": "  Random Indexing is a simple implementation of Random Projections with a wide\nrange of applications. It can solve a variety of problems with good accuracy\nwithout introducing much complexity. Here we use it for identifying the\nlanguage of text samples. We present a novel method of generating language\nrepresentation vectors using letter blocks. Further, we show that the method is\neasily implemented and requires little computational power and space.\nExperiments on a number of model parameters illustrate certain properties about\nhigh dimensional sparse vector representations of data. Proof of statistically\nrelevant language vectors are shown through the extremely high success of\nvarious language recognition tasks. On a difficult data set of 21,000 short\nsentences from 21 different languages, our model performs a language\nrecognition task and achieves 97.8% accuracy, comparable to state-of-the-art\nmethods.\n", "contributors": [{"name": "Joshi, Aditya", "sameAs": [], "familyName": "Joshi", "additionalName": "", "givenName": "Aditya", "email": ""}, {"name": "Halseth, Johan", "sameAs": [], "familyName": "Halseth", "additionalName": "", "givenName": "Johan", "email": ""}, {"name": "Kanerva, Pentti", "sameAs": [], "familyName": "Kanerva", "additionalName": "", "givenName": "Pentti", "email": ""}], "title": "Language Recognition using Random Indexing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-22", "2015-02-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7026", "oai:arXiv.org:1412.7026"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Random Indexing is a simple implementation of Random Projections with a wide\nrange of applications. It can solve a variety of problems with good accuracy\nwithout introducing much complexity. Here we use it for identifying the\nlanguage of text samples. We present a novel method of generating language\nrepresentation vectors using letter blocks. Further, we show that the method is\neasily implemented and requires little computational power and space.\nExperiments on a number of model parameters illustrate certain properties about\nhigh dimensional sparse vector representations of data. Proof of statistically\nrelevant language vectors are shown through the extremely high success of\nvarious language recognition tasks. On a difficult data set of 21,000 short\nsentences from 21 different languages, our model performs a language\nrecognition task and achieves 97.8% accuracy, comparable to state-of-the-art\nmethods.\n", "Comment: 7 pages, 1 figures, 2 tables, ICLR 2015"]}}], "languages": [null], "subjects": ["computer science - computation and language", "computer science - learning"], "providerUpdatedDateTime": "2015-03-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7026"}}, {"publisher": {"name": ""}, "description": "  In Multi-Channel Multi-Radio Wireless Mesh Networks (MCMR-WMN), finding the\noptimal routing by satisfying the Quality of Service (QoS) constraints is an\nambitious task. Multiple paths are available from the source node to the\ngateway for reliability, and sometimes it is necessary to deal with failures of\nthe link in WMN. A major challenge in a MCMR-WMN is finding the routing with\nQoS satisfied and an interference free path from the redundant paths, in order\nto transmit the packets through this path. The Particle Swarm Optimization\n(PSO) is an optimization technique to find the candidate solution in the search\nspace optimally, and it applies artificial intelligence to solve the routing\nproblem. On the other hand, the Genetic Algorithm (GA) is a population based\nmeta-heuristic optimization algorithm inspired by the natural evolution, such\nas selection,mutation and crossover. PSO can easily fall into a local optimal\nsolution, at the same time GA is not suitable for dynamic data due to the\nunderlying dynamic network. In this paper we propose an optimal intelligent\nrouting, using a Hybrid PSO-GA, which also meets the QoS constraints. Moreover,\nit integrates the strength of PSO and GA. The QoS constraints, such as\nbandwidth, delay, jitter and interference are transformed into penalty\nfunctions. The simulation results show that the hybrid approach outperforms PSO\nand GA individually, and it takes less convergence time comparatively, keeping\naway from converging prematurely.\n  Keywords: Wireless mesh networks, Multi-radio, Multi-channel, Particle swarm\noptimization, Genetic algorithm, Quality of service.\n", "contributors": [{"name": "Sarasvathi, V.", "sameAs": [], "familyName": "Sarasvathi", "additionalName": "", "givenName": "V.", "email": ""}, {"name": "Iyengar, N. Ch. S. N.", "sameAs": [], "familyName": "Iyengar", "additionalName": "Ch. S. N.", "givenName": "N.", "email": ""}, {"name": "Saha, Snehanshu", "sameAs": [], "familyName": "Saha", "additionalName": "", "givenName": "Snehanshu", "email": ""}], "title": "QoS Guaranteed Intelligent Routing Using Hybrid PSO-GA in Wireless Mesh\n  Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03639", "doi:10.1515/cait-2015-0007", "oai:arXiv.org:1503.03639"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In Multi-Channel Multi-Radio Wireless Mesh Networks (MCMR-WMN), finding the\noptimal routing by satisfying the Quality of Service (QoS) constraints is an\nambitious task. Multiple paths are available from the source node to the\ngateway for reliability, and sometimes it is necessary to deal with failures of\nthe link in WMN. A major challenge in a MCMR-WMN is finding the routing with\nQoS satisfied and an interference free path from the redundant paths, in order\nto transmit the packets through this path. The Particle Swarm Optimization\n(PSO) is an optimization technique to find the candidate solution in the search\nspace optimally, and it applies artificial intelligence to solve the routing\nproblem. On the other hand, the Genetic Algorithm (GA) is a population based\nmeta-heuristic optimization algorithm inspired by the natural evolution, such\nas selection,mutation and crossover. PSO can easily fall into a local optimal\nsolution, at the same time GA is not suitable for dynamic data due to the\nunderlying dynamic network. In this paper we propose an optimal intelligent\nrouting, using a Hybrid PSO-GA, which also meets the QoS constraints. Moreover,\nit integrates the strength of PSO and GA. The QoS constraints, such as\nbandwidth, delay, jitter and interference are transformed into penalty\nfunctions. The simulation results show that the hybrid approach outperforms PSO\nand GA individually, and it takes less convergence time comparatively, keeping\naway from converging prematurely.\n  Keywords: Wireless mesh networks, Multi-radio, Multi-channel, Particle swarm\noptimization, Genetic algorithm, Quality of service.\n", "Comment: 15 pages in Cybernetics and Information Technologies,Volume 15, No 1,\n  2015"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03639"}}, {"publisher": {"name": ""}, "description": "  We discuss some results around the following question: Let $f$ be a\nnonconstant complex entire function and $a$, $b$ two distinct complex numbers.\nIf $f$ and its derivative $f'$ share their simple $a$-points and also share the\nvalue $b$, does this imply $f\\equiv f'$?\n", "contributors": [{"name": "Schweizer, Andreas", "sameAs": [], "familyName": "Schweizer", "additionalName": "", "givenName": "Andreas", "email": ""}], "title": "Entire functions sharing simple $a$-points with their first derivative\n  II", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2719", "oai:arXiv.org:1411.2719"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We discuss some results around the following question: Let $f$ be a\nnonconstant complex entire function and $a$, $b$ two distinct complex numbers.\nIf $f$ and its derivative $f'$ share their simple $a$-points and also share the\nvalue $b$, does this imply $f\\equiv f'$?\n", "Comment: 11 pages; comments welcome"]}}], "languages": [null], "subjects": ["secondary 30d45", "primary 30d35", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2719"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "This experience report builds on an earlier study in which we interviewed eight project teams that were using iterative incremental lifecycles. In the study, we captured the practices the teams felt contributed to rapid delivery. We identified a mix of Agile and architecture practices that teams apply to rapidly field software and minimize disruption and delay. In this paper, we elaborate one practice from the study, prototyping with quality attribute focus. We compared two experiences in prototyping focused on quality attribute considerations applied on Scrum projects. We observe through interviews that feature development and prototyping practice spans multiple levels: feature development/sprint, release planning, and portfolio planning. We also observe other factors including rapid trade-off analysis, flexible architecture, and adoption of a set of enabling prototyping guidelines. The analysis of the observations sheds light on several aspects of the practice that enable the team to respond quickly and efficiently when prototype feedback suggests architectural change.", "contributors": [{"name": "Bellomo, Stephany", "sameAs": [], "familyName": "Bellomo", "additionalName": "", "givenName": "Stephany", "email": ""}, {"name": "Nord, Robert", "sameAs": [], "familyName": "Nord", "additionalName": "", "givenName": "Robert", "email": ""}, {"name": "Ozkaya, Ipek", "sameAs": [], "familyName": "Ozkaya", "additionalName": "", "givenName": "Ipek", "email": ""}], "title": "Elaboration on an Integrated Architecture and Requirement Practice: Prototyping with Quality Attribute Focus", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2015-01-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/sei/824", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1821&amp;context=sei", "oai:repository.cmu.edu:sei-1821"]}}, {"name": "setSpec", "properties": {"setSpec": "publication:sei"}}, {"name": "description", "properties": {"description": "This experience report builds on an earlier study in which we interviewed eight project teams that were using iterative incremental lifecycles. In the study, we captured the practices the teams felt contributed to rapid delivery. We identified a mix of Agile and architecture practices that teams apply to rapidly field software and minimize disruption and delay. In this paper, we elaborate one practice from the study, prototyping with quality attribute focus. We compared two experiences in prototyping focused on quality attribute considerations applied on Scrum projects. We observe through interviews that feature development and prototyping practice spans multiple levels: feature development/sprint, release planning, and portfolio planning. We also observe other factors including rapid trade-off analysis, flexible architecture, and adoption of a set of enabling prototyping guidelines. The analysis of the observations sheds light on several aspects of the practice that enable the team to respond quickly and efficiently when prototype feedback suggests architectural change."}}], "languages": [null], "subjects": ["software development practices", "requirements", "software engineering", "architecture trade-off", "quality attribute", "computer sciences", "prototyping", "release planning", "architecture", "agile software development"], "providerUpdatedDateTime": "2015-03-13T15:31:07", "uris": {"canonicalUri": "http://repository.cmu.edu/sei/824"}}, {"publisher": {"name": ""}, "description": "  A new approach is proposed, namely CSSF MIMO radar, which applies the\ntechnique of step frequency (SF) to compressive sensing (CS) based multi-input\nmulti-output (MIMO) radar. The proposed approach enables high resolution range,\nangle and Doppler estimation, while transmitting narrowband pulses. The problem\nof joint angle-Doppler-range estimation is first formulated to fit the CS\nframework, i.e., as an L1 optimization problem. Direct solution of this problem\nentails high complexity as it employs a basis matrix whose construction\nrequires discretization of the angle-Doppler-range space. Since high resolution\nrequires fine space discretization, the complexity of joint range, angle and\nDoppler estimation can be prohibitively high. For the case of slowly moving\ntargets, a technique is proposed that achieves significant complexity reduction\nby successively estimating angle-range and Doppler in a decoupled fashion and\nby employing initial estimates obtained via matched filtering to further reduce\nthe space that needs to be digitized. Numerical results show that the\ncombination of CS and SF results in a MIMO radar system that has superior\nresolution and requires far less data as compared to a system that uses a\nmatched filter with SF.\n", "contributors": [{"name": "Yu, Yao", "sameAs": [], "familyName": "Yu", "additionalName": "", "givenName": "Yao", "email": ""}, {"name": "Petropulu, Athina P.", "sameAs": [], "familyName": "Petropulu", "additionalName": "P.", "givenName": "Athina", "email": ""}, {"name": "Poor, H. Vincent", "sameAs": [], "familyName": "Poor", "additionalName": "Vincent", "givenName": "H.", "email": ""}], "title": "CSSF MIMO RADAR: Low-Complexity Compressive Sensing Based MIMO Radar\n  That Uses Step Frequency", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-01-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.2719", "oai:arXiv.org:1101.2719"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  A new approach is proposed, namely CSSF MIMO radar, which applies the\ntechnique of step frequency (SF) to compressive sensing (CS) based multi-input\nmulti-output (MIMO) radar. The proposed approach enables high resolution range,\nangle and Doppler estimation, while transmitting narrowband pulses. The problem\nof joint angle-Doppler-range estimation is first formulated to fit the CS\nframework, i.e., as an L1 optimization problem. Direct solution of this problem\nentails high complexity as it employs a basis matrix whose construction\nrequires discretization of the angle-Doppler-range space. Since high resolution\nrequires fine space discretization, the complexity of joint range, angle and\nDoppler estimation can be prohibitively high. For the case of slowly moving\ntargets, a technique is proposed that achieves significant complexity reduction\nby successively estimating angle-range and Doppler in a decoupled fashion and\nby employing initial estimates obtained via matched filtering to further reduce\nthe space that needs to be digitized. Numerical results show that the\ncombination of CS and SF results in a MIMO radar system that has superior\nresolution and requires far less data as compared to a system that uses a\nmatched filter with SF.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.2719"}}, {"publisher": {"name": ""}, "description": "  In this essay the stance on robots is discussed. The attitude against robots\nin history, starting in Ancient Greek culture until the industrial revolution\nis described. The uncanny valley and some possible explanations are given. Some\ndifferences in Western and Asian understanding of robots are listed and finally\nwe answer the question raised with the title.\n", "contributors": [{"name": "Barthelmess, Ulrike", "sameAs": [], "familyName": "Barthelmess", "additionalName": "", "givenName": "Ulrike", "email": ""}, {"name": "Furbach, Ulrich", "sameAs": [], "familyName": "Furbach", "additionalName": "", "givenName": "Ulrich", "email": ""}], "title": "Do we need Asimov's Laws?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-04-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.0961", "oai:arXiv.org:1405.0961"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this essay the stance on robots is discussed. The attitude against robots\nin history, starting in Ancient Greek culture until the industrial revolution\nis described. The uncanny valley and some possible explanations are given. Some\ndifferences in Western and Asian understanding of robots are listed and finally\nwe answer the question raised with the title.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2014-11-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.0961"}}, {"publisher": {"name": ""}, "description": "  Two procedures to compute the output distribution phi_S of certain stack\nfilters S (so called erosion-dilation cascades) are given. One rests on the\ndisjunctive normal form of S and also yields the rank selection probabilities.\nThe other is based on inclusion-exclusion and e.g. yields phi_S for some\nimportant LULU-operators S. Properties of phi_S can be used to characterize\nsmoothing properties of S. One of the methods discussed also allows for the\ncalculation of the reliability polynomial of any positive Boolean function\n(e.g. one derived from a connected graph).\n", "contributors": [{"name": "Anguelov, R.", "sameAs": [], "familyName": "Anguelov", "additionalName": "", "givenName": "R.", "email": ""}, {"name": "Butler, P. W.", "sameAs": [], "familyName": "Butler", "additionalName": "W.", "givenName": "P.", "email": ""}, {"name": "Rohwer, C. H.", "sameAs": [], "familyName": "Rohwer", "additionalName": "H.", "givenName": "C.", "email": ""}, {"name": "Wild, M.", "sameAs": [], "familyName": "Wild", "additionalName": "", "givenName": "M.", "email": ""}], "title": "The output distribution of important LULU-operators", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-03-23", "2014-10-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1003.4406", "doi:10.2989/16073606.2014.981684", "oai:arXiv.org:1003.4406"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Two procedures to compute the output distribution phi_S of certain stack\nfilters S (so called erosion-dilation cascades) are given. One rests on the\ndisjunctive normal form of S and also yields the rank selection probabilities.\nThe other is based on inclusion-exclusion and e.g. yields phi_S for some\nimportant LULU-operators S. Properties of phi_S can be used to characterize\nsmoothing properties of S. One of the methods discussed also allows for the\ncalculation of the reliability polynomial of any positive Boolean function\n(e.g. one derived from a connected graph).\n", "Comment: 20 pages, up to trivial differences this is the final version to be\n  published in Quaestiones Mathematicae 2015"]}}], "languages": [null], "subjects": ["computer science - other computer science", "62e15", "mathematics - probability"], "providerUpdatedDateTime": "2014-10-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1003.4406"}}, {"publisher": {"name": ""}, "description": "  This paper has been withdrawn due to an incorrect proof.\n", "contributors": [{"name": "Jose, Jubin", "sameAs": [], "familyName": "Jose", "additionalName": "", "givenName": "Jubin", "email": ""}, {"name": "Mitliagkas, Ioannis", "sameAs": [], "familyName": "Mitliagkas", "additionalName": "", "givenName": "Ioannis", "email": ""}, {"name": "Vishwanath, Sriram", "sameAs": [], "familyName": "Vishwanath", "additionalName": "", "givenName": "Sriram", "email": ""}], "title": "Sum Capacity of Gaussian Interfering Multiple Access Channels in the Low\n  Interference Regime", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-05-10", "2011-05-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.2096", "oai:arXiv.org:1105.2096"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper has been withdrawn due to an incorrect proof.\n", "Comment: This paper has been withdrawn due to an incorrect proof"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.2096"}}, {"publisher": {"name": ""}, "description": "  We describe algorithm MINRES-QLP and its FORTRAN 90 implementation for\nsolving symmetric or Hermitian linear systems or least-squares problems. If the\nsystem is singular, MINRES-QLP computes the unique minimum-length solution\n(also known as the pseudoinverse solution), which generally eludes MINRES. In\nall cases, it overcomes a potential instability in the original MINRES\nalgorithm. A positive-definite preconditioner may be supplied. Our FORTRAN 90\nimplementation illustrates a design pattern that allows users to make problem\ndata known to the solver but hidden and secure from other program units. In\nparticular, we circumvent the need for reverse communication. While we focus\nhere on a FORTRAN 90 implementation, we also provide and maintain MATLAB\nversions of MINRES and MINRES-QLP.\n", "contributors": [{"name": "Choi, Sou-Cheng T.", "sameAs": [], "familyName": "Choi", "additionalName": "T.", "givenName": "Sou-Cheng", "email": ""}, {"name": "Saunders, Michael A.", "sameAs": [], "familyName": "Saunders", "additionalName": "A.", "givenName": "Michael", "email": ""}], "title": "ALGORITHM 937: MINRES-QLP for Singular Symmetric and Hermitian Linear\n  Equations and Least-Squares Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-01-12", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1301.2707", "doi:10.1145/2527267", "oai:arXiv.org:1301.2707"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We describe algorithm MINRES-QLP and its FORTRAN 90 implementation for\nsolving symmetric or Hermitian linear systems or least-squares problems. If the\nsystem is singular, MINRES-QLP computes the unique minimum-length solution\n(also known as the pseudoinverse solution), which generally eludes MINRES. In\nall cases, it overcomes a potential instability in the original MINRES\nalgorithm. A positive-definite preconditioner may be supplied. Our FORTRAN 90\nimplementation illustrates a design pattern that allows users to make problem\ndata known to the solver but hidden and secure from other program units. In\nparticular, we circumvent the need for reverse communication. While we focus\nhere on a FORTRAN 90 implementation, we also provide and maintain MATLAB\nversions of MINRES and MINRES-QLP.\n", "Comment: 14 pages and 1 figure"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - mathematical software", "computer science - numerical analysis"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1301.2707"}}, {"publisher": {"name": ""}, "description": "  Given a mixed Hodge module and a meromorphic function f on a complex\nmanifold, we associate to these data a filtration (the irregular Hodge\nfiltration) on the exponentially twisted holonomic module, which extends the\nconstruction of http://arxiv.org/abs/1302.4537. We show the strictness of the\npush-forward filtered D-module through any projective morphism, by using the\ntheory of mixed twistor D-modules of T. Mochizuki. We consider the example of\nthe rescaling of a regular function f, which leads to an expression of the\nirregular Hodge filtration of the Laplace transform of the Gauss-Manin systems\nof f in terms of the Harder-Narasimhan filtration of the Kontsevich bundles\nassociated with f.\n", "contributors": [{"name": "Sabbah, Claude", "sameAs": [], "familyName": "Sabbah", "additionalName": "", "givenName": "Claude", "email": ""}, {"name": "Yu, Jeng-Daw", "sameAs": [], "familyName": "Yu", "additionalName": "", "givenName": "Jeng-Daw", "email": ""}], "title": "On the irregular Hodge filtration of exponentially twisted mixed Hodge\n  modules", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-05", "2015-04-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.1339", "oai:arXiv.org:1406.1339"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Given a mixed Hodge module and a meromorphic function f on a complex\nmanifold, we associate to these data a filtration (the irregular Hodge\nfiltration) on the exponentially twisted holonomic module, which extends the\nconstruction of http://arxiv.org/abs/1302.4537. We show the strictness of the\npush-forward filtered D-module through any projective morphism, by using the\ntheory of mixed twistor D-modules of T. Mochizuki. We consider the example of\nthe rescaling of a regular function f, which leads to an expression of the\nirregular Hodge filtration of the Laplace transform of the Gauss-Manin systems\nof f in terms of the Harder-Narasimhan filtration of the Kontsevich bundles\nassociated with f.\n", "Comment: 53 pages. V2: 56 pages, Introduction partly rewritten. Final revised\n  version to appear in Forum of Mathematics Sigma"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "14f40", "32s35", "32s40", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-04-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.1339"}}, {"publisher": {"name": ""}, "description": "  Let $S(\\phi)= \\{z:\\;|\\arg(z)|\\geq \\phi\\}$ be a sector on the complex plane\n$\\CC$. If $\\phi\\geq \\pi/2$, then $S(\\phi)$ is a convex set and, according to\nthe Gauss-Lucas theorem, if a polynomial $p(z)$ has all its zeros on $S(\\phi)$,\nthen the same is true for the zeros of all its derivatives. In this paper is\nproved that if the polynomial $p(z)$ is with real and non negative\ncoefficients, then the same is true also for $\\phi < \\pi/2$, when the sector is\nnot a convex set on the complex plane.\n", "contributors": [{"name": "Sendov, Bl.", "sameAs": [], "familyName": "Sendov", "additionalName": "", "givenName": "Bl.", "email": ""}], "title": "Analogue of Gauss-Lucas theorem for non convex set on the complex plane", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-26", "2015-01-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.6425", "oai:arXiv.org:1402.6425"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  Let $S(\\phi)= \\{z:\\;|\\arg(z)|\\geq \\phi\\}$ be a sector on the complex plane\n$\\CC$. If $\\phi\\geq \\pi/2$, then $S(\\phi)$ is a convex set and, according to\nthe Gauss-Lucas theorem, if a polynomial $p(z)$ has all its zeros on $S(\\phi)$,\nthen the same is true for the zeros of all its derivatives. In this paper is\nproved that if the polynomial $p(z)$ is with real and non negative\ncoefficients, then the same is true also for $\\phi < \\pi/2$, when the sector is\nnot a convex set on the complex plane.\n"}}], "languages": [null], "subjects": ["30c15", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.6425"}}, {"publisher": {"name": ""}, "description": "  In this paper, we design a Collaborative-Hierarchical Sparse and Low-Rank\n(C-HiSLR) model that is natural for recognizing human emotion in visual data.\nPrevious attempts require explicit expression components, which are often\nunavailable and difficult to recover. Instead, our model exploits the lowrank\nproperty over expressive facial frames and rescue inexact sparse\nrepresentations by incorporating group sparsity. For the CK+ dataset, C-HiSLR\non raw expressive faces performs as competitive as the Sparse Representation\nbased Classification (SRC) applied on manually prepared emotions. C-HiSLR\nperforms even better than SRC in terms of true positive rate.\n", "contributors": [{"name": "Xiang, Xiang", "sameAs": [], "familyName": "Xiang", "additionalName": "", "givenName": "Xiang", "email": ""}, {"name": "Dao, Minh", "sameAs": [], "familyName": "Dao", "additionalName": "", "givenName": "Minh", "email": ""}, {"name": "Hager, Gregory D.", "sameAs": [], "familyName": "Hager", "additionalName": "D.", "givenName": "Gregory", "email": ""}, {"name": "Tran, Trac D.", "sameAs": [], "familyName": "Tran", "additionalName": "D.", "givenName": "Trac", "email": ""}], "title": "Hierarchical Sparse and Collaborative Low-Rank Representation for\n  Emotion Recognition", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-06", "2015-04-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1606", "oai:arXiv.org:1410.1606"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we design a Collaborative-Hierarchical Sparse and Low-Rank\n(C-HiSLR) model that is natural for recognizing human emotion in visual data.\nPrevious attempts require explicit expression components, which are often\nunavailable and difficult to recover. Instead, our model exploits the lowrank\nproperty over expressive facial frames and rescue inexact sparse\nrepresentations by incorporating group sparsity. For the CK+ dataset, C-HiSLR\non raw expressive faces performs as competitive as the Sparse Representation\nbased Classification (SRC) applied on manually prepared emotions. C-HiSLR\nperforms even better than SRC in terms of true positive rate.\n", "Comment: 5 pages, 5 figures; accepted to IEEE ICASSP 2015; programs available\n  at https://github.com/eglxiang/icassp15_emotion/"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1606"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "The Pitman-Yor process provides an elegant way to cluster data that exhibit power law behavior, where the number of clusters is unknown or unbounded. Unfortunately, inference in PitmanYor process-based models is typically slow and does not scale well with dataset size. In this paper we present new auxiliary-variable representations for the Pitman-Yor process and a special case of the hierarchical Pitman-Yor process that allows us to develop parallel inference algorithms that distribute inference both on the data space and the model space. We show that our method scales well with increasing data while avoiding any degradation in estimate quality", "contributors": [{"name": "Dubey, Avinava", "sameAs": [], "familyName": "Dubey", "additionalName": "", "givenName": "Avinava", "email": ""}, {"name": "Williamson, Sinead", "sameAs": [], "familyName": "Williamson", "additionalName": "", "givenName": "Sinead", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "Parallel Markov Chain Monte Carlo for Pitman-Yor Mixture Models", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-07-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/142", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1146&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1146"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "The Pitman-Yor process provides an elegant way to cluster data that exhibit power law behavior, where the number of clusters is unknown or unbounded. Unfortunately, inference in PitmanYor process-based models is typically slow and does not scale well with dataset size. In this paper we present new auxiliary-variable representations for the Pitman-Yor process and a special case of the hierarchical Pitman-Yor process that allows us to develop parallel inference algorithms that distribute inference both on the data space and the model space. We show that our method scales well with increasing data while avoiding any degradation in estimate quality"}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-30T21:01:46", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/142"}}, {"publisher": {"name": ""}, "description": "  This paper studies the problem of detecting the presence of a small dense\ncommunity planted in a large Erd\\H{o}s-R\\'enyi random graph $\\mathcal{G}(N,q)$,\nwhere the edge probability within the community exceeds $q$ by a constant\nfactor. Assuming the hardness of the planted clique detection problem, we show\nthat the computational complexity of detecting the community exhibits the\nfollowing phase transition phenomenon: As the graph size $N$ grows and the\ngraph becomes sparser according to $q=N^{-\\alpha}$, there exists a critical\nvalue of $\\alpha = \\frac{2}{3}$, below which there exists a computationally\nintensive procedure that can detect far smaller communities than any\ncomputationally efficient procedure, and above which a linear-time procedure is\nstatistically optimal. The results also lead to the average-case hardness\nresults for recovering the dense community and approximating the densest\n$K$-subgraph.\n", "contributors": [{"name": "Hajek, Bruce", "sameAs": [], "familyName": "Hajek", "additionalName": "", "givenName": "Bruce", "email": ""}, {"name": "Wu, Yihong", "sameAs": [], "familyName": "Wu", "additionalName": "", "givenName": "Yihong", "email": ""}, {"name": "Xu, Jiaming", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Jiaming", "email": ""}], "title": "Computational Lower Bounds for Community Detection on Random Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-25", "2015-03-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.6625", "oai:arXiv.org:1406.6625"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  This paper studies the problem of detecting the presence of a small dense\ncommunity planted in a large Erd\\H{o}s-R\\'enyi random graph $\\mathcal{G}(N,q)$,\nwhere the edge probability within the community exceeds $q$ by a constant\nfactor. Assuming the hardness of the planted clique detection problem, we show\nthat the computational complexity of detecting the community exhibits the\nfollowing phase transition phenomenon: As the graph size $N$ grows and the\ngraph becomes sparser according to $q=N^{-\\alpha}$, there exists a critical\nvalue of $\\alpha = \\frac{2}{3}$, below which there exists a computationally\nintensive procedure that can detect far smaller communities than any\ncomputationally efficient procedure, and above which a linear-time procedure is\nstatistically optimal. The results also lead to the average-case hardness\nresults for recovering the dense community and approximating the densest\n$K$-subgraph.\n", "Comment: 28 pages"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "computer science - computational complexity", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.6625"}}, {"publisher": {"name": ""}, "description": "  The idea to unite smartphones used as personal environmental sensors and\nhealth indicators into a scalable network for data collection and processing by\nthe internet-cloud is proposed. Access to the sensors, which are available in\nevery smartphone, will provide the appropriate software. Such a monitoring at\nthe global level would reveal the impact of the electromagnetic radiation,\nenvironmental pollution and weather factors on human health. Participation of\nstudents in these measurements increases their educational and social\nactivities.\n", "contributors": [{"name": "Shatalov, Vladimir", "sameAs": [], "familyName": "Shatalov", "additionalName": "", "givenName": "Vladimir", "email": ""}, {"name": "Martynyuk, Victor", "sameAs": [], "familyName": "Martynyuk", "additionalName": "", "givenName": "Victor", "email": ""}, {"name": "Saveliev, Maxim", "sameAs": [], "familyName": "Saveliev", "additionalName": "", "givenName": "Maxim", "email": ""}], "title": "Through Global Monitoring to School of the Future: Smartphone as a\n  Laboratory in Pocket of Each Student", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7949", "oai:arXiv.org:1412.7949"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The idea to unite smartphones used as personal environmental sensors and\nhealth indicators into a scalable network for data collection and processing by\nthe internet-cloud is proposed. Access to the sensors, which are available in\nevery smartphone, will provide the appropriate software. Such a monitoring at\nthe global level would reveal the impact of the electromagnetic radiation,\nenvironmental pollution and weather factors on human health. Participation of\nstudents in these measurements increases their educational and social\nactivities.\n", "Comment: Report on the on-line conference \"Cloud Technologies in\n  Education'2014 (December 26, 2014)\"\n  http://tmn.ccjournals.eu/index.php/cte/CTE2014/paper/view/81"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7949"}}, {"publisher": {"name": ""}, "description": "  Random walks are basic diffusion processes on networks and have applications\nin, for example, searching, navigation, ranking, and community detection.\nRecent recognition of the importance of temporal aspects on networks spurred\nstudies of random walks on temporal networks. Here we theoretically study two\ntypes of event-driven random walks on a stochastic temporal network model that\nproduces arbitrary distributions of interevent-times. In the so-called active\nrandom walk, the interevent-time is reinitialized on all links upon each\nmovement of the walker. In the so-called passive random walk, the\ninterevent-time is only reinitialized on the link that has been used last time,\nand it is a type of correlated random walk. We find that the steady state is\nalways the uniform density for the passive random walk. In contrast, for the\nactive random walk, it increases or decreases with the node's degree depending\non the distribution of interevent-times. The mean recurrence time of a node is\ninversely proportional to the degree for both active and passive random walks.\nFurthermore, the mean recurrence time does or does not depend on the\ndistribution of interevent-times for the active and passive random walks,\nrespectively.\n", "contributors": [{"name": "Speidel, Leo", "sameAs": [], "familyName": "Speidel", "additionalName": "", "givenName": "Leo", "email": ""}, {"name": "Lambiotte, Renaud", "sameAs": [], "familyName": "Lambiotte", "additionalName": "", "givenName": "Renaud", "email": ""}, {"name": "Aihara, Kazuyuki", "sameAs": [], "familyName": "Aihara", "additionalName": "", "givenName": "Kazuyuki", "email": ""}, {"name": "Masuda, Naoki", "sameAs": [], "familyName": "Masuda", "additionalName": "", "givenName": "Naoki", "email": ""}], "title": "Steady state and mean recurrence time for random walks on stochastic\n  temporal networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-17", "2015-01-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.4582", "Physical Review E, 91, 012806 (2015)", "doi:10.1103/PhysRevE.91.012806", "oai:arXiv.org:1407.4582"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Random walks are basic diffusion processes on networks and have applications\nin, for example, searching, navigation, ranking, and community detection.\nRecent recognition of the importance of temporal aspects on networks spurred\nstudies of random walks on temporal networks. Here we theoretically study two\ntypes of event-driven random walks on a stochastic temporal network model that\nproduces arbitrary distributions of interevent-times. In the so-called active\nrandom walk, the interevent-time is reinitialized on all links upon each\nmovement of the walker. In the so-called passive random walk, the\ninterevent-time is only reinitialized on the link that has been used last time,\nand it is a type of correlated random walk. We find that the steady state is\nalways the uniform density for the passive random walk. In contrast, for the\nactive random walk, it increases or decreases with the node's degree depending\non the distribution of interevent-times. The mean recurrence time of a node is\ninversely proportional to the degree for both active and passive random walks.\nFurthermore, the mean recurrence time does or does not depend on the\ndistribution of interevent-times for the active and passive random walks,\nrespectively.\n", "Comment: 5 figures"]}}], "languages": [null], "subjects": ["condensed matter - disordered systems and neural networks", "physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.4582"}}, {"publisher": {"name": ""}, "description": "  We describe extensive computational experiments on spectral properties of\nrandom objects - random cubic graphs, random planar triangulations, and Voronoi\nand Delaunay diagrams of random (uniformly distributed) point sets on the\nsphere). We look at bulk eigenvalue distribution, eigenvalue spacings, and\nlocality properties of eigenvectors. We also look at the statistics of\n\\emph{nodal domains} of eigenvectors on these graphs. In all cases we discover\ncompletely new (at least to this author) phenomena. The author has tried to\nrefrain from making specific conjectures, inviting the reader, instead, to\nmeditate on the data.\n", "contributors": [{"name": "Rivin, Igor", "sameAs": [], "familyName": "Rivin", "additionalName": "", "givenName": "Igor", "email": ""}], "title": "Spectral Experiments+", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-12", "2014-10-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6771", "oai:arXiv.org:1410.6771"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:cond-mat", "physics:hep-th", "physics:math-ph"]}}, {"name": "description", "properties": {"description": ["  We describe extensive computational experiments on spectral properties of\nrandom objects - random cubic graphs, random planar triangulations, and Voronoi\nand Delaunay diagrams of random (uniformly distributed) point sets on the\nsphere). We look at bulk eigenvalue distribution, eigenvalue spacings, and\nlocality properties of eigenvectors. We also look at the statistics of\n\\emph{nodal domains} of eigenvectors on these graphs. In all cases we discover\ncompletely new (at least to this author) phenomena. The author has tried to\nrefrain from making specific conjectures, inviting the reader, instead, to\nmeditate on the data.\n", "Comment: 24 pages"]}}], "languages": [null], "subjects": ["05c80", "60d05", "computer science - computational geometry", "high energy physics - theory", "60b20", "mathematical physics", "mathematics - spectral theory", "condensed matter - statistical mechanics", "mathematics - probability"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6771"}}, {"publisher": {"name": ""}, "description": "  Do different fields of knowledge require different research strategies? A\nnumerical model exploring different virtual knowledge landscapes, revealed two\ndiverging optimal search strategies. Trend following is maximized when the\npopularity of new discoveries determine the number of individuals researching\nit. This strategy works best when many researchers explore few large areas of\nknowledge. In contrast, individuals or small groups of researchers are better\nin discovering small bits of information in dispersed knowledge landscapes.\nBibliometric data of scientific publications showed a continuous bipolar\ndistribution of these strategies, ranging from natural sciences, with highly\ncited publications in journals containing a large number of articles, to the\nsocial sciences, with rarely cited publications in many journals containing a\nsmall number of articles. The natural sciences seem to adapt their research\nstrategies to landscapes with large concentrated knowledge clusters, whereas\nsocial sciences seem to have adapted to search in landscapes with many small\nisolated knowledge clusters. Similar bipolar distributions were obtained when\ncomparing levels of insularity estimated by indicators of international\ncollaboration and levels of country-self citations: researchers in academic\nareas with many journals such as social sciences, arts and humanities, were the\nmost isolated, and that was true in different regions of the world. The work\nshows that quantitative measures estimating differences between academic\ndisciplines improve our understanding of different research strategies,\neventually helping interdisciplinary research and may be also help improve\nscience policies worldwide.\n", "contributors": [{"name": "Jaffe, Klaus", "sameAs": [], "familyName": "Jaffe", "additionalName": "", "givenName": "Klaus", "email": ""}], "title": "Social and Natural Sciences Differ in Their Research Strategies, Adapted\n  to Work for Different Knowledge Landscapes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-20", "2015-04-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.5107", "PLoS ONE 9(11): e113901. (2014)", "doi:10.1371/journal.pone.0113901", "oai:arXiv.org:1403.5107"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Do different fields of knowledge require different research strategies? A\nnumerical model exploring different virtual knowledge landscapes, revealed two\ndiverging optimal search strategies. Trend following is maximized when the\npopularity of new discoveries determine the number of individuals researching\nit. This strategy works best when many researchers explore few large areas of\nknowledge. In contrast, individuals or small groups of researchers are better\nin discovering small bits of information in dispersed knowledge landscapes.\nBibliometric data of scientific publications showed a continuous bipolar\ndistribution of these strategies, ranging from natural sciences, with highly\ncited publications in journals containing a large number of articles, to the\nsocial sciences, with rarely cited publications in many journals containing a\nsmall number of articles. The natural sciences seem to adapt their research\nstrategies to landscapes with large concentrated knowledge clusters, whereas\nsocial sciences seem to have adapted to search in landscapes with many small\nisolated knowledge clusters. Similar bipolar distributions were obtained when\ncomparing levels of insularity estimated by indicators of international\ncollaboration and levels of country-self citations: researchers in academic\nareas with many journals such as social sciences, arts and humanities, were the\nmost isolated, and that was true in different regions of the world. The work\nshows that quantitative measures estimating differences between academic\ndisciplines improve our understanding of different research strategies,\neventually helping interdisciplinary research and may be also help improve\nscience policies worldwide.\n", "Comment: Formerly called: Simulations suggest that social and natural sciences\n  differ in their research strategies adapted to work for different knowledge\n  landscapes"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - digital libraries"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.5107"}}, {"publisher": {"name": ""}, "description": "  The theory of slice regular functions of a quaternionic variable, introduced\nin 2006 by Gentili and Struppa, extends the notion of holomorphic function to\nthe quaternionic setting. This fast growing theory is already rich of many\nresults and has interesting applications. In this setting, the present paper is\ndevoted to introduce and study the quaternionic counterparts of Hardy spaces of\nholomorphic functions of one complex variable. The basic properties of the\ntheory of quaternionic Hardy spaces are investigated, and in particular a\nPoisson-type representation formula, the notions of outer function, singular\nfunction and inner function are given. A quaternionic (partial) counterpart of\nthe classical $H^p$-factorization theorem is proved. This last result assumes a\nparticularly interesting formulation for a large subclass of slice regular\nfunctions, where it is obtained in terms of an outer function, a singular\nfunction and a quaternionic Blaschke product.\n", "contributors": [{"name": "de Fabritiis, Chiara", "sameAs": [], "familyName": "de Fabritiis", "additionalName": "", "givenName": "Chiara", "email": ""}, {"name": "Gentili, Graziano", "sameAs": [], "familyName": "Gentili", "additionalName": "", "givenName": "Graziano", "email": ""}, {"name": "Sarfatti, Giulia", "sameAs": [], "familyName": "Sarfatti", "additionalName": "", "givenName": "Giulia", "email": ""}], "title": "Quaternionic Hardy spaces", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-04", "2015-03-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.1234", "oai:arXiv.org:1404.1234"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The theory of slice regular functions of a quaternionic variable, introduced\nin 2006 by Gentili and Struppa, extends the notion of holomorphic function to\nthe quaternionic setting. This fast growing theory is already rich of many\nresults and has interesting applications. In this setting, the present paper is\ndevoted to introduce and study the quaternionic counterparts of Hardy spaces of\nholomorphic functions of one complex variable. The basic properties of the\ntheory of quaternionic Hardy spaces are investigated, and in particular a\nPoisson-type representation formula, the notions of outer function, singular\nfunction and inner function are given. A quaternionic (partial) counterpart of\nthe classical $H^p$-factorization theorem is proved. This last result assumes a\nparticularly interesting formulation for a large subclass of slice regular\nfunctions, where it is obtained in terms of an outer function, a singular\nfunction and a quaternionic Blaschke product.\n", "Comment: 31 pages, some proofs shortened, some references added"]}}], "languages": [null], "subjects": ["30h10", "30g35", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.1234"}}, {"publisher": {"name": ""}, "description": "  Identifying communities has always been a fundamental task in analysis of\ncomplex networks. Many methods have been devised over the last decade for\ndetection of communities. Amongst them, the label propagation algorithm brings\ngreat scalability together with high accuracy. However, it has one major flaw;\nwhen the community structure in the network is not clear enough, it will assign\nevery node the same label, thus detecting the whole graph as one giant\ncommunity. We have addressed this issue by setting a capacity for communities,\nstarting from a small value and gradually increasing it over time. Preliminary\nresults show that not only our extension improves the detection capability of\nclassic label propagation algorithm when communities are not clearly\ndetectable, but also improves the overall quality of the identified clusters in\ncomplex networks with a clear community structure.\n", "contributors": [{"name": "Rezaei, Aria", "sameAs": [], "familyName": "Rezaei", "additionalName": "", "givenName": "Aria", "email": ""}, {"name": "Far, Saeed Mahlouji", "sameAs": [], "familyName": "Far", "additionalName": "Mahlouji", "givenName": "Saeed", "email": ""}, {"name": "Soleymani, Mahdieh", "sameAs": [], "familyName": "Soleymani", "additionalName": "", "givenName": "Mahdieh", "email": ""}], "title": "Controlled Label Propagation: Preventing Over-Propagation through\n  Gradual Expansion", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04694", "oai:arXiv.org:1503.04694"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Identifying communities has always been a fundamental task in analysis of\ncomplex networks. Many methods have been devised over the last decade for\ndetection of communities. Amongst them, the label propagation algorithm brings\ngreat scalability together with high accuracy. However, it has one major flaw;\nwhen the community structure in the network is not clear enough, it will assign\nevery node the same label, thus detecting the whole graph as one giant\ncommunity. We have addressed this issue by setting a capacity for communities,\nstarting from a small value and gradually increasing it over time. Preliminary\nresults show that not only our extension improves the detection capability of\nclassic label propagation algorithm when communities are not clearly\ndetectable, but also improves the overall quality of the identified clusters in\ncomplex networks with a clear community structure.\n", "Comment: 8 pages, 5 figures, conference"]}}], "languages": [null], "subjects": ["computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04694"}}, {"publisher": {"name": ""}, "description": "  This article gives theoretical insights into the performance of K-SVD, a\ndictionary learning algorithm that has gained significant popularity in\npractical applications. The particular question studied here is when a\ndictionary $\\Phi\\in \\mathbb{R}^{d \\times K}$ can be recovered as local minimum\nof the minimisation criterion underlying K-SVD from a set of $N$ training\nsignals $y_n =\\Phi x_n$. A theoretical analysis of the problem leads to two\ntypes of identifiability results assuming the training signals are generated\nfrom a tight frame with coefficients drawn from a random symmetric\ndistribution. First, asymptotic results showing, that in expectation the\ngenerating dictionary can be recovered exactly as a local minimum of the K-SVD\ncriterion if the coefficient distribution exhibits sufficient decay. Second,\nbased on the asymptotic results it is demonstrated that given a finite number\nof training samples $N$, such that $N/\\log N = O(K^3d)$, except with\nprobability $O(N^{-Kd})$ there is a local minimum of the K-SVD criterion within\ndistance $O(KN^{-1/4})$ to the generating dictionary.\n", "contributors": [{"name": "Schnass, Karin", "sameAs": [], "familyName": "Schnass", "additionalName": "", "givenName": "Karin", "email": ""}], "title": "On the Identifiability of Overcomplete Dictionaries via the Minimisation\n  Principle Underlying K-SVD", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-01-15", "2015-04-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1301.3375", "Applied and Computational Harmonic Analysis, Volume 37, Issue 3,\n  November 2014, Pages 464-491", "doi:10.1016/j.acha.2014.01.005", "oai:arXiv.org:1301.3375"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This article gives theoretical insights into the performance of K-SVD, a\ndictionary learning algorithm that has gained significant popularity in\npractical applications. The particular question studied here is when a\ndictionary $\\Phi\\in \\mathbb{R}^{d \\times K}$ can be recovered as local minimum\nof the minimisation criterion underlying K-SVD from a set of $N$ training\nsignals $y_n =\\Phi x_n$. A theoretical analysis of the problem leads to two\ntypes of identifiability results assuming the training signals are generated\nfrom a tight frame with coefficients drawn from a random symmetric\ndistribution. First, asymptotic results showing, that in expectation the\ngenerating dictionary can be recovered exactly as a local minimum of the K-SVD\ncriterion if the coefficient distribution exhibits sufficient decay. Second,\nbased on the asymptotic results it is demonstrated that given a finite number\nof training samples $N$, such that $N/\\log N = O(K^3d)$, except with\nprobability $O(N^{-Kd})$ there is a local minimum of the K-SVD criterion within\ndistance $O(KN^{-1/4})$ to the generating dictionary.\n", "Comment: 36 pages (double spaced), 3 figures, equivalent to final accepted\n  version"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1301.3375"}}, {"publisher": {"name": ""}, "description": "  Todays students are encouraged to study and develop expertise in more than\none national academic environment. As a matter of fact, their educational\nactivities inevitably occur in a variety of academic settings and even span\nseveral years. Consequently students academic results and progress are expected\nto be easily monitored and accessed nationally. The authors of the present\npaper have devised a student gradebook information network to be nationally\nemployed by all public and private universities and colleges. The papers deals\nwith the architectural principles underlying the system and discusses aspects\nrelated to data collection, data analysis and data storage across multiple\nmachines while providing a seamless view of entire infrastructure and service\ndelivery system from a single Web access point. The utility of the\narchitectural system is discussed in relationship with its major advantages:\nuser-friendliness, security access, flexibility, transparency, distributional\npower, and scalability. The major beneficiary of the system is the Romanian\nhigher education system.\n", "contributors": [{"name": "Turcu, Cristina", "sameAs": [], "familyName": "Turcu", "additionalName": "", "givenName": "Cristina", "email": ""}, {"name": "Turcu, Cornel", "sameAs": [], "familyName": "Turcu", "additionalName": "", "givenName": "Cornel", "email": ""}, {"name": "Graur, Evelina", "sameAs": [], "familyName": "Graur", "additionalName": "", "givenName": "Evelina", "email": ""}], "title": "A Proposal for a Nationwide Student Gradebook Information Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04288", "oai:arXiv.org:1503.04288"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Todays students are encouraged to study and develop expertise in more than\none national academic environment. As a matter of fact, their educational\nactivities inevitably occur in a variety of academic settings and even span\nseveral years. Consequently students academic results and progress are expected\nto be easily monitored and accessed nationally. The authors of the present\npaper have devised a student gradebook information network to be nationally\nemployed by all public and private universities and colleges. The papers deals\nwith the architectural principles underlying the system and discusses aspects\nrelated to data collection, data analysis and data storage across multiple\nmachines while providing a seamless view of entire infrastructure and service\ndelivery system from a single Web access point. The utility of the\narchitectural system is discussed in relationship with its major advantages:\nuser-friendliness, security access, flexibility, transparency, distributional\npower, and scalability. The major beneficiary of the system is the Romanian\nhigher education system.\n"}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04288"}}, {"publisher": {"name": ""}, "description": "  For multiple-input multiple-output (MIMO) spatial-multiplexing transmission,\nzero-forcing detection (ZF) is appealing because of its low complexity. Our\nrecent MIMO ZF performance analysis for Rician--Rayleigh fading, which is\nrelevant in heterogeneous networks, has yielded for the ZF outage probability\nand ergodic capacity infinite-series expressions. Because they arose from\nexpanding the confluent hypergeometric function $ {_1\\! F_1} (\\cdot, \\cdot,\n\\sigma) $ around 0, they do not converge numerically at realistically-high\nRician $ K $-factor values. Therefore, herein, we seek to take advantage of the\nfact that $ {_1\\! F_1} (\\cdot, \\cdot, \\sigma) $ satisfies a differential\nequation, i.e., it is a \\textit{holonomic} function. Holonomic functions can be\ncomputed by the \\textit{holonomic gradient method} (HGM), i.e., by numerically\nsolving the satisfied differential equation. Thus, we first reveal that the\nmoment generating function (m.g.f.) and probability density function (p.d.f.)\nof the ZF signal-to-noise ratio (SNR) are holonomic. Then, from the\ndifferential equation for $ {_1\\! F_1} (\\cdot, \\cdot, \\sigma) $, we deduce\nthose satisfied by the SNR m.g.f. and p.d.f., and demonstrate that the HGM\nhelps compute the p.d.f. accurately at practically-relevant values of $ K $.\nFinally, numerical integration of the SNR p.d.f. produced by HGM yields\naccurate ZF outage probability and ergodic capacity results.\n", "contributors": [{"name": "Siriteanu, Constantin", "sameAs": [], "familyName": "Siriteanu", "additionalName": "", "givenName": "Constantin", "email": ""}, {"name": "Takemura, Akimichi", "sameAs": [], "familyName": "Takemura", "additionalName": "", "givenName": "Akimichi", "email": ""}, {"name": "Kuriki, Satoshi", "sameAs": [], "familyName": "Kuriki", "additionalName": "", "givenName": "Satoshi", "email": ""}, {"name": "Shin, Hyundong", "sameAs": [], "familyName": "Shin", "additionalName": "", "givenName": "Hyundong", "email": ""}, {"name": "Koutschan, Christoph", "sameAs": [], "familyName": "Koutschan", "additionalName": "", "givenName": "Christoph", "email": ""}], "title": "MIMO Zero-Forcing Performance Evaluation Using the Holonomic Gradient\n  Method", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-15", "2015-04-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.3788", "IEEE Transactions on Wireless Communications, vol. 14, no. 4,\n  April 2015, pp. 2322-2335", "doi:10.1109/TWC.2014.2385075", "oai:arXiv.org:1403.3788"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  For multiple-input multiple-output (MIMO) spatial-multiplexing transmission,\nzero-forcing detection (ZF) is appealing because of its low complexity. Our\nrecent MIMO ZF performance analysis for Rician--Rayleigh fading, which is\nrelevant in heterogeneous networks, has yielded for the ZF outage probability\nand ergodic capacity infinite-series expressions. Because they arose from\nexpanding the confluent hypergeometric function $ {_1\\! F_1} (\\cdot, \\cdot,\n\\sigma) $ around 0, they do not converge numerically at realistically-high\nRician $ K $-factor values. Therefore, herein, we seek to take advantage of the\nfact that $ {_1\\! F_1} (\\cdot, \\cdot, \\sigma) $ satisfies a differential\nequation, i.e., it is a \\textit{holonomic} function. Holonomic functions can be\ncomputed by the \\textit{holonomic gradient method} (HGM), i.e., by numerically\nsolving the satisfied differential equation. Thus, we first reveal that the\nmoment generating function (m.g.f.) and probability density function (p.d.f.)\nof the ZF signal-to-noise ratio (SNR) are holonomic. Then, from the\ndifferential equation for $ {_1\\! F_1} (\\cdot, \\cdot, \\sigma) $, we deduce\nthose satisfied by the SNR m.g.f. and p.d.f., and demonstrate that the HGM\nhelps compute the p.d.f. accurately at practically-relevant values of $ K $.\nFinally, numerical integration of the SNR p.d.f. produced by HGM yields\naccurate ZF outage probability and ergodic capacity results.\n", "Comment: This manuscript was accepted in December 2014"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.3788"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Advances in sensing technologies and the growth of the internet have resulted in an explosion in the size of modern datasets, while storage and processing power continue to lag behind. This motivates the need for algorithms that are efficient, both in terms of the number of measurements needed and running time. To combat the challenges associated with large datasets, we propose a general framework for active hierarchical clustering that repeatedly runs an off-the-shelf clustering algorithm on small subsets of the data and comes with guarantees on performance, measurement complexity and runtime complexity. We instantiate this framework with a simple spectral clustering algorithm and provide concrete results on its performance, showing that, under some assumptions, this algorithm recovers all clusters of size \u2126(log n) using O(n log2 n) similarities and runs in O(n log3 n) time for a dataset of n objects. Through extensive experimentation we also demonstrate that this framework is practically alluring.", "contributors": [{"name": "Krishnamurthy, Akshay", "sameAs": [], "familyName": "Krishnamurthy", "additionalName": "", "givenName": "Akshay", "email": ""}, {"name": "Balakrishnan, Sivaraman", "sameAs": [], "familyName": "Balakrishnan", "additionalName": "", "givenName": "Sivaraman", "email": ""}, {"name": "Xu, Min", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Min", "email": ""}, {"name": "Singh, Aarti", "sameAs": [], "familyName": "Singh", "additionalName": "", "givenName": "Aarti", "email": ""}], "title": "Efficient Active Algorithms for Hierarchical Clustering", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2012-06-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/125", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1122&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1122"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Advances in sensing technologies and the growth of the internet have resulted in an explosion in the size of modern datasets, while storage and processing power continue to lag behind. This motivates the need for algorithms that are efficient, both in terms of the number of measurements needed and running time. To combat the challenges associated with large datasets, we propose a general framework for active hierarchical clustering that repeatedly runs an off-the-shelf clustering algorithm on small subsets of the data and comes with guarantees on performance, measurement complexity and runtime complexity. We instantiate this framework with a simple spectral clustering algorithm and provide concrete results on its performance, showing that, under some assumptions, this algorithm recovers all clusters of size \u2126(log n) using O(n log2 n) similarities and runs in O(n log3 n) time for a dataset of n objects. Through extensive experimentation we also demonstrate that this framework is practically alluring."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-24T22:08:14", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/125"}}, {"publisher": {"name": ""}, "description": "  Error backpropagation is an extremely effective algorithm for assigning\ncredit in artificial neural networks. However, weight updates under Backprop\ndepend on lengthy recursive computations and require separate output and error\nmessages -- features not shared by biological neurons, that are perhaps\nunnecessary. In this paper, we revisit Backprop and the credit assignment\nproblem. We first decompose Backprop into a collection of interacting learning\nalgorithms; provide regret bounds on the performance of these sub-algorithms;\nand factorize Backprop's error signals. Using these results, we derive a new\ncredit assignment algorithm for nonparametric regression, Kickback, that is\nsignificantly simpler than Backprop. Finally, we provide a sufficient condition\nfor Kickback to follow error gradients, and show that Kickback matches\nBackprop's performance on real-world regression benchmarks.\n", "contributors": [{"name": "Balduzzi, David", "sameAs": [], "familyName": "Balduzzi", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Vanchinathan, Hastagiri", "sameAs": [], "familyName": "Vanchinathan", "additionalName": "", "givenName": "Hastagiri", "email": ""}, {"name": "Buhmann, Joachim", "sameAs": [], "familyName": "Buhmann", "additionalName": "", "givenName": "Joachim", "email": ""}], "title": "Kickback cuts Backprop's red-tape: Biologically plausible credit\n  assignment in neural networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.6191", "oai:arXiv.org:1411.6191"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": ["  Error backpropagation is an extremely effective algorithm for assigning\ncredit in artificial neural networks. However, weight updates under Backprop\ndepend on lengthy recursive computations and require separate output and error\nmessages -- features not shared by biological neurons, that are perhaps\nunnecessary. In this paper, we revisit Backprop and the credit assignment\nproblem. We first decompose Backprop into a collection of interacting learning\nalgorithms; provide regret bounds on the performance of these sub-algorithms;\nand factorize Backprop's error signals. Using these results, we derive a new\ncredit assignment algorithm for nonparametric regression, Kickback, that is\nsignificantly simpler than Backprop. Finally, we provide a sufficient condition\nfor Kickback to follow error gradients, and show that Kickback matches\nBackprop's performance on real-world regression benchmarks.\n", "Comment: 7 pages. To appear, AAAI-15"]}}], "languages": [null], "subjects": ["quantitative biology - neurons and cognition", "computer science - neural and evolutionary computing", "computer science - learning"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.6191"}}, {"publisher": {"name": ""}, "description": "  As it is known in the finance risk and macroeconomics literature,\nrisk-sharing in large portfolios may increase the probability of creation of\ndefault clusters and of systemic risk. We review recent developments on\nmathematical and computational tools for the quantification of such phenomena.\nLimiting analysis such as law of large numbers and central limit theorems allow\nto approximate the distribution in large systems and study quantities such as\nthe loss distribution in large portfolios. Large deviations analysis allow us\nto study the tail of the loss distribution and to identify pathways to default\nclustering. Sensitivity analysis allows to understand the most likely ways in\nwhich different effects, such as contagion and systematic risks, combine to\nlead to large default rates. Such results could give useful insights into how\nto optimally safeguard against such events.\n", "contributors": [{"name": "Spiliopoulos, Konstantinos", "sameAs": [], "familyName": "Spiliopoulos", "additionalName": "", "givenName": "Konstantinos", "email": ""}], "title": "Systemic Risk and Default Clustering for Large Financial Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-21", "2015-02-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.5352", "oai:arXiv.org:1402.5352"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "q-fin"]}}, {"name": "description", "properties": {"description": ["  As it is known in the finance risk and macroeconomics literature,\nrisk-sharing in large portfolios may increase the probability of creation of\ndefault clusters and of systemic risk. We review recent developments on\nmathematical and computational tools for the quantification of such phenomena.\nLimiting analysis such as law of large numbers and central limit theorems allow\nto approximate the distribution in large systems and study quantities such as\nthe loss distribution in large portfolios. Large deviations analysis allow us\nto study the tail of the loss distribution and to identify pathways to default\nclustering. Sensitivity analysis allows to understand the most likely ways in\nwhich different effects, such as contagion and systematic risks, combine to\nlead to large default rates. Such results could give useful insights into how\nto optimally safeguard against such events.\n", "Comment: in Large Deviations and Asymptotic Methods in Finance, (Editors: P.\n  Friz, J. Gatheral, A. Gulisashvili, A. Jacqier, J. Teichmann) , Springer\n  Proceedings in Mathematics and Statistics, Vol. 110 2015,"]}}], "languages": [null], "subjects": ["60g57", "60g55", "quantitative finance - risk management", "60f05", "60f10", "91g40", "91g80", "quantitative finance - computational finance", "mathematics - probability"], "providerUpdatedDateTime": "2015-02-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.5352"}}, {"publisher": {"name": ""}, "description": "  In this paper, we consider the problem of the recognition of various kinds of\norderings produced by graph searches. To this aim, we introduce a new\nframework, the Tie-Breaking Label Search (TBLS), in order to handle a broad\nvariety of searches. This new model is based on partial orders defined on the\nlabel set and it unifies the General Label Search (GLS) formalism of Krueger,\nSimonet and Berry (2011), and the \"pattern-conditions\" formalism of Corneil and\nKrueger (2008). It allows us to derive some general properties including new\npattern-conditions (yielding memory-efficient certificates) for many usual\nsearches, including BFS, DFS, LBFS and LDFS. Furthermore, the new model allows\neasy expression of multi-sweep uses of searches that depend on previous\n(search) orderings of the graph's vertex set.\n", "contributors": [{"name": "Corneil, Derek G.", "sameAs": [], "familyName": "Corneil", "additionalName": "G.", "givenName": "Derek", "email": ""}, {"name": "Dusart, Jeremie", "sameAs": [], "familyName": "Dusart", "additionalName": "", "givenName": "Jeremie", "email": ""}, {"name": "Habib, Michel", "sameAs": [], "familyName": "Habib", "additionalName": "", "givenName": "Michel", "email": ""}, {"name": "de Montgolfier, Fabien", "sameAs": [], "familyName": "de Montgolfier", "additionalName": "", "givenName": "Fabien", "email": ""}], "title": "A tie-break model for graph search", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06148", "oai:arXiv.org:1501.06148"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we consider the problem of the recognition of various kinds of\norderings produced by graph searches. To this aim, we introduce a new\nframework, the Tie-Breaking Label Search (TBLS), in order to handle a broad\nvariety of searches. This new model is based on partial orders defined on the\nlabel set and it unifies the General Label Search (GLS) formalism of Krueger,\nSimonet and Berry (2011), and the \"pattern-conditions\" formalism of Corneil and\nKrueger (2008). It allows us to derive some general properties including new\npattern-conditions (yielding memory-efficient certificates) for many usual\nsearches, including BFS, DFS, LBFS and LDFS. Furthermore, the new model allows\neasy expression of multi-sweep uses of searches that depend on previous\n(search) orderings of the graph's vertex set.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06148"}}, {"publisher": {"name": ""}, "description": "  We prove that for every $\\epsilon>0$ and predicate $P:\\{0,1\\}^k\\rightarrow\n\\{0,1\\}$ that supports a pairwise independent distribution, there exists an\ninstance $\\mathcal{I}$ of the $\\mathsf{Max}P$ constraint satisfaction problem\non $n$ variables such that no assignment can satisfy more than a\n$\\tfrac{|P^{-1}(1)|}{2^k}+\\epsilon$ fraction of $\\mathcal{I}$'s constraints but\nthe degree $\\Omega(n)$ Sum of Squares semidefinite programming hierarchy cannot\ncertify that $\\mathcal{I}$ is unsatisfiable. Similar results were previously\nonly known for weaker hierarchies.\n", "contributors": [{"name": "Barak, Boaz", "sameAs": [], "familyName": "Barak", "additionalName": "", "givenName": "Boaz", "email": ""}, {"name": "Chan, Siu On", "sameAs": [], "familyName": "Chan", "additionalName": "On", "givenName": "Siu", "email": ""}, {"name": "Kothari, Pravesh", "sameAs": [], "familyName": "Kothari", "additionalName": "", "givenName": "Pravesh", "email": ""}], "title": "Sum of Squares Lower Bounds from Pairwise Independence", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-04", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00734", "oai:arXiv.org:1501.00734"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We prove that for every $\\epsilon>0$ and predicate $P:\\{0,1\\}^k\\rightarrow\n\\{0,1\\}$ that supports a pairwise independent distribution, there exists an\ninstance $\\mathcal{I}$ of the $\\mathsf{Max}P$ constraint satisfaction problem\non $n$ variables such that no assignment can satisfy more than a\n$\\tfrac{|P^{-1}(1)|}{2^k}+\\epsilon$ fraction of $\\mathcal{I}$'s constraints but\nthe degree $\\Omega(n)$ Sum of Squares semidefinite programming hierarchy cannot\ncertify that $\\mathcal{I}$ is unsatisfiable. Similar results were previously\nonly known for weaker hierarchies.\n", "Comment: 27 Pages (including the title page) and 4 figures including appendix"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "f.2.0"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00734"}}, {"publisher": {"name": ""}, "description": "  We study the design of nearly-linear-time algorithms for approximately\nsolving positive linear programs. Both the parallel and the sequential\ndeterministic versions of these algorithms require\n$\\tilde{O}(\\varepsilon^{-4})$ iterations, a dependence that has not been\nimproved since the introduction of these methods in 1993 by Luby and Nisan.\nMoreover, previous algorithms and their analyses rely on update steps and\nconvergence arguments that are combinatorial in nature, and do not seem to\narise naturally from an optimization viewpoint. In this paper, we leverage\ninsights from optimization theory to construct a novel algorithm that breaks\nthe longstanding $\\tilde{O}(\\varepsilon^{-4})$ barrier. Our algorithm has a\nsimple analysis and a clear motivation. Our work introduces a number of novel\ntechniques, such as the combined application of gradient descent and mirror\ndescent, and a truncated, smoothed version of the standard multiplicative\nweight update, which may be of independent interest.\n", "contributors": [{"name": "Allen-Zhu, Zeyuan", "sameAs": [], "familyName": "Allen-Zhu", "additionalName": "", "givenName": "Zeyuan", "email": ""}, {"name": "Orecchia, Lorenzo", "sameAs": [], "familyName": "Orecchia", "additionalName": "", "givenName": "Lorenzo", "email": ""}], "title": "Using Optimization to Break the Epsilon Barrier: A Faster and Simpler\n  Width-Independent Algorithm for Solving Positive Linear Programs in Parallel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-07", "2014-11-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.1925", "oai:arXiv.org:1407.1925"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We study the design of nearly-linear-time algorithms for approximately\nsolving positive linear programs. Both the parallel and the sequential\ndeterministic versions of these algorithms require\n$\\tilde{O}(\\varepsilon^{-4})$ iterations, a dependence that has not been\nimproved since the introduction of these methods in 1993 by Luby and Nisan.\nMoreover, previous algorithms and their analyses rely on update steps and\nconvergence arguments that are combinatorial in nature, and do not seem to\narise naturally from an optimization viewpoint. In this paper, we leverage\ninsights from optimization theory to construct a novel algorithm that breaks\nthe longstanding $\\tilde{O}(\\varepsilon^{-4})$ barrier. Our algorithm has a\nsimple analysis and a clear motivation. Our work introduces a number of novel\ntechniques, such as the combined application of gradient descent and mirror\ndescent, and a truncated, smoothed version of the standard multiplicative\nweight update, which may be of independent interest.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "mathematics - numerical analysis", "computer science - numerical analysis", "and cluster computing", "computer science - data structures and algorithms", "computer science - distributed", "parallel"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.1925"}}, {"publisher": {"name": ""}, "description": "  Much has been said about observability in system theory and control; however,\nit has been recently that observability in complex networks has seriously\nattracted the attention of researchers. This paper examines the\nstate-of-the-art and discusses some issues raised due to \"complexity\" and\n\"stochasticity\". These unresolved issues call for a new practical methodology.\nFor stochastic systems, a degree of observability may be defined and the\nobservability problem is not a binary (i.e., yes-no) question anymore. Here, we\npropose to employ a goal-seeking system to play a supervisory role in the\nnetwork. Hence, improving the degree of observability would be a valid\nobjective for the supervisory system. Towards this goal, the supervisor\ndynamically optimizes the observation process by reconfiguring the sensory\nparts in the network. A cognitive dynamic system is suggested as a proper\nchoice for the supervisory system. In this framework, the network itself is\nviewed as the environment with which the cognitive dynamic system interacts.\nComputer experiments confirm the potential of the proposed approach for\naddressing some of the issues raised in networks due to complexity and\nstochasticity.\n", "contributors": [{"name": "Fatemi, Mehdi", "sameAs": [], "familyName": "Fatemi", "additionalName": "", "givenName": "Mehdi", "email": ""}, {"name": "Setoodeh, Peyman", "sameAs": [], "familyName": "Setoodeh", "additionalName": "", "givenName": "Peyman", "email": ""}, {"name": "Haykin, Simon", "sameAs": [], "familyName": "Haykin", "additionalName": "", "givenName": "Simon", "email": ""}], "title": "Improving Observability of Stochastic Complex Networks under the\n  Supervision of Cognitive Dynamic Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6162", "oai:arXiv.org:1412.6162"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Much has been said about observability in system theory and control; however,\nit has been recently that observability in complex networks has seriously\nattracted the attention of researchers. This paper examines the\nstate-of-the-art and discusses some issues raised due to \"complexity\" and\n\"stochasticity\". These unresolved issues call for a new practical methodology.\nFor stochastic systems, a degree of observability may be defined and the\nobservability problem is not a binary (i.e., yes-no) question anymore. Here, we\npropose to employ a goal-seeking system to play a supervisory role in the\nnetwork. Hence, improving the degree of observability would be a valid\nobjective for the supervisory system. Towards this goal, the supervisor\ndynamically optimizes the observation process by reconfiguring the sensory\nparts in the network. A cognitive dynamic system is suggested as a proper\nchoice for the supervisory system. In this framework, the network itself is\nviewed as the environment with which the cognitive dynamic system interacts.\nComputer experiments confirm the potential of the proposed approach for\naddressing some of the issues raised in networks due to complexity and\nstochasticity.\n", "Comment: Submitted to IEEE Trans. Network Science and Engineering on October\n  25, 2014"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6162"}}, {"publisher": {"name": ""}, "description": "  The hypercube 2-segmentation problem is a certain biclustering problem that\nwas previously claimed to be NP-hard, but for which there does not appear to be\na publicly available proof of NP-hardness. This manuscript provides such a\nproof.\n", "contributors": [{"name": "Feige, Uriel", "sameAs": [], "familyName": "Feige", "additionalName": "", "givenName": "Uriel", "email": ""}], "title": "NP-hardness of hypercube 2-segmentation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0821", "oai:arXiv.org:1411.0821"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The hypercube 2-segmentation problem is a certain biclustering problem that\nwas previously claimed to be NP-hard, but for which there does not appear to be\na publicly available proof of NP-hardness. This manuscript provides such a\nproof.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity"], "providerUpdatedDateTime": "2014-11-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0821"}}, {"publisher": {"name": ""}, "description": "  This document presents the business requirement of Unified University\nInventory System (UUIS) in Technology-independent manner. All attempts have\nbeen made in using mostly business terminology and business language while\ndescribing the requirements in this document. Very minimal and commonly\nunderstood Technical terminology is used. Use case approach is used in modeling\nthe business requirements in this document.\n", "contributors": [{"name": "Alhazmi, Ali", "sameAs": [], "familyName": "Alhazmi", "additionalName": "", "givenName": "Ali", "email": ""}, {"name": "Al-Sharawi, Abdulrahman", "sameAs": [], "familyName": "Al-Sharawi", "additionalName": "", "givenName": "Abdulrahman", "email": ""}, {"name": "Liu, Bing", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Bing", "email": ""}, {"name": "Oliveira, Deyvisson", "sameAs": [], "familyName": "Oliveira", "additionalName": "", "givenName": "Deyvisson", "email": ""}, {"name": "Sobh, Kanj", "sameAs": [], "familyName": "Sobh", "additionalName": "", "givenName": "Kanj", "email": ""}, {"name": "Mayantz, Max", "sameAs": [], "familyName": "Mayantz", "additionalName": "", "givenName": "Max", "email": ""}, {"name": "de Bled, Robin", "sameAs": [], "familyName": "de Bled", "additionalName": "", "givenName": "Robin", "email": ""}, {"name": "Zhang, Yu Ming", "sameAs": [], "familyName": "Zhang", "additionalName": "Ming", "givenName": "Yu", "email": ""}], "title": "Software Requirements Specification of the IUfA's UUIS -- a Team 4\n  COMP5541-W10 Project Approach", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-05-02", "2010-05-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.0162", "oai:arXiv.org:1005.0162"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This document presents the business requirement of Unified University\nInventory System (UUIS) in Technology-independent manner. All attempts have\nbeen made in using mostly business terminology and business language while\ndescribing the requirements in this document. Very minimal and commonly\nunderstood Technical terminology is used. Use case approach is used in modeling\nthe business requirements in this document.\n", "Comment: 30 pages, 13 figures"]}}], "languages": [null], "subjects": ["k.6", "computer science - software engineering", "h.5.2", "d.2"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.0162"}}, {"publisher": {"name": ""}, "description": "  Polynomial kernel regression is one of the standard and state-of-the-art\nlearning strategies. However, as is well known, the choices of the degree of\npolynomial kernel and the regularization parameter are still open in the realm\nof model selection. The first aim of this paper is to develop a strategy to\nselect these parameters. On one hand, based on the worst-case learning rate\nanalysis, we show that the regularization term in polynomial kernel regression\nis not necessary. In other words, the regularization parameter can decrease\narbitrarily fast when the degree of the polynomial kernel is suitable tuned. On\nthe other hand,taking account of the implementation of the algorithm, the\nregularization term is required. Summarily, the effect of the regularization\nterm in polynomial kernel regression is only to circumvent the \" ill-condition\"\nof the kernel matrix. Based on this, the second purpose of this paper is to\npropose a new model selection strategy, and then design an efficient learning\nalgorithm. Both theoretical and experimental analysis show that the new\nstrategy outperforms the previous one. Theoretically, we prove that the new\nlearning strategy is almost optimal if the regression function is smooth.\nExperimentally, it is shown that the new strategy can significantly reduce the\ncomputational burden without loss of generalization capability.\n", "contributors": [{"name": "Lin, Shaobo", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Shaobo", "email": ""}, {"name": "Sun, Xingping", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Xingping", "email": ""}, {"name": "Xu, Zongben", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Zongben", "email": ""}, {"name": "Zeng, Jinshan", "sameAs": [], "familyName": "Zeng", "additionalName": "", "givenName": "Jinshan", "email": ""}], "title": "Model selection of polynomial kernel regression", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02143", "oai:arXiv.org:1503.02143"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Polynomial kernel regression is one of the standard and state-of-the-art\nlearning strategies. However, as is well known, the choices of the degree of\npolynomial kernel and the regularization parameter are still open in the realm\nof model selection. The first aim of this paper is to develop a strategy to\nselect these parameters. On one hand, based on the worst-case learning rate\nanalysis, we show that the regularization term in polynomial kernel regression\nis not necessary. In other words, the regularization parameter can decrease\narbitrarily fast when the degree of the polynomial kernel is suitable tuned. On\nthe other hand,taking account of the implementation of the algorithm, the\nregularization term is required. Summarily, the effect of the regularization\nterm in polynomial kernel regression is only to circumvent the \" ill-condition\"\nof the kernel matrix. Based on this, the second purpose of this paper is to\npropose a new model selection strategy, and then design an efficient learning\nalgorithm. Both theoretical and experimental analysis show that the new\nstrategy outperforms the previous one. Theoretically, we prove that the new\nlearning strategy is almost optimal if the regression function is smooth.\nExperimentally, it is shown that the new strategy can significantly reduce the\ncomputational burden without loss of generalization capability.\n", "Comment: 29 pages, 4 figures"]}}], "languages": [null], "subjects": ["f.2.2", "computer science - learning"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02143"}}, {"publisher": {"name": ""}, "description": "  Topic models are probabilistic models for discovering topical themes in\ncollections of documents. In real world applications, these models provide us\nwith the means of organizing what would otherwise be unstructured collections.\nThey can help us cluster a huge collection into different topics or find a\nsubset of the collection that resembles the topical theme found in an article\nat hand.\n  The first wave of topic models developed were able to discover the prevailing\ntopics in a big collection of documents spanning a period of time. It was later\nrealized that these time-invariant models were not capable of modeling 1) the\ntime varying number of topics they discover and 2) the time changing structure\nof these topics. Few models were developed to address this two deficiencies.\nThe online-hierarchical Dirichlet process models the documents with a time\nvarying number of topics. It varies the structure of the topics over time as\nwell. However, it relies on document order, not timestamps to evolve the model\nover time. The continuous-time dynamic topic model evolves topic structure in\ncontinuous-time. However, it uses a fixed number of topics over time.\n  In this dissertation, I present a model, the continuous-time infinite dynamic\ntopic model, that combines the advantages of these two models 1) the\nonline-hierarchical Dirichlet process, and 2) the continuous-time dynamic topic\nmodel. More specifically, the model I present is a probabilistic topic model\nthat does the following: 1) it changes the number of topics over continuous\ntime, and 2) it changes the topic structure over continuous-time.\n  I compared the model I developed with the two other models with different\nsetting values. The results obtained were favorable to my model and showed the\nneed for having a model that has a continuous-time varying number of topics and\ntopic structure.\n", "contributors": [{"name": "Elshamy, Wesam", "sameAs": [], "familyName": "Elshamy", "additionalName": "", "givenName": "Wesam", "email": ""}], "title": "Continuous-time Infinite Dynamic Topic Models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-02-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1302.7088", "oai:arXiv.org:1302.7088"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Topic models are probabilistic models for discovering topical themes in\ncollections of documents. In real world applications, these models provide us\nwith the means of organizing what would otherwise be unstructured collections.\nThey can help us cluster a huge collection into different topics or find a\nsubset of the collection that resembles the topical theme found in an article\nat hand.\n  The first wave of topic models developed were able to discover the prevailing\ntopics in a big collection of documents spanning a period of time. It was later\nrealized that these time-invariant models were not capable of modeling 1) the\ntime varying number of topics they discover and 2) the time changing structure\nof these topics. Few models were developed to address this two deficiencies.\nThe online-hierarchical Dirichlet process models the documents with a time\nvarying number of topics. It varies the structure of the topics over time as\nwell. However, it relies on document order, not timestamps to evolve the model\nover time. The continuous-time dynamic topic model evolves topic structure in\ncontinuous-time. However, it uses a fixed number of topics over time.\n  In this dissertation, I present a model, the continuous-time infinite dynamic\ntopic model, that combines the advantages of these two models 1) the\nonline-hierarchical Dirichlet process, and 2) the continuous-time dynamic topic\nmodel. More specifically, the model I present is a probabilistic topic model\nthat does the following: 1) it changes the number of topics over continuous\ntime, and 2) it changes the topic structure over continuous-time.\n  I compared the model I developed with the two other models with different\nsetting values. The results obtained were favorable to my model and showed the\nneed for having a model that has a continuous-time varying number of topics and\ntopic structure.\n", "Comment: Ph.D. dissertation, Kansas State University, 2013"]}}], "languages": [null], "subjects": ["statistics - applications", "68t10", "computer science - information retrieval", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1302.7088"}}, {"publisher": {"name": ""}, "description": "  In this paper we present the first algorithm in the streaming model to\ncharacterize completely the biconnectivity properties of undirected networks:\narticulation points, bridges, and connected and biconnected components. The\nmotivation of our work was the development of a real-time algorithm to monitor\nthe connectivity of the Autonomous Systems (AS) Network, but the solution\nprovided is general enough to be applied to any network.\n  The network structure is represented by a graph, and the algorithm is\nanalyzed in the datastream framework. Here, as in the \\emph{on-line} model, the\ninput graph is revealed one item (i.e., graph edge) after the other, in an\non-line fashion; but, if compared to traditional on-line computation, there are\nstricter requirements for both memory occupation and per item processing time.\nOur algorithm works by properly updating a forest over the graph nodes. All the\ngraph (bi)connectivity properties are stored in this forest. We prove the\ncorrectness of the algorithm, together with its space ($O(n\\,\\log n)$, with $n$\nbeing the number of nodes in the graph) and time bounds.\n  We also present the results of a brief experimental evaluation against\nreal-world graphs, including many samples of the AS network, ranging from\nmedium to massive size. These preliminary experimental results confirm the\neffectiveness of our approach.\n", "contributors": [{"name": "Ausiello, Giorgio", "sameAs": [], "familyName": "Ausiello", "additionalName": "", "givenName": "Giorgio", "email": ""}, {"name": "Firmani, Donatella", "sameAs": [], "familyName": "Firmani", "additionalName": "", "givenName": "Donatella", "email": ""}, {"name": "Laura, Luigi", "sameAs": [], "familyName": "Laura", "additionalName": "", "givenName": "Luigi", "email": ""}], "title": "Real-Time Monitoring of Undirected Networks: Articulation Points,\n  Bridges, and Connected and Biconnected Components", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-02-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1202.0319", "oai:arXiv.org:1202.0319"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper we present the first algorithm in the streaming model to\ncharacterize completely the biconnectivity properties of undirected networks:\narticulation points, bridges, and connected and biconnected components. The\nmotivation of our work was the development of a real-time algorithm to monitor\nthe connectivity of the Autonomous Systems (AS) Network, but the solution\nprovided is general enough to be applied to any network.\n  The network structure is represented by a graph, and the algorithm is\nanalyzed in the datastream framework. Here, as in the \\emph{on-line} model, the\ninput graph is revealed one item (i.e., graph edge) after the other, in an\non-line fashion; but, if compared to traditional on-line computation, there are\nstricter requirements for both memory occupation and per item processing time.\nOur algorithm works by properly updating a forest over the graph nodes. All the\ngraph (bi)connectivity properties are stored in this forest. We prove the\ncorrectness of the algorithm, together with its space ($O(n\\,\\log n)$, with $n$\nbeing the number of nodes in the graph) and time bounds.\n  We also present the results of a brief experimental evaluation against\nreal-world graphs, including many samples of the AS network, ranging from\nmedium to massive size. These preliminary experimental results confirm the\neffectiveness of our approach.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1202.0319"}}, {"publisher": {"name": ""}, "description": "  The Art Gallery Problem (AGP) asks for placing a minimum number of stationary\nguards in a polygonal region P, such that all points in P are guarded. The\nproblem is known to be NP-hard, and its inherent continuous structure (with\nboth the set of points that need to be guarded and the set of points that can\nbe used for guarding being uncountably infinite) makes it difficult to apply a\nstraightforward formulation as an Integer Linear Program. We use an iterative\nprimal-dual relaxation approach for solving AGP instances to optimality. At\neach stage, a pair of LP relaxations for a finite candidate subset of primal\ncovering and dual packing constraints and variables is considered; these\ncorrespond to possible guard positions and points that are to be guarded.\n  Particularly useful are cutting planes for eliminating fractional solutions.\nWe identify two classes of facets, based on Edge Cover and Set Cover (SC)\ninequalities. Solving the separation problem for the latter is NP-complete, but\nexploiting the underlying geometric structure, we show that large subclasses of\nfractional SC solutions cannot occur for the AGP. This allows us to separate\nthe relevant subset of facets in polynomial time. We also characterize all\nfacets for finite AGP relaxations with coefficients in {0, 1, 2}.\n  Finally, we demonstrate the practical usefulness of our approach. Our cutting\nplane technique yields a significant improvement in terms of speed and solution\nquality due to considerably reduced integrality gaps as compared to the\napproach by Kr\\\"oller et al.\n", "contributors": [{"name": "Fekete, S\u00e1ndor P.", "sameAs": [], "familyName": "Fekete", "additionalName": "P.", "givenName": "S\u00e1ndor", "email": ""}, {"name": "Friedrichs, Stephan", "sameAs": [], "familyName": "Friedrichs", "additionalName": "", "givenName": "Stephan", "email": ""}, {"name": "Kr\u00f6ller, Alexander", "sameAs": [], "familyName": "Kr\u00f6ller", "additionalName": "", "givenName": "Alexander", "email": ""}, {"name": "Schmidt, Christiane", "sameAs": [], "familyName": "Schmidt", "additionalName": "", "givenName": "Christiane", "email": ""}], "title": "Facets for Art Gallery Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-08-21", "2014-12-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1308.4670", "oai:arXiv.org:1308.4670"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The Art Gallery Problem (AGP) asks for placing a minimum number of stationary\nguards in a polygonal region P, such that all points in P are guarded. The\nproblem is known to be NP-hard, and its inherent continuous structure (with\nboth the set of points that need to be guarded and the set of points that can\nbe used for guarding being uncountably infinite) makes it difficult to apply a\nstraightforward formulation as an Integer Linear Program. We use an iterative\nprimal-dual relaxation approach for solving AGP instances to optimality. At\neach stage, a pair of LP relaxations for a finite candidate subset of primal\ncovering and dual packing constraints and variables is considered; these\ncorrespond to possible guard positions and points that are to be guarded.\n  Particularly useful are cutting planes for eliminating fractional solutions.\nWe identify two classes of facets, based on Edge Cover and Set Cover (SC)\ninequalities. Solving the separation problem for the latter is NP-complete, but\nexploiting the underlying geometric structure, we show that large subclasses of\nfractional SC solutions cannot occur for the AGP. This allows us to separate\nthe relevant subset of facets in polynomial time. We also characterize all\nfacets for finite AGP relaxations with coefficients in {0, 1, 2}.\n  Finally, we demonstrate the practical usefulness of our approach. Our cutting\nplane technique yields a significant improvement in terms of speed and solution\nquality due to considerably reduced integrality gaps as compared to the\napproach by Kr\\\"oller et al.\n", "Comment: 29 pages, 18 figures, 1 table"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - optimization and control", "f.2.2", "computer science - computational geometry"], "providerUpdatedDateTime": "2014-12-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1308.4670"}}, {"publisher": {"name": ""}, "description": "  In this paper, we consider an $\\ell_{0}$-norm penalized formulation of the\ngeneralized eigenvalue problem (GEP), aimed at extracting the leading sparse\ngeneralized eigenvector of a matrix pair. The formulation involves maximization\nof a discontinuous nonconcave objective function over a nonconvex constraint\nset, and is therefore computationally intractable. To tackle the problem, we\nfirst approximate the $\\ell_{0}$-norm by a continuous surrogate function. Then\nan algorithm is developed via iteratively majorizing the surrogate function by\na quadratic separable function, which at each iteration reduces to a regular\ngeneralized eigenvalue problem. A preconditioned steepest ascent algorithm for\nfinding the leading generalized eigenvector is provided. A systematic way based\non smoothing is proposed to deal with the \"singularity issue\" that arises when\na quadratic function is used to majorize the nondifferentiable surrogate\nfunction. For sparse GEPs with special structure, algorithms that admit a\nclosed-form solution at every iteration are derived. Numerical experiments show\nthat the proposed algorithms match or outperform existing algorithms in terms\nof computational complexity and support recovery.\n", "contributors": [{"name": "Song, Junxiao", "sameAs": [], "familyName": "Song", "additionalName": "", "givenName": "Junxiao", "email": ""}, {"name": "Babu, Prabhu", "sameAs": [], "familyName": "Babu", "additionalName": "", "givenName": "Prabhu", "email": ""}, {"name": "Palomar, Daniel P.", "sameAs": [], "familyName": "Palomar", "additionalName": "P.", "givenName": "Daniel", "email": ""}], "title": "Sparse Generalized Eigenvalue Problem via Smooth Optimization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-28", "2014-11-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6686", "oai:arXiv.org:1408.6686"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  In this paper, we consider an $\\ell_{0}$-norm penalized formulation of the\ngeneralized eigenvalue problem (GEP), aimed at extracting the leading sparse\ngeneralized eigenvector of a matrix pair. The formulation involves maximization\nof a discontinuous nonconcave objective function over a nonconvex constraint\nset, and is therefore computationally intractable. To tackle the problem, we\nfirst approximate the $\\ell_{0}$-norm by a continuous surrogate function. Then\nan algorithm is developed via iteratively majorizing the surrogate function by\na quadratic separable function, which at each iteration reduces to a regular\ngeneralized eigenvalue problem. A preconditioned steepest ascent algorithm for\nfinding the leading generalized eigenvector is provided. A systematic way based\non smoothing is proposed to deal with the \"singularity issue\" that arises when\na quadratic function is used to majorize the nondifferentiable surrogate\nfunction. For sparse GEPs with special structure, algorithms that admit a\nclosed-form solution at every iteration are derived. Numerical experiments show\nthat the proposed algorithms match or outperform existing algorithms in terms\nof computational complexity and support recovery.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-11-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6686"}}, {"publisher": {"name": ""}, "description": "Multiple focus groups were conducted to elicit perspectives from members of the Earth science informatics community on the sustainability of scientific software. Recommendations that the participants offered for near-term community actions and activities are described.", "contributors": [{"name": "Downs, Robert R.", "sameAs": [], "familyName": "Downs", "additionalName": "R.", "givenName": "Robert", "email": ""}, {"name": "Lenhardt, W. Christopher", "sameAs": [], "familyName": "Lenhardt", "additionalName": "Christopher", "givenName": "W.", "email": ""}, {"name": "Robinson, Erin", "sameAs": [], "familyName": "Robinson", "additionalName": "", "givenName": "Erin", "email": ""}, {"name": "Davis, Ethan", "sameAs": [], "familyName": "Davis", "additionalName": "", "givenName": "Ethan", "email": ""}, {"name": "Weber, Nicholas", "sameAs": [], "familyName": "Weber", "additionalName": "", "givenName": "Nicholas", "email": ""}], "title": "Community Recommendations for Improving Sustainable Scientific Software Practices", "shareProperties": {"source": "columbia"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014"}}, {"name": "identifier", "properties": {"identifier": ["http://dx.doi.org/10.7916/D8Q52NBC", "academiccommons.columbia.edu/ac:179856"]}}, {"name": "setSpec", "properties": {"setSpec": []}}], "languages": [null], "subjects": ["information science", "computer science"], "providerUpdatedDateTime": "2014-11-21T15:28:28", "uris": {"canonicalUri": "http://dx.doi.org/10.7916/D8Q52NBC"}}, {"publisher": {"name": ""}, "description": "  The main challenge in on-line handwritten character recognition in Indian\nlan- guage is the large size of the character set, larger similarity between\ndifferent characters in the script and the huge variation in writing style. In\nthis paper we propose a framework for on-line handwitten script recognition\ntaking cues from speech signal processing literature. The framework is based on\nidentify- ing strokes, which in turn lead to recognition of handwritten on-line\ncharacters rather that the conventional character identification. Though the\nframework is described for Devanagari script, the framework is general and can\nbe applied to any language.\n  The proposed platform consists of pre-processing, feature extraction, recog-\nnition and post processing like the conventional character recognition but ap-\nplied to strokes. The on-line Devanagari character recognition reduces to one\nof recognizing one of 69 primitives and recognition of a character is performed\nby recognizing a sequence of such primitives. We further show the impact of\nnoise removal on on-line raw data which is usually noisy. The use of Fuzzy\nDirec- tional Features to enhance the accuracy of stroke recognition is also\ndescribed. The recognition results are compared with commonly used directional\nfeatures in literature using several classifiers.\n", "contributors": [{"name": "Kopparapu, Sunil Kumar", "sameAs": [], "familyName": "Kopparapu", "additionalName": "Kumar", "givenName": "Sunil", "email": ""}, {"name": "L, Lajish V.", "sameAs": [], "familyName": "L", "additionalName": "V.", "givenName": "Lajish", "email": ""}], "title": "A Framework for On-Line Devanagari Handwritten Character Recognition", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6909", "oai:arXiv.org:1410.6909"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The main challenge in on-line handwritten character recognition in Indian\nlan- guage is the large size of the character set, larger similarity between\ndifferent characters in the script and the huge variation in writing style. In\nthis paper we propose a framework for on-line handwitten script recognition\ntaking cues from speech signal processing literature. The framework is based on\nidentify- ing strokes, which in turn lead to recognition of handwritten on-line\ncharacters rather that the conventional character identification. Though the\nframework is described for Devanagari script, the framework is general and can\nbe applied to any language.\n  The proposed platform consists of pre-processing, feature extraction, recog-\nnition and post processing like the conventional character recognition but ap-\nplied to strokes. The on-line Devanagari character recognition reduces to one\nof recognizing one of 69 primitives and recognition of a character is performed\nby recognizing a sequence of such primitives. We further show the impact of\nnoise removal on on-line raw data which is usually noisy. The use of Fuzzy\nDirec- tional Features to enhance the accuracy of stroke recognition is also\ndescribed. The recognition results are compared with commonly used directional\nfeatures in literature using several classifiers.\n", "Comment: 29 pages"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6909"}}, {"publisher": {"name": ""}, "description": "  We consider waking up a single-hop radio network with multiple channels.\nThere are $n$ stations connected to $b$ channels without collision detection.\nSome $k$ stations may become active spontaneously at arbitrary times, where $k$\nis unknown, and the goal is for all the stations to hear a successful\ntransmission as soon as possible after the first spontaneous activation. We\npresent a deterministic algorithm for the general problem that wakes up the\nnetwork in $O(k\\log^{1/b} k\\log n)$ time. We prove a lower bound that any\ndeterministic algorithm requires $\\Omega((k/b)\\log (n/k))$ time. We give a\ndeterministic algorithm for the special case when $b>d \\log \\log n$, for some\nconstant $d>1$, which wakes up the network in $O((k/b)\\log n\\log(b\\log n))$\ntime. This algorithm misses time optimality by at most a factor of $\\log n\\log\nb$. We give a randomized algorithm that wakes up the network within\n$O(k^{1/b}\\ln (1/\\epsilon))$ rounds with the probability of at least\n$1-\\epsilon$, for any unknown $0<\\epsilon<1$. We also consider a model of\njamming, in which each channel in any round may be jammed to prevent a\nsuccessful transmission, which happens with some known parameter probability\n$p$, independently across all channels and rounds. For this model, we give a\ndeterministic algorithm that wakes up the network in $O(\\log^{-1}(1/p) k\\log\nn\\log^{1/b} k)$ time with the probability of at least $1-1/{poly}(n)$.\n", "contributors": [{"name": "Chlebus, Bogdan S.", "sameAs": [], "familyName": "Chlebus", "additionalName": "S.", "givenName": "Bogdan", "email": ""}, {"name": "De Marco, Gianluca", "sameAs": [], "familyName": "De Marco", "additionalName": "", "givenName": "Gianluca", "email": ""}, {"name": "Kowalski, Dariusz R.", "sameAs": [], "familyName": "Kowalski", "additionalName": "R.", "givenName": "Dariusz", "email": ""}], "title": "Scalable Wake-up of Multi-Channel Single-Hop Radio Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4498", "oai:arXiv.org:1411.4498"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We consider waking up a single-hop radio network with multiple channels.\nThere are $n$ stations connected to $b$ channels without collision detection.\nSome $k$ stations may become active spontaneously at arbitrary times, where $k$\nis unknown, and the goal is for all the stations to hear a successful\ntransmission as soon as possible after the first spontaneous activation. We\npresent a deterministic algorithm for the general problem that wakes up the\nnetwork in $O(k\\log^{1/b} k\\log n)$ time. We prove a lower bound that any\ndeterministic algorithm requires $\\Omega((k/b)\\log (n/k))$ time. We give a\ndeterministic algorithm for the special case when $b>d \\log \\log n$, for some\nconstant $d>1$, which wakes up the network in $O((k/b)\\log n\\log(b\\log n))$\ntime. This algorithm misses time optimality by at most a factor of $\\log n\\log\nb$. We give a randomized algorithm that wakes up the network within\n$O(k^{1/b}\\ln (1/\\epsilon))$ rounds with the probability of at least\n$1-\\epsilon$, for any unknown $0<\\epsilon<1$. We also consider a model of\njamming, in which each channel in any round may be jammed to prevent a\nsuccessful transmission, which happens with some known parameter probability\n$p$, independently across all channels and rounds. For this model, we give a\ndeterministic algorithm that wakes up the network in $O(\\log^{-1}(1/p) k\\log\nn\\log^{1/b} k)$ time with the probability of at least $1-1/{poly}(n)$.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4498"}}, {"publisher": {"name": ""}, "description": "  Armed groups of civilians known as \"self-defense forces\" have ousted the\npowerful Knights Templar drug cartel from several towns in Michoacan. This\nmilitia uprising has unfolded on social media, particularly in the \"VXM\"\n(\"Valor por Michoacan,\" Spanish for \"Courage for Michoacan\") Facebook page,\ngathering more than 170,000 fans. Previous work on the Drug War has documented\nthe use of social media for real-time reports of violent clashes. However, VXM\ngoes one step further by taking on a pro-militia propagandist role, engaging in\ntwo-way communication with its audience. This paper presents a descriptive\nanalysis of VXM and its audience. We examined nine months of posts, from VXM's\ninception until May 2014, totaling 6,000 posts by VXM administrators and more\nthan 108,000 comments from its audience. We describe the main conversation\nthemes, post frequency and relationships with offline events and public\nfigures. We also characterize the behavior of VXM's most active audience\nmembers. Our work illustrates VXM's online mobilization strategies, and how its\naudience takes part in defining the narrative of this armed conflict. We\nconclude by discussing possible applications of our findings for the design of\nfuture communication technologies.\n", "contributors": [{"name": "Savage, Saiph", "sameAs": [], "familyName": "Savage", "additionalName": "", "givenName": "Saiph", "email": ""}, {"name": "Monroy-Hern\u00e1ndez, Andr\u00e9s", "sameAs": [], "familyName": "Monroy-Hern\u00e1ndez", "additionalName": "", "givenName": "Andr\u00e9s", "email": ""}], "title": "Participatory Militias: An Analysis of an Armed Movement's Online\n  Audience", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02065", "doi:10.1145/2675133.2675295", "oai:arXiv.org:1502.02065"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Armed groups of civilians known as \"self-defense forces\" have ousted the\npowerful Knights Templar drug cartel from several towns in Michoacan. This\nmilitia uprising has unfolded on social media, particularly in the \"VXM\"\n(\"Valor por Michoacan,\" Spanish for \"Courage for Michoacan\") Facebook page,\ngathering more than 170,000 fans. Previous work on the Drug War has documented\nthe use of social media for real-time reports of violent clashes. However, VXM\ngoes one step further by taking on a pro-militia propagandist role, engaging in\ntwo-way communication with its audience. This paper presents a descriptive\nanalysis of VXM and its audience. We examined nine months of posts, from VXM's\ninception until May 2014, totaling 6,000 posts by VXM administrators and more\nthan 108,000 comments from its audience. We describe the main conversation\nthemes, post frequency and relationships with offline events and public\nfigures. We also characterize the behavior of VXM's most active audience\nmembers. Our work illustrates VXM's online mobilization strategies, and how its\naudience takes part in defining the narrative of this armed conflict. We\nconclude by discussing possible applications of our findings for the design of\nfuture communication technologies.\n", "Comment: Participatory Militias: An Analysis of an Armed Movement's Online\n  Audience. Saiph Savage, Andres Monroy-Hernandez. CSCW: ACM Conference on\n  Computer-Supported Cooperative Work 2015"]}}], "languages": [null], "subjects": ["h.5.3", "computer science - computers and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02065"}}, {"publisher": {"name": ""}, "description": "  In this text we develop the formalism of products and powers of linear codes\nunder componentwise multiplication. As an expanded version of the author's talk\nat AGCT-14, focus is put mostly on basic properties and descriptive statements\nthat could otherwise probably not fit in a regular research paper. On the other\nhand, more advanced results and applications are only quickly mentioned with\nreferences to the literature. We also point out a few open problems.\n  Our presentation alternates between two points of view, which the theory\nintertwines in an essential way: that of combinatorial coding, and that of\nalgebraic geometry.\n  In appendices that can be read independently, we investigate topics in\nmultilinear algebra over finite fields, notably we establish a criterion for a\nsymmetric multilinear map to admit a symmetric algorithm, or equivalently, for\na symmetric tensor to decompose as a sum of elementary symmetric tensors.\n", "contributors": [{"name": "Randriambololona, Hugues", "sameAs": [], "familyName": "Randriambololona", "additionalName": "", "givenName": "Hugues", "email": ""}], "title": "On products and powers of linear codes under componentwise\n  multiplication", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-11-29", "2014-10-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.0022", "oai:arXiv.org:1312.0022"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this text we develop the formalism of products and powers of linear codes\nunder componentwise multiplication. As an expanded version of the author's talk\nat AGCT-14, focus is put mostly on basic properties and descriptive statements\nthat could otherwise probably not fit in a regular research paper. On the other\nhand, more advanced results and applications are only quickly mentioned with\nreferences to the literature. We also point out a few open problems.\n  Our presentation alternates between two points of view, which the theory\nintertwines in an essential way: that of combinatorial coding, and that of\nalgebraic geometry.\n  In appendices that can be read independently, we investigate topics in\nmultilinear algebra over finite fields, notably we establish a criterion for a\nsymmetric multilinear map to admit a symmetric algorithm, or equivalently, for\na symmetric tensor to decompose as a sum of elementary symmetric tensors.\n", "Comment: 75 pages; expanded version of a talk at AGCT-14 (Luminy), to appear\n  in vol. 637 of Contemporary Math., AMS, Apr. 2015; v3: minor typos corrected\n  in the final \"open questions\" section"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "computer science - information theory"], "providerUpdatedDateTime": "2014-10-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.0022"}}, {"publisher": {"name": ""}, "description": "  A Hermitian metric $\\omega$ on a complex manifold is called SKT or\npluriclosed if $dd^c\\omega=0$. Let M be a twistor space of a compact,\nanti-selfdual Riemannian manifold, admitting a pluriclosed Hermitian metric. We\nprove that in this case M is K\\\"ahler, hence isomorphic to $\\C P^3$ or a flag\nspace. This result is obtained from rational connectedness of the twistor\nspace, due to F. Campana. As an aside, we prove that the moduli space of\nrational curves on the twistor space of a K3 surface is Stein.\n", "contributors": [{"name": "Verbitsky, Misha", "sameAs": [], "familyName": "Verbitsky", "additionalName": "", "givenName": "Misha", "email": ""}], "title": "Rational curves and special metrics on twistor spaces", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-10-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1210.6725", "Geom. Topol. 18 (2014) 897-909", "doi:10.2140/gt.2014.18.897", "oai:arXiv.org:1210.6725"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  A Hermitian metric $\\omega$ on a complex manifold is called SKT or\npluriclosed if $dd^c\\omega=0$. Let M be a twistor space of a compact,\nanti-selfdual Riemannian manifold, admitting a pluriclosed Hermitian metric. We\nprove that in this case M is K\\\"ahler, hence isomorphic to $\\C P^3$ or a flag\nspace. This result is obtained from rational connectedness of the twistor\nspace, due to F. Campana. As an aside, we prove that the moduli space of\nrational curves on the twistor space of a K3 surface is Stein.\n", "Comment: 12 pages"]}}], "languages": [null], "subjects": ["mathematics - differential geometry", "mathematics - complex variables", "mathematics - algebraic geometry"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1210.6725"}}, {"publisher": {"name": ""}, "description": "  We prove a continuity result for the fibers of the Berkovich analytification\nof a complex algebraic variety with respect to the the maximum of the\nArchimedean norm and the trivial norm. As a consequence, we obtain\ngeneralizations of a result of Mikhalkin and Rullgard about degenerations of\namoebae onto tropical varieties.\n", "contributors": [{"name": "Jonsson, Mattias", "sameAs": [], "familyName": "Jonsson", "additionalName": "", "givenName": "Mattias", "email": ""}], "title": "Degenerations of amoebae and Berkovich spaces", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-05", "2015-04-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.1430", "oai:arXiv.org:1406.1430"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We prove a continuity result for the fibers of the Berkovich analytification\nof a complex algebraic variety with respect to the the maximum of the\nArchimedean norm and the trivial norm. As a consequence, we obtain\ngeneralizations of a result of Mikhalkin and Rullgard about degenerations of\namoebae onto tropical varieties.\n", "Comment: To appear in Math. Ann"]}}], "languages": [null], "subjects": ["mathematics - complex variables", "primary: 14t05", "32p05", "mathematics - algebraic geometry", "secondary: 32a60", "14m25"], "providerUpdatedDateTime": "2015-04-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.1430"}}, {"publisher": {"name": ""}, "description": "  The nature of Systems of Systems (SoSs), large complex systems composed of\nindependent, geographically distributed and continuously evolving constituent\nsystems, means that faults are unavoidable. Previous work on defining\ncontractual specifications of the constituent systems of SoSs does not provide\nany explicit consideration for faults. In this paper we address that gap by\nextending an existing pattern for modelling contracts with fault modelling\nconcepts. The proposed extensions are introduced with respect to an Audio\nVisual SoS case study from Bang and Olufsen, before discussing how they relate\nto previous work on modelling faults in SoSs.\n", "contributors": [{"name": "Andrews, Zoe", "sameAs": [], "familyName": "Andrews", "additionalName": "", "givenName": "Zoe", "email": ""}, {"name": "Bryans, Jeremy", "sameAs": [], "familyName": "Bryans", "additionalName": "", "givenName": "Jeremy", "email": ""}, {"name": "Payne, Richard", "sameAs": [], "familyName": "Payne", "additionalName": "", "givenName": "Richard", "email": ""}, {"name": "Kristensen, Klaus", "sameAs": [], "familyName": "Kristensen", "additionalName": "", "givenName": "Klaus", "email": ""}], "title": "Fault Modelling in System-of-Systems Contracts", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-30", "2014-10-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.7775", "oai:arXiv.org:1404.7775"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The nature of Systems of Systems (SoSs), large complex systems composed of\nindependent, geographically distributed and continuously evolving constituent\nsystems, means that faults are unavoidable. Previous work on defining\ncontractual specifications of the constituent systems of SoSs does not provide\nany explicit consideration for faults. In this paper we address that gap by\nextending an existing pattern for modelling contracts with fault modelling\nconcepts. The proposed extensions are introduced with respect to an Audio\nVisual SoS case study from Bang and Olufsen, before discussing how they relate\nto previous work on modelling faults in SoSs.\n", "Comment: EDCC-2014, EDSoS-2014, systems of systems, modelling, architectural\n  frameworks, contracts, faults"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2014-10-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.7775"}}, {"publisher": {"name": ""}, "description": "  The goal of this work is to provide a fiber integration formula on the\nDemailly tower, that avoids step-by-step elimination of horizontal cohomology\nclasses, and that yields computational effectivity. A natural twist of the\nDemailly tower is introduced and a recursive formula for the total Segre class\nat k-th level is obtained. Then, by interpreting single Segre classes as\ncoefficients, an iterated residue formula is derived.\n", "contributors": [{"name": "Darondeau, Lionel", "sameAs": [], "familyName": "Darondeau", "additionalName": "", "givenName": "Lionel", "email": ""}], "title": "Fiber integration on the Demailly tower", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-11-30", "2015-03-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.0109", "oai:arXiv.org:1312.0109"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The goal of this work is to provide a fiber integration formula on the\nDemailly tower, that avoids step-by-step elimination of horizontal cohomology\nclasses, and that yields computational effectivity. A natural twist of the\nDemailly tower is introduced and a recursive formula for the total Segre class\nat k-th level is obtained. Then, by interpreting single Segre classes as\ncoefficients, an iterated residue formula is derived.\n", "Comment: 22 pages, to appear in Annales de l'Institut Fourier"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "14c17", "32q45", "14q20", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.0109"}}, {"publisher": {"name": ""}, "description": "  Statistical methods have been widely employed in many practical natural\nlanguage processing applications. More specifically, complex networks concepts\nand methods from dynamical systems theory have been successfully applied to\nrecognize stylistic patterns in written texts. Despite the large amount of\nstudies devoted to represent texts with physical models, only a few studies\nhave assessed the relevance of attributes derived from the analysis of\nstylistic fluctuations. Because fluctuations represent a pivotal factor for\ncharacterizing a myriad of real systems, this study focused on the analysis of\nthe properties of stylistic fluctuations in texts via topological analysis of\ncomplex networks and intermittency measurements. The results showed that\ndifferent authors display distinct fluctuation patterns. In particular, it was\nfound that it is possible to identify the authorship of books using the\nintermittency of specific words. Taken together, the results described here\nsuggest that the patterns found in stylistic fluctuations could be used to\nanalyze other related complex systems. Furthermore, the discovery of novel\npatterns related to textual stylistic fluctuations indicates that these\npatterns could be useful to improve the state of the art of many\nstylistic-based natural language processing tasks.\n", "contributors": [{"name": "Amancio, Diego R.", "sameAs": [], "familyName": "Amancio", "additionalName": "R.", "givenName": "Diego", "email": ""}], "title": "Authorship recognition via fluctuation analysis of network topology and\n  word intermittency", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01245", "oai:arXiv.org:1502.01245"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Statistical methods have been widely employed in many practical natural\nlanguage processing applications. More specifically, complex networks concepts\nand methods from dynamical systems theory have been successfully applied to\nrecognize stylistic patterns in written texts. Despite the large amount of\nstudies devoted to represent texts with physical models, only a few studies\nhave assessed the relevance of attributes derived from the analysis of\nstylistic fluctuations. Because fluctuations represent a pivotal factor for\ncharacterizing a myriad of real systems, this study focused on the analysis of\nthe properties of stylistic fluctuations in texts via topological analysis of\ncomplex networks and intermittency measurements. The results showed that\ndifferent authors display distinct fluctuation patterns. In particular, it was\nfound that it is possible to identify the authorship of books using the\nintermittency of specific words. Taken together, the results described here\nsuggest that the patterns found in stylistic fluctuations could be used to\nanalyze other related complex systems. Furthermore, the discovery of novel\npatterns related to textual stylistic fluctuations indicates that these\npatterns could be useful to improve the state of the art of many\nstylistic-based natural language processing tasks.\n"}}], "languages": [null], "subjects": ["computer science - computation and language"], "providerUpdatedDateTime": "2015-02-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01245"}}, {"publisher": {"name": ""}, "description": "  We consider supervised learning with random decision trees, where the tree\nconstruction is completely random. The method is popularly used and works well\nin practice despite the simplicity of the setting, but its statistical\nmechanism is not yet well-understood. In this paper we provide strong\ntheoretical guarantees regarding learning with random decision trees. We\nanalyze and compare three different variants of the algorithm that have minimal\nmemory requirements: majority voting, threshold averaging and probabilistic\naveraging. The random structure of the tree enables us to adapt these methods\nto a differentially-private setting thus we also propose differentially-private\nversions of all three schemes. We give upper-bounds on the generalization error\nand mathematically explain how the accuracy depends on the number of random\ndecision trees. Furthermore, we prove that only logarithmic (in the size of the\ndataset) number of independently selected random decision trees suffice to\ncorrectly classify most of the data, even when differential-privacy guarantees\nmust be maintained. We empirically show that majority voting and threshold\naveraging give the best accuracy, also for conservative users requiring high\nprivacy guarantees. Furthermore, we demonstrate that a simple majority voting\nrule is an especially good candidate for the differentially-private classifier\nsince it is much less sensitive to the choice of forest parameters than other\nmethods.\n", "contributors": [{"name": "Bojarski, Mariusz", "sameAs": [], "familyName": "Bojarski", "additionalName": "", "givenName": "Mariusz", "email": ""}, {"name": "Choromanska, Anna", "sameAs": [], "familyName": "Choromanska", "additionalName": "", "givenName": "Anna", "email": ""}, {"name": "Choromanski, Krzysztof", "sameAs": [], "familyName": "Choromanski", "additionalName": "", "givenName": "Krzysztof", "email": ""}, {"name": "LeCun, Yann", "sameAs": [], "familyName": "LeCun", "additionalName": "", "givenName": "Yann", "email": ""}], "title": "Differentially- and non-differentially-private random decision trees", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-25", "2015-02-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6973", "oai:arXiv.org:1410.6973"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We consider supervised learning with random decision trees, where the tree\nconstruction is completely random. The method is popularly used and works well\nin practice despite the simplicity of the setting, but its statistical\nmechanism is not yet well-understood. In this paper we provide strong\ntheoretical guarantees regarding learning with random decision trees. We\nanalyze and compare three different variants of the algorithm that have minimal\nmemory requirements: majority voting, threshold averaging and probabilistic\naveraging. The random structure of the tree enables us to adapt these methods\nto a differentially-private setting thus we also propose differentially-private\nversions of all three schemes. We give upper-bounds on the generalization error\nand mathematically explain how the accuracy depends on the number of random\ndecision trees. Furthermore, we prove that only logarithmic (in the size of the\ndataset) number of independently selected random decision trees suffice to\ncorrectly classify most of the data, even when differential-privacy guarantees\nmust be maintained. We empirically show that majority voting and threshold\naveraging give the best accuracy, also for conservative users requiring high\nprivacy guarantees. Furthermore, we demonstrate that a simple majority voting\nrule is an especially good candidate for the differentially-private classifier\nsince it is much less sensitive to the choice of forest parameters than other\nmethods.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6973"}}, {"publisher": {"name": ""}, "description": "  We develop a fast variational approximation scheme for Gaussian process (GP)\nregression, where the spectrum of the covariance function is subjected to a\nsparse approximation. Our approach enables uncertainty in covariance function\nhyperparameters to be treated without using Monte Carlo methods and is robust\nto overfitting. Our article makes three contributions. First, we present a\nvariational Bayes algorithm for fitting sparse spectrum GP regression models\nthat uses nonconjugate variational message passing to derive fast and efficient\nupdates. Second, we propose a novel adaptive neighbourhood technique for\nobtaining predictive inference that is effective in dealing with\nnonstationarity. Regression is performed locally at each point to be predicted\nand the neighbourhood is determined using a measure defined based on\nlengthscales estimated from an initial fit. Weighting dimensions according to\nlengthscales, this downweights variables of little relevance, leading to\nautomatic variable selection and improved prediction. Third, we introduce a\ntechnique for accelerating convergence in nonconjugate variational message\npassing by adapting step sizes in the direction of the natural gradient of the\nlower bound. Our adaptive strategy can be easily implemented and empirical\nresults indicate significant speedups.\n", "contributors": [{"name": "Tan, Linda S. L.", "sameAs": [], "familyName": "Tan", "additionalName": "S. L.", "givenName": "Linda", "email": ""}, {"name": "Ong, Victor M. H.", "sameAs": [], "familyName": "Ong", "additionalName": "M. H.", "givenName": "Victor", "email": ""}, {"name": "Nott, David J.", "sameAs": [], "familyName": "Nott", "additionalName": "J.", "givenName": "David", "email": ""}, {"name": "Jasra, Ajay", "sameAs": [], "familyName": "Jasra", "additionalName": "", "givenName": "Ajay", "email": ""}], "title": "Variational inference for sparse spectrum Gaussian process regression", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-09", "2015-01-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.1999", "oai:arXiv.org:1306.1999"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": ["  We develop a fast variational approximation scheme for Gaussian process (GP)\nregression, where the spectrum of the covariance function is subjected to a\nsparse approximation. Our approach enables uncertainty in covariance function\nhyperparameters to be treated without using Monte Carlo methods and is robust\nto overfitting. Our article makes three contributions. First, we present a\nvariational Bayes algorithm for fitting sparse spectrum GP regression models\nthat uses nonconjugate variational message passing to derive fast and efficient\nupdates. Second, we propose a novel adaptive neighbourhood technique for\nobtaining predictive inference that is effective in dealing with\nnonstationarity. Regression is performed locally at each point to be predicted\nand the neighbourhood is determined using a measure defined based on\nlengthscales estimated from an initial fit. Weighting dimensions according to\nlengthscales, this downweights variables of little relevance, leading to\nautomatic variable selection and improved prediction. Third, we introduce a\ntechnique for accelerating convergence in nonconjugate variational message\npassing by adapting step sizes in the direction of the natural gradient of the\nlower bound. Our adaptive strategy can be easily implemented and empirical\nresults indicate significant speedups.\n", "Comment: 20 pages, 11 figures, 1 table"]}}], "languages": [null], "subjects": ["statistics - computation"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.1999"}}, {"publisher": {"name": ""}, "description": "  We consider banded block Toeplitz matrices $T_n$ with $n$ block rows and\ncolumns. We show that under certain technical assumptions, the normalized\neigenvalue counting measure of $T_n$ for $n\\to\\infty$ weakly converges to one\ncomponent of the unique vector of measures that minimizes a certain energy\nfunctional. In this way we generalize a recent result of Duits and Kuijlaars\nfor the scalar case. Along the way we also obtain an equilibrium problem\nassociated to an arbitrary algebraic curve, not necessarily related to a block\nToeplitz matrix.\n  For banded block Toeplitz matrices, there are several new phenomena that do\nnot occur in the scalar case: (i) The total masses of the equilibrium measures\ndo not necessarily form a simple arithmetic series but in general are obtained\nthrough a combinatorial rule; (ii) The limiting eigenvalue distribution may\ncontain point masses, and there may be attracting point sources in the\nequilibrium problem; (iii) More seriously, there are examples where the\nconnection between the limiting eigenvalue distribution of $T_n$ and the\nsolution to the equilibrium problem breaks down. We provide sufficient\nconditions guaranteeing that no such breakdown occurs; in particular we show\nthis if $T_n$ is a Hessenberg matrix.\n", "contributors": [{"name": "Delvaux, Steven", "sameAs": [], "familyName": "Delvaux", "additionalName": "", "givenName": "Steven", "email": ""}], "title": "Equilibrium problem for the eigenvalues of banded block Toeplitz\n  matrices", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-13", "2012-12-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.2644", "Math. Nachr. 285 (2012), 1935-1962", "oai:arXiv.org:1101.2644"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We consider banded block Toeplitz matrices $T_n$ with $n$ block rows and\ncolumns. We show that under certain technical assumptions, the normalized\neigenvalue counting measure of $T_n$ for $n\\to\\infty$ weakly converges to one\ncomponent of the unique vector of measures that minimizes a certain energy\nfunctional. In this way we generalize a recent result of Duits and Kuijlaars\nfor the scalar case. Along the way we also obtain an equilibrium problem\nassociated to an arbitrary algebraic curve, not necessarily related to a block\nToeplitz matrix.\n  For banded block Toeplitz matrices, there are several new phenomena that do\nnot occur in the scalar case: (i) The total masses of the equilibrium measures\ndo not necessarily form a simple arithmetic series but in general are obtained\nthrough a combinatorial rule; (ii) The limiting eigenvalue distribution may\ncontain point masses, and there may be attracting point sources in the\nequilibrium problem; (iii) More seriously, there are examples where the\nconnection between the limiting eigenvalue distribution of $T_n$ and the\nsolution to the equilibrium problem breaks down. We provide sufficient\nconditions guaranteeing that no such breakdown occurs; in particular we show\nthis if $T_n$ is a Hessenberg matrix.\n", "Comment: 32 pages, 7 figures"]}}], "languages": [null], "subjects": ["mathematics - classical analysis and odes", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.2644"}}, {"publisher": {"name": ""}, "description": "  A Random SubMatrix method (RSM) is proposed to calculate the low-rank\ndecomposition of large-scale matrices with known entry percentage \\rho. RSM is\nvery fast as the floating-point operations (flops) required are compared\nfavorably with the state-of-the-art algorithms. Meanwhile RSM is very\nmemory-saving. With known entries homogeneously distributed in the given\nmatrix, sub-matrices formed by known entries are randomly selected. According\nto the just proved theorem that subspace related to smaller singular values is\nless perturbed by noise, the null vectors or the right singular vectors\nassociated with the minor singular values are calculated for each submatrix.\nThe vectors are the null vectors of the corresponding submatrix in the ground\ntruth of the given large-scale matrix. If enough sub-matrices are randomly\nchosen, the low-rank decomposition is estimated. The experimental results on\nrandom synthetical matrices with sizes such as 131072X1024 and on real data\nsets indicate that RSM is much faster and memory-saving, and, meanwhile, has\nconsiderable high precision achieving or approximating to the best.\n", "contributors": [{"name": "Liu, Yiguang", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Yiguang", "email": ""}], "title": "A random algorithm for low-rank decomposition of large-scale matrices\n  with missing entries", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0814", "oai:arXiv.org:1411.0814"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  A Random SubMatrix method (RSM) is proposed to calculate the low-rank\ndecomposition of large-scale matrices with known entry percentage \\rho. RSM is\nvery fast as the floating-point operations (flops) required are compared\nfavorably with the state-of-the-art algorithms. Meanwhile RSM is very\nmemory-saving. With known entries homogeneously distributed in the given\nmatrix, sub-matrices formed by known entries are randomly selected. According\nto the just proved theorem that subspace related to smaller singular values is\nless perturbed by noise, the null vectors or the right singular vectors\nassociated with the minor singular values are calculated for each submatrix.\nThe vectors are the null vectors of the corresponding submatrix in the ground\ntruth of the given large-scale matrix. If enough sub-matrices are randomly\nchosen, the low-rank decomposition is estimated. The experimental results on\nrandom synthetical matrices with sizes such as 131072X1024 and on real data\nsets indicate that RSM is much faster and memory-saving, and, meanwhile, has\nconsiderable high precision achieving or approximating to the best.\n"}}], "languages": [null], "subjects": ["computer science - numerical analysis", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0814"}}, {"publisher": {"name": ""}, "description": "  We give a $2^{n+o(n)}$-time and space randomized algorithm for solving the\nexact Closest Vector Problem (CVP) on $n$-dimensional Euclidean lattices. This\nimproves on the previous fastest algorithm, the deterministic\n$\\widetilde{O}(4^{n})$-time and $\\widetilde{O}(2^{n})$-space algorithm of\nMicciancio and Voulgaris.\n  We achieve our main result in two steps. First, we show how to modify the\nsampling algorithm from ADRS15 to solve the problem of discrete Gaussian\nsampling over lattice shifts, $L- \\vec{t}$, with very low parameters. While the\nactual algorithm is a natural generalization of ADRS15, the analysis uses\nsubstantial new ideas. This yields a $2^{n+o(n)}$-time algorithm for\napproximate CVP with the very good approximation factor $\\gamma =\n1+2^{-o(n/\\log n)}$. Second, we show that the near-closest vectors to a target\nvector $\\vec{t}$ can be grouped into \"lower-dimensional clusters,\" and we use\nthis to obtain a recursive algorithm based on our sampler that solves exact CVP\nin $2^{n + o(n)}$ time.\n  The analysis of both steps depends crucially on some new properties of the\ndiscrete Gaussian distribution, which might be of independent interest.\n", "contributors": [{"name": "Aggarwal, Divesh", "sameAs": [], "familyName": "Aggarwal", "additionalName": "", "givenName": "Divesh", "email": ""}, {"name": "Dadush, Daniel", "sameAs": [], "familyName": "Dadush", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Stephens-Davidowitz, Noah", "sameAs": [], "familyName": "Stephens-Davidowitz", "additionalName": "", "givenName": "Noah", "email": ""}], "title": "Solving the Closest Vector Problem in $2^n$ Time--- The Discrete\n  Gaussian Strikes Again!", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01995", "oai:arXiv.org:1504.01995"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We give a $2^{n+o(n)}$-time and space randomized algorithm for solving the\nexact Closest Vector Problem (CVP) on $n$-dimensional Euclidean lattices. This\nimproves on the previous fastest algorithm, the deterministic\n$\\widetilde{O}(4^{n})$-time and $\\widetilde{O}(2^{n})$-space algorithm of\nMicciancio and Voulgaris.\n  We achieve our main result in two steps. First, we show how to modify the\nsampling algorithm from ADRS15 to solve the problem of discrete Gaussian\nsampling over lattice shifts, $L- \\vec{t}$, with very low parameters. While the\nactual algorithm is a natural generalization of ADRS15, the analysis uses\nsubstantial new ideas. This yields a $2^{n+o(n)}$-time algorithm for\napproximate CVP with the very good approximation factor $\\gamma =\n1+2^{-o(n/\\log n)}$. Second, we show that the near-closest vectors to a target\nvector $\\vec{t}$ can be grouped into \"lower-dimensional clusters,\" and we use\nthis to obtain a recursive algorithm based on our sampler that solves exact CVP\nin $2^{n + o(n)}$ time.\n  The analysis of both steps depends crucially on some new properties of the\ndiscrete Gaussian distribution, which might be of independent interest.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-04-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01995"}}, {"publisher": {"name": ""}, "description": "abstract: The objective of this research is to understand how a set of systems, as defined by the business process, creates value. The three studies contained in this work develop the model of process-based automation. The model states that complementarities among systems are specified by handoffs in the business process. The model also provides theory to explain why entry systems, boundary spanning systems, and back-end control systems provide different impacts on process quality and cost. The first study includes 135 U. S. acute care hospitals. The study finds that hospitals which followed an organizational pattern of process automation have better financial outcomes. The second study looks in more depth at where synergies might be found. It includes 341 California acute care hospitals over 11 years. It finds that increased costs and increase adverse drug events are associated with increased automation discontinuity. Further, the study shows that automation in the front end of the process has a more desirable outcome on cost than automation in the back end of the process. The third study examines the assumption that the systems are actually used. It is a cross-sectional analysis of over 2000 U. S. hospitals. This study finds that system usage is a critical factor in realizing benefits from automating the business process. The model of process-based automation has implications for information technology decision makers, long-term automation planning, and for information systems research. The analyses have additional implications for the healthcare industry.", "contributors": [{"name": "Spaulding, Trent Joseph (Author)", "sameAs": [], "familyName": "Spaulding", "additionalName": "Joseph", "givenName": "Trent", "email": ""}, {"name": "Santanam, Raghu T (Advisor)", "sameAs": [], "familyName": "Santanam", "additionalName": "T", "givenName": "Raghu", "email": ""}, {"name": "Vinze, Ajay  (Committee member)", "sameAs": [], "familyName": "Vinze", "additionalName": "", "givenName": "Ajay", "email": ""}, {"name": "Furukawa, Michael F (Committee member)", "sameAs": [], "familyName": "Furukawa", "additionalName": "F", "givenName": "Michael", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "A Model of Process-Based Automation: Cost and Quality Implications in the Medication Management Process", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "147 pages"}}, {"name": "date", "properties": {"date": "2011"}}, {"name": "description", "properties": {"description": ["abstract: The objective of this research is to understand how a set of systems, as defined by the business process, creates value. The three studies contained in this work develop the model of process-based automation. The model states that complementarities among systems are specified by handoffs in the business process. The model also provides theory to explain why entry systems, boundary spanning systems, and back-end control systems provide different impacts on process quality and cost. The first study includes 135 U. S. acute care hospitals. The study finds that hospitals which followed an organizational pattern of process automation have better financial outcomes. The second study looks in more depth at where synergies might be found. It includes 341 California acute care hospitals over 11 years. It finds that increased costs and increase adverse drug events are associated with increased automation discontinuity. Further, the study shows that automation in the front end of the process has a more desirable outcome on cost than automation in the back end of the process. The third study examines the assumption that the systems are actually used. It is a cross-sectional analysis of over 2000 U. S. hospitals. This study finds that system usage is a critical factor in realizing benefits from automating the business process. The model of process-based automation has implications for information technology decision makers, long-term automation planning, and for information systems research. The analyses have additional implications for the healthcare industry.", "Dissertation/Thesis", "Ph.D. Information Management 2011"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.8931", "item:8931"]}}], "languages": [null], "subjects": ["information systems", "computerized physician order entry", "health care management", "business process", "medication management", "healthcare", "information technology"], "providerUpdatedDateTime": "2015-02-12T01:08:30", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.8931"}}, {"publisher": {"name": ""}, "description": "  The apsis toolkit presented in this paper provides a flexible framework for\nhyperparameter optimization and includes both random search and a bayesian\noptimizer. It is implemented in Python and its architecture features\nadaptability to any desired machine learning code. It can easily be used with\ncommon Python ML frameworks such as scikit-learn. Published under the MIT\nLicense other researchers are heavily encouraged to check out the code,\ncontribute or raise any suggestions. The code can be found at\ngithub.com/FrederikDiehl/apsis.\n", "contributors": [{"name": "Diehl, Frederik", "sameAs": [], "familyName": "Diehl", "additionalName": "", "givenName": "Frederik", "email": ""}, {"name": "Jauch, Andreas", "sameAs": [], "familyName": "Jauch", "additionalName": "", "givenName": "Andreas", "email": ""}], "title": "apsis - Framework for Automated Optimization of Machine Learning Hyper\n  Parameters", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-10", "2015-03-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02946", "oai:arXiv.org:1503.02946"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The apsis toolkit presented in this paper provides a flexible framework for\nhyperparameter optimization and includes both random search and a bayesian\noptimizer. It is implemented in Python and its architecture features\nadaptability to any desired machine learning code. It can easily be used with\ncommon Python ML frameworks such as scikit-learn. Published under the MIT\nLicense other researchers are heavily encouraged to check out the code,\ncontribute or raise any suggestions. The code can be found at\ngithub.com/FrederikDiehl/apsis.\n"}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02946"}}, {"publisher": {"name": ""}, "description": "  How do we know that a kitchen is a kitchen by looking? Relatively little is\nknown about how we conceptualize and categorize different visual environments.\nTraditional models of visual perception posit that scene categorization is\nachieved through the recognition of a scene's objects, yet these models cannot\naccount for the mounting evidence that human observers are relatively\ninsensitive to the local details in an image. Psychologists have long theorized\nthat the affordances, or actionable possibilities of a stimulus are pivotal to\nits perception. To what extent are scene categories created from similar\naffordances? Using a large-scale experiment using hundreds of scene categories,\nwe show that the activities afforded by a visual scene provide a fundamental\ncategorization principle. Affordance-based similarity explained the majority of\nthe structure in the human scene categorization patterns, outperforming\nalternative similarities based on objects or visual features. We all models\nwere combined, affordances provided the majority of the predictive power in the\ncombined model, and nearly half of the total explained variance is captured\nonly by affordances. These results challenge many existing models of high-level\nvisual perception, and provide immediately testable hypotheses for the\nfunctional organization of the human perceptual system.\n", "contributors": [{"name": "Greene, Michelle R.", "sameAs": [], "familyName": "Greene", "additionalName": "R.", "givenName": "Michelle", "email": ""}, {"name": "Baldassano, Christopher", "sameAs": [], "familyName": "Baldassano", "additionalName": "", "givenName": "Christopher", "email": ""}, {"name": "Esteva, Andre", "sameAs": [], "familyName": "Esteva", "additionalName": "", "givenName": "Andre", "email": ""}, {"name": "Beck, Diane M.", "sameAs": [], "familyName": "Beck", "additionalName": "M.", "givenName": "Diane", "email": ""}, {"name": "Fei-Fei, Li", "sameAs": [], "familyName": "Fei-Fei", "additionalName": "", "givenName": "Li", "email": ""}], "title": "Affordances Provide a Fundamental Categorization Principle for Visual\n  Scenes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5340", "oai:arXiv.org:1411.5340"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": "  How do we know that a kitchen is a kitchen by looking? Relatively little is\nknown about how we conceptualize and categorize different visual environments.\nTraditional models of visual perception posit that scene categorization is\nachieved through the recognition of a scene's objects, yet these models cannot\naccount for the mounting evidence that human observers are relatively\ninsensitive to the local details in an image. Psychologists have long theorized\nthat the affordances, or actionable possibilities of a stimulus are pivotal to\nits perception. To what extent are scene categories created from similar\naffordances? Using a large-scale experiment using hundreds of scene categories,\nwe show that the activities afforded by a visual scene provide a fundamental\ncategorization principle. Affordance-based similarity explained the majority of\nthe structure in the human scene categorization patterns, outperforming\nalternative similarities based on objects or visual features. We all models\nwere combined, affordances provided the majority of the predictive power in the\ncombined model, and nearly half of the total explained variance is captured\nonly by affordances. These results challenge many existing models of high-level\nvisual perception, and provide immediately testable hypotheses for the\nfunctional organization of the human perceptual system.\n"}}], "languages": [null], "subjects": ["quantitative biology - neurons and cognition", "computer science - human-computer interaction", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5340"}}, {"publisher": {"name": ""}, "description": "  Much research in the last two decades has focused on Virtual Topology\nReconfiguration (VTR) problem. However, most of the proposed methods either has\nlow controllability, or the analysis of a control parameter is limited to\nempirical analysis. In this paper, we present a highly tunable Virtual Topology\n(VT) controller. First, we analyze the controllability of two previously\nproposed VTR algorithms: a heuristic method and a neural networks based method.\nThen we present insights on how to transform these VTR methods to their tunable\nversions. To benefit from the controllability, an optimality analysis of the\ncontrol parameter is needed. In the second part of the paper, through a\nprobabilistic analysis we find an optimal parameter for the neural network\nbased method. We validated our analysis through simulations. We propose this\nhighly tunable method as a new VTR algorithm.\n", "contributors": [{"name": "Hanay, Y. Sinan", "sameAs": [], "familyName": "Hanay", "additionalName": "Sinan", "givenName": "Y.", "email": ""}, {"name": "Arakawa, Shinichi", "sameAs": [], "familyName": "Arakawa", "additionalName": "", "givenName": "Shinichi", "email": ""}, {"name": "Murata, Masayuki", "sameAs": [], "familyName": "Murata", "additionalName": "", "givenName": "Masayuki", "email": ""}], "title": "A Highly Tunable Virtual Topology Controller", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05710", "oai:arXiv.org:1501.05710"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Much research in the last two decades has focused on Virtual Topology\nReconfiguration (VTR) problem. However, most of the proposed methods either has\nlow controllability, or the analysis of a control parameter is limited to\nempirical analysis. In this paper, we present a highly tunable Virtual Topology\n(VT) controller. First, we analyze the controllability of two previously\nproposed VTR algorithms: a heuristic method and a neural networks based method.\nThen we present insights on how to transform these VTR methods to their tunable\nversions. To benefit from the controllability, an optimality analysis of the\ncontrol parameter is needed. In the second part of the paper, through a\nprobabilistic analysis we find an optimal parameter for the neural network\nbased method. We validated our analysis through simulations. We propose this\nhighly tunable method as a new VTR algorithm.\n", "Comment: 7 pages, 5 figures"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05710"}}, {"publisher": {"name": ""}, "description": "  Diabetes is considered a lifestyle disease and a well managed self-care plays\nan important role in the treatment. Clinicians often conduct surveys to\nunderstand the self-care behaviors in their patients. In this context, we\npropose to use Self-Organising Maps (SOM) to explore the survey data for\nassessing the self-care behaviors in Type-1 diabetic patients. Specifically,\nSOM is used to visualize high dimensional similar patient profiles, which is\nrarely discussed. Experiments demonstrate that our findings through SOM\nanalysis corresponds well to the expectations of the clinicians. In addition,\nour findings inspire the experts to improve their understanding of the\nself-care behaviors for their patients. The principle findings in our study\nshow: 1) patients who take correct dose of insulin, inject insulin at the right\ntime, 2) patients who take correct food portions undertake regular physical\nactivity and 3) patients who eat on time take correct food portions.\n", "contributors": [{"name": "Tirunagari, Santosh", "sameAs": [], "familyName": "Tirunagari", "additionalName": "", "givenName": "Santosh", "email": ""}, {"name": "Poh, Norman", "sameAs": [], "familyName": "Poh", "additionalName": "", "givenName": "Norman", "email": ""}, {"name": "Hu, Guosheng", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Guosheng", "email": ""}, {"name": "Windridge, David", "sameAs": [], "familyName": "Windridge", "additionalName": "", "givenName": "David", "email": ""}], "title": "Identifying Similar Patients Using Self-Organising Maps: A Case Study on\n  Type-1 Diabetes Self-care Survey Responses", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06316", "oai:arXiv.org:1503.06316"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Diabetes is considered a lifestyle disease and a well managed self-care plays\nan important role in the treatment. Clinicians often conduct surveys to\nunderstand the self-care behaviors in their patients. In this context, we\npropose to use Self-Organising Maps (SOM) to explore the survey data for\nassessing the self-care behaviors in Type-1 diabetic patients. Specifically,\nSOM is used to visualize high dimensional similar patient profiles, which is\nrarely discussed. Experiments demonstrate that our findings through SOM\nanalysis corresponds well to the expectations of the clinicians. In addition,\nour findings inspire the experts to improve their understanding of the\nself-care behaviors for their patients. The principle findings in our study\nshow: 1) patients who take correct dose of insulin, inject insulin at the right\ntime, 2) patients who take correct food portions undertake regular physical\nactivity and 3) patients who eat on time take correct food portions.\n", "Comment: 01-05 pages"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - computational engineering", "finance", "and science"], "providerUpdatedDateTime": "2015-03-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06316"}}, {"publisher": {"name": ""}, "description": "  We propose a sampling scheme that can perfectly reconstruct a collection of\nspikes on the sphere from samples of their lowpass-filtered observations.\nCentral to our algorithm is a generalization of the annihilating filter method,\na tool widely used in array signal processing and finite-rate-of-innovation\n(FRI) sampling. The proposed algorithm can reconstruct $K$ spikes from\n$(K+\\sqrt{K})^2$ spatial samples. This sampling requirement improves over\npreviously known FRI sampling schemes on the sphere by a factor of four for\nlarge $K$.\n  We showcase the versatility of the proposed algorithm by applying it to three\ndifferent problems: 1) sampling diffusion processes induced by localized\nsources on the sphere, 2) shot noise removal, and 3) sound source localization\n(SSL) by a spherical microphone array. In particular, we show how SSL can be\nreformulated as a spherical sparse sampling problem.\n", "contributors": [{"name": "Dokmanic, Ivan", "sameAs": [], "familyName": "Dokmanic", "additionalName": "", "givenName": "Ivan", "email": ""}, {"name": "Lu, Yue M.", "sameAs": [], "familyName": "Lu", "additionalName": "M.", "givenName": "Yue", "email": ""}], "title": "Sampling Sparse Signals on the Sphere: Algorithms and Applications", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07577", "oai:arXiv.org:1502.07577"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We propose a sampling scheme that can perfectly reconstruct a collection of\nspikes on the sphere from samples of their lowpass-filtered observations.\nCentral to our algorithm is a generalization of the annihilating filter method,\na tool widely used in array signal processing and finite-rate-of-innovation\n(FRI) sampling. The proposed algorithm can reconstruct $K$ spikes from\n$(K+\\sqrt{K})^2$ spatial samples. This sampling requirement improves over\npreviously known FRI sampling schemes on the sphere by a factor of four for\nlarge $K$.\n  We showcase the versatility of the proposed algorithm by applying it to three\ndifferent problems: 1) sampling diffusion processes induced by localized\nsources on the sphere, 2) shot noise removal, and 3) sound source localization\n(SSL) by a spherical microphone array. In particular, we show how SSL can be\nreformulated as a spherical sparse sampling problem.\n", "Comment: 14 pages, 8 figures, submitted to IEEE Transactions on Signal\n  Processing"]}}], "languages": [null], "subjects": ["computer science - information theory", "computer science - sound"], "providerUpdatedDateTime": "2015-02-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07577"}}, {"publisher": {"name": ""}, "description": "  We study here the relative cohomology and the Gauss-Manin connections\nassociated to an isolated singularity of a function on a manifold with\nboundary, i.e. with a fixed hyperplane section. We prove several relative\nanalogs of classical theorems obtained mainly by E. Brieskorn and B. Malgrange,\nconcerning the properties of the Gauss-Manin connection as well as its\nrelations with the Picard-Lefschetz monodromy and the asymptotics of integrals\nof holomorphic forms along the vanishing cycles. Finally, we give an\napplication in isochore deformation theory, i.e. the deformation theory of\nboundary singularities with respect to a volume form. In particular we prove\nthe relative analog of J. Vey's isochore Morse lemma, J. -P. Fran\\c{c}oise's\ngeneralisation on the local normal forms of volume forms with respect to the\nboundary singularity-preserving diffeomorphisms, as well as M. D. Garay's\ntheorem on the isochore version of Mather's versal unfolding theorem.\n", "contributors": [{"name": "Kourliouros, Konstantinos", "sameAs": [], "familyName": "Kourliouros", "additionalName": "", "givenName": "Konstantinos", "email": ""}], "title": "Gauss-Manin Connections for Boundary Singularities and Isochore\n  Deformations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08021", "oai:arXiv.org:1503.08021"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  We study here the relative cohomology and the Gauss-Manin connections\nassociated to an isolated singularity of a function on a manifold with\nboundary, i.e. with a fixed hyperplane section. We prove several relative\nanalogs of classical theorems obtained mainly by E. Brieskorn and B. Malgrange,\nconcerning the properties of the Gauss-Manin connection as well as its\nrelations with the Picard-Lefschetz monodromy and the asymptotics of integrals\nof holomorphic forms along the vanishing cycles. Finally, we give an\napplication in isochore deformation theory, i.e. the deformation theory of\nboundary singularities with respect to a volume form. In particular we prove\nthe relative analog of J. Vey's isochore Morse lemma, J. -P. Fran\\c{c}oise's\ngeneralisation on the local normal forms of volume forms with respect to the\nboundary singularity-preserving diffeomorphisms, as well as M. D. Garay's\ntheorem on the isochore version of Mather's versal unfolding theorem.\n"}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08021"}}, {"publisher": {"name": ""}, "description": "  Sampling-based algorithms are viewed as practical solutions for\nhigh-dimensional motion planning. Recent progress has taken advantage of random\ngeometric graph theory to show how asymptotic optimality can also be achieved\nwith these methods. Achieving this desirable property for systems with dynamics\nrequires solving a two-point boundary value problem (BVP) in the state space of\nthe underlying dynamical system. It is difficult, however, if not impractical,\nto generate a BVP solver for a variety of important dynamical models of robots\nor physically simulated ones. Thus, an open challenge was whether it was even\npossible to achieve optimality guarantees when planning for systems without\naccess to a BVP solver. This work resolves the above question and describes how\nto achieve asymptotic optimality for kinodynamic planning using incremental\nsampling-based planners by introducing a new rigorous framework. Two new\nmethods, Stable Sparse-RRT (SST) and SST*, result from this analysis, which are\nasymptotically near-optimal and optimal, respectively. The techniques are shown\nto converge fast to high-quality paths, while they maintain only a sparse set\nof samples, which makes them computationally efficient. The good performance of\nthe planners is confirmed by experimental results using dynamical systems\nbenchmarks, as well as physically simulated robots.\n", "contributors": [{"name": "Li, Yanbo", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Yanbo", "email": ""}, {"name": "Littlefield, Zakary", "sameAs": [], "familyName": "Littlefield", "additionalName": "", "givenName": "Zakary", "email": ""}, {"name": "Bekris, Kostas E.", "sameAs": [], "familyName": "Bekris", "additionalName": "E.", "givenName": "Kostas", "email": ""}], "title": "Asymptotically Optimal Sampling-based Kinodynamic Planning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-10", "2014-11-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.2896", "oai:arXiv.org:1407.2896"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Sampling-based algorithms are viewed as practical solutions for\nhigh-dimensional motion planning. Recent progress has taken advantage of random\ngeometric graph theory to show how asymptotic optimality can also be achieved\nwith these methods. Achieving this desirable property for systems with dynamics\nrequires solving a two-point boundary value problem (BVP) in the state space of\nthe underlying dynamical system. It is difficult, however, if not impractical,\nto generate a BVP solver for a variety of important dynamical models of robots\nor physically simulated ones. Thus, an open challenge was whether it was even\npossible to achieve optimality guarantees when planning for systems without\naccess to a BVP solver. This work resolves the above question and describes how\nto achieve asymptotic optimality for kinodynamic planning using incremental\nsampling-based planners by introducing a new rigorous framework. Two new\nmethods, Stable Sparse-RRT (SST) and SST*, result from this analysis, which are\nasymptotically near-optimal and optimal, respectively. The techniques are shown\nto converge fast to high-quality paths, while they maintain only a sparse set\nof samples, which makes them computationally efficient. The good performance of\nthe planners is confirmed by experimental results using dynamical systems\nbenchmarks, as well as physically simulated robots.\n"}}], "languages": [null], "subjects": ["computer science - robotics"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.2896"}}, {"publisher": {"name": ""}, "description": "  Biobjective mixed integer linear programs (BOMILP) are optimization problems\nwhere two linear objectives are optimized over a polyhedron while restricting\nsome of the variables to be integer. Since many of the techniques for solving\nBOMILP (or approximating its solution set) are iterative processes which\nutilize data discovered during early iterations to aid in the discovery of\nimproved data during later iterations, it is highly desirable to efficiently\nstore the nondominated subset of a given set of data. This problem has not\nreceived considerable attention in the context of BOMILP; only naive methods\nhave been implemented. We seek to bridge this gap by presenting a new data\nstructure in the form of a modified binary tree that stores, updates, searches\nand returns nondominated solutions. This structure takes points and line\nsegments in $\\mathbb{R}^2$ as input and stores the nondominated subset of this\ninput. We note that when used alongside an exact solution procedure, such as\nbranch-and-bound (BB), at termination the data stored by this structure is\nprecisely the set of Pareto optimal solutions. We perform two experiments. The\nfirst is designed to compare the utility of our structure for storing\nnondominated data to that of a dynamic list which updates via pairwise\ncomparison. In the second we use our data structure alongside the biobjective\nBB techniques available in the literature and solve specific instances of\nBOMILP. The results of our first experiment suggest that the data structure\nperforms reasonably well in handling input of up to $10^7$ points or segments\nand does so much more efficiently than a dynamic list. The results of the\nsecond experiment show that when our structure is utilized alongside BB\nfathoming is enhanced and running times improve slightly.\n", "contributors": [{"name": "Adelgren, Nathan", "sameAs": [], "familyName": "Adelgren", "additionalName": "", "givenName": "Nathan", "email": ""}, {"name": "Belotti, Pietro", "sameAs": [], "familyName": "Belotti", "additionalName": "", "givenName": "Pietro", "email": ""}, {"name": "Gupte, Akshay", "sameAs": [], "familyName": "Gupte", "additionalName": "", "givenName": "Akshay", "email": ""}], "title": "Efficient storage of Pareto points in biobjective mixed integer\n  programming", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.6538", "oai:arXiv.org:1411.6538"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Biobjective mixed integer linear programs (BOMILP) are optimization problems\nwhere two linear objectives are optimized over a polyhedron while restricting\nsome of the variables to be integer. Since many of the techniques for solving\nBOMILP (or approximating its solution set) are iterative processes which\nutilize data discovered during early iterations to aid in the discovery of\nimproved data during later iterations, it is highly desirable to efficiently\nstore the nondominated subset of a given set of data. This problem has not\nreceived considerable attention in the context of BOMILP; only naive methods\nhave been implemented. We seek to bridge this gap by presenting a new data\nstructure in the form of a modified binary tree that stores, updates, searches\nand returns nondominated solutions. This structure takes points and line\nsegments in $\\mathbb{R}^2$ as input and stores the nondominated subset of this\ninput. We note that when used alongside an exact solution procedure, such as\nbranch-and-bound (BB), at termination the data stored by this structure is\nprecisely the set of Pareto optimal solutions. We perform two experiments. The\nfirst is designed to compare the utility of our structure for storing\nnondominated data to that of a dynamic list which updates via pairwise\ncomparison. In the second we use our data structure alongside the biobjective\nBB techniques available in the literature and solve specific instances of\nBOMILP. The results of our first experiment suggest that the data structure\nperforms reasonably well in handling input of up to $10^7$ points or segments\nand does so much more efficiently than a dynamic list. The results of the\nsecond experiment show that when our structure is utilized alongside BB\nfathoming is enhanced and running times improve slightly.\n", "Comment: Shorter version accepted to Proceedings of the INFORMS Computing\n  Society Meeting 2015"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - optimization and control", "e.1.7", "90c29", "90c11"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.6538"}}, {"publisher": {"name": ""}, "description": "  In this work a rationalized algorithm for Dirac numbers multiplication is\npresented. This algorithm has a low computational complexity feature and is\nwell suited to FPGA implementation. The computation of two Dirac numbers\nproduct using the na\\\"ive method takes 256 real multiplications and 240 real\nadditions, while the proposed algorithm can compute the same result in only 88\nreal multiplications and 256 real additions. During synthesis of the discussed\nalgorithm we use the fact that Dirac numbers product may be represented as\nvector-matrix product. The matrix participating in the product has unique\nstructural properties that allow performing its advantageous decomposition.\nNamely this decomposition leads to significant reducing of the computational\ncomplexity.\n", "contributors": [{"name": "Cariow, Aleksandr", "sameAs": [], "familyName": "Cariow", "additionalName": "", "givenName": "Aleksandr", "email": ""}, {"name": "Cariowa, Galina", "sameAs": [], "familyName": "Cariowa", "additionalName": "", "givenName": "Galina", "email": ""}], "title": "A new algorithm for multiplying two Dirac numbers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00828", "oai:arXiv.org:1501.00828"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this work a rationalized algorithm for Dirac numbers multiplication is\npresented. This algorithm has a low computational complexity feature and is\nwell suited to FPGA implementation. The computation of two Dirac numbers\nproduct using the na\\\"ive method takes 256 real multiplications and 240 real\nadditions, while the proposed algorithm can compute the same result in only 88\nreal multiplications and 256 real additions. During synthesis of the discussed\nalgorithm we use the fact that Dirac numbers product may be represented as\nvector-matrix product. The matrix participating in the product has unique\nstructural properties that allow performing its advantageous decomposition.\nNamely this decomposition leads to significant reducing of the computational\ncomplexity.\n", "Comment: 14 pages, 1 figure"]}}], "languages": [null], "subjects": ["65y20", "11r52", "68w35", "computer science - numerical analysis", "computer science - data structures and algorithms", "65f30", "15b33"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00828"}}, {"publisher": {"name": ""}, "description": "  We establish the satisfiability threshold for random k-SAT for all k >= k_0.\nThat is, there exists a limiting density alpha_s(k) such that a random k-SAT\nformula of clause density alpha is with high probability satisfiable for alpha\n< alpha_s(k), and unsatisfiable for alpha > alpha_s(k). The satisfiability\nthreshold alpha_s(k) is given explicitly by the one-step replica symmetry\nbreaking prediction from statistical physics. We believe that our methods may\napply to a range of random CSPs in the 1RSB universality class.\n", "contributors": [{"name": "Ding, Jian", "sameAs": [], "familyName": "Ding", "additionalName": "", "givenName": "Jian", "email": ""}, {"name": "Sly, Allan", "sameAs": [], "familyName": "Sly", "additionalName": "", "givenName": "Allan", "email": ""}, {"name": "Sun, Nike", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Nike", "email": ""}], "title": "Proof of the satisfiability conjecture for large k", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0650", "oai:arXiv.org:1411.0650"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:math-ph"]}}, {"name": "description", "properties": {"description": "  We establish the satisfiability threshold for random k-SAT for all k >= k_0.\nThat is, there exists a limiting density alpha_s(k) such that a random k-SAT\nformula of clause density alpha is with high probability satisfiable for alpha\n< alpha_s(k), and unsatisfiable for alpha > alpha_s(k). The satisfiability\nthreshold alpha_s(k) is given explicitly by the one-step replica symmetry\nbreaking prediction from statistical physics. We believe that our methods may\napply to a range of random CSPs in the 1RSB universality class.\n"}}], "languages": [null], "subjects": ["mathematical physics", "computer science - discrete mathematics", "mathematics - probability"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0650"}}, {"publisher": {"name": ""}, "description": "  This paper introduces a model of environmental acoustic scenes which adopts a\nmorphological approach by ab-stracting temporal structures of acoustic scenes.\nTo demonstrate its potential, this model is employed to evaluate the\nperformance of a large set of acoustic events detection systems. This model\nallows us to explicitly control key morphological aspects of the acoustic scene\nand isolate their impact on the performance of the system under evaluation.\nThus, more information can be gained on the behavior of evaluated systems,\nproviding guidance for further improvements. The proposed model is validated\nusing submitted systems from the IEEE DCASE Challenge; results indicate that\nthe proposed scheme is able to successfully build datasets useful for\nevaluating some aspects the performance of event detection systems, more\nparticularly their robustness to new listening conditions and the increasing\nlevel of background sounds.\n", "contributors": [{"name": "Lagrange, Mathieu", "sameAs": [], "familyName": "Lagrange", "additionalName": "", "givenName": "Mathieu", "email": ""}, {"name": "Lafay, Gr\u00e9goire", "sameAs": [], "familyName": "Lafay", "additionalName": "", "givenName": "Gr\u00e9goire", "email": ""}, {"name": "Rossignol, Mathias", "sameAs": [], "familyName": "Rossignol", "additionalName": "", "givenName": "Mathias", "email": ""}, {"name": "Benetos, Emmanouil", "sameAs": [], "familyName": "Benetos", "additionalName": "", "givenName": "Emmanouil", "email": ""}, {"name": "Roebel, Axel", "sameAs": [], "familyName": "Roebel", "additionalName": "", "givenName": "Axel", "email": ""}], "title": "An evaluation framework for event detection using a morphological model\n  of acoustic scenes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.00141", "oai:arXiv.org:1502.00141"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  This paper introduces a model of environmental acoustic scenes which adopts a\nmorphological approach by ab-stracting temporal structures of acoustic scenes.\nTo demonstrate its potential, this model is employed to evaluate the\nperformance of a large set of acoustic events detection systems. This model\nallows us to explicitly control key morphological aspects of the acoustic scene\nand isolate their impact on the performance of the system under evaluation.\nThus, more information can be gained on the behavior of evaluated systems,\nproviding guidance for further improvements. The proposed model is validated\nusing submitted systems from the IEEE DCASE Challenge; results indicate that\nthe proposed scheme is able to successfully build datasets useful for\nevaluating some aspects the performance of event detection systems, more\nparticularly their robustness to new listening conditions and the increasing\nlevel of background sounds.\n"}}], "languages": [null], "subjects": ["computer science - sound", "statistics - machine learning"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.00141"}}, {"publisher": {"name": ""}, "description": "  It is shown that polar codes achieve the symmetric capacity of discrete\nmemoryless channels with arbitrary input alphabet sizes. It is shown that in\ngeneral, channel polarization happens in several, rather than only two levels\nso that the synthesized channels are either useless, perfect or \"partially\nperfect\". Any subset of the channel input alphabet which is closed under\naddition, induces a coset partition of the alphabet through its shifts. For any\nsuch partition of the input alphabet, there exists a corresponding partially\nperfect channel whose outputs uniquely determine the coset to which the channel\ninput belongs. By a slight modification of the encoding and decoding rules, it\nis shown that perfect transmission of certain information symbols over\npartially perfect channels is possible. Our result is general regarding both\nthe cardinality and the algebraic structure of the channel input alphabet; i.e\nwe show that for any channel input alphabet size and any Abelian group\nstructure on the alphabet, polar codes are optimal. It is also shown through an\nexample that polar codes when considered as group/coset codes, do not achieve\nthe capacity achievable using coset codes over arbitrary channels.\n", "contributors": [{"name": "Sahebi, Aria G.", "sameAs": [], "familyName": "Sahebi", "additionalName": "G.", "givenName": "Aria", "email": ""}, {"name": "Pradhan, S. Sandeep", "sameAs": [], "familyName": "Pradhan", "additionalName": "Sandeep", "givenName": "S.", "email": ""}], "title": "Multilevel Polarization of Polar Codes Over Arbitrary Discrete\n  Memoryless Channels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-07-07", "2012-06-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1107.1535", "oai:arXiv.org:1107.1535"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  It is shown that polar codes achieve the symmetric capacity of discrete\nmemoryless channels with arbitrary input alphabet sizes. It is shown that in\ngeneral, channel polarization happens in several, rather than only two levels\nso that the synthesized channels are either useless, perfect or \"partially\nperfect\". Any subset of the channel input alphabet which is closed under\naddition, induces a coset partition of the alphabet through its shifts. For any\nsuch partition of the input alphabet, there exists a corresponding partially\nperfect channel whose outputs uniquely determine the coset to which the channel\ninput belongs. By a slight modification of the encoding and decoding rules, it\nis shown that perfect transmission of certain information symbols over\npartially perfect channels is possible. Our result is general regarding both\nthe cardinality and the algebraic structure of the channel input alphabet; i.e\nwe show that for any channel input alphabet size and any Abelian group\nstructure on the alphabet, polar codes are optimal. It is also shown through an\nexample that polar codes when considered as group/coset codes, do not achieve\nthe capacity achievable using coset codes over arbitrary channels.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1107.1535"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "While the spectral graph partitioning method gives high quality segmentation, segmenting large graphs by the spectral method is computationally expensive. Numerous multilevel graph partitioning algorithms are proposed to reduce the segmentation time for the spectral partition of large graphs. However, the greedy local refinement used in these multilevel schemes has the tendency of trapping the partition in poor local minima. In this thesis, I develop a multilevel graph partitioning algorithm that incorporates the inverse powering method with greedy local refinement. The combination of the inverse powering method with greedy local refinement ensures that the partition quality of the multilevel method is as good as, if not better than, segmenting the large graph by the spectral method. In addition, I present a scheme to construct the adjacency matrix, W and degree matrix, D for the coarse graphs. The proposed multilevel graph partitioning algorithm is able to bisect a graph (k = 2) with significantly shorter time than segmenting the original graph without the multilevel implementation, and at the same time achieving the same normalized cut (Ncut) value. The starting eigenvector, obtained by solving a generalized eigenvalue problem on the coarsest graph, is close to the Fiedler vector of the original graph. Hence, the inverse iteration needs only a few iterations to converge the starting vector. In the k-way multilevel graph partition, the larger the graph, the greater the reduction in the time needed for segmenting the graph. For the multilevel image segmentation, the multilevel scheme is able to give better segmentation than segmenting the original image. The multilevel scheme has higher success of preserving the salient part of an object.", "contributors": [{"name": "Kong, Tian Fook", "sameAs": [], "familyName": "Kong", "additionalName": "Fook", "givenName": "Tian", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "Gilbert Strang.", "sameAs": [], "familyName": "Strang.", "additionalName": "", "givenName": "Gilbert", "email": ""}], "title": "Multilevel spectral clustering : graph partitions and image segmentation", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "146 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/45275", "310969204", "oai:dspace.mit.edu:1721.1/45275"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2009-04-29T17:19:04Z", "2009-04-29T17:19:04Z", "2008", "2008"]}}, {"name": "description", "properties": {"description": ["While the spectral graph partitioning method gives high quality segmentation, segmenting large graphs by the spectral method is computationally expensive. Numerous multilevel graph partitioning algorithms are proposed to reduce the segmentation time for the spectral partition of large graphs. However, the greedy local refinement used in these multilevel schemes has the tendency of trapping the partition in poor local minima. In this thesis, I develop a multilevel graph partitioning algorithm that incorporates the inverse powering method with greedy local refinement. The combination of the inverse powering method with greedy local refinement ensures that the partition quality of the multilevel method is as good as, if not better than, segmenting the large graph by the spectral method. In addition, I present a scheme to construct the adjacency matrix, W and degree matrix, D for the coarse graphs. The proposed multilevel graph partitioning algorithm is able to bisect a graph (k = 2) with significantly shorter time than segmenting the original graph without the multilevel implementation, and at the same time achieving the same normalized cut (Ncut) value. The starting eigenvector, obtained by solving a generalized eigenvalue problem on the coarsest graph, is close to the Fiedler vector of the original graph. Hence, the inverse iteration needs only a few iterations to converge the starting vector. In the k-way multilevel graph partition, the larger the graph, the greater the reduction in the time needed for segmenting the graph. For the multilevel image segmentation, the multilevel scheme is able to give better segmentation than segmenting the original image. The multilevel scheme has higher success of preserving the salient part of an object.", "(cont.) In this work, I also show that the Ncut value is not the ultimate yardstick for the segmentation quality of an image. Finding a partition that has lower Ncut value does not necessary means better segmentation quality. Segmenting large images by the multilevel method offers both speed and quality.", "by Tian Fook Kong.", "Thesis (S.M.)--Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2008.", "Includes bibliographical references (p. 145-146)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39115", "hdl_1721.1_39117"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:17", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/45275"}}, {"publisher": {"name": ""}, "description": "  In this paper we describe a new tool, SReach, which solves probabilistic\nbounded reachability problems for two classes of stochastic hybrid systems. The\nfirst one is (nonlinear) hybrid automata with parametric uncertainty. The\nsecond one is probabilistic hybrid automata with additional randomness for both\ntransition probabilities and variable resets. Standard approaches to\nreachability problems for linear hybrid systems require numerical solutions for\nlarge optimization problems, and become infeasible for systems involving both\nnonlinear dynamics over the reals and stochasticity. Our approach encodes\nstochastic information by using random variables, and combines the randomized\nsampling, a $\\delta$-complete decision procedure, and statistical tests. SReach\nutilizes the $\\delta$-complete decision procedure to solve reachability\nproblems in a sound manner, i.e., it always decides correctly if, for a given\nassignment to all random variables, the system actually reaches the unsafe\nregion. The statistical tests adapted guarantee arbitrary small error bounds\nbetween probabilities estimated by SReach and real ones. Compared to standard\nsimulation-based methods, our approach supports non-deterministic branching,\nincreases the coverage of simulation, and avoids the zero-crossing problem. We\ndemonstrate our method's feasibility by applying SReach to three representative\nbiological models and to additional benchmarks for nonlinear hybrid systems\nwith multiple probabilistic system parameters.\n", "contributors": [{"name": "Wang, Qinsi", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Qinsi", "email": ""}, {"name": "Zuliani, Paolo", "sameAs": [], "familyName": "Zuliani", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Kong, Soonho", "sameAs": [], "familyName": "Kong", "additionalName": "", "givenName": "Soonho", "email": ""}, {"name": "Gao, Sicun", "sameAs": [], "familyName": "Gao", "additionalName": "", "givenName": "Sicun", "email": ""}, {"name": "Clarke, Edmund M.", "sameAs": [], "familyName": "Clarke", "additionalName": "M.", "givenName": "Edmund", "email": ""}], "title": "SReach: A Bounded Model Checker for Stochastic Hybrid Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-28", "2014-10-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.7206", "oai:arXiv.org:1404.7206"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper we describe a new tool, SReach, which solves probabilistic\nbounded reachability problems for two classes of stochastic hybrid systems. The\nfirst one is (nonlinear) hybrid automata with parametric uncertainty. The\nsecond one is probabilistic hybrid automata with additional randomness for both\ntransition probabilities and variable resets. Standard approaches to\nreachability problems for linear hybrid systems require numerical solutions for\nlarge optimization problems, and become infeasible for systems involving both\nnonlinear dynamics over the reals and stochasticity. Our approach encodes\nstochastic information by using random variables, and combines the randomized\nsampling, a $\\delta$-complete decision procedure, and statistical tests. SReach\nutilizes the $\\delta$-complete decision procedure to solve reachability\nproblems in a sound manner, i.e., it always decides correctly if, for a given\nassignment to all random variables, the system actually reaches the unsafe\nregion. The statistical tests adapted guarantee arbitrary small error bounds\nbetween probabilities estimated by SReach and real ones. Compared to standard\nsimulation-based methods, our approach supports non-deterministic branching,\nincreases the coverage of simulation, and avoids the zero-crossing problem. We\ndemonstrate our method's feasibility by applying SReach to three representative\nbiological models and to additional benchmarks for nonlinear hybrid systems\nwith multiple probabilistic system parameters.\n"}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.7206"}}, {"publisher": {"name": ""}, "description": "  A number of ill-posed inverse problems in signal processing, like blind\ndeconvolution, matrix factorization, dictionary learning and blind source\nseparation share the common characteristic of being bilinear inverse problems\n(BIPs), i.e. the observation model is a function of two variables and\nconditioned on one variable being known, the observation is a linear function\nof the other variable. A key issue that arises for such inverse problems is\nthat of identifiability, i.e. whether the observation is sufficient to\nunambiguously determine the pair of inputs that generated the observation.\nIdentifiability is a key concern for applications like blind equalization in\nwireless communications and data mining in machine learning. Herein, a unifying\nand flexible approach to identifiability analysis for general conic prior\nconstrained BIPs is presented, exploiting a connection to low-rank matrix\nrecovery via lifting. We develop deterministic identifiability conditions on\nthe input signals and examine their satisfiability in practice for three\nclasses of signal distributions, viz. dependent but uncorrelated, independent\nGaussian, and independent Bernoulli. In each case, scaling laws are developed\nthat trade-off probability of robust identifiability with the complexity of the\nrank two null space. An added appeal of our approach is that the rank two null\nspace can be partly or fully characterized for many bilinear problems of\ninterest (e.g. blind deconvolution). We present numerical experiments involving\nvariations on the blind deconvolution problem that exploit a characterization\nof the rank two null space and demonstrate that the scaling laws offer good\nestimates of identifiability.\n", "contributors": [{"name": "Choudhary, Sunav", "sameAs": [], "familyName": "Choudhary", "additionalName": "", "givenName": "Sunav", "email": ""}, {"name": "Mitra, Urbashi", "sameAs": [], "familyName": "Mitra", "additionalName": "", "givenName": "Urbashi", "email": ""}], "title": "Identifiability Scaling Laws in Bilinear Inverse Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-11", "2014-11-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.2637", "oai:arXiv.org:1402.2637"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A number of ill-posed inverse problems in signal processing, like blind\ndeconvolution, matrix factorization, dictionary learning and blind source\nseparation share the common characteristic of being bilinear inverse problems\n(BIPs), i.e. the observation model is a function of two variables and\nconditioned on one variable being known, the observation is a linear function\nof the other variable. A key issue that arises for such inverse problems is\nthat of identifiability, i.e. whether the observation is sufficient to\nunambiguously determine the pair of inputs that generated the observation.\nIdentifiability is a key concern for applications like blind equalization in\nwireless communications and data mining in machine learning. Herein, a unifying\nand flexible approach to identifiability analysis for general conic prior\nconstrained BIPs is presented, exploiting a connection to low-rank matrix\nrecovery via lifting. We develop deterministic identifiability conditions on\nthe input signals and examine their satisfiability in practice for three\nclasses of signal distributions, viz. dependent but uncorrelated, independent\nGaussian, and independent Bernoulli. In each case, scaling laws are developed\nthat trade-off probability of robust identifiability with the complexity of the\nrank two null space. An added appeal of our approach is that the rank two null\nspace can be partly or fully characterized for many bilinear problems of\ninterest (e.g. blind deconvolution). We present numerical experiments involving\nvariations on the blind deconvolution problem that exploit a characterization\nof the rank two null space and demonstrate that the scaling laws offer good\nestimates of identifiability.\n", "Comment: 25 pages, 5 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.2637"}}, {"publisher": {"name": ""}, "description": "  We propose a method for estimating channel parameters from RSSI measurements\nand the lost packet count, which can work in the presence of losses due to both\ninterference and signal attenuation below the noise floor. This is especially\nimportant in the wireless networks, such as vehicular, where propagation model\nchanges with the density of nodes. The method is based on Stochastic\nExpectation Maximization, where the received data is modeled as a mixture of\ndistributions (no/low interference and strong interference), incomplete\n(censored) due to packet losses. The PDFs in the mixture are Gamma, according\nto the commonly accepted model for wireless signal and interference power. This\napproach leverages the loss count as additional information, hence\noutperforming maximum likelihood estimation, which does not use this\ninformation (ML-), for a small number of received RSSI samples. Hence, it\nallows inexpensive on-line channel estimation from ad-hoc collected data. The\nmethod also outperforms ML- on uncensored data mixtures, as ML- assumes that\nsamples are from a single-mode PDF.\n", "contributors": [{"name": "Kokalj-Filipovic, Silvija", "sameAs": [], "familyName": "Kokalj-Filipovic", "additionalName": "", "givenName": "Silvija", "email": ""}, {"name": "Greenstein, Larry", "sameAs": [], "familyName": "Greenstein", "additionalName": "", "givenName": "Larry", "email": ""}], "title": "EM-Based Channel Estimation from Crowd-Sourced RSSI Samples Corrupted by\n  Noise and Interference", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01072", "oai:arXiv.org:1504.01072"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We propose a method for estimating channel parameters from RSSI measurements\nand the lost packet count, which can work in the presence of losses due to both\ninterference and signal attenuation below the noise floor. This is especially\nimportant in the wireless networks, such as vehicular, where propagation model\nchanges with the density of nodes. The method is based on Stochastic\nExpectation Maximization, where the received data is modeled as a mixture of\ndistributions (no/low interference and strong interference), incomplete\n(censored) due to packet losses. The PDFs in the mixture are Gamma, according\nto the commonly accepted model for wireless signal and interference power. This\napproach leverages the loss count as additional information, hence\noutperforming maximum likelihood estimation, which does not use this\ninformation (ML-), for a small number of received RSSI samples. Hence, it\nallows inexpensive on-line channel estimation from ad-hoc collected data. The\nmethod also outperforms ML- on uncensored data mixtures, as ML- assumes that\nsamples are from a single-mode PDF.\n", "Comment: CISS 2015"]}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01072"}}, {"publisher": {"name": ""}, "description": "  The strong solutions of Nine Men's Morris and its variant, Lasker Morris are\nwell-known results (the starting positions are draws). We re-examined both of\nthese games, and calculated extended strong solutions for them. By this we mean\nthe game-theoretic values of all possible game states that could be reached\nfrom certain starting positions where the number of stones to be placed by the\nplayers is different from the standard rules. These were also calculated for a\npreviously unsolved third variant, Morabaraba, with interesting results: most\nof the starting positions where the players can place an equal number of stones\n(including the standard starting position) are wins for the first player (as\nopposed to the above games, where these are usually draws).\n  We also developed a multi-valued retrograde analysis, and used it as a basis\nfor an algorithm for solving these games ultra-strongly. This means that when\nour program is playing against a fallible opponent, it has a greater chance of\nachieving a better result than the game-theoretic value, compared to randomly\nselecting between \"just strongly\" optimal moves. Previous attempts on\nultra-strong solutions used local heuristics or learning during games, but we\nincorporated our algorithm into the retrograde analysis.\n", "contributors": [{"name": "G\u00e9vay, G\u00e1bor E.", "sameAs": [], "familyName": "G\u00e9vay", "additionalName": "E.", "givenName": "G\u00e1bor", "email": ""}, {"name": "Danner, G\u00e1bor", "sameAs": [], "familyName": "Danner", "additionalName": "", "givenName": "G\u00e1bor", "email": ""}], "title": "Calculating Ultra-Strong and Extended Solutions for Nine Men's Morris,\n  Morabaraba, and Lasker", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-31", "2015-03-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.0032", "oai:arXiv.org:1408.0032"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The strong solutions of Nine Men's Morris and its variant, Lasker Morris are\nwell-known results (the starting positions are draws). We re-examined both of\nthese games, and calculated extended strong solutions for them. By this we mean\nthe game-theoretic values of all possible game states that could be reached\nfrom certain starting positions where the number of stones to be placed by the\nplayers is different from the standard rules. These were also calculated for a\npreviously unsolved third variant, Morabaraba, with interesting results: most\nof the starting positions where the players can place an equal number of stones\n(including the standard starting position) are wins for the first player (as\nopposed to the above games, where these are usually draws).\n  We also developed a multi-valued retrograde analysis, and used it as a basis\nfor an algorithm for solving these games ultra-strongly. This means that when\nour program is playing against a fallible opponent, it has a greater chance of\nachieving a better result than the game-theoretic value, compared to randomly\nselecting between \"just strongly\" optimal moves. Previous attempts on\nultra-strong solutions used local heuristics or learning during games, but we\nincorporated our algorithm into the retrograde analysis.\n", "Comment: (c) 2015 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other users, including\n  reprinting/republishing this material for advertising or promotional\n  purposes, creating new collective works for resale or redistribution to\n  servers or lists, or reuse of any copyrighted components of this work in\n  other works"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "i.2.8"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.0032"}}, {"publisher": {"name": ""}, "description": "  In the restructured electricity industry, electricity pooling markets are an\noligopoly with strategic producers possessing private information (private\nproduction cost function). We focus on pooling markets where aggregate demand\nis represented by a non-strategic agent.\n  Inelasticity of demand is a main difficulty in electricity markets which can\npotentially result in market failure and high prices. We consider demand to be\ninelastic.\n  We propose a market mechanism that has the following features. (F1) It is\nindividually rational. (F2) It is budget balanced. (F3) It is price efficient,\nthat is, at equilibrium the price of electricity is equal to the marginal cost\nof production. (F4) The energy production profile corresponding to every\nnon-zero Nash equilibrium of the game induced by the mechanism is a solution of\nthe corresponding centralized problem where the objective is the maximization\nof the sum of the producers' and consumers' utilities.\n  We identify some open problems associated with our approach to electricity\npooling markets.\n", "contributors": [{"name": "Rasouli, Mohammad", "sameAs": [], "familyName": "Rasouli", "additionalName": "", "givenName": "Mohammad", "email": ""}, {"name": "Teneketzis, Demosthenis", "sameAs": [], "familyName": "Teneketzis", "additionalName": "", "givenName": "Demosthenis", "email": ""}], "title": "Electricity Pooling Markets with Strategic Producers Possessing\n  Asymmetric Information II: Inelastic Demand", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-21", "2014-10-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.5539", "oai:arXiv.org:1404.5539"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In the restructured electricity industry, electricity pooling markets are an\noligopoly with strategic producers possessing private information (private\nproduction cost function). We focus on pooling markets where aggregate demand\nis represented by a non-strategic agent.\n  Inelasticity of demand is a main difficulty in electricity markets which can\npotentially result in market failure and high prices. We consider demand to be\ninelastic.\n  We propose a market mechanism that has the following features. (F1) It is\nindividually rational. (F2) It is budget balanced. (F3) It is price efficient,\nthat is, at equilibrium the price of electricity is equal to the marginal cost\nof production. (F4) The energy production profile corresponding to every\nnon-zero Nash equilibrium of the game induced by the mechanism is a solution of\nthe corresponding centralized problem where the objective is the maximization\nof the sum of the producers' and consumers' utilities.\n  We identify some open problems associated with our approach to electricity\npooling markets.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.5539"}}, {"publisher": {"name": ""}, "description": "  It is an unfortunate convention of science that research should pretend to be\nreproducible; our top tips will help you mitigate this fussy conventionality,\nenabling you to enthusiastically showcase your irreproducible work.\n", "contributors": [{"name": "Hong, Neil P. Chue", "sameAs": [], "familyName": "Hong", "additionalName": "P. Chue", "givenName": "Neil", "email": ""}, {"name": "Crick, Tom", "sameAs": [], "familyName": "Crick", "additionalName": "", "givenName": "Tom", "email": ""}, {"name": "Gent, Ian P.", "sameAs": [], "familyName": "Gent", "additionalName": "P.", "givenName": "Ian", "email": ""}, {"name": "Kotthoff, Lars", "sameAs": [], "familyName": "Kotthoff", "additionalName": "", "givenName": "Lars", "email": ""}], "title": "Top Tips to Make Your Research Irreproducible", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.00062", "oai:arXiv.org:1504.00062"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  It is an unfortunate convention of science that research should pretend to be\nreproducible; our top tips will help you mitigate this fussy conventionality,\nenabling you to enthusiastically showcase your irreproducible work.\n", "Comment: 2 pages, LaTeX"]}}], "languages": [null], "subjects": ["computer science - computational engineering", "finance", "and science", "computer science - computers and society"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.00062"}}, {"publisher": {"name": ""}, "description": "  In the context of distributed estimation, we consider the problem of sensor\ncollaboration, which refers to the act of sharing measurements with neighboring\nsensors prior to transmission to a fusion center. While incorporating the cost\nof sensor collaboration, we aim to find optimal sparse collaboration schemes\nsubject to a certain information or energy constraint. Two types of sensor\ncollaboration problems are studied: minimum energy with an information\nconstraint; and maximum information with an energy constraint. To solve the\nresulting sensor collaboration problems, we present tractable optimization\nformulations and propose efficient methods which render near-optimal solutions\nin numerical experiments. We also explore the situation in which there is a\ncost associated with the involvement of each sensor in the estimation scheme.\nIn such situations, the participating sensors must be chosen judiciously. We\nintroduce a unified framework to jointly design the optimal sensor selection\nand collaboration schemes. For a given estimation performance, we show\nempirically that there exists a trade-off between sensor selection and sensor\ncollaboration.\n", "contributors": [{"name": "Liu, Sijia", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Sijia", "email": ""}, {"name": "Kar, Swarnendu", "sameAs": [], "familyName": "Kar", "additionalName": "", "givenName": "Swarnendu", "email": ""}, {"name": "Fardad, Makan", "sameAs": [], "familyName": "Fardad", "additionalName": "", "givenName": "Makan", "email": ""}, {"name": "Varshney, Pramod K.", "sameAs": [], "familyName": "Varshney", "additionalName": "K.", "givenName": "Pramod", "email": ""}], "title": "Sparsity-Aware Sensor Collaboration for Linear Coherent Estimation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-27", "2015-02-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6566", "oai:arXiv.org:1408.6566"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  In the context of distributed estimation, we consider the problem of sensor\ncollaboration, which refers to the act of sharing measurements with neighboring\nsensors prior to transmission to a fusion center. While incorporating the cost\nof sensor collaboration, we aim to find optimal sparse collaboration schemes\nsubject to a certain information or energy constraint. Two types of sensor\ncollaboration problems are studied: minimum energy with an information\nconstraint; and maximum information with an energy constraint. To solve the\nresulting sensor collaboration problems, we present tractable optimization\nformulations and propose efficient methods which render near-optimal solutions\nin numerical experiments. We also explore the situation in which there is a\ncost associated with the involvement of each sensor in the estimation scheme.\nIn such situations, the participating sensors must be chosen judiciously. We\nintroduce a unified framework to jointly design the optimal sensor selection\nand collaboration schemes. For a given estimation performance, we show\nempirically that there exists a trade-off between sensor selection and sensor\ncollaboration.\n", "Comment: IEEE Transactions on Signal Processing"]}}], "languages": [null], "subjects": ["computer science - information theory", "statistics - methodology"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6566"}}, {"publisher": {"name": ""}, "description": "  We present a study on connection errors in networks of linear features and\nmethods of error detection. We model networks with special connection\nspecifications as networks with hierarchically connected features and define\nerrors considering the spatial relationships and the functionality of the\nnetwork elements. A general definition of the problem of the detection of\nconnection errors which takes into account the functionality of the network\nelements is discussed. Then a series of spatial algorithms that solve different\naspects of the problem is presented. We also define and analyze the notion of\ngeometrical reduction as a method of achieving efficient performance. In the\nlast section the undecidability of algorithmic error correction is discussed.\n", "contributors": [{"name": "Rodis, Panteleimon", "sameAs": [], "familyName": "Rodis", "additionalName": "", "givenName": "Panteleimon", "email": ""}], "title": "Connection errors in networks of linear features and the application of\n  geometrical reduction in spatial data algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-27", "2015-04-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.5410", "oai:arXiv.org:1101.5410"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We present a study on connection errors in networks of linear features and\nmethods of error detection. We model networks with special connection\nspecifications as networks with hierarchically connected features and define\nerrors considering the spatial relationships and the functionality of the\nnetwork elements. A general definition of the problem of the detection of\nconnection errors which takes into account the functionality of the network\nelements is discussed. Then a series of spatial algorithms that solve different\naspects of the problem is presented. We also define and analyze the notion of\ngeometrical reduction as a method of achieving efficient performance. In the\nlast section the undecidability of algorithmic error correction is discussed.\n", "Comment: 14 pages, 4 spatial algorithms, 3 illustrations"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.5410"}}, {"publisher": {"name": "John Wiley & Sons Ltd"}, "description": "", "contributors": [{"name": "Rosa-Bray, M", "sameAs": [], "familyName": "Rosa-Bray", "additionalName": "", "givenName": "M", "email": ""}, {"name": "Wisdom, C", "sameAs": [], "familyName": "Wisdom", "additionalName": "", "givenName": "C", "email": ""}, {"name": "Marier, J F", "sameAs": [], "familyName": "Marier", "additionalName": "F", "givenName": "J", "email": ""}, {"name": "Mouksassi, M-S", "sameAs": [], "familyName": "Mouksassi", "additionalName": "", "givenName": "M-S", "email": ""}, {"name": "Wada, S", "sameAs": [], "familyName": "Wada", "additionalName": "", "givenName": "S", "email": ""}], "title": "The effect of plasmapheresis on blood pressure in voluntary plasma donors", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["blood component collection and production"], "providerUpdatedDateTime": "2015-01-30T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4302974"}}, {"publisher": {"name": ""}, "description": "  We propose, analyze and demonstrate an architecture for scalable cooperative\nreception. In a cluster of N + 1 receive nodes, one node is designated as the\nfinal receiver, and the N other nodes act as amplify-and-forward relays which\nadapt their phases such that the relayed signals add up constructively at the\ndesignated receiver. This yields received SNR scaling linearly with N, while\navoiding the linear increase in overhead incurred by a direct approach in which\nreceived signals are separately quantized and transmitted for centralized\nprocessing. By transforming the task of long-distance distributed receive\nbeamforming into one of local distributed transmit beamforming, we can leverage\na scalable one-bit feedback algorithm for phase synchronization. We show that\ntime division between the long-distance and local links eliminates the need for\nexplicit frequency synchronization. We provide an analytical framework, whose\nresults closely match Monte Carlo simulations, to evaluate the impact of phase\nnoise due to relaying delay on the performance of the one-bit feedback\nalgorithm. Experimental results from our prototype implementation on\nsoftware-defined radios demonstrate the expected gains in received signal\nstrength despite significant oscillator drift, and are consistent with results\nfrom our analytical framework.\n", "contributors": [{"name": "Quitin, Francois", "sameAs": [], "familyName": "Quitin", "additionalName": "", "givenName": "Francois", "email": ""}, {"name": "Irish, Andrew T.", "sameAs": [], "familyName": "Irish", "additionalName": "T.", "givenName": "Andrew", "email": ""}, {"name": "Madhow, Upamanyu", "sameAs": [], "familyName": "Madhow", "additionalName": "", "givenName": "Upamanyu", "email": ""}], "title": "A scalable architecture for distributed receive beamforming: analysis\n  and experimental demonstration", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05695", "oai:arXiv.org:1501.05695"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We propose, analyze and demonstrate an architecture for scalable cooperative\nreception. In a cluster of N + 1 receive nodes, one node is designated as the\nfinal receiver, and the N other nodes act as amplify-and-forward relays which\nadapt their phases such that the relayed signals add up constructively at the\ndesignated receiver. This yields received SNR scaling linearly with N, while\navoiding the linear increase in overhead incurred by a direct approach in which\nreceived signals are separately quantized and transmitted for centralized\nprocessing. By transforming the task of long-distance distributed receive\nbeamforming into one of local distributed transmit beamforming, we can leverage\na scalable one-bit feedback algorithm for phase synchronization. We show that\ntime division between the long-distance and local links eliminates the need for\nexplicit frequency synchronization. We provide an analytical framework, whose\nresults closely match Monte Carlo simulations, to evaluate the impact of phase\nnoise due to relaying delay on the performance of the one-bit feedback\nalgorithm. Experimental results from our prototype implementation on\nsoftware-defined radios demonstrate the expected gains in received signal\nstrength despite significant oscillator drift, and are consistent with results\nfrom our analytical framework.\n", "Comment: submitted to IEEE Transactions on Wireless Communications"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05695"}}, {"publisher": {"name": ""}, "description": "  Link failures in wide area networks are common. To recover from such\nfailures, a number of methods such as SONET rings, protection cycles, and\nsource rerouting have been investigated. Two important considerations in such\napproaches are the recovery time and the needed spare capacity to complete the\nrecovery. Usually, these techniques attempt to achieve a recovery time less\nthan 50 ms. In this paper we introduce an approach that provides link failure\nrecovery in a hitless manner, or without any appreciable delay. This is\nachieved by means of a method called diversity coding. We present an algorithm\nfor the design of an overlay network to achieve recovery from single link\nfailures in arbitrary networks via diversity coding. This algorithm is designed\nto minimize spare capacity for recovery. We compare the recovery time and spare\ncapacity performance of this algorithm against conventional techniques in terms\nof recovery time, spare capacity, and a joint metric called Quality of Recovery\n(QoR). QoR incorporates both the spare capacity percentages and worst case\nrecovery times. Based on these results, we conclude that the proposed technique\nprovides much shorter recovery times while achieving similar extra capacity, or\nbetter QoR performance overall.\n", "contributors": [{"name": "Avci, S. N.", "sameAs": [], "familyName": "Avci", "additionalName": "N.", "givenName": "S.", "email": ""}, {"name": "Hu, X.", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "X.", "email": ""}, {"name": "Ayanoglu, E.", "sameAs": [], "familyName": "Ayanoglu", "additionalName": "", "givenName": "E.", "email": ""}], "title": "Recovery from Link Failures in Networks with Arbitrary Topology via\n  Diversity Coding", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-06-02", "2011-06-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1106.0489", "oai:arXiv.org:1106.0489"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Link failures in wide area networks are common. To recover from such\nfailures, a number of methods such as SONET rings, protection cycles, and\nsource rerouting have been investigated. Two important considerations in such\napproaches are the recovery time and the needed spare capacity to complete the\nrecovery. Usually, these techniques attempt to achieve a recovery time less\nthan 50 ms. In this paper we introduce an approach that provides link failure\nrecovery in a hitless manner, or without any appreciable delay. This is\nachieved by means of a method called diversity coding. We present an algorithm\nfor the design of an overlay network to achieve recovery from single link\nfailures in arbitrary networks via diversity coding. This algorithm is designed\nto minimize spare capacity for recovery. We compare the recovery time and spare\ncapacity performance of this algorithm against conventional techniques in terms\nof recovery time, spare capacity, and a joint metric called Quality of Recovery\n(QoR). QoR incorporates both the spare capacity percentages and worst case\nrecovery times. Based on these results, we conclude that the proposed technique\nprovides much shorter recovery times while achieving similar extra capacity, or\nbetter QoR performance overall.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1106.0489"}}, {"publisher": {"name": ""}, "description": "  In contrast to its wired counterpart, wireless communication is highly\nsusceptible to eavesdropping due to the broadcast nature of the wireless\npropagation medium. Recent works have proposed the use of interference to\nreduce eavesdropping capabilities in wireless wiretap networks. However, the\nconcurrent effect of interference on both eavesdropping receivers (ERs) and\nlegitimate receivers (LRs) has not been thoroughly investigated, and carefully\nengineering the network interference is required to harness the full potential\nof interference for wireless secrecy. This two part paper addresses this issue\nby proposing a generalized interference alignment (GIA) technique, which\njointly designs the transceivers at the legitimate partners to impede the ERs\nwithout interfering with LRs. In Part I, we have established a theoretical\nframework for the GIA technique. In Part II, we will first propose an efficient\nGIA algorithm that is applicable to large-scale networks and then evaluate the\nperformance of this algorithm in stochastic wireless wiretap network via both\nanalysis and simulation. These results reveal insights into when and how GIA\ncontributes to wireless secrecy.\n", "contributors": [{"name": "Ruan, Liangzhong", "sameAs": [], "familyName": "Ruan", "additionalName": "", "givenName": "Liangzhong", "email": ""}, {"name": "Lau, Vincent K. N.", "sameAs": [], "familyName": "Lau", "additionalName": "K. N.", "givenName": "Vincent", "email": ""}, {"name": "Win, Moe Z.", "sameAs": [], "familyName": "Win", "additionalName": "Z.", "givenName": "Moe", "email": ""}], "title": "Generalized Interference Alignment --- Part II: Application to Wireless\n  Secrecy", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06361", "oai:arXiv.org:1503.06361"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In contrast to its wired counterpart, wireless communication is highly\nsusceptible to eavesdropping due to the broadcast nature of the wireless\npropagation medium. Recent works have proposed the use of interference to\nreduce eavesdropping capabilities in wireless wiretap networks. However, the\nconcurrent effect of interference on both eavesdropping receivers (ERs) and\nlegitimate receivers (LRs) has not been thoroughly investigated, and carefully\nengineering the network interference is required to harness the full potential\nof interference for wireless secrecy. This two part paper addresses this issue\nby proposing a generalized interference alignment (GIA) technique, which\njointly designs the transceivers at the legitimate partners to impede the ERs\nwithout interfering with LRs. In Part I, we have established a theoretical\nframework for the GIA technique. In Part II, we will first propose an efficient\nGIA algorithm that is applicable to large-scale networks and then evaluate the\nperformance of this algorithm in stochastic wireless wiretap network via both\nanalysis and simulation. These results reveal insights into when and how GIA\ncontributes to wireless secrecy.\n", "Comment: minor revision at IEEE Transactions on Signal Processing"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06361"}}, {"publisher": {"name": ""}, "description": "  It is known that the Bergman projection operator maps the space of\nessentially bounded functions in the unit ball in the d-dimensional complex\nvector space onto the Bloch space of the unit ball. This paper deals with the\nvarious semi-norms of the Bergman projection. We improve some recent results.\n", "contributors": [{"name": "Markovic, Marijan", "sameAs": [], "familyName": "Markovic", "additionalName": "", "givenName": "Marijan", "email": ""}], "title": "Semi-norms of the Bergman projection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-19", "2015-04-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.4688", "oai:arXiv.org:1402.4688"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  It is known that the Bergman projection operator maps the space of\nessentially bounded functions in the unit ball in the d-dimensional complex\nvector space onto the Bloch space of the unit ball. This paper deals with the\nvarious semi-norms of the Bergman projection. We improve some recent results.\n", "Comment: to appear in Computational Methods and Function Theory"]}}], "languages": [null], "subjects": ["mathematics - complex variables"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.4688"}}, {"publisher": {"name": ""}, "description": "  We prove that rational and 1-rational singularities of complex spaces are\nstable under taking quotients by holomorphic actions of reductive and compact\nLie groups. This extends a result of Boutot to the analytic category and yields\na refinement of his result in the algebraic category. As one of the main\ntechnical tools vanishing theorems for cohomology groups with support on fibres\nof resolutions are proven.\n", "contributors": [{"name": "Greb, Daniel", "sameAs": [], "familyName": "Greb", "additionalName": "", "givenName": "Daniel", "email": ""}], "title": "Rational singularities and quotients by holomorphic group actions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2009-06-25", "2010-04-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/0906.4623", "Ann. Scuola Norm. Sup. Pisa Cl. Sci. (5), Vol. X, issue 2 (2011),\n  413-426", "doi:10.2422/2036-2145.2011.2.07", "oai:arXiv.org:0906.4623"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We prove that rational and 1-rational singularities of complex spaces are\nstable under taking quotients by holomorphic actions of reductive and compact\nLie groups. This extends a result of Boutot to the analytic category and yields\na refinement of his result in the algebraic category. As one of the main\ntechnical tools vanishing theorems for cohomology groups with support on fibres\nof resolutions are proven.\n", "Comment: 13 pages; typos corrected, references added and updated; to appear in\n  Annali della Scuola Normale Superiore, Classe di Scienze."]}}], "languages": [null], "subjects": ["32s05", "32m05", "32c36", "mathematics - complex variables", "mathematics - algebraic geometry", "14l30"], "providerUpdatedDateTime": "2015-04-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/0906.4623"}}, {"publisher": {"name": ""}, "description": "  Marx and Strohh\\\"acker showed around in 1933 that $f(z)/z$ is subordinate to\n$1/(1-z)$ for a normalized convex function $f$ on the unit disk $|z|<1.$\nBrickman, Hallenbeck, MacGregor and Wilken proved in 1973 further that $f(z)/z$\nis subordinate to $k_\\alpha(z)/z$ if $f$ is convex of order $\\alpha$ for\n$1/2\\le\\alpha<1$ and conjectured that this is true also for $0<\\alpha<1/2.$\nHere, $k_\\alpha$ is the standard extremal function in the class of normalized\nconvex functions of order $\\alpha$ and $k_0(z)=z/(1-z).$ We prove the\nconjecture and study geometric properties of convex functions of order\n$\\alpha.$ In particular, we prove that $(f+g)/2$ is starlike whenever $f$ and\n$g$ both are convex of order $3/5.$\n", "contributors": [{"name": "Sugawa, Toshiyuki", "sameAs": [], "familyName": "Sugawa", "additionalName": "", "givenName": "Toshiyuki", "email": ""}, {"name": "Wang, Li-Mei", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Li-Mei", "email": ""}], "title": "Notes on convex functions of order $\\alpha$", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.05127", "oai:arXiv.org:1502.05127"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Marx and Strohh\\\"acker showed around in 1933 that $f(z)/z$ is subordinate to\n$1/(1-z)$ for a normalized convex function $f$ on the unit disk $|z|<1.$\nBrickman, Hallenbeck, MacGregor and Wilken proved in 1973 further that $f(z)/z$\nis subordinate to $k_\\alpha(z)/z$ if $f$ is convex of order $\\alpha$ for\n$1/2\\le\\alpha<1$ and conjectured that this is true also for $0<\\alpha<1/2.$\nHere, $k_\\alpha$ is the standard extremal function in the class of normalized\nconvex functions of order $\\alpha$ and $k_0(z)=z/(1-z).$ We prove the\nconjecture and study geometric properties of convex functions of order\n$\\alpha.$ In particular, we prove that $(f+g)/2$ is starlike whenever $f$ and\n$g$ both are convex of order $3/5.$\n", "Comment: 12 pages"]}}], "languages": [null], "subjects": ["secondary 30c75", "primary 30c45", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-02-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.05127"}}, {"publisher": {"name": ""}, "description": "  In this article, two closed and convex sets for blind deconvolution problem\nare proposed. Most blurring functions in microscopy are symmetric with respect\nto the origin. Therefore, they do not modify the phase of the Fourier transform\n(FT) of the original image. As a result blurred image and the original image\nhave the same FT phase. Therefore, the set of images with a prescribed FT phase\ncan be used as a constraint set in blind deconvolution problems. Another convex\nset that can be used during the image reconstruction process is the epigraph\nset of Total Variation (TV) function. This set does not need a prescribed upper\nbound on the total variation of the image. The upper bound is automatically\nadjusted according to the current image of the restoration process. Both of\nthese two closed and convex sets can be used as a part of any blind\ndeconvolution algorithm. Simulation examples are presented.\n", "contributors": [{"name": "Tofighi, Mohammad", "sameAs": [], "familyName": "Tofighi", "additionalName": "", "givenName": "Mohammad", "email": ""}, {"name": "Yorulmaz, Onur", "sameAs": [], "familyName": "Yorulmaz", "additionalName": "", "givenName": "Onur", "email": ""}, {"name": "Cetin, A. Enis", "sameAs": [], "familyName": "Cetin", "additionalName": "Enis", "givenName": "A.", "email": ""}], "title": "Phase and TV Based Convex Sets for Blind Deconvolution of Microscopic\n  Images", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04776", "oai:arXiv.org:1503.04776"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this article, two closed and convex sets for blind deconvolution problem\nare proposed. Most blurring functions in microscopy are symmetric with respect\nto the origin. Therefore, they do not modify the phase of the Fourier transform\n(FT) of the original image. As a result blurred image and the original image\nhave the same FT phase. Therefore, the set of images with a prescribed FT phase\ncan be used as a constraint set in blind deconvolution problems. Another convex\nset that can be used during the image reconstruction process is the epigraph\nset of Total Variation (TV) function. This set does not need a prescribed upper\nbound on the total variation of the image. The upper bound is automatically\nadjusted according to the current image of the restoration process. Both of\nthese two closed and convex sets can be used as a part of any blind\ndeconvolution algorithm. Simulation examples are presented.\n", "Comment: Submitted to IEEE Selected Topics in Signal Processing"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04776"}}, {"publisher": {"name": ""}, "description": "  The ordered weighted $\\ell_1$ norm (OWL) was recently proposed, with two\ndifferent motivations: its good statistical properties as a sparsity promoting\nregularizer; the fact that it generalizes the so-called {\\it octagonal\nshrinkage and clustering algorithm for regression} (OSCAR), which has the\nability to cluster/group regression variables that are highly correlated. This\npaper contains several contributions to the study and application of OWL\nregularization: the derivation of the atomic formulation of the OWL norm; the\nderivation of the dual of the OWL norm, based on its atomic formulation; a new\nand simpler derivation of the proximity operator of the OWL norm; an efficient\nscheme to compute the Euclidean projection onto an OWL ball; the instantiation\nof the conditional gradient (CG, also known as Frank-Wolfe) algorithm for\nlinear regression problems under OWL regularization; the instantiation of\naccelerated projected gradient algorithms for the same class of problems.\nFinally, a set of experiments give evidence that accelerated projected gradient\nalgorithms are considerably faster than CG, for the class of problems\nconsidered.\n", "contributors": [{"name": "Zeng, Xiangrong", "sameAs": [], "familyName": "Zeng", "additionalName": "", "givenName": "Xiangrong", "email": ""}, {"name": "Figueiredo, M\u00e1rio A. T.", "sameAs": [], "familyName": "Figueiredo", "additionalName": "A. T.", "givenName": "M\u00e1rio", "email": ""}], "title": "The Ordered Weighted $\\ell_1$ Norm: Atomic Formulation, Projections, and\n  Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-15", "2015-04-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.4271", "oai:arXiv.org:1409.4271"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The ordered weighted $\\ell_1$ norm (OWL) was recently proposed, with two\ndifferent motivations: its good statistical properties as a sparsity promoting\nregularizer; the fact that it generalizes the so-called {\\it octagonal\nshrinkage and clustering algorithm for regression} (OSCAR), which has the\nability to cluster/group regression variables that are highly correlated. This\npaper contains several contributions to the study and application of OWL\nregularization: the derivation of the atomic formulation of the OWL norm; the\nderivation of the dual of the OWL norm, based on its atomic formulation; a new\nand simpler derivation of the proximity operator of the OWL norm; an efficient\nscheme to compute the Euclidean projection onto an OWL ball; the instantiation\nof the conditional gradient (CG, also known as Frank-Wolfe) algorithm for\nlinear regression problems under OWL regularization; the instantiation of\naccelerated projected gradient algorithms for the same class of problems.\nFinally, a set of experiments give evidence that accelerated projected gradient\nalgorithms are considerably faster than CG, for the class of problems\nconsidered.\n", "Comment: 13 pages, 17 figures. The latest version of this paper was submitted\n  to a journal"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - information theory", "computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.4271"}}, {"publisher": {"name": ""}, "description": "  Relaying has been extensively studied during the last decades and has found\nnumerous applications in wireless communications. The simplest relaying method,\nnamely amplify and forward, has shown potential in MIMO multiple access\nsystems, when Gaussian fading channels are assumed for both hops. However, in\nsome cases ill conditioned channels may appear on the second hop. For example,\nthis impairment could affect cooperative BS systems with microwave link\nbackhauling, which involve strong line of sight channels with insufficient\nscattering. In this paper, we consider a large system analysis of such as model\nfocusing on both optimal joint decoding and joint MMSE filtering receivers.\nAnalytical methods based on free probability are presented for calculating the\nergodic throughput, the MMSE error and the average SINR. Furthermore, the\nperformance degradation of the system throughput is evaluated considering\nsecond hop impairments such as ill-conditioning and rank deficiency, while\nhigh- and low-SNR limits are calculated for the considered performance metrics.\nFinally, the cooperative BS system is compared to a conventional channel\nresource division strategy and suitable operating points are proposed.\n", "contributors": [{"name": "Chatzinotas, Symeon", "sameAs": [], "familyName": "Chatzinotas", "additionalName": "", "givenName": "Symeon", "email": ""}], "title": "Large System Analysis for Amplify & Forward SIMO Multiple Access Channel\n  with Ill-conditioned Second Hop", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1569", "oai:arXiv.org:1411.1569"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Relaying has been extensively studied during the last decades and has found\nnumerous applications in wireless communications. The simplest relaying method,\nnamely amplify and forward, has shown potential in MIMO multiple access\nsystems, when Gaussian fading channels are assumed for both hops. However, in\nsome cases ill conditioned channels may appear on the second hop. For example,\nthis impairment could affect cooperative BS systems with microwave link\nbackhauling, which involve strong line of sight channels with insufficient\nscattering. In this paper, we consider a large system analysis of such as model\nfocusing on both optimal joint decoding and joint MMSE filtering receivers.\nAnalytical methods based on free probability are presented for calculating the\nergodic throughput, the MMSE error and the average SINR. Furthermore, the\nperformance degradation of the system throughput is evaluated considering\nsecond hop impairments such as ill-conditioning and rank deficiency, while\nhigh- and low-SNR limits are calculated for the considered performance metrics.\nFinally, the cooperative BS system is compared to a conventional channel\nresource division strategy and suitable operating points are proposed.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1569"}}, {"publisher": {"name": ""}, "description": "  In wireless networks relay nodes can be used to assist the users'\ntransmissions to reach their destination. Work on relay cooperation, from a\nphysical layer perspective, has up to now yielded well-known results. This\npaper takes a different stance focusing on network-level cooperation. Extending\nprevious results for a single relay, we investigate here the benefits from the\ndeployment of a second one. We assume that the two relays do not generate\npackets of their own and the system employs random access to the medium; we\nfurther consider slotted time and that the users have saturated queues. We\nobtain analytical expressions for the arrival and service rates of the queues\nof the two relays and the stability conditions. We investigate a model of the\nsystem, in which the users are divided into clusters, each being served by one\nrelay, and show its advantages in terms of aggregate and throughput per user.\nWe quantify the above, analytically for the case of the collision channel and\nthrough simulations for the case of Multi-Packet Reception (MPR), and we\nprovide insight on when the deployment of a second relay in the system can\nyield significant advantages.\n", "contributors": [{"name": "Papadimitriou, Georgios", "sameAs": [], "familyName": "Papadimitriou", "additionalName": "", "givenName": "Georgios", "email": ""}, {"name": "Pappas, Nikolaos", "sameAs": [], "familyName": "Pappas", "additionalName": "", "givenName": "Nikolaos", "email": ""}, {"name": "Angelakis, Vangelis", "sameAs": [], "familyName": "Angelakis", "additionalName": "", "givenName": "Vangelis", "email": ""}, {"name": "Traganitis, Apostolos", "sameAs": [], "familyName": "Traganitis", "additionalName": "", "givenName": "Apostolos", "email": ""}], "title": "Network-Level Performance Evaluation of a Two-Relay Cooperative Random\n  Access Wireless System", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-23", "2014-12-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.5949", "oai:arXiv.org:1406.5949"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In wireless networks relay nodes can be used to assist the users'\ntransmissions to reach their destination. Work on relay cooperation, from a\nphysical layer perspective, has up to now yielded well-known results. This\npaper takes a different stance focusing on network-level cooperation. Extending\nprevious results for a single relay, we investigate here the benefits from the\ndeployment of a second one. We assume that the two relays do not generate\npackets of their own and the system employs random access to the medium; we\nfurther consider slotted time and that the users have saturated queues. We\nobtain analytical expressions for the arrival and service rates of the queues\nof the two relays and the stability conditions. We investigate a model of the\nsystem, in which the users are divided into clusters, each being served by one\nrelay, and show its advantages in terms of aggregate and throughput per user.\nWe quantify the above, analytically for the case of the collision channel and\nthrough simulations for the case of Multi-Packet Reception (MPR), and we\nprovide insight on when the deployment of a second relay in the system can\nyield significant advantages.\n", "Comment: Submitted for journal publication"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.5949"}}, {"publisher": {"name": ""}, "description": "  We consider apictorial edge-matching puzzles, in which the goal is to arrange\na collection of puzzle pieces with colored edges so that the colors match along\nthe edges of adjacent pieces. We devise an algebraic representation for this\nproblem and provide conditions under which it exactly characterizes a puzzle.\nUsing the new representation, we recast the combinatorial, discrete problem of\nsolving puzzles as a global, polynomial system of equations with continuous\nvariables. We further propose new algorithms for generating approximate\nsolutions to the continuous problem by solving a sequence of convex\nrelaxations.\n", "contributors": [{"name": "Kovalsky, Shahar Z.", "sameAs": [], "familyName": "Kovalsky", "additionalName": "Z.", "givenName": "Shahar", "email": ""}, {"name": "Glasner, Daniel", "sameAs": [], "familyName": "Glasner", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Basri, Ronen", "sameAs": [], "familyName": "Basri", "additionalName": "", "givenName": "Ronen", "email": ""}], "title": "A Global Approach for Solving Edge-Matching Puzzles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-21", "2015-02-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.5957", "oai:arXiv.org:1409.5957"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We consider apictorial edge-matching puzzles, in which the goal is to arrange\na collection of puzzle pieces with colored edges so that the colors match along\nthe edges of adjacent pieces. We devise an algebraic representation for this\nproblem and provide conditions under which it exactly characterizes a puzzle.\nUsing the new representation, we recast the combinatorial, discrete problem of\nsolving puzzles as a global, polynomial system of equations with continuous\nvariables. We further propose new algorithms for generating approximate\nsolutions to the continuous problem by solving a sequence of convex\nrelaxations.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.5957"}}, {"publisher": {"name": ""}, "description": "  The least-mean-squares (LMS) algorithm is the most popular algorithm in\nadaptive filtering. Several variable step-size strategies have been suggested\nto improve the performance of the LMS algorithm. These strategies enhance the\nperformance of the algorithm but a major drawback is the complexity in the\ntheoretical analysis of the resultant algorithms. Researchers use several\nassumptions to find closed-form analytical solutions. This work presents a\nunified approach for the analysis of variable step-size LMS algorithms. The\napproach is then applied to several variable step-size strategies and\ntheoretical and simulation results are compared.\n", "contributors": [{"name": "Saeed, Muhammad Omer Bin", "sameAs": [], "familyName": "Saeed", "additionalName": "Omer Bin", "givenName": "Muhammad", "email": ""}], "title": "A Unified Analysis Approach for LMS-based Variable Step-Size Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.02487", "oai:arXiv.org:1501.02487"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The least-mean-squares (LMS) algorithm is the most popular algorithm in\nadaptive filtering. Several variable step-size strategies have been suggested\nto improve the performance of the LMS algorithm. These strategies enhance the\nperformance of the algorithm but a major drawback is the complexity in the\ntheoretical analysis of the resultant algorithms. Researchers use several\nassumptions to find closed-form analytical solutions. This work presents a\nunified approach for the analysis of variable step-size LMS algorithms. The\napproach is then applied to several variable step-size strategies and\ntheoretical and simulation results are compared.\n", "Comment: 5 pages, 1 figure, 5 tables"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-01-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.02487"}}, {"publisher": {"name": ""}, "description": "  With increasing use of digital control it is natural to view control inputs\nand outputs as stochastic processes assuming values over finite alphabets\nrather than in a Euclidean space. As control over networks becomes increasingly\ncommon, data compression by reducing the size of the input and output alphabets\nwithout losing the fidelity of representation becomes relevant. This requires\nus to define a notion of distance between two stochastic processes assuming\nvalues in distinct sets, possibly of different cardinalities. If the two\nprocesses are i.i.d., then the problem becomes one of defining a metric between\ntwo probability distributions over distinct finite sets of possibly different\ncardinalities. This is the problem addressed in the present paper. A metric is\ndefined in terms of a joint distribution on the product of the two sets, which\nhas the two given distributions as its marginals, and has minimum entropy.\nComputing the metric exactly turns out to be NP-hard. Therefore an efficient\ngreedy algorithm is presented for finding an upper bound on the distance. This\nproblem also turns out to be NP-hard, so again a greedy algorithm is\nconstructed for finding a suboptimal reduced order approximation. Taken\ntogether, all the results presented here permit the approximation of an i.i.d.\nprocess over a set of large cardinality by another i.i.d. process over a set of\nsmaller cardinality. In future work, attempts will be made to extend this work\nto Markov processes over finite sets.\n", "contributors": [{"name": "Vidyasagar, Mathukumalli", "sameAs": [], "familyName": "Vidyasagar", "additionalName": "", "givenName": "Mathukumalli", "email": ""}], "title": "A Metric Between Probability Distributions on Finite Sets of Different\n  Cardinalities and Applications to Order Reduction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-22", "2011-09-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.4521", "oai:arXiv.org:1104.4521"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  With increasing use of digital control it is natural to view control inputs\nand outputs as stochastic processes assuming values over finite alphabets\nrather than in a Euclidean space. As control over networks becomes increasingly\ncommon, data compression by reducing the size of the input and output alphabets\nwithout losing the fidelity of representation becomes relevant. This requires\nus to define a notion of distance between two stochastic processes assuming\nvalues in distinct sets, possibly of different cardinalities. If the two\nprocesses are i.i.d., then the problem becomes one of defining a metric between\ntwo probability distributions over distinct finite sets of possibly different\ncardinalities. This is the problem addressed in the present paper. A metric is\ndefined in terms of a joint distribution on the product of the two sets, which\nhas the two given distributions as its marginals, and has minimum entropy.\nComputing the metric exactly turns out to be NP-hard. Therefore an efficient\ngreedy algorithm is presented for finding an upper bound on the distance. This\nproblem also turns out to be NP-hard, so again a greedy algorithm is\nconstructed for finding a suboptimal reduced order approximation. Taken\ntogether, all the results presented here permit the approximation of an i.i.d.\nprocess over a set of large cardinality by another i.i.d. process over a set of\nsmaller cardinality. In future work, attempts will be made to extend this work\nto Markov processes over finite sets.\n", "Comment: 32 pages, no figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "computer science - information theory", "93e99"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.4521"}}, {"publisher": {"name": ""}, "description": "  This paper was originally designed as a literature review for a doctoral\ndissertation focusing on Wikipedia. This exposition gives the structure of\nWikipedia and the latest trends in Wikipedia research.\n", "contributors": [{"name": "Martin, Owen S.", "sameAs": [], "familyName": "Martin", "additionalName": "S.", "givenName": "Owen", "email": ""}], "title": "A Wikipedia Literature Review", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-10-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1110.5863", "oai:arXiv.org:1110.5863"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper was originally designed as a literature review for a doctoral\ndissertation focusing on Wikipedia. This exposition gives the structure of\nWikipedia and the latest trends in Wikipedia research.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - digital libraries"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1110.5863"}}, {"publisher": {"name": ""}, "description": "  In this work we study on a 2-dimensional square lattice a recent version of\nthe Naming Game, an agent-based model used for describing the emergence of\nlinguistic structures. The system is open-ended and agents can invent new words\nall along the evolution of the game, picking them up from a pool characterised\nby a Gaussian distribution with standard deviation $\\sigma$. The model displays\na nonequilibrium phase transition at a critical point $\\sigma_{c}\\approx 25.6$,\nwhich separates an absorbing consensus state from an active fragmented state\nwhere agents continuously exchange different words. The finite-size scaling\nanalysis of our simulations strongly suggests that the phase transition is\ndiscontinuous.\n", "contributors": [{"name": "Crokidakis, Nuno", "sameAs": [], "familyName": "Crokidakis", "additionalName": "", "givenName": "Nuno", "email": ""}, {"name": "Brigatti, Edgardo", "sameAs": [], "familyName": "Brigatti", "additionalName": "", "givenName": "Edgardo", "email": ""}], "title": "Discontinuous phase transition in an open-ended Naming Game", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2994", "J. Stat. Mech. P01019 (2015)", "doi:10.1088/1742-5468/2015/01/P01019", "oai:arXiv.org:1412.2994"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  In this work we study on a 2-dimensional square lattice a recent version of\nthe Naming Game, an agent-based model used for describing the emergence of\nlinguistic structures. The system is open-ended and agents can invent new words\nall along the evolution of the game, picking them up from a pool characterised\nby a Gaussian distribution with standard deviation $\\sigma$. The model displays\na nonequilibrium phase transition at a critical point $\\sigma_{c}\\approx 25.6$,\nwhich separates an absorbing consensus state from an active fragmented state\nwhere agents continuously exchange different words. The finite-size scaling\nanalysis of our simulations strongly suggests that the phase transition is\ndiscontinuous.\n", "Comment: 13 pages, 6 figures, to appear in JSTAT"]}}], "languages": [null], "subjects": ["physics - physics and society", "condensed matter - statistical mechanics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2994"}}, {"publisher": {"name": ""}, "description": "  Generally, social network analysis has often focused on the topology of the\nnetwork without considering the characteristics of individuals involved in\nthem. Less attention is given to study the behavior of individuals, considering\nthey are the basic entity of a graph. Given a mobile social network graph, what\nare good features to extract key information from the nodes?How many distinct\nneighborhood patterns exist for ego nodes? What clues does such information\nprovide to study nodes over a long period of time?\n  In this report, we develop an automated system in order to discover the\noccurrences of prototypical ego-centric patterns from data. We aim to provide a\ndata-driven instrument to be used in behavioral sciences for graph\ninterpretations. We analyze social networks derived from real-world data\ncollected with smart-phones. We select 13 well-known network measures,\nespecially those concerned with ego graphs. We form eight feature subsets and\nthen assess their performance using unsupervised clustering techniques to\ndiscover distinguishing ego-centric patterns. From clustering analysis, we\ndiscover that eight distinct neighborhood patterns have emerged. This\ncategorization allows concise analysis of users' data as they change over time.\nThe results provide a fine-grained analysis for the contribution of different\nfeature sets to detect unique clustering patterns. Last, as a case study, two\ndatasets are studied over long periods to demonstrate the utility of this\nmethod. The study shows the effectiveness of the proposed approach in\ndiscovering important trends from data.\n", "contributors": [{"name": "Muhammad, Syed Agha", "sameAs": [], "familyName": "Muhammad", "additionalName": "Agha", "givenName": "Syed", "email": ""}, {"name": "Van Laerhoven, Kristof", "sameAs": [], "familyName": "Van Laerhoven", "additionalName": "", "givenName": "Kristof", "email": ""}], "title": "An Automated System for Discovering Neighborhood Patterns in Ego\n  Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04877", "oai:arXiv.org:1503.04877"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Generally, social network analysis has often focused on the topology of the\nnetwork without considering the characteristics of individuals involved in\nthem. Less attention is given to study the behavior of individuals, considering\nthey are the basic entity of a graph. Given a mobile social network graph, what\nare good features to extract key information from the nodes?How many distinct\nneighborhood patterns exist for ego nodes? What clues does such information\nprovide to study nodes over a long period of time?\n  In this report, we develop an automated system in order to discover the\noccurrences of prototypical ego-centric patterns from data. We aim to provide a\ndata-driven instrument to be used in behavioral sciences for graph\ninterpretations. We analyze social networks derived from real-world data\ncollected with smart-phones. We select 13 well-known network measures,\nespecially those concerned with ego graphs. We form eight feature subsets and\nthen assess their performance using unsupervised clustering techniques to\ndiscover distinguishing ego-centric patterns. From clustering analysis, we\ndiscover that eight distinct neighborhood patterns have emerged. This\ncategorization allows concise analysis of users' data as they change over time.\nThe results provide a fine-grained analysis for the contribution of different\nfeature sets to detect unique clustering patterns. Last, as a case study, two\ndatasets are studied over long periods to demonstrate the utility of this\nmethod. The study shows the effectiveness of the proposed approach in\ndiscovering important trends from data.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04877"}}, {"publisher": {"name": ""}, "description": "  When delegating computation to a service provider, as in cloud computing, we\nseek some reassurance that the output is correct and complete. Yet recomputing\nthe output as a check is inefficient and expensive, and it may not even be\nfeasible to store all the data locally. We are therefore interested in proof\nsystems which allow a service provider to prove the correctness of its output\nto a streaming (sublinear space) user, who cannot store the full input or\nperform the full computation herself.\n  Our approach is two-fold. First, we describe a carefully chosen instantiation\nof one of the most efficient general-purpose constructions for arbitrary\ncomputations (streaming or otherwise), due to Goldwasser, Kalai, and Rothblum.\nThis requires several new insights to make the methodology more practical. Our\nmain contribution is in achieving a prover who runs in time O(S(n) log S(n)),\nwhere S(n) is the size of an arithmetic circuit computing the function of\ninterest. Our experimental results demonstrate that a practical general-purpose\nprotocol for verifiable computation may be significantly closer to reality than\npreviously realized.\n  Second, we describe techniques that achieve genuine scalability for protocols\nfine-tuned for specific important problems in streaming and database\nprocessing. Focusing in particular on non-interactive protocols for problems\nranging from matrix-vector multiplication to bipartite perfect matching, we\nbuild on prior work to achieve a prover who runs in nearly linear-time, while\nobtaining optimal tradeoffs between communication cost and the user's working\nmemory. Existing techniques required (substantially) superlinear time for the\nprover. We argue that even if general-purpose methods improve, fine-tuned\nprotocols will remain valuable in real-world settings for key problems, and\nhence special attention to specific problems is warranted.\n", "contributors": [{"name": "Cormode, Graham", "sameAs": [], "familyName": "Cormode", "additionalName": "", "givenName": "Graham", "email": ""}, {"name": "Mitzenmacher, Michael", "sameAs": [], "familyName": "Mitzenmacher", "additionalName": "", "givenName": "Michael", "email": ""}, {"name": "Thaler, Justin", "sameAs": [], "familyName": "Thaler", "additionalName": "", "givenName": "Justin", "email": ""}], "title": "Practical Verified Computation with Streaming Interactive Proofs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-05-10", "2012-02-12"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.2003", "oai:arXiv.org:1105.2003"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  When delegating computation to a service provider, as in cloud computing, we\nseek some reassurance that the output is correct and complete. Yet recomputing\nthe output as a check is inefficient and expensive, and it may not even be\nfeasible to store all the data locally. We are therefore interested in proof\nsystems which allow a service provider to prove the correctness of its output\nto a streaming (sublinear space) user, who cannot store the full input or\nperform the full computation herself.\n  Our approach is two-fold. First, we describe a carefully chosen instantiation\nof one of the most efficient general-purpose constructions for arbitrary\ncomputations (streaming or otherwise), due to Goldwasser, Kalai, and Rothblum.\nThis requires several new insights to make the methodology more practical. Our\nmain contribution is in achieving a prover who runs in time O(S(n) log S(n)),\nwhere S(n) is the size of an arithmetic circuit computing the function of\ninterest. Our experimental results demonstrate that a practical general-purpose\nprotocol for verifiable computation may be significantly closer to reality than\npreviously realized.\n  Second, we describe techniques that achieve genuine scalability for protocols\nfine-tuned for specific important problems in streaming and database\nprocessing. Focusing in particular on non-interactive protocols for problems\nranging from matrix-vector multiplication to bipartite perfect matching, we\nbuild on prior work to achieve a prover who runs in nearly linear-time, while\nobtaining optimal tradeoffs between communication cost and the user's working\nmemory. Existing techniques required (substantially) superlinear time for the\nprover. We argue that even if general-purpose methods improve, fine-tuned\nprotocols will remain valuable in real-world settings for key problems, and\nhence special attention to specific problems is warranted.\n", "Comment: 39 pages, 12 figures, 2 tables. Accepted to ITCS 2012"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity", "computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.2003"}}, {"publisher": {"name": ""}, "description": "  The development of technologies of multimedia, linked to that of Internet and\ndemocratization of high outflow, has made henceforth E-learning possible for\nlearners being in virtual classes and geographically distributed. The quality\nand quantity of asynchronous and synchronous communications are the key\nelements for E-learning success. It is important to have a propitious\nsupervision to reduce the feeling of isolation in E-learning. This feeling of\nisolation is among the main causes of loss and high rates of stalling in\nE-learning. The researches to be conducted in this domain aim to bring\nsolutions of convergence coming from real time image for the capture and\nrecognition of hand gestures. These gestures will be analyzed by the system and\ntransformed as indicator of participation. This latter is displayed in the\ntable of performance of the tutor as a curve according to the time. In case of\nisolation of learner, the indicator of participation will become red and the\ntutor will be informed of learners with difficulties to participate during\nlearning session.\n", "contributors": [{"name": "Mourad, Bousaaid", "sameAs": [], "familyName": "Mourad", "additionalName": "", "givenName": "Bousaaid", "email": ""}, {"name": "Tarik, Ayaou", "sameAs": [], "familyName": "Tarik", "additionalName": "", "givenName": "Ayaou", "email": ""}, {"name": "Karim, Afdel", "sameAs": [], "familyName": "Karim", "additionalName": "", "givenName": "Afdel", "email": ""}, {"name": "Pascal, Estraillier", "sameAs": [], "familyName": "Pascal", "additionalName": "", "givenName": "Estraillier", "email": ""}], "title": "Real-Time System of Hand Detection And Gesture Recognition In Cyber\n  Presence Interactive System For E-Learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07243", "Journal of Engineering Research and Applications Vol. 4, Issue 9\n  (Version 1), September 2014, pp.1-5", "oai:arXiv.org:1502.07243"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The development of technologies of multimedia, linked to that of Internet and\ndemocratization of high outflow, has made henceforth E-learning possible for\nlearners being in virtual classes and geographically distributed. The quality\nand quantity of asynchronous and synchronous communications are the key\nelements for E-learning success. It is important to have a propitious\nsupervision to reduce the feeling of isolation in E-learning. This feeling of\nisolation is among the main causes of loss and high rates of stalling in\nE-learning. The researches to be conducted in this domain aim to bring\nsolutions of convergence coming from real time image for the capture and\nrecognition of hand gestures. These gestures will be analyzed by the system and\ntransformed as indicator of participation. This latter is displayed in the\ntable of performance of the tutor as a curve according to the time. In case of\nisolation of learner, the indicator of participation will become red and the\ntutor will be informed of learners with difficulties to participate during\nlearning session.\n", "Comment: 5 pages. arXiv admin note: substantial text overlap with\n  arXiv:1502.06641"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07243"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Our interactions with cities are increasingly mediated through a complex array of technologies, including location-aware mobile devices and a vast number of online platforms. However, we often also use these tools to create content about the places that we live in and travel through. My thesis examines what I define as \"place-based media,\" that is, user-generated content produced about place. This content - photos of street life, overheard quotes, and local reviews, for example - emerges out of daily routines, and has a reciprocal relationship with the urban environment, both contributing to, as well as reflecting the life of the city. In this thesis, I aim to explore the relationship between the technologies and practices involved in the production of place-based media. In my approach, I situate place-based media within relevant historical precedents, such as street photography. In addition, I examine content produced about a single neighborhood, Central Square, Cambridge, in order to better understand the social and affective qualities of content that is created in dialogue with place. Ultimately, this project examines the production of place-based media as an everyday urban practice, with an eye towards the potential implications these media could have for contemporary cities and city neighborhoods.", "contributors": [{"name": "Boghani, Amar K. (Amar Kapadia)", "sameAs": [], "familyName": "Boghani", "additionalName": "K.", "givenName": "Amar", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Comparative Media Studies.", "sameAs": [], "familyName": "Studies.", "additionalName": "Institute of Technology. Department of Comparative Media", "givenName": "Massachusetts", "email": ""}, {"name": "William Charles Uricchio.", "sameAs": [], "familyName": "Uricchio.", "additionalName": "Charles", "givenName": "William", "email": ""}], "title": "The city expressed : everyday media production and the urban environment", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "192 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/81077", "857829777", "oai:dspace.mit.edu:1721.1/81077"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2013-09-24T19:41:21Z", "2013-09-24T19:41:21Z", "2013", "2013"]}}, {"name": "description", "properties": {"description": ["Our interactions with cities are increasingly mediated through a complex array of technologies, including location-aware mobile devices and a vast number of online platforms. However, we often also use these tools to create content about the places that we live in and travel through. My thesis examines what I define as \"place-based media,\" that is, user-generated content produced about place. This content - photos of street life, overheard quotes, and local reviews, for example - emerges out of daily routines, and has a reciprocal relationship with the urban environment, both contributing to, as well as reflecting the life of the city. In this thesis, I aim to explore the relationship between the technologies and practices involved in the production of place-based media. In my approach, I situate place-based media within relevant historical precedents, such as street photography. In addition, I examine content produced about a single neighborhood, Central Square, Cambridge, in order to better understand the social and affective qualities of content that is created in dialogue with place. Ultimately, this project examines the production of place-based media as an everyday urban practice, with an eye towards the potential implications these media could have for contemporary cities and city neighborhoods.", "by Amar K. Boghani.", "Thesis (S.M.)--Massachusetts Institute of Technology, Dept. of Comparative Media Studies, 2013.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (p. 111-115)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39100", "hdl_1721.1_39097"]}}], "languages": [null], "subjects": ["comparative media studies."], "providerUpdatedDateTime": "2015-04-27T14:44:38", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/81077"}}, {"publisher": {"name": ""}, "description": "  We study the relations between a contract automata and an interaction model.\nIn the former model, distributed services are abstracted away as automata -\noblivious of their partners - that coordinate with each other through an\norchestrator. The interaction model relies on channel-based asynchronous\ncommunication and choreography to coordinate distributed services.\n  We define a notion of strong agreement on the contract model, exhibit a\nnatural mapping from the contract model to the interaction model, and give\nconditions to ensure that strong agreement corresponds to well-formed\nchoreography.\n", "contributors": [{"name": "Basile, Davide", "sameAs": [], "familyName": "Basile", "additionalName": "", "givenName": "Davide", "email": ""}, {"name": "Degano, Pierpaolo", "sameAs": [], "familyName": "Degano", "additionalName": "", "givenName": "Pierpaolo", "email": ""}, {"name": "Ferrari, Gian-Luigi", "sameAs": [], "familyName": "Ferrari", "additionalName": "", "givenName": "Gian-Luigi", "email": ""}, {"name": "Tuosto, Emilio", "sameAs": [], "familyName": "Tuosto", "additionalName": "", "givenName": "Emilio", "email": ""}], "title": "From Orchestration to Choreography through Contract Automata", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.7471", "EPTCS 166, 2014, pp. 67-85", "doi:10.4204/EPTCS.166.8", "oai:arXiv.org:1410.7471"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study the relations between a contract automata and an interaction model.\nIn the former model, distributed services are abstracted away as automata -\noblivious of their partners - that coordinate with each other through an\norchestrator. The interaction model relies on channel-based asynchronous\ncommunication and choreography to coordinate distributed services.\n  We define a notion of strong agreement on the contract model, exhibit a\nnatural mapping from the contract model to the interaction model, and give\nconditions to ensure that strong agreement corresponds to well-formed\nchoreography.\n", "Comment: In Proceedings ICE 2014, arXiv:1410.7013"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "computer science - logic in computer science"], "providerUpdatedDateTime": "2014-10-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.7471"}}, {"publisher": {"name": ""}, "description": "  Finding chordless cycles is an important theoretical problem in the Graph\nTheory area. It also can be applied to practical problems such as discover\nwhich predators compete for the same food in ecological networks. Motivated by\nthe problem of theoretical interest and also by its significant practical\nimportance, we present in this paper a parallel algorithm for enumerating all\nthe chordless cycles in undirected graphs, which was implemented in OpenCL.\n", "contributors": [{"name": "Dias, Elis\u00e2ngela Silva", "sameAs": [], "familyName": "Dias", "additionalName": "Silva", "givenName": "Elis\u00e2ngela", "email": ""}, {"name": "Castonguay, Diane", "sameAs": [], "familyName": "Castonguay", "additionalName": "", "givenName": "Diane", "email": ""}, {"name": "Longo, Humberto", "sameAs": [], "familyName": "Longo", "additionalName": "", "givenName": "Humberto", "email": ""}, {"name": "Jradi, Walid Abdala Rfaei", "sameAs": [], "familyName": "Jradi", "additionalName": "Abdala Rfaei", "givenName": "Walid", "email": ""}, {"name": "Nascimento, Hugo A. D. do", "sameAs": [], "familyName": "Nascimento", "additionalName": "A. D.", "givenName": "Hugo", "email": ""}], "title": "Fast Parallel Algorithm for Enumerating All Chordless Cycles in Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4876", "oai:arXiv.org:1410.4876"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Finding chordless cycles is an important theoretical problem in the Graph\nTheory area. It also can be applied to practical problems such as discover\nwhich predators compete for the same food in ecological networks. Motivated by\nthe problem of theoretical interest and also by its significant practical\nimportance, we present in this paper a parallel algorithm for enumerating all\nthe chordless cycles in undirected graphs, which was implemented in OpenCL.\n", "Comment: 9 pages"]}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-10-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4876"}}, {"publisher": {"name": ""}, "description": "  In this paper we study the consistency of an empirical minimum error entropy\n(MEE) algorithm in a regression setting. We introduce two types of consistency.\nThe error entropy consistency, which requires the error entropy of the learned\nfunction to approximate the minimum error entropy, is shown to be always true\nif the bandwidth parameter tends to 0 at an appropriate rate. The regression\nconsistency, which requires the learned function to approximate the regression\nfunction, however, is a complicated issue. We prove that the error entropy\nconsistency implies the regression consistency for homoskedastic models where\nthe noise is independent of the input variable. But for heteroskedastic models,\na counterexample is used to show that the two types of consistency do not\ncoincide. A surprising result is that the regression consistency is always\ntrue, provided that the bandwidth parameter tends to infinity at an appropriate\nrate. Regression consistency of two classes of special models is shown to hold\nwith fixed bandwidth parameter, which further illustrates the complexity of\nregression consistency of MEE. Fourier transform plays crucial roles in our\nanalysis.\n", "contributors": [{"name": "Fan, Jun", "sameAs": [], "familyName": "Fan", "additionalName": "", "givenName": "Jun", "email": ""}, {"name": "Hu, Ting", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Ting", "email": ""}, {"name": "Wu, Qiang", "sameAs": [], "familyName": "Wu", "additionalName": "", "givenName": "Qiang", "email": ""}, {"name": "Zhou, Ding-Xuan", "sameAs": [], "familyName": "Zhou", "additionalName": "", "givenName": "Ding-Xuan", "email": ""}], "title": "Consistency Analysis of an Empirical Minimum Error Entropy Algorithm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5272", "oai:arXiv.org:1412.5272"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  In this paper we study the consistency of an empirical minimum error entropy\n(MEE) algorithm in a regression setting. We introduce two types of consistency.\nThe error entropy consistency, which requires the error entropy of the learned\nfunction to approximate the minimum error entropy, is shown to be always true\nif the bandwidth parameter tends to 0 at an appropriate rate. The regression\nconsistency, which requires the learned function to approximate the regression\nfunction, however, is a complicated issue. We prove that the error entropy\nconsistency implies the regression consistency for homoskedastic models where\nthe noise is independent of the input variable. But for heteroskedastic models,\na counterexample is used to show that the two types of consistency do not\ncoincide. A surprising result is that the regression consistency is always\ntrue, provided that the bandwidth parameter tends to infinity at an appropriate\nrate. Regression consistency of two classes of special models is shown to hold\nwith fixed bandwidth parameter, which further illustrates the complexity of\nregression consistency of MEE. Fourier transform plays crucial roles in our\nanalysis.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-12-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5272"}}, {"publisher": {"name": ""}, "description": "  Two proper polynomial maps $f_1, \\,f_2 \\colon \\mC^n \\lr \\mC^n$ are said to be\n\\emph{equivalent} if there exist $\\Phi_1,\\, \\Phi_2 \\in \\textrm{Aut}(\\mC^n)$\nsuch that $f_2=\\Phi_2 \\circ f_1 \\circ \\Phi_1$. In this article we investigate\nproper polynomial maps of topological degree $d \\geq 2$ up to equivalence. In\nparticular we describe some of our recent results in the case $n=2$ and we\npartially extend them in higher dimension.\n", "contributors": [{"name": "Bisi, Cinzia", "sameAs": [], "familyName": "Bisi", "additionalName": "", "givenName": "Cinzia", "email": ""}, {"name": "Polizzi, Francesco", "sameAs": [], "familyName": "Polizzi", "additionalName": "", "givenName": "Francesco", "email": ""}], "title": "Proper polynomial self-maps of the affine space: state of the art and\n  new results", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-05-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.0078", "Contemporary Mathematics 553 (2011), 15-25", "oai:arXiv.org:1005.0078"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Two proper polynomial maps $f_1, \\,f_2 \\colon \\mC^n \\lr \\mC^n$ are said to be\n\\emph{equivalent} if there exist $\\Phi_1,\\, \\Phi_2 \\in \\textrm{Aut}(\\mC^n)$\nsuch that $f_2=\\Phi_2 \\circ f_1 \\circ \\Phi_1$. In this article we investigate\nproper polynomial maps of topological degree $d \\geq 2$ up to equivalence. In\nparticular we describe some of our recent results in the case $n=2$ and we\npartially extend them in higher dimension.\n", "Comment: Final version, as to appear in Contemporary Mathematics, Proceedings\n  of Complex Analysis and Dynamical Systems IV, held in Nahariya, Israel, May\n  2009."]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "20h15", "secondary: 14e05", "primary: 14r10", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.0078"}}, {"publisher": {"name": ""}, "description": "  The reliable detection of speed of moving vehicles is considered key to\ntraffic law enforcement in most countries, and is seen by many as an important\ntool to reduce the number of traffic accidents and fatalities. Many automatic\nsystems and different methods are employed in different countries, but as a\nrule they tend to be expensive and/or labor intensive, often employing outdated\ntechnology due to the long development time. Here we describe a speed detection\nsystem that relies on simple everyday equipment - a laptop and a consumer web\ncamera. Our method is based on tracking the license plates of cars, which gives\nthe relative movement of the cars in the image. This image displacement is\ntranslated to actual motion by using the method of projection to a reference\nplane, where the reference plane is the road itself. However, since license\nplates do not touch the road, we must compensate for the entailed distortion in\nspeed measurement. We show how to compute the compensation factor using\nknowledge of the license plate standard dimensions. Consequently our system\ncomputes the true speed of moving vehicles fast and accurately. We show\npromising results on videos obtained in a number of scenes and with different\ncar models.\n", "contributors": [{"name": "Ginzburg, Chaim", "sameAs": [], "familyName": "Ginzburg", "additionalName": "", "givenName": "Chaim", "email": ""}, {"name": "Raphael, Amit", "sameAs": [], "familyName": "Raphael", "additionalName": "", "givenName": "Amit", "email": ""}, {"name": "Weinshall, Daphna", "sameAs": [], "familyName": "Weinshall", "additionalName": "", "givenName": "Daphna", "email": ""}], "title": "A Cheap System for Vehicle Speed Detection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06751", "oai:arXiv.org:1501.06751"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The reliable detection of speed of moving vehicles is considered key to\ntraffic law enforcement in most countries, and is seen by many as an important\ntool to reduce the number of traffic accidents and fatalities. Many automatic\nsystems and different methods are employed in different countries, but as a\nrule they tend to be expensive and/or labor intensive, often employing outdated\ntechnology due to the long development time. Here we describe a speed detection\nsystem that relies on simple everyday equipment - a laptop and a consumer web\ncamera. Our method is based on tracking the license plates of cars, which gives\nthe relative movement of the cars in the image. This image displacement is\ntranslated to actual motion by using the method of projection to a reference\nplane, where the reference plane is the road itself. However, since license\nplates do not touch the road, we must compensate for the entailed distortion in\nspeed measurement. We show how to compute the compensation factor using\nknowledge of the license plate standard dimensions. Consequently our system\ncomputes the true speed of moving vehicles fast and accurately. We show\npromising results on videos obtained in a number of scenes and with different\ncar models.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06751"}}, {"publisher": {"name": ""}, "description": "  Network reconciliation is the problem of identifying nodes in separate\nnetworks that represent the same entity, for example matching nodes across\nsocial networks that correspond to the same user. We introduce a technique to\ncompute probably approximately correct (PAC) bounds on precision and recall for\nnetwork reconciliation algorithms. The bounds require some verified matches,\nbut those matches may be used to develop the algorithms. The bounds do not\nrequire knowledge of the network generation process, and they can supply\nconfidence levels for individual matches.\n", "contributors": [{"name": "Le, Ya", "sameAs": [], "familyName": "Le", "additionalName": "", "givenName": "Ya", "email": ""}, {"name": "Bax, Eric", "sameAs": [], "familyName": "Bax", "additionalName": "", "givenName": "Eric", "email": ""}, {"name": "Barbieri, Nicola", "sameAs": [], "familyName": "Barbieri", "additionalName": "", "givenName": "Nicola", "email": ""}, {"name": "Soriano, David Garcia", "sameAs": [], "familyName": "Soriano", "additionalName": "Garcia", "givenName": "David", "email": ""}, {"name": "Mehta, Jitesh", "sameAs": [], "familyName": "Mehta", "additionalName": "", "givenName": "Jitesh", "email": ""}, {"name": "Li, James", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "James", "email": ""}], "title": "Validation of Network Reconciliation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0023", "oai:arXiv.org:1411.0023"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Network reconciliation is the problem of identifying nodes in separate\nnetworks that represent the same entity, for example matching nodes across\nsocial networks that correspond to the same user. We introduce a technique to\ncompute probably approximately correct (PAC) bounds on precision and recall for\nnetwork reconciliation algorithms. The bounds require some verified matches,\nbut those matches may be used to develop the algorithms. The bounds do not\nrequire knowledge of the network generation process, and they can supply\nconfidence levels for individual matches.\n", "Comment: Short version will be submitted to NIPS workshop on networks, 2014"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0023"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "In distributed ML applications, shared parameters are usually replicated among computing nodes to minimize network overhead. Therefore, proper consistency model must be carefully chosen to ensure algorithm's correctness and provide high throughput. Existing consistency models used in general-purpose databases and modern distributed ML systems are either too loose to guarantee correctness of the ML algorithms or too strict and thus fail to fully exploit the computing power of the underlying distributed system. Many ML algorithms fall into the category of \\emph{iterative convergent algorithms} which start from a randomly chosen initial point and converge to optima by repeating iteratively a set of procedures. We've found that many such algorithms are to a bounded amount of inconsistency and still converge correctly. This property allows distributed ML to relax strict consistency models to improve system performance while theoretically guarantees algorithmic correctness. In this paper, we present several relaxed consistency models for asynchronous parallel computation and theoretically prove their algorithmic correctness. The proposed consistency models are implemented in a distributed parameter server and evaluated in the context of a popular ML application: topic modeling.", "contributors": [{"name": "Wei, Jinliang", "sameAs": [], "familyName": "Wei", "additionalName": "", "givenName": "Jinliang", "email": ""}, {"name": "Dai, Wei", "sameAs": [], "familyName": "Dai", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Kumar, Abhimanu", "sameAs": [], "familyName": "Kumar", "additionalName": "", "givenName": "Abhimanu", "email": ""}, {"name": "Zheng, Xun", "sameAs": [], "familyName": "Zheng", "additionalName": "", "givenName": "Xun", "email": ""}, {"name": "Ho, Qirong", "sameAs": [], "familyName": "Ho", "additionalName": "", "givenName": "Qirong", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "Consistent Bounded-Asynchronous Parameter Servers for Distributed ML", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-01-02T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/140", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1139&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1139"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "In distributed ML applications, shared parameters are usually replicated among computing nodes to minimize network overhead. Therefore, proper consistency model must be carefully chosen to ensure algorithm's correctness and provide high throughput. Existing consistency models used in general-purpose databases and modern distributed ML systems are either too loose to guarantee correctness of the ML algorithms or too strict and thus fail to fully exploit the computing power of the underlying distributed system. Many ML algorithms fall into the category of \\emph{iterative convergent algorithms} which start from a randomly chosen initial point and converge to optima by repeating iteratively a set of procedures. We've found that many such algorithms are to a bounded amount of inconsistency and still converge correctly. This property allows distributed ML to relax strict consistency models to improve system performance while theoretically guarantees algorithmic correctness. In this paper, we present several relaxed consistency models for asynchronous parallel computation and theoretically prove their algorithmic correctness. The proposed consistency models are implemented in a distributed parameter server and evaluated in the context of a popular ML application: topic modeling."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-27T21:01:09", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/140"}}, {"publisher": {"name": ""}, "description": "  We propose the object-oriented networking (OON) framework, for meeting the\ngeneralized interconnection, mobility and technology integration requirements\nunderlining the Internet. In OON, the various objects that need to be accessed\nthrough the Internet (content, smart things, services, people, etc.) are viewed\nas network layer resources, rather than as application layer resources as in\nthe IP communications model. By abstracting them as computing objects -with\nattributes and methods- they are identified by expressive, discoverable names,\nwhile data are exchanged between them in the context of their methods, based on\nsuitably defined system-specific names. An OON-enabled Internet is not only a\nglobal data delivery medium but also a universal object discovery and service\ndevelopment platform; service-level interactions can be realized through native\nnetwork means, without requiring standardized protocols. OON can be realized\nthrough existing software-defined networking or network functions\nvirtualization technologies and it can be deployed in an incremental fashion.\n", "contributors": [{"name": "Georgatsos, Panos", "sameAs": [], "familyName": "Georgatsos", "additionalName": "", "givenName": "Panos", "email": ""}, {"name": "Flegkas, Paris", "sameAs": [], "familyName": "Flegkas", "additionalName": "", "givenName": "Paris", "email": ""}, {"name": "Sourlas, Vasilis", "sameAs": [], "familyName": "Sourlas", "additionalName": "", "givenName": "Vasilis", "email": ""}, {"name": "Tassiulas, Leandros", "sameAs": [], "familyName": "Tassiulas", "additionalName": "", "givenName": "Leandros", "email": ""}], "title": "Object-Oriented Networking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07495", "oai:arXiv.org:1502.07495"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We propose the object-oriented networking (OON) framework, for meeting the\ngeneralized interconnection, mobility and technology integration requirements\nunderlining the Internet. In OON, the various objects that need to be accessed\nthrough the Internet (content, smart things, services, people, etc.) are viewed\nas network layer resources, rather than as application layer resources as in\nthe IP communications model. By abstracting them as computing objects -with\nattributes and methods- they are identified by expressive, discoverable names,\nwhile data are exchanged between them in the context of their methods, based on\nsuitably defined system-specific names. An OON-enabled Internet is not only a\nglobal data delivery medium but also a universal object discovery and service\ndevelopment platform; service-level interactions can be realized through native\nnetwork means, without requiring standardized protocols. OON can be realized\nthrough existing software-defined networking or network functions\nvirtualization technologies and it can be deployed in an incremental fashion.\n", "Comment: 7 pages, 1 figure"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-02-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07495"}}, {"publisher": {"name": ""}, "description": "  We study the computational complexity of exact minimisation of separable\nrational-valued discrete functions. Let $\\Gamma$ be a set of rational-valued\nfunctions on a fixed finite domain; such a set is called a finite-valued\nconstraint language. The valued constraint satisfaction problem,\n$\\operatorname{VCSP}(\\Gamma)$, is the problem of minimising a function given as\na sum of functions from $\\Gamma$. We establish a dichotomy theorem with respect\nto exact solvability for all finite-valued constraint languages defined on\ndomains of arbitrary finite size.\n  We show that every constraint language $\\Gamma$ either admits a binary\nsymmetric fractional polymorphism in which case the basic linear programming\nrelaxation solves any instance of $\\operatorname{VCSP}(\\Gamma)$ exactly, or\n$\\Gamma$ satisfies a simple hardness condition that allows for a\npolynomial-time reduction from Max-Cut to $\\operatorname{VCSP}(\\Gamma)$.\n", "contributors": [{"name": "Thapper, Johan", "sameAs": [], "familyName": "Thapper", "additionalName": "", "givenName": "Johan", "email": ""}, {"name": "Zivny, Stanislav", "sameAs": [], "familyName": "Zivny", "additionalName": "", "givenName": "Stanislav", "email": ""}], "title": "The complexity of finite-valued CSPs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-10-10", "2015-02-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1210.2987", "oai:arXiv.org:1210.2987"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study the computational complexity of exact minimisation of separable\nrational-valued discrete functions. Let $\\Gamma$ be a set of rational-valued\nfunctions on a fixed finite domain; such a set is called a finite-valued\nconstraint language. The valued constraint satisfaction problem,\n$\\operatorname{VCSP}(\\Gamma)$, is the problem of minimising a function given as\na sum of functions from $\\Gamma$. We establish a dichotomy theorem with respect\nto exact solvability for all finite-valued constraint languages defined on\ndomains of arbitrary finite size.\n  We show that every constraint language $\\Gamma$ either admits a binary\nsymmetric fractional polymorphism in which case the basic linear programming\nrelaxation solves any instance of $\\operatorname{VCSP}(\\Gamma)$ exactly, or\n$\\Gamma$ satisfies a simple hardness condition that allows for a\npolynomial-time reduction from Max-Cut to $\\operatorname{VCSP}(\\Gamma)$.\n", "Comment: A full version of a STOC'13 paper, submitted for journal publication"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "f.2.0"], "providerUpdatedDateTime": "2015-02-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1210.2987"}}, {"publisher": {"name": ""}, "description": "  In 1986, Spencer Bloch gave an abstract definition of a (regulator) map from\nhigher Chow groups to Deligne-Beilinson cohomology. This map can be defined on\nthe underlying complexes, and Kerr, Lewis and M\\\"uller-Stach gave an explicit\ndescription of this map in terms of currents. Using a multiplicative version of\nthe Deligne complex, we give a commutative version of this map.\n", "contributors": [{"name": "Wei\u00dfschuh, Thomas", "sameAs": [], "familyName": "Wei\u00dfschuh", "additionalName": "", "givenName": "Thomas", "email": ""}], "title": "A commutative regulator map into Deligne-Beilinson cohomology", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4686", "oai:arXiv.org:1410.4686"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  In 1986, Spencer Bloch gave an abstract definition of a (regulator) map from\nhigher Chow groups to Deligne-Beilinson cohomology. This map can be defined on\nthe underlying complexes, and Kerr, Lewis and M\\\"uller-Stach gave an explicit\ndescription of this map in terms of currents. Using a multiplicative version of\nthe Deligne complex, we give a commutative version of this map.\n"}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-10-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4686"}}, {"publisher": {"name": ""}, "description": "  The Hilbert space of probability mass functions (pmf) is introduced in this\nthesis. A factorization method for multivariate pmfs is proposed by using the\ntools provided by the Hilbert space of pmfs. The resulting factorization is\nspecial for two reasons. First, it reveals the algebraic relations between the\ninvolved random variables. Second, it determines the conditional independence\nrelations between the random variables. Due to the first property of the\nresulting factorization, it can be shown that channel decoders can be employed\nin the solution of probabilistic inference problems other than decoding. This\napproach might lead to new probabilistic inference algorithms and new hardware\noptions for the implementation of these algorithms. An example of new inference\nalgorithms inspired by the idea of using channel decoder for other inference\ntasks is a multiple-input multiple-output (MIMO) detection algorithm which has\na complexity of the square-root of the optimum MIMO detection algorithm.\n", "contributors": [{"name": "Bayramoglu, Muhammet Fatih", "sameAs": [], "familyName": "Bayramoglu", "additionalName": "Fatih", "givenName": "Muhammet", "email": ""}], "title": "The Hilbert Space of Probability Mass Functions and Applications on\n  Probabilistic Inference", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02940", "oai:arXiv.org:1502.02940"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The Hilbert space of probability mass functions (pmf) is introduced in this\nthesis. A factorization method for multivariate pmfs is proposed by using the\ntools provided by the Hilbert space of pmfs. The resulting factorization is\nspecial for two reasons. First, it reveals the algebraic relations between the\ninvolved random variables. Second, it determines the conditional independence\nrelations between the random variables. Due to the first property of the\nresulting factorization, it can be shown that channel decoders can be employed\nin the solution of probabilistic inference problems other than decoding. This\napproach might lead to new probabilistic inference algorithms and new hardware\noptions for the implementation of these algorithms. An example of new inference\nalgorithms inspired by the idea of using channel decoder for other inference\ntasks is a multiple-input multiple-output (MIMO) detection algorithm which has\na complexity of the square-root of the optimum MIMO detection algorithm.\n", "Comment: PhD Dissertation, 123 pages"]}}], "languages": [null], "subjects": ["computer science - information theory", "mathematics - probability"], "providerUpdatedDateTime": "2015-02-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02940"}}, {"publisher": {"name": ""}, "description": "  We present a method of solving the T-optimal design problem for nonlinear\ndynamical systems using dynamic programming. In contrast with previous dynamic\nprogramming formulations, we avoid adding an equation for the dispersion to the\nsystem state, allowing for more efficient solutions.\n", "contributors": [{"name": "Maidens, John", "sameAs": [], "familyName": "Maidens", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Arcak, Murat", "sameAs": [], "familyName": "Arcak", "additionalName": "", "givenName": "Murat", "email": ""}], "title": "A note on optimal experiment design for nonlinear systems using dynamic\n  programming", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07232", "oai:arXiv.org:1503.07232"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We present a method of solving the T-optimal design problem for nonlinear\ndynamical systems using dynamic programming. In contrast with previous dynamic\nprogramming formulations, we avoid adding an equation for the dispersion to the\nsystem state, allowing for more efficient solutions.\n", "Comment: 4 pages, 1 figure"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control"], "providerUpdatedDateTime": "2015-03-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07232"}}, {"publisher": {"name": ""}, "description": "  Given a context free language $L(G)$ over alphabet $\\Sigma$ and a string $s\n\\in \\Sigma^*$, the language edit distance (Lan-ED) problem seeks the minimum\nnumber of edits (insertions, deletions and substitutions) required to convert\n$s$ into a valid member of $L(G)$. The well-known dynamic programming algorithm\nsolves this problem in $O(n^3)$ time (ignoring grammar size) where $n$ is the\nstring length [Aho, Peterson 1972, Myers 1985]. Despite its vast number of\napplications, there is no algorithm known till date that computes or\napproximates Lan-ED in true sub-cubic time.\n  In this paper we give the first such algorithm that computes Lan-ED almost\noptimally. For any arbitrary $\\epsilon > 0$, our algorithm runs in\n$\\tilde{O}(\\frac{n^{\\omega}}{poly(\\epsilon)})$ time and returns an estimate\nwithin a multiplicative approximation factor of $(1+\\epsilon)$, where $\\omega$\nis the exponent of ordinary matrix multiplication of $n$ dimensional square\nmatrices. It also computes the edit script. Further, for all substrings of $s$,\nwe can estimate their Lan-ED within $(1\\pm \\epsilon)$ factor in\n$\\tilde{O}(\\frac{n^{\\omega}}{poly(\\epsilon)})$ time with high probability. We\nalso design the very first sub-cubic ($\\tilde{O}(n^\\omega)$) algorithm to\nhandle arbitrary stochastic context free grammar (SCFG) parsing. SCFGs lie the\nfoundation of statistical natural language processing, they generalize hidden\nMarkov models, and have found widespread applications.\n  To complement our upper bound result, we show that exact computation of\nLan-ED in true sub-cubic time will imply a truly sub-cubic algorithm for\nall-pairs shortest paths. This will result in a breakthrough for a large range\nof problems in graphs and matrices due to sub-cubic equivalence. By a known\nlower bound result [Lee 2002], improving upon our time bound of $O(n^\\omega)$\nfor any nontrivial multiplicative approximation is (almost) not possible.\n", "contributors": [{"name": "Saha, Barna", "sameAs": [], "familyName": "Saha", "additionalName": "", "givenName": "Barna", "email": ""}], "title": "Faster Language Edit Distance, Connection to All-pairs Shortest Paths\n  and Related Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7315", "oai:arXiv.org:1411.7315"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Given a context free language $L(G)$ over alphabet $\\Sigma$ and a string $s\n\\in \\Sigma^*$, the language edit distance (Lan-ED) problem seeks the minimum\nnumber of edits (insertions, deletions and substitutions) required to convert\n$s$ into a valid member of $L(G)$. The well-known dynamic programming algorithm\nsolves this problem in $O(n^3)$ time (ignoring grammar size) where $n$ is the\nstring length [Aho, Peterson 1972, Myers 1985]. Despite its vast number of\napplications, there is no algorithm known till date that computes or\napproximates Lan-ED in true sub-cubic time.\n  In this paper we give the first such algorithm that computes Lan-ED almost\noptimally. For any arbitrary $\\epsilon > 0$, our algorithm runs in\n$\\tilde{O}(\\frac{n^{\\omega}}{poly(\\epsilon)})$ time and returns an estimate\nwithin a multiplicative approximation factor of $(1+\\epsilon)$, where $\\omega$\nis the exponent of ordinary matrix multiplication of $n$ dimensional square\nmatrices. It also computes the edit script. Further, for all substrings of $s$,\nwe can estimate their Lan-ED within $(1\\pm \\epsilon)$ factor in\n$\\tilde{O}(\\frac{n^{\\omega}}{poly(\\epsilon)})$ time with high probability. We\nalso design the very first sub-cubic ($\\tilde{O}(n^\\omega)$) algorithm to\nhandle arbitrary stochastic context free grammar (SCFG) parsing. SCFGs lie the\nfoundation of statistical natural language processing, they generalize hidden\nMarkov models, and have found widespread applications.\n  To complement our upper bound result, we show that exact computation of\nLan-ED in true sub-cubic time will imply a truly sub-cubic algorithm for\nall-pairs shortest paths. This will result in a breakthrough for a large range\nof problems in graphs and matrices due to sub-cubic equivalence. By a known\nlower bound result [Lee 2002], improving upon our time bound of $O(n^\\omega)$\nfor any nontrivial multiplicative approximation is (almost) not possible.\n", "Comment: 39 pages"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2014-11-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7315"}}, {"publisher": {"name": ""}, "description": "  In this contribution, we develop an accurate and effective event detection\nmethod to detect events from a Twitter stream, which uses visual and textual\ninformation to improve the performance of the mining process. The method\nmonitors a Twitter stream to pick up tweets having texts and images and stores\nthem into a database. This is followed by applying a mining algorithm to detect\nan event. The procedure starts with detecting events based on text only by\nusing the feature of the bag-of-words which is calculated using the term\nfrequency-inverse document frequency (TF-IDF) method. Then it detects the event\nbased on image only by using visual features including histogram of oriented\ngradients (HOG) descriptors, grey-level cooccurrence matrix (GLCM), and color\nhistogram. K nearest neighbours (Knn) classification is used in the detection.\nThe final decision of the event detection is made based on the reliabilities of\ntext only detection and image only detection. The experiment result showed that\nthe proposed method achieved high accuracy of 0.94, comparing with 0.89 with\ntexts only, and 0.86 with images only.\n", "contributors": [{"name": "Alqhtani, Samar M.", "sameAs": [], "familyName": "Alqhtani", "additionalName": "M.", "givenName": "Samar", "email": ""}, {"name": "Luo, Suhuai", "sameAs": [], "familyName": "Luo", "additionalName": "", "givenName": "Suhuai", "email": ""}, {"name": "Regan, Brian", "sameAs": [], "familyName": "Regan", "additionalName": "", "givenName": "Brian", "email": ""}], "title": "Fusing Text and Image for Event Detection in Twitter", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03920", "doi:10.5121/ijma.2015.7103", "oai:arXiv.org:1503.03920"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this contribution, we develop an accurate and effective event detection\nmethod to detect events from a Twitter stream, which uses visual and textual\ninformation to improve the performance of the mining process. The method\nmonitors a Twitter stream to pick up tweets having texts and images and stores\nthem into a database. This is followed by applying a mining algorithm to detect\nan event. The procedure starts with detecting events based on text only by\nusing the feature of the bag-of-words which is calculated using the term\nfrequency-inverse document frequency (TF-IDF) method. Then it detects the event\nbased on image only by using visual features including histogram of oriented\ngradients (HOG) descriptors, grey-level cooccurrence matrix (GLCM), and color\nhistogram. K nearest neighbours (Knn) classification is used in the detection.\nThe final decision of the event detection is made based on the reliabilities of\ntext only detection and image only detection. The experiment result showed that\nthe proposed method achieved high accuracy of 0.94, comparing with 0.89 with\ntexts only, and 0.86 with images only.\n", "Comment: 9 Pages, 4 figuers"]}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - multimedia"], "providerUpdatedDateTime": "2015-03-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03920"}}, {"publisher": {"name": ""}, "description": "  Magnetic shape memory alloys are characterized by the coupling between a\nstructural phase transition and magnetic one. This permits to control the shape\nchange via an external magnetic field, at least in single crystals. Composite\nmaterials with single-crystalline particles embedded in a softer matrix have\nbeen proposed as a way to overcome the blocking of the transformation at grain\nboundaries. We investigate hysteresis phenomena for small NiMnGa single\ncrystals embedded in a polymer matrix for slowly varying magnetic fields. The\nevolution of the microstructure is studied within the rate-independent\nvariational framework proposed by Mielke and Theil (1999). The underlying\nvariational model incorporates linearized elasticity, micromagnetism, stray\nfield and a dissipation term proportional to the volume swept by the phase\nboundary. The time discretization is based on an incremental minimization of\nthe sum of energy and dissipation. A backtracking approach is employed to\napproximately ensure the global minimality condition. We illustrate and discuss\nthe influence of the particle geometry (volume fraction, shape, arrangement)\nand the polymer elastic parameters on the observed hysteresis and compare with\nrecent experimental results.\n", "contributors": [{"name": "Conti, Sergio", "sameAs": [], "familyName": "Conti", "additionalName": "", "givenName": "Sergio", "email": ""}, {"name": "Lenz, Martin", "sameAs": [], "familyName": "Lenz", "additionalName": "", "givenName": "Martin", "email": ""}, {"name": "Rumpf, Martin", "sameAs": [], "familyName": "Rumpf", "additionalName": "", "givenName": "Martin", "email": ""}], "title": "Hysteresis in Magnetic Shape Memory Composites: Modeling and Simulation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.05608", "oai:arXiv.org:1502.05608"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Magnetic shape memory alloys are characterized by the coupling between a\nstructural phase transition and magnetic one. This permits to control the shape\nchange via an external magnetic field, at least in single crystals. Composite\nmaterials with single-crystalline particles embedded in a softer matrix have\nbeen proposed as a way to overcome the blocking of the transformation at grain\nboundaries. We investigate hysteresis phenomena for small NiMnGa single\ncrystals embedded in a polymer matrix for slowly varying magnetic fields. The\nevolution of the microstructure is studied within the rate-independent\nvariational framework proposed by Mielke and Theil (1999). The underlying\nvariational model incorporates linearized elasticity, micromagnetism, stray\nfield and a dissipation term proportional to the volume swept by the phase\nboundary. The time discretization is based on an incremental minimization of\nthe sum of energy and dissipation. A backtracking approach is employed to\napproximately ensure the global minimality condition. We illustrate and discuss\nthe influence of the particle geometry (volume fraction, shape, arrangement)\nand the polymer elastic parameters on the observed hysteresis and compare with\nrecent experimental results.\n", "Comment: 18 pages, 11 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "mathematics - numerical analysis", "74f15", "74n30 (primary)", "74s15 (secondary)"], "providerUpdatedDateTime": "2015-02-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.05608"}}, {"publisher": {"name": ""}, "description": "  In contrast to the existing approaches to bisimulation for fuzzy systems, we\nintroduce a behavioral distance to measure the behavioral similarity of states\nin a nondeterministic fuzzy-transition system. This behavioral distance is\ndefined as the greatest fixed point of a suitable monotonic function and\nprovides a quantitative analogue of bisimilarity. The behavioral distance has\nthe important property that two states are at zero distance if and only if they\nare bisimilar. Moreover, for any given threshold, we find that states with\nbehavioral distances bounded by the threshold are equivalent. In addition, we\nshow that two system combinators---parallel composition and product---are\nnon-expansive with respect to our behavioral distance, which makes\ncompositional verification possible.\n", "contributors": [{"name": "Cao, Yongzhi", "sameAs": [], "familyName": "Cao", "additionalName": "", "givenName": "Yongzhi", "email": ""}, {"name": "Wang, Huaiqing", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Huaiqing", "email": ""}, {"name": "Sun, Sherry X.", "sameAs": [], "familyName": "Sun", "additionalName": "X.", "givenName": "Sherry", "email": ""}, {"name": "Chen, Guoqing", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Guoqing", "email": ""}], "title": "A Behavioral Distance for Fuzzy-Transition Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-10-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1110.0248", "oai:arXiv.org:1110.0248"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In contrast to the existing approaches to bisimulation for fuzzy systems, we\nintroduce a behavioral distance to measure the behavioral similarity of states\nin a nondeterministic fuzzy-transition system. This behavioral distance is\ndefined as the greatest fixed point of a suitable monotonic function and\nprovides a quantitative analogue of bisimilarity. The behavioral distance has\nthe important property that two states are at zero distance if and only if they\nare bisimilar. Moreover, for any given threshold, we find that states with\nbehavioral distances bounded by the threshold are equivalent. In addition, we\nshow that two system combinators---parallel composition and product---are\nnon-expansive with respect to our behavioral distance, which makes\ncompositional verification possible.\n", "Comment: 12 double column pages"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1110.0248"}}, {"publisher": {"name": ""}, "description": "  We present an approach for penalized tensor decomposition (PTD) that\nestimates smoothly varying latent factors in multi-way data. This generalizes\nexisting work on sparse tensor decomposition and penalized matrix\ndecompositions, in a manner parallel to the generalized lasso of Tibshirani and\nTaylor (2011) for regression and smoothing problems. Our approach presents many\nnontrivial challenges at the intersection of modeling and computation, which\nare studied in detail. An efficient coordinate-wise optimization algorithm for\n(PTD) is presented, and its convergence properties are characterized. The\nmethod is applied both to simulated data and real data on flu hospitalizations\nin Texas. These results show that our penalized tensor decomposition can offer\nmajor improvements on existing methods for analyzing multi-way data that\nexhibit smooth spatial or temporal features.\n", "contributors": [{"name": "Padilla, Oscar Hernan Madrid", "sameAs": [], "familyName": "Padilla", "additionalName": "Hernan Madrid", "givenName": "Oscar", "email": ""}, {"name": "Scott, James G.", "sameAs": [], "familyName": "Scott", "additionalName": "G.", "givenName": "James", "email": ""}], "title": "Tensor decomposition with generalized lasso penalties", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06930", "oai:arXiv.org:1502.06930"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  We present an approach for penalized tensor decomposition (PTD) that\nestimates smoothly varying latent factors in multi-way data. This generalizes\nexisting work on sparse tensor decomposition and penalized matrix\ndecompositions, in a manner parallel to the generalized lasso of Tibshirani and\nTaylor (2011) for regression and smoothing problems. Our approach presents many\nnontrivial challenges at the intersection of modeling and computation, which\nare studied in detail. An efficient coordinate-wise optimization algorithm for\n(PTD) is presented, and its convergence properties are characterized. The\nmethod is applied both to simulated data and real data on flu hospitalizations\nin Texas. These results show that our penalized tensor decomposition can offer\nmajor improvements on existing methods for analyzing multi-way data that\nexhibit smooth spatial or temporal features.\n"}}], "languages": [null], "subjects": ["statistics - computation", "statistics - methodology", "statistics - machine learning"], "providerUpdatedDateTime": "2015-02-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06930"}}, {"publisher": {"name": ""}, "description": "  Policy search methods based on reinforcement learning and optimal control can\nallow robots to automatically learn a wide range of tasks. However, practical\napplications of policy search tend to require the policy to be supported by\nhand-engineered components for perception, state estimation, and low-level\ncontrol. We propose a method for learning policies that map raw, low-level\nobservations, consisting of joint angles and camera images, directly to the\ntorques at the robot's joints. The policies are represented as deep\nconvolutional neural networks (CNNs) with 92,000 parameters. The high\ndimensionality of such policies poses a tremendous challenge for policy search.\nTo address this challenge, we develop a sensorimotor guided policy search\nmethod that can handle high-dimensional policies and partially observed tasks.\nWe use BADMM to decompose policy search into an optimal control phase and\nsupervised learning phase, allowing CNN policies to be trained with standard\nsupervised learning techniques. This method can learn a number of manipulation\ntasks that require close coordination between vision and control, including\ninserting a block into a shape sorting cube, screwing on a bottle cap, fitting\nthe claw of a toy hammer under a nail with various grasps, and placing a coat\nhanger on a clothes rack.\n", "contributors": [{"name": "Levine, Sergey", "sameAs": [], "familyName": "Levine", "additionalName": "", "givenName": "Sergey", "email": ""}, {"name": "Finn, Chelsea", "sameAs": [], "familyName": "Finn", "additionalName": "", "givenName": "Chelsea", "email": ""}, {"name": "Darrell, Trevor", "sameAs": [], "familyName": "Darrell", "additionalName": "", "givenName": "Trevor", "email": ""}, {"name": "Abbeel, Pieter", "sameAs": [], "familyName": "Abbeel", "additionalName": "", "givenName": "Pieter", "email": ""}], "title": "End-to-End Training of Deep Visuomotor Policies", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.00702", "oai:arXiv.org:1504.00702"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Policy search methods based on reinforcement learning and optimal control can\nallow robots to automatically learn a wide range of tasks. However, practical\napplications of policy search tend to require the policy to be supported by\nhand-engineered components for perception, state estimation, and low-level\ncontrol. We propose a method for learning policies that map raw, low-level\nobservations, consisting of joint angles and camera images, directly to the\ntorques at the robot's joints. The policies are represented as deep\nconvolutional neural networks (CNNs) with 92,000 parameters. The high\ndimensionality of such policies poses a tremendous challenge for policy search.\nTo address this challenge, we develop a sensorimotor guided policy search\nmethod that can handle high-dimensional policies and partially observed tasks.\nWe use BADMM to decompose policy search into an optimal control phase and\nsupervised learning phase, allowing CNN policies to be trained with standard\nsupervised learning techniques. This method can learn a number of manipulation\ntasks that require close coordination between vision and control, including\ninserting a block into a shape sorting cube, screwing on a bottle cap, fitting\nthe claw of a toy hammer under a nail with various grasps, and placing a coat\nhanger on a clothes rack.\n"}}], "languages": [null], "subjects": ["computer science - robotics", "computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.00702"}}, {"publisher": {"name": ""}, "description": "  We empirically analyze two versions of the well-known \"randomized rumor\nspreading\" protocol to disseminate a piece of information in networks. In the\nclassical model, in each round each informed node informs a random neighbor. In\nthe recently proposed quasirandom variant, each node has a (cyclic) list of its\nneighbors. Once informed, it starts at a random position of the list, but from\nthen on informs its neighbors in the order of the list. While for sparse random\ngraphs a better performance of the quasirandom model could be proven, all other\nresults show that, independent of the structure of the lists, the same\nasymptotic performance guarantees hold as for the classical model. In this\nwork, we compare the two models experimentally. This not only shows that the\nquasirandom model generally is faster, but also that the runtime is more\nconcentrated around the mean. This is surprising given that much fewer random\nbits are used in the quasirandom process. These advantages are also observed in\na lossy communication model, where each transmission does not reach its target\nwith a certain probability, and in an asynchronous model, where nodes send at\nrandom times drawn from an exponential distribution. We also show that\ntypically the particular structure of the lists has little influence on the\nefficiency.\n", "contributors": [{"name": "Doerr, Benjamin", "sameAs": [], "familyName": "Doerr", "additionalName": "", "givenName": "Benjamin", "email": ""}, {"name": "Friedrich, Tobias", "sameAs": [], "familyName": "Friedrich", "additionalName": "", "givenName": "Tobias", "email": ""}, {"name": "K\u00fcnnemann, Marvin", "sameAs": [], "familyName": "K\u00fcnnemann", "additionalName": "", "givenName": "Marvin", "email": ""}, {"name": "Sauerwald, Thomas", "sameAs": [], "familyName": "Sauerwald", "additionalName": "", "givenName": "Thomas", "email": ""}], "title": "Quasirandom Rumor Spreading: An Experimental Analysis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-12-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1012.5357", "oai:arXiv.org:1012.5357"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We empirically analyze two versions of the well-known \"randomized rumor\nspreading\" protocol to disseminate a piece of information in networks. In the\nclassical model, in each round each informed node informs a random neighbor. In\nthe recently proposed quasirandom variant, each node has a (cyclic) list of its\nneighbors. Once informed, it starts at a random position of the list, but from\nthen on informs its neighbors in the order of the list. While for sparse random\ngraphs a better performance of the quasirandom model could be proven, all other\nresults show that, independent of the structure of the lists, the same\nasymptotic performance guarantees hold as for the classical model. In this\nwork, we compare the two models experimentally. This not only shows that the\nquasirandom model generally is faster, but also that the runtime is more\nconcentrated around the mean. This is surprising given that much fewer random\nbits are used in the quasirandom process. These advantages are also observed in\na lossy communication model, where each transmission does not reach its target\nwith a certain probability, and in an asynchronous model, where nodes send at\nrandom times drawn from an exponential distribution. We also show that\ntypically the particular structure of the lists has little influence on the\nefficiency.\n", "Comment: 14 pages, appeared in ALENEX'09"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "f.2.2", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1012.5357"}}, {"publisher": {"name": ""}, "description": "  In this paper, we describe a new neuro-inspired, hardware-friendly readout\nstage for the liquid state machine (LSM), a popular model for reservoir\ncomputing. Compared to the parallel perceptron architecture trained by the\np-delta algorithm, which is the state of the art in terms of performance of\nreadout stages, our readout architecture and learning algorithm can attain\nbetter performance with significantly less synaptic resources making it\nattractive for VLSI implementation. Inspired by the nonlinear properties of\ndendrites in biological neurons, our readout stage incorporates neurons having\nmultiple dendrites with a lumped nonlinearity. The number of synaptic\nconnections on each branch is significantly lower than the total number of\nconnections from the liquid neurons and the learning algorithm tries to find\nthe best 'combination' of input connections on each branch to reduce the error.\nHence, the learning involves network rewiring (NRW) of the readout network\nsimilar to structural plasticity observed in its biological counterparts. We\nshow that compared to a single perceptron using analog weights, this\narchitecture for the readout can attain, even by using the same number of\nbinary valued synapses, up to 3.3 times less error for a two-class spike train\nclassification problem and 2.4 times less error for an input rate approximation\ntask. Even with 60 times larger synapses, a group of 60 parallel perceptrons\ncannot attain the performance of the proposed dendritically enhanced readout.\nAn additional advantage of this method for hardware implementations is that the\n'choice' of connectivity can be easily implemented exploiting address event\nrepresentation (AER) protocols commonly used in current neuromorphic systems\nwhere the connection matrix is stored in memory. Also, due to the use of binary\nsynapses, our proposed method is more robust against statistical variations.\n", "contributors": [{"name": "Roy, Subhrajit", "sameAs": [], "familyName": "Roy", "additionalName": "", "givenName": "Subhrajit", "email": ""}, {"name": "Banerjee, Amitava", "sameAs": [], "familyName": "Banerjee", "additionalName": "", "givenName": "Amitava", "email": ""}, {"name": "Basu, Arindam", "sameAs": [], "familyName": "Basu", "additionalName": "", "givenName": "Arindam", "email": ""}], "title": "Liquid State Machine with Dendritically Enhanced Readout for Low-power,\n  Neuromorphic VLSI Implementations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5458", "IEEE Transactions on Biomedical Circuits and Systems, vol.8, no.5,\n  pp.681,695, Oct. 2014", "doi:10.1109/TBCAS.2014.2362969", "oai:arXiv.org:1411.5458"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we describe a new neuro-inspired, hardware-friendly readout\nstage for the liquid state machine (LSM), a popular model for reservoir\ncomputing. Compared to the parallel perceptron architecture trained by the\np-delta algorithm, which is the state of the art in terms of performance of\nreadout stages, our readout architecture and learning algorithm can attain\nbetter performance with significantly less synaptic resources making it\nattractive for VLSI implementation. Inspired by the nonlinear properties of\ndendrites in biological neurons, our readout stage incorporates neurons having\nmultiple dendrites with a lumped nonlinearity. The number of synaptic\nconnections on each branch is significantly lower than the total number of\nconnections from the liquid neurons and the learning algorithm tries to find\nthe best 'combination' of input connections on each branch to reduce the error.\nHence, the learning involves network rewiring (NRW) of the readout network\nsimilar to structural plasticity observed in its biological counterparts. We\nshow that compared to a single perceptron using analog weights, this\narchitecture for the readout can attain, even by using the same number of\nbinary valued synapses, up to 3.3 times less error for a two-class spike train\nclassification problem and 2.4 times less error for an input rate approximation\ntask. Even with 60 times larger synapses, a group of 60 parallel perceptrons\ncannot attain the performance of the proposed dendritically enhanced readout.\nAn additional advantage of this method for hardware implementations is that the\n'choice' of connectivity can be easily implemented exploiting address event\nrepresentation (AER) protocols commonly used in current neuromorphic systems\nwhere the connection matrix is stored in memory. Also, due to the use of binary\nsynapses, our proposed method is more robust against statistical variations.\n", "Comment: 14 pages, 19 figures, Journal"]}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - emerging technologies"], "providerUpdatedDateTime": "2014-11-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5458"}}, {"publisher": {"name": ""}, "description": "  Most categorical models of meaning use a functor from the syntactic category\nto the semantic category. When semantic information is available, the problem\nof grammar induction can therefore be defined as finding preimages of the\nsemantic types under this forgetful functor, lifting the information flow from\nthe semantic level to a valid reduction at the syntactic level. We study the\ncomplexity of grammar induction, and show that for a variety of type systems,\nincluding pivotal and compact closed categories, the grammar induction problem\nis NP-complete. Our approach could be extended to linguistic type systems such\nas autonomous or bi-closed categories.\n", "contributors": [{"name": "Delpeuch, Antonin", "sameAs": [], "familyName": "Delpeuch", "additionalName": "", "givenName": "Antonin", "email": ""}], "title": "Complexity of Grammar Induction for Quantum Types", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-13", "2014-12-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.3925", "EPTCS 172, 2014, pp. 236-248", "doi:10.4204/EPTCS.172.16", "oai:arXiv.org:1404.3925"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Most categorical models of meaning use a functor from the syntactic category\nto the semantic category. When semantic information is available, the problem\nof grammar induction can therefore be defined as finding preimages of the\nsemantic types under this forgetful functor, lifting the information flow from\nthe semantic level to a valid reduction at the syntactic level. We study the\ncomplexity of grammar induction, and show that for a variety of type systems,\nincluding pivotal and compact closed categories, the grammar induction problem\nis NP-complete. Our approach could be extended to linguistic type systems such\nas autonomous or bi-closed categories.\n", "Comment: In Proceedings QPL 2014, arXiv:1412.8102"]}}], "languages": [null], "subjects": ["mathematics - category theory", "computer science - computation and language"], "providerUpdatedDateTime": "2014-12-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.3925"}}, {"publisher": {"name": ""}, "description": "  The universe of potentially interesting, searchable literature is expanding\ncontinuously. Besides the normal expansion, there is an additional influx of\nliterature because of interdisciplinary boundaries becoming more and more\ndiffuse. Hence, the need for accurate, efficient and intelligent search tools\nis bigger than ever. Even with a sophisticated search engine, looking for\ninformation can still result in overwhelming results. An overload of\ninformation has the intrinsic danger of scaring visitors away, and any\norganization, for-profit or not-for-profit, in the business of providing\nscholarly information wants to capture and keep the attention of its target\naudience. Publishers and search engine engineers alike will benefit from a\nservice that is able to provide visitors with recommendations that closely meet\ntheir interests. Providing visitors with special deals, new options and\nhighlights may be interesting to a certain degree, but what makes more sense\n(especially from a commercial point of view) than to let visitors do most of\nthe work by the mere action of making choices? Hiring psychics is not an\noption, so a technological solution is needed to recommend items that a visitor\nis likely to be looking for. In this presentation we will introduce such a\nsolution and argue that it is practically feasible to incorporate this approach\ninto a useful addition to any information retrieval system with enough usage.\n", "contributors": [{"name": "Henneken, Edwin A.", "sameAs": [], "familyName": "Henneken", "additionalName": "A.", "givenName": "Edwin", "email": ""}, {"name": "Kurtz, Michael J.", "sameAs": [], "familyName": "Kurtz", "additionalName": "J.", "givenName": "Michael", "email": ""}, {"name": "Accomazzi, Alberto", "sameAs": [], "familyName": "Accomazzi", "additionalName": "", "givenName": "Alberto", "email": ""}, {"name": "Grant, Carolyn", "sameAs": [], "familyName": "Grant", "additionalName": "", "givenName": "Carolyn", "email": ""}, {"name": "Thompson, Donna", "sameAs": [], "familyName": "Thompson", "additionalName": "", "givenName": "Donna", "email": ""}, {"name": "Bohlen, Elizabeth", "sameAs": [], "familyName": "Bohlen", "additionalName": "", "givenName": "Elizabeth", "email": ""}, {"name": "Di Milia, Giovanni", "sameAs": [], "familyName": "Di Milia", "additionalName": "", "givenName": "Giovanni", "email": ""}, {"name": "Luker, Jay", "sameAs": [], "familyName": "Luker", "additionalName": "", "givenName": "Jay", "email": ""}, {"name": "Murray, Stephen S.", "sameAs": [], "familyName": "Murray", "additionalName": "S.", "givenName": "Stephen", "email": ""}], "title": "Finding Your Literature Match -- A Recommender System", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-05-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.2308", "oai:arXiv.org:1005.2308"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The universe of potentially interesting, searchable literature is expanding\ncontinuously. Besides the normal expansion, there is an additional influx of\nliterature because of interdisciplinary boundaries becoming more and more\ndiffuse. Hence, the need for accurate, efficient and intelligent search tools\nis bigger than ever. Even with a sophisticated search engine, looking for\ninformation can still result in overwhelming results. An overload of\ninformation has the intrinsic danger of scaring visitors away, and any\norganization, for-profit or not-for-profit, in the business of providing\nscholarly information wants to capture and keep the attention of its target\naudience. Publishers and search engine engineers alike will benefit from a\nservice that is able to provide visitors with recommendations that closely meet\ntheir interests. Providing visitors with special deals, new options and\nhighlights may be interesting to a certain degree, but what makes more sense\n(especially from a commercial point of view) than to let visitors do most of\nthe work by the mere action of making choices? Hiring psychics is not an\noption, so a technological solution is needed to recommend items that a visitor\nis likely to be looking for. In this presentation we will introduce such a\nsolution and argue that it is practically feasible to incorporate this approach\ninto a useful addition to any information retrieval system with enough usage.\n", "Comment: Contribution to the proceedings of the colloquium Future Professional\n  Communication in Astronomy II, 13-14 April 2010, Cambridge, Massachusetts. 11\n  pages, 4 figures."]}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - digital libraries"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.2308"}}, {"publisher": {"name": ""}, "description": "  This paper present the mathematical fundaments and experimental study of an\nalgorithm used to find the optimal position for the camera lens to obtain a\nmaximum of details. This information can be further applied to a appropriate\nsystem to automatically correct this position. The algorithm is based on the\nevaluation of a so called resolution function who calculates the maximum of\ngradient in a certain zone of the image. The paper also presents alternative\nforms of the function, results of measurements and set up a set of practical\nrules for the right application of the algorithm.\n", "contributors": [{"name": "Arsinte, Radu", "sameAs": [], "familyName": "Arsinte", "additionalName": "", "givenName": "Radu", "email": ""}], "title": "Study of a Robust Algorithm Applied in the Optimal Position Tuning for\n  the Camera Lens in Automated Visual Inspection Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06081", "Proceedings of Fifth International Conference on Pattern\n  Recognition and Information Processing - PRIP'99 - May 18-20, 1999 Minsk,\n  Belarus - pag.237-242 - ISBN 83-87362-16-6", "oai:arXiv.org:1502.06081"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper present the mathematical fundaments and experimental study of an\nalgorithm used to find the optimal position for the camera lens to obtain a\nmaximum of details. This information can be further applied to a appropriate\nsystem to automatically correct this position. The algorithm is based on the\nevaluation of a so called resolution function who calculates the maximum of\ngradient in a certain zone of the image. The paper also presents alternative\nforms of the function, results of measurements and set up a set of practical\nrules for the right application of the algorithm.\n", "Comment: 5 pages, 2 figures"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06081"}}, {"publisher": {"name": ""}, "description": "  Detailed description of procedures around architecture reviews. In order to\nsucceed in building and deploying complex software solutions, an architecture\nis essential. For many in the industry structured reviews of these\narchitectures is also de rigor. Practices for such reviews have been developed\nand reported on for years. One aspect that does not receive as much attention\nbut is no less important is the relationship between these architectures and\nthe requirements for deploying them into production environments. At Wolters\nKluwer's Corporate Legal Services we first established a typical architecture\nreview process and then established a two phase production preparation review\nprocess. This paper describes in detail how these practices work and some of\nthe technical results of these reviews including the frequency and style of the\nreviews, the process automation around them, and the number and nature of some\nof the technical flaws eliminated by enforcing these reviews. This paper lays\nthe ground work for others who would be interested in following similar\npractices.\n", "contributors": [{"name": "Cusick, James", "sameAs": [], "familyName": "Cusick", "additionalName": "", "givenName": "James", "email": ""}], "title": "Architecture and Production Readiness Reviews in Practice", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-05-10", "2014-12-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1305.2402", "oai:arXiv.org:1305.2402"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Detailed description of procedures around architecture reviews. In order to\nsucceed in building and deploying complex software solutions, an architecture\nis essential. For many in the industry structured reviews of these\narchitectures is also de rigor. Practices for such reviews have been developed\nand reported on for years. One aspect that does not receive as much attention\nbut is no less important is the relationship between these architectures and\nthe requirements for deploying them into production environments. At Wolters\nKluwer's Corporate Legal Services we first established a typical architecture\nreview process and then established a two phase production preparation review\nprocess. This paper describes in detail how these practices work and some of\nthe technical results of these reviews including the frequency and style of the\nreviews, the process automation around them, and the number and nature of some\nof the technical flaws eliminated by enforcing these reviews. This paper lays\nthe ground work for others who would be interested in following similar\npractices.\n"}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-01-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1305.2402"}}, {"publisher": {"name": ""}, "description": "  Modern spreadsheet systems can be used to implement complex spreadsheet\napplications including data sheets, customized user forms and executable\nprocedures written in a scripting language. These applications are often\ndeveloped by practitioners that do not follow any software engineering practice\nand do not produce any design documentation. Thus, spreadsheet applications may\nbe very difficult to be maintained or restructured. In this position paper we\npresent in a nutshell two reverse engineering techniques and a tool that we are\ncurrently realizing for the abstraction of conceptual data models and business\nlogic models.\n", "contributors": [{"name": "Amalfitano, Domenico", "sameAs": [], "familyName": "Amalfitano", "additionalName": "", "givenName": "Domenico", "email": ""}, {"name": "Amatucci, Nicola", "sameAs": [], "familyName": "Amatucci", "additionalName": "", "givenName": "Nicola", "email": ""}, {"name": "De Simone, Vincenzo", "sameAs": [], "familyName": "De Simone", "additionalName": "", "givenName": "Vincenzo", "email": ""}, {"name": "Fasolino, Anna Rita", "sameAs": [], "familyName": "Fasolino", "additionalName": "Rita", "givenName": "Anna", "email": ""}, {"name": "Tramontana, Porfirio", "sameAs": [], "familyName": "Tramontana", "additionalName": "", "givenName": "Porfirio", "email": ""}], "title": "Toward Reverse Engineering of VBA Based Excel Spreadsheet Applications", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03401", "oai:arXiv.org:1503.03401"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Modern spreadsheet systems can be used to implement complex spreadsheet\napplications including data sheets, customized user forms and executable\nprocedures written in a scripting language. These applications are often\ndeveloped by practitioners that do not follow any software engineering practice\nand do not produce any design documentation. Thus, spreadsheet applications may\nbe very difficult to be maintained or restructured. In this position paper we\npresent in a nutshell two reverse engineering techniques and a tool that we are\ncurrently realizing for the abstraction of conceptual data models and business\nlogic models.\n", "Comment: In Proceedings of the 2nd Workshop on Software Engineering Methods in\n  Spreadsheets (http://spreadsheetlab.org/sems15/)"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-03-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03401"}}, {"publisher": {"name": ""}, "description": "  We propose to augment rating based recommender systems by providing the user\nwith additional information which might help him in his choice or in the\nunderstanding of the recommendation. We consider here as a new task, the\ngeneration of personalized reviews associated to items. We use an extractive\nsummary formulation for generating these reviews. We also show that the two\ninformation sources, ratings and items could be used both for estimating\nratings and for generating summaries, leading to improved performance for each\nsystem compared to the use of a single source. Besides these two contributions,\nwe show how a personalized polarity classifier can integrate the rating and\ntextual aspects. Overall, the proposed system offers the user three\npersonalized hints for a recommendation: rating, text and polarity. We evaluate\nthese three components on two datasets using appropriate measures for each\ntask.\n", "contributors": [{"name": "Poussevin, Micka\u00ebl", "sameAs": [], "familyName": "Poussevin", "additionalName": "", "givenName": "Micka\u00ebl", "email": ""}, {"name": "Guigue, Vincent", "sameAs": [], "familyName": "Guigue", "additionalName": "", "givenName": "Vincent", "email": ""}, {"name": "Gallinari, Patrick", "sameAs": [], "familyName": "Gallinari", "additionalName": "", "givenName": "Patrick", "email": ""}], "title": "Extended Recommendation Framework: Generating the Text of a User Review\n  as a Personalized Summary", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5448", "oai:arXiv.org:1412.5448"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We propose to augment rating based recommender systems by providing the user\nwith additional information which might help him in his choice or in the\nunderstanding of the recommendation. We consider here as a new task, the\ngeneration of personalized reviews associated to items. We use an extractive\nsummary formulation for generating these reviews. We also show that the two\ninformation sources, ratings and items could be used both for estimating\nratings and for generating summaries, leading to improved performance for each\nsystem compared to the use of a single source. Besides these two contributions,\nwe show how a personalized polarity classifier can integrate the rating and\ntextual aspects. Overall, the proposed system offers the user three\npersonalized hints for a recommendation: rating, text and polarity. We evaluate\nthese three components on two datasets using appropriate measures for each\ntask.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - computation and language"], "providerUpdatedDateTime": "2014-12-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5448"}}, {"publisher": {"name": "eScholarship, University of California"}, "description": "", "contributors": [{"name": "McCubbins, Colin H", "sameAs": [], "familyName": "McCubbins", "additionalName": "H", "givenName": "Colin", "email": ""}, {"name": "McCubbins, Mathew D", "sameAs": [], "familyName": "McCubbins", "additionalName": "D", "givenName": "Mathew", "email": ""}], "title": "Proposition 13 and The California Fiscal Shell Game", "shareProperties": {"source": "ucescholarship"}, "otherProperties": [{"name": "type", "properties": {"type": "article"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2010-02-03"}}, {"name": "identifier", "properties": {"identifier": ["qt400320ph", "http://www.escholarship.org/uc/item/400320ph", "qt400320ph"]}}, {"name": "setSpec", "properties": {"setSpec": []}}, {"name": "source", "properties": {"source": "McCubbins, Colin H; & McCubbins, Mathew D. (2010). Proposition 13 and The California Fiscal Shell Game. California Journal of Politics and Policy, 2(2). doi: 10.5070/P2P881. Retrieved from: http://www.escholarship.org/uc/item/400320ph"}}, {"name": "coverage", "properties": {"coverage": []}}, {"name": "relation", "properties": {"relation": []}}, {"name": "rights", "properties": {"rights": "public"}}], "languages": [null], "subjects": ["debt", "proposition 13", "revenue", "tax", "comparative series", "initiative", "synthetic controls"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://www.escholarship.org/uc/item/400320ph"}}, {"publisher": {"name": ""}, "description": "  Transcription of broadcast news is an interesting and challenging application\nfor large-vocabulary continuous speech recognition (LVCSR). We present in\ndetail the structure of a manually segmented and annotated corpus including\nover 160 hours of German broadcast news, and propose it as an evaluation\nframework of LVCSR systems. We show our own experimental results on the corpus,\nachieved with a state-of-the-art LVCSR decoder, measuring the effect of\ndifferent feature sets and decoding parameters, and thereby demonstrate that\nreal-time decoding of our test set is feasible on a desktop PC at 9.2% word\nerror rate.\n", "contributors": [{"name": "Weninger, Felix", "sameAs": [], "familyName": "Weninger", "additionalName": "", "givenName": "Felix", "email": ""}, {"name": "Schuller, Bj\u00f6rn", "sameAs": [], "familyName": "Schuller", "additionalName": "", "givenName": "Bj\u00f6rn", "email": ""}, {"name": "Eyben, Florian", "sameAs": [], "familyName": "Eyben", "additionalName": "", "givenName": "Florian", "email": ""}, {"name": "W\u00f6llmer, Martin", "sameAs": [], "familyName": "W\u00f6llmer", "additionalName": "", "givenName": "Martin", "email": ""}, {"name": "Rigoll, Gerhard", "sameAs": [], "familyName": "Rigoll", "additionalName": "", "givenName": "Gerhard", "email": ""}], "title": "A Broadcast News Corpus for Evaluation and Tuning of German LVCSR\n  Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4616", "oai:arXiv.org:1412.4616"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Transcription of broadcast news is an interesting and challenging application\nfor large-vocabulary continuous speech recognition (LVCSR). We present in\ndetail the structure of a manually segmented and annotated corpus including\nover 160 hours of German broadcast news, and propose it as an evaluation\nframework of LVCSR systems. We show our own experimental results on the corpus,\nachieved with a state-of-the-art LVCSR decoder, measuring the effect of\ndifferent feature sets and decoding parameters, and thereby demonstrate that\nreal-time decoding of our test set is feasible on a desktop PC at 9.2% word\nerror rate.\n", "Comment: submitted to INTERSPEECH 2010 on May 3, 2010"]}}], "languages": [null], "subjects": ["computer science - computation and language", "computer science - sound"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4616"}}, {"publisher": {"name": ""}, "description": "abstract: This dissertation illuminates overlaps in Mormonism and the New Spirituality in North America, showing their shared history and epistemologies. As example of these connections, it introduces ethnographic data from women who are members of the Church of Jesus Christ of Latter-day Saints in order to show (a) how living LDS women adapt and integrate elements from the New Spirituality with Mormon ideas about the nature of reality into hybrid spiritualities; and (b) how they negotiate their blended religious identities both in relation to the current American New Spirituality milieu and the highly centralized, hierarchical, and patriarchal Church of Jesus Christ of Latter-day Saints. The study focuses on religious hybridity with an emphasis on gender and the negotiation of power deriving from patriarchal religious authority, highlighting the dance between institutional power structures and individual authority. It illuminates processes and discourses of religious adaptation and synthesis through which these LDS women creatively and provocatively challenge LDS Church formal power structures.", "contributors": [{"name": "Daughtrey, Doe  (Author)", "sameAs": [], "familyName": "Daughtrey", "additionalName": "", "givenName": "Doe", "email": ""}, {"name": "Cady, Linell  (Advisor)", "sameAs": [], "familyName": "Cady", "additionalName": "", "givenName": "Linell", "email": ""}, {"name": "Mcdannell, Colleen  (Committee member)", "sameAs": [], "familyName": "Mcdannell", "additionalName": "", "givenName": "Colleen", "email": ""}, {"name": "Wenger, Tisa  (Committee member)", "sameAs": [], "familyName": "Wenger", "additionalName": "", "givenName": "Tisa", "email": ""}, {"name": "Fessenden, Tracy  (Committee member)", "sameAs": [], "familyName": "Fessenden", "additionalName": "", "givenName": "Tracy", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Mormonism and the New Spirituality: LDS Women's Hybrid Spiritualities", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "431 pages"}}, {"name": "date", "properties": {"date": "2012"}}, {"name": "description", "properties": {"description": ["abstract: This dissertation illuminates overlaps in Mormonism and the New Spirituality in North America, showing their shared history and epistemologies. As example of these connections, it introduces ethnographic data from women who are members of the Church of Jesus Christ of Latter-day Saints in order to show (a) how living LDS women adapt and integrate elements from the New Spirituality with Mormon ideas about the nature of reality into hybrid spiritualities; and (b) how they negotiate their blended religious identities both in relation to the current American New Spirituality milieu and the highly centralized, hierarchical, and patriarchal Church of Jesus Christ of Latter-day Saints. The study focuses on religious hybridity with an emphasis on gender and the negotiation of power deriving from patriarchal religious authority, highlighting the dance between institutional power structures and individual authority. It illuminates processes and discourses of religious adaptation and synthesis through which these LDS women creatively and provocatively challenge LDS Church formal power structures.", "Dissertation/Thesis", "Ph.D. Religious Studies 2012"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.14737", "item:14737"]}}], "languages": [null], "subjects": ["contemporary paganism", "new age", "religion and popular culture", "comparative religion", "gender studies", "american studies", "religion and gender", "mormonism", "new spirituality"], "providerUpdatedDateTime": "2015-02-12T01:13:25", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.14737"}}, {"publisher": {"name": ""}, "description": "  We revisit the implementation of iterative solvers on discrete graphics\nprocessing units and demonstrate the benefit of implementations using extensive\nkernel fusion for pipelined formulations over conventional implementations of\nclassical formulations. The proposed implementations with both CUDA and OpenCL\nare freely available in ViennaCL and achieve up to three-fold performance gains\nwhen compared to other solver packages for graphics processing units. Highest\nperformance gains are obtained for small to medium-sized systems, while our\nimplementations remain competitive with vendor-tuned implementations for very\nlarge systems. Our results are especially beneficial for transient problems,\nwhere many small to medium-sized systems instead of a single big system need to\nbe solved.\n", "contributors": [{"name": "Rupp, Karl", "sameAs": [], "familyName": "Rupp", "additionalName": "", "givenName": "Karl", "email": ""}, {"name": "Weinbub, Josef", "sameAs": [], "familyName": "Weinbub", "additionalName": "", "givenName": "Josef", "email": ""}, {"name": "J\u00fcngel, Ansgar", "sameAs": [], "familyName": "J\u00fcngel", "additionalName": "", "givenName": "Ansgar", "email": ""}, {"name": "Grasser, Tibor", "sameAs": [], "familyName": "Grasser", "additionalName": "", "givenName": "Tibor", "email": ""}], "title": "Pipelined Iterative Solvers with Kernel Fusion for Graphics Processing\n  Units", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4054", "oai:arXiv.org:1410.4054"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We revisit the implementation of iterative solvers on discrete graphics\nprocessing units and demonstrate the benefit of implementations using extensive\nkernel fusion for pipelined formulations over conventional implementations of\nclassical formulations. The proposed implementations with both CUDA and OpenCL\nare freely available in ViennaCL and achieve up to three-fold performance gains\nwhen compared to other solver packages for graphics processing units. Highest\nperformance gains are obtained for small to medium-sized systems, while our\nimplementations remain competitive with vendor-tuned implementations for very\nlarge systems. Our results are especially beneficial for transient problems,\nwhere many small to medium-sized systems instead of a single big system need to\nbe solved.\n", "Comment: 23 pages, 9 figures, 1 table"]}}], "languages": [null], "subjects": ["65f50", "65f10 (secondary)", "computer science - mathematical software", "computer science - performance", "65y05 (primary)", "and cluster computing", "computer science - distributed", "65y10", "parallel"], "providerUpdatedDateTime": "2014-10-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4054"}}, {"publisher": {"name": ""}, "description": "abstract: The purpose of this experimental study was to investigate the effects of textual and visual annotations on Spanish listening comprehension and vocabulary acquisition in the context of an online multimedia listening activity. 95 students who were enrolled in different sections of first year Spanish classes at a community college and a large southwestern university were randomly assigned to one of four versions of an online multimedia listening activity that contained textual and visual annotations of several key words. Students then took a comprehension and vocabulary posttest and a survey to measure cognitive load and general attitudes towards the program. Results indicated that textual annotations had a significant positive effect on listening comprehension and that visual annotations had a significant positive effect on how successful students felt. No statistically significant differences were found for other variables. Participants also reported positive attitudes towards vocabulary annotations and expressed a desire to see more annotations during multimedia listening activities of this type. These findings provide further evidence of the impact that multimedia may have on language acquisition. These findings have implications for multimedia design and for future research. Language listening activities should include a variety of vocabulary annotations that may help students to understand what they hear and to help them learn new vocabulary. Further research is needed outside of the laboratory, in the online and increasingly-mobile language learning environment in order to align the research with the environment in which many students currently study. The incorporation of motivation into multimedia learning theory and cognitive load should be explored, as well as new measures of cognitive load.", "contributors": [{"name": "Cottam, Michael Evan (Author)", "sameAs": [], "familyName": "Cottam", "additionalName": "Evan", "givenName": "Michael", "email": ""}, {"name": "Savenye, Wilhelmina  (Advisor)", "sameAs": [], "familyName": "Savenye", "additionalName": "", "givenName": "Wilhelmina", "email": ""}, {"name": "Klein, James D. (Committee member)", "sameAs": [], "familyName": "Klein", "additionalName": "D.", "givenName": "James", "email": ""}, {"name": "Atkinson, Robert  (Committee member)", "sameAs": [], "familyName": "Atkinson", "additionalName": "", "givenName": "Robert", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "The Effects of Visual and Textual Annotations on Spanish Listening Comprehension, Vocabulary Acquisition and Cognitive Load", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "148 pages"}}, {"name": "date", "properties": {"date": "2010"}}, {"name": "description", "properties": {"description": ["abstract: The purpose of this experimental study was to investigate the effects of textual and visual annotations on Spanish listening comprehension and vocabulary acquisition in the context of an online multimedia listening activity. 95 students who were enrolled in different sections of first year Spanish classes at a community college and a large southwestern university were randomly assigned to one of four versions of an online multimedia listening activity that contained textual and visual annotations of several key words. Students then took a comprehension and vocabulary posttest and a survey to measure cognitive load and general attitudes towards the program. Results indicated that textual annotations had a significant positive effect on listening comprehension and that visual annotations had a significant positive effect on how successful students felt. No statistically significant differences were found for other variables. Participants also reported positive attitudes towards vocabulary annotations and expressed a desire to see more annotations during multimedia listening activities of this type. These findings provide further evidence of the impact that multimedia may have on language acquisition. These findings have implications for multimedia design and for future research. Language listening activities should include a variety of vocabulary annotations that may help students to understand what they hear and to help them learn new vocabulary. Further research is needed outside of the laboratory, in the online and increasingly-mobile language learning environment in order to align the research with the environment in which many students currently study. The incorporation of motivation into multimedia learning theory and cognitive load should be explored, as well as new measures of cognitive load.", "Dissertation/Thesis", "Ph.D. Educational Technology 2010"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.8633", "item:8633"]}}], "languages": [null], "subjects": ["linguistics", "language", "educational psychology", "multimedia", "listening comprehension", "cognitive load", "vocabulary acquisition", "education", "technology"], "providerUpdatedDateTime": "2015-02-12T01:08:01", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.8633"}}, {"publisher": {"name": ""}, "description": "  Let $X$ be a compact quotient of a bounded domain in $\\mathbb C^n$. Let $K_X$\nbe the canonical line bundle of $X$. In this paper, we shall introduce the\nnotion of $S$ very ampleness for the pluri-canonical line bundles $mK_X$ by\nusing the Poincar\\'e series. The main result is an effective Seshadri constant\ncriterion of $S$ very ampleness for $mK_X$. An elementary proof of surjectivity\nof the Poincar\\'e map is also given.\n", "contributors": [{"name": "Wu, Jujie", "sameAs": [], "familyName": "Wu", "additionalName": "", "givenName": "Jujie", "email": ""}, {"name": "Wang, Xu", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Xu", "email": ""}], "title": "Poincare Series And Very Ampleness Criterion For Pluri-canonical Bundles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.00081", "oai:arXiv.org:1504.00081"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  Let $X$ be a compact quotient of a bounded domain in $\\mathbb C^n$. Let $K_X$\nbe the canonical line bundle of $X$. In this paper, we shall introduce the\nnotion of $S$ very ampleness for the pluri-canonical line bundles $mK_X$ by\nusing the Poincar\\'e series. The main result is an effective Seshadri constant\ncriterion of $S$ very ampleness for $mK_X$. An elementary proof of surjectivity\nof the Poincar\\'e map is also given.\n"}}], "languages": [null], "subjects": ["mathematics - complex variables"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.00081"}}, {"publisher": {"name": ""}, "description": "  The estimation of the time- and frequency-dependent coherent-to-diffuse power\nratio (CDR) from the measured spatial coherence between two omnidirectional\nmicrophones is investigated. Known CDR estimators are formulated in a common\nframework, illustrated using a geometric interpretation in the complex plane,\nand investigated with respect to bias and robustness towards model errors.\nSeveral novel unbiased CDR estimators are proposed, and it is shown that\nknowledge of either the direction of arrival (DOA) of the target source or the\ncoherence of the noise field is sufficient for unbiased CDR estimation. The\nvalidity of the model for the application of CDR estimates to dereverberation\nis investigated using measured and simulated impulse responses. A CDR-based\ndereverberation system is presented and evaluated using signal-based quality\nmeasures as well as automatic speech recognition accuracy. The results show\nthat the proposed unbiased estimators have a practical advantage over existing\nestimators, and that the proposed DOA-independent estimator can be used for\neffective blind dereverberation.\n", "contributors": [{"name": "Schwarz, Andreas", "sameAs": [], "familyName": "Schwarz", "additionalName": "", "givenName": "Andreas", "email": ""}, {"name": "Kellermann, Walter", "sameAs": [], "familyName": "Kellermann", "additionalName": "", "givenName": "Walter", "email": ""}], "title": "Coherent-to-Diffuse Power Ratio Estimation for Dereverberation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-02-12", "2015-02-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03784", "doi:10.1109/TASLP.2015.2418571", "oai:arXiv.org:1502.03784"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The estimation of the time- and frequency-dependent coherent-to-diffuse power\nratio (CDR) from the measured spatial coherence between two omnidirectional\nmicrophones is investigated. Known CDR estimators are formulated in a common\nframework, illustrated using a geometric interpretation in the complex plane,\nand investigated with respect to bias and robustness towards model errors.\nSeveral novel unbiased CDR estimators are proposed, and it is shown that\nknowledge of either the direction of arrival (DOA) of the target source or the\ncoherence of the noise field is sufficient for unbiased CDR estimation. The\nvalidity of the model for the application of CDR estimates to dereverberation\nis investigated using measured and simulated impulse responses. A CDR-based\ndereverberation system is presented and evaluated using signal-based quality\nmeasures as well as automatic speech recognition accuracy. The results show\nthat the proposed unbiased estimators have a practical advantage over existing\nestimators, and that the proposed DOA-independent estimator can be used for\neffective blind dereverberation.\n", "Comment: submitted to IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing, 2015"]}}], "languages": [null], "subjects": ["computer science - sound"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03784"}}, {"publisher": {"name": ""}, "description": "  We consider the problem of recovering the sparsest vector in a subspace\n$\\mathcal{S} \\subseteq \\mathbb{R}^p$ with $\\mathrm{dim}(\\mathcal{S}) = n < p$.\nThis problem can be considered a homogeneous variant of the sparse recovery\nproblem, and finds applications in sparse dictionary learning, sparse PCA, and\nother problems in signal processing and machine learning. Simple convex\nheuristics for this problem provably break down when the fraction of nonzero\nentries in the target sparse vector substantially exceeds $1/\\sqrt{n}$. In\ncontrast, we exhibit a relatively simple nonconvex approach based on\nalternating directions, which provably succeeds even when the fraction of\nnonzero entries is $\\Omega(1)$. To our knowledge, this is the first practical\nalgorithm to achieve this linear scaling. This result assumes a planted sparse\nmodel, in which the target sparse vector is embedded in an otherwise random\nsubspace. Empirically, our proposed algorithm also succeeds in more challenging\ndata models arising, e.g., from sparse dictionary learning.\n", "contributors": [{"name": "Qu, Qing", "sameAs": [], "familyName": "Qu", "additionalName": "", "givenName": "Qing", "email": ""}, {"name": "Sun, Ju", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Ju", "email": ""}, {"name": "Wright, John", "sameAs": [], "familyName": "Wright", "additionalName": "", "givenName": "John", "email": ""}], "title": "Finding a sparse vector in a subspace: Linear sparsity using alternating\n  directions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4659", "oai:arXiv.org:1412.4659"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  We consider the problem of recovering the sparsest vector in a subspace\n$\\mathcal{S} \\subseteq \\mathbb{R}^p$ with $\\mathrm{dim}(\\mathcal{S}) = n < p$.\nThis problem can be considered a homogeneous variant of the sparse recovery\nproblem, and finds applications in sparse dictionary learning, sparse PCA, and\nother problems in signal processing and machine learning. Simple convex\nheuristics for this problem provably break down when the fraction of nonzero\nentries in the target sparse vector substantially exceeds $1/\\sqrt{n}$. In\ncontrast, we exhibit a relatively simple nonconvex approach based on\nalternating directions, which provably succeeds even when the fraction of\nnonzero entries is $\\Omega(1)$. To our knowledge, this is the first practical\nalgorithm to achieve this linear scaling. This result assumes a planted sparse\nmodel, in which the target sparse vector is embedded in an otherwise random\nsubspace. Empirically, our proposed algorithm also succeeds in more challenging\ndata models arising, e.g., from sparse dictionary learning.\n", "Comment: 38 pages, 4 figures. Extended abstract appears in Advances in Neural\n  Information Processing Systems (NIPS), 2014"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - information theory", "computer science - learning", "statistics - machine learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4659"}}, {"publisher": {"name": "ScholarlyCommons"}, "description": "This policy brief examines the evolution of the educational leadership development system in England to see what ideas American leaders and policymakers might take from looking transnationally. The brief is based on a more in-depth examination of that leadership development system described in a CPRE research report entitled Building a Lattice for School Leadership: The Top-to-Bottom Rethinking of Leadership Development in England and What It Might Mean for American Education. The research report was based upon a year of research on school leadership in England that included extensive background research, site visits to schools and leadership programs, and over 20 interviews with government officials, teachers and school leaders, university researchers, union officials, and both forprofit and non-profit school leadership providers.", "contributors": [{"name": "Supovitz, Jonathan A", "sameAs": [], "familyName": "Supovitz", "additionalName": "A", "givenName": "Jonathan", "email": ""}], "title": "Building a Lattice for School Leadership: Lessons From England", "shareProperties": {"source": "upennsylvania"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2015-03-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.upenn.edu/cpre_policybriefs/7", "http://repository.upenn.edu/cgi/viewcontent.cgi?article=1000&amp;context=cpre_policybriefs", "oai:repository.upenn.edu:cpre_policybriefs-1000"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:cpre", "publication:cpre_policybriefs"]}}, {"name": "source", "properties": {"source": "CPRE Policy Briefs"}}, {"name": "rights", "properties": {"rights": []}}], "languages": [null], "subjects": ["educational leadership", "leadership studies", "education policy", "international and comparative education"], "providerUpdatedDateTime": "2015-03-26T19:16:08", "uris": {"canonicalUri": "http://repository.upenn.edu/cpre_policybriefs/7"}}, {"publisher": {"name": ""}, "description": "  An analytical framework for performance analysis and optimization of coded\nV-BLAST is developed. Average power and/or rate allocations to minimize the\noutage probability as well as their robustness and dual problems are\ninvestigated. Compact, closed-form expressions for the optimum allocations and\ncorresponding system performance are given. The uniform power allocation is\nshown to be near optimum in the low outage regime in combination with the\noptimum rate allocation. The average rate allocation provides the largest\nperformance improvement (extra diversity gain), and the average power\nallocation offers a modest SNR gain limited by the number of transmit antennas\nbut does not increase the diversity gain. The dual problems are shown to have\nthe same solutions as the primal ones. All these allocation strategies are\nshown to be robust. The reported results also apply to coded multiuser\ndetection and channel equalization systems relying on successive interference\ncancelation.\n", "contributors": [{"name": "Kostina, Victoria", "sameAs": [], "familyName": "Kostina", "additionalName": "", "givenName": "Victoria", "email": ""}, {"name": "Loyka, Sergey", "sameAs": [], "familyName": "Loyka", "additionalName": "", "givenName": "Sergey", "email": ""}], "title": "Optimum Power and Rate Allocation for Coded V-BLAST: Average\n  Optimization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-10-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1010.2789", "oai:arXiv.org:1010.2789"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  An analytical framework for performance analysis and optimization of coded\nV-BLAST is developed. Average power and/or rate allocations to minimize the\noutage probability as well as their robustness and dual problems are\ninvestigated. Compact, closed-form expressions for the optimum allocations and\ncorresponding system performance are given. The uniform power allocation is\nshown to be near optimum in the low outage regime in combination with the\noptimum rate allocation. The average rate allocation provides the largest\nperformance improvement (extra diversity gain), and the average power\nallocation offers a modest SNR gain limited by the number of transmit antennas\nbut does not increase the diversity gain. The dual problems are shown to have\nthe same solutions as the primal ones. All these allocation strategies are\nshown to be robust. The reported results also apply to coded multiuser\ndetection and channel equalization systems relying on successive interference\ncancelation.\n", "Comment: accepted by IEEE Transactions on Communications"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1010.2789"}}, {"publisher": {"name": ""}, "description": "  Four quantum code constructions generating several new families of good\nnonbinary quantum nonprimitive non-narrow-sense Bose-Chaudhuri-Hocquenghem\n(BCH) codes are presented in this paper. The first two ones are based on\nCalderbank-Shor-Steane (CSS) construction derived from two nonprimitive BCH\ncodes, not necessarily self-orthogonal. The third one is based on nonbinary\nSteane's enlargement of CSS codes applied to suitable sub-families of\nnonprimitive non-narrow-sense BCH codes. The fourth construction is derived\nfrom suitable sub-families of Hermitian self-orthogonal nonprimitive\nnon-narrow-sense BCH codes. These constructions generate new families of\nquantum BCH codes whose parameters are better than the ones available in the\nliterature.\n", "contributors": [{"name": "La Guardia, Giuliano G.", "sameAs": [], "familyName": "La Guardia", "additionalName": "G.", "givenName": "Giuliano", "email": ""}], "title": "On the Construction of Nonbinary Quantum BCH Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-12-22", "2013-12-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1212.5687", "IEEE Transactions on Information Theory 60(3), 2014", "oai:arXiv.org:1212.5687"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": "  Four quantum code constructions generating several new families of good\nnonbinary quantum nonprimitive non-narrow-sense Bose-Chaudhuri-Hocquenghem\n(BCH) codes are presented in this paper. The first two ones are based on\nCalderbank-Shor-Steane (CSS) construction derived from two nonprimitive BCH\ncodes, not necessarily self-orthogonal. The third one is based on nonbinary\nSteane's enlargement of CSS codes applied to suitable sub-families of\nnonprimitive non-narrow-sense BCH codes. The fourth construction is derived\nfrom suitable sub-families of Hermitian self-orthogonal nonprimitive\nnon-narrow-sense BCH codes. These constructions generate new families of\nquantum BCH codes whose parameters are better than the ones available in the\nliterature.\n"}}], "languages": [null], "subjects": ["quantum physics", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1212.5687"}}, {"publisher": {"name": ""}, "description": "  Subset selection from massive data with noised information is increasingly\npopular for various applications. This problem is still highly challenging as\ncurrent methods are generally slow in speed and sensitive to outliers. To\naddress the above two issues, we propose an accelerated robust subset selection\n(ARSS) method. Specifically in the subset selection area, this is the first\nattempt to employ the $\\ell_{p}(0<p\\leq1)$-norm based measure for the\nrepresentation loss, preventing large errors from dominating our objective. As\na result, the robustness against outlier elements is greatly enhanced.\nActually, data size is generally much larger than feature length, i.e. $N\\gg\nL$. Based on this observation, we propose a speedup solver (via ALM and\nequivalent derivations) to highly reduce the computational cost, theoretically\nfrom $O(N^{4})$ to $O(N{}^{2}L)$. Extensive experiments on ten benchmark\ndatasets verify that our method not only outperforms state of the art methods,\nbut also runs 10,000+ times faster than the most related method.\n", "contributors": [{"name": "Zhu, Feiyun", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "Feiyun", "email": ""}, {"name": "Fan, Bin", "sameAs": [], "familyName": "Fan", "additionalName": "", "givenName": "Bin", "email": ""}, {"name": "Zhu, Xinliang", "sameAs": [], "familyName": "Zhu", "additionalName": "", "givenName": "Xinliang", "email": ""}, {"name": "Wang, Ying", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Ying", "email": ""}, {"name": "Xiang, Shiming", "sameAs": [], "familyName": "Xiang", "additionalName": "", "givenName": "Shiming", "email": ""}, {"name": "Pan, Chunhong", "sameAs": [], "familyName": "Pan", "additionalName": "", "givenName": "Chunhong", "email": ""}], "title": "10,000+ Times Accelerated Robust Subset Selection (ARSS)", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-12", "2014-11-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.3660", "oai:arXiv.org:1409.3660"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  Subset selection from massive data with noised information is increasingly\npopular for various applications. This problem is still highly challenging as\ncurrent methods are generally slow in speed and sensitive to outliers. To\naddress the above two issues, we propose an accelerated robust subset selection\n(ARSS) method. Specifically in the subset selection area, this is the first\nattempt to employ the $\\ell_{p}(0<p\\leq1)$-norm based measure for the\nrepresentation loss, preventing large errors from dominating our objective. As\na result, the robustness against outlier elements is greatly enhanced.\nActually, data size is generally much larger than feature length, i.e. $N\\gg\nL$. Based on this observation, we propose a speedup solver (via ALM and\nequivalent derivations) to highly reduce the computational cost, theoretically\nfrom $O(N^{4})$ to $O(N{}^{2}L)$. Extensive experiments on ten benchmark\ndatasets verify that our method not only outperforms state of the art methods,\nbut also runs 10,000+ times faster than the most related method.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.3660"}}, {"publisher": {"name": ""}, "description": "  Complete Pick algebras - these are, roughly, the multiplier algebras in which\nPick's interpolation theorem holds true - have been the focus of much research\nin the last twenty years or so. All (irreducible) complete Pick algebras may be\nrealized concretely as the algebras obtained by restricting multipliers on\nDrury-Arveson space to a subvariety of the unit ball; to be precise: every\nirreducible complete Pick algebra has the form $M_V = \\{f|_V : f \\in M_d\\}$,\nwhere $M_d$ denotes the multiplier algebra of the Drury-Arveson space $H^2_d$,\nand $V$ is the joint zero set of some functions in $M_d$. In recent years\nseveral works were devoted to the classification of complete Pick algebras in\nterms of the complex geometry of the varieties with which they are associated.\nThe purpose of this survey is to give an account of this research in a\ncomprehensive and unified way. We describe the array of tools and methods that\nwere developed for this program, and take the opportunity to clarify, improve,\nand correct some parts of the literature.\n", "contributors": [{"name": "Salomon, Guy", "sameAs": [], "familyName": "Salomon", "additionalName": "", "givenName": "Guy", "email": ""}, {"name": "Shalit, Orr", "sameAs": [], "familyName": "Shalit", "additionalName": "", "givenName": "Orr", "email": ""}], "title": "The isomorphism problem for complete Pick algebras: a survey", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7817", "oai:arXiv.org:1412.7817"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Complete Pick algebras - these are, roughly, the multiplier algebras in which\nPick's interpolation theorem holds true - have been the focus of much research\nin the last twenty years or so. All (irreducible) complete Pick algebras may be\nrealized concretely as the algebras obtained by restricting multipliers on\nDrury-Arveson space to a subvariety of the unit ball; to be precise: every\nirreducible complete Pick algebra has the form $M_V = \\{f|_V : f \\in M_d\\}$,\nwhere $M_d$ denotes the multiplier algebra of the Drury-Arveson space $H^2_d$,\nand $V$ is the joint zero set of some functions in $M_d$. In recent years\nseveral works were devoted to the classification of complete Pick algebras in\nterms of the complex geometry of the varieties with which they are associated.\nThe purpose of this survey is to give an account of this research in a\ncomprehensive and unified way. We describe the array of tools and methods that\nwere developed for this program, and take the opportunity to clarify, improve,\nand correct some parts of the literature.\n", "Comment: 28 pages. Prepared for Proceedings of IWOTA 2014"]}}], "languages": [null], "subjects": ["47a13", "47l30", "mathematics - functional analysis", "mathematics - complex variables", "mathematics - operator algebras", "46e22"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7817"}}, {"publisher": {"name": ""}, "description": "  We study the expression complexity of two basic problems involving the\ncomparison of primitive positive formulas: equivalence and containment. In\nparticular, we study the complexity of these problems relative to finite\nrelational structures. We present two generic hardness results for the studied\nproblems, and discuss evidence that they are optimal and yield, for each of the\nproblems, a complexity trichotomy.\n", "contributors": [{"name": "Bova, Simone", "sameAs": [], "familyName": "Bova", "additionalName": "", "givenName": "Simone", "email": ""}, {"name": "Chen, Hubie", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Hubie", "email": ""}, {"name": "Valeriote, Matthew", "sameAs": [], "familyName": "Valeriote", "additionalName": "", "givenName": "Matthew", "email": ""}], "title": "Generic Expression Hardness Results for Primitive Positive Formula\n  Comparison", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-05-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.5745", "oai:arXiv.org:1205.5745"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We study the expression complexity of two basic problems involving the\ncomparison of primitive positive formulas: equivalence and containment. In\nparticular, we study the complexity of these problems relative to finite\nrelational structures. We present two generic hardness results for the studied\nproblems, and discuss evidence that they are optimal and yield, for each of the\nproblems, a complexity trichotomy.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "computer science - databases", "computer science - logic in computer science"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.5745"}}, {"publisher": {"name": ""}, "description": "  Bourgain recently constructed $O(1)$-monotone bipartite expanders. By\ncombining this result with a generalisation of the unraveling method of Kannan,\nwe construct 3-monotone bipartite expanders, which is best possible. Similarly,\nwe construct bipartite expanders that have 3-page book embeddings, 2-queue\nlayouts, and 4-track layouts. All these results are best possible.\n", "contributors": [{"name": "Dujmovi\u0107, Vida", "sameAs": [], "familyName": "Dujmovi\u0107", "additionalName": "", "givenName": "Vida", "email": ""}, {"name": "Sidiropoulos, Anastasios", "sameAs": [], "familyName": "Sidiropoulos", "additionalName": "", "givenName": "Anastasios", "email": ""}, {"name": "Wood, David R.", "sameAs": [], "familyName": "Wood", "additionalName": "R.", "givenName": "David", "email": ""}], "title": "3-Monotone Expanders", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05020", "oai:arXiv.org:1501.05020"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Bourgain recently constructed $O(1)$-monotone bipartite expanders. By\ncombining this result with a generalisation of the unraveling method of Kannan,\nwe construct 3-monotone bipartite expanders, which is best possible. Similarly,\nwe construct bipartite expanders that have 3-page book embeddings, 2-queue\nlayouts, and 4-track layouts. All these results are best possible.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-01-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05020"}}, {"publisher": {"name": ""}, "description": "  We develop a worst-case analysis of aggregation of classifier ensembles for\nbinary classification. The task of predicting to minimize error is formulated\nas a game played over a given set of unlabeled data (a transductive setting),\nwhere prior label information is encoded as constraints on the game. The\nminimax solution of this game identifies cases where a weighted combination of\nthe classifiers can perform significantly better than any single classifier.\n", "contributors": [{"name": "Balsubramani, Akshay", "sameAs": [], "familyName": "Balsubramani", "additionalName": "", "givenName": "Akshay", "email": ""}, {"name": "Freund, Yoav", "sameAs": [], "familyName": "Freund", "additionalName": "", "givenName": "Yoav", "email": ""}], "title": "Optimally Combining Classifiers Using Unlabeled Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-05", "2015-03-09"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01811", "oai:arXiv.org:1503.01811"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  We develop a worst-case analysis of aggregation of classifier ensembles for\nbinary classification. The task of predicting to minimize error is formulated\nas a game played over a given set of unlabeled data (a transductive setting),\nwhere prior label information is encoded as constraints on the game. The\nminimax solution of this game identifies cases where a weighted combination of\nthe classifiers can perform significantly better than any single classifier.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01811"}}, {"publisher": {"name": ""}, "description": "  Errors in data are usually unwelcome and so some means to correct them is\nuseful. However, it is difficult to define, detect or correct errors in an\nunsupervised way. Here, we train a deep neural network to re-synthesize its\ninputs at its output layer for a given class of data. We then exploit the fact\nthat this abstract transformation, which we call a deep transform (DT),\ninherently rejects information (errors) existing outside of the abstract\nfeature space. Using the DT to perform probabilistic re-synthesis, we\ndemonstrate the recovery of data that has been subject to extreme degradation.\n", "contributors": [{"name": "Simpson, Andrew J. R.", "sameAs": [], "familyName": "Simpson", "additionalName": "J. R.", "givenName": "Andrew", "email": ""}], "title": "Deep Transform: Error Correction via Probabilistic Re-Synthesis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04617", "oai:arXiv.org:1502.04617"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Errors in data are usually unwelcome and so some means to correct them is\nuseful. However, it is difficult to define, detect or correct errors in an\nunsupervised way. Here, we train a deep neural network to re-synthesize its\ninputs at its output layer for a given class of data. We then exploit the fact\nthat this abstract transformation, which we call a deep transform (DT),\ninherently rejects information (errors) existing outside of the abstract\nfeature space. Using the DT to perform probabilistic re-synthesis, we\ndemonstrate the recovery of data that has been subject to extreme degradation.\n"}}], "languages": [null], "subjects": ["computer science - learning", "68txx"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04617"}}, {"publisher": {"name": ""}, "description": "  Recently, XACML is a popular access control policy language that is used\nwidely in many applications. Policies in XACML are built based on many\ncomponents over distributed resources. Due to the expressiveness of XACML, it\nis not trivial for policy administrators to understand the overall effect and\nconsequences of XACML policies they have written. In this paper we show a\nmechanism and a tool how to analyses big access control policies sets such as\n(i) incompleteness policies, (ii) conflicting policies, and (iii) unreachable\npolicies. To detect these problems we present a method using Answer Set\nProgramming (ASP) in the context of XACML 3.0.\n", "contributors": [{"name": "Ramli, Carroline Dewi Puspa Kencana", "sameAs": [], "familyName": "Ramli", "additionalName": "Dewi Puspa Kencana", "givenName": "Carroline", "email": ""}], "title": "Detecting Incompleteness, Conflicting and Unreachability XACML Policies\n  using Answer Set Programming", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02732", "oai:arXiv.org:1503.02732"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Recently, XACML is a popular access control policy language that is used\nwidely in many applications. Policies in XACML are built based on many\ncomponents over distributed resources. Due to the expressiveness of XACML, it\nis not trivial for policy administrators to understand the overall effect and\nconsequences of XACML policies they have written. In this paper we show a\nmechanism and a tool how to analyses big access control policies sets such as\n(i) incompleteness policies, (ii) conflicting policies, and (iii) unreachable\npolicies. To detect these problems we present a method using Answer Set\nProgramming (ASP) in the context of XACML 3.0.\n", "Comment: arXiv admin note: text overlap with arXiv:1206.5327"]}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02732"}}, {"publisher": {"name": ""}, "description": "  The word position automaton was introduced by Glushkov and McNaughton in the\nearly 1960. This automaton is homogeneous and has (||\\E||+1) states for a word\nexpression of alphabetic width ||\\E||. This kind of automata is extended to\nregular tree expressions.\n  In this paper, we give an efficient algorithm that computes the \\Follow sets,\nwhich are used in different algorithms of conversion of a regular expression\ninto tree automata. In the following, we consider the k-position tree automaton\nconstruction. We prove that for a regular expression \\E of a size |\\E| and\nalphabetic width ||\\E||, the \\Follow sets can be computed in O(||\\E||\\cdot\n|\\E|) time complexity.\n", "contributors": [{"name": "Sebti, Nadia Ouali", "sameAs": [], "familyName": "Sebti", "additionalName": "Ouali", "givenName": "Nadia", "email": ""}, {"name": "Ziadi, Djelloul", "sameAs": [], "familyName": "Ziadi", "additionalName": "", "givenName": "Djelloul", "email": ""}], "title": "Algorithm for the k-Position Tree Automaton Construction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06194", "oai:arXiv.org:1502.06194"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The word position automaton was introduced by Glushkov and McNaughton in the\nearly 1960. This automaton is homogeneous and has (||\\E||+1) states for a word\nexpression of alphabetic width ||\\E||. This kind of automata is extended to\nregular tree expressions.\n  In this paper, we give an efficient algorithm that computes the \\Follow sets,\nwhich are used in different algorithms of conversion of a regular expression\ninto tree automata. In the following, we consider the k-position tree automaton\nconstruction. We prove that for a regular expression \\E of a size |\\E| and\nalphabetic width ||\\E||, the \\Follow sets can be computed in O(||\\E||\\cdot\n|\\E|) time complexity.\n", "Comment: arXiv admin note: text overlap with arXiv:1403.6251, arXiv:1401.5951"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06194"}}, {"publisher": {"name": "Elsevier/North-Holland Biomedical Press"}, "description": "\u2022We use a normative (Bayes optimal) model of oculomotor pursuit.\u2022We average the empirical responses of subjects performing a pursuit paradigm.\u2022We invert these responses using the pursuit model and dynamic causal modelling.\u2022We thereby estimate the precision of subjects\u2019 Bayesian beliefs from their pursuit.\u2022This could be used to quantify abnormal precision encoding in schizophrenia.", "contributors": [{"name": "Adams, Rick A.", "sameAs": [], "familyName": "Adams", "additionalName": "A.", "givenName": "Rick", "email": ""}, {"name": "Aponte, Eduardo", "sameAs": [], "familyName": "Aponte", "additionalName": "", "givenName": "Eduardo", "email": ""}, {"name": "Marshall, Louise", "sameAs": [], "familyName": "Marshall", "additionalName": "", "givenName": "Louise", "email": ""}, {"name": "Friston, Karl J.", "sameAs": [], "familyName": "Friston", "additionalName": "J.", "givenName": "Karl", "email": ""}], "title": "Active inference and oculomotor pursuit: The dynamic causal modelling of eye movements", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["computational neuroscience"], "providerUpdatedDateTime": "2015-03-15T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4346275"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "This research investigates the distortion on the electrical distribution system for a high voltage DC Integrated Power System (IPS). The analysis was concentrated on the power supplied to a propulsion motor driven by an inverter with simulated silicon carbide switches. Theoretically, silicon carbide switches have the advantage of being able to withstand a very large blocking voltage and carry very large forward currents. Silicon carbide switches are also very efficient due to their quick rise and fall times. Since silicon carbide switches can withstand high voltage differentials and switch faster than silicon switches, the switching effects on the electrical distribution system were investigated. The current state of silicon carbide power electronics was also investigated. This research quantifies the current and voltage distortion over various operating conditions. A system model was developed using Matlab, Simulink, and SimPowerSystems. The model consisted of a synchronous generator supplying a rectifier and inverter set driving an induction motor. This induction motor simulates the propulsion motor for a Navy ship. This model had a DC link voltage of 10 kV in order to simulate future Navy IPS systems. The current and voltage distortion were compared to MIL STD 1399 and IEEE STD 519 and 45.", "contributors": [{"name": "Fallier, William F. (William Frederick)", "sameAs": [], "familyName": "Fallier", "additionalName": "F.", "givenName": "William", "email": ""}, {"name": "Massachusetts Institute of Technology. Dept. of Electrical Engineering and Computer Science.", "sameAs": [], "familyName": "Science.", "additionalName": "Institute of Technology. Dept. of Electrical Engineering and Computer", "givenName": "Massachusetts", "email": ""}, {"name": "James L. Kirtley.", "sameAs": [], "familyName": "Kirtley.", "additionalName": "L.", "givenName": "James", "email": ""}], "title": "Analysis of system wide distortion in an integrated power system utilizing a high voltage DC bus and silicon carbide power devices", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "172 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/39730", "181006289", "oai:dspace.mit.edu:1721.1/39730"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2007-12-07T16:14:45Z", "2007-12-07T16:14:45Z", "2007", "2007"]}}, {"name": "description", "properties": {"description": ["This research investigates the distortion on the electrical distribution system for a high voltage DC Integrated Power System (IPS). The analysis was concentrated on the power supplied to a propulsion motor driven by an inverter with simulated silicon carbide switches. Theoretically, silicon carbide switches have the advantage of being able to withstand a very large blocking voltage and carry very large forward currents. Silicon carbide switches are also very efficient due to their quick rise and fall times. Since silicon carbide switches can withstand high voltage differentials and switch faster than silicon switches, the switching effects on the electrical distribution system were investigated. The current state of silicon carbide power electronics was also investigated. This research quantifies the current and voltage distortion over various operating conditions. A system model was developed using Matlab, Simulink, and SimPowerSystems. The model consisted of a synchronous generator supplying a rectifier and inverter set driving an induction motor. This induction motor simulates the propulsion motor for a Navy ship. This model had a DC link voltage of 10 kV in order to simulate future Navy IPS systems. The current and voltage distortion were compared to MIL STD 1399 and IEEE STD 519 and 45.", "by William F. Fallier.", "Thesis (Nav. E.)--Massachusetts Institute of Technology, Dept. of Mechanical Engineering; and, (S.M.)--Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2007.", "Includes bibliographical references (p. 81-82)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7685", "hdl_1721.1_7851", "hdl_1721.1_7663", "hdl_1721.1_7817"]}}], "languages": [null], "subjects": ["mechanical engineering.", "electrical engineering and computer science."], "providerUpdatedDateTime": "2014-11-06T07:21:00", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/39730"}}, {"publisher": {"name": ""}, "description": "  Consider the continuum of points on the edges of a network, i.e., a\nconnected, undirected graph with positive edge weights. We measure the distance\nbetween these points in terms of the weighted shortest path distance, called\nthe network distance. Within this metric space, we study farthest points and\nfarthest distances. We introduce optimal data structures supporting queries for\nthe farthest distance and the farthest points on trees, cycles, uni-cyclic\nnetworks, and cactus networks.\n", "contributors": [{"name": "Bose, Prosenjit", "sameAs": [], "familyName": "Bose", "additionalName": "", "givenName": "Prosenjit", "email": ""}, {"name": "De Carufel, Jean-Lou", "sameAs": [], "familyName": "De Carufel", "additionalName": "", "givenName": "Jean-Lou", "email": ""}, {"name": "Grimm, Carsten", "sameAs": [], "familyName": "Grimm", "additionalName": "", "givenName": "Carsten", "email": ""}, {"name": "Maheshwari, Anil", "sameAs": [], "familyName": "Maheshwari", "additionalName": "", "givenName": "Anil", "email": ""}, {"name": "Smid, Michiel", "sameAs": [], "familyName": "Smid", "additionalName": "", "givenName": "Michiel", "email": ""}], "title": "Optimal Data Structures for Farthest-Point Queries in Cactus Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1879", "doi:10.7155/jgaa.00345", "oai:arXiv.org:1411.1879"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Consider the continuum of points on the edges of a network, i.e., a\nconnected, undirected graph with positive edge weights. We measure the distance\nbetween these points in terms of the weighted shortest path distance, called\nthe network distance. Within this metric space, we study farthest points and\nfarthest distances. We introduce optimal data structures supporting queries for\nthe farthest distance and the farthest points on trees, cycles, uni-cyclic\nnetworks, and cactus networks.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1879"}}, {"publisher": {"name": ""}, "description": "  In this paper, we pioneer the study of physical-layer security in\nheterogeneous networks (HetNets). We investigate secure communications in a\ntwo-tier downlink HetNet, which comprises one macrocell and several femtocells.\nEach cell has multiple users and an eavesdropper attempts to wiretap the\nintended macrocell user. Firstly, we consider an orthogonal spectrum allocation\nstrategy to eliminate co-channel interference, and propose the secrecy transmit\nbeamforming only operating in the macrocell (STB-OM) as a partial solution for\nsecure communication in HetNet. Next, we consider a secrecy-oriented\nnon-orthogonal spectrum allocation strategy and propose two cooperative STBs\nwhich rely on the collaboration amongst the macrocell base station (MBS) and\nthe adjacent femtocell base stations (FBSs). Our first cooperative STB is the\nSTB sequentially operating in the macrocell and femtocells (STB-SMF), where the\ncooperative FBSs individually design their STB matrices and then feed their\nperformance metrics to the MBS for guiding the STB in the macrocell. Aiming to\nimprove the performance of STB-SMF, we further propose the STB jointly designed\nin the macrocell and femtocells (STB-JMF), where all cooperative FBSs feed\nchannel state information to the MBS for designing the joint STB. Unlike\nconventional STBs conceived for broadcasting or interference channels, the\nthree proposed STB schemes all entail relatively sophisticated optimizations\ndue to QoS constraints of the legitimate users. In order to efficiently use\nthese STB schemes, the original optimization problems are reformulated and\nconvex optimization techniques, such as second-order cone programming and\nsemidefinite programming, are invoked to obtain the optimal solutions.\nNumerical results demonstrate that the proposed STB schemes are highly\neffective in improving the secrecy rate performance of HetNet.\n", "contributors": [{"name": "Lv, Tiejun", "sameAs": [], "familyName": "Lv", "additionalName": "", "givenName": "Tiejun", "email": ""}, {"name": "Gao, Hui", "sameAs": [], "familyName": "Gao", "additionalName": "", "givenName": "Hui", "email": ""}, {"name": "Yang, Shaoshi", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Shaoshi", "email": ""}], "title": "Secrecy Transmit Beamforming for Heterogeneous Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01056", "doi:10.1109/JSAC.2015.2416984", "oai:arXiv.org:1503.01056"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we pioneer the study of physical-layer security in\nheterogeneous networks (HetNets). We investigate secure communications in a\ntwo-tier downlink HetNet, which comprises one macrocell and several femtocells.\nEach cell has multiple users and an eavesdropper attempts to wiretap the\nintended macrocell user. Firstly, we consider an orthogonal spectrum allocation\nstrategy to eliminate co-channel interference, and propose the secrecy transmit\nbeamforming only operating in the macrocell (STB-OM) as a partial solution for\nsecure communication in HetNet. Next, we consider a secrecy-oriented\nnon-orthogonal spectrum allocation strategy and propose two cooperative STBs\nwhich rely on the collaboration amongst the macrocell base station (MBS) and\nthe adjacent femtocell base stations (FBSs). Our first cooperative STB is the\nSTB sequentially operating in the macrocell and femtocells (STB-SMF), where the\ncooperative FBSs individually design their STB matrices and then feed their\nperformance metrics to the MBS for guiding the STB in the macrocell. Aiming to\nimprove the performance of STB-SMF, we further propose the STB jointly designed\nin the macrocell and femtocells (STB-JMF), where all cooperative FBSs feed\nchannel state information to the MBS for designing the joint STB. Unlike\nconventional STBs conceived for broadcasting or interference channels, the\nthree proposed STB schemes all entail relatively sophisticated optimizations\ndue to QoS constraints of the legitimate users. In order to efficiently use\nthese STB schemes, the original optimization problems are reformulated and\nconvex optimization techniques, such as second-order cone programming and\nsemidefinite programming, are invoked to obtain the optimal solutions.\nNumerical results demonstrate that the proposed STB schemes are highly\neffective in improving the secrecy rate performance of HetNet.\n", "Comment: 17 pages, 14 figures, 3 algorithms and 1 table, to appear in IEEE\n  Journal on Selected Areas in Communications, 2015"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01056"}}, {"publisher": {"name": ""}, "description": "  The modern engineering landscape increasingly requires a range of skills to\nsuccessfully integrate complex systems. Project-based learning is used to help\nstudents build professional skills. However, it is typically applied to small\nteams and small efforts. This paper describes an experience in engaging a large\nnumber of students in research projects within a multi-year interdisciplinary\nresearch effort. The projects expose the students to various disciplines in\nComputer Science (embedded systems, algorithm design, networking), Electrical\nEngineering (circuit design, wireless communications, hardware prototyping),\nand Applied Physics (thin-film battery design, solar cell fabrication). While a\nstudent project is usually focused on one discipline area, it requires\ninteraction with at least two other areas. Over 5 years, 180 semester-long\nprojects have been completed. The students were a diverse group of high school,\nundergraduate, and M.S. Computer Science, Computer Engineering, and Electrical\nEngineering students. Some of the approaches that were taken to facilitate\nstudent learning are real-world system development constraints, regular\ncross-group meetings, and extensive involvement of Ph.D. students in student\nmentorship and knowledge transfer. To assess the approaches, a survey was\nconducted among the participating students. The results demonstrate the\neffectiveness of the approaches. For example, 70% of the students surveyed\nindicated that working on their research project improved their ability to\nfunction on multidisciplinary teams more than coursework, internships, or any\nother activity.\n", "contributors": [{"name": "Margolies, Robert", "sameAs": [], "familyName": "Margolies", "additionalName": "", "givenName": "Robert", "email": ""}, {"name": "Gorlatova, Maria", "sameAs": [], "familyName": "Gorlatova", "additionalName": "", "givenName": "Maria", "email": ""}, {"name": "Sarik, John", "sameAs": [], "familyName": "Sarik", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Kinget, Peter", "sameAs": [], "familyName": "Kinget", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Kymissis, Ioannis", "sameAs": [], "familyName": "Kymissis", "additionalName": "", "givenName": "Ioannis", "email": ""}, {"name": "Zussman, Gil", "sameAs": [], "familyName": "Zussman", "additionalName": "", "givenName": "Gil", "email": ""}], "title": "Project-based Learning within a Large-Scale Interdisciplinary Research\n  Effort", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6935", "oai:arXiv.org:1410.6935"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The modern engineering landscape increasingly requires a range of skills to\nsuccessfully integrate complex systems. Project-based learning is used to help\nstudents build professional skills. However, it is typically applied to small\nteams and small efforts. This paper describes an experience in engaging a large\nnumber of students in research projects within a multi-year interdisciplinary\nresearch effort. The projects expose the students to various disciplines in\nComputer Science (embedded systems, algorithm design, networking), Electrical\nEngineering (circuit design, wireless communications, hardware prototyping),\nand Applied Physics (thin-film battery design, solar cell fabrication). While a\nstudent project is usually focused on one discipline area, it requires\ninteraction with at least two other areas. Over 5 years, 180 semester-long\nprojects have been completed. The students were a diverse group of high school,\nundergraduate, and M.S. Computer Science, Computer Engineering, and Electrical\nEngineering students. Some of the approaches that were taken to facilitate\nstudent learning are real-world system development constraints, regular\ncross-group meetings, and extensive involvement of Ph.D. students in student\nmentorship and knowledge transfer. To assess the approaches, a survey was\nconducted among the participating students. The results demonstrate the\neffectiveness of the approaches. For example, 70% of the students surveyed\nindicated that working on their research project improved their ability to\nfunction on multidisciplinary teams more than coursework, internships, or any\nother activity.\n"}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6935"}}, {"publisher": {"name": ""}, "description": "  Recently, utilizing renewable energy for wireless system has attracted\nextensive attention. However, due to the instable energy supply and the limited\nbattery capacity, renewable energy cannot guarantee to provide the perpetual\noperation for wireless sensor networks (WSN). The coexistence of renewable\nenergy and electricity grid is expected as a promising energy supply manner to\nremain function for a potentially infinite lifetime. In this paper, we propose\na new system model suitable for WSN, taking into account multiple energy\nconsumptions due to sensing, transmission and reception, heterogeneous energy\nsupplies from renewable energy, electricity grid and mixed energy, and\nmultidimension stochastic natures due to energy harvesting profile, electricity\nprice and channel condition. A discrete-time stochastic cross-layer\noptimization problem is formulated to achieve the optimal trade-off between the\ntime-average rate utility and electricity cost subject to the data and energy\nqueuing stability constraints. The Lyapunov drift-plus-penalty with\nperturbation technique and block coordinate descent method is applied to obtain\na fully distributed and low-complexity cross-layer algorithm only requiring\nknowledge of the instantaneous system state. The explicit trade-off between the\noptimization objective and queue backlog is theoretically proven. Finally, the\nextensive simulations verify the theoretic claims.\n", "contributors": [{"name": "Xu, Weiqiang", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Weiqiang", "email": ""}, {"name": "Zhang, Yushu", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Yushu", "email": ""}, {"name": "Shi, Qingjiang", "sameAs": [], "familyName": "Shi", "additionalName": "", "givenName": "Qingjiang", "email": ""}, {"name": "Wang, Xiaodong", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Xiaodong", "email": ""}], "title": "Energy Management and Cross Layer Optimization for Wireless Sensor\n  Network Powered by Heterogeneous Energy Sources", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-07", "2014-11-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1973", "oai:arXiv.org:1410.1973"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Recently, utilizing renewable energy for wireless system has attracted\nextensive attention. However, due to the instable energy supply and the limited\nbattery capacity, renewable energy cannot guarantee to provide the perpetual\noperation for wireless sensor networks (WSN). The coexistence of renewable\nenergy and electricity grid is expected as a promising energy supply manner to\nremain function for a potentially infinite lifetime. In this paper, we propose\na new system model suitable for WSN, taking into account multiple energy\nconsumptions due to sensing, transmission and reception, heterogeneous energy\nsupplies from renewable energy, electricity grid and mixed energy, and\nmultidimension stochastic natures due to energy harvesting profile, electricity\nprice and channel condition. A discrete-time stochastic cross-layer\noptimization problem is formulated to achieve the optimal trade-off between the\ntime-average rate utility and electricity cost subject to the data and energy\nqueuing stability constraints. The Lyapunov drift-plus-penalty with\nperturbation technique and block coordinate descent method is applied to obtain\na fully distributed and low-complexity cross-layer algorithm only requiring\nknowledge of the instantaneous system state. The explicit trade-off between the\noptimization objective and queue backlog is theoretically proven. Finally, the\nextensive simulations verify the theoretic claims.\n", "Comment: submitted to IEEE Transactions on Wireless Communications, Under\n  Second Round Review after Major Revision"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1973"}}, {"publisher": {"name": ""}, "description": "  This paper considers a problem of distributed hypothesis testing and social\nlearning. Individual nodes in a network receive noisy local (private)\nobservations whose distribution is parameterized by a discrete parameter\n(hypotheses). The conditional distributions are known locally at the nodes, but\nthe true parameter/hypothesis is not known. An update rule is analyzed in which\nnodes first perform a Bayesian update of their belief (distribution estimate)\nof the parameter based on their local observation, communicate these updates to\ntheir neighbors, and then perform a \"non-Bayesian\" linear consensus using the\nlog-beliefs of their neighbors. In this paper we show that under mild\nassumptions, the belief of any node in any incorrect hypothesis converges to\nzero exponentially fast, and we characterize the exponential rate of learning\nwhich is given in terms of the network structure and the divergences between\nthe observations' distributions. Our main result is the large deviation\nproperty established on the rate of convergence with an explicit\ncharacterization of the probability of convergence.\n", "contributors": [{"name": "Lalitha, Anusha", "sameAs": [], "familyName": "Lalitha", "additionalName": "", "givenName": "Anusha", "email": ""}, {"name": "Javidi, Tara", "sameAs": [], "familyName": "Javidi", "additionalName": "", "givenName": "Tara", "email": ""}, {"name": "Sarwate, Anand", "sameAs": [], "familyName": "Sarwate", "additionalName": "", "givenName": "Anand", "email": ""}], "title": "Social Learning and Distributed Hypothesis Testing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-16", "2014-10-21"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4307", "oai:arXiv.org:1410.4307"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  This paper considers a problem of distributed hypothesis testing and social\nlearning. Individual nodes in a network receive noisy local (private)\nobservations whose distribution is parameterized by a discrete parameter\n(hypotheses). The conditional distributions are known locally at the nodes, but\nthe true parameter/hypothesis is not known. An update rule is analyzed in which\nnodes first perform a Bayesian update of their belief (distribution estimate)\nof the parameter based on their local observation, communicate these updates to\ntheir neighbors, and then perform a \"non-Bayesian\" linear consensus using the\nlog-beliefs of their neighbors. In this paper we show that under mild\nassumptions, the belief of any node in any incorrect hypothesis converges to\nzero exponentially fast, and we characterize the exponential rate of learning\nwhich is given in terms of the network structure and the divergences between\nthe observations' distributions. Our main result is the large deviation\nproperty established on the rate of convergence with an explicit\ncharacterization of the probability of convergence.\n"}}], "languages": [null], "subjects": ["mathematics - statistics theory", "mathematics - optimization and control", "computer science - information theory"], "providerUpdatedDateTime": "2014-10-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4307"}}, {"publisher": {"name": ""}, "description": "  Mathematical model for hit phenomena presented by A Ishii et al in 2012 has\nbeen extended to analyze and predict a lot of hit subject using social network\nsystem. The equation for each individual consumers is assumed and the equation\nof social response to each hit subject is derived as stochastic process of\nstatistical physics. The advertisement effect is included as external force and\nthe communication effects are included as two-body and three-body interaction.\nThe applications of this model are demonstrated for analyzing population of\nweekly TV drama. Including both the realtime view data and the playback view\ndata, we found that the indirect communication correlate strongly to the TV\nviewing rate data for recent Japanese 20 TV drama.\n", "contributors": [{"name": "Ishii, Akira", "sameAs": [], "familyName": "Ishii", "additionalName": "", "givenName": "Akira", "email": ""}, {"name": "Kitao, Akiko", "sameAs": [], "familyName": "Kitao", "additionalName": "", "givenName": "Akiko", "email": ""}, {"name": "Usui, Tsukasa", "sameAs": [], "familyName": "Usui", "additionalName": "", "givenName": "Tsukasa", "email": ""}, {"name": "Uchiyama, Koki", "sameAs": [], "familyName": "Uchiyama", "additionalName": "", "givenName": "Koki", "email": ""}], "title": "Mathematical model for hit phenomena and its application to analyze\n  popularity of weekly tv drama", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00758", "oai:arXiv.org:1501.00758"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Mathematical model for hit phenomena presented by A Ishii et al in 2012 has\nbeen extended to analyze and predict a lot of hit subject using social network\nsystem. The equation for each individual consumers is assumed and the equation\nof social response to each hit subject is derived as stochastic process of\nstatistical physics. The advertisement effect is included as external force and\nthe communication effects are included as two-body and three-body interaction.\nThe applications of this model are demonstrated for analyzing population of\nweekly TV drama. Including both the realtime view data and the playback view\ndata, we found that the indirect communication correlate strongly to the TV\nviewing rate data for recent Japanese 20 TV drama.\n", "Comment: 18 pages, 12 figures, submitted to International Journal of Modern\n  Physics B: Special issue: Advances on Statistical Physics of Complex Systems\n  as a conference paper of International Conference on Statisitical Physics,\n  Rhodes, Greece, 7-11 July 2014"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00758"}}, {"publisher": {"name": ""}, "description": "  For information transmission a discrete time channel with independent\nadditive Gaussian noise is used. There is also another channel with independent\nadditive Gaussian noise (the feedback channel), and the transmitter observes\nwithout delay all outputs of the forward channel via that channel. Transmission\nof nonexponential number of messages is considered (i.e. transmission rate\nequals zero) and the achievable decoding error exponent for such a combination\nof channels is investigated. The transmission method strengthens the method\nused by authors earlier for BSC and Gaussian channels. In particular, for small\nfeedback noise, it allows to gain 33.3\\% (instead of 23.6\\% earlier in the\nsimilar case of Gaussian channel).\n", "contributors": [{"name": "Burnashev, Marat V.", "sameAs": [], "familyName": "Burnashev", "additionalName": "V.", "givenName": "Marat", "email": ""}, {"name": "Yamamoto, Hirosuke", "sameAs": [], "familyName": "Yamamoto", "additionalName": "", "givenName": "Hirosuke", "email": ""}], "title": "On Using Feedback in a Gaussian Channel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04887", "Problems of Information Transmission, vol. 50, no. 3, pp. 19--34,\n  2014", "oai:arXiv.org:1501.04887"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  For information transmission a discrete time channel with independent\nadditive Gaussian noise is used. There is also another channel with independent\nadditive Gaussian noise (the feedback channel), and the transmitter observes\nwithout delay all outputs of the forward channel via that channel. Transmission\nof nonexponential number of messages is considered (i.e. transmission rate\nequals zero) and the achievable decoding error exponent for such a combination\nof channels is investigated. The transmission method strengthens the method\nused by authors earlier for BSC and Gaussian channels. In particular, for small\nfeedback noise, it allows to gain 33.3\\% (instead of 23.6\\% earlier in the\nsimilar case of Gaussian channel).\n", "Comment: arXiv admin note: text overlap with arXiv:1208.2786"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04887"}}, {"publisher": {"name": ""}, "description": "  Collisions are a main cause of throughput degradation in WLANs. The current\ncontention mechanism used in IEEE 802.11 networks is called Carrier Sense\nMultiple Access with Collision Avoidance (CSMA/CA). It uses a Binary\nExponential Backoff (BEB) technique to randomise each contender attempt of\ntransmitting, effectively reducing the collision probability. Nevertheless,\nCSMA/CA relies on a random backoff that while effective and totally\ndistributed, in principle is unable to completely eliminate collisions,\ntherefore degrading the network throughput as more contenders attempt to share\nthe channel. Carrier Sense Multiple Access with Enhanced Collision Avoidance\n(CSMA/ECA) is able to create a collision-free schedule in a totally distributed\nmanner using a deterministic backoff after successful transmissions. Hysteresis\nand Fair Share are two extensions of CSMA/ECA to support a large number of\ncontenders in a collision-free schedule. CSMA/ECA offers better throughput than\nCSMA/CA and short-term throughput fairness.\n  This work describes CSMA/ECA and its extensions. Additionally, it provides\nthe first evaluation results of CSMA/ECA in non-saturated traffic conditions as\nwell as its performance when coexisting with CSMA/CA nodes. Furthermore, the\neffects of imperfect clocks over CSMA/ECA's deterministic backoff mechanism and\nits consequences when attempting to implement the protocol in real hardware are\nalso analysed.\n", "contributors": [{"name": "Sanabria-Russo, Luis", "sameAs": [], "familyName": "Sanabria-Russo", "additionalName": "", "givenName": "Luis", "email": ""}, {"name": "Barcelo, Jaume", "sameAs": [], "familyName": "Barcelo", "additionalName": "", "givenName": "Jaume", "email": ""}, {"name": "Bellalta, Boris", "sameAs": [], "familyName": "Bellalta", "additionalName": "", "givenName": "Boris", "email": ""}], "title": "A High Efficiency MAC Protocol for WLANs: Providing Fairness in Dense\n  Scenarios", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1395", "oai:arXiv.org:1412.1395"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Collisions are a main cause of throughput degradation in WLANs. The current\ncontention mechanism used in IEEE 802.11 networks is called Carrier Sense\nMultiple Access with Collision Avoidance (CSMA/CA). It uses a Binary\nExponential Backoff (BEB) technique to randomise each contender attempt of\ntransmitting, effectively reducing the collision probability. Nevertheless,\nCSMA/CA relies on a random backoff that while effective and totally\ndistributed, in principle is unable to completely eliminate collisions,\ntherefore degrading the network throughput as more contenders attempt to share\nthe channel. Carrier Sense Multiple Access with Enhanced Collision Avoidance\n(CSMA/ECA) is able to create a collision-free schedule in a totally distributed\nmanner using a deterministic backoff after successful transmissions. Hysteresis\nand Fair Share are two extensions of CSMA/ECA to support a large number of\ncontenders in a collision-free schedule. CSMA/ECA offers better throughput than\nCSMA/CA and short-term throughput fairness.\n  This work describes CSMA/ECA and its extensions. Additionally, it provides\nthe first evaluation results of CSMA/ECA in non-saturated traffic conditions as\nwell as its performance when coexisting with CSMA/CA nodes. Furthermore, the\neffects of imperfect clocks over CSMA/ECA's deterministic backoff mechanism and\nits consequences when attempting to implement the protocol in real hardware are\nalso analysed.\n", "Comment: This work has been submitted to the IEEE/ACM Transactions on\n  Networking journal"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-12-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1395"}}, {"publisher": {"name": ""}, "description": "  The ring and polynomial learning with errors problems (Ring-LWE and Poly-LWE)\nhave been proposed as hard problems to form the basis for cryptosystems, and\nvarious security reductions to hard lattice problems have been presented. So\nfar these problems have been stated for general (number) rings but have only\nbeen closely examined for cyclotomic number rings. In this paper, we state and\nexamine the Ring-LWE problem for general number rings and demonstrate provably\nweak instances of Ring-LWE. We construct an explicit family of number fields\nfor which we have an efficient attack. We demonstrate the attack in both theory\nand practice, providing code and running times for the attack. The attack runs\nin time linear in q, where q is the modulus.\n  Our attack is based on the attack on Poly-LWE which was presented in\n[Eisentr\\\"ager-Hallgren-Lauter]. We extend the EHL-attack to apply to a larger\nclass of number fields, and show how it applies to attack Ring-LWE for a\nheuristically large class of fields. Certain Ring-LWE instances can be\ntransformed into Poly-LWE instances without distorting the error too much, and\nthus provide the first weak instances of the Ring-LWE problem. We also provide\nadditional examples of fields which are vulnerable to our attacks on Poly-LWE,\nincluding power-of-$2$ cyclotomic fields, presented using the minimal\npolynomial of $\\zeta_{2^n} \\pm 1$.\n", "contributors": [{"name": "Elias, Yara", "sameAs": [], "familyName": "Elias", "additionalName": "", "givenName": "Yara", "email": ""}, {"name": "Lauter, Kristin E.", "sameAs": [], "familyName": "Lauter", "additionalName": "E.", "givenName": "Kristin", "email": ""}, {"name": "Ozman, Ekin", "sameAs": [], "familyName": "Ozman", "additionalName": "", "givenName": "Ekin", "email": ""}, {"name": "Stange, Katherine E.", "sameAs": [], "familyName": "Stange", "additionalName": "E.", "givenName": "Katherine", "email": ""}], "title": "Provably weak instances of Ring-LWE", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03708", "oai:arXiv.org:1502.03708"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The ring and polynomial learning with errors problems (Ring-LWE and Poly-LWE)\nhave been proposed as hard problems to form the basis for cryptosystems, and\nvarious security reductions to hard lattice problems have been presented. So\nfar these problems have been stated for general (number) rings but have only\nbeen closely examined for cyclotomic number rings. In this paper, we state and\nexamine the Ring-LWE problem for general number rings and demonstrate provably\nweak instances of Ring-LWE. We construct an explicit family of number fields\nfor which we have an efficient attack. We demonstrate the attack in both theory\nand practice, providing code and running times for the attack. The attack runs\nin time linear in q, where q is the modulus.\n  Our attack is based on the attack on Poly-LWE which was presented in\n[Eisentr\\\"ager-Hallgren-Lauter]. We extend the EHL-attack to apply to a larger\nclass of number fields, and show how it applies to attack Ring-LWE for a\nheuristically large class of fields. Certain Ring-LWE instances can be\ntransformed into Poly-LWE instances without distorting the error too much, and\nthus provide the first weak instances of the Ring-LWE problem. We also provide\nadditional examples of fields which are vulnerable to our attacks on Poly-LWE,\nincluding power-of-$2$ cyclotomic fields, presented using the minimal\npolynomial of $\\zeta_{2^n} \\pm 1$.\n", "Comment: 24 pages including computer code"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "mathematics - number theory", "94a60", "11t71"], "providerUpdatedDateTime": "2015-02-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03708"}}, {"publisher": {"name": ""}, "description": "  Establishing secret common randomness between two or multiple devices in a\nnetwork resides at the root of communication security. The problem is\ntraditionally decomposed into a randomness generation stage (randomness purity\nis subject to employing often costly true random number generators) and a\nkey-agreement information exchange stage, which can rely on public-key\ninfrastructure or on key wrapping. In this paper, we propose KERMAN, an\nalternative key establishment algorithm for ad-hoc networks which works by\nharvesting randomness directly from the network routing metadata, thus\nachieving both pure randomness generation and (implicitly) secret-key\nagreement. Our algorithm relies on the route discovery phase of an ad-hoc\nnetwork employing the Dynamic Source Routing protocol, is lightweight, and\nrequires minimal communication overhead.\n", "contributors": [{"name": "Shoja, Mohammad Reza Khalili", "sameAs": [], "familyName": "Shoja", "additionalName": "Reza Khalili", "givenName": "Mohammad", "email": ""}, {"name": "Amariucai, George Traian", "sameAs": [], "familyName": "Amariucai", "additionalName": "Traian", "givenName": "George", "email": ""}, {"name": "Wei, Shuangqing", "sameAs": [], "familyName": "Wei", "additionalName": "", "givenName": "Shuangqing", "email": ""}, {"name": "Deng, Jing", "sameAs": [], "familyName": "Deng", "additionalName": "", "givenName": "Jing", "email": ""}], "title": "KERMAN: A Key Establishment Algorithm based on Harvesting Randomness in\n  MANETs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03744", "oai:arXiv.org:1504.03744"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Establishing secret common randomness between two or multiple devices in a\nnetwork resides at the root of communication security. The problem is\ntraditionally decomposed into a randomness generation stage (randomness purity\nis subject to employing often costly true random number generators) and a\nkey-agreement information exchange stage, which can rely on public-key\ninfrastructure or on key wrapping. In this paper, we propose KERMAN, an\nalternative key establishment algorithm for ad-hoc networks which works by\nharvesting randomness directly from the network routing metadata, thus\nachieving both pure randomness generation and (implicitly) secret-key\nagreement. Our algorithm relies on the route discovery phase of an ad-hoc\nnetwork employing the Dynamic Source Routing protocol, is lightweight, and\nrequires minimal communication overhead.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-04-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03744"}}, {"publisher": {"name": ""}, "description": "  The girth of a matrix is the least number of linearly dependent columns, in\ncontrast to the rank which is the largest number of linearly independent\ncolumns. This paper considers the construction of {\\it high-girth} matrices,\nwhose probabilistic girth is close to its rank. Random matrices can be used to\nshow the existence of high-girth matrices with constant relative rank, but the\nconstruction is non-explicit. This paper uses a polar-like construction to\nobtain a deterministic and efficient construction of high-girth matrices for\narbitrary fields and relative ranks. Applications to coding and sparse recovery\nare discussed.\n", "contributors": [{"name": "Abbe, Emmanuel", "sameAs": [], "familyName": "Abbe", "additionalName": "", "givenName": "Emmanuel", "email": ""}, {"name": "Wigderson, Yuval", "sameAs": [], "familyName": "Wigderson", "additionalName": "", "givenName": "Yuval", "email": ""}], "title": "High-Girth Matrices and Polarization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06528", "oai:arXiv.org:1501.06528"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  The girth of a matrix is the least number of linearly dependent columns, in\ncontrast to the rank which is the largest number of linearly independent\ncolumns. This paper considers the construction of {\\it high-girth} matrices,\nwhose probabilistic girth is close to its rank. Random matrices can be used to\nshow the existence of high-girth matrices with constant relative rank, but the\nconstruction is non-explicit. This paper uses a polar-like construction to\nobtain a deterministic and efficient construction of high-girth matrices for\narbitrary fields and relative ranks. Applications to coding and sparse recovery\nare discussed.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06528"}}, {"publisher": {"name": ""}, "description": "  Sentiment analysis of microblogs such as Twitter has recently gained a fair\namount of attention. One of the simplest sentiment analysis approaches compares\nthe words of a posting against a labeled word list, where each word has been\nscored for valence, -- a 'sentiment lexicon' or 'affective word lists'. There\nexist several affective word lists, e.g., ANEW (Affective Norms for English\nWords) developed before the advent of microblogging and sentiment analysis. I\nwanted to examine how well ANEW and other word lists performs for the detection\nof sentiment strength in microblog posts in comparison with a new word list\nspecifically constructed for microblogs. I used manually labeled postings from\nTwitter scored for sentiment. Using a simple word matching I show that the new\nword list may perform better than ANEW, though not as good as the more\nelaborate approach found in SentiStrength.\n", "contributors": [{"name": "Nielsen, Finn \u00c5rup", "sameAs": [], "familyName": "Nielsen", "additionalName": "\u00c5rup", "givenName": "Finn", "email": ""}], "title": "A new ANEW: Evaluation of a word list for sentiment analysis in\n  microblogs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-03-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1103.2903", "oai:arXiv.org:1103.2903"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Sentiment analysis of microblogs such as Twitter has recently gained a fair\namount of attention. One of the simplest sentiment analysis approaches compares\nthe words of a posting against a labeled word list, where each word has been\nscored for valence, -- a 'sentiment lexicon' or 'affective word lists'. There\nexist several affective word lists, e.g., ANEW (Affective Norms for English\nWords) developed before the advent of microblogging and sentiment analysis. I\nwanted to examine how well ANEW and other word lists performs for the detection\nof sentiment strength in microblog posts in comparison with a new word list\nspecifically constructed for microblogs. I used manually labeled postings from\nTwitter scored for sentiment. Using a simple word matching I show that the new\nword list may perform better than ANEW, though not as good as the more\nelaborate approach found in SentiStrength.\n", "Comment: 6 pages, 4 figures, 1 table, Submitted to \"Making Sense of Microposts\n  (#MSM2011)\""]}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - computation and language", "68m11", "h.4.3", "j.4"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1103.2903"}}, {"publisher": {"name": ""}, "description": "  We introduce and solve the problem of Byzantine fault tolerant distributed\nquickest change detection in both continuous and discrete time setups. In this\nproblem, multiple sensors sequentially observe random signals from the\nenvironment and send their observations to a control center that will determine\nwhether there is a change in the statistical behavior of the observations. We\nassume that the signals are independent and identically distributed across\nsensors. An unknown subset of sensors are compromised and will send arbitrarily\nmodified and even artificially generated signals to the control center. It is\nshown that the performance of the the so-called CUSUM statistic, which is\noptimal when all sensors are honest, will be significantly degraded in the\npresence of even a single dishonest sensor. In particular, instead of in a\nlogarithmically the detection delay grows linearly with the average run length\n(ARL) to false alarm. To mitigate such a performance degradation, we propose a\nfully distributed low complexity detection scheme. We show that the proposed\nscheme can recover the log scaling. We also propose a centralized group-wise\nscheme that can further reduce the detection delay.\n", "contributors": [{"name": "Bayraktar, Erhan", "sameAs": [], "familyName": "Bayraktar", "additionalName": "", "givenName": "Erhan", "email": ""}, {"name": "Lai, Lifeng", "sameAs": [], "familyName": "Lai", "additionalName": "", "givenName": "Lifeng", "email": ""}], "title": "Byzantine Fault Tolerant Distributed Quickest Change Detection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-09", "2014-12-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.2086", "oai:arXiv.org:1306.2086"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We introduce and solve the problem of Byzantine fault tolerant distributed\nquickest change detection in both continuous and discrete time setups. In this\nproblem, multiple sensors sequentially observe random signals from the\nenvironment and send their observations to a control center that will determine\nwhether there is a change in the statistical behavior of the observations. We\nassume that the signals are independent and identically distributed across\nsensors. An unknown subset of sensors are compromised and will send arbitrarily\nmodified and even artificially generated signals to the control center. It is\nshown that the performance of the the so-called CUSUM statistic, which is\noptimal when all sensors are honest, will be significantly degraded in the\npresence of even a single dishonest sensor. In particular, instead of in a\nlogarithmically the detection delay grows linearly with the average run length\n(ARL) to false alarm. To mitigate such a performance degradation, we propose a\nfully distributed low complexity detection scheme. We show that the proposed\nscheme can recover the log scaling. We also propose a centralized group-wise\nscheme that can further reduce the detection delay.\n", "Comment: Final version. To appear in the SIAM Journal on Control and\n  Optimization. Keywords: (Non-Bayesian) quickest change detection, Byzantine\n  fault tolerance, distributed sensor network, robust optimal stopping in\n  continuous and discrete time"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "computer science - information theory", "mathematics - probability"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.2086"}}, {"publisher": {"name": ""}, "description": "  Algorithms to find communities in networks rely just on structural\ninformation and search for cohesive subsets of nodes. On the other hand, most\nscholars implicitly or explicitly assume that structural communities represent\ngroups of nodes with similar (non-topological) properties or functions. This\nhypothesis could not be verified, so far, because of the lack of network\ndatasets with information on the classification of the nodes. We show that\ntraditional community detection methods fail to find the metadata groups in\nmany large networks. Our results show that there is a marked separation between\nstructural communities and metadata groups, in line with recent findings. That\nmeans that either our current modeling of community structure has to be\nsubstantially modified, or that metadata groups may not be recoverable from\ntopology alone.\n", "contributors": [{"name": "Hric, Darko", "sameAs": [], "familyName": "Hric", "additionalName": "", "givenName": "Darko", "email": ""}, {"name": "Darst, Richard K.", "sameAs": [], "familyName": "Darst", "additionalName": "K.", "givenName": "Richard", "email": ""}, {"name": "Fortunato, Santo", "sameAs": [], "familyName": "Fortunato", "additionalName": "", "givenName": "Santo", "email": ""}], "title": "Community detection in networks: Structural communities versus ground\n  truth", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-01", "2014-12-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.0146", "Phys. Rev. E 90, 062805 (2014)", "doi:10.1103/PhysRevE.90.062805", "oai:arXiv.org:1406.0146"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics", "q-bio"]}}, {"name": "description", "properties": {"description": ["  Algorithms to find communities in networks rely just on structural\ninformation and search for cohesive subsets of nodes. On the other hand, most\nscholars implicitly or explicitly assume that structural communities represent\ngroups of nodes with similar (non-topological) properties or functions. This\nhypothesis could not be verified, so far, because of the lack of network\ndatasets with information on the classification of the nodes. We show that\ntraditional community detection methods fail to find the metadata groups in\nmany large networks. Our results show that there is a marked separation between\nstructural communities and metadata groups, in line with recent findings. That\nmeans that either our current modeling of community structure has to be\nsubstantially modified, or that metadata groups may not be recoverable from\ntopology alone.\n", "Comment: 21 pages, 19 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - information retrieval", "quantitative biology - quantitative methods", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.0146"}}, {"publisher": {"name": ""}, "description": "  In this paper, we consider a distributed detection problem for a censoring\nsensor network where each sensor's communication rate is significantly reduced\nby transmitting only \"informative\" observations to the Fusion Center (FC), and\ncensoring those deemed \"uninformative\". While the independence of data from\ncensoring sensors is often assumed in previous research, we explore spatial\ndependence among observations. Our focus is on designing the fusion rule under\nthe Neyman-Pearson (NP) framework that takes into account the spatial\ndependence among observations. Two transmission scenarios are considered, one\nwhere uncensored observations are transmitted directly to the FC and second\nwhere they are first quantized and then transmitted to further improve\ntransmission efficiency. Copula-based Generalized Likelihood Ratio Test (GLRT)\nfor censored data is proposed with both continuous and discrete messages\nreceived at the FC corresponding to different transmission strategies. We\naddress the computational issues of the copula-based GLRTs involving\nmultidimensional integrals by presenting more efficient fusion rules, based on\nthe key idea of injecting controlled noise at the FC before fusion. Although,\nthe signal-to-noise ratio (SNR) is reduced by introducing controlled noise at\nthe receiver, simulation results demonstrate that the resulting noise-aided\nfusion approach based on adding artificial noise performs very closely to the\nexact copula-based GLRTs. Copula-based GLRTs and their noise-aided counterparts\nby exploiting the spatial dependence greatly improve detection performance\ncompared with the fusion rule under independence assumption.\n", "contributors": [{"name": "He, Hao", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Hao", "email": ""}, {"name": "Varshney, Pramod K.", "sameAs": [], "familyName": "Varshney", "additionalName": "K.", "givenName": "Pramod", "email": ""}], "title": "Fusing Censored Dependent Data for Distributed Detection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07826", "oai:arXiv.org:1503.07826"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  In this paper, we consider a distributed detection problem for a censoring\nsensor network where each sensor's communication rate is significantly reduced\nby transmitting only \"informative\" observations to the Fusion Center (FC), and\ncensoring those deemed \"uninformative\". While the independence of data from\ncensoring sensors is often assumed in previous research, we explore spatial\ndependence among observations. Our focus is on designing the fusion rule under\nthe Neyman-Pearson (NP) framework that takes into account the spatial\ndependence among observations. Two transmission scenarios are considered, one\nwhere uncensored observations are transmitted directly to the FC and second\nwhere they are first quantized and then transmitted to further improve\ntransmission efficiency. Copula-based Generalized Likelihood Ratio Test (GLRT)\nfor censored data is proposed with both continuous and discrete messages\nreceived at the FC corresponding to different transmission strategies. We\naddress the computational issues of the copula-based GLRTs involving\nmultidimensional integrals by presenting more efficient fusion rules, based on\nthe key idea of injecting controlled noise at the FC before fusion. Although,\nthe signal-to-noise ratio (SNR) is reduced by introducing controlled noise at\nthe receiver, simulation results demonstrate that the resulting noise-aided\nfusion approach based on adding artificial noise performs very closely to the\nexact copula-based GLRTs. Copula-based GLRTs and their noise-aided counterparts\nby exploiting the spatial dependence greatly improve detection performance\ncompared with the fusion rule under independence assumption.\n"}}], "languages": [null], "subjects": ["statistics - applications", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07826"}}, {"publisher": {"name": "ScholarlyCommons"}, "description": "Epidermal growth factor receptor (EGFR) mutation and overexpression promote tumorigenesis in multiple cancers. Understanding the complex EGFR regulatory network is critical for developing effective therapeutic interventions. To this end, this work investigated the functions of two incompletely characterized regulators of EGFR trafficking and signaling, mitogen-inducible gene 6 (MIG6) and Sprouty2 (SPRY2), in two cancer settings where EGFR mutation is common, non-small cell lung cancer (NSCLC) and glioblastoma multiforme (GBM). In NSCLC cells, results indicate that MIG6, an endogenous inhibitor of EGFR activity and endocytic adaptor, is surprisingly responsible for at least half of EGFR endocytosis, suggesting that a substantial fraction of internalized EGFR may not be competent to drive signaling. Computational modeling further suggested that in cells expressing kinase-activated, endocytosis-impaired EGFR mutants, the importance of MIG6 relative to other endocytic pathways is increased, but that MIG6 internalization capacity is reduced compared to cells expressing wild-type EGFR. Additional data indicate that SPRY2 expression reduces EGFR endocytosis rate primarily by promoting EGFR expression, which overwhelms the saturable EGFR endocytic pathway, but that SPRY2 also promotes ERK phosphorylation and resistance to EGFR inhibition independent of EGFR expression level. In GBM cell lines, our data demonstrate that SPRY2 expression promotes proliferation, anchorage-independent growth, resistance to EGFR and c-MET co-inhibition, and growth as mouse tumor xenografts. Additional studies identified SPRY2-mediated regulation of the strength and effects of JNK and p38 MAP kinase pathways as important for controlling GBM cell behaviors. Through analysis of public datasets and a collaborative analysis of human and rat tumors, we further found that elevated SPRY2 expression is associated with reduced patient survival and expression of EGFR variant III, an EGFR mutant linked to aggressive GBM. Thus, while SPRY2 is a candidate tumor suppressor in other contexts, our results support a tumor promoter role for SPRY2 in GBM and identify SPRY2 and the pathways it regulates as potential therapeutic targets or biomarkers for therapeutic response. Overall, these findings add new qualitative and quantitative understanding of the complexities of EGFR trafficking and signaling regulation and the functions of SPRY2 and MIG6 that may be leveraged to develop improved cancer therapies.", "contributors": [{"name": "Walsh, Alice Macdonald", "sameAs": [], "familyName": "Walsh", "additionalName": "Macdonald", "givenName": "Alice", "email": ""}], "title": "Regulation of cell signaling by MIG6 and Sprouty2 in cancers with EGFR mutations", "shareProperties": {"source": "upennsylvania"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-01-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.upenn.edu/edissertations/1302", "http://repository.upenn.edu/cgi/viewcontent.cgi?article=2426&amp;context=edissertations", "oai:repository.upenn.edu:edissertations-2426"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:be", "publication:edissertations", "publication:seas"]}}, {"name": "source", "properties": {"source": "Publicly Accessible Penn Dissertations"}}, {"name": "rights", "properties": {"rights": []}}], "languages": [null], "subjects": ["cancer", "drug resistance", "feedback", "cell biology", "biomedical", "computational modeling", "signaling"], "providerUpdatedDateTime": "2015-03-16T19:01:32", "uris": {"canonicalUri": "http://repository.upenn.edu/edissertations/1302"}}, {"publisher": {"name": ""}, "description": "  \\noindent We present an algorithm to $3$-colour a graph $G$ without triangles\nor induced paths on seven vertices in $O(|V(G)|^7)$ time. In fact, our\nalgorithm solves the list $3$-colouring problem, where each vertex is assigned\na subset of $\\{1,2,3\\}$ as its admissible colours.\n", "contributors": [{"name": "Bonomo, Flavia", "sameAs": [], "familyName": "Bonomo", "additionalName": "", "givenName": "Flavia", "email": ""}, {"name": "Schaudt, Oliver", "sameAs": [], "familyName": "Schaudt", "additionalName": "", "givenName": "Oliver", "email": ""}, {"name": "Stein, Maya", "sameAs": [], "familyName": "Stein", "additionalName": "", "givenName": "Maya", "email": ""}], "title": "3-Colouring graphs without triangles or induced paths on seven vertices", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-30", "2014-10-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.0040", "oai:arXiv.org:1410.0040"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  \\noindent We present an algorithm to $3$-colour a graph $G$ without triangles\nor induced paths on seven vertices in $O(|V(G)|^7)$ time. In fact, our\nalgorithm solves the list $3$-colouring problem, where each vertex is assigned\na subset of $\\{1,2,3\\}$ as its admissible colours.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-10-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.0040"}}, {"publisher": {"name": ""}, "description": "  Over the past few years, symmetric positive definite (SPD) matrices have been\nreceiving considerable attention from computer vision community. Though various\ndistance measures have been proposed in the past for comparing SPD matrices,\nthe two most widely-used measures are affine-invariant distance and\nlog-Euclidean distance. This is because these two measures are true geodesic\ndistances induced by Riemannian geometry. In this work, we focus on the\nlog-Euclidean Riemannian geometry and propose a data-driven approach for\nlearning Riemannian metrics/geodesic distances for SPD matrices. We show that\nthe geodesic distance learned using the proposed approach performs better than\nvarious existing distance measures when evaluated on face matching and\nclustering tasks.\n", "contributors": [{"name": "Vemulapalli, Raviteja", "sameAs": [], "familyName": "Vemulapalli", "additionalName": "", "givenName": "Raviteja", "email": ""}, {"name": "Jacobs, David W.", "sameAs": [], "familyName": "Jacobs", "additionalName": "W.", "givenName": "David", "email": ""}], "title": "Riemannian Metric Learning for Symmetric Positive Definite Matrices", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.02393", "oai:arXiv.org:1501.02393"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Over the past few years, symmetric positive definite (SPD) matrices have been\nreceiving considerable attention from computer vision community. Though various\ndistance measures have been proposed in the past for comparing SPD matrices,\nthe two most widely-used measures are affine-invariant distance and\nlog-Euclidean distance. This is because these two measures are true geodesic\ndistances induced by Riemannian geometry. In this work, we focus on the\nlog-Euclidean Riemannian geometry and propose a data-driven approach for\nlearning Riemannian metrics/geodesic distances for SPD matrices. We show that\nthe geodesic distance learned using the proposed approach performs better than\nvarious existing distance measures when evaluated on face matching and\nclustering tasks.\n"}}], "languages": [null], "subjects": ["computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.02393"}}, {"publisher": {"name": ""}, "description": "  We present a user-friendly, but powerful interface for the data mining of\nscientific repositories. We present the tool in use with actual astronomy data\nand show how it may be used to achieve many different types of powerful\nsemantic queries. The tool itself hides the gory details of query formulation,\nand data retrieval from the user, and allows the user to create workflows which\nmay be used to transform the data into a convenient form.\n", "contributors": [{"name": "Thomas, Brian", "sameAs": [], "familyName": "Thomas", "additionalName": "", "givenName": "Brian", "email": ""}, {"name": "Shaya, Edward", "sameAs": [], "familyName": "Shaya", "additionalName": "", "givenName": "Edward", "email": ""}], "title": "A User Interface for Semantically Oriented Data Mining of Astronomy\n  Repositories", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06492", "oai:arXiv.org:1502.06492"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:astro-ph"]}}, {"name": "description", "properties": {"description": ["  We present a user-friendly, but powerful interface for the data mining of\nscientific repositories. We present the tool in use with actual astronomy data\nand show how it may be used to achieve many different types of powerful\nsemantic queries. The tool itself hides the gory details of query formulation,\nand data retrieval from the user, and allows the user to create workflows which\nmay be used to transform the data into a convenient form.\n", "Comment: ADASS ASP Conference Series, Vol. 394, Proceedings of the conference\n  held 23-26 September, 2007, in Kensington Town Hall, London, United Kingdom.\n  Edited by Robert W. Argyle, Peter S. Bunclark, and James R. Lewis., p.361"]}}], "languages": [null], "subjects": ["computer science - human-computer interaction", "astrophysics - instrumentation and methods for astrophysics"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06492"}}, {"publisher": {"name": ""}, "description": "  In this work, we consider linear-feedback schemes for the two-user Gaussian\nbroadcast channel with noiseless feedback. We extend the transmission scheme of\n[Ozarow and Leung, 1984] by applying estimators with memory instead of the\nmemoryless estimators used by Ozarow and Leung (OL) in their original work. A\nrecursive formulation of the mean square errors achieved by the proposed\nestimators is provided, along with a proof for the existence of a fixed point.\nThis enables characterizing the achievable rates of the extended scheme.\nFinally, via numerical simulations it is shown that the extended scheme can\nimprove upon the original OL scheme in terms of achievable rates, as well as\nachieve a low probability of error after a finite number of channel uses.\n", "contributors": [{"name": "Murin, Yonathan", "sameAs": [], "familyName": "Murin", "additionalName": "", "givenName": "Yonathan", "email": ""}, {"name": "Kaspi, Yonatan", "sameAs": [], "familyName": "Kaspi", "additionalName": "", "givenName": "Yonatan", "email": ""}, {"name": "Dabora, Ron", "sameAs": [], "familyName": "Dabora", "additionalName": "", "givenName": "Ron", "email": ""}], "title": "On the Ozarow-Leung Scheme for the Gaussian Broadcast Channel with\n  Feedback", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6782", "doi:10.1109/LSP.2014.2375893", "oai:arXiv.org:1412.6782"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this work, we consider linear-feedback schemes for the two-user Gaussian\nbroadcast channel with noiseless feedback. We extend the transmission scheme of\n[Ozarow and Leung, 1984] by applying estimators with memory instead of the\nmemoryless estimators used by Ozarow and Leung (OL) in their original work. A\nrecursive formulation of the mean square errors achieved by the proposed\nestimators is provided, along with a proof for the existence of a fixed point.\nThis enables characterizing the achievable rates of the extended scheme.\nFinally, via numerical simulations it is shown that the extended scheme can\nimprove upon the original OL scheme in terms of achievable rates, as well as\nachieve a low probability of error after a finite number of channel uses.\n", "Comment: Accepted to IEEE Signal Processing Letters"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6782"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "by William Q. Hubbard, Jr.", "contributors": [{"name": "Hubbard, Bill, 1947-", "sameAs": [], "familyName": "Hubbard", "additionalName": "", "givenName": "Bill", "email": ""}, {"name": "Stanford Anderson.", "sameAs": [], "familyName": "Anderson.", "additionalName": "", "givenName": "Stanford", "email": ""}], "title": "A system of formal analysis for architectural composition", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "193 leaves"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/67370", "02660500", "oai:dspace.mit.edu:1721.1/67370"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2011-12-05T19:45:42Z", "2011-12-05T19:45:42Z", "1976"]}}, {"name": "description", "properties": {"description": ["by William Q. Hubbard, Jr.", "Thesis. 1976. M.ArchAS--Massachusetts Institute of Technology. Dept. of Architecture.", "Microfiche copy available in Archives and Rotch.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7635", "hdl_1721.1_7772"]}}], "languages": [null], "subjects": ["architecture conservation and restoration designs and plans", "proportion", "etc", "architecture", "architecture composition", "architectural design", "architecture history"], "providerUpdatedDateTime": "2015-04-27T15:30:03", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/67370"}}, {"publisher": {"name": ""}, "description": "  We propose a multicast scheduling scheme to exploit content reuse when there\nis asynchronicity in user requests. A unicast transmission setup is used for\ncontent delivery, while multicast transmission is employed opportunistically to\nreduce wireless resource usage. We then develop a multicast scheduling scheme\nfor the downlink multiple-input multiple output orthogonal-frequency division\nmultiplexing system in IEEE 802.11 wireless local area network (WLAN). At each\ntime slot, the scheduler serves the users by either unicast or multicast\ntransmission. Out-sequence data received by a user is stored in user's cache\nfor future use.Multicast precoding and user selection for multicast grouping\nare also considered and compliance with the IEEE 802.11 WLAN transmission\nprotocol. The scheduling scheme is based on the Lyapunov optimization\ntechnique, which aims to maximize system rate. The resulting scheme has low\ncomplexity and requires no prior statistical information on the channels and\nqueues. Furthermore, in the absence of channel error, the proposed scheme\nrestricts the worst case of frame dropping deadline, which is useful for\ndelivering real-time traffic. Simulation results show that our proposed\nalgorithm outperforms existing techniques by 17 % to 35 % in term of user\ncapacity.\n", "contributors": [{"name": "Tan, Peng Hui", "sameAs": [], "familyName": "Tan", "additionalName": "Hui", "givenName": "Peng", "email": ""}, {"name": "Joung, Jingon", "sameAs": [], "familyName": "Joung", "additionalName": "", "givenName": "Jingon", "email": ""}, {"name": "Sun, Sumei", "sameAs": [], "familyName": "Sun", "additionalName": "", "givenName": "Sumei", "email": ""}], "title": "Opportunistic Multicast Scheduling for Unicast Transmission in MIMO-OFDM\n  System", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2714", "oai:arXiv.org:1411.2714"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We propose a multicast scheduling scheme to exploit content reuse when there\nis asynchronicity in user requests. A unicast transmission setup is used for\ncontent delivery, while multicast transmission is employed opportunistically to\nreduce wireless resource usage. We then develop a multicast scheduling scheme\nfor the downlink multiple-input multiple output orthogonal-frequency division\nmultiplexing system in IEEE 802.11 wireless local area network (WLAN). At each\ntime slot, the scheduler serves the users by either unicast or multicast\ntransmission. Out-sequence data received by a user is stored in user's cache\nfor future use.Multicast precoding and user selection for multicast grouping\nare also considered and compliance with the IEEE 802.11 WLAN transmission\nprotocol. The scheduling scheme is based on the Lyapunov optimization\ntechnique, which aims to maximize system rate. The resulting scheme has low\ncomplexity and requires no prior statistical information on the channels and\nqueues. Furthermore, in the absence of channel error, the proposed scheme\nrestricts the worst case of frame dropping deadline, which is useful for\ndelivering real-time traffic. Simulation results show that our proposed\nalgorithm outperforms existing techniques by 17 % to 35 % in term of user\ncapacity.\n", "Comment: 6 pages, conference"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2714"}}, {"publisher": {"name": ""}, "description": "  A network supporting deep unsupervised learning is presented. The network is\nan autoencoder with lateral shortcut connections from the encoder to decoder at\neach level of the hierarchy. The lateral shortcut connections allow the higher\nlevels of the hierarchy to focus on abstract invariant features. While standard\nautoencoders are analogous to latent variable models with a single layer of\nstochastic variables, the proposed network is analogous to hierarchical latent\nvariables models. Learning combines denoising autoencoder and denoising sources\nseparation frameworks. Each layer of the network contributes to the cost\nfunction a term which measures the distance of the representations produced by\nthe encoder and the decoder. Since training signals originate from all levels\nof the network, all layers can learn efficiently even in deep networks. The\nspeedup offered by cost terms from higher levels of the hierarchy and the\nability to learn invariant features are demonstrated in experiments.\n", "contributors": [{"name": "Valpola, Harri", "sameAs": [], "familyName": "Valpola", "additionalName": "", "givenName": "Harri", "email": ""}], "title": "From neural PCA to deep unsupervised learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-28", "2015-02-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7783", "oai:arXiv.org:1411.7783"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  A network supporting deep unsupervised learning is presented. The network is\nan autoencoder with lateral shortcut connections from the encoder to decoder at\neach level of the hierarchy. The lateral shortcut connections allow the higher\nlevels of the hierarchy to focus on abstract invariant features. While standard\nautoencoders are analogous to latent variable models with a single layer of\nstochastic variables, the proposed network is analogous to hierarchical latent\nvariables models. Learning combines denoising autoencoder and denoising sources\nseparation frameworks. Each layer of the network contributes to the cost\nfunction a term which measures the distance of the representations produced by\nthe encoder and the decoder. Since training signals originate from all levels\nof the network, all layers can learn efficiently even in deep networks. The\nspeedup offered by cost terms from higher levels of the hierarchy and the\nability to learn invariant features are demonstrated in experiments.\n", "Comment: A revised version of an article that has been accepted for\n  publication in Advances in Independent Component Analysis and Learning\n  Machines (2015), edited by Ella Bingham, Samuel Kaski, Jorma Laaksonen and\n  Jouko Lampinen"]}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7783"}}, {"publisher": {"name": ""}, "description": "  In the classical cop and robber game, two players, the cop C and the robber\nR, move alternatively along edges of a finite graph G. The cop captures the\nrobber if both players are on the same vertex at the same moment of time. A\ngraph G is called cop win if the cop always captures the robber after a finite\nnumber of steps. Nowakowski, Winkler (1983) and Quilliot (1983) characterized\nthe cop-win graphs as graphs admitting a dismantling scheme. In this paper, we\ncharacterize in a similar way the class CW(s,s') of cop-win graphs in the game\nin which the cop and the robber move at different speeds s' and s, s'<= s. We\nalso establish some connections between cop-win graphs for this game with s'<s\nand Gromov's hyperbolicity. In the particular case s'=1 and s=2, we prove that\nthe class of cop-win graphs is exactly the well-known class of dually chordal\ngraphs. We show that all classes CW(s,1), s>=3, coincide and we provide a\nstructural characterization of these graphs. We also investigate several\ndismantling schemes necessary or sufficient for the cop-win graphs in the game\nin which the robber is visible only every k moves for a fixed integer k>1. We\ncharacterize the graphs which are cop-win for any value of k. Finally, we\nconsider the game where the cop wins if he is at distance at most 1 from the\nrobber and we characterize via a specific dismantling scheme the bipartite\ngraphs where a single cop wins in this game.\n", "contributors": [{"name": "Chalopin, J\u00e9r\u00e9mie", "sameAs": [], "familyName": "Chalopin", "additionalName": "", "givenName": "J\u00e9r\u00e9mie", "email": ""}, {"name": "Chepoi, Victor", "sameAs": [], "familyName": "Chepoi", "additionalName": "", "givenName": "Victor", "email": ""}, {"name": "Nisse, Nicolas", "sameAs": [], "familyName": "Nisse", "additionalName": "", "givenName": "Nicolas", "email": ""}, {"name": "Vax\u00e8s, Yann", "sameAs": [], "familyName": "Vax\u00e8s", "additionalName": "", "givenName": "Yann", "email": ""}], "title": "Cop and robber games when the robber can hide and ride", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-01-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1001.4457", "SIAM J. Discrete Math. 25(2011) 333-359", "oai:arXiv.org:1001.4457"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In the classical cop and robber game, two players, the cop C and the robber\nR, move alternatively along edges of a finite graph G. The cop captures the\nrobber if both players are on the same vertex at the same moment of time. A\ngraph G is called cop win if the cop always captures the robber after a finite\nnumber of steps. Nowakowski, Winkler (1983) and Quilliot (1983) characterized\nthe cop-win graphs as graphs admitting a dismantling scheme. In this paper, we\ncharacterize in a similar way the class CW(s,s') of cop-win graphs in the game\nin which the cop and the robber move at different speeds s' and s, s'<= s. We\nalso establish some connections between cop-win graphs for this game with s'<s\nand Gromov's hyperbolicity. In the particular case s'=1 and s=2, we prove that\nthe class of cop-win graphs is exactly the well-known class of dually chordal\ngraphs. We show that all classes CW(s,1), s>=3, coincide and we provide a\nstructural characterization of these graphs. We also investigate several\ndismantling schemes necessary or sufficient for the cop-win graphs in the game\nin which the robber is visible only every k moves for a fixed integer k>1. We\ncharacterize the graphs which are cop-win for any value of k. Finally, we\nconsider the game where the cop wins if he is at distance at most 1 from the\nrobber and we characterize via a specific dismantling scheme the bipartite\ngraphs where a single cop wins in this game.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1001.4457"}}, {"publisher": {"name": ""}, "description": "  Decision support system in Requirements engineering plays an important role\nin software development life cycle. The relationship between functional and\nnon-functional requirements often plays a crucial role in resolving conflicts\nor arriving at decisions in requirements engineering phase. Goal-Oriented\nRequirements Engineering (GORE) methods make a good attempt of addressing these\naspects which are helpful in decision support. We propose a GORE method -\nIntegrating goals after prioritization and evaluation (IGAPE). The method is\nsemi-formal in nature thereby ensuring active stakeholder participation. In\nthis paper we elaborate the various steps of IGAPE method. The output of IGAPE\nis then given as input to a decision support system which makes use of Analytic\nHierarchy Process (AHP) and Technique for Order of Preference by Similarity to\nIdeal Solution (TOPSIS). Integration of IGAPE with AHP and TOPSIS will clearly\nprovide a rationale for various decisions which are arrived at during the\nrequirements engineering phase. The method is illustrated for an e-commerce\napplication and is validated by expert analysis approach.\n", "contributors": [{"name": "Vinay, S", "sameAs": [], "familyName": "Vinay", "additionalName": "", "givenName": "S", "email": ""}, {"name": "Aithal, Shridhar", "sameAs": [], "familyName": "Aithal", "additionalName": "", "givenName": "Shridhar", "email": ""}, {"name": "Adiga, Sudhakara", "sameAs": [], "familyName": "Adiga", "additionalName": "", "givenName": "Sudhakara", "email": ""}], "title": "Integrating goals after prioritization and evaluation-A Goal-oriented\n  requirements engineering method", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2588", "doi:10.5121/ijsea.2014.5604", "oai:arXiv.org:1412.2588"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Decision support system in Requirements engineering plays an important role\nin software development life cycle. The relationship between functional and\nnon-functional requirements often plays a crucial role in resolving conflicts\nor arriving at decisions in requirements engineering phase. Goal-Oriented\nRequirements Engineering (GORE) methods make a good attempt of addressing these\naspects which are helpful in decision support. We propose a GORE method -\nIntegrating goals after prioritization and evaluation (IGAPE). The method is\nsemi-formal in nature thereby ensuring active stakeholder participation. In\nthis paper we elaborate the various steps of IGAPE method. The output of IGAPE\nis then given as input to a decision support system which makes use of Analytic\nHierarchy Process (AHP) and Technique for Order of Preference by Similarity to\nIdeal Solution (TOPSIS). Integration of IGAPE with AHP and TOPSIS will clearly\nprovide a rationale for various decisions which are arrived at during the\nrequirements engineering phase. The method is illustrated for an e-commerce\napplication and is validated by expert analysis approach.\n", "Comment: IJSEA 2014"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2588"}}, {"publisher": {"name": ""}, "description": "  We investigate compressibility of the dimension of positive semidefinite\nmatrices while approximately preserving their pairwise inner products. This can\neither be regarded as compression of positive semidefinite factorizations of\nnonnegative matrices or (if the matrices are subject to additional\nnormalization constraints) as compression of quantum models. We derive both\nlower and upper bounds on compressibility. Applications are broad and range\nfrom the statistical analysis of experimental data to bounding the one-way\nquantum communication complexity of Boolean functions.\n", "contributors": [{"name": "Stark, Cyril J.", "sameAs": [], "familyName": "Stark", "additionalName": "J.", "givenName": "Cyril", "email": ""}, {"name": "Harrow, Aram W.", "sameAs": [], "familyName": "Harrow", "additionalName": "W.", "givenName": "Aram", "email": ""}], "title": "Compressibility of positive semidefinite factorizations and quantum\n  models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7437", "oai:arXiv.org:1412.7437"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": ["  We investigate compressibility of the dimension of positive semidefinite\nmatrices while approximately preserving their pairwise inner products. This can\neither be regarded as compression of positive semidefinite factorizations of\nnonnegative matrices or (if the matrices are subject to additional\nnormalization constraints) as compression of quantum models. We derive both\nlower and upper bounds on compressibility. Applications are broad and range\nfrom the statistical analysis of experimental data to bounding the one-way\nquantum communication complexity of Boolean functions.\n", "Comment: 13 pages"]}}], "languages": [null], "subjects": ["quantum physics", "computer science - information theory"], "providerUpdatedDateTime": "2014-12-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7437"}}, {"publisher": {"name": ""}, "description": "  In this paper, we study top-$k$ aggregate (or group) nearest neighbor queries\nusing the weighted SUM operator under the $L_1$ metric in the plane. Given a\nset $P$ of $n$ points, for any query consisting of a set $Q$ of $m$ weighted\npoints and an integer $k$, $ 1 \\le k \\le n$, the top-$k$ aggregate nearest\nneighbor query asks for the $k$ points of $P$ whose aggregate distances to $Q$\nare the smallest, where the aggregate distance of each point $p$ of $P$ to $Q$\nis the sum of the weighted distances from $p$ to all points of $Q$. We build an\n$O(n\\log n\\log\\log n)$-size data structure in $O(n\\log n \\log\\log n)$ time,\nsuch that each top-$k$ query can be answered in $O(m\\log m+(k+m)\\log^2 n)$\ntime. We also obtain other results with trade-off between preprocessing and\nquery. Even for the special case where $k=1$, our results are better than the\npreviously best method (in PODS 2012), which requires $O(n\\log^2 n)$\npreprocessing time, $O(n\\log^2 n)$ space, and $O(m^2\\log^3 n)$ query time. In\naddition, for the one-dimensional version of this problem, our approach can\nbuild an $O(n)$-size data structure in $O(n\\log n)$ time that can support\n$O(\\min\\{k,\\log m\\}\\cdot m+k+\\log n)$ time queries. Further, we extend our\ntechniques to the top-$k$ aggregate farthest neighbor queries, with the same\nbounds.\n", "contributors": [{"name": "Wang, Haitao", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Haitao", "email": ""}, {"name": "Zhang, Wuzhou", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Wuzhou", "email": ""}], "title": "On Top-$k$ Weighted SUM Aggregate Nearest and Farthest Neighbors in the\n  $L_1$ Plane", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-11-21", "2014-11-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1211.5084", "oai:arXiv.org:1211.5084"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we study top-$k$ aggregate (or group) nearest neighbor queries\nusing the weighted SUM operator under the $L_1$ metric in the plane. Given a\nset $P$ of $n$ points, for any query consisting of a set $Q$ of $m$ weighted\npoints and an integer $k$, $ 1 \\le k \\le n$, the top-$k$ aggregate nearest\nneighbor query asks for the $k$ points of $P$ whose aggregate distances to $Q$\nare the smallest, where the aggregate distance of each point $p$ of $P$ to $Q$\nis the sum of the weighted distances from $p$ to all points of $Q$. We build an\n$O(n\\log n\\log\\log n)$-size data structure in $O(n\\log n \\log\\log n)$ time,\nsuch that each top-$k$ query can be answered in $O(m\\log m+(k+m)\\log^2 n)$\ntime. We also obtain other results with trade-off between preprocessing and\nquery. Even for the special case where $k=1$, our results are better than the\npreviously best method (in PODS 2012), which requires $O(n\\log^2 n)$\npreprocessing time, $O(n\\log^2 n)$ space, and $O(m^2\\log^3 n)$ query time. In\naddition, for the one-dimensional version of this problem, our approach can\nbuild an $O(n)$-size data structure in $O(n\\log n)$ time that can support\n$O(\\min\\{k,\\log m\\}\\cdot m+k+\\log n)$ time queries. Further, we extend our\ntechniques to the top-$k$ aggregate farthest neighbor queries, with the same\nbounds.\n", "Comment: 24 pages; this version extends our results in the previous version to\n  more general problem settings, and the title has been changed accordingly"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - databases", "computer science - computational geometry"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1211.5084"}}, {"publisher": {"name": ""}, "description": "  Approximating non-linear kernels using feature maps has gained a lot of\ninterest in recent years due to applications in reducing training and testing\ntimes of SVM classifiers and other kernel based learning algorithms. We extend\nthis line of work and present low distortion embeddings for dot product kernels\ninto linear Euclidean spaces. We base our results on a classical result in\nharmonic analysis characterizing all dot product kernels and use it to define\nrandomized feature maps into explicit low dimensional Euclidean spaces in which\nthe native dot product provides an approximation to the dot product kernel with\nhigh confidence.\n", "contributors": [{"name": "Kar, Purushottam", "sameAs": [], "familyName": "Kar", "additionalName": "", "givenName": "Purushottam", "email": ""}, {"name": "Karnick, Harish", "sameAs": [], "familyName": "Karnick", "additionalName": "", "givenName": "Harish", "email": ""}], "title": "Random Feature Maps for Dot Product Kernels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-01-31", "2012-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1201.6530", "Journal of Machine Learning Research, W&CP 22 (2012) 583-591", "oai:arXiv.org:1201.6530"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  Approximating non-linear kernels using feature maps has gained a lot of\ninterest in recent years due to applications in reducing training and testing\ntimes of SVM classifiers and other kernel based learning algorithms. We extend\nthis line of work and present low distortion embeddings for dot product kernels\ninto linear Euclidean spaces. We base our results on a classical result in\nharmonic analysis characterizing all dot product kernels and use it to define\nrandomized feature maps into explicit low dimensional Euclidean spaces in which\nthe native dot product provides an approximation to the dot product kernel with\nhigh confidence.\n", "Comment: To appear in the proceedings of the 15th International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2012). This version corrects\n  a minor error with Lemma 10. Acknowledgements : Devanshu Bhimwal"]}}], "languages": [null], "subjects": ["statistics - machine learning", "computer science - learning", "mathematics - functional analysis", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1201.6530"}}, {"publisher": {"name": ""}, "description": "  We introduce a learning-based approach to detect repeatable keypoints under\ndrastic imaging changes of weather and lighting conditions to which\nstate-of-the-art keypoint detectors are surprisingly sensitive. We first\nidentify good keypoint candidates in multiple training images taken from the\nsame viewpoint. We then train a regressor to predict a score map whose maxima\nare those points so that they can be found by simple non-maximum suppression.\nAs there are no standard datasets to test the influence of these kinds of\nchanges, we created our own, which we will make publicly available. We will\nshow that our method significantly outperforms the state-of-the-art methods in\nsuch challenging conditions, while still achieving state-of-the-art performance\non the untrained standard Oxford dataset.\n", "contributors": [{"name": "Verdie, Yannick", "sameAs": [], "familyName": "Verdie", "additionalName": "", "givenName": "Yannick", "email": ""}, {"name": "Yi, Kwang Moo", "sameAs": [], "familyName": "Yi", "additionalName": "Moo", "givenName": "Kwang", "email": ""}, {"name": "Fua, Pascal", "sameAs": [], "familyName": "Fua", "additionalName": "", "givenName": "Pascal", "email": ""}, {"name": "Lepetit, Vincent", "sameAs": [], "familyName": "Lepetit", "additionalName": "", "givenName": "Vincent", "email": ""}], "title": "TILDE: A Temporally Invariant Learned DEtector", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-17", "2015-03-12"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4568", "oai:arXiv.org:1411.4568"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We introduce a learning-based approach to detect repeatable keypoints under\ndrastic imaging changes of weather and lighting conditions to which\nstate-of-the-art keypoint detectors are surprisingly sensitive. We first\nidentify good keypoint candidates in multiple training images taken from the\nsame viewpoint. We then train a regressor to predict a score map whose maxima\nare those points so that they can be found by simple non-maximum suppression.\nAs there are no standard datasets to test the influence of these kinds of\nchanges, we created our own, which we will make publicly available. We will\nshow that our method significantly outperforms the state-of-the-art methods in\nsuch challenging conditions, while still achieving state-of-the-art performance\non the untrained standard Oxford dataset.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4568"}}, {"publisher": {"name": ""}, "description": "  We develop a framework for extracting a concise representation of the shape\ninformation available from diffuse shading in a small image patch. This\nproduces a mid-level scene descriptor, comprised of local shape distributions\nthat are inferred separately at every image patch across multiple scales. The\nframework is based on a quadratic representation of local shape that, in the\nabsence of noise, has guarantees on recovering accurate local shape and\nlighting. And when noise is present, the inferred local shape distributions\nprovide useful shape information without over-committing to any particular\nimage explanation. These local shape distributions naturally encode the fact\nthat some smooth diffuse regions are more informative than others, and they\nenable efficient and robust reconstruction of object-scale shape. Experimental\nresults show that this approach to surface reconstruction compares well against\nthe state-of-art on both synthetic images and captured photographs.\n", "contributors": [{"name": "Xiong, Ying", "sameAs": [], "familyName": "Xiong", "additionalName": "", "givenName": "Ying", "email": ""}, {"name": "Chakrabarti, Ayan", "sameAs": [], "familyName": "Chakrabarti", "additionalName": "", "givenName": "Ayan", "email": ""}, {"name": "Basri, Ronen", "sameAs": [], "familyName": "Basri", "additionalName": "", "givenName": "Ronen", "email": ""}, {"name": "Gortler, Steven J.", "sameAs": [], "familyName": "Gortler", "additionalName": "J.", "givenName": "Steven", "email": ""}, {"name": "Jacobs, David W.", "sameAs": [], "familyName": "Jacobs", "additionalName": "W.", "givenName": "David", "email": ""}, {"name": "Zickler, Todd", "sameAs": [], "familyName": "Zickler", "additionalName": "", "givenName": "Todd", "email": ""}], "title": "From Shading to Local Shape", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-10", "2014-04-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.2916", "IEEE Trans. PAMI 37 (2015) 67-79", "doi:10.1109/TPAMI.2014.2343211", "oai:arXiv.org:1310.2916"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We develop a framework for extracting a concise representation of the shape\ninformation available from diffuse shading in a small image patch. This\nproduces a mid-level scene descriptor, comprised of local shape distributions\nthat are inferred separately at every image patch across multiple scales. The\nframework is based on a quadratic representation of local shape that, in the\nabsence of noise, has guarantees on recovering accurate local shape and\nlighting. And when noise is present, the inferred local shape distributions\nprovide useful shape information without over-committing to any particular\nimage explanation. These local shape distributions naturally encode the fact\nthat some smooth diffuse regions are more informative than others, and they\nenable efficient and robust reconstruction of object-scale shape. Experimental\nresults show that this approach to surface reconstruction compares well against\nthe state-of-art on both synthetic images and captured photographs.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-04-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.2916"}}, {"publisher": {"name": ""}, "description": "  In this letter, we present the first characterization for the achievable\nDegrees-of-Freedom (DoF) by Blind Interference Alignment (BIA) using staggered\nantenna switching in the $K$-user Gaussian Interference Channel. In such\nscheme, each transmitter is equipped with one conventional antenna and each\nreceiver is equipped with one reconfigurable (multi-mode) antenna. Assuming\nthat the channel is known to the receivers only, we show that BIA can achieve\n$\\frac{2K}{K+2}$ DoF, which surpasses the sum DoF achieved by previously known\ninterference alignment schemes with delayed channel state information at\ntransmitters (CSIT). This result implies that the sum DoF is upper bounded by\n2, which means that the best we can do with BIA is to double the DoF achieved\nby orthogonal multiple access schemes. Moreover, we propose an algorithm to\ngenerate the transmit beamforming vectors and the reconfigurable antenna\nswitching patterns, and apply this algorithm to the 4-user SISO Interference\nChannel, showing that $\\frac{4}{3}$ sum DoF is achievable.\n", "contributors": [{"name": "Alaa, Ahmed M.", "sameAs": [], "familyName": "Alaa", "additionalName": "M.", "givenName": "Ahmed", "email": ""}, {"name": "Ismail, Mahmoud H.", "sameAs": [], "familyName": "Ismail", "additionalName": "H.", "givenName": "Mahmoud", "email": ""}], "title": "Degrees-of-Freedom of the K-user SISO Interference Channel with Blind\n  Interference Alignment using Staggered Antenna Switching", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-27", "2014-12-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6427", "oai:arXiv.org:1408.6427"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this letter, we present the first characterization for the achievable\nDegrees-of-Freedom (DoF) by Blind Interference Alignment (BIA) using staggered\nantenna switching in the $K$-user Gaussian Interference Channel. In such\nscheme, each transmitter is equipped with one conventional antenna and each\nreceiver is equipped with one reconfigurable (multi-mode) antenna. Assuming\nthat the channel is known to the receivers only, we show that BIA can achieve\n$\\frac{2K}{K+2}$ DoF, which surpasses the sum DoF achieved by previously known\ninterference alignment schemes with delayed channel state information at\ntransmitters (CSIT). This result implies that the sum DoF is upper bounded by\n2, which means that the best we can do with BIA is to double the DoF achieved\nby orthogonal multiple access schemes. Moreover, we propose an algorithm to\ngenerate the transmit beamforming vectors and the reconfigurable antenna\nswitching patterns, and apply this algorithm to the 4-user SISO Interference\nChannel, showing that $\\frac{4}{3}$ sum DoF is achievable.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6427"}}, {"publisher": {"name": ""}, "description": "  One of the frustrating things in the digital fabrication era is that its\nmedia are neither affordable nor easily accessible and usable.\nThree-dimensional (3D) fabrication media (DFM) such as 3D Printers and 3D\nScanners have experienced an upsurge in popularity, while the latter remain\nexpensive and hard to function. With this paper, we aim to present you the\nRhoScanner Project - a an affordable and efficient Three-dimensional Projective\nScanner for Smart-phones, hence shedding light on the extended capabilities of\ndigital fabrication media on popular use.\n", "contributors": [{"name": "Papachristou, Marios", "sameAs": [], "familyName": "Papachristou", "additionalName": "", "givenName": "Marios", "email": ""}], "title": "Designing and Building a Three-dimensional Projective Scanner for\n  Smartphones", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04315", "oai:arXiv.org:1503.04315"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  One of the frustrating things in the digital fabrication era is that its\nmedia are neither affordable nor easily accessible and usable.\nThree-dimensional (3D) fabrication media (DFM) such as 3D Printers and 3D\nScanners have experienced an upsurge in popularity, while the latter remain\nexpensive and hard to function. With this paper, we aim to present you the\nRhoScanner Project - a an affordable and efficient Three-dimensional Projective\nScanner for Smart-phones, hence shedding light on the extended capabilities of\ndigital fabrication media on popular use.\n"}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04315"}}, {"publisher": {"name": ""}, "description": "  Distributed Denial of Service (DDoS) attacks have become more prominent\nrecently, both in frequency of occurrence, as well as magnitude. Such attacks\nrender key Internet resources unavailable and disrupt its normal operation. It\nis therefore of paramount importance to quickly identify malicious Internet\nactivity. The DDoS threat model includes characteristics such as: (i)\nheavy-hitters that transmit large volumes of traffic towards \"victims\", (ii)\npersistent-hitters that send traffic, not necessarily large, to specific\ndestinations to be used as attack facilitators, (iii) host and port scanning\nfor compiling lists of un-secure servers to be used as attack amplifiers, etc.\nThis conglomeration of problems motivates the development of space/time\nefficient summaries of data traffic streams that can be used to identify\nheavy-hitters associated with the above attack vectors. This paper presents a\nhashing-based framework and fast algorithms that take into account the\nlarge-dimensionality of the incoming network stream and can be employed to\nquickly identify the culprits. The algorithms and data structures proposed\nprovide a synopsis of the network stream that is not taxing to fast-memory, and\ncan be efficiently implemented in hardware due to simple bit-wise operations.\nThe methods are evaluated using real-world Internet data from a large academic\nnetwork.\n", "contributors": [{"name": "Kallitsis, Michael", "sameAs": [], "familyName": "Kallitsis", "additionalName": "", "givenName": "Michael", "email": ""}, {"name": "Stoev, Stilian", "sameAs": [], "familyName": "Stoev", "additionalName": "", "givenName": "Stilian", "email": ""}, {"name": "Michailidis, George", "sameAs": [], "familyName": "Michailidis", "additionalName": "", "givenName": "George", "email": ""}], "title": "Hashing Pursuit for Online Identification of Heavy-Hitters in High-Speed\n  Network Streams", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6148", "oai:arXiv.org:1412.6148"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Distributed Denial of Service (DDoS) attacks have become more prominent\nrecently, both in frequency of occurrence, as well as magnitude. Such attacks\nrender key Internet resources unavailable and disrupt its normal operation. It\nis therefore of paramount importance to quickly identify malicious Internet\nactivity. The DDoS threat model includes characteristics such as: (i)\nheavy-hitters that transmit large volumes of traffic towards \"victims\", (ii)\npersistent-hitters that send traffic, not necessarily large, to specific\ndestinations to be used as attack facilitators, (iii) host and port scanning\nfor compiling lists of un-secure servers to be used as attack amplifiers, etc.\nThis conglomeration of problems motivates the development of space/time\nefficient summaries of data traffic streams that can be used to identify\nheavy-hitters associated with the above attack vectors. This paper presents a\nhashing-based framework and fast algorithms that take into account the\nlarge-dimensionality of the incoming network stream and can be employed to\nquickly identify the culprits. The algorithms and data structures proposed\nprovide a synopsis of the network stream that is not taxing to fast-memory, and\ncan be efficiently implemented in hardware due to simple bit-wise operations.\nThe methods are evaluated using real-world Internet data from a large academic\nnetwork.\n", "Comment: 14 pages"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - cryptography and security", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6148"}}, {"publisher": {"name": ""}, "description": "  We study two fundamental problems related to finding subgraphs: (1) given\ngraphs G and H, Subgraph Test asks if H is isomorphic to a subgraph of G, (2)\ngiven graphs G, H, and an integer t, Packing asks if G contains t\nvertex-disjoint subgraphs isomorphic to H. For every graph class F, let\nF-Subgraph Test and F-Packing be the special cases of the two problems where H\nis restricted to be in F. Our goal is to study which classes F make the two\nproblems tractable in one of the following senses:\n  * (randomized) polynomial-time solvable,\n  * admits a polynomial (many-one) kernel, or\n  * admits a polynomial Turing kernel (that is, has an adaptive polynomial-time\nprocedure that reduces the problem to a polynomial number of instances, each of\nwhich has size bounded polynomially by the size of the solution).\n  We identify a simple combinatorial property such that if a hereditary class F\nhas this property, then F-Packing admits a polynomial kernel, and has no\npolynomial (many-one) kernel otherwise, unless the polynomial hierarchy\ncollapses. Furthermore, if F does not have this property, then F-Packing is\neither WK[1]-hard, W[1]-hard, or Long Path-hard, giving evidence that it does\nnot admit polynomial Turing kernels either.\n  For F-Subgraph Test, we show that if every graph of a hereditary class F\nsatisfies the property that it is possible to delete a bounded number of\nvertices such that every remaining component has size at most two, then\nF-Subgraph Test is solvable in randomized polynomial time and it is NP-hard\notherwise. We introduce a combinatorial property called (a,b,c,d)-splittability\nand show that if every graph in a hereditary class F has this property, then\nF-Subgraph Test admits a polynomial Turing kernel and it is WK[1]-hard,\nW[1]-hard, or Long Path-hard, otherwise.\n", "contributors": [{"name": "Jansen, Bart M. P.", "sameAs": [], "familyName": "Jansen", "additionalName": "M. P.", "givenName": "Bart", "email": ""}, {"name": "Marx, D\u00e1niel", "sameAs": [], "familyName": "Marx", "additionalName": "", "givenName": "D\u00e1niel", "email": ""}], "title": "Characterizing the easy-to-find subgraphs from the viewpoint of\n  polynomial-time algorithms, kernels, and Turing kernels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.0855", "oai:arXiv.org:1410.0855"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study two fundamental problems related to finding subgraphs: (1) given\ngraphs G and H, Subgraph Test asks if H is isomorphic to a subgraph of G, (2)\ngiven graphs G, H, and an integer t, Packing asks if G contains t\nvertex-disjoint subgraphs isomorphic to H. For every graph class F, let\nF-Subgraph Test and F-Packing be the special cases of the two problems where H\nis restricted to be in F. Our goal is to study which classes F make the two\nproblems tractable in one of the following senses:\n  * (randomized) polynomial-time solvable,\n  * admits a polynomial (many-one) kernel, or\n  * admits a polynomial Turing kernel (that is, has an adaptive polynomial-time\nprocedure that reduces the problem to a polynomial number of instances, each of\nwhich has size bounded polynomially by the size of the solution).\n  We identify a simple combinatorial property such that if a hereditary class F\nhas this property, then F-Packing admits a polynomial kernel, and has no\npolynomial (many-one) kernel otherwise, unless the polynomial hierarchy\ncollapses. Furthermore, if F does not have this property, then F-Packing is\neither WK[1]-hard, W[1]-hard, or Long Path-hard, giving evidence that it does\nnot admit polynomial Turing kernels either.\n  For F-Subgraph Test, we show that if every graph of a hereditary class F\nsatisfies the property that it is possible to delete a bounded number of\nvertices such that every remaining component has size at most two, then\nF-Subgraph Test is solvable in randomized polynomial time and it is NP-hard\notherwise. We introduce a combinatorial property called (a,b,c,d)-splittability\nand show that if every graph in a hereditary class F has this property, then\nF-Subgraph Test admits a polynomial Turing kernel and it is WK[1]-hard,\nW[1]-hard, or Long Path-hard, otherwise.\n", "Comment: 69 pages, extended abstract to appear in the proceedings of SODA 2015"]}}], "languages": [null], "subjects": ["g.2.2", "f.2.2", "computer science - computational complexity", "68q17", "computer science - data structures and algorithms", "68r10"], "providerUpdatedDateTime": "2014-10-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.0855"}}, {"publisher": {"name": ""}, "description": "  In this paper, we introduce a new class of transform method --- the\narithmetic cosine transform (ACT). We provide the central mathematical\nproperties of the ACT, necessary in designing efficient and accurate\nimplementations of the new transform method. The key mathematical tools used in\nthe paper come from analytic number theory, in particular the properties of the\nRiemann zeta function. Additionally, we demonstrate that an exact signal\ninterpolation is achievable for any block-length. Approximate calculations were\nalso considered. The numerical examples provided show the potential of the ACT\nfor various digital signal processing applications.\n", "contributors": [{"name": "Cintra, R. J.", "sameAs": [], "familyName": "Cintra", "additionalName": "J.", "givenName": "R.", "email": ""}, {"name": "Dimitrov, V. S.", "sameAs": [], "familyName": "Dimitrov", "additionalName": "S.", "givenName": "V.", "email": ""}], "title": "The Arithmetic Cosine Transform: Exact and Approximate Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01377", "IEEE Transactions on Signal Processing, vol. 58, no. 6, pp.\n  3076-3085, June 2010", "doi:10.1109/TSP.2010.2045781", "oai:arXiv.org:1502.01377"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  In this paper, we introduce a new class of transform method --- the\narithmetic cosine transform (ACT). We provide the central mathematical\nproperties of the ACT, necessary in designing efficient and accurate\nimplementations of the new transform method. The key mathematical tools used in\nthe paper come from analytic number theory, in particular the properties of the\nRiemann zeta function. Additionally, we demonstrate that an exact signal\ninterpolation is achievable for any block-length. Approximate calculations were\nalso considered. The numerical examples provided show the potential of the ACT\nfor various digital signal processing applications.\n", "Comment: 17 pages, 3 figures"]}}], "languages": [null], "subjects": ["statistics - applications", "mathematics - numerical analysis", "statistics - methodology", "computer science - numerical analysis", "statistics - computation"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01377"}}, {"publisher": {"name": "American Diabetes Association"}, "description": "Differences in susceptibility to diabetic nephropathy (DN) between mouse strains with identical levels of hyperglycemia correlate with renal levels of oxidative stress, shown previously to play a central role in the pathogenesis of DN. Susceptibility to DN appears to be genetically determined, but the critical genes have not yet been identified. Overexpression of the enzyme glyoxalase 1 (Glo1), which prevents posttranslational modification of proteins by the glycolysis-derived \u03b1-oxoaldehyde, methylglyoxal (MG), prevents hyperglycemia-induced oxidative stress in cultured cells and model organisms. In this study, we show that in nondiabetic mice, knockdown of Glo1 increases to diabetic levels both MG modification of glomerular proteins and oxidative stress, causing alterations in kidney morphology indistinguishable from those caused by diabetes. We also show that in diabetic mice, Glo1 overexpression completely prevents diabetes-induced increases in MG modification of glomerular proteins, increased oxidative stress, and the development of diabetic kidney pathology, despite unchanged levels of diabetic hyperglycemia. Together, these data indicate that Glo1 activity regulates the sensitivity of the kidney to hyperglycemic-induced renal pathology and that alterations in the rate of MG detoxification are sufficient to determine the glycemic set point at which DN occurs.", "contributors": [{"name": "Giacco, Ferdinando", "sameAs": [], "familyName": "Giacco", "additionalName": "", "givenName": "Ferdinando", "email": ""}, {"name": "Du, Xueliang", "sameAs": [], "familyName": "Du", "additionalName": "", "givenName": "Xueliang", "email": ""}, {"name": "D\u2019Agati, Vivette D.", "sameAs": [], "familyName": "D\u2019Agati", "additionalName": "D.", "givenName": "Vivette", "email": ""}, {"name": "Milne, Ross", "sameAs": [], "familyName": "Milne", "additionalName": "", "givenName": "Ross", "email": ""}, {"name": "Sui, Guangzhi", "sameAs": [], "familyName": "Sui", "additionalName": "", "givenName": "Guangzhi", "email": ""}, {"name": "Geoffrion, Michele", "sameAs": [], "familyName": "Geoffrion", "additionalName": "", "givenName": "Michele", "email": ""}, {"name": "Brownlee, Michael", "sameAs": [], "familyName": "Brownlee", "additionalName": "", "givenName": "Michael", "email": ""}], "title": "Knockdown of Glyoxalase 1 Mimics Diabetic Nephropathy in Nondiabetic Mice", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["complications"], "providerUpdatedDateTime": "2015-01-01T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3868051"}}, {"publisher": {"name": ""}, "description": "  We present a new similarity measure based on information theoretic measures\nwhich is superior than Normalized Compression Distance for clustering problems\nand inherits the useful properties of conditional Kolmogorov complexity. We\nshow that Normalized Compression Dictionary Size and Normalized Compression\nDictionary Entropy are computationally more efficient, as the need to perform\nthe compression itself is eliminated. Also they scale linearly with exponential\nvector size growth and are content independent. We show that normalized\ncompression dictionary distance is compressor independent, if limited to\nlossless compressors, which gives space for optimizations and implementation\nspeed improvement for real-time and big data applications. The introduced\nmeasure is applicable for machine learning tasks of parameter-free unsupervised\nclustering, supervised learning such as classification and regression, feature\nselection, and is applicable for big data problems with order of magnitude\nspeed increase.\n", "contributors": [{"name": "Bogomolov, Andrey", "sameAs": [], "familyName": "Bogomolov", "additionalName": "", "givenName": "Andrey", "email": ""}, {"name": "Lepri, Bruno", "sameAs": [], "familyName": "Lepri", "additionalName": "", "givenName": "Bruno", "email": ""}, {"name": "Pianesi, Fabio", "sameAs": [], "familyName": "Pianesi", "additionalName": "", "givenName": "Fabio", "email": ""}], "title": "Generalized Compression Dictionary Distance as Universal Similarity\n  Measure", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5792", "oai:arXiv.org:1410.5792"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  We present a new similarity measure based on information theoretic measures\nwhich is superior than Normalized Compression Distance for clustering problems\nand inherits the useful properties of conditional Kolmogorov complexity. We\nshow that Normalized Compression Dictionary Size and Normalized Compression\nDictionary Entropy are computationally more efficient, as the need to perform\nthe compression itself is eliminated. Also they scale linearly with exponential\nvector size growth and are content independent. We show that normalized\ncompression dictionary distance is compressor independent, if limited to\nlossless compressors, which gives space for optimizations and implementation\nspeed improvement for real-time and big data applications. The introduced\nmeasure is applicable for machine learning tasks of parameter-free unsupervised\nclustering, supervised learning such as classification and regression, feature\nselection, and is applicable for big data problems with order of magnitude\nspeed increase.\n", "Comment: 2014 Conference on Big Data from Space (BiDS 14)"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "computer science - artificial intelligence", "computer science - information theory", "statistics - machine learning"], "providerUpdatedDateTime": "2014-10-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5792"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Distributed machine learning has typically been approached from a data parallel perspective, where big data are partitioned to multiple workers and an algorithm is executed concurrently over different data subsets under various synchronization schemes to ensure speed-up and/or correctness. A sibling problem that has received relatively less attention is how to ensure efficient and correct model parallel execution of ML algorithms, where parameters of an ML program are partitioned to different workers and undergone concurrent iterative updates. We argue that model and data parallelisms impose rather different challenges for system design, algorithmic adjustment, and theoretical analysis. In this paper, we develop a system for model-parallelism, STRADS, that provides a programming abstraction for scheduling parameter updates by discovering and leveraging changing structural properties of ML programs. STRADS enables a flexible tradeoff between scheduling efficiency and fidelity to intrinsic dependencies within the models, and improves memory efficiency of distributed ML. We demonstrate the efficacy of model-parallel algorithms implemented on STRADS versus popular implementations for topic modeling, matrix factorization, and Lasso.", "contributors": [{"name": "Lee, Seunghak", "sameAs": [], "familyName": "Lee", "additionalName": "", "givenName": "Seunghak", "email": ""}, {"name": "Kim, Jin Kyu", "sameAs": [], "familyName": "Kim", "additionalName": "Kyu", "givenName": "Jin", "email": ""}, {"name": "Zheng, Xun", "sameAs": [], "familyName": "Zheng", "additionalName": "", "givenName": "Xun", "email": ""}, {"name": "Ho, Qirong", "sameAs": [], "familyName": "Ho", "additionalName": "", "givenName": "Qirong", "email": ""}, {"name": "Gibson, Garth", "sameAs": [], "familyName": "Gibson", "additionalName": "", "givenName": "Garth", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "On Model Parallelization and Scheduling Strategies for Distributed Machine Learning", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-12-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/147", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1141&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1141"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Distributed machine learning has typically been approached from a data parallel perspective, where big data are partitioned to multiple workers and an algorithm is executed concurrently over different data subsets under various synchronization schemes to ensure speed-up and/or correctness. A sibling problem that has received relatively less attention is how to ensure efficient and correct model parallel execution of ML algorithms, where parameters of an ML program are partitioned to different workers and undergone concurrent iterative updates. We argue that model and data parallelisms impose rather different challenges for system design, algorithmic adjustment, and theoretical analysis. In this paper, we develop a system for model-parallelism, STRADS, that provides a programming abstraction for scheduling parameter updates by discovering and leveraging changing structural properties of ML programs. STRADS enables a flexible tradeoff between scheduling efficiency and fidelity to intrinsic dependencies within the models, and improves memory efficiency of distributed ML. We demonstrate the efficacy of model-parallel algorithms implemented on STRADS versus popular implementations for topic modeling, matrix factorization, and Lasso."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-30T21:01:59", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/147"}}, {"publisher": {"name": ""}, "description": "  In this report, a novel variation of Particle Swarm Optimization (PSO)\nalgorithm, called Multiagent Coordination Optimization (MCO), is implemented in\na parallel computing way for practical use by introducing MATLAB built-in\nfunction \"parfor\" into MCO. Then we rigorously analyze the global convergence\nof MCO by means of semistability theory. Besides sharing global optimal\nsolutions with the PSO algorithm, the MCO algorithm integrates cooperative\nswarm behavior of multiple agents into the update formula by sharing velocity\nand position information between neighbors to improve its performance.\nNumerical evaluation of the parallel MCO algorithm is provided in the report by\nrunning the proposed algorithm on supercomputers in the High Performance\nComputing Center at Texas Tech University. In particular, the optimal value and\nconsuming time are compared with PSO and serial MCO by solving several\nbenchmark functions in the literature, respectively. Based on the simulation\nresults, the performance of the parallel MCO is not only superb compared with\nPSO for solving many nonlinear, noncovex optimization problems, but also is of\nhigh efficiency by saving the computational time.\n", "contributors": [{"name": "Hui, Qing", "sameAs": [], "familyName": "Hui", "additionalName": "", "givenName": "Qing", "email": ""}, {"name": "Zhang, Haopeng", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Haopeng", "email": ""}], "title": "Convergence Analysis and Parallel Computing Implementation for the\n  Multiagent Coordination Optimization Algorithm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-02", "2014-11-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.0225", "oai:arXiv.org:1306.0225"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this report, a novel variation of Particle Swarm Optimization (PSO)\nalgorithm, called Multiagent Coordination Optimization (MCO), is implemented in\na parallel computing way for practical use by introducing MATLAB built-in\nfunction \"parfor\" into MCO. Then we rigorously analyze the global convergence\nof MCO by means of semistability theory. Besides sharing global optimal\nsolutions with the PSO algorithm, the MCO algorithm integrates cooperative\nswarm behavior of multiple agents into the update formula by sharing velocity\nand position information between neighbors to improve its performance.\nNumerical evaluation of the parallel MCO algorithm is provided in the report by\nrunning the proposed algorithm on supercomputers in the High Performance\nComputing Center at Texas Tech University. In particular, the optimal value and\nconsuming time are compared with PSO and serial MCO by solving several\nbenchmark functions in the literature, respectively. Based on the simulation\nresults, the performance of the parallel MCO is not only superb compared with\nPSO for solving many nonlinear, noncovex optimization problems, but also is of\nhigh efficiency by saving the computational time.\n", "Comment: 51 pages, 34 figures"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "49j45", "i.2.8", "93d99", "90c59", "mathematics - dynamical systems", "g.1.6", "computer science - neural and evolutionary computing", "65y05", "g.1.0"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.0225"}}, {"publisher": {"name": ""}, "description": "  Most existing content-based filtering approaches learn user profiles\nindependently without capturing the similarity among users. Bayesian\nhierarchical models \\cite{Zhang:Efficient} learn user profiles jointly and have\nthe advantage of being able to borrow discriminative information from other\nusers through a Bayesian prior. However, the standard Bayesian hierarchical\nmodels assume all user profiles are generated from the same prior. Considering\nthe diversity of user interests, this assumption could be improved by\nintroducing more flexibility. Besides, most existing content-based filtering\napproaches implicitly assume that each user profile corresponds to exactly one\nuser interest and fail to capture a user's multiple interests (information\nneeds).\n  In this paper, we present a flexible Bayesian hierarchical modeling approach\nto model both commonality and diversity among users as well as individual\nusers' multiple interests. We propose two models each with different\nassumptions, and the proposed models are called Discriminative Factored Prior\nModels (DFPM). In our models, each user profile is modeled as a discriminative\nclassifier with a factored model as its prior, and different factors contribute\nin different levels to each user profile. Compared with existing content-based\nfiltering models, DFPM are interesting because they can 1) borrow\ndiscriminative criteria of other users while learning a particular user profile\nthrough the factored prior; 2) trade off well between diversity and commonality\namong users; and 3) handle the challenging classification situation where each\nclass contains multiple concepts. The experimental results on a dataset\ncollected from real users on digg.com show that our models significantly\noutperform the baseline models of L-2 regularized logistic regression and\ntraditional Bayesian hierarchical model with logistic regression.\n", "contributors": [{"name": "Zhang, Lanbo", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Lanbo", "email": ""}, {"name": "Zhang, Yi", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Yi", "email": ""}], "title": "Hierarchical Bayesian Models with Factorization for Content-Based\n  Recommendation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.8118", "oai:arXiv.org:1412.8118"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Most existing content-based filtering approaches learn user profiles\nindependently without capturing the similarity among users. Bayesian\nhierarchical models \\cite{Zhang:Efficient} learn user profiles jointly and have\nthe advantage of being able to borrow discriminative information from other\nusers through a Bayesian prior. However, the standard Bayesian hierarchical\nmodels assume all user profiles are generated from the same prior. Considering\nthe diversity of user interests, this assumption could be improved by\nintroducing more flexibility. Besides, most existing content-based filtering\napproaches implicitly assume that each user profile corresponds to exactly one\nuser interest and fail to capture a user's multiple interests (information\nneeds).\n  In this paper, we present a flexible Bayesian hierarchical modeling approach\nto model both commonality and diversity among users as well as individual\nusers' multiple interests. We propose two models each with different\nassumptions, and the proposed models are called Discriminative Factored Prior\nModels (DFPM). In our models, each user profile is modeled as a discriminative\nclassifier with a factored model as its prior, and different factors contribute\nin different levels to each user profile. Compared with existing content-based\nfiltering models, DFPM are interesting because they can 1) borrow\ndiscriminative criteria of other users while learning a particular user profile\nthrough the factored prior; 2) trade off well between diversity and commonality\namong users; and 3) handle the challenging classification situation where each\nclass contains multiple concepts. The experimental results on a dataset\ncollected from real users on digg.com show that our models significantly\noutperform the baseline models of L-2 regularized logistic regression and\ntraditional Bayesian hierarchical model with logistic regression.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.8118"}}, {"publisher": {"name": ""}, "description": "  Given an initial placement of a set of rectangles in the plane, we consider\nthe problem of finding a disjoint placement of the rectangles that minimizes\nthe area of the bounding box and preserves the orthogonal order i.e.\\ maintains\nthe sorted ordering of the rectangle centers along both $x$-axis and $y$-axis\nwith respect to the initial placement. This problem is known as Layout\nAdjustment for Disjoint Rectangles(LADR). It was known that LADR is\n$\\mathbb{NP}$-hard, but only heuristics were known for it. We show that a\ncertain decision version of LADR is $\\mathbb{APX}$-hard, and give a constant\nfactor approximation for LADR.\n", "contributors": [{"name": "Bandyapadhyay, Sayan", "sameAs": [], "familyName": "Bandyapadhyay", "additionalName": "", "givenName": "Sayan", "email": ""}, {"name": "Bhowmick, Santanu", "sameAs": [], "familyName": "Bhowmick", "additionalName": "", "givenName": "Santanu", "email": ""}, {"name": "Varadarajan, Kasturi", "sameAs": [], "familyName": "Varadarajan", "additionalName": "", "givenName": "Kasturi", "email": ""}], "title": "A Constant Factor Approximation for Orthogonal Order Preserving Layout\n  Adjustment", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03847", "oai:arXiv.org:1502.03847"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Given an initial placement of a set of rectangles in the plane, we consider\nthe problem of finding a disjoint placement of the rectangles that minimizes\nthe area of the bounding box and preserves the orthogonal order i.e.\\ maintains\nthe sorted ordering of the rectangle centers along both $x$-axis and $y$-axis\nwith respect to the initial placement. This problem is known as Layout\nAdjustment for Disjoint Rectangles(LADR). It was known that LADR is\n$\\mathbb{NP}$-hard, but only heuristics were known for it. We show that a\ncertain decision version of LADR is $\\mathbb{APX}$-hard, and give a constant\nfactor approximation for LADR.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "computer science - discrete mathematics", "i.3.5", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-02-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03847"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Low-dimensional embedding, manifold learning, clustering, classification, and anomaly detection are among the most important problems in machine learning. Here we consider the setting where each instance of the inputs corresponds to a continuous probability distribution. These distributions are unknown to us, but we are given some i.i.d. samples from each of them. While most of the existing machine learning methods operate on points, i.e. finite-dimensional feature vectors, in our setting we study algorithms that operate on groups, i.e. sets of feature vectors. For this purpose, we propose new nonparametric, consistent estimators for a large family of divergences and describe how to apply them for machine learning problems. As important special cases, the estimators can be used to estimate R\u00b4enyi, Tsallis, Kullback-Leibler, Hellinger, Bhattacharyya distance, L2 divergences, and mutual information. We present empirical results on synthetic data, real word images, and astronomical data sets.", "contributors": [{"name": "Poczos, Barnabas", "sameAs": [], "familyName": "Poczos", "additionalName": "", "givenName": "Barnabas", "email": ""}, {"name": "Xiong, Liang", "sameAs": [], "familyName": "Xiong", "additionalName": "", "givenName": "Liang", "email": ""}, {"name": "Schneider, Jeff", "sameAs": [], "familyName": "Schneider", "additionalName": "", "givenName": "Jeff", "email": ""}], "title": "Nonparametric Divergence Estimation and its Applications to Machine Learning", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2011-01-01T08:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/88", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1095&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1095"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Low-dimensional embedding, manifold learning, clustering, classification, and anomaly detection are among the most important problems in machine learning. Here we consider the setting where each instance of the inputs corresponds to a continuous probability distribution. These distributions are unknown to us, but we are given some i.i.d. samples from each of them. While most of the existing machine learning methods operate on points, i.e. finite-dimensional feature vectors, in our setting we study algorithms that operate on groups, i.e. sets of feature vectors. For this purpose, we propose new nonparametric, consistent estimators for a large family of divergences and describe how to apply them for machine learning problems. As important special cases, the estimators can be used to estimate R\u00b4enyi, Tsallis, Kullback-Leibler, Hellinger, Bhattacharyya distance, L2 divergences, and mutual information. We present empirical results on synthetic data, real word images, and astronomical data sets."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-03-17T21:24:06", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/88"}}, {"publisher": {"name": ""}, "description": "  Given a non-deterministic timed automaton with silent transitions (eNTA), we\nshow that after an initial stage it becomes time-periodic. After computing the\nperiodic parameters, we construct a finite almost periodic augmented region\nautomaton, which includes a clock measuring the global time. In the next step\nwe construct the timestamp of the automaton: the union of all its observable\ntimed traces, which contains all the dates on which events occur - a\ngeneralization of the reachability problem. The timestamp of each event is an\nalmost periodic subset of the non-negative reals. We also construct a simple\ndeterministic timed automaton with the same timestamp as the given timed\nautomaton, in contrast to the fact that the timed automaton itself may be\nnon-determinizable. One application is the decidability of the $1$-bounded\nlanguage inclusion problem for eNTA. Another is a partial method, which is not\nbounded by time or number of steps, for showing the non-inclusion of languages\nof timed automata.\n", "contributors": [{"name": "Rosenmann, Amnon", "sameAs": [], "familyName": "Rosenmann", "additionalName": "", "givenName": "Amnon", "email": ""}], "title": "Almost Periodicity and the Timestamp of Timed Automata", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-17", "2014-12-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5669", "oai:arXiv.org:1412.5669"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Given a non-deterministic timed automaton with silent transitions (eNTA), we\nshow that after an initial stage it becomes time-periodic. After computing the\nperiodic parameters, we construct a finite almost periodic augmented region\nautomaton, which includes a clock measuring the global time. In the next step\nwe construct the timestamp of the automaton: the union of all its observable\ntimed traces, which contains all the dates on which events occur - a\ngeneralization of the reachability problem. The timestamp of each event is an\nalmost periodic subset of the non-negative reals. We also construct a simple\ndeterministic timed automaton with the same timestamp as the given timed\nautomaton, in contrast to the fact that the timed automaton itself may be\nnon-determinizable. One application is the decidability of the $1$-bounded\nlanguage inclusion problem for eNTA. Another is a partial method, which is not\nbounded by time or number of steps, for showing the non-inclusion of languages\nof timed automata.\n", "Comment: 25 pages, 10 figures; Typo in Title of first submission"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "d.2.4", "f.1.1"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5669"}}, {"publisher": {"name": ""}, "description": "  The main problem in colour management in prepress department is lack of\navailability of literature on colour management and knowledge gap between\nprepress department and press department. So a digital test from has been\ncreated by Adobe Photoshop to analyse the ICC profile and to create a new\nprofile and this analysed data is used to study about various grey scale of RGB\nand CMYK images. That helps in conversion of image from RGB to CMYK in prepress\ndepartment.\n", "contributors": [{"name": "Dilawari, Jaswinder Singh", "sameAs": [], "familyName": "Dilawari", "additionalName": "Singh", "givenName": "Jaswinder", "email": ""}, {"name": "Khanna, Ravinder", "sameAs": [], "familyName": "Khanna", "additionalName": "", "givenName": "Ravinder", "email": ""}], "title": "Creation of Digital Test Form for Prepress Department", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-09-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1209.5039", "(IJCSIS) International Journal of Computer Science and Information\n  Security, Vol. 10, No. 9, September 2012 (IJCSIS) International Journal of\n  Computer Science and Information Security, Vol. 10, No. 9, September 2012", "oai:arXiv.org:1209.5039"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The main problem in colour management in prepress department is lack of\navailability of literature on colour management and knowledge gap between\nprepress department and press department. So a digital test from has been\ncreated by Adobe Photoshop to analyse the ICC profile and to create a new\nprofile and this analysed data is used to study about various grey scale of RGB\nand CMYK images. That helps in conversion of image from RGB to CMYK in prepress\ndepartment.\n", "Comment: 5 Pages,4 Figures"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1209.5039"}}, {"publisher": {"name": ""}, "description": "  We consider the recovery of sparse signals that share a common support from\nmultiple measurement vectors. The performance of several algorithms developed\nfor this task depends on parameters like dimension of the sparse signal,\ndimension of measurement vector, sparsity level, measurement noise. We propose\na fusion framework, where several multiple measurement vector reconstruction\nalgorithms participate and the final signal estimate is obtained by combining\nthe signal estimates of the participating algorithms. We present the conditions\nfor achieving a better reconstruction performance than the participating\nalgorithms. Numerical simulations demonstrate that the proposed fusion\nalgorithm often performs better than the participating algorithms.\n", "contributors": [{"name": "G., Deepa K.", "sameAs": [], "familyName": "G.", "additionalName": "K.", "givenName": "Deepa", "email": ""}, {"name": "Ambat, Sooraj K.", "sameAs": [], "familyName": "Ambat", "additionalName": "K.", "givenName": "Sooraj", "email": ""}, {"name": "Hari, K. V. S.", "sameAs": [], "familyName": "Hari", "additionalName": "V. S.", "givenName": "K.", "email": ""}], "title": "Fusion of Sparse Reconstruction Algorithms for Multiple Measurement\n  Vectors", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01705", "oai:arXiv.org:1504.01705"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  We consider the recovery of sparse signals that share a common support from\nmultiple measurement vectors. The performance of several algorithms developed\nfor this task depends on parameters like dimension of the sparse signal,\ndimension of measurement vector, sparsity level, measurement noise. We propose\na fusion framework, where several multiple measurement vector reconstruction\nalgorithms participate and the final signal estimate is obtained by combining\nthe signal estimates of the participating algorithms. We present the conditions\nfor achieving a better reconstruction performance than the participating\nalgorithms. Numerical simulations demonstrate that the proposed fusion\nalgorithm often performs better than the participating algorithms.\n"}}], "languages": [null], "subjects": ["computer science - information theory", "statistics - methodology"], "providerUpdatedDateTime": "2015-04-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01705"}}, {"publisher": {"name": ""}, "description": "  Let $A$ be an algebra of bounded smooth functions on the interior of a\ncompact set in the plane. We study the following problem: if\n$f,f_1,\\dots,f_n\\in A$ satisfy $|f|\\leq \\sum_{j=1}^n |f_j|$, does there exist\n$g_j\\in A$ and a constant $N\\in\\N$ such that $f^N=\\sum_{j=1}^n g_j f_j$? A\nprominent role in our proofs is played by a new space, $C_{\\dbar, 1}(K)$, which\nwe call the algebra of $\\dbar$-smooth functions.\n  In the case $n=1$, a complete solution is given for the algebras $A^m(K)$ of\nfunctions holomorphic in $K^\\circ$ and whose first $m$-derivatives extend\ncontinuously to $\\ov{K^\\circ}$. This necessitates the introduction of a special\nclass of compacta, the so-called locally L-connected sets.\n  We also present another constructive proof of the Nullstellensatz for $A(K)$,\nthat is only based on elementary $\\dbar$-calculus and Wolff's method.\n", "contributors": [{"name": "Mortini, Raymond", "sameAs": [], "familyName": "Mortini", "additionalName": "", "givenName": "Raymond", "email": ""}, {"name": "Rupp, Rudolf", "sameAs": [], "familyName": "Rupp", "additionalName": "", "givenName": "Rudolf", "email": ""}], "title": "Corona-type theorems and division in some function algebras on planar\n  domains", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-01-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1301.7668", "The Corona Problem, Connections Between Operator Theory, Function\n  Theory, and Geometry Series: Fields Institute Communications, Vol. 72\n  Douglas, R.G., Krantz, S.G., Sawyer, E.T., Treil, S., Wick, B.D. (Eds.),\n  (2014) pp. 127-151", "oai:arXiv.org:1301.7668"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Let $A$ be an algebra of bounded smooth functions on the interior of a\ncompact set in the plane. We study the following problem: if\n$f,f_1,\\dots,f_n\\in A$ satisfy $|f|\\leq \\sum_{j=1}^n |f_j|$, does there exist\n$g_j\\in A$ and a constant $N\\in\\N$ such that $f^N=\\sum_{j=1}^n g_j f_j$? A\nprominent role in our proofs is played by a new space, $C_{\\dbar, 1}(K)$, which\nwe call the algebra of $\\dbar$-smooth functions.\n  In the case $n=1$, a complete solution is given for the algebras $A^m(K)$ of\nfunctions holomorphic in $K^\\circ$ and whose first $m$-derivatives extend\ncontinuously to $\\ov{K^\\circ}$. This necessitates the introduction of a special\nclass of compacta, the so-called locally L-connected sets.\n  We also present another constructive proof of the Nullstellensatz for $A(K)$,\nthat is only based on elementary $\\dbar$-calculus and Wolff's method.\n", "Comment: 23 pages, 6 figures"]}}], "languages": [null], "subjects": ["30h50", "46j10", "46j15", "46j20", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-10-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1301.7668"}}, {"publisher": {"name": ""}, "description": "  A model checker can produce a trace of counterexample, for an erroneous\nprogram, which is often long and difficult to understand. In general, the part\nabout the loops is the largest among the instructions in this trace. This makes\nthe location of errors in loops critical, to analyze errors in the overall\nprogram. In this paper, we explore the scala-bility capabilities of LocFaults,\nour error localization approach exploiting paths of CFG(Control Flow Graph)\nfrom a counterexample to calculate the MCDs (Minimal Correction Deviations),\nand MCSs (Minimal Correction Subsets) from each found MCD. We present the times\nof our approach on programs with While-loops unfolded b times, and a number of\ndeviated conditions ranging from 0 to n. Our preliminary results show that the\ntimes of our approach, constraint-based and flow-driven, are better compared to\nBugAssist which is based on SAT and transforms the entire program to a Boolean\nformula, and further the information provided by LocFaults is more expressive\nfor the user.\n", "contributors": [{"name": "Bekkouche, Mohammed", "sameAs": [], "familyName": "Bekkouche", "additionalName": "", "givenName": "Mohammed", "email": ""}], "title": "Exploration of the scalability of LocFaults approach for error\n  localization with While-loops programs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.05508", "oai:arXiv.org:1503.05508"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  A model checker can produce a trace of counterexample, for an erroneous\nprogram, which is often long and difficult to understand. In general, the part\nabout the loops is the largest among the instructions in this trace. This makes\nthe location of errors in loops critical, to analyze errors in the overall\nprogram. In this paper, we explore the scala-bility capabilities of LocFaults,\nour error localization approach exploiting paths of CFG(Control Flow Graph)\nfrom a counterexample to calculate the MCDs (Minimal Correction Deviations),\nand MCSs (Minimal Correction Subsets) from each found MCD. We present the times\nof our approach on programs with While-loops unfolded b times, and a number of\ndeviated conditions ranging from 0 to n. Our preliminary results show that the\ntimes of our approach, constraint-based and flow-driven, are better compared to\nBugAssist which is based on SAT and transforms the entire program to a Boolean\nformula, and further the information provided by LocFaults is more expressive\nfor the user.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - software engineering"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.05508"}}, {"publisher": {"name": ""}, "description": "Thesis (Ph.D.)--University of Washington, 2014", "contributors": [{"name": "Dickerson, John F.", "sameAs": [], "familyName": "Dickerson", "additionalName": "F.", "givenName": "John", "email": ""}, {"name": "Basu, Anirban", "sameAs": [], "familyName": "Basu", "additionalName": "", "givenName": "Anirban", "email": ""}], "title": "Role of Patient Adherence in the Treatment and Prevention of Depression", "shareProperties": {"source": "uwashington"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": ["2015-02-24T17:35:36Z", "2014"]}}, {"name": "identifier", "properties": {"identifier": ["Dickerson_washington_0250E_14006.pdf", "http://hdl.handle.net/1773/27498", "oai:digital.lib.washington.edu:1773/27498"]}}, {"name": "setSpec", "properties": {"setSpec": ["com_1773_4888", "col_1773_4928"]}}, {"name": "rights", "properties": {"rights": []}}], "languages": [null], "subjects": ["statistics", "public health", "economics", "health services", "adherence; bias; comparative effectiveness; cost effectiveness; instrumental variable; mental health"], "providerUpdatedDateTime": "2015-02-25T11:04:44", "uris": {"canonicalUri": "http://hdl.handle.net/1773/27498"}}, {"publisher": {"name": ""}, "description": "  In this paper, we defined the viseme (visual speech element) and described\nabout the method of extracting visual feature vector. We defined the 10 visemes\nbased on vowel by analyzing of Korean utterance and proposed the method of\nextracting the 20-dimensional visual feature vector, combination of static\nfeatures and dynamic features. Lastly, we took an experiment in recognizing\nwords based on 3-viseme HMM and evaluated the efficiency.\n", "contributors": [{"name": "Won, Ha Jong", "sameAs": [], "familyName": "Won", "additionalName": "Jong", "givenName": "Ha", "email": ""}, {"name": "Chol, Li Gwang", "sameAs": [], "familyName": "Chol", "additionalName": "Gwang", "givenName": "Li", "email": ""}, {"name": "Chol, Kim Hyok", "sameAs": [], "familyName": "Chol", "additionalName": "Hyok", "givenName": "Kim", "email": ""}, {"name": "Song, Li Kum", "sameAs": [], "familyName": "Song", "additionalName": "Kum", "givenName": "Li", "email": ""}], "title": "Definition of Visual Speech Element and Research on a Method of\n  Extracting Feature Vector for Korean Lip-Reading", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4114", "oai:arXiv.org:1411.4114"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we defined the viseme (visual speech element) and described\nabout the method of extracting visual feature vector. We defined the 10 visemes\nbased on vowel by analyzing of Korean utterance and proposed the method of\nextracting the 20-dimensional visual feature vector, combination of static\nfeatures and dynamic features. Lastly, we took an experiment in recognizing\nwords based on 3-viseme HMM and evaluated the efficiency.\n"}}], "languages": [null], "subjects": ["computer science - computation and language", "computer science - learning", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4114"}}, {"publisher": {"name": ""}, "description": "  We propose a new approach to sequential testing which is an adaptive\n(on-line) extension of the (off-line) framework developed in [10]. It relies\nupon testing of pairs of hypotheses in the case where each hypothesis states\nthat the vector of parameters underlying the dis- tribution of observations\nbelongs to a convex set. The nearly optimal under appropriate conditions test\nis yielded by a solution to an efficiently solvable convex optimization prob-\nlem. The proposed methodology can be seen as a computationally friendly\nreformulation of the classical sequential testing.\n", "contributors": [{"name": "Juditsky, Anatoli", "sameAs": [], "familyName": "Juditsky", "additionalName": "", "givenName": "Anatoli", "email": ""}, {"name": "Nemirovski, Arkadi", "sameAs": [], "familyName": "Nemirovski", "additionalName": "", "givenName": "Arkadi", "email": ""}], "title": "On sequential hypotheses testing via convex optimization", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1605", "oai:arXiv.org:1412.1605"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "stat"]}}, {"name": "description", "properties": {"description": "  We propose a new approach to sequential testing which is an adaptive\n(on-line) extension of the (off-line) framework developed in [10]. It relies\nupon testing of pairs of hypotheses in the case where each hypothesis states\nthat the vector of parameters underlying the dis- tribution of observations\nbelongs to a convex set. The nearly optimal under appropriate conditions test\nis yielded by a solution to an efficiently solvable convex optimization prob-\nlem. The proposed methodology can be seen as a computationally friendly\nreformulation of the classical sequential testing.\n"}}], "languages": [null], "subjects": ["mathematics - statistics theory", "statistics - computation"], "providerUpdatedDateTime": "2014-12-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1605"}}, {"publisher": {"name": ""}, "description": "  The immediate snapshot complexes were introduced as combinatorial models for\nthe protocol complexes in the context of theoretical distributed computing. In\nthe previous work we have developed a formal language of witness structures in\norder to define and to analyze these complexes.\n  In this paper, we study topology of immediate snapshot complexes. It was\nknown that these complexes are always pure and that they are pseudomanifolds.\nHere we prove two further independent topological properties. First, we show\nthat immediate snapshot complexes are collapsible. Second, we show that these\ncomplexes are homeomorphic to closed balls. Specifically, given any immediate\nsnapshot complex $P(\\tr)$, we show that there exists a homeomorphism\n$\\varphi:\\da^{|\\supp\\tr|-1}\\ra P(\\tr)$, such that $\\varphi(\\sigma)$ is a\nsubcomplex of $P(\\tr)$, whenever $\\sigma$ is a simplex in the simplicial\ncomplex $\\da^{|\\supp\\tr|-1}$.\n", "contributors": [{"name": "Kozlov, Dmitry N.", "sameAs": [], "familyName": "Kozlov", "additionalName": "N.", "givenName": "Dmitry", "email": ""}], "title": "Topology of the immediate snapshot complexes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-23", "2014-11-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.5813", "oai:arXiv.org:1404.5813"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The immediate snapshot complexes were introduced as combinatorial models for\nthe protocol complexes in the context of theoretical distributed computing. In\nthe previous work we have developed a formal language of witness structures in\norder to define and to analyze these complexes.\n  In this paper, we study topology of immediate snapshot complexes. It was\nknown that these complexes are always pure and that they are pseudomanifolds.\nHere we prove two further independent topological properties. First, we show\nthat immediate snapshot complexes are collapsible. Second, we show that these\ncomplexes are homeomorphic to closed balls. Specifically, given any immediate\nsnapshot complex $P(\\tr)$, we show that there exists a homeomorphism\n$\\varphi:\\da^{|\\supp\\tr|-1}\\ra P(\\tr)$, such that $\\varphi(\\sigma)$ is a\nsubcomplex of $P(\\tr)$, whenever $\\sigma$ is a simplex in the simplicial\ncomplex $\\da^{|\\supp\\tr|-1}$.\n", "Comment: final version as it appears in Topology and it Applications, Article\n  number 5275. arXiv admin note: substantial text overlap with arXiv:1402.4707"]}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.5813"}}, {"publisher": {"name": ""}, "description": "  The Abel differential equation $y'=p(x)y^3 + q(x) y^2$ with polynomial\ncoefficients $p,q$ is said to have a center on $[a,b]$ if all its solutions,\nwith the initial value $y(a)$ small enough, satisfy the condition $y(a)=y(b)$.\nThe problem of giving conditions on $(p,q,a,b)$ implying a center for the Abel\nequation is analogous to the classical Poincar\\'e Center-Focus problem for\nplane vector fields. Center conditions are provided by an infinite system of\n\"Center Equations\". An important new information on these equations has been\nobtained via a detailed analysis of two related structures: Composition Algebra\nand Moment Equations (first order approximation of the Center ones). Recently\none of the basic open questions in this direction - the \"Polynomial moments\nproblem\" - has been completely settled in \\cite{mp1,pak}.\n  In this paper we present a progress in the following two main directions:\nFirst, we translate the results of \\cite{mp1,pak} into the language of\nAlgebraic Geometry of the Center Equations. On this base we obtain new\ninformation on the center conditions, significantly extending, in particular,\nthe results of \\cite{broy}. Second, we study the \"second Melnikov coefficients\"\n(second order approximation of the Center equations) showing that in many cases\nvanishing of the moments and of these coefficients is sufficient in order to\ncompletely characterize centers.\n", "contributors": [{"name": "Briskin, M.", "sameAs": [], "familyName": "Briskin", "additionalName": "", "givenName": "M.", "email": ""}, {"name": "Pakovich, F.", "sameAs": [], "familyName": "Pakovich", "additionalName": "", "givenName": "F.", "email": ""}, {"name": "Yomdin, Y.", "sameAs": [], "familyName": "Yomdin", "additionalName": "", "givenName": "Y.", "email": ""}], "title": "Algebraic Geometry of the Center-Focus problem for Abel Differential\n  Equation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-11-06", "2014-07-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1211.1296", "doi:10.1017/etds.2014.94", "oai:arXiv.org:1211.1296"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  The Abel differential equation $y'=p(x)y^3 + q(x) y^2$ with polynomial\ncoefficients $p,q$ is said to have a center on $[a,b]$ if all its solutions,\nwith the initial value $y(a)$ small enough, satisfy the condition $y(a)=y(b)$.\nThe problem of giving conditions on $(p,q,a,b)$ implying a center for the Abel\nequation is analogous to the classical Poincar\\'e Center-Focus problem for\nplane vector fields. Center conditions are provided by an infinite system of\n\"Center Equations\". An important new information on these equations has been\nobtained via a detailed analysis of two related structures: Composition Algebra\nand Moment Equations (first order approximation of the Center ones). Recently\none of the basic open questions in this direction - the \"Polynomial moments\nproblem\" - has been completely settled in \\cite{mp1,pak}.\n  In this paper we present a progress in the following two main directions:\nFirst, we translate the results of \\cite{mp1,pak} into the language of\nAlgebraic Geometry of the Center Equations. On this base we obtain new\ninformation on the center conditions, significantly extending, in particular,\nthe results of \\cite{broy}. Second, we study the \"second Melnikov coefficients\"\n(second order approximation of the Center equations) showing that in many cases\nvanishing of the moments and of these coefficients is sufficient in order to\ncompletely characterize centers.\n"}}], "languages": [null], "subjects": ["34c08", "mathematics - complex variables", "34c07", "mathematics - dynamical systems", "mathematics - classical analysis and odes"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1211.1296"}}, {"publisher": {"name": ""}, "description": "  Godel's theory T can be understood as a theory of the simply-typed lambda\ncalculus that is extended to include the constant 0, the successor function S,\nand the operator R_tau for primitive recursion on objects of type tau. It is\nknown that the functions from non-negative integers to non-negative integers\nthat can be defined in this theory are exactly the <epsilon_0-recursive\nfunctions of non-negative integers. As an extension of this result, we show\nthat when the domain and codomain are restricted to pure closed normal forms,\nthe functionals of arbitrary type that are definable in T can be encoded as\n<epsilon_0-recursive functions.\n", "contributors": [{"name": "Szudzik, Matthew P.", "sameAs": [], "familyName": "Szudzik", "additionalName": "P.", "givenName": "Matthew", "email": ""}], "title": "On the definability of functionals in G\\\"odel's theory T", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-11-29", "2014-10-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1011.6353", "oai:arXiv.org:1011.6353"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Godel's theory T can be understood as a theory of the simply-typed lambda\ncalculus that is extended to include the constant 0, the successor function S,\nand the operator R_tau for primitive recursion on objects of type tau. It is\nknown that the functions from non-negative integers to non-negative integers\nthat can be defined in this theory are exactly the <epsilon_0-recursive\nfunctions of non-negative integers. As an extension of this result, we show\nthat when the domain and codomain are restricted to pure closed normal forms,\nthe functionals of arbitrary type that are definable in T can be encoded as\n<epsilon_0-recursive functions.\n", "Comment: 13 pages, 0 figures; metadata updated, other minor changes"]}}], "languages": [null], "subjects": ["mathematics - logic", "03d65", "computer science - logic in computer science", "03f10 (secondary)", "03b40 (primary)"], "providerUpdatedDateTime": "2014-10-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1011.6353"}}, {"publisher": {"name": ""}, "description": "  This paper attempts to explain consequences of the relational calculus not\nallowing relations to be domains of relations, and to suggest a solution for\nthe issue. On the example of SQL we describe the consequent problem of the\nmultitude of different representations for relations; analyze in detail the\ndisadvantages of the notions \"TABLE\" and \"FOREIGN KEY\"; and propose a complex\nsolution which includes brand new data language, abandonment of tables as a\nrepresentation for relations, and relatively small yet very significant\nalteration of the data storage concept, called \"multitable index\".\n", "contributors": [{"name": "Panferov, Eugene", "sameAs": [], "familyName": "Panferov", "additionalName": "", "givenName": "Eugene", "email": ""}], "title": "A Next-Generation Data Language Proposal", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-02", "2015-03-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.00503", "oai:arXiv.org:1503.00503"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper attempts to explain consequences of the relational calculus not\nallowing relations to be domains of relations, and to suggest a solution for\nthe issue. On the example of SQL we describe the consequent problem of the\nmultitude of different representations for relations; analyze in detail the\ndisadvantages of the notions \"TABLE\" and \"FOREIGN KEY\"; and propose a complex\nsolution which includes brand new data language, abandonment of tables as a\nrepresentation for relations, and relatively small yet very significant\nalteration of the data storage concept, called \"multitable index\".\n", "Comment: 19 pages"]}}], "languages": [null], "subjects": ["computer science - databases", "computer science - programming languages"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.00503"}}, {"publisher": {"name": ""}, "description": "  Since its introduction by Valiant in 1984, PAC learning of DNF expressions\nremains one of the central problems in learning theory. We consider this\nproblem in the setting where the underlying distribution is uniform, or more\ngenerally, a product distribution. Kalai, Samorodnitsky and Teng (2009) showed\nthat in this setting a DNF expression can be efficiently approximated from its\n\"heavy\" low-degree Fourier coefficients alone. This is in contrast to previous\napproaches where boosting was used and thus Fourier coefficients of the target\nfunction modified by various distributions were needed. This property is\ncrucial for learning of DNF expressions over smoothed product distributions, a\nlearning model introduced by Kalai et al. (2009) and inspired by the seminal\nsmoothed analysis model of Spielman and Teng (2001).\n  We introduce a new approach to learning (or approximating) a polynomial\nthreshold functions which is based on creating a function with range [-1,1]\nthat approximately agrees with the unknown function on low-degree Fourier\ncoefficients. We then describe conditions under which this is sufficient for\nlearning polynomial threshold functions. Our approach yields a new, simple\nalgorithm for approximating any polynomial-size DNF expression from its \"heavy\"\nlow-degree Fourier coefficients alone. Our algorithm greatly simplifies the\nproof of learnability of DNF expressions over smoothed product distributions.\nWe also describe an application of our algorithm to learning monotone DNF\nexpressions over product distributions. Building on the work of Servedio\n(2001), we give an algorithm that runs in time $\\poly((s \\cdot\n\\log{(s/\\eps)})^{\\log{(s/\\eps)}}, n)$, where $s$ is the size of the target DNF\nexpression and $\\eps$ is the accuracy. This improves on $\\poly((s \\cdot\n\\log{(ns/\\eps)})^{\\log{(s/\\eps)} \\cdot \\log{(1/\\eps)}}, n)$ bound of Servedio\n(2001).\n", "contributors": [{"name": "Feldman, Vitaly", "sameAs": [], "familyName": "Feldman", "additionalName": "", "givenName": "Vitaly", "email": ""}], "title": "Learning DNF Expressions from Fourier Spectrum", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-03-02", "2013-04-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1203.0594", "oai:arXiv.org:1203.0594"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Since its introduction by Valiant in 1984, PAC learning of DNF expressions\nremains one of the central problems in learning theory. We consider this\nproblem in the setting where the underlying distribution is uniform, or more\ngenerally, a product distribution. Kalai, Samorodnitsky and Teng (2009) showed\nthat in this setting a DNF expression can be efficiently approximated from its\n\"heavy\" low-degree Fourier coefficients alone. This is in contrast to previous\napproaches where boosting was used and thus Fourier coefficients of the target\nfunction modified by various distributions were needed. This property is\ncrucial for learning of DNF expressions over smoothed product distributions, a\nlearning model introduced by Kalai et al. (2009) and inspired by the seminal\nsmoothed analysis model of Spielman and Teng (2001).\n  We introduce a new approach to learning (or approximating) a polynomial\nthreshold functions which is based on creating a function with range [-1,1]\nthat approximately agrees with the unknown function on low-degree Fourier\ncoefficients. We then describe conditions under which this is sufficient for\nlearning polynomial threshold functions. Our approach yields a new, simple\nalgorithm for approximating any polynomial-size DNF expression from its \"heavy\"\nlow-degree Fourier coefficients alone. Our algorithm greatly simplifies the\nproof of learnability of DNF expressions over smoothed product distributions.\nWe also describe an application of our algorithm to learning monotone DNF\nexpressions over product distributions. Building on the work of Servedio\n(2001), we give an algorithm that runs in time $\\poly((s \\cdot\n\\log{(s/\\eps)})^{\\log{(s/\\eps)}}, n)$, where $s$ is the size of the target DNF\nexpression and $\\eps$ is the accuracy. This improves on $\\poly((s \\cdot\n\\log{(ns/\\eps)})^{\\log{(s/\\eps)} \\cdot \\log{(1/\\eps)}}, n)$ bound of Servedio\n(2001).\n", "Comment: Appears in Conference on Learning Theory (COLT) 2012"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity", "computer science - learning"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1203.0594"}}, {"publisher": {"name": ""}, "description": "Thesis (Ph.D.)--University of Washington, 2014", "contributors": [{"name": "Christensen, Janara Maria", "sameAs": [], "familyName": "Christensen", "additionalName": "Maria", "givenName": "Janara", "email": ""}, {"name": "Mausam, .", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Mausam", "email": ""}], "title": "Towards Large Scale Summarization", "shareProperties": {"source": "uwashington"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": ["2015-02-24T17:33:20Z", "2015-02-24T17:33:20Z", "2014"]}}, {"name": "identifier", "properties": {"identifier": ["Christensen_washington_0250E_13808.pdf", "http://hdl.handle.net/1773/27448", "oai:digital.lib.washington.edu:1773/27448"]}}, {"name": "setSpec", "properties": {"setSpec": ["com_1773_4888", "col_1773_4909"]}}, {"name": "rights", "properties": {"rights": []}}], "languages": [null], "subjects": ["computer science and engineering", "computer science"], "providerUpdatedDateTime": "2015-02-25T11:02:32", "uris": {"canonicalUri": "http://hdl.handle.net/1773/27448"}}, {"publisher": {"name": ""}, "description": "  The purpose of this paper is to prove an interpolation formula involving\nderivatives for entire functions of exponential type. We extend the\ninterpolation formula derived by J. Vaaler in [37, Theorem 9] to general $L^p$\nde Branges spaces. We extensively use techniques from de Branges' theory of\nHilbert spaces of entire functions as developed in [6], but a crucial passage\ninvolves the Hilbert-type inequalities as derived in [15]. We give applications\nto homogeneous spaces of entire functions that involve Bessel functions and we\nprove a uniqueness result for extremal one-sided band-limited approximations of\nradial functions in Euclidean spaces.\n", "contributors": [{"name": "Gon\u00e7alves, Felipe", "sameAs": [], "familyName": "Gon\u00e7alves", "additionalName": "", "givenName": "Felipe", "email": ""}], "title": "Interpolation Formulas With Derivatives in De Branges Spaces", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.05178", "oai:arXiv.org:1503.05178"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The purpose of this paper is to prove an interpolation formula involving\nderivatives for entire functions of exponential type. We extend the\ninterpolation formula derived by J. Vaaler in [37, Theorem 9] to general $L^p$\nde Branges spaces. We extensively use techniques from de Branges' theory of\nHilbert spaces of entire functions as developed in [6], but a crucial passage\ninvolves the Hilbert-type inequalities as derived in [15]. We give applications\nto homogeneous spaces of entire functions that involve Bessel functions and we\nprove a uniqueness result for extremal one-sided band-limited approximations of\nradial functions in Euclidean spaces.\n", "Comment: 25 pages"]}}], "languages": [null], "subjects": ["41a05", "33c10", "30d10", "41a30", "mathematics - complex variables", "46e22"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.05178"}}, {"publisher": {"name": "Institute of Electrical and Electronics Engineers"}, "description": "As the demand for higher data rates increases, commercial analog-to-digital converters (ADCs) are more commonly being implemented with multiple on-chip converters whose outputs are time-interleaved. The distortion generated by time-interleaved ADCs is now not only a function of the nonlinear behavior of the constituent circuitry, but also mismatches associated with interleaving multiple output streams. To mitigate distortion generated by time-interleaved ADCs, we have developed a polyphase NonLinear EQualizer (pNLEQ) which is capable of simultaneously mitigating distortion generated by both the on-chip circuitry and mismatches due to time interleaving. In this paper, we describe the pNLEQ architecture and present measurements of its performance.", "contributors": [{"name": "Goodman, Joel I.", "sameAs": [], "familyName": "Goodman", "additionalName": "I.", "givenName": "Joel", "email": ""}, {"name": "Miller, Benjamin A.", "sameAs": [], "familyName": "Miller", "additionalName": "A.", "givenName": "Benjamin", "email": ""}, {"name": "Herman, Matthew", "sameAs": [], "familyName": "Herman", "additionalName": "", "givenName": "Matthew", "email": ""}, {"name": "Raz, Gil", "sameAs": [], "familyName": "Raz", "additionalName": "", "givenName": "Gil", "email": ""}, {"name": "Jackson, Jeffrey", "sameAs": [], "familyName": "Jackson", "additionalName": "", "givenName": "Jeffrey", "email": ""}], "title": "Polyphase Nonlinear Equalization of Time-Interleaved Analog-to-Digital Converters", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": ["Article", "http://purl.org/eprint/type/JournalArticle"]}}, {"name": "source", "properties": {"source": "IEEE"}}, {"name": "format", "properties": {"format": []}}, {"name": "rights", "properties": {"rights": "Article is made available in accordance with the publisher\u2019s policy and may be subject to US copyright law. Please refer to the publisher\u2019s site for terms of use."}}, {"name": "identifier", "properties": {"identifier": ["1932-4553", "INSPEC Accession Number: 10664321", "http://hdl.handle.net/1721.1/52371", "Goodman, J. et al. \u201cPolyphase Nonlinear Equalization of Time-Interleaved Analog-to-Digital Converters.\u201d Selected Topics in Signal Processing, IEEE Journal of 3.3 (2009): 362-373. \u00a9 2009 Institute of Electrical and Electronics Engineers", "PUBLISHER_POLICY", "oai:dspace.mit.edu:1721.1/52371"]}}, {"name": "relation", "properties": {"relation": ["http://dx.doi.org/10.1109/JSTSP.2009.2020243", "IEEE Journal of Selected Topics in Signal Processing"]}}, {"name": "date", "properties": {"date": ["2010-03-08T16:24:36Z", "2010-03-08T16:24:36Z", "2009-05", "2009-03"]}}, {"name": "description", "properties": {"description": ["As the demand for higher data rates increases, commercial analog-to-digital converters (ADCs) are more commonly being implemented with multiple on-chip converters whose outputs are time-interleaved. The distortion generated by time-interleaved ADCs is now not only a function of the nonlinear behavior of the constituent circuitry, but also mismatches associated with interleaving multiple output streams. To mitigate distortion generated by time-interleaved ADCs, we have developed a polyphase NonLinear EQualizer (pNLEQ) which is capable of simultaneously mitigating distortion generated by both the on-chip circuitry and mismatches due to time interleaving. In this paper, we describe the pNLEQ architecture and present measurements of its performance.", "Defense Advanced Research Projects Agency (Air Force Contract FA8721-05-C-0002)"]}}, {"name": "setSpec", "properties": {"setSpec": "hdl_1721.1_49433"}}], "languages": [null], "subjects": ["volterra", "mismatch distortions", "compressed sensing", "time-interleaved analog-to-digital converter (adc)", "nonlinear compensation", "nonlinear equalization", "polynomial filter", "multidimensional filter"], "providerUpdatedDateTime": "2015-03-20T19:04:51", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/52371"}}, {"publisher": {"name": ""}, "description": "  Assume that a multi-user multiple-input multiple-output (MIMO) system is\ndesigned from scratch to uniformly cover a given area with maximal energy\nefficiency (EE). What are the optimal number of antennas, active users, and\ntransmit power? The aim of this paper is to answer this fundamental question.\nWe consider jointly the uplink and downlink with different processing schemes\nat the base station and propose a new realistic power consumption model that\nreveals how the above parameters affect the EE. Closed-form expressions for the\nEE-optimal value of each parameter, when the other two are fixed, are provided\nfor zero-forcing (ZF) processing in single-cell scenarios. These expressions\nprove how the parameters interact. For example, in sharp contrast to common\nbelief, the transmit power is found to increase (not to decrease) with the\nnumber of antennas. This implies that energy-efficient systems can operate in\nhigh signal-to-noise ratio regimes in which interference-suppressing signal\nprocessing is mandatory. Numerical and analytical results show that the maximal\nEE is achieved by a massive MIMO setup wherein hundreds of antennas are\ndeployed to serve a relatively large number of users using ZF processing. The\nnumerical results show the same behavior under imperfect channel state\ninformation and in symmetric multi-cell scenarios.\n", "contributors": [{"name": "Bj\u00f6rnson, Emil", "sameAs": [], "familyName": "Bj\u00f6rnson", "additionalName": "", "givenName": "Emil", "email": ""}, {"name": "Sanguinetti, Luca", "sameAs": [], "familyName": "Sanguinetti", "additionalName": "", "givenName": "Luca", "email": ""}, {"name": "Hoydis, Jakob", "sameAs": [], "familyName": "Hoydis", "additionalName": "", "givenName": "Jakob", "email": ""}, {"name": "Debbah, M\u00e9rouane", "sameAs": [], "familyName": "Debbah", "additionalName": "", "givenName": "M\u00e9rouane", "email": ""}], "title": "Optimal Design of Energy-Efficient Multi-User MIMO Systems: Is Massive\n  MIMO the Answer?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-24", "2015-03-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.6150", "oai:arXiv.org:1403.6150"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Assume that a multi-user multiple-input multiple-output (MIMO) system is\ndesigned from scratch to uniformly cover a given area with maximal energy\nefficiency (EE). What are the optimal number of antennas, active users, and\ntransmit power? The aim of this paper is to answer this fundamental question.\nWe consider jointly the uplink and downlink with different processing schemes\nat the base station and propose a new realistic power consumption model that\nreveals how the above parameters affect the EE. Closed-form expressions for the\nEE-optimal value of each parameter, when the other two are fixed, are provided\nfor zero-forcing (ZF) processing in single-cell scenarios. These expressions\nprove how the parameters interact. For example, in sharp contrast to common\nbelief, the transmit power is found to increase (not to decrease) with the\nnumber of antennas. This implies that energy-efficient systems can operate in\nhigh signal-to-noise ratio regimes in which interference-suppressing signal\nprocessing is mandatory. Numerical and analytical results show that the maximal\nEE is achieved by a massive MIMO setup wherein hundreds of antennas are\ndeployed to serve a relatively large number of users using ZF processing. The\nnumerical results show the same behavior under imperfect channel state\ninformation and in symmetric multi-cell scenarios.\n", "Comment: To appear in IEEE Transactions on Wireless Communications, 16 pages,\n  14 figures, 2 tables. The results can be reproduced using the following\n  Matlab code: https://github.com/emilbjornson/is-massive-MIMO-the-answer"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.6150"}}, {"publisher": {"name": ""}, "description": "  We prove the Shepp--Olkin conjecture, which states that the entropy of the\nsum of independent Bernoulli random variables is concave in the parameters of\nthe individual random variables. Our proof is a refinement of an argument\npreviously presented by the same authors, which resolved the conjecture in the\nmonotonic case (where all the parameters are simultaneously increasing). In\nfact, we show that the monotonic case is the worst case, using a careful\nanalysis of concavity properties of the derivatives of the probability mass\nfunction. We propose a generalization of Shepp and Olkin's original conjecture,\nto consider Renyi and Tsallis entropies.\n", "contributors": [{"name": "Hillion, Erwan", "sameAs": [], "familyName": "Hillion", "additionalName": "", "givenName": "Erwan", "email": ""}, {"name": "Johnson, Oliver", "sameAs": [], "familyName": "Johnson", "additionalName": "", "givenName": "Oliver", "email": ""}], "title": "A proof of the Shepp-Olkin entropy concavity conjecture", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01570", "oai:arXiv.org:1503.01570"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We prove the Shepp--Olkin conjecture, which states that the entropy of the\nsum of independent Bernoulli random variables is concave in the parameters of\nthe individual random variables. Our proof is a refinement of an argument\npreviously presented by the same authors, which resolved the conjecture in the\nmonotonic case (where all the parameters are simultaneously increasing). In\nfact, we show that the monotonic case is the worst case, using a careful\nanalysis of concavity properties of the derivatives of the probability mass\nfunction. We propose a generalization of Shepp and Olkin's original conjecture,\nto consider Renyi and Tsallis entropies.\n"}}], "languages": [null], "subjects": ["computer science - information theory", "mathematics - probability"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01570"}}, {"publisher": {"name": ""}, "description": "  The problem of sending two correlated vector Gaussian sources over a\nbandwidth-matched two-user scalar Gaussian broadcast channel is studied in this\nwork, where each receiver wishes to reconstruct its target source under a\ncovariance distortion constraint. We derive a lower bound on the optimal\ntradeoff between the transmit power and the achievable reconstruction\ndistortion pair. Our derivation is based on a new bounding technique which\ninvolves the introduction of appropriate remote sources. Furthermore, it is\nshown that this lower bound is achievable by a class of hybrid schemes for the\nspecial case where the weak receiver wishes to reconstruct a scalar source\nunder the mean squared error distortion constraint.\n", "contributors": [{"name": "Song, Lin", "sameAs": [], "familyName": "Song", "additionalName": "", "givenName": "Lin", "email": ""}, {"name": "Chen, Jun", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Jun", "email": ""}, {"name": "Tian, Chao", "sameAs": [], "familyName": "Tian", "additionalName": "", "givenName": "Chao", "email": ""}], "title": "Broadcasting Correlated Vector Gaussians", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02927", "oai:arXiv.org:1503.02927"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The problem of sending two correlated vector Gaussian sources over a\nbandwidth-matched two-user scalar Gaussian broadcast channel is studied in this\nwork, where each receiver wishes to reconstruct its target source under a\ncovariance distortion constraint. We derive a lower bound on the optimal\ntradeoff between the transmit power and the achievable reconstruction\ndistortion pair. Our derivation is based on a new bounding technique which\ninvolves the introduction of appropriate remote sources. Furthermore, it is\nshown that this lower bound is achievable by a class of hybrid schemes for the\nspecial case where the weak receiver wishes to reconstruct a scalar source\nunder the mean squared error distortion constraint.\n", "Comment: 13 pages"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02927"}}, {"publisher": {"name": ""}, "description": "  This article presents novel results concerning the recovery of signals from\nundersampled data in the common situation where such signals are not sparse in\nan orthonormal basis or incoherent dictionary, but in a truly redundant\ndictionary. This work thus bridges a gap in the literature and shows not only\nthat compressed sensing is viable in this context, but also that accurate\nrecovery is possible via an L1-analysis optimization problem. We introduce a\ncondition on the measurement/sensing matrix, which is a natural generalization\nof the now well-known restricted isometry property, and which guarantees\naccurate recovery of signals that are nearly sparse in (possibly) highly\novercomplete and coherent dictionaries. This condition imposes no incoherence\nrestriction on the dictionary and our results may be the first of this kind. We\ndiscuss practical examples and the implications of our results on those\napplications, and complement our study by demonstrating the potential of\nL1-analysis for such problems.\n", "contributors": [{"name": "Candes, Emmanuel J.", "sameAs": [], "familyName": "Candes", "additionalName": "J.", "givenName": "Emmanuel", "email": ""}, {"name": "Eldar, Yonina C.", "sameAs": [], "familyName": "Eldar", "additionalName": "C.", "givenName": "Yonina", "email": ""}, {"name": "Needell, Deanna", "sameAs": [], "familyName": "Needell", "additionalName": "", "givenName": "Deanna", "email": ""}, {"name": "Randall, Paige", "sameAs": [], "familyName": "Randall", "additionalName": "", "givenName": "Paige", "email": ""}], "title": "Compressed Sensing with Coherent and Redundant Dictionaries", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-05-14", "2010-12-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.2613", "oai:arXiv.org:1005.2613"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  This article presents novel results concerning the recovery of signals from\nundersampled data in the common situation where such signals are not sparse in\nan orthonormal basis or incoherent dictionary, but in a truly redundant\ndictionary. This work thus bridges a gap in the literature and shows not only\nthat compressed sensing is viable in this context, but also that accurate\nrecovery is possible via an L1-analysis optimization problem. We introduce a\ncondition on the measurement/sensing matrix, which is a natural generalization\nof the now well-known restricted isometry property, and which guarantees\naccurate recovery of signals that are nearly sparse in (possibly) highly\novercomplete and coherent dictionaries. This condition imposes no incoherence\nrestriction on the dictionary and our results may be the first of this kind. We\ndiscuss practical examples and the implications of our results on those\napplications, and complement our study by demonstrating the potential of\nL1-analysis for such problems.\n"}}], "languages": [null], "subjects": ["94a12", "mathematics - numerical analysis", "41a45", "computer science - information theory", "42a10"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.2613"}}, {"publisher": {"name": "eScholarship, University of California"}, "description": "", "contributors": [{"name": "Povey, S", "sameAs": [], "familyName": "Povey", "additionalName": "", "givenName": "S", "email": ""}, {"name": "Smith, M", "sameAs": [], "familyName": "Smith", "additionalName": "", "givenName": "M", "email": ""}, {"name": "Haines, J", "sameAs": [], "familyName": "Haines", "additionalName": "", "givenName": "J", "email": ""}, {"name": "Kwiatkowski, D", "sameAs": [], "familyName": "Kwiatkowski", "additionalName": "", "givenName": "D", "email": ""}, {"name": "Fountain, J", "sameAs": [], "familyName": "Fountain", "additionalName": "", "givenName": "J", "email": ""}, {"name": "Bale, A", "sameAs": [], "familyName": "Bale", "additionalName": "", "givenName": "A", "email": ""}, {"name": "Abbott, C", "sameAs": [], "familyName": "Abbott", "additionalName": "", "givenName": "C", "email": ""}, {"name": "Jackson, I", "sameAs": [], "familyName": "Jackson", "additionalName": "", "givenName": "I", "email": ""}, {"name": "Lawrie, M", "sameAs": [], "familyName": "Lawrie", "additionalName": "", "givenName": "M", "email": ""}, {"name": "Hult\u00e9n, M", "sameAs": [], "familyName": "Hult\u00e9n", "additionalName": "", "givenName": "M", "email": ""}], "title": "Report and abstracts of the First International Workshop on Chromosome 9. Held at Girton College Cambridge, UK, 22-24 March, 1992.", "shareProperties": {"source": "ucescholarship"}, "otherProperties": [{"name": "type", "properties": {"type": "article"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "1992-01-01"}}, {"name": "identifier", "properties": {"identifier": ["qt9ps8n973", "http://www.escholarship.org/uc/item/9ps8n973", "qt9ps8n973"]}}, {"name": "setSpec", "properties": {"setSpec": []}}, {"name": "source", "properties": {"source": "Povey, S; Smith, M; Haines, J; Kwiatkowski, D; Fountain, J; Bale, A; \u00a0et al.(1992). Report and abstracts of the First International Workshop on Chromosome 9. Held at Girton College Cambridge, UK, 22-24 March, 1992.. Annals of Human Genetics, 56, Pt - 3/. UC Irvine: Retrieved from: http://www.escholarship.org/uc/item/9ps8n973"}}, {"name": "coverage", "properties": {"coverage": "Pt - 3/"}}, {"name": "relation", "properties": {"relation": []}}, {"name": "rights", "properties": {"rights": "Attribution (CC BY): http://creativecommons.org/licenses/by/3.0/"}}], "languages": [null], "subjects": ["conference paper", "nucleotide sequence", "human", "p.h.s.", "chromosomes", "mouse", "pair 9", "dna", "non-u.s. gov't", "single stranded", "support", "single-stranded", "genetics", "animal", "non-p.h.s.", "comparative study", "chromosome mapping", "single stranded dna", "molecular genetics", "tuberous sclerosis", "mice", "base sequence", "molecular sequence data", "linkage (genetics)", "genetic linkage", "chromosome map", "chromosome 9", "u.s. gov't"], "providerUpdatedDateTime": "2015-04-02T00:00:00", "uris": {"canonicalUri": "http://www.escholarship.org/uc/item/9ps8n973"}}, {"publisher": {"name": ""}, "description": "  We present the first high order one-step ADER-WENO finite volume scheme with\nAdaptive Mesh Refinement (AMR) in multiple space dimensions. High order spatial\naccuracy is obtained through a WENO reconstruction, while a high order one-step\ntime discretization is achieved using a local space-time discontinuous Galerkin\npredictor method. Due to the one-step nature of the underlying scheme, the\nresulting algorithm is particularly well suited for an AMR strategy on\nspace-time adaptive meshes, i.e.with time-accurate local time stepping. The AMR\nproperty has been implemented 'cell-by-cell', with a standard tree-type\nalgorithm, while the scheme has been parallelized via the Message Passing\nInterface (MPI) paradigm. The new scheme has been tested over a wide range of\nexamples for nonlinear systems of hyperbolic conservation laws, including the\nclassical Euler equations of compressible gas dynamics and the equations of\nmagnetohydrodynamics (MHD). High order in space and time have been confirmed\nvia a numerical convergence study and a detailed analysis of the computational\nspeed-up with respect to highly refined uniform meshes is also presented. We\nalso show test problems where the presented high order AMR scheme behaves\nclearly better than traditional second order AMR methods. The proposed scheme\nthat combines for the first time high order ADER methods with space--time\nadaptive grids in two and three space dimensions is likely to become a useful\ntool in several fields of computational physics, applied mathematics and\nmechanics.\n", "contributors": [{"name": "Dumbser, Michael", "sameAs": [], "familyName": "Dumbser", "additionalName": "", "givenName": "Michael", "email": ""}, {"name": "Zanotti, Olindo", "sameAs": [], "familyName": "Zanotti", "additionalName": "", "givenName": "Olindo", "email": ""}, {"name": "Hidalgo, Arturo", "sameAs": [], "familyName": "Hidalgo", "additionalName": "", "givenName": "Arturo", "email": ""}, {"name": "Balsara, Dinshaw S.", "sameAs": [], "familyName": "Balsara", "additionalName": "S.", "givenName": "Dinshaw", "email": ""}], "title": "ADER-WENO Finite Volume Schemes with Space-Time Adaptive Mesh Refinement", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-12-14", "2015-03-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1212.3585", "Journal of Computational Physics, Volume 248, p. 257-286 (2013)", "doi:10.1016/j.jcp.2013.04.017", "oai:arXiv.org:1212.3585"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:astro-ph", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We present the first high order one-step ADER-WENO finite volume scheme with\nAdaptive Mesh Refinement (AMR) in multiple space dimensions. High order spatial\naccuracy is obtained through a WENO reconstruction, while a high order one-step\ntime discretization is achieved using a local space-time discontinuous Galerkin\npredictor method. Due to the one-step nature of the underlying scheme, the\nresulting algorithm is particularly well suited for an AMR strategy on\nspace-time adaptive meshes, i.e.with time-accurate local time stepping. The AMR\nproperty has been implemented 'cell-by-cell', with a standard tree-type\nalgorithm, while the scheme has been parallelized via the Message Passing\nInterface (MPI) paradigm. The new scheme has been tested over a wide range of\nexamples for nonlinear systems of hyperbolic conservation laws, including the\nclassical Euler equations of compressible gas dynamics and the equations of\nmagnetohydrodynamics (MHD). High order in space and time have been confirmed\nvia a numerical convergence study and a detailed analysis of the computational\nspeed-up with respect to highly refined uniform meshes is also presented. We\nalso show test problems where the presented high order AMR scheme behaves\nclearly better than traditional second order AMR methods. The proposed scheme\nthat combines for the first time high order ADER methods with space--time\nadaptive grids in two and three space dimensions is likely to become a useful\ntool in several fields of computational physics, applied mathematics and\nmechanics.\n", "Comment: With updated bibliography information"]}}], "languages": [null], "subjects": ["physics - computational physics", "mathematics - numerical analysis", "computer science - numerical analysis", "astrophysics - instrumentation and methods for astrophysics"], "providerUpdatedDateTime": "2015-03-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1212.3585"}}, {"publisher": {"name": ""}, "description": "  Discourse markers are universal linguistic events subject to language\nvariation. Although an extensive literature has already reported language\nspecific traits of these events, little has been said on their cross-language\nbehavior and on building an inventory of multilingual lexica of discourse\nmarkers. This work describes new methods and approaches for the description,\nclassification, and annotation of discourse markers in the specific domain of\nthe Europarl corpus. The study of discourse markers in the context of\ntranslation is crucial due to the idiomatic nature of these structures.\nMultilingual lexica together with the functional analysis of such structures\nare useful tools for the hard task of translating discourse markers into\npossible equivalents from one language to another. Using Daniel Marcu's\nvalidated discourse markers for English, extracted from the Brown Corpus, our\npurpose is to build multilingual lexica of discourse markers for other\nlanguages, based on machine translation techniques. The major assumption in\nthis study is that the usage of a discourse marker is independent of the\nlanguage, i.e., the rhetorical function of a discourse marker in a sentence in\none language is equivalent to the rhetorical function of the same discourse\nmarker in another language.\n", "contributors": [{"name": "Lopes, Ant\u00f3nio", "sameAs": [], "familyName": "Lopes", "additionalName": "", "givenName": "Ant\u00f3nio", "email": ""}, {"name": "de Matos, David Martins", "sameAs": [], "familyName": "de Matos", "additionalName": "Martins", "givenName": "David", "email": ""}, {"name": "Cabarr\u00e3o, Vera", "sameAs": [], "familyName": "Cabarr\u00e3o", "additionalName": "", "givenName": "Vera", "email": ""}, {"name": "Ribeiro, Ricardo", "sameAs": [], "familyName": "Ribeiro", "additionalName": "", "givenName": "Ricardo", "email": ""}, {"name": "Moniz, Helena", "sameAs": [], "familyName": "Moniz", "additionalName": "", "givenName": "Helena", "email": ""}, {"name": "Trancoso, Isabel", "sameAs": [], "familyName": "Trancoso", "additionalName": "", "givenName": "Isabel", "email": ""}, {"name": "Mata, Ana Isabel", "sameAs": [], "familyName": "Mata", "additionalName": "Isabel", "givenName": "Ana", "email": ""}], "title": "Towards Using Machine Translation Techniques to Induce Multilingual\n  Lexica of Discourse Markers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.09144", "oai:arXiv.org:1503.09144"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Discourse markers are universal linguistic events subject to language\nvariation. Although an extensive literature has already reported language\nspecific traits of these events, little has been said on their cross-language\nbehavior and on building an inventory of multilingual lexica of discourse\nmarkers. This work describes new methods and approaches for the description,\nclassification, and annotation of discourse markers in the specific domain of\nthe Europarl corpus. The study of discourse markers in the context of\ntranslation is crucial due to the idiomatic nature of these structures.\nMultilingual lexica together with the functional analysis of such structures\nare useful tools for the hard task of translating discourse markers into\npossible equivalents from one language to another. Using Daniel Marcu's\nvalidated discourse markers for English, extracted from the Brown Corpus, our\npurpose is to build multilingual lexica of discourse markers for other\nlanguages, based on machine translation techniques. The major assumption in\nthis study is that the usage of a discourse marker is independent of the\nlanguage, i.e., the rhetorical function of a discourse marker in a sentence in\none language is equivalent to the rhetorical function of the same discourse\nmarker in another language.\n", "Comment: 6 pages"]}}], "languages": [null], "subjects": ["i.2.7", "computer science - computation and language"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.09144"}}, {"publisher": {"name": ""}, "description": "  Attosecond streaking is one of the most fundamental processes in attosecond\nscience allowing for a mapping of temporal (i.e. phase) information on the\nenergy domain. We show that on the single-particle level attosecond streaking\ntime shifts contain spectral phase information associated with the\nEisenbud-Wigner-Smith (EWS) time delay, provided the influence of the streaking\ninfrared field is properly accounted for. While the streaking phase shifts for\nshort-ranged potentials agree with the associated EWS delays, Coulomb\npotentials require special care. We show that the interaction between the\noutgoing electron and the combined Coulomb and IR laser fields lead to a\nstreaking phase shift that can be described classically.\n", "contributors": [{"name": "Pazourek, Renate", "sameAs": [], "familyName": "Pazourek", "additionalName": "", "givenName": "Renate", "email": ""}, {"name": "Nagele, Stefan", "sameAs": [], "familyName": "Nagele", "additionalName": "", "givenName": "Stefan", "email": ""}, {"name": "Doblhoff-Dier, Katharina", "sameAs": [], "familyName": "Doblhoff-Dier", "additionalName": "", "givenName": "Katharina", "email": ""}, {"name": "Feist, Johannes", "sameAs": [], "familyName": "Feist", "additionalName": "", "givenName": "Johannes", "email": ""}, {"name": "Lemell, Christoph", "sameAs": [], "familyName": "Lemell", "additionalName": "", "givenName": "Christoph", "email": ""}, {"name": "T\u00f6k\u00e9si, Karoly", "sameAs": [], "familyName": "T\u00f6k\u00e9si", "additionalName": "", "givenName": "Karoly", "email": ""}, {"name": "Burgd\u00f6rfer, Joachim", "sameAs": [], "familyName": "Burgd\u00f6rfer", "additionalName": "", "givenName": "Joachim", "email": ""}], "title": "Probing scattering phase shifts by attosecond streaking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-11-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.4172", "J. Phys.: Conf. Ser. 388, 012029 (2012)", "doi:10.1088/1742-6596/388/1/012029", "oai:arXiv.org:1111.4172"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": "  Attosecond streaking is one of the most fundamental processes in attosecond\nscience allowing for a mapping of temporal (i.e. phase) information on the\nenergy domain. We show that on the single-particle level attosecond streaking\ntime shifts contain spectral phase information associated with the\nEisenbud-Wigner-Smith (EWS) time delay, provided the influence of the streaking\ninfrared field is properly accounted for. While the streaking phase shifts for\nshort-ranged potentials agree with the associated EWS delays, Coulomb\npotentials require special care. We show that the interaction between the\noutgoing electron and the combined Coulomb and IR laser fields lead to a\nstreaking phase shift that can be described classically.\n"}}], "languages": [null], "subjects": ["physics - computational physics", "physics - atomic physics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.4172"}}, {"publisher": {"name": ""}, "description": "  In this work, we present the problem of rash driving detection algorithm\nusing a single wide angle camera sensor, particularly useful in the Indian\ncontext. To our knowledge this rash driving problem has not been addressed\nusing Image processing techniques (existing works use other sensors such as\naccelerometer). Car Image processing literature, though rich and mature, does\nnot address the rash driving problem. In this work-in-progress paper, we\npresent the need to address this problem, our approach and our future plans to\nbuild a rash driving detector.\n", "contributors": [{"name": "Haloi, Mrinal", "sameAs": [], "familyName": "Haloi", "additionalName": "", "givenName": "Mrinal", "email": ""}, {"name": "Jayagopi, Dinesh Babu", "sameAs": [], "familyName": "Jayagopi", "additionalName": "Babu", "givenName": "Dinesh", "email": ""}], "title": "Characterizing driving behavior using automatic visual analysis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04036", "doi:10.1145/2662117.2662126", "oai:arXiv.org:1503.04036"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this work, we present the problem of rash driving detection algorithm\nusing a single wide angle camera sensor, particularly useful in the Indian\ncontext. To our knowledge this rash driving problem has not been addressed\nusing Image processing techniques (existing works use other sensors such as\naccelerometer). Car Image processing literature, though rich and mature, does\nnot address the rash driving problem. In this work-in-progress paper, we\npresent the need to address this problem, our approach and our future plans to\nbuild a rash driving detector.\n", "Comment: 4 pages,7 figures, IBM-ICARE2014"]}}], "languages": [null], "subjects": ["h.4.3", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04036"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Many organisms have evolved DNA damage response mechanisms to deal with the constant damage to DNA caused by endogenous and exogenous agents. These mechanisms activate cell cycle checkpoints to allow time for DNA repair or, in the case of severely damaged DNA, initiate cell death mechanisms to maintain genomic integrity. The cell's response to DNA damaging agents includes wide spread changes in the transcriptional state of the cell that have been implicated in cell death or survival decisions. However, we do not fully understand how the multiple and sometimes opposing transcriptional signals are interpreted to make these critical decisions. A computational and systems biology approach was taken to study the wide-spread transcriptional changes induced in human cell lines after exposure to a DNA damaging and chemotherapeutic agent, 1,3-bis-(2-chloroethyl)- 1 -nitrosourea (BCNU or carmustine). Cell lines with extreme sensitivity or resistance to BCNU were identified from a set of twenty four genetically diverse human lymphoblastoid cell lines using a high-throughput method that was developed as part of this thesis. This assay has broad applications and can be used to simultaneously screen multiple cell lines and drugs for accurate measurements of cell proliferation and survival after drug treatment. The assay has the advantage of having a large dynamic range that allows sensitivity measurements on a multi-log scale allowing better resolution of comparative sensitivities. Temporal transcription profiles were measured in cell lines with extreme BCNU sensitivity or resistance to generate a large transcription data set amenable to bioinformatics analysis. A transcriptional signature of 706 genes, differentially expressed between BCNU sensitive and resistant cell lines, was identified. Network and gene ontology enrichment identified these differentially expressed genes as being involved in key DNA damage response processes like apoptosis and mitosis. Experimental evidence showed that the transcription signature correlated with observed cellular phenotypes. Furthermore, the NF-Y transcription factor binding motif was enriched in the promoter region of 62 mitosis-related genes downregulated in BCNU sensitive but not resistant cell lines. Chromatin immunoprecipitation followed by sequencing (ChIP-seq) confirmed NF-Y occupancy in 54 of the 62 genes, thus implicating NF-Y as a possible regulator of the observed stalling of entry into mitosis. Using experimental and computational techniques we deciphered the functional importance of differential transcription between BCNU sensitive and resistant cell lines and identified NF-Y as an important factor in the transcriptional and phenotypic cell response to BCNU such as the control of entry into mitosis.", "contributors": [{"name": "Valiathan, Chandni Rajan", "sameAs": [], "familyName": "Valiathan", "additionalName": "Rajan", "givenName": "Chandni", "email": ""}, {"name": "Massachusetts Institute of Technology. Computational and Systems Biology Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computational and Systems Biology", "givenName": "Massachusetts", "email": ""}, {"name": "Leona Samson.", "sameAs": [], "familyName": "Samson.", "additionalName": "", "givenName": "Leona", "email": ""}], "title": "Identifying a transcriptional signature for cell sensitivity to the cancer chemotherapy agent, BCNU", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "195 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/65773", "749453776", "oai:dspace.mit.edu:1721.1/65773"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2011-09-13T17:50:49Z", "2011-09-13T17:50:49Z", "2011", "2011"]}}, {"name": "description", "properties": {"description": ["Many organisms have evolved DNA damage response mechanisms to deal with the constant damage to DNA caused by endogenous and exogenous agents. These mechanisms activate cell cycle checkpoints to allow time for DNA repair or, in the case of severely damaged DNA, initiate cell death mechanisms to maintain genomic integrity. The cell's response to DNA damaging agents includes wide spread changes in the transcriptional state of the cell that have been implicated in cell death or survival decisions. However, we do not fully understand how the multiple and sometimes opposing transcriptional signals are interpreted to make these critical decisions. A computational and systems biology approach was taken to study the wide-spread transcriptional changes induced in human cell lines after exposure to a DNA damaging and chemotherapeutic agent, 1,3-bis-(2-chloroethyl)- 1 -nitrosourea (BCNU or carmustine). Cell lines with extreme sensitivity or resistance to BCNU were identified from a set of twenty four genetically diverse human lymphoblastoid cell lines using a high-throughput method that was developed as part of this thesis. This assay has broad applications and can be used to simultaneously screen multiple cell lines and drugs for accurate measurements of cell proliferation and survival after drug treatment. The assay has the advantage of having a large dynamic range that allows sensitivity measurements on a multi-log scale allowing better resolution of comparative sensitivities. Temporal transcription profiles were measured in cell lines with extreme BCNU sensitivity or resistance to generate a large transcription data set amenable to bioinformatics analysis. A transcriptional signature of 706 genes, differentially expressed between BCNU sensitive and resistant cell lines, was identified. Network and gene ontology enrichment identified these differentially expressed genes as being involved in key DNA damage response processes like apoptosis and mitosis. Experimental evidence showed that the transcription signature correlated with observed cellular phenotypes. Furthermore, the NF-Y transcription factor binding motif was enriched in the promoter region of 62 mitosis-related genes downregulated in BCNU sensitive but not resistant cell lines. Chromatin immunoprecipitation followed by sequencing (ChIP-seq) confirmed NF-Y occupancy in 54 of the 62 genes, thus implicating NF-Y as a possible regulator of the observed stalling of entry into mitosis. Using experimental and computational techniques we deciphered the functional importance of differential transcription between BCNU sensitive and resistant cell lines and identified NF-Y as an important factor in the transcriptional and phenotypic cell response to BCNU such as the control of entry into mitosis.", "by Chandni Rajan Valiathan.", "Thesis (Ph. D.)--Massachusetts Institute of Technology, Computational and Systems Biology Program, 2011.", "Cataloged from PDF version of thesis.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_54823", "hdl_1721.1_54828"]}}], "languages": [null], "subjects": ["computational and systems biology program."], "providerUpdatedDateTime": "2015-04-27T14:53:06", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/65773"}}, {"publisher": {"name": ""}, "description": "  Bounded-rate multi-mode systems are hybrid systems that can switch among a\nfinite set of modes. Its dynamics is specified by a finite number of\nreal-valued variables with mode-dependent rates that can vary within given\nbounded sets. Given an arbitrary piecewise linear trajectory, we study the\nproblem of following the trajectory with arbitrary precision, using motion\nprimitives given as bounded-rate multi-mode systems. We give an algorithm to\nsolve the problem and show that the problem is co-NP complete. We further prove\nthat the problem can be solved in polynomial time for multi-mode systems with\nfixed dimension. We study the problem with dwell-time requirement and show the\ndecidability of the problem under certain positivity restriction on the rate\nvectors. Finally, we show that introducing structure to the multi-mode systems\nleads to undecidability, even when using only a single clock variable.\n", "contributors": [{"name": "Bhave, Devendra", "sameAs": [], "familyName": "Bhave", "additionalName": "", "givenName": "Devendra", "email": ""}, {"name": "Jha, Sagar", "sameAs": [], "familyName": "Jha", "additionalName": "", "givenName": "Sagar", "email": ""}, {"name": "Krishna, Shankara Narayanan", "sameAs": [], "familyName": "Krishna", "additionalName": "Narayanan", "givenName": "Shankara", "email": ""}, {"name": "Schewe, Sven", "sameAs": [], "familyName": "Schewe", "additionalName": "", "givenName": "Sven", "email": ""}, {"name": "Trivedi, Ashutosh", "sameAs": [], "familyName": "Trivedi", "additionalName": "", "givenName": "Ashutosh", "email": ""}], "title": "Bounded-Rate Multi-Mode Systems Based Motion Planning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3670", "oai:arXiv.org:1412.3670"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Bounded-rate multi-mode systems are hybrid systems that can switch among a\nfinite set of modes. Its dynamics is specified by a finite number of\nreal-valued variables with mode-dependent rates that can vary within given\nbounded sets. Given an arbitrary piecewise linear trajectory, we study the\nproblem of following the trajectory with arbitrary precision, using motion\nprimitives given as bounded-rate multi-mode systems. We give an algorithm to\nsolve the problem and show that the problem is co-NP complete. We further prove\nthat the problem can be solved in polynomial time for multi-mode systems with\nfixed dimension. We study the problem with dwell-time requirement and show the\ndecidability of the problem under certain positivity restriction on the rate\nvectors. Finally, we show that introducing structure to the multi-mode systems\nleads to undecidability, even when using only a single clock variable.\n", "Comment: 14 pages, 12 figures, HSCC - 2015"]}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3670"}}, {"publisher": {"name": ""}, "description": "  We construct random point processes in the complex plane that are\nasymptotically close to a given doubling measure. The processes we construct\nare the zero sets of random entire functions that are constructed through\ngeneralised Fock spaces. We offer two alternative constructions, one via bases\nfor these spaces and another via frames, and we show that for both\nconstructions the average distribution of the zero set is close to the given\ndoubling measure, and that the variance is much less than the variance of the\ncorresponding Poisson point process. We prove some asymptotic large deviation\nestimates for these processes, which in particular allow us to estimate the\n`hole probability', the probability that there are no zeroes in a given open\nbounded subset of the plane. We also show that the `smooth linear statistics'\nare asymptotically normal, under an additional regularity hypothesis on the\nmeasure. These generalise previous results by Sodin and Tsirelson for the\nLebesgue measure.\n", "contributors": [{"name": "Buckley, Jeremiah", "sameAs": [], "familyName": "Buckley", "additionalName": "", "givenName": "Jeremiah", "email": ""}, {"name": "Massaneda, Xavier", "sameAs": [], "familyName": "Massaneda", "additionalName": "", "givenName": "Xavier", "email": ""}, {"name": "Ortega-Cerd\u00e0, Joaquim", "sameAs": [], "familyName": "Ortega-Cerd\u00e0", "additionalName": "", "givenName": "Joaquim", "email": ""}], "title": "Inhomogenous random zero sets", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-12-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1212.5548", "Indiana Univ. Math. J. 63 (2014), no. 3, 739-781", "doi:10.1512/iumj.2014.63.5260", "oai:arXiv.org:1212.5548"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We construct random point processes in the complex plane that are\nasymptotically close to a given doubling measure. The processes we construct\nare the zero sets of random entire functions that are constructed through\ngeneralised Fock spaces. We offer two alternative constructions, one via bases\nfor these spaces and another via frames, and we show that for both\nconstructions the average distribution of the zero set is close to the given\ndoubling measure, and that the variance is much less than the variance of the\ncorresponding Poisson point process. We prove some asymptotic large deviation\nestimates for these processes, which in particular allow us to estimate the\n`hole probability', the probability that there are no zeroes in a given open\nbounded subset of the plane. We also show that the `smooth linear statistics'\nare asymptotically normal, under an additional regularity hypothesis on the\nmeasure. These generalise previous results by Sodin and Tsirelson for the\nLebesgue measure.\n", "Comment: 39 paqes"]}}], "languages": [null], "subjects": ["mathematics - probability", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1212.5548"}}, {"publisher": {"name": ""}, "description": "  In this note we improve our upper bound given earlier by showing that every\n9-fold covering of a point set in the space by finitely many translates of an\noctant decomposes into two coverings, and our lower bound by a construction for\na 4-fold covering that does not decompose into two coverings. We also prove\nthat certain dynamic interval coloring problems are equivalent to the above\nquestion. The same bounds also hold for coverings of points in $\\R^2$ by\nfinitely many homothets or translates of a triangle.\n", "contributors": [{"name": "Keszegh, Bal\u00e1zs", "sameAs": [], "familyName": "Keszegh", "additionalName": "", "givenName": "Bal\u00e1zs", "email": ""}, {"name": "P\u00e1lv\u00f6lgyi, D\u00f6m\u00f6t\u00f6r", "sameAs": [], "familyName": "P\u00e1lv\u00f6lgyi", "additionalName": "", "givenName": "D\u00f6m\u00f6t\u00f6r", "email": ""}], "title": "More on Decomposing Coverings by Octants", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01669", "oai:arXiv.org:1503.01669"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this note we improve our upper bound given earlier by showing that every\n9-fold covering of a point set in the space by finitely many translates of an\noctant decomposes into two coverings, and our lower bound by a construction for\na 4-fold covering that does not decompose into two coverings. We also prove\nthat certain dynamic interval coloring problems are equivalent to the above\nquestion. The same bounds also hold for coverings of points in $\\R^2$ by\nfinitely many homothets or translates of a triangle.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01669"}}, {"publisher": {"name": ""}, "description": "  In blind hyperspectral unmixing (HU), the pure-pixel assumption is well-known\nto be powerful in enabling simple and effective blind HU solutions. However,\nthe pure-pixel assumption is not always satisfied in an exact sense, especially\nfor scenarios where pixels are heavily mixed. In the no pure-pixel case, a good\nblind HU approach to consider is the minimum volume enclosing simplex (MVES).\nEmpirical experience has suggested that MVES algorithms can perform well\nwithout pure pixels, although it was not totally clear why this is true from a\ntheoretical viewpoint. This paper aims to address the latter issue. We develop\nan analysis framework wherein the perfect endmember identifiability of MVES is\nstudied under the noiseless case. We prove that MVES is indeed robust against\nlack of pure pixels, as long as the pixels do not get too heavily mixed and too\nasymmetrically spread. The theoretical results are verified by numerical\nsimulations.\n", "contributors": [{"name": "Lin, Chia-Hsiang", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Chia-Hsiang", "email": ""}, {"name": "Ma, Wing-Kin", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Wing-Kin", "email": ""}, {"name": "Li, Wei-Chiang", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Wei-Chiang", "email": ""}, {"name": "Chi, Chong-Yung", "sameAs": [], "familyName": "Chi", "additionalName": "", "givenName": "Chong-Yung", "email": ""}, {"name": "Ambikapathi, ArulMurugan", "sameAs": [], "familyName": "Ambikapathi", "additionalName": "", "givenName": "ArulMurugan", "email": ""}], "title": "Identifiability of the Simplex Volume Minimization Criterion for Blind\n  Hyperspectral Unmixing: The No Pure-Pixel Case", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-19", "2015-02-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.5273", "oai:arXiv.org:1406.5273"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  In blind hyperspectral unmixing (HU), the pure-pixel assumption is well-known\nto be powerful in enabling simple and effective blind HU solutions. However,\nthe pure-pixel assumption is not always satisfied in an exact sense, especially\nfor scenarios where pixels are heavily mixed. In the no pure-pixel case, a good\nblind HU approach to consider is the minimum volume enclosing simplex (MVES).\nEmpirical experience has suggested that MVES algorithms can perform well\nwithout pure pixels, although it was not totally clear why this is true from a\ntheoretical viewpoint. This paper aims to address the latter issue. We develop\nan analysis framework wherein the perfect endmember identifiability of MVES is\nstudied under the noiseless case. We prove that MVES is indeed robust against\nlack of pure pixels, as long as the pixels do not get too heavily mixed and too\nasymmetrically spread. The theoretical results are verified by numerical\nsimulations.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - information theory", "statistics - machine learning"], "providerUpdatedDateTime": "2015-02-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.5273"}}, {"publisher": {"name": ""}, "description": "  Optical coherence tomography (OCT) is an important interferometric diagnostic\ntechnique which provides cross-sectional views of the subsurface microstructure\nof biological tissues. However, the imaging quality of high-speed OCT is\nlimited due to the large speckle noise. To address this problem, this paper\nproposes a multi-frame algorithmic method to denoise OCT volume.\nMathematically, we build an optimization model which forces the temporally\nregistered frames to be low rank, and the gradient in each frame to be sparse,\nunder logarithmic image formation and noise variance constraints. Besides, a\nconvex optimization algorithm based on the augmented Lagrangian method is\nderived to solve the above model. The results reveal that our approach\noutperforms the other methods in terms of both speckle noise suppression and\ncrucial detail preservation.\n", "contributors": [{"name": "Bian, Liheng", "sameAs": [], "familyName": "Bian", "additionalName": "", "givenName": "Liheng", "email": ""}, {"name": "Suo, Jinli", "sameAs": [], "familyName": "Suo", "additionalName": "", "givenName": "Jinli", "email": ""}, {"name": "Chen, Feng", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Feng", "email": ""}, {"name": "Dai, Qionghai", "sameAs": [], "familyName": "Dai", "additionalName": "", "givenName": "Qionghai", "email": ""}], "title": "Multi-frame denoising of high speed optical coherence tomography data\n  using inter-frame and intra-frame priors", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-06", "2014-11-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.1931", "doi:10.1117/1.JBO.20.3.036006", "oai:arXiv.org:1312.1931"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Optical coherence tomography (OCT) is an important interferometric diagnostic\ntechnique which provides cross-sectional views of the subsurface microstructure\nof biological tissues. However, the imaging quality of high-speed OCT is\nlimited due to the large speckle noise. To address this problem, this paper\nproposes a multi-frame algorithmic method to denoise OCT volume.\nMathematically, we build an optimization model which forces the temporally\nregistered frames to be low rank, and the gradient in each frame to be sparse,\nunder logarithmic image formation and noise variance constraints. Besides, a\nconvex optimization algorithm based on the augmented Lagrangian method is\nderived to solve the above model. The results reveal that our approach\noutperforms the other methods in terms of both speckle noise suppression and\ncrucial detail preservation.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.1931"}}, {"publisher": {"name": ""}, "description": "  Non-intrusive load monitoring (NILM) or energy disaggregation, aims to\ndisaggregate a household's electricity consumption into constituent appliances.\nMore than three decades of work in NILM has resulted in the development of\nseveral novel algorithmic approaches. However, despite these advancements, two\ncore challenges still exist: i) disaggregating low power consumption appliances\nand ii) distinguishing between multiple instances of similar appliances. These\nchallenges are becoming increasingly important due to an increasing number of\nappliances and increased usage of electronics in homes. Previous approaches\nhave attempted to solve these problems using expensive hardware involving high\nsampling rates better suited to laboratory settings, or using additional number\nof sensors, limiting the ease of deployment. In this work, we explore using\ncommercial-off-the-shelf (COTS) power line communication (PLC) modems as an\ninexpensive and easy to deploy alternative solution to these problems. We use\nthe reduction in bandwidth between two PLC modems, caused due to the change in\nPLC modulation scheme when different appliances are operated as a signature for\nan appliance. Since the noise generated in the powerline is dependent both on\ntype and location of an appliance, we believe that our technique based on PLC\nmodems can be a promising addition for solving NILM.\n", "contributors": [{"name": "Batra, Nipun", "sameAs": [], "familyName": "Batra", "additionalName": "", "givenName": "Nipun", "email": ""}, {"name": "Gulati, Manoj", "sameAs": [], "familyName": "Gulati", "additionalName": "", "givenName": "Manoj", "email": ""}, {"name": "Jain, Puneet", "sameAs": [], "familyName": "Jain", "additionalName": "", "givenName": "Puneet", "email": ""}, {"name": "Whitehouse, Kamin", "sameAs": [], "familyName": "Whitehouse", "additionalName": "", "givenName": "Kamin", "email": ""}, {"name": "Singh, Amarjeet", "sameAs": [], "familyName": "Singh", "additionalName": "", "givenName": "Amarjeet", "email": ""}], "title": "Poster Abstract: Bits and Watts: Improving energy disaggregation\n  performance using power line communication modems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-20", "2014-10-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.5907", "doi:10.1145/2674061.2675039", "oai:arXiv.org:1409.5907"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Non-intrusive load monitoring (NILM) or energy disaggregation, aims to\ndisaggregate a household's electricity consumption into constituent appliances.\nMore than three decades of work in NILM has resulted in the development of\nseveral novel algorithmic approaches. However, despite these advancements, two\ncore challenges still exist: i) disaggregating low power consumption appliances\nand ii) distinguishing between multiple instances of similar appliances. These\nchallenges are becoming increasingly important due to an increasing number of\nappliances and increased usage of electronics in homes. Previous approaches\nhave attempted to solve these problems using expensive hardware involving high\nsampling rates better suited to laboratory settings, or using additional number\nof sensors, limiting the ease of deployment. In this work, we explore using\ncommercial-off-the-shelf (COTS) power line communication (PLC) modems as an\ninexpensive and easy to deploy alternative solution to these problems. We use\nthe reduction in bandwidth between two PLC modems, caused due to the change in\nPLC modulation scheme when different appliances are operated as a signature for\nan appliance. Since the noise generated in the powerline is dependent both on\ntype and location of an appliance, we believe that our technique based on PLC\nmodems can be a promising addition for solving NILM.\n"}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.5907"}}, {"publisher": {"name": ""}, "description": "  We introduce the study of forcing sets in mathematical origami. The origami\nmaterial folds flat along straight line segments called creases, each of which\nis assigned a folding direction of mountain or valley. A subset $F$ of creases\nis forcing if the global folding mountain/valley assignment can be deduced from\nits restriction to $F$. In this paper we focus on one particular class of\nfoldable patterns called Miura-ori, which divide the plane into congruent\nparallelograms using horizontal lines and zig-zag vertical lines. We develop\nefficient algorithms for constructing a minimum forcing set of a Miura-ori map,\nand for deciding whether a given set of creases is forcing or not. We also\nprovide tight bounds on the size of a forcing set, establishing that the\nstandard mountain-valley assignment for the Miura-ori is the one that requires\nthe most creases in its forcing sets. Additionally, given a partial\nmountain/valley assignment to a subset of creases of a Miura-ori map, we\ndetermine whether the assignment domain can be extended to a locally\nflat-foldable pattern on all the creases. At the heart of our results is a\nnovel correspondence between flat-foldable Miura-ori maps and $3$-colorings of\ngrid graphs.\n", "contributors": [{"name": "Ballinger, Brad", "sameAs": [], "familyName": "Ballinger", "additionalName": "", "givenName": "Brad", "email": ""}, {"name": "Damian, Mirela", "sameAs": [], "familyName": "Damian", "additionalName": "", "givenName": "Mirela", "email": ""}, {"name": "Eppstein, David", "sameAs": [], "familyName": "Eppstein", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Flatland, Robin", "sameAs": [], "familyName": "Flatland", "additionalName": "", "givenName": "Robin", "email": ""}, {"name": "Ginepro, Jessica", "sameAs": [], "familyName": "Ginepro", "additionalName": "", "givenName": "Jessica", "email": ""}, {"name": "Hull, Thomas", "sameAs": [], "familyName": "Hull", "additionalName": "", "givenName": "Thomas", "email": ""}], "title": "Minimum Forcing Sets for Miura Folding Patterns", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2231", "oai:arXiv.org:1410.2231"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We introduce the study of forcing sets in mathematical origami. The origami\nmaterial folds flat along straight line segments called creases, each of which\nis assigned a folding direction of mountain or valley. A subset $F$ of creases\nis forcing if the global folding mountain/valley assignment can be deduced from\nits restriction to $F$. In this paper we focus on one particular class of\nfoldable patterns called Miura-ori, which divide the plane into congruent\nparallelograms using horizontal lines and zig-zag vertical lines. We develop\nefficient algorithms for constructing a minimum forcing set of a Miura-ori map,\nand for deciding whether a given set of creases is forcing or not. We also\nprovide tight bounds on the size of a forcing set, establishing that the\nstandard mountain-valley assignment for the Miura-ori is the one that requires\nthe most creases in its forcing sets. Additionally, given a partial\nmountain/valley assignment to a subset of creases of a Miura-ori map, we\ndetermine whether the assignment domain can be extended to a locally\nflat-foldable pattern on all the creases. At the heart of our results is a\nnovel correspondence between flat-foldable Miura-ori maps and $3$-colorings of\ngrid graphs.\n", "Comment: 20 pages, 16 figures. To appear at the ACM/SIAM Symp. on Discrete\n  Algorithms (SODA 2015)"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "f.2.2", "computer science - discrete mathematics"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2231"}}, {"publisher": {"name": ""}, "description": "  Scientometrics is the study of the quantitative aspects of the process of\nscience as a communication system. It is centrally, but not only, concerned\nwith the analysis of citations in the academic literature. In recent years it\nhas come to play a major role in the measurement and evaluation of research\nperformance. In this review we consider: the historical development of\nscientometrics, sources of citation data, citation metrics and the \"laws\" of\nscientometrics, normalisation, journal impact factors and other journal\nmetrics, visualising and mapping science, evaluation and policy, and future\ndevelopments.\n", "contributors": [{"name": "Mingers, John", "sameAs": [], "familyName": "Mingers", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Leydesdorff, Loet", "sameAs": [], "familyName": "Leydesdorff", "additionalName": "", "givenName": "Loet", "email": ""}], "title": "A Review of Theory and Practice in Scientometrics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-22", "2015-04-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05462", "oai:arXiv.org:1501.05462"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Scientometrics is the study of the quantitative aspects of the process of\nscience as a communication system. It is centrally, but not only, concerned\nwith the analysis of citations in the academic literature. In recent years it\nhas come to play a major role in the measurement and evaluation of research\nperformance. In this review we consider: the historical development of\nscientometrics, sources of citation data, citation metrics and the \"laws\" of\nscientometrics, normalisation, journal impact factors and other journal\nmetrics, visualising and mapping science, evaluation and policy, and future\ndevelopments.\n", "Comment: accepted for publication in the European Journal of Operational\n  Research"]}}], "languages": [null], "subjects": ["computer science - digital libraries"], "providerUpdatedDateTime": "2015-04-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05462"}}, {"publisher": {"name": ""}, "description": "  Bit-interleaved coded modulation (BICM) using (bi-)orthogonal signals is\nespecially well suited for the application in impulse-radio ultra-wideband\ntransmission systems, which typically operate in the power-limited regime and\nrequire a very low-complexity transmitter and receiver design. In this paper we\nanalyze the capacity of BICM using (bi-)orthogonal signals with coherent and\nnoncoherent detection and put particular focus on the power-limited or wideband\nregime. We give analytical expressions for the ratio energy per bit vs. noise\npower spectral density in the limit of infinite bandwidth and the respective\nwideband slope, and thus, are able to quantify the loss incurred by the\nrestriction to BICM in contrast to coded modulation. The gained theoretical\ninsights allow to derive design rules for impulse-radio ultra-wideband\ntransmission systems.\n", "contributors": [{"name": "Schenk, Andreas", "sameAs": [], "familyName": "Schenk", "additionalName": "", "givenName": "Andreas", "email": ""}, {"name": "Fischer, Robert F. H.", "sameAs": [], "familyName": "Fischer", "additionalName": "F. H.", "givenName": "Robert", "email": ""}], "title": "Capacity of BICM Using (Bi-)Orthogonal Signal Constellations in\n  Impulse-Radio Ultra-Wideband Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-02-14", "2011-04-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1102.2761", "oai:arXiv.org:1102.2761"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Bit-interleaved coded modulation (BICM) using (bi-)orthogonal signals is\nespecially well suited for the application in impulse-radio ultra-wideband\ntransmission systems, which typically operate in the power-limited regime and\nrequire a very low-complexity transmitter and receiver design. In this paper we\nanalyze the capacity of BICM using (bi-)orthogonal signals with coherent and\nnoncoherent detection and put particular focus on the power-limited or wideband\nregime. We give analytical expressions for the ratio energy per bit vs. noise\npower spectral density in the limit of infinite bandwidth and the respective\nwideband slope, and thus, are able to quantify the loss incurred by the\nrestriction to BICM in contrast to coded modulation. The gained theoretical\ninsights allow to derive design rules for impulse-radio ultra-wideband\ntransmission systems.\n", "Comment: Draft-version of a manuscript submitted to ICUWB'11"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1102.2761"}}, {"publisher": {"name": ""}, "description": "  Taking full advantages of both heterogeneous networks (HetNets) and cloud\naccess radio access networks (CRANs), heterogeneous cloud radio access networks\n(H-CRANs) are presented to enhance both the spectral and energy efficiencies,\nwhere remote radio heads (RRHs) are mainly used to provide high data rates for\nusers with high quality of service (QoS) requirements, while the high power\nnode (HPN) is deployed to guarantee the seamless coverage and serve users with\nlow QoS requirements. To mitigate the inter-tier interference and improve EE\nperformances in H-CRANs, characterizing user association with RRH/HPN is\nconsidered in this paper, and the traditional soft fractional frequency reuse\n(S-FFR) is enhanced. Based on the RRH/HPN association constraint and the\nenhanced S-FFR, an energy-efficient optimization problem with the resource\nassignment and power allocation for the orthogonal frequency division multiple\naccess (OFDMA) based H-CRANs is formulated as a non-convex objective function.\nTo deal with the non-convexity, an equivalent convex feasibility problem is\nreformulated, and closedform expressions for the energy-efficient resource\nallocation solution to jointly allocate the resource block and transmit power\nare derived by the Lagrange dual decomposition method. Simulation results\nconfirm that the H-CRAN architecture and the corresponding resource allocation\nsolution can enhance the energy efficiency significantly.\n", "contributors": [{"name": "Peng, Mugen", "sameAs": [], "familyName": "Peng", "additionalName": "", "givenName": "Mugen", "email": ""}, {"name": "Zhang, Kecheng", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Kecheng", "email": ""}, {"name": "Jiang, Jiamo", "sameAs": [], "familyName": "Jiang", "additionalName": "", "givenName": "Jiamo", "email": ""}, {"name": "Wang, Jiaheng", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Jiaheng", "email": ""}, {"name": "Wang, Wenbo", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Wenbo", "email": ""}], "title": "Energy-Efficient Resource Assignment and Power Allocation in\n  Heterogeneous Cloud Radio Access Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3788", "oai:arXiv.org:1412.3788"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Taking full advantages of both heterogeneous networks (HetNets) and cloud\naccess radio access networks (CRANs), heterogeneous cloud radio access networks\n(H-CRANs) are presented to enhance both the spectral and energy efficiencies,\nwhere remote radio heads (RRHs) are mainly used to provide high data rates for\nusers with high quality of service (QoS) requirements, while the high power\nnode (HPN) is deployed to guarantee the seamless coverage and serve users with\nlow QoS requirements. To mitigate the inter-tier interference and improve EE\nperformances in H-CRANs, characterizing user association with RRH/HPN is\nconsidered in this paper, and the traditional soft fractional frequency reuse\n(S-FFR) is enhanced. Based on the RRH/HPN association constraint and the\nenhanced S-FFR, an energy-efficient optimization problem with the resource\nassignment and power allocation for the orthogonal frequency division multiple\naccess (OFDMA) based H-CRANs is formulated as a non-convex objective function.\nTo deal with the non-convexity, an equivalent convex feasibility problem is\nreformulated, and closedform expressions for the energy-efficient resource\nallocation solution to jointly allocate the resource block and transmit power\nare derived by the Lagrange dual decomposition method. Simulation results\nconfirm that the H-CRAN architecture and the corresponding resource allocation\nsolution can enhance the energy efficiency significantly.\n", "Comment: 13 pages, 7 figures, accepted by IEEE TVT"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3788"}}, {"publisher": {"name": ""}, "description": "  In this paper, we show $O(1.415^n)$-time and $O(1.190^n)$-space exact\nalgorithms for 0-1 integer programs where constraints are linear equalities and\ncoefficients are arbitrary real numbers. Our algorithms are quadratically\nfaster than exhaustive search and almost quadratically faster than an algorithm\nfor an inequality version of the problem by Impagliazzo, Lovett, Paturi and\nSchneider (arXiv:1401.5512), which motivated our work. Rather than improving\nthe time and space complexity, we advance to a simple direction as inclusion of\nmany NP-hard problems in terms of exact exponential algorithms. Specifically,\nwe extend our algorithms to linear optimization problems.\n", "contributors": [{"name": "Ueno, Kenya", "sameAs": [], "familyName": "Ueno", "additionalName": "", "givenName": "Kenya", "email": ""}], "title": "Exact Algorithms for 0-1 Integer Programs with Linear Equality\n  Constraints", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-27", "2014-11-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.6851", "oai:arXiv.org:1405.6851"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we show $O(1.415^n)$-time and $O(1.190^n)$-space exact\nalgorithms for 0-1 integer programs where constraints are linear equalities and\ncoefficients are arbitrary real numbers. Our algorithms are quadratically\nfaster than exhaustive search and almost quadratically faster than an algorithm\nfor an inequality version of the problem by Impagliazzo, Lovett, Paturi and\nSchneider (arXiv:1401.5512), which motivated our work. Rather than improving\nthe time and space complexity, we advance to a simple direction as inclusion of\nmany NP-hard problems in terms of exact exponential algorithms. Specifically,\nwe extend our algorithms to linear optimization problems.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.6851"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Training structured predictors often requires a considerable time selecting features or tweaking the kernel. Multiple kernel learning (MKL) sidesteps this issue by embedding the kernel learning into the training procedure. Despite the recent progress towards efficiency of MKL algorithms, the structured output case remains an open research front. We propose a family of online algorithms able to tackle variants of MKL and group-LASSO, for which we show regret, convergence, and generalization bounds. Experiments on handwriting recognition and dependency parsing attest the success of the approach.", "contributors": [{"name": "Martins, Andre F.T.", "sameAs": [], "familyName": "Martins", "additionalName": "F.T.", "givenName": "Andre", "email": ""}, {"name": "Smith, Noah A.", "sameAs": [], "familyName": "Smith", "additionalName": "A.", "givenName": "Noah", "email": ""}, {"name": "Xing, Eric P.", "sameAs": [], "familyName": "Xing", "additionalName": "P.", "givenName": "Eric", "email": ""}, {"name": "Aguiar, Pedro M.Q.", "sameAs": [], "familyName": "Aguiar", "additionalName": "M.Q.", "givenName": "Pedro", "email": ""}, {"name": "Figeuiredo, Mario A. T.", "sameAs": [], "familyName": "Figeuiredo", "additionalName": "A. T.", "givenName": "Mario", "email": ""}], "title": "Online Learning of Structured Predictors with Multiple Kernels", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2011-04-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/220", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1216&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1216"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:scs", "publication:machine_learning"]}}, {"name": "description", "properties": {"description": "Training structured predictors often requires a considerable time selecting features or tweaking the kernel. Multiple kernel learning (MKL) sidesteps this issue by embedding the kernel learning into the training procedure. Despite the recent progress towards efficiency of MKL algorithms, the structured output case remains an open research front. We propose a family of online algorithms able to tackle variants of MKL and group-LASSO, for which we show regret, convergence, and generalization bounds. Experiments on handwriting recognition and dependency parsing attest the success of the approach."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-04-09T20:51:32", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/220"}}, {"publisher": {"name": ""}, "description": "  The objective of Content-Based Image Retrieval (CBIR) methods is essentially\nto extract, from large (image) databases, a specified number of images similar\nin visual and semantic content to a so-called query image. To bridge the\nsemantic gap that exists between the representation of an image by low-level\nfeatures (namely, colour, shape, texture) and its high-level semantic content\nas perceived by humans, CBIR systems typically make use of the relevance\nfeedback (RF) mechanism. RF iteratively incorporates user-given inputs\nregarding the relevance of retrieved images, to improve retrieval efficiency.\nOne approach is to vary the weights of the features dynamically via feature\nreweighting. In this work, an attempt has been made to improve retrieval\naccuracy by enhancing a CBIR system based on color features alone, through\nimplicit incorporation of shape information obtained through prior segmentation\nof the images. Novel schemes for feature reweighting as well as for\ninitialization of the relevant set for improved relevance feedback, have also\nbeen proposed for boosting performance of RF- based CBIR. At the same time, new\nmeasures for evaluation of retrieval accuracy have been suggested, to overcome\nthe limitations of existing measures in the RF context. Results of extensive\nexperiments have been presented to illustrate the effectiveness of the proposed\napproaches.\n", "contributors": [{"name": "Bose, Smarajit", "sameAs": [], "familyName": "Bose", "additionalName": "", "givenName": "Smarajit", "email": ""}, {"name": "Pal, Amita", "sameAs": [], "familyName": "Pal", "additionalName": "", "givenName": "Amita", "email": ""}, {"name": "Mallick, Jhimli", "sameAs": [], "familyName": "Mallick", "additionalName": "", "givenName": "Jhimli", "email": ""}, {"name": "Kumar, Sunil", "sameAs": [], "familyName": "Kumar", "additionalName": "", "givenName": "Sunil", "email": ""}, {"name": "Rudra, Pratyaydipta", "sameAs": [], "familyName": "Rudra", "additionalName": "", "givenName": "Pratyaydipta", "email": ""}], "title": "A Hybrid Approach for Improved Content-based Image Retrieval using\n  Segmentation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03215", "oai:arXiv.org:1502.03215"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  The objective of Content-Based Image Retrieval (CBIR) methods is essentially\nto extract, from large (image) databases, a specified number of images similar\nin visual and semantic content to a so-called query image. To bridge the\nsemantic gap that exists between the representation of an image by low-level\nfeatures (namely, colour, shape, texture) and its high-level semantic content\nas perceived by humans, CBIR systems typically make use of the relevance\nfeedback (RF) mechanism. RF iteratively incorporates user-given inputs\nregarding the relevance of retrieved images, to improve retrieval efficiency.\nOne approach is to vary the weights of the features dynamically via feature\nreweighting. In this work, an attempt has been made to improve retrieval\naccuracy by enhancing a CBIR system based on color features alone, through\nimplicit incorporation of shape information obtained through prior segmentation\nof the images. Novel schemes for feature reweighting as well as for\ninitialization of the relevant set for improved relevance feedback, have also\nbeen proposed for boosting performance of RF- based CBIR. At the same time, new\nmeasures for evaluation of retrieval accuracy have been suggested, to overcome\nthe limitations of existing measures in the RF context. Results of extensive\nexperiments have been presented to illustrate the effectiveness of the proposed\napproaches.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval", "statistics - methodology", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03215"}}, {"publisher": {"name": ""}, "description": "  Oscillations between swing modes of electric machines is an important\nlimitation in achieving a high level of transient performance and reliability\nin power grids. Based on the new advances in measurement and transmission of\nwide-area information, this work proposes a distributed networked control\nscheme by considering the communication delays. The results are applied to\nreduce the inter-area swing oscillations in a power grid. In comparison with\nthe previous works, we provide a more realistic modeling of the resulting\nnetworked control system with data sampling and delays. The exactness of the\nproposed modeling allows for precise evaluation and comparison between the\ndistributed and decentralized schema. A symmetric a dual machine power system\nis highly oscillatory and we focus on this case to evaluate the ability of the\nproposed control design in dampening of the oscillations. The design can be\ndone either based on optimization of a quadratic cost function or a disturbance\nattenuation level\n", "contributors": [{"name": "Tavassoli, Babak", "sameAs": [], "familyName": "Tavassoli", "additionalName": "", "givenName": "Babak", "email": ""}], "title": "Design and Evaluation of Distributed Networked Control for a\n  Dual-Machine Power System", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01887", "oai:arXiv.org:1504.01887"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Oscillations between swing modes of electric machines is an important\nlimitation in achieving a high level of transient performance and reliability\nin power grids. Based on the new advances in measurement and transmission of\nwide-area information, this work proposes a distributed networked control\nscheme by considering the communication delays. The results are applied to\nreduce the inter-area swing oscillations in a power grid. In comparison with\nthe previous works, we provide a more realistic modeling of the resulting\nnetworked control system with data sampling and delays. The exactness of the\nproposed modeling allows for precise evaluation and comparison between the\ndistributed and decentralized schema. A symmetric a dual machine power system\nis highly oscillatory and we focus on this case to evaluate the ability of the\nproposed control design in dampening of the oscillations. The design can be\ndone either based on optimization of a quadratic cost function or a disturbance\nattenuation level\n"}}], "languages": [null], "subjects": ["computer science - systems and control"], "providerUpdatedDateTime": "2015-04-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01887"}}, {"publisher": {"name": ""}, "description": "  This article is about twofold arithmetic. Here I introduce algorithms and\nexperimental code for twofold variant of C/C++ standard functions exp() and\nlog(), and expm1() and log1p(). Twofold function $y_0+y_1 \\approx f(x_0+x_1)$\nis nearly 2x-precise so can assess accuracy of standard one. Performance allows\nassessing on-fly: twofold texp() over double is ~10x times faster than expq()\nby GNU quadmath.\n", "contributors": [{"name": "Latkin, Evgeny", "sameAs": [], "familyName": "Latkin", "additionalName": "", "givenName": "Evgeny", "email": ""}], "title": "Twofold exp and log", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.05216", "oai:arXiv.org:1502.05216"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This article is about twofold arithmetic. Here I introduce algorithms and\nexperimental code for twofold variant of C/C++ standard functions exp() and\nlog(), and expm1() and log1p(). Twofold function $y_0+y_1 \\approx f(x_0+x_1)$\nis nearly 2x-precise so can assess accuracy of standard one. Performance allows\nassessing on-fly: twofold texp() over double is ~10x times faster than expq()\nby GNU quadmath.\n", "Comment: Experimental code and tests at \"twofolds\" project Web site:\n  https://sites.google.com/site/yevgenylatkin/"]}}], "languages": [null], "subjects": ["computer science - mathematical software"], "providerUpdatedDateTime": "2015-02-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.05216"}}, {"publisher": {"name": ""}, "description": "  Motivated by the fact that transfer functions do not contain structural\ninformation about networks, dynamical structure functions were introduced to\ncapture causal relationships between measured nodes in networks. From the\ndynamical structure functions, a) we show that the actual number of hidden\nstates can be larger than the number of hidden states estimated from the\ncorresponding transfer function; b) we can obtain partial information about the\ntrue state-space equation, which cannot in general be obtained from the\ntransfer function. Based on these properties, this paper proposes algorithms to\nfind minimal realisations for a given dynamical structure function. This helps\nto estimate the minimal number of hidden states, to better understand the\ncomplexity of the network, and to identify potential targets for new\nmeasurements.\n", "contributors": [{"name": "Yuan, Ye", "sameAs": [], "familyName": "Yuan", "additionalName": "", "givenName": "Ye", "email": ""}, {"name": "Glover, Keith", "sameAs": [], "familyName": "Glover", "additionalName": "", "givenName": "Keith", "email": ""}, {"name": "Goncalvees, Jorge", "sameAs": [], "familyName": "Goncalvees", "additionalName": "", "givenName": "Jorge", "email": ""}], "title": "On minimal realisations of dynamical structure functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-29", "2014-12-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.0072", "oai:arXiv.org:1409.0072"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Motivated by the fact that transfer functions do not contain structural\ninformation about networks, dynamical structure functions were introduced to\ncapture causal relationships between measured nodes in networks. From the\ndynamical structure functions, a) we show that the actual number of hidden\nstates can be larger than the number of hidden states estimated from the\ncorresponding transfer function; b) we can obtain partial information about the\ntrue state-space equation, which cannot in general be obtained from the\ntransfer function. Based on these properties, this paper proposes algorithms to\nfind minimal realisations for a given dynamical structure function. This helps\nto estimate the minimal number of hidden states, to better understand the\ncomplexity of the network, and to identify potential targets for new\nmeasurements.\n"}}], "languages": [null], "subjects": ["computer science - systems and control"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.0072"}}, {"publisher": {"name": ""}, "description": "  This paper presents results on the typical number of simultaneous\npoint-to-point transmissions above a minimum rate that can be sustained in a\nnetwork with $n$ transmitter-receiver node pairs when all transmitting nodes\ncan potentially interfere with all receivers. In particular we obtain a scaling\nlaw when the fading gains are independent Rayleigh distributed random variables\nand the transmitters over different realizations are located at the points of a\nstationary Poisson field in the plane. We show that asymptotically with\nprobability approaching 1, the number of simultaneous transmissions (links that\ncan transmit at greater than a minimum rate) is of the order of\n$O(n^{\\frac{1}{4}})$. These asymptotic results are confirmed from simulations.\n", "contributors": [{"name": "Keshavarz, Hengameh", "sameAs": [], "familyName": "Keshavarz", "additionalName": "", "givenName": "Hengameh", "email": ""}, {"name": "Mazumdar, Ravi R.", "sameAs": [], "familyName": "Mazumdar", "additionalName": "R.", "givenName": "Ravi", "email": ""}, {"name": "Roy, Rahul", "sameAs": [], "familyName": "Roy", "additionalName": "", "givenName": "Rahul", "email": ""}, {"name": "Zoghalchi, Farshid", "sameAs": [], "familyName": "Zoghalchi", "additionalName": "", "givenName": "Farshid", "email": ""}], "title": "On the number of active links in random wireless networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3098", "oai:arXiv.org:1412.3098"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  This paper presents results on the typical number of simultaneous\npoint-to-point transmissions above a minimum rate that can be sustained in a\nnetwork with $n$ transmitter-receiver node pairs when all transmitting nodes\ncan potentially interfere with all receivers. In particular we obtain a scaling\nlaw when the fading gains are independent Rayleigh distributed random variables\nand the transmitters over different realizations are located at the points of a\nstationary Poisson field in the plane. We show that asymptotically with\nprobability approaching 1, the number of simultaneous transmissions (links that\ncan transmit at greater than a minimum rate) is of the order of\n$O(n^{\\frac{1}{4}})$. These asymptotic results are confirmed from simulations.\n"}}], "languages": [null], "subjects": ["computer science - information theory", "94a17", "secondary 60g60", "primary 94a40"], "providerUpdatedDateTime": "2014-12-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3098"}}, {"publisher": {"name": ""}, "description": "  Mobile network operators are facing the difficult task of significantly\nincreasing capacity to meet projected demand while keeping CAPEX and OPEX down.\nWe argue that infrastructure sharing is a key consideration in operators'\nplanning of the evolution of their networks, and that such planning can be\nviewed as a stage in the cognitive cycle. In this paper, we present a framework\nto model this planning process while taking into account both the ability to\nshare resources and the constraints imposed by competition regulation (the\nlatter quantified using the Herfindahl index). Using real-world demand and\ndeployment data, we find that the ability to share infrastructure essentially\nmoves capacity from rural, sparsely populated areas (where some of the current\ninfrastructure can be decommissioned) to urban ones (where most of the\nnext-generation base stations would be deployed), with significant increases in\nresource efficiency. Tight competition regulation somewhat limits the ability\nto share but does not entirely jeopardize those gains, while having the\nsecondary effect of encouraging the wider deployment of next-generation\ntechnologies.\n", "contributors": [{"name": "Di Francesco, Paolo", "sameAs": [], "familyName": "Di Francesco", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Malandrino, Francesco", "sameAs": [], "familyName": "Malandrino", "additionalName": "", "givenName": "Francesco", "email": ""}, {"name": "Forde, Tim K.", "sameAs": [], "familyName": "Forde", "additionalName": "K.", "givenName": "Tim", "email": ""}, {"name": "DaSilva, Luiz A.", "sameAs": [], "familyName": "DaSilva", "additionalName": "A.", "givenName": "Luiz", "email": ""}], "title": "A Sharing- and Competition-Aware Framework for Cellular Network\n  Evolution Planning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03213", "oai:arXiv.org:1504.03213"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Mobile network operators are facing the difficult task of significantly\nincreasing capacity to meet projected demand while keeping CAPEX and OPEX down.\nWe argue that infrastructure sharing is a key consideration in operators'\nplanning of the evolution of their networks, and that such planning can be\nviewed as a stage in the cognitive cycle. In this paper, we present a framework\nto model this planning process while taking into account both the ability to\nshare resources and the constraints imposed by competition regulation (the\nlatter quantified using the Herfindahl index). Using real-world demand and\ndeployment data, we find that the ability to share infrastructure essentially\nmoves capacity from rural, sparsely populated areas (where some of the current\ninfrastructure can be decommissioned) to urban ones (where most of the\nnext-generation base stations would be deployed), with significant increases in\nresource efficiency. Tight competition regulation somewhat limits the ability\nto share but does not entirely jeopardize those gains, while having the\nsecondary effect of encouraging the wider deployment of next-generation\ntechnologies.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03213"}}, {"publisher": {"name": ""}, "description": "  We propose a nonparametric procedure to achieve fast inference in generative\ngraphical models when the number of latent states is very large. The approach\nis based on iterative latent variable preselection, where we alternate between\nlearning a 'selection function' to reveal the relevant latent variables, and\nuse this to obtain a compact approximation of the posterior distribution for\nEM; this can make inference possible where the number of possible latent states\nis e.g. exponential in the number of latent variables, whereas an exact\napproach would be computationally unfeasible. We learn the selection function\nentirely from the observed data and current EM state via Gaussian process\nregression: this is by contrast with earlier approaches, where selections were\nhand-designed for each problem setting. We show our approach to perform as well\nas these bespoke selection functions on a wide variety of inference problems:\nin particular, for the challenging case of a hierarchical model for object\nlocalization with occlusion, we achieve results that match a customized\nstate-of-the-art selection method, at a far lower computational cost.\n", "contributors": [{"name": "Shelton, Jacquelyn A.", "sameAs": [], "familyName": "Shelton", "additionalName": "A.", "givenName": "Jacquelyn", "email": ""}, {"name": "Gasthaus, Jan", "sameAs": [], "familyName": "Gasthaus", "additionalName": "", "givenName": "Jan", "email": ""}, {"name": "Dai, Zhenwen", "sameAs": [], "familyName": "Dai", "additionalName": "", "givenName": "Zhenwen", "email": ""}, {"name": "Luecke, Joerg", "sameAs": [], "familyName": "Luecke", "additionalName": "", "givenName": "Joerg", "email": ""}, {"name": "Gretton, Arthur", "sameAs": [], "familyName": "Gretton", "additionalName": "", "givenName": "Arthur", "email": ""}], "title": "GP-select: Accelerating EM using adaptive subspace preselection", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3411", "oai:arXiv.org:1412.3411"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  We propose a nonparametric procedure to achieve fast inference in generative\ngraphical models when the number of latent states is very large. The approach\nis based on iterative latent variable preselection, where we alternate between\nlearning a 'selection function' to reveal the relevant latent variables, and\nuse this to obtain a compact approximation of the posterior distribution for\nEM; this can make inference possible where the number of possible latent states\nis e.g. exponential in the number of latent variables, whereas an exact\napproach would be computationally unfeasible. We learn the selection function\nentirely from the observed data and current EM state via Gaussian process\nregression: this is by contrast with earlier approaches, where selections were\nhand-designed for each problem setting. We show our approach to perform as well\nas these bespoke selection functions on a wide variety of inference problems:\nin particular, for the challenging case of a hierarchical model for object\nlocalization with occlusion, we achieve results that match a customized\nstate-of-the-art selection method, at a far lower computational cost.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-12-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3411"}}, {"publisher": {"name": ""}, "description": "  This paper considers the problem of distributed estimation in an incremental\nnetwork when the measurements taken by the node follow a widely linear model.\nThe proposed algorithm which we refer to it as incremental augmented affine\nprojection algorithm (incAAPA) utilizes the full second order statistical\ninformation in the complex domain. Moreover, it exploits spatio-temporal\ndiversity to improve the estimation performance. We derive steady-state\nperformance metric of the incAAPA in terms of the mean-square deviation (MSD).\nWe further derive sufficient conditions to ensure mean-square convergence. Our\nanalysis illustrate that the proposed algorithm is able to process both second\norder circular (proper) and noncircular (improper) signals. The validity of the\ntheoretical results and the good performance of the proposed algorithm are\ndemonstrated by several computer simulations.\n", "contributors": [{"name": "Khalili, Azam", "sameAs": [], "familyName": "Khalili", "additionalName": "", "givenName": "Azam", "email": ""}, {"name": "Bazzi, Wael M.", "sameAs": [], "familyName": "Bazzi", "additionalName": "M.", "givenName": "Wael", "email": ""}, {"name": "Rastegarnia, Amir", "sameAs": [], "familyName": "Rastegarnia", "additionalName": "", "givenName": "Amir", "email": ""}], "title": "Analysis of incremental augmented affine projection algorithm for\n  distributed estimation of complex signals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4477", "oai:arXiv.org:1410.4477"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper considers the problem of distributed estimation in an incremental\nnetwork when the measurements taken by the node follow a widely linear model.\nThe proposed algorithm which we refer to it as incremental augmented affine\nprojection algorithm (incAAPA) utilizes the full second order statistical\ninformation in the complex domain. Moreover, it exploits spatio-temporal\ndiversity to improve the estimation performance. We derive steady-state\nperformance metric of the incAAPA in terms of the mean-square deviation (MSD).\nWe further derive sufficient conditions to ensure mean-square convergence. Our\nanalysis illustrate that the proposed algorithm is able to process both second\norder circular (proper) and noncircular (improper) signals. The validity of the\ntheoretical results and the good performance of the proposed algorithm are\ndemonstrated by several computer simulations.\n", "Comment: 23 pages, 6 figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4477"}}, {"publisher": {"name": ""}, "description": "  This paper presents a generalization of the $\\kappa$-$\\mu$ shadowed model\nwhen multiple antennas are present at both the transmitter and receiver sides,\ni.e, for a multiple-input multiple-output (MIMO) scenario. Using multivariate\nstatistical theory, the MIMO $\\kappa$-$\\mu$ shadowed model is defined. Its\nprobability density function (pdf) can be expressed in terms of the well-known\ngamma-Wishart distribution and the moment generating function is carried out\nfrom it. Closed-form expressions for the cumulative distribution function (cdf)\nand the pdf of the maximum eigenvalue are derived. Like the single-input\nsingle-output (SISO) model present in the literature, the MIMO $\\kappa$-$\\mu$\nshadowed model allows the unification of some MIMO stochastic channels. In\nfact, the MIMO Rayleigh, MIMO Nakagami-$m$, MIMO Rician, MIMO $\\kappa$-$\\mu$\nand MIMO Rician-Shadowed models can be derived from it, and so their SISO\ncounterparts, i.e, the Rayleigh, Nakagami-$m$, Rician, $\\kappa$-$\\mu$ and\nRician-Shadowed, respectively.\n", "contributors": [{"name": "Moreno-Pozas, Laureano", "sameAs": [], "familyName": "Moreno-Pozas", "additionalName": "", "givenName": "Laureano", "email": ""}, {"name": "Martos-Naya, Eduardo", "sameAs": [], "familyName": "Martos-Naya", "additionalName": "", "givenName": "Eduardo", "email": ""}], "title": "A Random Matrix Model for $\\kappa$-$\\mu$ Shadowed Fading", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-15", "2015-03-23"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.3998", "oai:arXiv.org:1410.3998"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper presents a generalization of the $\\kappa$-$\\mu$ shadowed model\nwhen multiple antennas are present at both the transmitter and receiver sides,\ni.e, for a multiple-input multiple-output (MIMO) scenario. Using multivariate\nstatistical theory, the MIMO $\\kappa$-$\\mu$ shadowed model is defined. Its\nprobability density function (pdf) can be expressed in terms of the well-known\ngamma-Wishart distribution and the moment generating function is carried out\nfrom it. Closed-form expressions for the cumulative distribution function (cdf)\nand the pdf of the maximum eigenvalue are derived. Like the single-input\nsingle-output (SISO) model present in the literature, the MIMO $\\kappa$-$\\mu$\nshadowed model allows the unification of some MIMO stochastic channels. In\nfact, the MIMO Rayleigh, MIMO Nakagami-$m$, MIMO Rician, MIMO $\\kappa$-$\\mu$\nand MIMO Rician-Shadowed models can be derived from it, and so their SISO\ncounterparts, i.e, the Rayleigh, Nakagami-$m$, Rician, $\\kappa$-$\\mu$ and\nRician-Shadowed, respectively.\n", "Comment: This work has been submitted to an international for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.3998"}}, {"publisher": {"name": ""}, "description": "  This paper presents a digital signal processing tool developed using\nMatlabTM, which provides a very low-cost and effective strategy for\nanalog-to-digital conversion of legated paper biomedical maps without requiring\ndedicated hardware. This software-based approach is particularly helpful for\ndigitalizing biomedical signals acquired from analogical devices equipped with\na plottingter. Albeit signals used in biomedical diagnosis are the primary\nconcern, this imaging processing tool is suitable to modernize facilities in a\nnon-expensive way. Legated paper ECG and EEG charts can be fast and efficiently\ndigitalized in order to be added in existing up-to-date medical data banks,\nimproving the follow-up of patients.\n", "contributors": [{"name": "Silva, A. R. Gomes e", "sameAs": [], "familyName": "Silva", "additionalName": "R. Gomes e", "givenName": "A.", "email": ""}, {"name": "de Oliveira, H. M.", "sameAs": [], "familyName": "de Oliveira", "additionalName": "M.", "givenName": "H.", "email": ""}, {"name": "Lins, R. D.", "sameAs": [], "familyName": "Lins", "additionalName": "D.", "givenName": "R.", "email": ""}], "title": "Converting ECG and other paper legated biomedical maps into digital\n  signals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.05906", "oai:arXiv.org:1502.05906"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper presents a digital signal processing tool developed using\nMatlabTM, which provides a very low-cost and effective strategy for\nanalog-to-digital conversion of legated paper biomedical maps without requiring\ndedicated hardware. This software-based approach is particularly helpful for\ndigitalizing biomedical signals acquired from analogical devices equipped with\na plottingter. Albeit signals used in biomedical diagnosis are the primary\nconcern, this imaging processing tool is suitable to modernize facilities in a\nnon-expensive way. Legated paper ECG and EEG charts can be fast and efficiently\ndigitalized in order to be added in existing up-to-date medical data banks,\nimproving the follow-up of patients.\n", "Comment: 5 pages, 8 figures. XXV Simposio Brasileiro de Telecomunicacoes, 2007"]}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2015-02-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.05906"}}, {"publisher": {"name": ""}, "description": "  Working in a three-dimensional variant of Winfree's abstract Tile Assembly\nModel, we show that, for all $N \\in \\mathbb{N}$, there is a tile set that\nuniquely self-assembles into an $N \\times N$ square shape at temperature 1 with\noptimal program-size complexity of $O(\\log N / \\log \\log N)$ (the program-size\ncomplexity, also known as tile complexity, of a shape is the minimum number of\nunique tile types required to uniquely self-assemble it). Moreover, our\nconstruction is \"just barely\" 3D in the sense that it works even when the\nplacement of tiles is restricted to the $z = 0$ and $z = 1$ planes. This result\naffirmatively answers an open question from Cook, Fu, Schweller (SODA 2011). To\nachieve this result, we develop a general 3D temperature 1 optimal encoding\nconstruction, reminiscent of the 2D temperature 2 optimal encoding construction\nof Soloveichik and Winfree (SICOMP 2007), and perhaps of independent interest.\n", "contributors": [{"name": "Furcy, David", "sameAs": [], "familyName": "Furcy", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Micka, Samuel", "sameAs": [], "familyName": "Micka", "additionalName": "", "givenName": "Samuel", "email": ""}, {"name": "Summers, Scott M.", "sameAs": [], "familyName": "Summers", "additionalName": "M.", "givenName": "Scott", "email": ""}], "title": "Optimal program-size complexity for self-assembly at temperature 1 in 3D", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1122", "oai:arXiv.org:1411.1122"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Working in a three-dimensional variant of Winfree's abstract Tile Assembly\nModel, we show that, for all $N \\in \\mathbb{N}$, there is a tile set that\nuniquely self-assembles into an $N \\times N$ square shape at temperature 1 with\noptimal program-size complexity of $O(\\log N / \\log \\log N)$ (the program-size\ncomplexity, also known as tile complexity, of a shape is the minimum number of\nunique tile types required to uniquely self-assemble it). Moreover, our\nconstruction is \"just barely\" 3D in the sense that it works even when the\nplacement of tiles is restricted to the $z = 0$ and $z = 1$ planes. This result\naffirmatively answers an open question from Cook, Fu, Schweller (SODA 2011). To\nachieve this result, we develop a general 3D temperature 1 optimal encoding\nconstruction, reminiscent of the 2D temperature 2 optimal encoding construction\nof Soloveichik and Winfree (SICOMP 2007), and perhaps of independent interest.\n"}}], "languages": [null], "subjects": ["computer science - emerging technologies", "computer science - computational geometry"], "providerUpdatedDateTime": "2014-11-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1122"}}, {"publisher": {"name": ""}, "description": "  The R package sns implements Stochastic Newton Sampler (SNS), a\nMetropolis-Hastings Monte Carlo Markov Chain algorithm where the proposal\ndensity function is a multivariate Gaussian based on a local, second-order\nTaylor series expansion of log-density. The mean of the proposal function is\nthe full Newton step in Newton-Raphson optimization algorithm. Taking advantage\nof the local, multivariate geometry captured in log-density Hessian allows SNS\nto be more efficient than univariate samplers, approaching independent sampling\nas the density function increasingly resembles a multivariate Gaussian. SNS\nrequires the log-density Hessian to be negative-definite everywhere in order to\nconstruct a valid proposal function. This property holds, or can be easily\nchecked, for many GLM-like models. When initial point is far from density peak,\nrunning SNS in non-stochastic mode by taking the Newton step, augmented with\nwith line search, allows the MCMC chain to converge to high-density areas\nfaster. For high-dimensional problems, partitioning of state space into\nlower-dimensional subsets, and applying SNS to the subsets within a Gibbs\nsampling framework can significantly improve the mixing of SNS chains. In\naddition to the above strategies for improving convergence and mixing, sns\noffers diagnostics and visualization capabilities, as well as a function for\nsample-based calculation of Bayesian predictive posterior distributions.\n", "contributors": [{"name": "Mahani, Alireza S.", "sameAs": [], "familyName": "Mahani", "additionalName": "S.", "givenName": "Alireza", "email": ""}, {"name": "Hasan, Asad", "sameAs": [], "familyName": "Hasan", "additionalName": "", "givenName": "Asad", "email": ""}, {"name": "Jiang, Marshall", "sameAs": [], "familyName": "Jiang", "additionalName": "", "givenName": "Marshall", "email": ""}, {"name": "Sharabiani, Mansour T. A.", "sameAs": [], "familyName": "Sharabiani", "additionalName": "T. A.", "givenName": "Mansour", "email": ""}], "title": "Stochastic Newton Sampler: R Package sns", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02008", "oai:arXiv.org:1502.02008"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  The R package sns implements Stochastic Newton Sampler (SNS), a\nMetropolis-Hastings Monte Carlo Markov Chain algorithm where the proposal\ndensity function is a multivariate Gaussian based on a local, second-order\nTaylor series expansion of log-density. The mean of the proposal function is\nthe full Newton step in Newton-Raphson optimization algorithm. Taking advantage\nof the local, multivariate geometry captured in log-density Hessian allows SNS\nto be more efficient than univariate samplers, approaching independent sampling\nas the density function increasingly resembles a multivariate Gaussian. SNS\nrequires the log-density Hessian to be negative-definite everywhere in order to\nconstruct a valid proposal function. This property holds, or can be easily\nchecked, for many GLM-like models. When initial point is far from density peak,\nrunning SNS in non-stochastic mode by taking the Newton step, augmented with\nwith line search, allows the MCMC chain to converge to high-density areas\nfaster. For high-dimensional problems, partitioning of state space into\nlower-dimensional subsets, and applying SNS to the subsets within a Gibbs\nsampling framework can significantly improve the mixing of SNS chains. In\naddition to the above strategies for improving convergence and mixing, sns\noffers diagnostics and visualization capabilities, as well as a function for\nsample-based calculation of Bayesian predictive posterior distributions.\n"}}], "languages": [null], "subjects": ["statistics - computation", "statistics - methodology"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02008"}}, {"publisher": {"name": ""}, "description": "  This paper considers onboard control of a small-sized quadrotor using a\nstrapdown embedded optical flow sensor which is conventionally used for desktop\nmice. The vehicle considered in this paper can carry only few dozen grams of\npayload, therefore conventional camera-based optical flow methods are not\napplicable. We present hovering control of the small-sized quadrotor using a\nsingle-chip optical flow sensor, implemented on an 8-bit microprocessor without\nexternal sensors or communication with a ground control station. Detailed\ndescription of all the system components is provided along with evaluation of\nthe accuracy. Experimental results from flight tests are validated with the\nground-truth data provided by a high-accuracy reference system.\n", "contributors": [{"name": "Lim, Hyon", "sameAs": [], "familyName": "Lim", "additionalName": "", "givenName": "Hyon", "email": ""}, {"name": "Lee, Hyeonbeom", "sameAs": [], "familyName": "Lee", "additionalName": "", "givenName": "Hyeonbeom", "email": ""}, {"name": "Kim, H. Jin", "sameAs": [], "familyName": "Kim", "additionalName": "Jin", "givenName": "H.", "email": ""}], "title": "Onboard Flight Control of a Small Quadrotor Using Single Strapdown\n  Optical Flow Sensor", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-03-20", "2012-03-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1203.4349", "oai:arXiv.org:1203.4349"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper considers onboard control of a small-sized quadrotor using a\nstrapdown embedded optical flow sensor which is conventionally used for desktop\nmice. The vehicle considered in this paper can carry only few dozen grams of\npayload, therefore conventional camera-based optical flow methods are not\napplicable. We present hovering control of the small-sized quadrotor using a\nsingle-chip optical flow sensor, implemented on an 8-bit microprocessor without\nexternal sensors or communication with a ground control station. Detailed\ndescription of all the system components is provided along with evaluation of\nthe accuracy. Experimental results from flight tests are validated with the\nground-truth data provided by a high-accuracy reference system.\n", "Comment: I would like to remove this article due to copyright problem. Please\n  remove my article as soon as possible"]}}], "languages": [null], "subjects": ["computer science - robotics"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1203.4349"}}, {"publisher": {"name": ""}, "description": "  Werner's set-theoretical model is one of the most intuitive models of CC. It\ncombines a functional view of predicative universes with a collapsed view of\nimpredicative sort Prop. However this model of Prop is so coarse that the\nprinciple of excluded middle $P \\lor \\neg P$ holds. In this paper, we interpret\nProp into a Heyting algebra to make it more intuitionistic without sacrificing\nsimplicity.\n", "contributors": [{"name": "Sato, Masahiro", "sameAs": [], "familyName": "Sato", "additionalName": "", "givenName": "Masahiro", "email": ""}], "title": "An Intuitionistic Set-theoretical Model of the Extended Calculus of\n  Constructions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2235", "oai:arXiv.org:1412.2235"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Werner's set-theoretical model is one of the most intuitive models of CC. It\ncombines a functional view of predicative universes with a collapsed view of\nimpredicative sort Prop. However this model of Prop is so coarse that the\nprinciple of excluded middle $P \\lor \\neg P$ holds. In this paper, we interpret\nProp into a Heyting algebra to make it more intuitionistic without sacrificing\nsimplicity.\n"}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2235"}}, {"publisher": {"name": ""}, "description": "  The magnetic field integral equation for axially symmetric cavities with\nperfectly conducting surfaces is discretized according to a high-order\nconvergent Fourier--Nystr\\\"om scheme. The resulting solver is used to determine\neigenwavenumbers and normalized magnetic eigenfields to very high accuracy in\nthe entire computational domain.\n", "contributors": [{"name": "Helsing, Johan", "sameAs": [], "familyName": "Helsing", "additionalName": "", "givenName": "Johan", "email": ""}, {"name": "Karlsson, Anders", "sameAs": [], "familyName": "Karlsson", "additionalName": "", "givenName": "Anders", "email": ""}], "title": "Determination of normalized magnetic eigenfields in microwave cavities", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.0848", "oai:arXiv.org:1410.0848"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": ["  The magnetic field integral equation for axially symmetric cavities with\nperfectly conducting surfaces is discretized according to a high-order\nconvergent Fourier--Nystr\\\"om scheme. The resulting solver is used to determine\neigenwavenumbers and normalized magnetic eigenfields to very high accuracy in\nthe entire computational domain.\n", "Comment: 23 pages, 4 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "65n25", "31b10", "78m15", "35q61"], "providerUpdatedDateTime": "2014-10-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.0848"}}, {"publisher": {"name": ""}, "description": "  Lifted inference has been proposed for various probabilistic logical\nframeworks in order to compute the probability of queries in a time that\ndepends on the size of the domains of the random variables rather than the\nnumber of instances. Even if various authors have underlined its importance for\nprobabilistic logic programming (PLP), lifted inference has been applied up to\nnow only to relational languages outside of logic programming. In this paper we\nadapt Generalized Counting First Order Variable Elimination (GC-FOVE) to the\nproblem of computing the probability of queries to probabilistic logic programs\nunder the distribution semantics. In particular, we extend the Prolog Factor\nLanguage (PFL) to include two new types of factors that are needed for\nrepresenting ProbLog programs. These factors take into account the existing\ncausal independence relationships among random variables and are managed by the\nextension to variable elimination proposed by Zhang and Poole for dealing with\nconvergent variables and heterogeneous factors. Two new operators are added to\nGC-FOVE for treating heterogeneous factors. The resulting algorithm, called\nLP$^2$ for Lifted Probabilistic Logic Programming, has been implemented by\nmodifying the PFL implementation of GC-FOVE and tested on three benchmarks for\nlifted inference. A comparison with PITA and ProbLog2 shows the potential of\nthe approach.\n", "contributors": [{"name": "Bellodi, Elena", "sameAs": [], "familyName": "Bellodi", "additionalName": "", "givenName": "Elena", "email": ""}, {"name": "Lamma, Evelina", "sameAs": [], "familyName": "Lamma", "additionalName": "", "givenName": "Evelina", "email": ""}, {"name": "Riguzzi, Fabrizio", "sameAs": [], "familyName": "Riguzzi", "additionalName": "", "givenName": "Fabrizio", "email": ""}, {"name": "Costa, Vitor Santos", "sameAs": [], "familyName": "Costa", "additionalName": "Santos", "givenName": "Vitor", "email": ""}, {"name": "Zese, Riccardo", "sameAs": [], "familyName": "Zese", "additionalName": "", "givenName": "Riccardo", "email": ""}], "title": "Lifted Variable Elimination for Probabilistic Logic Programming", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-13", "2014-10-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.3218", "doi:10.1017/S1471068414000283", "oai:arXiv.org:1405.3218"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Lifted inference has been proposed for various probabilistic logical\nframeworks in order to compute the probability of queries in a time that\ndepends on the size of the domains of the random variables rather than the\nnumber of instances. Even if various authors have underlined its importance for\nprobabilistic logic programming (PLP), lifted inference has been applied up to\nnow only to relational languages outside of logic programming. In this paper we\nadapt Generalized Counting First Order Variable Elimination (GC-FOVE) to the\nproblem of computing the probability of queries to probabilistic logic programs\nunder the distribution semantics. In particular, we extend the Prolog Factor\nLanguage (PFL) to include two new types of factors that are needed for\nrepresenting ProbLog programs. These factors take into account the existing\ncausal independence relationships among random variables and are managed by the\nextension to variable elimination proposed by Zhang and Poole for dealing with\nconvergent variables and heterogeneous factors. Two new operators are added to\nGC-FOVE for treating heterogeneous factors. The resulting algorithm, called\nLP$^2$ for Lifted Probabilistic Logic Programming, has been implemented by\nmodifying the PFL implementation of GC-FOVE and tested on three benchmarks for\nlifted inference. A comparison with PITA and ProbLog2 shows the potential of\nthe approach.\n", "Comment: To appear in Theory and Practice of Logic Programming (TPLP). arXiv\n  admin note: text overlap with arXiv:1402.0565 by other authors"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence"], "providerUpdatedDateTime": "2014-10-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.3218"}}, {"publisher": {"name": ""}, "description": "  There have been numerous works on network intrusion detection and prevention\nsystems, but work on application layer intrusion detection and prevention is\nrare and not very mature. Intrusion detection and prevention at both network\nand application layers are important for cyber-security and enterprise system\nsecurity. Since application layer intrusion is increasing day by day, it is\nimperative to give adequate attention to it and use state-of-the-art algorithms\nfor effective detection and prevention. This paper talks about current state of\napplication layer intrusion detection and prevention capabilities in commercial\nand open-source space and provides a path for evolution to more mature state\nthat will address not only enterprise system security, but also national\ncyber-defence. Scalability and cost-effectiveness were important factors which\nshaped the proposed solution.\n", "contributors": [{"name": "Saha, Amal", "sameAs": [], "familyName": "Saha", "additionalName": "", "givenName": "Amal", "email": ""}, {"name": "Sanyal, Sugata", "sameAs": [], "familyName": "Sanyal", "additionalName": "", "givenName": "Sugata", "email": ""}], "title": "Application Layer Intrusion Detection with Combination of Explicit-Rule-\n  Based and Machine Learning Algorithms and Deployment in Cyber- Defence\n  Program", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3089", "oai:arXiv.org:1411.3089"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  There have been numerous works on network intrusion detection and prevention\nsystems, but work on application layer intrusion detection and prevention is\nrare and not very mature. Intrusion detection and prevention at both network\nand application layers are important for cyber-security and enterprise system\nsecurity. Since application layer intrusion is increasing day by day, it is\nimperative to give adequate attention to it and use state-of-the-art algorithms\nfor effective detection and prevention. This paper talks about current state of\napplication layer intrusion detection and prevention capabilities in commercial\nand open-source space and provides a path for evolution to more mature state\nthat will address not only enterprise system security, but also national\ncyber-defence. Scalability and cost-effectiveness were important factors which\nshaped the proposed solution.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3089"}}, {"publisher": {"name": ""}, "description": "  Elliptic M\\\"obius transformations of the unit disk are those for which there\nis a fixed point in $\\mathbb{D}$. It is not hard to classify which M\\\"obius\ntransformations are elliptic in terms of the parameters. The set of parameters\ncan be identified with the solid torus $S^1 \\times \\mathbb{D}$, and the set of\nelliptic parameters is called the domain of ellipticity. In this paper, we\nstudy the domain of ellipticity for non-trivial unicritical Blaschke products.\nWe will also study the set corresponding to the Mandelbrot set for this family,\nand show how it can be obtained from the domain of ellipticity by adding one\npoint.\n", "contributors": [{"name": "Fletcher, Alastair", "sameAs": [], "familyName": "Fletcher", "additionalName": "", "givenName": "Alastair", "email": ""}], "title": "Unicritical Blaschke products and domains of ellipticity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-11", "2014-12-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.2418", "oai:arXiv.org:1408.2418"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Elliptic M\\\"obius transformations of the unit disk are those for which there\nis a fixed point in $\\mathbb{D}$. It is not hard to classify which M\\\"obius\ntransformations are elliptic in terms of the parameters. The set of parameters\ncan be identified with the solid torus $S^1 \\times \\mathbb{D}$, and the set of\nelliptic parameters is called the domain of ellipticity. In this paper, we\nstudy the domain of ellipticity for non-trivial unicritical Blaschke products.\nWe will also study the set corresponding to the Mandelbrot set for this family,\nand show how it can be obtained from the domain of ellipticity by adding one\npoint.\n", "Comment: 3 figures"]}}], "languages": [null], "subjects": ["mathematics - dynamical systems", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.2418"}}, {"publisher": {"name": ""}, "description": "  Can we move beyond simply networking creative individuals to establishing\ndiverse communities of practice for innovation through discursive methods.\nFurthermore, can we digitise their creativity activities within an integrative\nsocio-cultural collaborative technology platform that could then support\ndistributed innovation. First, we consider the complexity of creative cultures\nfrom the perspective of design innovation, including how to nurture creativity\nactivities in what we call Creative Gardens. Specifically, how they could grow,\ndiverge, and combine, be- ing cultivated to nurture emergent, disruptive,\ncollaborative innovation. Then, we consider the digitisation of Creative\nGardens from the perspective of digital culture. Specifically, the tenets of\nCreative Gardens as dynamic and innovative communities. This includes\nconsidering the challenges and opportunities around digitisation, the\ninfluences around the connectivity with knowledge cultivation, and the\npotential for distributed innovation as collective intelligence to utilise\ndiverse expertise. We conclude be considering the importance of the issues and\nquestions raised, and their potential for the future.\n", "contributors": [{"name": "Briscoe, Gerard", "sameAs": [], "familyName": "Briscoe", "additionalName": "", "givenName": "Gerard", "email": ""}, {"name": "Lockwood, Joseph", "sameAs": [], "familyName": "Lockwood", "additionalName": "", "givenName": "Joseph", "email": ""}], "title": "Creative Gardens", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-09-23", "2015-02-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1309.5769", "oai:arXiv.org:1309.5769"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Can we move beyond simply networking creative individuals to establishing\ndiverse communities of practice for innovation through discursive methods.\nFurthermore, can we digitise their creativity activities within an integrative\nsocio-cultural collaborative technology platform that could then support\ndistributed innovation. First, we consider the complexity of creative cultures\nfrom the perspective of design innovation, including how to nurture creativity\nactivities in what we call Creative Gardens. Specifically, how they could grow,\ndiverge, and combine, be- ing cultivated to nurture emergent, disruptive,\ncollaborative innovation. Then, we consider the digitisation of Creative\nGardens from the perspective of digital culture. Specifically, the tenets of\nCreative Gardens as dynamic and innovative communities. This includes\nconsidering the challenges and opportunities around digitisation, the\ninfluences around the connectivity with knowledge cultivation, and the\npotential for distributed innovation as collective intelligence to utilise\ndiverse expertise. We conclude be considering the importance of the issues and\nquestions raised, and their potential for the future.\n", "Comment: 4 pages, conference"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-02-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1309.5769"}}, {"publisher": {"name": ""}, "description": "  An increasing amount of geo-referenced mobile phone data enables the\nidentification of behavioral patterns, habits and movements of people. With\nthis data, we can extract the knowledge potentially useful for many\napplications including the one tackled in this study - understanding spatial\nvariation of epidemics. We explored the datasets collected by a cell phone\nservice provider and linked them to spatial HIV prevalence rates estimated from\npublicly available surveys. For that purpose, 224 features were extracted from\nmobility and connectivity traces and related to the level of HIV epidemic in 50\nIvory Coast departments. By means of regression models, we evaluated predictive\nability of extracted features. Several models predicted HIV prevalence that are\nhighly correlated (>0.7) with actual values. Through contribution analysis we\nidentified key elements that impact the rate of infections. Our findings\nindicate that night connectivity and activity, spatial area covered by users\nand overall migrations are strongly linked to HIV. By visualizing the\ncommunication and mobility flows, we strived to explain the spatial structure\nof epidemics. We discovered that strong ties and hubs in communication and\nmobility align with HIV hot spots.\n", "contributors": [{"name": "Brdar, Sanja", "sameAs": [], "familyName": "Brdar", "additionalName": "", "givenName": "Sanja", "email": ""}, {"name": "Gavric, Katarina", "sameAs": [], "familyName": "Gavric", "additionalName": "", "givenName": "Katarina", "email": ""}, {"name": "Culibrk, Dubravko", "sameAs": [], "familyName": "Culibrk", "additionalName": "", "givenName": "Dubravko", "email": ""}, {"name": "Crnojevic, Vladimir", "sameAs": [], "familyName": "Crnojevic", "additionalName": "", "givenName": "Vladimir", "email": ""}], "title": "Unveiling Spatial Epidemiology of HIV with Mobile Phone Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06575", "oai:arXiv.org:1503.06575"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  An increasing amount of geo-referenced mobile phone data enables the\nidentification of behavioral patterns, habits and movements of people. With\nthis data, we can extract the knowledge potentially useful for many\napplications including the one tackled in this study - understanding spatial\nvariation of epidemics. We explored the datasets collected by a cell phone\nservice provider and linked them to spatial HIV prevalence rates estimated from\npublicly available surveys. For that purpose, 224 features were extracted from\nmobility and connectivity traces and related to the level of HIV epidemic in 50\nIvory Coast departments. By means of regression models, we evaluated predictive\nability of extracted features. Several models predicted HIV prevalence that are\nhighly correlated (>0.7) with actual values. Through contribution analysis we\nidentified key elements that impact the rate of infections. Our findings\nindicate that night connectivity and activity, spatial area covered by users\nand overall migrations are strongly linked to HIV. By visualizing the\ncommunication and mobility flows, we strived to explain the spatial structure\nof epidemics. We discovered that strong ties and hubs in communication and\nmobility align with HIV hot spots.\n", "Comment: 13 pages, 4 figures, 2 tables"]}}], "languages": [null], "subjects": ["statistics - applications", "computer science - computers and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06575"}}, {"publisher": {"name": ""}, "description": "  A quantum-mechanical description of the magnetic shape anisotropy, that is\nusually ascribed to the classical magnetic dipole-dipole interaction, has been\ndeveloped. This is achieved by including the Breit-interaction, that can be\nseen as an electronic current-current interaction in addition to the\nconventional Coulomb interaction, within fully relativistic band structure\ncalculations. The major sources of the magnetic anisotropy, spin-orbit coupling\nand the Breit-interaction, are treated coherently this way. This seems to be\nespecially important for layered systems for which often both sources\ncontribute with opposite sign to the magnetic anisotropy energy. Applications\nto layered transition metal systems are presented to demonstrate the\nimplications of this new approach in treating the magnetic shape anisotropy.\n", "contributors": [{"name": "Bornemann, S.", "sameAs": [], "familyName": "Bornemann", "additionalName": "", "givenName": "S.", "email": ""}, {"name": "Minar, J.", "sameAs": [], "familyName": "Minar", "additionalName": "", "givenName": "J.", "email": ""}, {"name": "Braun, J.", "sameAs": [], "familyName": "Braun", "additionalName": "", "givenName": "J.", "email": ""}, {"name": "Koedderitzsch, D.", "sameAs": [], "familyName": "Koedderitzsch", "additionalName": "", "givenName": "D.", "email": ""}, {"name": "Ebert, H.", "sameAs": [], "familyName": "Ebert", "additionalName": "", "givenName": "H.", "email": ""}], "title": "Ab-initio description of the magnetic shape anisotropy due to the Breit\n  interaction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2010-12-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1012.1115", "oai:arXiv.org:1012.1115"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  A quantum-mechanical description of the magnetic shape anisotropy, that is\nusually ascribed to the classical magnetic dipole-dipole interaction, has been\ndeveloped. This is achieved by including the Breit-interaction, that can be\nseen as an electronic current-current interaction in addition to the\nconventional Coulomb interaction, within fully relativistic band structure\ncalculations. The major sources of the magnetic anisotropy, spin-orbit coupling\nand the Breit-interaction, are treated coherently this way. This seems to be\nespecially important for layered systems for which often both sources\ncontribute with opposite sign to the magnetic anisotropy energy. Applications\nto layered transition metal systems are presented to demonstrate the\nimplications of this new approach in treating the magnetic shape anisotropy.\n", "Comment: 4 pages, 4 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "condensed matter - strongly correlated electrons", "condensed matter - materials science"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1012.1115"}}, {"publisher": {"name": ""}, "description": "  In this report we describe a tool framework for certifying properties of\nPLCs: CERTPLC. CERTPLC can handle PLC descriptions provided in the Sequential\nFunction Chart (SFC) language of the IEC 61131-3 standard. It provides routines\nto certify properties of systems by delivering an independently checkable\nformal system description and proof (called certificate) for the desired\nproperties. We focus on properties that can be described as inductive\ninvariants. System descriptions and certificates are generated and handled\nusing the COQ proof assistant. Our tool framework is used to provide supporting\nevidence for the safety of embedded systems in the industrial automation domain\nto third-party authorities. In this document we describe the tool framework:\nusage scenarios, the archi-tecture, semantics of PLCs and their realization in\nCOQ, proof generation and the construction of certificates.\n", "contributors": [{"name": "Blech, Jan Olaf", "sameAs": [], "familyName": "Blech", "additionalName": "Olaf", "givenName": "Jan", "email": ""}], "title": "A Tool for the Certification of PLCs based on a Coq Semantics for\n  Sequential Function Charts", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-02-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1102.3529", "oai:arXiv.org:1102.3529"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this report we describe a tool framework for certifying properties of\nPLCs: CERTPLC. CERTPLC can handle PLC descriptions provided in the Sequential\nFunction Chart (SFC) language of the IEC 61131-3 standard. It provides routines\nto certify properties of systems by delivering an independently checkable\nformal system description and proof (called certificate) for the desired\nproperties. We focus on properties that can be described as inductive\ninvariants. System descriptions and certificates are generated and handled\nusing the COQ proof assistant. Our tool framework is used to provide supporting\nevidence for the safety of embedded systems in the industrial automation domain\nto third-party authorities. In this document we describe the tool framework:\nusage scenarios, the archi-tecture, semantics of PLCs and their realization in\nCOQ, proof generation and the construction of certificates.\n"}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1102.3529"}}, {"publisher": {"name": ""}, "description": "  Precise complexity results are derived for the model checking problems for\nMTL (metric temporal logic) and TPTL (timed propositional temporal logic) on\n(in)finite data words and deterministic one-counter machines. Depending on the\nnumber of register variables and the encoding of numbers in constraints (unary\nor binary), the complexity is either P-complete or PSPACE-complete.\n", "contributors": [{"name": "Feng, Shiguang", "sameAs": [], "familyName": "Feng", "additionalName": "", "givenName": "Shiguang", "email": ""}, {"name": "Lohrey, Markus", "sameAs": [], "familyName": "Lohrey", "additionalName": "", "givenName": "Markus", "email": ""}, {"name": "Quaas, Karin", "sameAs": [], "familyName": "Quaas", "additionalName": "", "givenName": "Karin", "email": ""}], "title": "Path-Checking for MTL and TPTL over Data Words", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-11", "2015-03-19"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3644", "oai:arXiv.org:1412.3644"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Precise complexity results are derived for the model checking problems for\nMTL (metric temporal logic) and TPTL (timed propositional temporal logic) on\n(in)finite data words and deterministic one-counter machines. Depending on the\nnumber of register variables and the encoding of numbers in constraints (unary\nor binary), the complexity is either P-complete or PSPACE-complete.\n"}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3644"}}, {"publisher": {"name": ""}, "description": "  Vector Symbolic Architectures (VSAs) are high-dimensional vector\nrepresentations of objects (eg., words, image parts), relations (eg., sentence\nstructures), and sequences for use with machine learning algorithms. They\nconsist of a vector addition operator for representing a collection of\nunordered objects, a Binding operator for associating groups of objects, and a\nmethodology for encoding complex structures.\n  We first develop Constraints that machine learning imposes upon VSAs: for\nexample, similar structures must be represented by similar vectors. The\nconstraints suggest that current VSAs should represent phrases (\"The smart\nBrazilian girl\") by binding sums of terms, in addition to simply binding the\nterms directly.\n  We show that matrix multiplication can be used as the binding operator for a\nVSA, and that matrix elements can be chosen at random. A consequence for living\nsystems is that binding is mathematically possible without the need to specify,\nin advance, precise neuron-to-neuron connection properties for large numbers of\nsynapses.\n  A VSA that incorporates these ideas, MBAT (Matrix Binding of Additive Terms),\nis described that satisfies all Constraints.\n  With respect to machine learning, for some types of problems appropriate VSA\nrepresentations permit us to prove learnability, rather than relying on\nsimulations. We also propose dividing machine (and neural) learning and\nrepresentation into three Stages, with differing roles for learning in each\nstage.\n  For neural modeling, we give \"representational reasons\" for nervous systems\nto have many recurrent connections, as well as for the importance of phrases in\nlanguage processing.\n  Sizing simulations and analyses suggest that VSAs in general, and MBAT in\nparticular, are ready for real-world applications.\n", "contributors": [{"name": "Gallant, Stephen I.", "sameAs": [], "familyName": "Gallant", "additionalName": "I.", "givenName": "Stephen", "email": ""}, {"name": "Okaywe, T. Wendy", "sameAs": [], "familyName": "Okaywe", "additionalName": "Wendy", "givenName": "T.", "email": ""}], "title": "Representing Objects, Relations, and Sequences", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.07627", "Neural Computation 25, 2038-2078 (August 2013)", "oai:arXiv.org:1501.07627"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Vector Symbolic Architectures (VSAs) are high-dimensional vector\nrepresentations of objects (eg., words, image parts), relations (eg., sentence\nstructures), and sequences for use with machine learning algorithms. They\nconsist of a vector addition operator for representing a collection of\nunordered objects, a Binding operator for associating groups of objects, and a\nmethodology for encoding complex structures.\n  We first develop Constraints that machine learning imposes upon VSAs: for\nexample, similar structures must be represented by similar vectors. The\nconstraints suggest that current VSAs should represent phrases (\"The smart\nBrazilian girl\") by binding sums of terms, in addition to simply binding the\nterms directly.\n  We show that matrix multiplication can be used as the binding operator for a\nVSA, and that matrix elements can be chosen at random. A consequence for living\nsystems is that binding is mathematically possible without the need to specify,\nin advance, precise neuron-to-neuron connection properties for large numbers of\nsynapses.\n  A VSA that incorporates these ideas, MBAT (Matrix Binding of Additive Terms),\nis described that satisfies all Constraints.\n  With respect to machine learning, for some types of problems appropriate VSA\nrepresentations permit us to prove learnability, rather than relying on\nsimulations. We also propose dividing machine (and neural) learning and\nrepresentation into three Stages, with differing roles for learning in each\nstage.\n  For neural modeling, we give \"representational reasons\" for nervous systems\nto have many recurrent connections, as well as for the importance of phrases in\nlanguage processing.\n  Sizing simulations and analyses suggest that VSAs in general, and MBAT in\nparticular, are ready for real-world applications.\n", "Comment: 41 pages"]}}], "languages": [null], "subjects": ["computer science - learning"], "providerUpdatedDateTime": "2015-02-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.07627"}}, {"publisher": {"name": ""}, "description": "  The purpose of this paper is to study metrics suitable for assessing\nuncertainty of power spectra when these are based on finite second-order\nstatistics. The family of power spectra which is consistent with a given range\nof values for the estimated statistics represents the uncertainty set about the\n\"true\" power spectrum. Our aim is to quantify the size of this uncertainty set\nusing suitable notions of distance, and in particular, to compute the diameter\nof the set since this represents an upper bound on the distance between any\nchoice of a nominal element in the set and the \"true\" power spectrum. Since the\nuncertainty set may contain power spectra with lines and discontinuities, it is\nnatural to quantify distances in the weak topology---the topology defined by\ncontinuity of moments. We provide examples of such weakly-continuous metrics\nand focus on particular metrics for which we can explicitly quantify spectral\nuncertainty. We then consider certain high resolution techniques which utilize\nfilter-banks for pre-processing, and compute worst-case a priori uncertainty\nbounds solely on the basis of the filter dynamics. This allows the a priori\ntuning of the filter-banks for improved resolution over selected frequency\nbands.\n", "contributors": [{"name": "Karlsson, Johan", "sameAs": [], "familyName": "Karlsson", "additionalName": "", "givenName": "Johan", "email": ""}, {"name": "Georgiou, Tryphon T.", "sameAs": [], "familyName": "Georgiou", "additionalName": "T.", "givenName": "Tryphon", "email": ""}], "title": "Uncertainty Bounds for Spectral Estimation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-01-21", "2012-09-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1201.4469", "oai:arXiv.org:1201.4469"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  The purpose of this paper is to study metrics suitable for assessing\nuncertainty of power spectra when these are based on finite second-order\nstatistics. The family of power spectra which is consistent with a given range\nof values for the estimated statistics represents the uncertainty set about the\n\"true\" power spectrum. Our aim is to quantify the size of this uncertainty set\nusing suitable notions of distance, and in particular, to compute the diameter\nof the set since this represents an upper bound on the distance between any\nchoice of a nominal element in the set and the \"true\" power spectrum. Since the\nuncertainty set may contain power spectra with lines and discontinuities, it is\nnatural to quantify distances in the weak topology---the topology defined by\ncontinuity of moments. We provide examples of such weakly-continuous metrics\nand focus on particular metrics for which we can explicitly quantify spectral\nuncertainty. We then consider certain high resolution techniques which utilize\nfilter-banks for pre-processing, and compute worst-case a priori uncertainty\nbounds solely on the basis of the filter dynamics. This allows the a priori\ntuning of the filter-banks for improved resolution over selected frequency\nbands.\n", "Comment: 8 figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "g.3", "62g07", "mathematics - statistics theory", "93e10"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1201.4469"}}, {"publisher": {"name": ""}, "description": "  The need to estimate smooth probability distributions (a.k.a. probability\ndensities) from finite sampled data is ubiquitous in science. Many approaches\nto this problem have been described, but none is yet regarded as providing a\ndefinitive solution. Maximum entropy estimation and Bayesian field theory are\ntwo such approaches. Both have origins in statistical physics, but the\nrelationship between them has remained unclear. Here I unify these two methods\nby showing that every maximum entropy density estimate can be recovered in the\ninfinite smoothness limit of an appropriate Bayesian field theory. I also show\nthat Bayesian field theory estimation can be performed without imposing any\nboundary conditions on candidate densities, and that the infinite smoothness\nlimit of these theories recovers the most common types of maximum entropy\nestimates. Bayesian field theory is thus seen to provide a natural test of the\nvalidity of the maximum entropy null hypothesis. Bayesian field theory also\nreturns a lower entropy density estimate when the maximum entropy hypothesis is\nfalsified. The computations necessary for this approach can be performed\nrapidly for one-dimensional data, and software for doing this is provided.\nBased on these results, I argue that Bayesian field theory is poised to provide\na definitive solution to the density estimation problem in one dimension.\n", "contributors": [{"name": "Kinney, Justin B.", "sameAs": [], "familyName": "Kinney", "additionalName": "B.", "givenName": "Justin", "email": ""}], "title": "Unification of field theory and maximum entropy methods for learning\n  probability densities", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-19", "2015-03-21"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5371", "oai:arXiv.org:1411.5371"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics", "q-bio", "stat"]}}, {"name": "description", "properties": {"description": ["  The need to estimate smooth probability distributions (a.k.a. probability\ndensities) from finite sampled data is ubiquitous in science. Many approaches\nto this problem have been described, but none is yet regarded as providing a\ndefinitive solution. Maximum entropy estimation and Bayesian field theory are\ntwo such approaches. Both have origins in statistical physics, but the\nrelationship between them has remained unclear. Here I unify these two methods\nby showing that every maximum entropy density estimate can be recovered in the\ninfinite smoothness limit of an appropriate Bayesian field theory. I also show\nthat Bayesian field theory estimation can be performed without imposing any\nboundary conditions on candidate densities, and that the infinite smoothness\nlimit of these theories recovers the most common types of maximum entropy\nestimates. Bayesian field theory is thus seen to provide a natural test of the\nvalidity of the maximum entropy null hypothesis. Bayesian field theory also\nreturns a lower entropy density estimate when the maximum entropy hypothesis is\nfalsified. The computations necessary for this approach can be performed\nrapidly for one-dimensional data, and software for doing this is provided.\nBased on these results, I argue that Bayesian field theory is poised to provide\na definitive solution to the density estimation problem in one dimension.\n", "Comment: 16 pages, 4 figures. The text has been greatly expanded. Open source\n  software is available at https://github.com/jbkinney/14_maxent"]}}], "languages": [null], "subjects": ["statistics and probability", "quantitative biology - quantitative methods", "computer science - learning", "statistics - machine learning", "physics - data analysis"], "providerUpdatedDateTime": "2015-03-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5371"}}, {"publisher": {"name": ""}, "description": "  We consider a nonatomic congestion game on a graph, with several classes of\nplayers. Each player wants to go from its origin vertex to its destination\nvertex at the minimum cost and all players of a given class share the same\ncharacteristics: cost functions on each arc, and origin-destination pair. Under\nsome mild conditions, it is known that a Nash equilibrium exists, but the\ncomputation of an equilibrium in the multiclass case is an open problem for\ngeneral functions. We consider the specific case where the cost functions are\naffine. We show that this problem is polynomially solvable when the number of\nvertices and the number of classes are fixed. In particular, it shows that the\nparallel-link case with a fixed number of classes is polynomially solvable. On\na more practical side, we propose an extension of Lemke's algorithm able to\nsolve this problem.\n", "contributors": [{"name": "Meunier, Fr\u00e9d\u00e9ric", "sameAs": [], "familyName": "Meunier", "additionalName": "", "givenName": "Fr\u00e9d\u00e9ric", "email": ""}, {"name": "Pradeau, Thomas", "sameAs": [], "familyName": "Pradeau", "additionalName": "", "givenName": "Thomas", "email": ""}], "title": "Computing solutions of the multiclass network equilibrium problem with\n  affine cost functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6496", "oai:arXiv.org:1412.6496"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We consider a nonatomic congestion game on a graph, with several classes of\nplayers. Each player wants to go from its origin vertex to its destination\nvertex at the minimum cost and all players of a given class share the same\ncharacteristics: cost functions on each arc, and origin-destination pair. Under\nsome mild conditions, it is known that a Nash equilibrium exists, but the\ncomputation of an equilibrium in the multiclass case is an open problem for\ngeneral functions. We consider the specific case where the cost functions are\naffine. We show that this problem is polynomially solvable when the number of\nvertices and the number of classes are fixed. In particular, it shows that the\nparallel-link case with a fixed number of classes is polynomially solvable. On\na more practical side, we propose an extension of Lemke's algorithm able to\nsolve this problem.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory", "mathematics - optimization and control"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6496"}}, {"publisher": {"name": ""}, "description": "  Cloud computing systems, in which clients rent and share computing resources\nof third party platforms, have gained widespread use in recent years.\nFurthermore, cloud computing for mobile systems (i.e., systems in which the\nclients are mobile devices) have too been receiving considerable attention in\ntechnical literature. We propose a new method of delegating computations of\nresource-constrained mobile clients, in which multiple servers interact to\nconstruct an encrypted program known as garbled circuit. Next, using garbled\ninputs from a mobile client, another server executes this garbled circuit and\nreturns the resulting garbled outputs. Our system assures privacy of the mobile\nclient's data, even if the executing server chooses to collude with all but one\nof the other servers. We adapt the garbled circuit design of Beaver et al. and\nthe secure multiparty computation protocol of Goldreich et al. for the purpose\nof building a secure cloud computing for mobile systems. Our method\nincorporates the novel use of the cryptographically secure pseudo random number\ngenerator of Blum et al. that enables the mobile client to efficiently retrieve\nthe result of the computation, as well as to verify that the evaluator actually\nperformed the computation. We analyze the server-side and client-side\ncomplexity of our system. Using real-world data, we evaluate our system for a\nprivacy preserving search application that locates the nearest bank/ATM from\nthe mobile client. We also measure the time taken to construct and evaluate the\ngarbled circuit for varying number of servers, demonstrating the feasibility of\nour secure and verifiable cloud computing for mobile systems.\n", "contributors": [{"name": "Premnath, Sriram N.", "sameAs": [], "familyName": "Premnath", "additionalName": "N.", "givenName": "Sriram", "email": ""}, {"name": "Haas, Zygmunt J.", "sameAs": [], "familyName": "Haas", "additionalName": "J.", "givenName": "Zygmunt", "email": ""}], "title": "A Practical, Secure, and Verifiable Cloud Computing for Mobile Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1389", "oai:arXiv.org:1410.1389"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Cloud computing systems, in which clients rent and share computing resources\nof third party platforms, have gained widespread use in recent years.\nFurthermore, cloud computing for mobile systems (i.e., systems in which the\nclients are mobile devices) have too been receiving considerable attention in\ntechnical literature. We propose a new method of delegating computations of\nresource-constrained mobile clients, in which multiple servers interact to\nconstruct an encrypted program known as garbled circuit. Next, using garbled\ninputs from a mobile client, another server executes this garbled circuit and\nreturns the resulting garbled outputs. Our system assures privacy of the mobile\nclient's data, even if the executing server chooses to collude with all but one\nof the other servers. We adapt the garbled circuit design of Beaver et al. and\nthe secure multiparty computation protocol of Goldreich et al. for the purpose\nof building a secure cloud computing for mobile systems. Our method\nincorporates the novel use of the cryptographically secure pseudo random number\ngenerator of Blum et al. that enables the mobile client to efficiently retrieve\nthe result of the computation, as well as to verify that the evaluator actually\nperformed the computation. We analyze the server-side and client-side\ncomplexity of our system. Using real-world data, we evaluate our system for a\nprivacy preserving search application that locates the nearest bank/ATM from\nthe mobile client. We also measure the time taken to construct and evaluate the\ngarbled circuit for varying number of servers, demonstrating the feasibility of\nour secure and verifiable cloud computing for mobile systems.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1389"}}, {"publisher": {"name": ""}, "description": "  Mobile networks are vulnerable to signalling attacks and storms that are\ncaused by traffic patterns that overload the control plane, and differ from\ndistributed denial of service (DDoS) attacks in the Internet since they\ndirectly attack the control plane, and also reserve wireless bandwidth without\nactually using it. Such attacks can result from malware and mobile botnets, as\nwell as from poorly designed applications, and can cause service outages in 3G\nand 4G networks which have been experienced by mobile operators. Since the\nradio resource control (RRC) protocol in 3G and 4G networks is particularly\nsusceptible to such attacks, we analyze their effect with a mathematical model\nthat helps to predict the congestion that is caused by an attack. A detailed\nsimulation model of a mobile network is used to better understand the temporal\ndynamics of user behavior and signalling in the network and to show how RRC\nbased signalling attacks and storms cause significant problems in the control\nplane and the user plane of the network. Our analysis also serves to identify\nhow storms can be detected, and to propose how system parameters can be chosen\nto mitigate their effect.\n", "contributors": [{"name": "Gorbil, Gokce", "sameAs": [], "familyName": "Gorbil", "additionalName": "", "givenName": "Gokce", "email": ""}, {"name": "Abdelrahman, Omer H.", "sameAs": [], "familyName": "Abdelrahman", "additionalName": "H.", "givenName": "Omer", "email": ""}, {"name": "Pavloski, Mihajlo", "sameAs": [], "familyName": "Pavloski", "additionalName": "", "givenName": "Mihajlo", "email": ""}, {"name": "Gelenbe, Erol", "sameAs": [], "familyName": "Gelenbe", "additionalName": "", "givenName": "Erol", "email": ""}], "title": "Storms in Mobile Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1280", "oai:arXiv.org:1411.1280"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Mobile networks are vulnerable to signalling attacks and storms that are\ncaused by traffic patterns that overload the control plane, and differ from\ndistributed denial of service (DDoS) attacks in the Internet since they\ndirectly attack the control plane, and also reserve wireless bandwidth without\nactually using it. Such attacks can result from malware and mobile botnets, as\nwell as from poorly designed applications, and can cause service outages in 3G\nand 4G networks which have been experienced by mobile operators. Since the\nradio resource control (RRC) protocol in 3G and 4G networks is particularly\nsusceptible to such attacks, we analyze their effect with a mathematical model\nthat helps to predict the congestion that is caused by an attack. A detailed\nsimulation model of a mobile network is used to better understand the temporal\ndynamics of user behavior and signalling in the network and to show how RRC\nbased signalling attacks and storms cause significant problems in the control\nplane and the user plane of the network. Our analysis also serves to identify\nhow storms can be detected, and to propose how system parameters can be chosen\nto mitigate their effect.\n", "Comment: Submitted to the IEEE TETC special issue on \"Emerging topics in Cyber\n  Security\""]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1280"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose a novel low complexity scaling strategy of min-sum\ndecoding algorithm for irregular LDPC codes. In the proposed method, we\ngeneralize our previously proposed simplified Variable Scaled Min-Sum\n(SVS-min-sum) by replacing the sub-optimal starting value and heuristic update\nfor the scaling factor sequence by optimized values. Density evolution and\nNelder-Mead optimization are used offline, prior to the decoding, to obtain the\noptimal starting point and per iteration updating step size for the scaling\nfactor sequence of the proposed scaling strategy. The optimization of these\nparameters proves to be of noticeable positive impact on the decoding\nperformance. We used different DVB-T2 LDPC codes in our simulation. Simulation\nresults show the superior performance (in both WER and latency) of the proposed\nalgorithm to other Min-Sum based algorithms. In addition to that, generalized\nSVS-min-sum algorithm has very close performance to LLR-SPA with much lower\ncomplexity.\n", "contributors": [{"name": "Emran, Ahmed A.", "sameAs": [], "familyName": "Emran", "additionalName": "A.", "givenName": "Ahmed", "email": ""}, {"name": "Elsabrouty, Maha", "sameAs": [], "familyName": "Elsabrouty", "additionalName": "", "givenName": "Maha", "email": ""}], "title": "Generalized Simplified Variable-Scaled Min Sum LDPC decoder for\n  irregular LDPC Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.07336", "oai:arXiv.org:1501.07336"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this paper, we propose a novel low complexity scaling strategy of min-sum\ndecoding algorithm for irregular LDPC codes. In the proposed method, we\ngeneralize our previously proposed simplified Variable Scaled Min-Sum\n(SVS-min-sum) by replacing the sub-optimal starting value and heuristic update\nfor the scaling factor sequence by optimized values. Density evolution and\nNelder-Mead optimization are used offline, prior to the decoding, to obtain the\noptimal starting point and per iteration updating step size for the scaling\nfactor sequence of the proposed scaling strategy. The optimization of these\nparameters proves to be of noticeable positive impact on the decoding\nperformance. We used different DVB-T2 LDPC codes in our simulation. Simulation\nresults show the superior performance (in both WER and latency) of the proposed\nalgorithm to other Min-Sum based algorithms. In addition to that, generalized\nSVS-min-sum algorithm has very close performance to LLR-SPA with much lower\ncomplexity.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.07336"}}, {"publisher": {"name": ""}, "description": "  In this paper, we describe an algorithm for sensor network localization (SNL)\nthat proceeds by dividing the whole network into smaller subnetworks, then\nlocalizes them in parallel using some fast and accurate algorithm, and finally\nregisters the localized subnetworks in a global coordinate system. We\ndemonstrate that this divide-and-conquer algorithm can be used to leverage\nexisting high-precision SNL algorithms to large-scale networks, which could\notherwise only be applied to small-to-medium sized networks. The main\ncontribution of this paper concerns the final registration phase. In\nparticular, we consider a least-squares formulation of the registration problem\n(both with and without anchor constraints) and demonstrate how this otherwise\nnon-convex problem can be relaxed into a tractable convex program. We provide\nsome preliminary simulation results for large-scale SNL demonstrating that the\nproposed registration algorithm (together with an accurate localization scheme)\noffers a good tradeoff between run time and accuracy.\n", "contributors": [{"name": "Chaudhury, Kunal N.", "sameAs": [], "familyName": "Chaudhury", "additionalName": "N.", "givenName": "Kunal", "email": ""}, {"name": "Khoo, Yuehaw", "sameAs": [], "familyName": "Khoo", "additionalName": "", "givenName": "Yuehaw", "email": ""}, {"name": "Singer, Amit", "sameAs": [], "familyName": "Singer", "additionalName": "", "givenName": "Amit", "email": ""}], "title": "Large-Scale Sensor Network Localization via Rigid Subnetwork\n  Registration", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-29", "2015-01-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.8135", "oai:arXiv.org:1310.8135"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we describe an algorithm for sensor network localization (SNL)\nthat proceeds by dividing the whole network into smaller subnetworks, then\nlocalizes them in parallel using some fast and accurate algorithm, and finally\nregisters the localized subnetworks in a global coordinate system. We\ndemonstrate that this divide-and-conquer algorithm can be used to leverage\nexisting high-precision SNL algorithms to large-scale networks, which could\notherwise only be applied to small-to-medium sized networks. The main\ncontribution of this paper concerns the final registration phase. In\nparticular, we consider a least-squares formulation of the registration problem\n(both with and without anchor constraints) and demonstrate how this otherwise\nnon-convex problem can be relaxed into a tractable convex program. We provide\nsome preliminary simulation results for large-scale SNL demonstrating that the\nproposed registration algorithm (together with an accurate localization scheme)\noffers a good tradeoff between run time and accuracy.\n", "Comment: 5 pages, 8 figures, 1 table. To appear in Proc. IEEE International\n  Conference on Acoustics, Speech, and Signal Processing, April 19-24, 2015"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control", "computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-01-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.8135"}}, {"publisher": {"name": ""}, "description": "  We compare tools for complementing nondeterministic B\\\"uchi automata with a\nrecent termination-analysis algorithm. Complementation of B\\\"uchi automata is a\nkey step in program verification. Early constructions using a Ramsey-based\nargument have been supplanted by rank-based constructions with exponentially\nbetter bounds. In 2001 Lee et al. presented the size-change termination (SCT)\nproblem, along with both a reduction to B\\\"uchi automata and a Ramsey-based\nalgorithm. The Ramsey-based algorithm was presented as a more practical\nalternative to the automata-theoretic approach, but strongly resembles the\ninitial complementation constructions for B\\\"uchi automata. We prove that the\nSCT algorithm is a specialized realization of the Ramsey-based complementation\nconstruction. To do so, we extend the Ramsey-based complementation construction\nto provide a containment-testing algorithm. Surprisingly, empirical analysis\nsuggests that despite the massive gap in worst-case complexity, Ramsey-based\napproaches are superior over the domain of SCT problems. Upon further analysis\nwe discover an interesting property of the problem space that both explains\nthis result and provides a chance to improve rank-based tools. With these\nimprovements, we show that theoretical gains in efficiency of the rank-based\napproach are mirrored in empirical performance.\n", "contributors": [{"name": "Fogarty, Seth", "sameAs": [], "familyName": "Fogarty", "additionalName": "", "givenName": "Seth", "email": ""}, {"name": "Vardi, Moshe Y.", "sameAs": [], "familyName": "Vardi", "additionalName": "Y.", "givenName": "Moshe", "email": ""}], "title": "B\\\"uchi Complementation and Size-Change Termination", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-10-27", "2012-02-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1110.6183", "LMCS 8 (1:13) 2012", "doi:10.2168/LMCS-8(1:13)2012", "oai:arXiv.org:1110.6183"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We compare tools for complementing nondeterministic B\\\"uchi automata with a\nrecent termination-analysis algorithm. Complementation of B\\\"uchi automata is a\nkey step in program verification. Early constructions using a Ramsey-based\nargument have been supplanted by rank-based constructions with exponentially\nbetter bounds. In 2001 Lee et al. presented the size-change termination (SCT)\nproblem, along with both a reduction to B\\\"uchi automata and a Ramsey-based\nalgorithm. The Ramsey-based algorithm was presented as a more practical\nalternative to the automata-theoretic approach, but strongly resembles the\ninitial complementation constructions for B\\\"uchi automata. We prove that the\nSCT algorithm is a specialized realization of the Ramsey-based complementation\nconstruction. To do so, we extend the Ramsey-based complementation construction\nto provide a containment-testing algorithm. Surprisingly, empirical analysis\nsuggests that despite the massive gap in worst-case complexity, Ramsey-based\napproaches are superior over the domain of SCT problems. Upon further analysis\nwe discover an interesting property of the problem space that both explains\nthis result and provides a chance to improve rank-based tools. With these\nimprovements, we show that theoretical gains in efficiency of the rank-based\napproach are mirrored in empirical performance.\n"}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "d.2.4"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1110.6183"}}, {"publisher": {"name": ""}, "description": "  We consider state and parameter estimation in multiple target tracking\nproblems with data association uncertainties and unknown number of targets. We\nshow how the problem can be recast into a conditionally linear Gaussian\nstate-space model with unknown parameters and present an algorithm for\ncomputationally efficient inference on the resulting model. The proposed\nalgorithm is based on combining the Rao-Blackwellized Monte Carlo data\nassociation algorithm with particle Markov chain Monte Carlo algorithms to\njointly estimate both parameters and data associations. Both particle marginal\nMetropolis-Hastings and particle Gibbs variants of particle MCMC are\nconsidered. We demonstrate the performance of the method both using simulated\ndata and in a real-data case study of using multiple target tracking to\nestimate the brown bear population in Finland.\n", "contributors": [{"name": "Kokkala, Juho", "sameAs": [], "familyName": "Kokkala", "additionalName": "", "givenName": "Juho", "email": ""}, {"name": "S\u00e4rkk\u00e4, Simo", "sameAs": [], "familyName": "S\u00e4rkk\u00e4", "additionalName": "", "givenName": "Simo", "email": ""}], "title": "Combining Particle MCMC with Rao-Blackwellized Monte Carlo Data\n  Association for Parameter Estimation in Multiple Target Tracking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-30", "2015-02-20"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.8502", "oai:arXiv.org:1409.8502"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "stat"]}}, {"name": "description", "properties": {"description": ["  We consider state and parameter estimation in multiple target tracking\nproblems with data association uncertainties and unknown number of targets. We\nshow how the problem can be recast into a conditionally linear Gaussian\nstate-space model with unknown parameters and present an algorithm for\ncomputationally efficient inference on the resulting model. The proposed\nalgorithm is based on combining the Rao-Blackwellized Monte Carlo data\nassociation algorithm with particle Markov chain Monte Carlo algorithms to\njointly estimate both parameters and data associations. Both particle marginal\nMetropolis-Hastings and particle Gibbs variants of particle MCMC are\nconsidered. We demonstrate the performance of the method both using simulated\ndata and in a real-data case study of using multiple target tracking to\nestimate the brown bear population in Finland.\n", "Comment: Revised version. 43 pages, 4 figures"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "statistics - applications", "statistics - methodology", "mathematics - dynamical systems", "statistics - computation"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.8502"}}, {"publisher": {"name": ""}, "description": "  Multiphase active contour based models are useful in identifying multiple\nregions with different characteristics such as the mean values of regions. This\nis relevant in brain magnetic resonance images (MRIs), allowing the\ndifferentiation of white matter against gray matter. We consider a well defined\nglobally convex formulation of Vese and Chan multiphase active contour model\nfor segmenting brain MRI images. A well-established theory and an efficient\ndual minimization scheme are thoroughly described which guarantees optimal\nsolutions and provides stable segmentations. Moreover, under the dual\nminimization implementation our model perfectly describes disjoint regions by\navoiding local minima solutions. Experimental results indicate that the\nproposed approach provides better accuracy than other related multiphase active\ncontour algorithms even under severe noise, intensity inhomogeneities, and\npartial volume effects.\n", "contributors": [{"name": "Moreno, Juan C.", "sameAs": [], "familyName": "Moreno", "additionalName": "C.", "givenName": "Juan", "email": ""}, {"name": "Prasath, V. B. S.", "sameAs": [], "familyName": "Prasath", "additionalName": "B. S.", "givenName": "V.", "email": ""}, {"name": "Proenca, Hugo", "sameAs": [], "familyName": "Proenca", "additionalName": "", "givenName": "Hugo", "email": ""}, {"name": "Palaniappan, K.", "sameAs": [], "familyName": "Palaniappan", "additionalName": "", "givenName": "K.", "email": ""}], "title": "Brain MRI Segmentation with Fast and Globally Convex Multiphase Active\n  Contours", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2013-08-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1308.6056", "Computer Vision and Image Understanding, 125, 237-250, 2014", "doi:10.1016/j.cviu.2014.04.010", "oai:arXiv.org:1308.6056"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Multiphase active contour based models are useful in identifying multiple\nregions with different characteristics such as the mean values of regions. This\nis relevant in brain magnetic resonance images (MRIs), allowing the\ndifferentiation of white matter against gray matter. We consider a well defined\nglobally convex formulation of Vese and Chan multiphase active contour model\nfor segmenting brain MRI images. A well-established theory and an efficient\ndual minimization scheme are thoroughly described which guarantees optimal\nsolutions and provides stable segmentations. Moreover, under the dual\nminimization implementation our model perfectly describes disjoint regions by\navoiding local minima solutions. Experimental results indicate that the\nproposed approach provides better accuracy than other related multiphase active\ncontour algorithms even under severe noise, intensity inhomogeneities, and\npartial volume effects.\n"}}], "languages": [null], "subjects": ["68u10", "i.4.6", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1308.6056"}}, {"publisher": {"name": ""}, "description": "  Let $k$ be a nonnegative integer. In the approximate $k$-flat nearest\nneighbor ($k$-ANN) problem, we are given a set $P \\subset \\mathbb{R}^d$ of $n$\npoints in $d$-dimensional space and a fixed approximation factor $c > 1$. Our\ngoal is to preprocess $P$ so that we can efficiently answer approximate\n$k$-flat nearest neighbor queries: given a $k$-flat $F$, find a point in $P$\nwhose distance to $F$ is within a factor $c$ of the distance between $F$ and\nthe closest point in $P$. The case $k = 0$ corresponds to the well-studied\napproximate nearest neighbor problem, for which a plethora of results are\nknown, both in low and high dimensions. The case $k = 1$ is called approximate\nline nearest neighbor. In this case, we are aware of only one provably\nefficient data structure, due to Andoni, Indyk, Krauthgamer, and Nguyen. For $k\n\\geq 2$, we know of no previous results.\n  We present the first efficient data structure that can handle approximate\nnearest neighbor queries for arbitrary $k$. We use a data structure for\n$0$-ANN-queries as a black box, and the performance depends on the parameters\nof the $0$-ANN solution: suppose we have an $0$-ANN structure with query time\n$O(n^{\\rho})$ and space requirement $O(n^{1+\\sigma})$, for $\\rho, \\sigma > 0$.\nThen we can answer $k$-ANN queries in time $O(n^{k/(k + 1 - \\rho) + t})$ and\nspace $O(n^{1+\\sigma k/(k + 1 - \\rho)} + n\\log^{O(1/t)} n)$. Here, $t > 0$ is\nan arbitrary constant and the $O$-notation hides exponential factors in $k$,\n$1/t$, and $c$ and polynomials in $d$. Our new data structures also give an\nimprovement in the space requirement over the previous result for $1$-ANN: we\ncan achieve near-linear space and sublinear query time, a further step towards\npractical applications where space constitutes the bottleneck.\n", "contributors": [{"name": "Mulzer, Wolfgang", "sameAs": [], "familyName": "Mulzer", "additionalName": "", "givenName": "Wolfgang", "email": ""}, {"name": "Nguyen, Huy L.", "sameAs": [], "familyName": "Nguyen", "additionalName": "L.", "givenName": "Huy", "email": ""}, {"name": "Seiferth, Paul", "sameAs": [], "familyName": "Seiferth", "additionalName": "", "givenName": "Paul", "email": ""}, {"name": "Stein, Yannik", "sameAs": [], "familyName": "Stein", "additionalName": "", "givenName": "Yannik", "email": ""}], "title": "Approximate k-flat Nearest Neighbor Search", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1519", "oai:arXiv.org:1411.1519"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Let $k$ be a nonnegative integer. In the approximate $k$-flat nearest\nneighbor ($k$-ANN) problem, we are given a set $P \\subset \\mathbb{R}^d$ of $n$\npoints in $d$-dimensional space and a fixed approximation factor $c > 1$. Our\ngoal is to preprocess $P$ so that we can efficiently answer approximate\n$k$-flat nearest neighbor queries: given a $k$-flat $F$, find a point in $P$\nwhose distance to $F$ is within a factor $c$ of the distance between $F$ and\nthe closest point in $P$. The case $k = 0$ corresponds to the well-studied\napproximate nearest neighbor problem, for which a plethora of results are\nknown, both in low and high dimensions. The case $k = 1$ is called approximate\nline nearest neighbor. In this case, we are aware of only one provably\nefficient data structure, due to Andoni, Indyk, Krauthgamer, and Nguyen. For $k\n\\geq 2$, we know of no previous results.\n  We present the first efficient data structure that can handle approximate\nnearest neighbor queries for arbitrary $k$. We use a data structure for\n$0$-ANN-queries as a black box, and the performance depends on the parameters\nof the $0$-ANN solution: suppose we have an $0$-ANN structure with query time\n$O(n^{\\rho})$ and space requirement $O(n^{1+\\sigma})$, for $\\rho, \\sigma > 0$.\nThen we can answer $k$-ANN queries in time $O(n^{k/(k + 1 - \\rho) + t})$ and\nspace $O(n^{1+\\sigma k/(k + 1 - \\rho)} + n\\log^{O(1/t)} n)$. Here, $t > 0$ is\nan arbitrary constant and the $O$-notation hides exponential factors in $k$,\n$1/t$, and $c$ and polynomials in $d$. Our new data structures also give an\nimprovement in the space requirement over the previous result for $1$-ANN: we\ncan achieve near-linear space and sublinear query time, a further step towards\npractical applications where space constitutes the bottleneck.\n", "Comment: 22 pages, 1 figure"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational geometry"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1519"}}, {"publisher": {"name": ""}, "description": "  Social networks help to bond people who share similar interests all over the\nworld. As a complement, the Facebook \"Like\" button is an efficient tool that\nbonds people with the online information. People click on the \"Like\" button to\nexpress their fondness of a particular piece of information and in turn tend to\nvisit webpages with high \"Like\" count. The important fact of the Like count is\nthat it reflects the number of actual users who \"liked\" this information.\nHowever, according to our study, one can easily exploit the defects of the\n\"Like\" button to counterfeit a high \"Like\" count. We provide a proof-of-concept\nimplementation of these exploits, and manage to generate 100 fake Likes in 5\nminutes with a single account. We also reveal existing counterfeiting\ntechniques used by some online sellers to achieve unfair advantage for\npromoting their products. To address this fake Like problem, we study the\nvarying patterns of Like count and propose an innovative fake Like detection\nmethod based on clustering. To evaluate the effectiveness of our algorithm, we\ncollect the Like count history of more than 9,000 websites. Our experiments\nsuccessfully uncover 16 suspicious fake Like buyers that show abnormal Like\ncount increase patterns.\n", "contributors": [{"name": "Lin, Xinye", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Xinye", "email": ""}, {"name": "Xia, Mingyuan", "sameAs": [], "familyName": "Xia", "additionalName": "", "givenName": "Mingyuan", "email": ""}, {"name": "Liu, Xue", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Xue", "email": ""}], "title": "Does \"Like\" Really Mean Like? A Study of the Facebook Fake Like\n  Phenomenon and an Efficient Countermeasure", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-18", "2015-03-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.05414", "oai:arXiv.org:1503.05414"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Social networks help to bond people who share similar interests all over the\nworld. As a complement, the Facebook \"Like\" button is an efficient tool that\nbonds people with the online information. People click on the \"Like\" button to\nexpress their fondness of a particular piece of information and in turn tend to\nvisit webpages with high \"Like\" count. The important fact of the Like count is\nthat it reflects the number of actual users who \"liked\" this information.\nHowever, according to our study, one can easily exploit the defects of the\n\"Like\" button to counterfeit a high \"Like\" count. We provide a proof-of-concept\nimplementation of these exploits, and manage to generate 100 fake Likes in 5\nminutes with a single account. We also reveal existing counterfeiting\ntechniques used by some online sellers to achieve unfair advantage for\npromoting their products. To address this fake Like problem, we study the\nvarying patterns of Like count and propose an innovative fake Like detection\nmethod based on clustering. To evaluate the effectiveness of our algorithm, we\ncollect the Like count history of more than 9,000 websites. Our experiments\nsuccessfully uncover 16 suspicious fake Like buyers that show abnormal Like\ncount increase patterns.\n", "Comment: 10 pages; updated the flaw details according to new Facebook API"]}}], "languages": [null], "subjects": ["k.4.1", "h.4", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.05414"}}, {"publisher": {"name": ""}, "description": "  Fires, lights at night and mobile phone activity have been separately used as\nproxy indicators of human activity with high potential for measuring human\ndevelopment. In this preliminary report, we develop some tools and\nmethodologies to identify and visualize relations among remote sensing datasets\ncontaining fires and night lights information with mobile phone activity in\nCote D'Ivoire from December 2011 to April 2012.\n", "contributors": [{"name": "Pastor-Escuredo, David", "sameAs": [], "familyName": "Pastor-Escuredo", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Savy, Thierry", "sameAs": [], "familyName": "Savy", "additionalName": "", "givenName": "Thierry", "email": ""}, {"name": "Luengo-Oroz, Miguel A.", "sameAs": [], "familyName": "Luengo-Oroz", "additionalName": "A.", "givenName": "Miguel", "email": ""}], "title": "Can Fires, Night Lights, and Mobile Phones reveal behavioral\n  fingerprints useful for Development?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00549", "oai:arXiv.org:1501.00549"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Fires, lights at night and mobile phone activity have been separately used as\nproxy indicators of human activity with high potential for measuring human\ndevelopment. In this preliminary report, we develop some tools and\nmethodologies to identify and visualize relations among remote sensing datasets\ncontaining fires and night lights information with mobile phone activity in\nCote D'Ivoire from December 2011 to April 2012.\n", "Comment: Published in D4D Challenge. NetMob, May 1-3, 2013, MIT"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00549"}}, {"publisher": {"name": ""}, "description": "  Sorting algorithms have attracted a great deal of attention and study, as\nthey have numerous applications to Mathematics, Computer Science and related\nfields. In this thesis, we first deal with the mathematical analysis of the\nQuicksort algorithm and its variants. Specifically, we study the time\ncomplexity of the algorithm and we provide a complete demonstration of the\nvariance of the number of comparisons required, a known result but one whose\ndetailed proof is not easy to read out of the literature. We also examine\nvariants of Quicksort, where multiple pivots are chosen for the partitioning of\nthe array.\n  The rest of this work is dedicated to the analysis of finding the true order\nby further pairwise comparisons when a partial order compatible with the true\norder is given in advance. We discuss a number of cases where the partially\nordered sets arise at random. To this end, we employ results from Graph and\nInformation Theory. Finally, we obtain an alternative bound on the number of\nlinear extensions when the partially ordered set arises from a random graph,\nand discuss the possible application of Shellsort in merging chains.\n", "contributors": [{"name": "Iliopoulos, Vasileios", "sameAs": [], "familyName": "Iliopoulos", "additionalName": "", "givenName": "Vasileios", "email": ""}], "title": "The Quicksort algorithm and related topics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-09", "2015-03-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02504", "oai:arXiv.org:1503.02504"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Sorting algorithms have attracted a great deal of attention and study, as\nthey have numerous applications to Mathematics, Computer Science and related\nfields. In this thesis, we first deal with the mathematical analysis of the\nQuicksort algorithm and its variants. Specifically, we study the time\ncomplexity of the algorithm and we provide a complete demonstration of the\nvariance of the number of comparisons required, a known result but one whose\ndetailed proof is not easy to read out of the literature. We also examine\nvariants of Quicksort, where multiple pivots are chosen for the partitioning of\nthe array.\n  The rest of this work is dedicated to the analysis of finding the true order\nby further pairwise comparisons when a partial order compatible with the true\norder is given in advance. We discuss a number of cases where the partially\nordered sets arise at random. To this end, we employ results from Graph and\nInformation Theory. Finally, we obtain an alternative bound on the number of\nlinear extensions when the partially ordered set arises from a random graph,\nand discuss the possible application of Shellsort in merging chains.\n", "Comment: PhD thesis. Reference [23] was missing in first version. It now reads\n  correctly in page 142, Section 5.6"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02504"}}, {"publisher": {"name": ""}, "description": "  In this work we propose a generalization of Winfree's abstract Tile Assembly\nModel (aTAM) in which tile types are assigned rigid shapes, or geometries,\nalong each tile face. We examine the number of distinct tile types needed to\nassemble shapes within this model, the temperature required for efficient\nassembly, and the problem of designing compact geometric faces to meet given\ncompatibility specifications. Our results show a dramatic decrease in the\nnumber of tile types needed to assemble $n \\times n$ squares to\n$\\Theta(\\sqrt{\\log n})$ at temperature 1 for the most simple model which meets\na lower bound from Kolmogorov complexity, and $O(\\log\\log n)$ in a model in\nwhich tile aggregates must move together through obstacle free paths within the\nplane. This stands in contrast to the $\\Theta(\\log n / \\log\\log n)$ tile types\nat temperature 2 needed in the basic aTAM. We also provide a general method for\nsimulating a large and computationally universal class of temperature 2 aTAM\nsystems with geometric tiles at temperature 1. Finally, we consider the problem\nof computing a set of compact geometric faces for a tile system to implement a\ngiven set of compatibility specifications. We show a number of bounds on the\ncomplexity of geometry size needed for various classes of compatibility\nspecifications, many of which we directly apply to our tile assembly results to\nachieve non-trivial reductions in geometry size.\n", "contributors": [{"name": "Fu, Bin", "sameAs": [], "familyName": "Fu", "additionalName": "", "givenName": "Bin", "email": ""}, {"name": "Patitz, Matthew J.", "sameAs": [], "familyName": "Patitz", "additionalName": "J.", "givenName": "Matthew", "email": ""}, {"name": "Schweller, Robert T.", "sameAs": [], "familyName": "Schweller", "additionalName": "T.", "givenName": "Robert", "email": ""}, {"name": "Sheline, Bobby", "sameAs": [], "familyName": "Sheline", "additionalName": "", "givenName": "Bobby", "email": ""}], "title": "Self-Assembly with Geometric Tiles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-04-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.2809", "oai:arXiv.org:1104.2809"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this work we propose a generalization of Winfree's abstract Tile Assembly\nModel (aTAM) in which tile types are assigned rigid shapes, or geometries,\nalong each tile face. We examine the number of distinct tile types needed to\nassemble shapes within this model, the temperature required for efficient\nassembly, and the problem of designing compact geometric faces to meet given\ncompatibility specifications. Our results show a dramatic decrease in the\nnumber of tile types needed to assemble $n \\times n$ squares to\n$\\Theta(\\sqrt{\\log n})$ at temperature 1 for the most simple model which meets\na lower bound from Kolmogorov complexity, and $O(\\log\\log n)$ in a model in\nwhich tile aggregates must move together through obstacle free paths within the\nplane. This stands in contrast to the $\\Theta(\\log n / \\log\\log n)$ tile types\nat temperature 2 needed in the basic aTAM. We also provide a general method for\nsimulating a large and computationally universal class of temperature 2 aTAM\nsystems with geometric tiles at temperature 1. Finally, we consider the problem\nof computing a set of compact geometric faces for a tile system to implement a\ngiven set of compatibility specifications. We show a number of bounds on the\ncomplexity of geometry size needed for various classes of compatibility\nspecifications, many of which we directly apply to our tile assembly results to\nachieve non-trivial reductions in geometry size.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity", "computer science - emerging technologies", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.2809"}}, {"publisher": {"name": ""}, "description": "  We undertake an extensive numerical investigation of the graph spectra of\nthousands regular graphs, a set of random Erd\\\"os-R\\'enyi graphs, the two most\npopular types of complex networks and an evolving genetic network by using\nnovel conceptual and experimental tools. Our objective in so doing is to\ncontribute to an understanding of the meaning of the Eigenvalues of a graph\nrelative to its topological and information-theoretic properties. We introduce\na technique for identifying the most informative Eigenvalues of evolving\nnetworks by comparing graph spectra behavior to their algorithmic complexity.\nWe suggest that extending techniques can be used to further investigate the\nbehavior of evolving biological networks. In the extended version of this paper\nwe apply these techniques to seven tissue specific regulatory networks as\nstatic example and network of a na\\\"ive pluripotent immune cell in the process\nof differentiating towards a Th17 cell as evolving example, finding the most\nand least informative Eigenvalues at every stage.\n", "contributors": [{"name": "Zenil, Hector", "sameAs": [], "familyName": "Zenil", "additionalName": "", "givenName": "Hector", "email": ""}, {"name": "Kiani, Narsis A.", "sameAs": [], "familyName": "Kiani", "additionalName": "A.", "givenName": "Narsis", "email": ""}, {"name": "Tegn\u00e9r, Jesper", "sameAs": [], "familyName": "Tegn\u00e9r", "additionalName": "", "givenName": "Jesper", "email": ""}], "title": "Numerical Investigation of Graph Spectra and Information\n  Interpretability of Eigenvalues", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06080", "oai:arXiv.org:1501.06080"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We undertake an extensive numerical investigation of the graph spectra of\nthousands regular graphs, a set of random Erd\\\"os-R\\'enyi graphs, the two most\npopular types of complex networks and an evolving genetic network by using\nnovel conceptual and experimental tools. Our objective in so doing is to\ncontribute to an understanding of the meaning of the Eigenvalues of a graph\nrelative to its topological and information-theoretic properties. We introduce\na technique for identifying the most informative Eigenvalues of evolving\nnetworks by comparing graph spectra behavior to their algorithmic complexity.\nWe suggest that extending techniques can be used to further investigate the\nbehavior of evolving biological networks. In the extended version of this paper\nwe apply these techniques to seven tissue specific regulatory networks as\nstatic example and network of a na\\\"ive pluripotent immune cell in the process\nof differentiating towards a Th17 cell as evolving example, finding the most\nand least informative Eigenvalues at every stage.\n", "Comment: Forthcoming in 3rd International Work-Conference on Bioinformatics\n  and Biomedical Engineering (IWBBIO), Lecture Notes in Bioinformatics, 2015"]}}], "languages": [null], "subjects": ["computer science - information theory", "mathematics - spectral theory", "mathematics - dynamical systems"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06080"}}, {"publisher": {"name": ""}, "description": "  We introduce the Xapagy cognitive architecture: a software system designed to\nperform narrative reasoning. The architecture has been designed from scratch to\nmodel and mimic the activities performed by humans when witnessing, reading,\nrecalling, narrating and talking about stories.\n", "contributors": [{"name": "B\u00f6l\u00f6ni, Ladislau", "sameAs": [], "familyName": "B\u00f6l\u00f6ni", "additionalName": "", "givenName": "Ladislau", "email": ""}], "title": "Xapagy: a cognitive architecture for narrative reasoning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.3486", "oai:arXiv.org:1105.3486"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We introduce the Xapagy cognitive architecture: a software system designed to\nperform narrative reasoning. The architecture has been designed from scratch to\nmodel and mimic the activities performed by humans when witnessing, reading,\nrecalling, narrating and talking about stories.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "i.2.0", "68t01"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.3486"}}, {"publisher": {"name": ""}, "description": "  Territorial subdivisions and geographic borders are essential for\nunderstanding phenomena in sociology, political science, history, and\neconomics. They influence the interregional flow of information and\ncross-border trade and affect the diffusion of innovation and technology.\nHowever, most existing administrative borders were determined by a variety of\nhistoric and political circumstances along with some degree of arbitrariness.\nSocieties have changed drastically, and it is doubtful that currently existing\nborders reflect the most logical divisions. Fortunately, at this point in\nhistory we are in a position to actually measure some aspects of the geographic\nstructure of society through human mobility. Large-scale transportation systems\nsuch as trains and airlines provide data about the number of people traveling\nbetween geographic locations, and many promising human mobility proxies are\nbeing discovered, such as cell phones, bank notes, and various online social\nnetworks. In this chapter we apply two optimization techniques to a human\nmobility proxy (bank note circulation) to investigate the effective geographic\nborders that emerge from a direct analysis of human mobility.\n", "contributors": [{"name": "Grady, Daniel", "sameAs": [], "familyName": "Grady", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Brune, Rafael", "sameAs": [], "familyName": "Brune", "additionalName": "", "givenName": "Rafael", "email": ""}, {"name": "Thiemann, Christian", "sameAs": [], "familyName": "Thiemann", "additionalName": "", "givenName": "Christian", "email": ""}, {"name": "Theis, Fabian", "sameAs": [], "familyName": "Theis", "additionalName": "", "givenName": "Fabian", "email": ""}, {"name": "Brockmann, Dirk", "sameAs": [], "familyName": "Brockmann", "additionalName": "", "givenName": "Dirk", "email": ""}], "title": "Modularity maximization and tree clustering: Novel ways to determine\n  effective geographic borders", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.1200", "oai:arXiv.org:1104.1200"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Territorial subdivisions and geographic borders are essential for\nunderstanding phenomena in sociology, political science, history, and\neconomics. They influence the interregional flow of information and\ncross-border trade and affect the diffusion of innovation and technology.\nHowever, most existing administrative borders were determined by a variety of\nhistoric and political circumstances along with some degree of arbitrariness.\nSocieties have changed drastically, and it is doubtful that currently existing\nborders reflect the most logical divisions. Fortunately, at this point in\nhistory we are in a position to actually measure some aspects of the geographic\nstructure of society through human mobility. Large-scale transportation systems\nsuch as trains and airlines provide data about the number of people traveling\nbetween geographic locations, and many promising human mobility proxies are\nbeing discovered, such as cell phones, bank notes, and various online social\nnetworks. In this chapter we apply two optimization techniques to a human\nmobility proxy (bank note circulation) to investigate the effective geographic\nborders that emerge from a direct analysis of human mobility.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.1200"}}, {"publisher": {"name": ""}, "description": "  Recent years have witnessed significant interest in convex relaxations of the\npower flows, several papers showing that the second-order cone relaxation is\ntight for tree networks under various conditions on loads or voltages. This\npaper shows that AC-feasibility, i.e., to find whether some generator dispatch\ncan satisfy a given demand, is NP-Hard for tree networks.\n", "contributors": [{"name": "Lehmann, Karsten", "sameAs": [], "familyName": "Lehmann", "additionalName": "", "givenName": "Karsten", "email": ""}, {"name": "Grastien, Alban", "sameAs": [], "familyName": "Grastien", "additionalName": "", "givenName": "Alban", "email": ""}, {"name": "Van Hentenryck, Pascal", "sameAs": [], "familyName": "Van Hentenryck", "additionalName": "", "givenName": "Pascal", "email": ""}], "title": "AC-Feasibility on Tree Networks is NP-Hard", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.8253", "oai:arXiv.org:1410.8253"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Recent years have witnessed significant interest in convex relaxations of the\npower flows, several papers showing that the second-order cone relaxation is\ntight for tree networks under various conditions on loads or voltages. This\npaper shows that AC-feasibility, i.e., to find whether some generator dispatch\ncan satisfy a given demand, is NP-Hard for tree networks.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - computational complexity"], "providerUpdatedDateTime": "2014-10-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.8253"}}, {"publisher": {"name": ""}, "description": "  Exact synthesis is a tool used in algorithms for approximating an arbitrary\nqubit unitary with a sequence of quantum gates from some finite set. These\napproximation algorithms find asymptotically optimal approximations in\nprobabilistic polynomial time, in some cases even finding the optimal solution\nin probabilistic polynomial time given access to an oracle for factoring\nintegers. In this paper, we present a common mathematical structure underlying\nall results related to the exact synthesis of qubit unitaries known to date,\nincluding Clifford+T, Clifford-cyclotomic and V-basis gate sets, as well as\ngates sets induced by the braiding of Fibonacci anyons in topological quantum\ncomputing. The framework presented here also provides a means to answer\nquestions related to the exact synthesis of unitaries for wide classes of other\ngate sets, such as Clifford+T+V and SU(2) level k anyons.\n", "contributors": [{"name": "Kliuchnikov, Vadym", "sameAs": [], "familyName": "Kliuchnikov", "additionalName": "", "givenName": "Vadym", "email": ""}, {"name": "Yard, Jon", "sameAs": [], "familyName": "Yard", "additionalName": "", "givenName": "Jon", "email": ""}], "title": "A framework for exact synthesis", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.04350", "oai:arXiv.org:1504.04350"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": ["  Exact synthesis is a tool used in algorithms for approximating an arbitrary\nqubit unitary with a sequence of quantum gates from some finite set. These\napproximation algorithms find asymptotically optimal approximations in\nprobabilistic polynomial time, in some cases even finding the optimal solution\nin probabilistic polynomial time given access to an oracle for factoring\nintegers. In this paper, we present a common mathematical structure underlying\nall results related to the exact synthesis of qubit unitaries known to date,\nincluding Clifford+T, Clifford-cyclotomic and V-basis gate sets, as well as\ngates sets induced by the braiding of Fibonacci anyons in topological quantum\ncomputing. The framework presented here also provides a means to answer\nquestions related to the exact synthesis of unitaries for wide classes of other\ngate sets, such as Clifford+T+V and SU(2) level k anyons.\n", "Comment: 40 pages, preliminary version"]}}], "languages": [null], "subjects": ["quantum physics", "computer science - emerging technologies"], "providerUpdatedDateTime": "2015-04-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.04350"}}, {"publisher": {"name": ""}, "description": "  The three standard products (the Cartesian, the direct and the strong\nproduct) of undirected graphs have been wellinvestigated, unique prime factor\ndecomposition (PFD) are known and polynomial time algorithms have been\nestablished for determining the prime factors.\n  For directed graphs, unique PFD results with respect to the standard products\nare known. However, there is still a lack of algorithms, that computes the PFD\nof directed graphs with respect to the direct and the strong product in\ngeneral. In this contribution, we focus on the algorithmic aspects for\ndetermining the PFD of directed graphs with respect to the strong product.\nEssential for computing the prime factors is the construction of a so-called\nCartesian skeleton. This article introduces the notion of the Cartesian\nskeleton of directed graphs as a generalization of the Cartesian skeleton of\nundirected graphs. We provide new, fast and transparent algorithms for its\nconstruction. Moreover, we present a first polynomial time algorithm for\ndetermining the PFD with respect to the strong product of arbitrary connected\ndigraphs.\n", "contributors": [{"name": "Hellmuth, Marc", "sameAs": [], "familyName": "Hellmuth", "additionalName": "", "givenName": "Marc", "email": ""}, {"name": "Marc, Tilen", "sameAs": [], "familyName": "Marc", "additionalName": "", "givenName": "Tilen", "email": ""}], "title": "On the Cartesian Skeleton and the Factorization of the Strong Product of\n  Digraphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-01-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1401.4965", "doi:10.1016/j.tcs.2014.10.045", "oai:arXiv.org:1401.4965"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  The three standard products (the Cartesian, the direct and the strong\nproduct) of undirected graphs have been wellinvestigated, unique prime factor\ndecomposition (PFD) are known and polynomial time algorithms have been\nestablished for determining the prime factors.\n  For directed graphs, unique PFD results with respect to the standard products\nare known. However, there is still a lack of algorithms, that computes the PFD\nof directed graphs with respect to the direct and the strong product in\ngeneral. In this contribution, we focus on the algorithmic aspects for\ndetermining the PFD of directed graphs with respect to the strong product.\nEssential for computing the prime factors is the construction of a so-called\nCartesian skeleton. This article introduces the notion of the Cartesian\nskeleton of directed graphs as a generalization of the Cartesian skeleton of\nundirected graphs. We provide new, fast and transparent algorithms for its\nconstruction. Moreover, we present a first polynomial time algorithm for\ndetermining the PFD with respect to the strong product of arbitrary connected\ndigraphs.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-11-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1401.4965"}}, {"publisher": {"name": ""}, "description": "  This article surveys work done in the last six years on the unification of\nvarious functional interpretations including G\\\"odel's dialectica\ninterpretation, its Diller-Nahm variant, Kreisel modified realizability,\nStein's family of functional interpretations, functional interpretations \"with\ntruth\", and bounded functional interpretations. Our goal in the present paper\nis twofold: (1) to look back and single out the main lessons learnt so far, and\n(2) to look forward and list several open questions and possible directions for\nfurther research.\n", "contributors": [{"name": "Oliva, Paulo", "sameAs": [], "familyName": "Oliva", "additionalName": "", "givenName": "Paulo", "email": ""}], "title": "Unifying Functional Interpretations: Past and Future", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4364", "oai:arXiv.org:1410.4364"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This article surveys work done in the last six years on the unification of\nvarious functional interpretations including G\\\"odel's dialectica\ninterpretation, its Diller-Nahm variant, Kreisel modified realizability,\nStein's family of functional interpretations, functional interpretations \"with\ntruth\", and bounded functional interpretations. Our goal in the present paper\nis twofold: (1) to look back and single out the main lessons learnt so far, and\n(2) to look forward and list several open questions and possible directions for\nfurther research.\n", "Comment: 18 pages"]}}], "languages": [null], "subjects": ["mathematics - logic", "computer science - logic in computer science", "03b47", "03f25"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4364"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Can we model the temporal evolution of topics in Web image collections? If so, can we exploit the understanding of dynamics to solve novel visual problems or improve recognition performance? These two challenging questions are the motivation for this work. We propose a nonparametric approach to modeling and analysis of topical evolution in image sets. A scalable and parallelizable sequential Monte Carlo based method is developed to construct the similarity network of a large-scale dataset that provides a base representation for wide ranges of dynamics analysis. In this paper, we provide several experimental results to support the usefulness of image dynamics with the datasets of 47 topics gathered from Flickr. First, we produce some interesting observations such as tracking of subtopic evolution and outbreak detection, which cannot be achieved with conventional image sets. Second, we also present the complementary benefits that the images can introduce over the associated text analysis. Finally, we show that the training using the temporal association significantly improves the recognition performance.", "contributors": [{"name": "Kim, Gunhee", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Gunhee", "email": ""}, {"name": "Xing, Eric P.", "sameAs": [], "familyName": "Xing", "additionalName": "P.", "givenName": "Eric", "email": ""}, {"name": "Torralba, Antonio", "sameAs": [], "familyName": "Torralba", "additionalName": "", "givenName": "Antonio", "email": ""}], "title": "Modeling and Analysis of Dynamic Behaviors of Web Image Collections", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2010-09-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/239", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1235&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1235"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Can we model the temporal evolution of topics in Web image collections? If so, can we exploit the understanding of dynamics to solve novel visual problems or improve recognition performance? These two challenging questions are the motivation for this work. We propose a nonparametric approach to modeling and analysis of topical evolution in image sets. A scalable and parallelizable sequential Monte Carlo based method is developed to construct the similarity network of a large-scale dataset that provides a base representation for wide ranges of dynamics analysis. In this paper, we provide several experimental results to support the usefulness of image dynamics with the datasets of 47 topics gathered from Flickr. First, we produce some interesting observations such as tracking of subtopic evolution and outbreak detection, which cannot be achieved with conventional image sets. Second, we also present the complementary benefits that the images can introduce over the associated text analysis. Finally, we show that the training using the temporal association significantly improves the recognition performance."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-04-13T21:30:13", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/239"}}, {"publisher": {"name": ""}, "description": "  Suppose $(X,\\omega)$ is a compact K\\\"ahler manifold. Following Mabuchi, the\nspace of smooth K\\\"ahler potentials $\\mathcal H$ can be endowed with a\nRiemannian structure, which induces an infinite dimensional path length metric\nspace $(\\mathcal H,d)$. We prove that the metric completion of $(\\mathcal H,d)$\ncan be identified with $(\\mathcal E^2(X,\\omega),\\tilde d)$, and this latter\nspace is a complete non-positively curved geodesic metric space. In obtaining\nthis result, we will rely on envelope techniques which allow for a treatment in\na very general context. Profiting from this, we will characterize the pairs of\npotentials in $\\text{PSH}(X,\\omega)$ that can be connected by weak geodesics\nand we will also give a characterization of $\\mathcal E(X,\\omega)$ in this\ncontext.\n", "contributors": [{"name": "Darvas, Tam\u00e1s", "sameAs": [], "familyName": "Darvas", "additionalName": "", "givenName": "Tam\u00e1s", "email": ""}], "title": "The Mabuchi Completion of the Space of K\\\"ahler Potentials", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-01-28", "2015-03-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1401.7318", "oai:arXiv.org:1401.7318"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Suppose $(X,\\omega)$ is a compact K\\\"ahler manifold. Following Mabuchi, the\nspace of smooth K\\\"ahler potentials $\\mathcal H$ can be endowed with a\nRiemannian structure, which induces an infinite dimensional path length metric\nspace $(\\mathcal H,d)$. We prove that the metric completion of $(\\mathcal H,d)$\ncan be identified with $(\\mathcal E^2(X,\\omega),\\tilde d)$, and this latter\nspace is a complete non-positively curved geodesic metric space. In obtaining\nthis result, we will rely on envelope techniques which allow for a treatment in\na very general context. Profiting from this, we will characterize the pairs of\npotentials in $\\text{PSH}(X,\\omega)$ that can be connected by weak geodesics\nand we will also give a characterization of $\\mathcal E(X,\\omega)$ in this\ncontext.\n", "Comment: v3 New title and new introduction. No other changes"]}}], "languages": [null], "subjects": ["mathematics - differential geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1401.7318"}}, {"publisher": {"name": ""}, "description": "  The ability to recognize the liquid surface and the liquid level in\ntransparent containers is perhaps the most commonly used evaluation method when\ndealing with fluids. Such recognition is essential in determining the liquid\nvolume, fill level, phase boundaries and phase separation in various fluid\nsystems. The recognition of liquid surfaces is particularly important in\nsolution chemistry, where it is essential to many laboratory techniques (e.g.,\nextraction, distillation, titration). A general method for the recognition of\ninterfaces between liquid and air or between phase-separating liquids could\nhave a wide range of applications and contribute to the understanding of the\nvisual properties of such interfaces. This work examines a computer vision\nmethod for the recognition of liquid surfaces and liquid levels in various\ntransparent containers. The method can be applied to recognition of both\nliquid-air and liquid-liquid surfaces. No prior knowledge of the number of\nphases is required. The method receives the image of the liquid container and\nthe boundaries of the container in the image and scans all possible curves that\ncould correspond to the outlines of liquid surfaces in the image. The method\nthen compares each curve to the image to rate its correspondence with the\noutline of the real liquid surface by examining various image properties in the\narea surrounding each point of the curve. The image properties that were found\nto give the best indication of the liquid surface are the relative intensity\nchange, the edge density change and the gradient direction relative to the\ncurve normal.\n", "contributors": [{"name": "Eppel, Sagi", "sameAs": [], "familyName": "Eppel", "additionalName": "", "givenName": "Sagi", "email": ""}, {"name": "Kachman, Tal", "sameAs": [], "familyName": "Kachman", "additionalName": "", "givenName": "Tal", "email": ""}], "title": "Computer vision-based recognition of liquid surfaces and phase\n  boundaries in transparent vessels, with emphasis on chemistry applications", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-28", "2014-11-06"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.7174", "oai:arXiv.org:1404.7174"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The ability to recognize the liquid surface and the liquid level in\ntransparent containers is perhaps the most commonly used evaluation method when\ndealing with fluids. Such recognition is essential in determining the liquid\nvolume, fill level, phase boundaries and phase separation in various fluid\nsystems. The recognition of liquid surfaces is particularly important in\nsolution chemistry, where it is essential to many laboratory techniques (e.g.,\nextraction, distillation, titration). A general method for the recognition of\ninterfaces between liquid and air or between phase-separating liquids could\nhave a wide range of applications and contribute to the understanding of the\nvisual properties of such interfaces. This work examines a computer vision\nmethod for the recognition of liquid surfaces and liquid levels in various\ntransparent containers. The method can be applied to recognition of both\nliquid-air and liquid-liquid surfaces. No prior knowledge of the number of\nphases is required. The method receives the image of the liquid container and\nthe boundaries of the container in the image and scans all possible curves that\ncould correspond to the outlines of liquid surfaces in the image. The method\nthen compares each curve to the image to rate its correspondence with the\noutline of the real liquid surface by examining various image properties in the\narea surrounding each point of the curve. The image properties that were found\nto give the best indication of the liquid surface are the relative intensity\nchange, the edge density change and the gradient direction relative to the\ncurve normal.\n", "Comment: Source code for phase boundary and liquid surface recognition\n  available at:\n  http://www.mathworks.com/matlabcentral/fileexchange/46893-computer-vision-based-recognition-of-liquid-surface-and-liquid-level-of-liquid-of-transparent-vessel"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.7174"}}, {"publisher": {"name": ""}, "description": "  I examine the topic of training scientific generalists. To focus the\ndiscussion, I propose the creation of a new graduate program, analogous in\nstructure to existing MD/PhD programs, aimed at training a critical mass of\nscientific researchers with substantial intellectual breadth. In addition to\ncompleting the normal requirements for a PhD, students would undergo an\nintense, several year training period designed to expose them to the core\nvocabulary of multiple subjects at the graduate level. After providing some\nhistorical and philosophical context for this proposal, I outline how such a\nprogram could be implemented with little institutional overhead by existing\nresearch universities. Finally, I discuss alternative possibilities for\ntraining generalists by taking advantage of contemporary developments in online\nlearning and open science.\n", "contributors": [{"name": "Sarma, Gopal", "sameAs": [], "familyName": "Sarma", "additionalName": "", "givenName": "Gopal", "email": ""}], "title": "Should we train scientific generalists?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4422", "oai:arXiv.org:1410.4422"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  I examine the topic of training scientific generalists. To focus the\ndiscussion, I propose the creation of a new graduate program, analogous in\nstructure to existing MD/PhD programs, aimed at training a critical mass of\nscientific researchers with substantial intellectual breadth. In addition to\ncompleting the normal requirements for a PhD, students would undergo an\nintense, several year training period designed to expose them to the core\nvocabulary of multiple subjects at the graduate level. After providing some\nhistorical and philosophical context for this proposal, I outline how such a\nprogram could be implemented with little institutional overhead by existing\nresearch universities. Finally, I discuss alternative possibilities for\ntraining generalists by taking advantage of contemporary developments in online\nlearning and open science.\n", "Comment: 8 pages"]}}], "languages": [null], "subjects": ["computer science - computers and society", "physics - physics education"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4422"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose and study a new semi-random model for graph\npartitioning problems. We believe that it captures many properties of\nreal--world instances. The model is more flexible than the semi-random model of\nFeige and Kilian and planted random model of Bui, Chaudhuri, Leighton and\nSipser.\n  We develop a general framework for solving semi-random instances and apply it\nto several problems of interest. We present constant factor bi-criteria\napproximation algorithms for semi-random instances of the Balanced Cut,\nMulticut, Min Uncut, Sparsest Cut and Small Set Expansion problems. We also\nshow how to almost recover the optimal solution if the instance satisfies an\nadditional expanding condition. Our algorithms work in a wider range of\nparameters than most algorithms for previously studied random and semi-random\nmodels.\n  Additionally, we study a new planted algebraic expander model and develop\nconstant factor bi-criteria approximation algorithms for graph partitioning\nproblems in this model.\n", "contributors": [{"name": "Makarychev, Konstantin", "sameAs": [], "familyName": "Makarychev", "additionalName": "", "givenName": "Konstantin", "email": ""}, {"name": "Makarychev, Yury", "sameAs": [], "familyName": "Makarychev", "additionalName": "", "givenName": "Yury", "email": ""}, {"name": "Vijayaraghavan, Aravindan", "sameAs": [], "familyName": "Vijayaraghavan", "additionalName": "", "givenName": "Aravindan", "email": ""}], "title": "Approximation Algorithms for Semi-random Graph Partitioning Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2012-05-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.2234", "oai:arXiv.org:1205.2234"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In this paper, we propose and study a new semi-random model for graph\npartitioning problems. We believe that it captures many properties of\nreal--world instances. The model is more flexible than the semi-random model of\nFeige and Kilian and planted random model of Bui, Chaudhuri, Leighton and\nSipser.\n  We develop a general framework for solving semi-random instances and apply it\nto several problems of interest. We present constant factor bi-criteria\napproximation algorithms for semi-random instances of the Balanced Cut,\nMulticut, Min Uncut, Sparsest Cut and Small Set Expansion problems. We also\nshow how to almost recover the optimal solution if the instance satisfies an\nadditional expanding condition. Our algorithms work in a wider range of\nparameters than most algorithms for previously studied random and semi-random\nmodels.\n  Additionally, we study a new planted algebraic expander model and develop\nconstant factor bi-criteria approximation algorithms for graph partitioning\nproblems in this model.\n", "Comment: To appear at the 44th ACM Symposium on Theory of Computing (STOC\n  2012)"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - computational complexity"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.2234"}}, {"publisher": {"name": ""}, "description": "  We propose a method called Fast and Realistic Attacker Modeling and\nEvaluation (FRAME) that can reduce pessimism in static noise analysis by\nexploiting temporal logical correlation of attackers and using novel techniques\ntermed envelopes and $\\sigma$ functions. Unlike conventional pruning-based\napproaches, FRAME efficiently considers all relevant attackers, thereby\nproducing more realistic results. FRAME was tested with complex industrial\ndesign and successfully reduced the pessimism of conventional techniques by\n30.4% on average, with little computational overhead.\n", "contributors": [{"name": "Yoon, Sungroh", "sameAs": [], "familyName": "Yoon", "additionalName": "", "givenName": "Sungroh", "email": ""}, {"name": "Oh, Nahmsuk", "sameAs": [], "familyName": "Oh", "additionalName": "", "givenName": "Nahmsuk", "email": ""}, {"name": "Tehrani, Peivand", "sameAs": [], "familyName": "Tehrani", "additionalName": "", "givenName": "Peivand", "email": ""}, {"name": "Chung, Eui-Young", "sameAs": [], "familyName": "Chung", "additionalName": "", "givenName": "Eui-Young", "email": ""}, {"name": "De Micheli, Giovanni", "sameAs": [], "familyName": "De Micheli", "additionalName": "", "givenName": "Giovanni", "email": ""}], "title": "FRAME: Fast and Realistic Attacker Modeling and Evaluation for Temporal\n  Logical Correlation in Static Noise", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.02236", "oai:arXiv.org:1502.02236"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We propose a method called Fast and Realistic Attacker Modeling and\nEvaluation (FRAME) that can reduce pessimism in static noise analysis by\nexploiting temporal logical correlation of attackers and using novel techniques\ntermed envelopes and $\\sigma$ functions. Unlike conventional pruning-based\napproaches, FRAME efficiently considers all relevant attackers, thereby\nproducing more realistic results. FRAME was tested with complex industrial\ndesign and successfully reduced the pessimism of conventional techniques by\n30.4% on average, with little computational overhead.\n"}}], "languages": [null], "subjects": ["computer science - other computer science", "b.7.2"], "providerUpdatedDateTime": "2015-02-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.02236"}}, {"publisher": {"name": ""}, "description": "  The structure of the network underlying many complex systems, whether\nartificial or natural, plays a significant role in how these systems operate.\nAs a result, much emphasis has been placed on accurately describing networks\nusing network theoretic metrics. When it comes to generating networks with\nsimilar properties, however, the set of available techniques and properties\nthat can be controlled for remains limited. Further, whilst it is becoming\nclear that some of the metrics currently used to control the generation of such\nnetworks are not very prescriptive so that networks could potentially exhibit\nvery different higher-order structure within those constraints, network\ngenerating algorithms typically produce fairly contrived networks and lack\nmechanisms by which to systematically explore the space of network solutions.\nIn this paper, we explore the potential of a multi-objective novelty-biased GA\nto provide a viable alternative to these algorithms. We believe our results\nprovide the first proof of principle that (i) it is possible to use GAs to\ngenerate graphs satisfying set levels of key classical graph theoretic\nproperties and (ii) it is possible to generate diverse solutions within these\nconstraints. The paper is only a preliminary step, however, and we identify key\navenues for further development.\n", "contributors": [{"name": "Overbury, Peter", "sameAs": [], "familyName": "Overbury", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Berthouze, Luc", "sameAs": [], "familyName": "Berthouze", "additionalName": "", "givenName": "Luc", "email": ""}], "title": "Using novelty-biased GA to sample diversity in graphs satisfying\n  constraints", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06342", "oai:arXiv.org:1503.06342"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The structure of the network underlying many complex systems, whether\nartificial or natural, plays a significant role in how these systems operate.\nAs a result, much emphasis has been placed on accurately describing networks\nusing network theoretic metrics. When it comes to generating networks with\nsimilar properties, however, the set of available techniques and properties\nthat can be controlled for remains limited. Further, whilst it is becoming\nclear that some of the metrics currently used to control the generation of such\nnetworks are not very prescriptive so that networks could potentially exhibit\nvery different higher-order structure within those constraints, network\ngenerating algorithms typically produce fairly contrived networks and lack\nmechanisms by which to systematically explore the space of network solutions.\nIn this paper, we explore the potential of a multi-objective novelty-biased GA\nto provide a viable alternative to these algorithms. We believe our results\nprovide the first proof of principle that (i) it is possible to use GAs to\ngenerate graphs satisfying set levels of key classical graph theoretic\nproperties and (ii) it is possible to generate diverse solutions within these\nconstraints. The paper is only a preliminary step, however, and we identify key\navenues for further development.\n", "Comment: Extended version of a short paper accepted for publication in\n  Proceedings of Genetic and Evolutionary Computation Conference (GECCO'15)"]}}], "languages": [null], "subjects": ["g.2.2", "05c85", "90b15", "computer science - social and information networks", "physics - physics and society", "68r10", "computer science - neural and evolutionary computing", "mathematics - combinatorics", "90c35"], "providerUpdatedDateTime": "2015-03-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06342"}}, {"publisher": {"name": ""}, "description": "  Quantum computation, in particular Grover's algorithm, has aroused a great\ndeal of interest since it allows for a quadratic speedup to be obtained in\nsearch procedures. Classical search procedures for an $N$ element database\nrequire at most $O(N)$ time complexity. Grover's algorithm is able to find a\nsolution with high probability in $O(\\sqrt{N})$ time through an amplitude\namplification scheme. In this work we draw elements from both classical and\nquantum computation to develop an alternative search proposal based on quantum\nentanglement detection schemes. In 2002, Horodecki and Ekert proposed an\nefficient method for direct detection of quantum entanglement. Our proposition\nto quantum search combines quantum entanglement detection alongside\nentanglement inducing operators. Grover's quantum search relies on measuring a\nquantum superposition after having applied a unitary evolution. We deviate from\nthe standard method by focusing on fine-tuning a unitary operator in order to\ninfer the solution with certainty. Our proposal sacrifices space for speed and\ndepends on the mathematical properties of linear positive maps $\\Lambda$ which\nhave not been operationally characterized. Whether such a $\\Lambda$ can be\neasily determined remains an open question.\n", "contributors": [{"name": "Tarrataca, Lu\u00eds", "sameAs": [], "familyName": "Tarrataca", "additionalName": "", "givenName": "Lu\u00eds", "email": ""}, {"name": "Wichert, Andreas", "sameAs": [], "familyName": "Wichert", "additionalName": "", "givenName": "Andreas", "email": ""}], "title": "Can Quantum Entanglement Detection Schemes Improve Search?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01959", "Quantum Information Processing, 2012, 11:1, 55-66", "doi:10.1007/s11128-011-0231-4", "oai:arXiv.org:1502.01959"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": "  Quantum computation, in particular Grover's algorithm, has aroused a great\ndeal of interest since it allows for a quadratic speedup to be obtained in\nsearch procedures. Classical search procedures for an $N$ element database\nrequire at most $O(N)$ time complexity. Grover's algorithm is able to find a\nsolution with high probability in $O(\\sqrt{N})$ time through an amplitude\namplification scheme. In this work we draw elements from both classical and\nquantum computation to develop an alternative search proposal based on quantum\nentanglement detection schemes. In 2002, Horodecki and Ekert proposed an\nefficient method for direct detection of quantum entanglement. Our proposition\nto quantum search combines quantum entanglement detection alongside\nentanglement inducing operators. Grover's quantum search relies on measuring a\nquantum superposition after having applied a unitary evolution. We deviate from\nthe standard method by focusing on fine-tuning a unitary operator in order to\ninfer the solution with certainty. Our proposal sacrifices space for speed and\ndepends on the mathematical properties of linear positive maps $\\Lambda$ which\nhave not been operationally characterized. Whether such a $\\Lambda$ can be\neasily determined remains an open question.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "quantum physics"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01959"}}, {"publisher": {"name": ""}, "description": "  A pure geometric description of the Kobayashi balls of C-convex domains is\ngiven in terms of the so-called minimal basis.\n", "contributors": [{"name": "Nikolov, Nikolai", "sameAs": [], "familyName": "Nikolov", "additionalName": "", "givenName": "Nikolai", "email": ""}, {"name": "Trybula, Maria", "sameAs": [], "familyName": "Trybula", "additionalName": "", "givenName": "Maria", "email": ""}], "title": "The Kobayashi balls of C-convex domains", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-04-25", "2014-05-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1404.6481", "doi:10.1007/s00605-015-0746-3", "oai:arXiv.org:1404.6481"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  A pure geometric description of the Kobayashi balls of C-convex domains is\ngiven in terms of the so-called minimal basis.\n", "Comment: v2: Proposition 3 (iii) is improved - the Lempert function is\n  replaced by the Kobayashi metric"]}}], "languages": [null], "subjects": ["32f45", "32f17", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1404.6481"}}, {"publisher": {"name": ""}, "description": "  We analyze tensors in the tensor product of three m-dimensional vector spaces\nsatisfying Strassen's equations for border rank m. Results include: two purely\ngeometric characterizations of the Coppersmith-Winograd tensor, a reduction to\nthe study of symmetric tensors under a mild genericity hypothesis, and numerous\nadditional equations and examples. This study is closely connected to the study\nof the variety of m-dimensional abelian subspaces of the space of endomorphisms\nof an m-dimensional vector space, and the subvariety consisting of the Zariski\nclosure of the variety of maximal tori, called the variety of reductions.\n", "contributors": [{"name": "Landsberg, J. M.", "sameAs": [], "familyName": "Landsberg", "additionalName": "M.", "givenName": "J.", "email": ""}, {"name": "Micha\u0142ek, Mateusz", "sameAs": [], "familyName": "Micha\u0142ek", "additionalName": "", "givenName": "Mateusz", "email": ""}], "title": "Abelian Tensors", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03732", "oai:arXiv.org:1504.03732"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We analyze tensors in the tensor product of three m-dimensional vector spaces\nsatisfying Strassen's equations for border rank m. Results include: two purely\ngeometric characterizations of the Coppersmith-Winograd tensor, a reduction to\nthe study of symmetric tensors under a mild genericity hypothesis, and numerous\nadditional equations and examples. This study is closely connected to the study\nof the variety of m-dimensional abelian subspaces of the space of endomorphisms\nof an m-dimensional vector space, and the subvariety consisting of the Zariski\nclosure of the variety of maximal tori, called the variety of reductions.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "15a69", "14n05", "15a21", "68q17", "mathematics - algebraic geometry"], "providerUpdatedDateTime": "2015-04-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03732"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose a new method for detecting unauthorized network\nintrusions, based on a traffic flow model and Cisco NetFlow protocol\napplication. The method developed allows us not only to detect the most common\ntypes of network attack (DDoS and port scanning), but also to make a list of\ntrespassers' IP-addresses. Therefore, this method can be applied in intrusion\ndetection systems, and in those systems which lock these IP-addresses.\n", "contributors": [{"name": "Galtsev, Aleksey A.", "sameAs": [], "familyName": "Galtsev", "additionalName": "A.", "givenName": "Aleksey", "email": ""}, {"name": "Sukhov, Andrei M.", "sameAs": [], "familyName": "Sukhov", "additionalName": "M.", "givenName": "Andrei", "email": ""}], "title": "Network attack detection at flow level", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.1010", "oai:arXiv.org:1104.1010"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we propose a new method for detecting unauthorized network\nintrusions, based on a traffic flow model and Cisco NetFlow protocol\napplication. The method developed allows us not only to detect the most common\ntypes of network attack (DDoS and port scanning), but also to make a list of\ntrespassers' IP-addresses. Therefore, this method can be applied in intrusion\ndetection systems, and in those systems which lock these IP-addresses.\n"}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.1010"}}, {"publisher": {"name": ""}, "description": "  Operational semantics has established itself as a flexible but rigorous means\nto describe the meaning of programming languages. Oftentimes, it is felt\nnecessary to keep a semantics small, for example to facilitate its use for\nmodel checking by avoiding state space explosion. However, omitting many\ndetails in a semantics typically makes results valid for a limited core\nlanguage only, leaving a wide gap towards any real implementation. In this\npaper we present a full-fledged semantics of the concurrent object-oriented\nprogramming language SCOOP (Simple Concurrent Object-Oriented Programming). The\nsemantics has been found detailed enough to guide an implementation of the\nSCOOP compiler and runtime system, and to detect and correct a variety of\nerrors and ambiguities in the original informal specification and prototype\nimplementation. In our formal specification, we use abstract data types with\npreconditions and axioms to describe the state, and introduce a number of\nspecial run-time operations to model the runtime system with our inference\nrules. This approach allows us to make our large formal specification\nmanageable, providing a first step towards reference documents for specifying\nobject-oriented languages based on operational semantics.\n", "contributors": [{"name": "Morandi, Benjamin", "sameAs": [], "familyName": "Morandi", "additionalName": "", "givenName": "Benjamin", "email": ""}, {"name": "Nanz, Sebastian", "sameAs": [], "familyName": "Nanz", "additionalName": "", "givenName": "Sebastian", "email": ""}, {"name": "Meyer, Bertrand", "sameAs": [], "familyName": "Meyer", "additionalName": "", "givenName": "Bertrand", "email": ""}], "title": "A comprehensive operational semantics of the SCOOP programming model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-05", "2012-04-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.1038", "oai:arXiv.org:1101.1038"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Operational semantics has established itself as a flexible but rigorous means\nto describe the meaning of programming languages. Oftentimes, it is felt\nnecessary to keep a semantics small, for example to facilitate its use for\nmodel checking by avoiding state space explosion. However, omitting many\ndetails in a semantics typically makes results valid for a limited core\nlanguage only, leaving a wide gap towards any real implementation. In this\npaper we present a full-fledged semantics of the concurrent object-oriented\nprogramming language SCOOP (Simple Concurrent Object-Oriented Programming). The\nsemantics has been found detailed enough to guide an implementation of the\nSCOOP compiler and runtime system, and to detect and correct a variety of\nerrors and ambiguities in the original informal specification and prototype\nimplementation. In our formal specification, we use abstract data types with\npreconditions and axioms to describe the state, and introduce a number of\nspecial run-time operations to model the runtime system with our inference\nrules. This approach allows us to make our large formal specification\nmanageable, providing a first step towards reference documents for specifying\nobject-oriented languages based on operational semantics.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "computer science - programming languages", "f.3.2", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.1038"}}, {"publisher": {"name": ""}, "description": "  The outage probability performance of a dual-hop amplify-and-forward\nselective relaying system with global relay selection is analyzed for\nNakagami-$m$ fading channels in the presence of multiple interferers at both\nthe relays and the destination. Two different cases are considered. In the\nfirst case, the interferers are assumed to have random number and locations.\nOutage probability using the generalized Gamma approximation (GGA) in the form\nof one-dimensional integral is derived. In the second case, the interferers are\nassumed to have fixed number and locations. Exact outage probability in the\nform of one-dimensional integral is derived. For both cases, closed-form\nexpressions of lower bounds and asymptotic expressions for high\nsignal-to-interference-plus-noise ratio are also provided. Simplified\nclosed-form expressions of outage probability for special cases (e.g., dominant\ninterferences, i.i.d. interferers, Rayleigh distributed signals) are studied.\nNumerical results are presented to show the accuracy of our analysis by\nexamining the effects of the number and locations of interferers on the outage\nperformances of both AF systems with random and fixed interferers.\n", "contributors": [{"name": "Wang, Kezhi", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Kezhi", "email": ""}, {"name": "Chen, Yunfei", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Yunfei", "email": ""}, {"name": "Di Renzo, Marco", "sameAs": [], "familyName": "Di Renzo", "additionalName": "", "givenName": "Marco", "email": ""}], "title": "Outage Probability of Dual-Hop Selective AF With Randomly Distributed\n  and Fixed Interferers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1074", "oai:arXiv.org:1410.1074"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The outage probability performance of a dual-hop amplify-and-forward\nselective relaying system with global relay selection is analyzed for\nNakagami-$m$ fading channels in the presence of multiple interferers at both\nthe relays and the destination. Two different cases are considered. In the\nfirst case, the interferers are assumed to have random number and locations.\nOutage probability using the generalized Gamma approximation (GGA) in the form\nof one-dimensional integral is derived. In the second case, the interferers are\nassumed to have fixed number and locations. Exact outage probability in the\nform of one-dimensional integral is derived. For both cases, closed-form\nexpressions of lower bounds and asymptotic expressions for high\nsignal-to-interference-plus-noise ratio are also provided. Simplified\nclosed-form expressions of outage probability for special cases (e.g., dominant\ninterferences, i.i.d. interferers, Rayleigh distributed signals) are studied.\nNumerical results are presented to show the accuracy of our analysis by\nexamining the effects of the number and locations of interferers on the outage\nperformances of both AF systems with random and fixed interferers.\n", "Comment: 35 pages, 11 figures, accepted with minor revisions for publication\n  as a regular paper in the IEEE Transactions on Vehicular Technology on\n  21/09/2014"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1074"}}, {"publisher": {"name": "BMJ Publishing Group"}, "description": "", "contributors": [{"name": "Mo, Qian", "sameAs": [], "familyName": "Mo", "additionalName": "", "givenName": "Qian", "email": ""}, {"name": "Wang, Yang", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yang", "email": ""}, {"name": "Ye, Yongming", "sameAs": [], "familyName": "Ye", "additionalName": "", "givenName": "Yongming", "email": ""}, {"name": "Yu, Jinna", "sameAs": [], "familyName": "Yu", "additionalName": "", "givenName": "Jinna", "email": ""}, {"name": "Liu, Zhishun", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Zhishun", "email": ""}], "title": "Acupuncture for adults with overactive bladder: a systematic review protocol", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["complementary medicine"], "providerUpdatedDateTime": "2015-01-16T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4289716"}}, {"publisher": {"name": ""}, "description": "  We examine the characteristic features of reversible and quantum computations\nin the presence of supplementary external information, known as advice. In\nparticular, we present a simple, algebraic characterization of languages\nrecognized by one-way reversible finite automata augmented with deterministic\nadvice. With a further elaborate argument, we prove a similar but slightly\nweaker result for bounded-error one-way quantum finite automata with advice.\nImmediate applications of those properties lead to containments and separations\namong various language families when they are assisted by appropriately chosen\nadvice. We further demonstrate the power and limitation of randomized advice\nand quantum advice when they are given to one-way quantum finite automata.\n", "contributors": [{"name": "Yamakami, Tomoyuki", "sameAs": [], "familyName": "Yamakami", "additionalName": "", "givenName": "Tomoyuki", "email": ""}], "title": "One-Way Reversible and Quantum Finite Automata with Advice", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-08-30", "2014-10-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1208.6092", "oai:arXiv.org:1208.6092"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:quant-ph"]}}, {"name": "description", "properties": {"description": ["  We examine the characteristic features of reversible and quantum computations\nin the presence of supplementary external information, known as advice. In\nparticular, we present a simple, algebraic characterization of languages\nrecognized by one-way reversible finite automata augmented with deterministic\nadvice. With a further elaborate argument, we prove a similar but slightly\nweaker result for bounded-error one-way quantum finite automata with advice.\nImmediate applications of those properties lead to containments and separations\namong various language families when they are assisted by appropriately chosen\nadvice. We further demonstrate the power and limitation of randomized advice\nand quantum advice when they are given to one-way quantum finite automata.\n", "Comment: A4, 10pt, 1 figure, 31 pages. This is a complete version of an\n  extended abstract appeared in the Proceedings of the 6th International\n  Conference on Language and Automata Theory and Applications (LATA 2012),\n  March 5-9, 2012, A Coruna, Spain, Lecture Notes in Computer Science,\n  Springer-Verlag, Vol.7183, pp.526-537, 2012"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "quantum physics", "computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2014-10-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1208.6092"}}, {"publisher": {"name": ""}, "description": "  We study convergence properties of pseudo-marginal Markov chain Monte Carlo\nalgorithms (Andrieu and Roberts [Ann. Statist. 37 (2009) 697-725]). We find\nthat the asymptotic variance of the pseudo-marginal algorithm is always at\nleast as large as that of the marginal algorithm. We show that if the marginal\nchain admits a (right) spectral gap and the weights (normalised estimates of\nthe target density) are uniformly bounded, then the pseudo-marginal chain has a\nspectral gap. In many cases, a similar result holds for the absolute spectral\ngap, which is equivalent to geometric ergodicity. We consider also unbounded\nweight distributions and recover polynomial convergence rates in more specific\ncases, when the marginal algorithm is uniformly ergodic or an independent\nMetropolis-Hastings or a random-walk Metropolis targeting a super-exponential\ndensity with regular contours. Our results on geometric and polynomial\nconvergence rates imply central limit theorems. We also prove that under\ngeneral conditions, the asymptotic variance of the pseudo-marginal algorithm\nconverges to the asymptotic variance of the marginal algorithm if the accuracy\nof the estimators is increased.\n", "contributors": [{"name": "Andrieu, Christophe", "sameAs": [], "familyName": "Andrieu", "additionalName": "", "givenName": "Christophe", "email": ""}, {"name": "Vihola, Matti", "sameAs": [], "familyName": "Vihola", "additionalName": "", "givenName": "Matti", "email": ""}], "title": "Convergence properties of pseudo-marginal Markov chain Monte Carlo\n  algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-10-04", "2015-03-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1210.1484", "Annals of Applied Probability 2015, Vol. 25, No. 2, 1030-1077", "doi:10.1214/14-AAP1022", "oai:arXiv.org:1210.1484"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "stat"]}}, {"name": "description", "properties": {"description": ["  We study convergence properties of pseudo-marginal Markov chain Monte Carlo\nalgorithms (Andrieu and Roberts [Ann. Statist. 37 (2009) 697-725]). We find\nthat the asymptotic variance of the pseudo-marginal algorithm is always at\nleast as large as that of the marginal algorithm. We show that if the marginal\nchain admits a (right) spectral gap and the weights (normalised estimates of\nthe target density) are uniformly bounded, then the pseudo-marginal chain has a\nspectral gap. In many cases, a similar result holds for the absolute spectral\ngap, which is equivalent to geometric ergodicity. We consider also unbounded\nweight distributions and recover polynomial convergence rates in more specific\ncases, when the marginal algorithm is uniformly ergodic or an independent\nMetropolis-Hastings or a random-walk Metropolis targeting a super-exponential\ndensity with regular contours. Our results on geometric and polynomial\nconvergence rates imply central limit theorems. We also prove that under\ngeneral conditions, the asymptotic variance of the pseudo-marginal algorithm\nconverges to the asymptotic variance of the marginal algorithm if the accuracy\nof the estimators is increased.\n", "Comment: Published at http://dx.doi.org/10.1214/14-AAP1022 in the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)"]}}], "languages": [null], "subjects": ["statistics - computation", "mathematics - probability"], "providerUpdatedDateTime": "2015-03-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1210.1484"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "The American daytime serial drama is among the oldest television genres and remains a vital part of the television lineup for ABC and CBS as what this thesis calls an immersive story world. However, many within the television industry are now predicting that the genre will fade into obscurity after two decades of declining ratings. This study outlines how the soap opera industry is and could be further adapting to the technological and social changes of a convergence culture to maintain and revitalize the genre's relevance for viewers and advertisers alike. CBS/Procter and Gamble Productions/TeleVest's As the World Turns will serve as a case study for these changes. This project examines how the existing fan base plays an active role in gaining and maintaining new fans by researching historical and contemporary examples of social relationships that fans form with other fans and the show itself. In addition to looking at how these fan communities operate, this thesis focuses on how soap operas have adapted and might adapt to alternate revenue models such as product placement, capitalize on their vast content archives, and tell stories through multiple media formats. The study concludes that soap operas should be managed as brands and not ephemeral television content because of their permanence in the television landscape, that fans outside the target advertising demographic should be empowered as proselytizers for the show, and that a transgenerational storytelling approach best utilizes the power of the genre to tell its stories.", "contributors": [{"name": "Ford, Samuel Earl", "sameAs": [], "familyName": "Ford", "additionalName": "Earl", "givenName": "Samuel", "email": ""}, {"name": "Massachusetts Institute of Technology. Dept. of Comparative Media Studies.", "sameAs": [], "familyName": "Studies.", "additionalName": "Institute of Technology. Dept. of Comparative Media", "givenName": "Massachusetts", "email": ""}, {"name": "William Charles Uricchio.", "sameAs": [], "familyName": "Uricchio.", "additionalName": "Charles", "givenName": "William", "email": ""}], "title": "As the world turns in a convergence culture", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "176 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/39223", "166228334", "oai:dspace.mit.edu:1721.1/39223"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2007-10-19T21:05:08Z", "2007-10-19T21:05:08Z", "2007", "2007"]}}, {"name": "description", "properties": {"description": ["The American daytime serial drama is among the oldest television genres and remains a vital part of the television lineup for ABC and CBS as what this thesis calls an immersive story world. However, many within the television industry are now predicting that the genre will fade into obscurity after two decades of declining ratings. This study outlines how the soap opera industry is and could be further adapting to the technological and social changes of a convergence culture to maintain and revitalize the genre's relevance for viewers and advertisers alike. CBS/Procter and Gamble Productions/TeleVest's As the World Turns will serve as a case study for these changes. This project examines how the existing fan base plays an active role in gaining and maintaining new fans by researching historical and contemporary examples of social relationships that fans form with other fans and the show itself. In addition to looking at how these fan communities operate, this thesis focuses on how soap operas have adapted and might adapt to alternate revenue models such as product placement, capitalize on their vast content archives, and tell stories through multiple media formats. The study concludes that soap operas should be managed as brands and not ephemeral television content because of their permanence in the television landscape, that fans outside the target advertising demographic should be empowered as proselytizers for the show, and that a transgenerational storytelling approach best utilizes the power of the genre to tell its stories.", "by Samuel Earl Ford.", "Thesis (S.M.)--Massachusetts Institute of Technology, Dept. of Comparative Media Studies, 2007.", "This electronic version was submitted by the student author.  The certified thesis is available in the Institute Archives and Special Collections.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39100", "hdl_1721.1_39097"]}}], "languages": [null], "subjects": ["comparative media studies.", "as the world turns (television program)"], "providerUpdatedDateTime": "2015-04-27T14:44:36", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/39223"}}, {"publisher": {"name": ""}, "description": "  This paper presents a probabilistic omnidirectional millimeter-wave path loss\nmodel based on real-world 28 GHz and 73 GHz measurements collected in New York\nCity. The probabilistic path loss approach uses a free space line-of-sight\npropagation model, and for non-line-of-sight conditions uses either a close-in\nfree space reference distance path loss model or a floating-intercept path loss\nmodel. The probabilistic model employs a weighting function that specifies the\nline-of-sight probability for a given transmitter-receiver separation distance.\nResults show that the probabilistic path loss model offers virtually identical\nresults whether one uses a non-line-of-sight close-in free space reference\ndistance path loss model, with a reference distance of 1 meter, or a\nfloating-intercept path loss model. This letter also shows that site-specific\nenvironmental information may be used to yield the probabilistic weighting\nfunction for choosing between line-of-sight and non-line-of-sight conditions.\n", "contributors": [{"name": "Samimi, Mathew K.", "sameAs": [], "familyName": "Samimi", "additionalName": "K.", "givenName": "Mathew", "email": ""}, {"name": "Rappaport, Theodore S.", "sameAs": [], "familyName": "Rappaport", "additionalName": "S.", "givenName": "Theodore", "email": ""}, {"name": "MacCartney Jr, George R.", "sameAs": [], "familyName": "MacCartney", "additionalName": "R.", "givenName": "George", "email": ""}], "title": "Probabilistic Omnidirectional Path Loss Models for Millimeter-Wave\n  Outdoor Communications", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-25", "2015-03-31"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.07612", "oai:arXiv.org:1503.07612"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper presents a probabilistic omnidirectional millimeter-wave path loss\nmodel based on real-world 28 GHz and 73 GHz measurements collected in New York\nCity. The probabilistic path loss approach uses a free space line-of-sight\npropagation model, and for non-line-of-sight conditions uses either a close-in\nfree space reference distance path loss model or a floating-intercept path loss\nmodel. The probabilistic model employs a weighting function that specifies the\nline-of-sight probability for a given transmitter-receiver separation distance.\nResults show that the probabilistic path loss model offers virtually identical\nresults whether one uses a non-line-of-sight close-in free space reference\ndistance path loss model, with a reference distance of 1 meter, or a\nfloating-intercept path loss model. This letter also shows that site-specific\nenvironmental information may be used to yield the probabilistic weighting\nfunction for choosing between line-of-sight and non-line-of-sight conditions.\n", "Comment: 4 pages, 4 figures, IEEE Wireless Communications Letters (March 2015)"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.07612"}}, {"publisher": {"name": ""}, "description": "  The advance in RF energy transfer and harvesting technique over the past\ndecade has enabled wireless energy replenishment for electronic devices, which\nis deemed as a promising alternative to address the energy bottleneck of\nconventional battery-powered devices. In this paper, by using a stochastic\ngeometry approach, we aim to analyze the performance of an RF-powered wireless\nsensor in a downlink simultaneous wireless information and power transfer\n(SWIPT) system with ambient RF transmitters. Specifically, we consider the\npoint-to-point downlink SWIPT transmission from an access point to a wireless\nsensor in a network, where ambient RF transmitters are distributed as a Ginibre\n?$\\alpha$-determinantal point process (DPP), which becomes the Poisson point\nprocess when $\\alpha$? approaches zero. In the considered network, we focus on\nanalyzing the performance of a sensor equipped with the power-splitting\narchitecture. Under this architecture, we characterize the expected RF energy\nharvesting rate of the sensor. Moreover, we derive the upper bound of both\npower and transmission outage probabilities. Numerical results show that our\nupper bounds are accurate for different value of ?$\\alpha$.\n", "contributors": [{"name": "Lu, Xiao", "sameAs": [], "familyName": "Lu", "additionalName": "", "givenName": "Xiao", "email": ""}, {"name": "Flint, Ian", "sameAs": [], "familyName": "Flint", "additionalName": "", "givenName": "Ian", "email": ""}, {"name": "Niyato, Dusit", "sameAs": [], "familyName": "Niyato", "additionalName": "", "givenName": "Dusit", "email": ""}, {"name": "Privault, Nicolas", "sameAs": [], "familyName": "Privault", "additionalName": "", "givenName": "Nicolas", "email": ""}, {"name": "Wang, Ping", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Ping", "email": ""}], "title": "Performance Analysis of Simultaneous Wireless Information and Power\n  Transfer with Ambient RF Energy Harvesting", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00683", "oai:arXiv.org:1501.00683"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The advance in RF energy transfer and harvesting technique over the past\ndecade has enabled wireless energy replenishment for electronic devices, which\nis deemed as a promising alternative to address the energy bottleneck of\nconventional battery-powered devices. In this paper, by using a stochastic\ngeometry approach, we aim to analyze the performance of an RF-powered wireless\nsensor in a downlink simultaneous wireless information and power transfer\n(SWIPT) system with ambient RF transmitters. Specifically, we consider the\npoint-to-point downlink SWIPT transmission from an access point to a wireless\nsensor in a network, where ambient RF transmitters are distributed as a Ginibre\n?$\\alpha$-determinantal point process (DPP), which becomes the Poisson point\nprocess when $\\alpha$? approaches zero. In the considered network, we focus on\nanalyzing the performance of a sensor equipped with the power-splitting\narchitecture. Under this architecture, we characterize the expected RF energy\nharvesting rate of the sensor. Moreover, we derive the upper bound of both\npower and transmission outage probabilities. Numerical results show that our\nupper bounds are accurate for different value of ?$\\alpha$.\n", "Comment: IEEE Wireless Communications and Networking Conference"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00683"}}, {"publisher": {"name": ""}, "description": "  In this paper, we present a framework for resource allocations for multicast\ndevice-to-device (D2D) communications underlaying a cellular network. The\nobjective is to maximize the sum throughput of active cellular users (CUs) and\nfeasible D2D groups in a cell, while meeting a certain\nsignal-to-interferenceplus- noise ratio (SINR) constraint for both the CUs and\nD2D groups. We formulate the problem of power and channel allocation as a mixed\ninteger nonlinear programming (MINLP) problem where one D2D group can reuse the\nchannels of multiple CUs and the channel of each CU can be reused by multiple\nD2D groups. Distinct from existing approaches in the literature, our\nformulation and solution methods provide an effective and flexible means to\nutilize radio resources in cellular networks and share them with multicast\ngroups without causing harmful interference to each other. A variant of the\ngeneralized bender decomposition (GBD) is applied to optimally solve the MINLP\nproblem. A greedy algorithm and a low-complexity heuristic solution are then\ndevised. The performance of all schemes is evaluated through extensive\nsimulations. Numerical results demonstrate that the proposed greedy algorithm\ncan achieve closeto- optimal performance, and the heuristic algorithm provides\ngood performance, though inferior than that of the greedy, with much lower\ncomplexity.\n", "contributors": [{"name": "Meshgi, Hadi", "sameAs": [], "familyName": "Meshgi", "additionalName": "", "givenName": "Hadi", "email": ""}, {"name": "Zhao, Dongmei", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Dongmei", "email": ""}, {"name": "Zheng, Rong", "sameAs": [], "familyName": "Zheng", "additionalName": "", "givenName": "Rong", "email": ""}], "title": "Optimal Resource Allocation in Multicast Device-to-Device Communications\n  Underlaying LTE Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-12"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03576", "oai:arXiv.org:1503.03576"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we present a framework for resource allocations for multicast\ndevice-to-device (D2D) communications underlaying a cellular network. The\nobjective is to maximize the sum throughput of active cellular users (CUs) and\nfeasible D2D groups in a cell, while meeting a certain\nsignal-to-interferenceplus- noise ratio (SINR) constraint for both the CUs and\nD2D groups. We formulate the problem of power and channel allocation as a mixed\ninteger nonlinear programming (MINLP) problem where one D2D group can reuse the\nchannels of multiple CUs and the channel of each CU can be reused by multiple\nD2D groups. Distinct from existing approaches in the literature, our\nformulation and solution methods provide an effective and flexible means to\nutilize radio resources in cellular networks and share them with multicast\ngroups without causing harmful interference to each other. A variant of the\ngeneralized bender decomposition (GBD) is applied to optimally solve the MINLP\nproblem. A greedy algorithm and a low-complexity heuristic solution are then\ndevised. The performance of all schemes is evaluated through extensive\nsimulations. Numerical results demonstrate that the proposed greedy algorithm\ncan achieve closeto- optimal performance, and the heuristic algorithm provides\ngood performance, though inferior than that of the greedy, with much lower\ncomplexity.\n", "Comment: 29 pages"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03576"}}, {"publisher": {"name": ""}, "description": "  We propose a new coding scheme for the discrete memoryless two-user\nmulti-access channel (MAC) with rate-limited feedback. Our scheme combines\nideas from the Venkataramanan-Pradhan scheme for perfect feedback with ideas\nfrom the Shaviv-Steinberg scheme for rate-limited feedback.\n  Our achievable region includes the Shaviv-Steinberg achievable region and\nthis inclusion can be strict. For general MACs and for sufficiently large\nfeedback rates, our scheme outperforms the Shaviv-Steinberg scheme as it\nachieves the same rate region as the Venkataramanan-Pradhan scheme for perfect\nfeedback (which cannot be achieved by the Shaviv-Steinberg scheme).\nFurthermore, we numerically evaluate our achievable region with a specific\n(Gaussian) choice of random variables for the memoryless two-user Gaussian MAC.\nOur simulation results show that for some parameters of the Gaussian MAC and\nthe feedback rate, our scheme achieves a strictly larger sum-rate than the\nShaviv-Steinberg scheme.\n", "contributors": [{"name": "Amor, Selma Belhadj", "sameAs": [], "familyName": "Amor", "additionalName": "Belhadj", "givenName": "Selma", "email": ""}], "title": "A New Coding Scheme for Discrete Memoryless MACs with Common\n  Rate-Limited Feedback", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03266", "oai:arXiv.org:1503.03266"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We propose a new coding scheme for the discrete memoryless two-user\nmulti-access channel (MAC) with rate-limited feedback. Our scheme combines\nideas from the Venkataramanan-Pradhan scheme for perfect feedback with ideas\nfrom the Shaviv-Steinberg scheme for rate-limited feedback.\n  Our achievable region includes the Shaviv-Steinberg achievable region and\nthis inclusion can be strict. For general MACs and for sufficiently large\nfeedback rates, our scheme outperforms the Shaviv-Steinberg scheme as it\nachieves the same rate region as the Venkataramanan-Pradhan scheme for perfect\nfeedback (which cannot be achieved by the Shaviv-Steinberg scheme).\nFurthermore, we numerically evaluate our achievable region with a specific\n(Gaussian) choice of random variables for the memoryless two-user Gaussian MAC.\nOur simulation results show that for some parameters of the Gaussian MAC and\nthe feedback rate, our scheme achieves a strictly larger sum-rate than the\nShaviv-Steinberg scheme.\n", "Comment: 5 pages, 1 figure, submitted to the European Conference on Networks\n  and Communications 2015 (EuCNC'2015), Paris, France"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03266"}}, {"publisher": {"name": ""}, "description": "  In this paper, we present two symbiotic optimizations to optimize recursive\ntask parallel (RTP) programs by reducing the task creation and termination\noverheads. Our first optimization Aggressive Finish-Elimination (AFE) helps\nreduce the redundant join operations to a large extent. The second optimization\nDynamic Load-Balanced loop Chunking (DLBC) extends the prior work on loop\nchunking to decide on the number of parallel tasks based on the number of\navailable worker threads, at runtime. Further, we discuss the impact of\nexceptions on our optimizations and extend them to handle RTP programs that may\nthrow exceptions. We implemented DCAFE (= DLBC+AFE) in the X10v2.3 compiler and\ntested it over a set of benchmark kernels on two different hardwares (a 16-core\nIntel system and a 64-core AMD system). With respect to the base X10 compiler\nextended with loop-chunking of Nandivada et al [Nandivada et\nal.(2013)Nandivada, Shirako, Zhao, and Sarkar](LC), DCAFE achieved a geometric\nmean speed up of 5.75x and 4.16x on the Intel and AMD system, respectively. We\nalso present an evaluation with respect to the energy consumption on the Intel\nsystem and show that on average, compared to the LC versions, the DCAFE\nversions consume 71.2% less energy.\n", "contributors": [{"name": "Gupta, Suyash", "sameAs": [], "familyName": "Gupta", "additionalName": "", "givenName": "Suyash", "email": ""}, {"name": "Shrivastava, Rahul", "sameAs": [], "familyName": "Shrivastava", "additionalName": "", "givenName": "Rahul", "email": ""}, {"name": "Nandivada, V. Krishna", "sameAs": [], "familyName": "Nandivada", "additionalName": "Krishna", "givenName": "V.", "email": ""}], "title": "DCAFE: Dynamic load-balanced loop Chunking & Aggressive Finish\n  Elimination for Recursive Task Parallel Programs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.06086", "oai:arXiv.org:1502.06086"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we present two symbiotic optimizations to optimize recursive\ntask parallel (RTP) programs by reducing the task creation and termination\noverheads. Our first optimization Aggressive Finish-Elimination (AFE) helps\nreduce the redundant join operations to a large extent. The second optimization\nDynamic Load-Balanced loop Chunking (DLBC) extends the prior work on loop\nchunking to decide on the number of parallel tasks based on the number of\navailable worker threads, at runtime. Further, we discuss the impact of\nexceptions on our optimizations and extend them to handle RTP programs that may\nthrow exceptions. We implemented DCAFE (= DLBC+AFE) in the X10v2.3 compiler and\ntested it over a set of benchmark kernels on two different hardwares (a 16-core\nIntel system and a 64-core AMD system). With respect to the base X10 compiler\nextended with loop-chunking of Nandivada et al [Nandivada et\nal.(2013)Nandivada, Shirako, Zhao, and Sarkar](LC), DCAFE achieved a geometric\nmean speed up of 5.75x and 4.16x on the Intel and AMD system, respectively. We\nalso present an evaluation with respect to the energy consumption on the Intel\nsystem and show that on average, compared to the LC versions, the DCAFE\nversions consume 71.2% less energy.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.06086"}}, {"publisher": {"name": ""}, "description": "  We assume a full-duplex (FD) cooperative network subject to hostile attacks\nand undergoing composite fading channels. We focus on two scenarios:\n\\textit{a)} the transmitter has full CSI, for which we derive closed-form\nexpressions for the \\textit{average secrecy rate}; and \\textit{b)} the\ntransmitter only knows the CSI of the legitimate nodes, for which we obtain\nclosed-form expressions for the \\textit{secrecy outage probability}. We show\nthat secure FD relaying is feasible, even under strong self-interference and in\nthe presence of sophisticated multiple antenna eavesdropper.\n", "contributors": [{"name": "Alves, Hirley", "sameAs": [], "familyName": "Alves", "additionalName": "", "givenName": "Hirley", "email": ""}, {"name": "Brante, Glauber", "sameAs": [], "familyName": "Brante", "additionalName": "", "givenName": "Glauber", "email": ""}, {"name": "Souza, Richard D.", "sameAs": [], "familyName": "Souza", "additionalName": "D.", "givenName": "Richard", "email": ""}, {"name": "da Costa, Daniel B.", "sameAs": [], "familyName": "da Costa", "additionalName": "B.", "givenName": "Daniel", "email": ""}, {"name": "Latva-aho, Matti", "sameAs": [], "familyName": "Latva-aho", "additionalName": "", "givenName": "Matti", "email": ""}], "title": "On the Performance of Secure Full-Duplex Relaying under Composite Fading\n  Channels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3856", "oai:arXiv.org:1411.3856"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We assume a full-duplex (FD) cooperative network subject to hostile attacks\nand undergoing composite fading channels. We focus on two scenarios:\n\\textit{a)} the transmitter has full CSI, for which we derive closed-form\nexpressions for the \\textit{average secrecy rate}; and \\textit{b)} the\ntransmitter only knows the CSI of the legitimate nodes, for which we obtain\nclosed-form expressions for the \\textit{secrecy outage probability}. We show\nthat secure FD relaying is feasible, even under strong self-interference and in\nthe presence of sophisticated multiple antenna eavesdropper.\n"}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-11-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3856"}}, {"publisher": {"name": ""}, "description": "  Neural spikes in the brain form stochastic sequences, i.e., belong to the\nclass of pulse noises. This stochasticity is a counterintuitive feature because\nextracting information - such as the commonly supposed neural information of\nmean spike frequency - requires long times for reasonably low error\nprobability. The mystery could be solved by noise-based logic, wherein\nrandomness has an important function and allows large speed enhancements for\nspecial-purpose tasks, and the same mechanism is at work for the brain logic\nversion of this concept.\n", "contributors": [{"name": "Kish, Laszlo B.", "sameAs": [], "familyName": "Kish", "additionalName": "B.", "givenName": "Laszlo", "email": ""}, {"name": "Granqvist, Claes-Goran", "sameAs": [], "familyName": "Granqvist", "additionalName": "", "givenName": "Claes-Goran", "email": ""}, {"name": "Bezrukov, Sergey M.", "sameAs": [], "familyName": "Bezrukov", "additionalName": "M.", "givenName": "Sergey", "email": ""}, {"name": "Horvath, Tamas", "sameAs": [], "familyName": "Horvath", "additionalName": "", "givenName": "Tamas", "email": ""}], "title": "Brain: Biological noise-based logic", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-08-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.4077", "Advances in Cognitive Neurodynamics 2015, pp 319-322", "doi:10.1007/978-94-017-9548-7_45", "oai:arXiv.org:1408.4077"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Neural spikes in the brain form stochastic sequences, i.e., belong to the\nclass of pulse noises. This stochasticity is a counterintuitive feature because\nextracting information - such as the commonly supposed neural information of\nmean spike frequency - requires long times for reasonably low error\nprobability. The mystery could be solved by noise-based logic, wherein\nrandomness has an important function and allows large speed enhancements for\nspecial-purpose tasks, and the same mechanism is at work for the brain logic\nversion of this concept.\n", "Comment: paper in press"]}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - emerging technologies"], "providerUpdatedDateTime": "2015-03-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.4077"}}, {"publisher": {"name": ""}, "description": "  Applying traditional collaborative filtering to digital publishing is\nchallenging because user data is very sparse due to the high volume of\ndocuments relative to the number of users. Content based approaches, on the\nother hand, is attractive because textual content is often very informative. In\nthis paper we describe large-scale content based collaborative filtering for\ndigital publishing. To solve the digital publishing recommender problem we\ncompare two approaches: latent Dirichlet allocation (LDA) and deep belief nets\n(DBN) that both find low-dimensional latent representations for documents.\nEfficient retrieval can be carried out in the latent representation. We work\nboth on public benchmarks and digital media content provided by Issuu, an\nonline publishing platform. This article also comes with a newly developed deep\nbelief nets toolbox for topic modeling tailored towards performance evaluation\nof the DBN model and comparisons to the LDA model.\n", "contributors": [{"name": "Maaloe, Lars", "sameAs": [], "familyName": "Maaloe", "additionalName": "", "givenName": "Lars", "email": ""}, {"name": "Arngren, Morten", "sameAs": [], "familyName": "Arngren", "additionalName": "", "givenName": "Morten", "email": ""}, {"name": "Winther, Ole", "sameAs": [], "familyName": "Winther", "additionalName": "", "givenName": "Ole", "email": ""}], "title": "Deep Belief Nets for Topic Modeling", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04325", "oai:arXiv.org:1501.04325"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Applying traditional collaborative filtering to digital publishing is\nchallenging because user data is very sparse due to the high volume of\ndocuments relative to the number of users. Content based approaches, on the\nother hand, is attractive because textual content is often very informative. In\nthis paper we describe large-scale content based collaborative filtering for\ndigital publishing. To solve the digital publishing recommender problem we\ncompare two approaches: latent Dirichlet allocation (LDA) and deep belief nets\n(DBN) that both find low-dimensional latent representations for documents.\nEfficient retrieval can be carried out in the latent representation. We work\nboth on public benchmarks and digital media content provided by Issuu, an\nonline publishing platform. This article also comes with a newly developed deep\nbelief nets toolbox for topic modeling tailored towards performance evaluation\nof the DBN model and comparisons to the LDA model.\n", "Comment: Accepted to the ICML-2014 Workshop on Knowledge-Powered Deep Learning\n  for Text Mining"]}}], "languages": [null], "subjects": ["computer science - computation and language", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04325"}}, {"publisher": {"name": ""}, "description": "  In this paper we address the following problem in web document and\ninformation retrieval (IR): How can we use long-term context information to\ngain better IR performance? Unlike common IR methods that use bag of words\nrepresentation for queries and documents, we treat them as a sequence of words\nand use long short term memory (LSTM) to capture contextual dependencies. The\nresulting model, the LSTM version of the Deep-Structured Semantic Model (DSSM),\nis a significant extension of the recent Recurrent-DSSM(Palangi et al., 2015)\nwithout the LSTMstructure. Experimental evaluation on an IR task derived from\nthe Bing web search demonstrates the ability of the proposed LSTM-DSSM in\naddressing both lexical mismatch and long-term context modelling issues,\nthereby, significantly outperforming the state of the art method of R-DSSM for\nweb search.\n", "contributors": [{"name": "Palangi, H.", "sameAs": [], "familyName": "Palangi", "additionalName": "", "givenName": "H.", "email": ""}, {"name": "Deng, L.", "sameAs": [], "familyName": "Deng", "additionalName": "", "givenName": "L.", "email": ""}, {"name": "Shen, Y.", "sameAs": [], "familyName": "Shen", "additionalName": "", "givenName": "Y.", "email": ""}, {"name": "Gao, J.", "sameAs": [], "familyName": "Gao", "additionalName": "", "givenName": "J.", "email": ""}, {"name": "He, X.", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "X.", "email": ""}, {"name": "Chen, J.", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "J.", "email": ""}, {"name": "Song, X.", "sameAs": [], "familyName": "Song", "additionalName": "", "givenName": "X.", "email": ""}, {"name": "Ward, R.", "sameAs": [], "familyName": "Ward", "additionalName": "", "givenName": "R.", "email": ""}], "title": "Semantic Modelling with Long-Short-Term Memory for Information Retrieval", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-20", "2014-12-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.6629", "oai:arXiv.org:1412.6629"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper we address the following problem in web document and\ninformation retrieval (IR): How can we use long-term context information to\ngain better IR performance? Unlike common IR methods that use bag of words\nrepresentation for queries and documents, we treat them as a sequence of words\nand use long short term memory (LSTM) to capture contextual dependencies. The\nresulting model, the LSTM version of the Deep-Structured Semantic Model (DSSM),\nis a significant extension of the recent Recurrent-DSSM(Palangi et al., 2015)\nwithout the LSTMstructure. Experimental evaluation on an IR task derived from\nthe Bing web search demonstrates the ability of the proposed LSTM-DSSM in\naddressing both lexical mismatch and long-term context modelling issues,\nthereby, significantly outperforming the state of the art method of R-DSSM for\nweb search.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.6629"}}, {"publisher": {"name": ""}, "description": "  Deep within the networks of distributed systems, one often finds anomalies\nthat affect their efficiency and performance. These anomalies are difficult to\ndetect because the distributed systems may not have sufficient sensors to\nmonitor the flow of traffic within the interconnected nodes of the networks.\nWithout early detection and making corrections, these anomalies may aggravate\nover time and could possibly cause disastrous outcomes in the system in the\nunforeseeable future. Using only coarse-grained information from the two end\npoints of network flows, we propose a network transmission model and a\nlocalization algorithm, to detect the location of anomalies and rank them using\na proposed metric within distributed systems. We evaluate our approach on\npassengers' records of an urbanized city's public transportation system and\ncorrelate our findings with passengers' postings on social media microblogs.\nOur experiments show that the metric derived using our localization algorithm\ngives a better ranking of anomalies as compared to standard deviation measures\nfrom statistical models. Our case studies also demonstrate that transportation\nevents reported in social media microblogs matches the locations of our detect\nanomalies, suggesting that our algorithm performs well in locating the\nanomalies within distributed systems.\n", "contributors": [{"name": "Chua, Freddy Chong Tat", "sameAs": [], "familyName": "Chua", "additionalName": "Chong Tat", "givenName": "Freddy", "email": ""}, {"name": "Lim, Ee-Peng", "sameAs": [], "familyName": "Lim", "additionalName": "", "givenName": "Ee-Peng", "email": ""}, {"name": "Huberman, Bernardo A.", "sameAs": [], "familyName": "Huberman", "additionalName": "A.", "givenName": "Bernardo", "email": ""}], "title": "Detecting Flow Anomalies in Distributed Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-22", "2014-12-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.6064", "oai:arXiv.org:1407.6064"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Deep within the networks of distributed systems, one often finds anomalies\nthat affect their efficiency and performance. These anomalies are difficult to\ndetect because the distributed systems may not have sufficient sensors to\nmonitor the flow of traffic within the interconnected nodes of the networks.\nWithout early detection and making corrections, these anomalies may aggravate\nover time and could possibly cause disastrous outcomes in the system in the\nunforeseeable future. Using only coarse-grained information from the two end\npoints of network flows, we propose a network transmission model and a\nlocalization algorithm, to detect the location of anomalies and rank them using\na proposed metric within distributed systems. We evaluate our approach on\npassengers' records of an urbanized city's public transportation system and\ncorrelate our findings with passengers' postings on social media microblogs.\nOur experiments show that the metric derived using our localization algorithm\ngives a better ranking of anomalies as compared to standard deviation measures\nfrom statistical models. Our case studies also demonstrate that transportation\nevents reported in social media microblogs matches the locations of our detect\nanomalies, suggesting that our algorithm performs well in locating the\nanomalies within distributed systems.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - computers and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.6064"}}, {"publisher": {"name": ""}, "description": "  We study the Bayesian model averaging approach to learning Bayesian network\nstructures (DAGs) from data. We develop new algorithms including the first\nalgorithm that is able to efficiently sample DAGs according to the exact\nstructure posterior. The DAG samples can then be used to construct estimators\nfor the posterior of any feature. We theoretically prove good properties of our\nestimators and empirically show that our estimators considerably outperform the\nestimators from the previous state-of-the-art methods.\n", "contributors": [{"name": "He, Ru", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Ru", "email": ""}, {"name": "Tian, Jin", "sameAs": [], "familyName": "Tian", "additionalName": "", "givenName": "Jin", "email": ""}, {"name": "Wu, Huaiqing", "sameAs": [], "familyName": "Wu", "additionalName": "", "givenName": "Huaiqing", "email": ""}], "title": "Structure Learning in Bayesian Networks of Moderate Size by Efficient\n  Sampling", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-18"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04370", "oai:arXiv.org:1501.04370"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  We study the Bayesian model averaging approach to learning Bayesian network\nstructures (DAGs) from data. We develop new algorithms including the first\nalgorithm that is able to efficiently sample DAGs according to the exact\nstructure posterior. The DAG samples can then be used to construct estimators\nfor the posterior of any feature. We theoretically prove good properties of our\nestimators and empirically show that our estimators considerably outperform the\nestimators from the previous state-of-the-art methods.\n", "Comment: 51 pages"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04370"}}, {"publisher": {"name": ""}, "description": "  The adjoint method, among other sensitivity analysis methods, can fail in\nchaotic dynamical systems. The result from these methods can be too large,\noften by orders of magnitude, when the result is the derivative of a long time\naveraged quantity. This failure is known to be caused by ill-conditioned\ninitial value problems. This paper overcomes this failure by replacing the\ninitial value problem with the well-conditioned \"least squares shadowing (LSS)\nproblem\". The LSS problem is then linearized in our sensitivity analysis\nalgorithm, which computes a derivative that converges to the derivative of the\ninfinitely long time average. We demonstrate our algorithm in several dynamical\nsystems exhibiting both periodic and chaotic oscillations.\n", "contributors": [{"name": "Wang, Qiqi", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Qiqi", "email": ""}, {"name": "Hu, Rui", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Rui", "email": ""}, {"name": "Blonigan, Patrick", "sameAs": [], "familyName": "Blonigan", "additionalName": "", "givenName": "Patrick", "email": ""}], "title": "Least Squares Shadowing sensitivity analysis of chaotic limit cycle\n  oscillations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-04-01", "2014-02-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1204.0159", "doi:10.1016/j.jcp.2014.03.002", "oai:arXiv.org:1204.0159"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:nlin", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The adjoint method, among other sensitivity analysis methods, can fail in\nchaotic dynamical systems. The result from these methods can be too large,\noften by orders of magnitude, when the result is the derivative of a long time\naveraged quantity. This failure is known to be caused by ill-conditioned\ninitial value problems. This paper overcomes this failure by replacing the\ninitial value problem with the well-conditioned \"least squares shadowing (LSS)\nproblem\". The LSS problem is then linearized in our sensitivity analysis\nalgorithm, which computes a derivative that converges to the derivative of the\ninfinitely long time average. We demonstrate our algorithm in several dynamical\nsystems exhibiting both periodic and chaotic oscillations.\n", "Comment: submitted to JCP in revised form"]}}], "languages": [null], "subjects": ["physics - computational physics", "physics - fluid dynamics", "nonlinear sciences - chaotic dynamics"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1204.0159"}}, {"publisher": {"name": ""}, "description": "  Radio-frequency (RF) impairments in the transceiver hardware of communication\nsystems (e.g., phase noise (PN), high power amplifier (HPA) nonlinearities, or\nin-phase/quadrature-phase (I/Q) imbalance) can severely degrade the performance\nof traditional multiple-input multiple-output (MIMO) systems. Although\ncalibration algorithms can partially compensate these impairments, the\nremaining distortion still has substantial impact. Despite this, most prior\nworks have not analyzed this type of distortion. In this paper, we investigate\nthe impact of residual transceiver hardware impairments on the MIMO system\nperformance. In particular, we consider a transceiver impairment model, which\nhas been experimentally validated, and derive analytical ergodic capacity\nexpressions for both exact and high signal-to-noise ratios (SNRs). We\ndemonstrate that the capacity saturates in the high-SNR regime, thereby\ncreating a finite capacity ceiling. We also present a linear approximation for\nthe ergodic capacity in the low-SNR regime, and show that impairments have only\na second-order impact on the capacity. Furthermore, we analyze the effect of\ntransceiver impairments on large-scale MIMO systems; interestingly, we prove\nthat if one increases the number of antennas at one side only, the capacity\nbehaves similar to the finite-dimensional case. On the contrary, if the number\nof antennas on both sides increases with a fixed ratio, the capacity ceiling\nvanishes; thus, impairments cause only a bounded offset in the capacity\ncompared to the ideal transceiver hardware case.\n", "contributors": [{"name": "Zhang, Xinlin", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Xinlin", "email": ""}, {"name": "Matthaiou, Michail", "sameAs": [], "familyName": "Matthaiou", "additionalName": "", "givenName": "Michail", "email": ""}, {"name": "Bj\u00f6rnson, Emil", "sameAs": [], "familyName": "Bj\u00f6rnson", "additionalName": "", "givenName": "Emil", "email": ""}, {"name": "Coldrey, Mikael", "sameAs": [], "familyName": "Coldrey", "additionalName": "", "givenName": "Mikael", "email": ""}, {"name": "Debbah, M\u00e9rouane", "sameAs": [], "familyName": "Debbah", "additionalName": "", "givenName": "M\u00e9rouane", "email": ""}], "title": "On the MIMO Capacity with Residual Transceiver Hardware Impairments", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-06-13", "2014-12-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1406.3619", "oai:arXiv.org:1406.3619"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Radio-frequency (RF) impairments in the transceiver hardware of communication\nsystems (e.g., phase noise (PN), high power amplifier (HPA) nonlinearities, or\nin-phase/quadrature-phase (I/Q) imbalance) can severely degrade the performance\nof traditional multiple-input multiple-output (MIMO) systems. Although\ncalibration algorithms can partially compensate these impairments, the\nremaining distortion still has substantial impact. Despite this, most prior\nworks have not analyzed this type of distortion. In this paper, we investigate\nthe impact of residual transceiver hardware impairments on the MIMO system\nperformance. In particular, we consider a transceiver impairment model, which\nhas been experimentally validated, and derive analytical ergodic capacity\nexpressions for both exact and high signal-to-noise ratios (SNRs). We\ndemonstrate that the capacity saturates in the high-SNR regime, thereby\ncreating a finite capacity ceiling. We also present a linear approximation for\nthe ergodic capacity in the low-SNR regime, and show that impairments have only\na second-order impact on the capacity. Furthermore, we analyze the effect of\ntransceiver impairments on large-scale MIMO systems; interestingly, we prove\nthat if one increases the number of antennas at one side only, the capacity\nbehaves similar to the finite-dimensional case. On the contrary, if the number\nof antennas on both sides increases with a fixed ratio, the capacity ceiling\nvanishes; thus, impairments cause only a bounded offset in the capacity\ncompared to the ideal transceiver hardware case.\n", "Comment: Accepted for publication at the IEEE International Conference on\n  Communications (ICC 2014), 7 pages, 6 figures"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1406.3619"}}, {"publisher": {"name": ""}, "description": "  This paper summarizes the work on implementing few solutions for the Steiner\nTree problem which we undertook in the PAAL project. The main focus of the\nproject is the development of generic implementations of approximation\nalgorithms together with universal solution frameworks. In particular, we have\nimplemented Zelikovsky 11/6-approximation using local search framework, and\n1.39-approximation by Byrka et al. using iterative rounding framework. These\ntwo algorithms are experimentally compared with greedy 2-approximation, with\nexact but exponential time Dreyfus-Wagner algorithm, as well as with results\ngiven by a state-of-the-art local search techniques by Uchoa and Werneck. The\nresults of this paper are twofold. On one hand, we demonstrate that high level\nalgorithmic concepts can be designed and efficiently used in C++. On the other\nhand, we show that the above algorithms with good theoretical guarantees, give\ndecent results in practice, but are inferior to state-of-the-art heuristical\napproaches.\n", "contributors": [{"name": "Ciebiera, Krzysztof", "sameAs": [], "familyName": "Ciebiera", "additionalName": "", "givenName": "Krzysztof", "email": ""}, {"name": "Godlewski, Piotr", "sameAs": [], "familyName": "Godlewski", "additionalName": "", "givenName": "Piotr", "email": ""}, {"name": "Sankowski, Piotr", "sameAs": [], "familyName": "Sankowski", "additionalName": "", "givenName": "Piotr", "email": ""}, {"name": "Wygocki, Piotr", "sameAs": [], "familyName": "Wygocki", "additionalName": "", "givenName": "Piotr", "email": ""}], "title": "Approximation Algorithms for Steiner Tree Problems Based on Universal\n  Solution Frameworks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.7534", "oai:arXiv.org:1410.7534"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper summarizes the work on implementing few solutions for the Steiner\nTree problem which we undertook in the PAAL project. The main focus of the\nproject is the development of generic implementations of approximation\nalgorithms together with universal solution frameworks. In particular, we have\nimplemented Zelikovsky 11/6-approximation using local search framework, and\n1.39-approximation by Byrka et al. using iterative rounding framework. These\ntwo algorithms are experimentally compared with greedy 2-approximation, with\nexact but exponential time Dreyfus-Wagner algorithm, as well as with results\ngiven by a state-of-the-art local search techniques by Uchoa and Werneck. The\nresults of this paper are twofold. On one hand, we demonstrate that high level\nalgorithmic concepts can be designed and efficiently used in C++. On the other\nhand, we show that the above algorithms with good theoretical guarantees, give\ndecent results in practice, but are inferior to state-of-the-art heuristical\napproaches.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - software engineering"], "providerUpdatedDateTime": "2014-10-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.7534"}}, {"publisher": {"name": ""}, "description": "  The wide bandwidth and large number of antennas used in millimeter wave\nsystems put a heavy burden on the power consumption at the receiver. In this\npaper, using an additive quantization noise model, the effect of analog-digital\nconversion (ADC) resolution and bandwidth on the achievable rate is\ninvestigated for a multi-antenna system under a receiver power constraint. Two\nreceiver architectures, analog and digital combining, are compared in terms of\nperformance. Results demonstrate that: (i) For both analog and digital\ncombining, there is a maximum bandwidth beyond which the achievable rate\ndecreases; (ii) Depending on the operating regime of the system, analog\ncombiner may have higher rate but digital combining uses less bandwidth when\nonly ADC power consumption is considered, (iii) digital combining may have\nhigher rate when power consumption of all the components in the receiver\nfront-end are taken into account.\n", "contributors": [{"name": "Orhan, Oner", "sameAs": [], "familyName": "Orhan", "additionalName": "", "givenName": "Oner", "email": ""}, {"name": "Erkip, Elza", "sameAs": [], "familyName": "Erkip", "additionalName": "", "givenName": "Elza", "email": ""}, {"name": "Rangan, Sundeep", "sameAs": [], "familyName": "Rangan", "additionalName": "", "givenName": "Sundeep", "email": ""}], "title": "Low Power Analog-to-Digital Conversion in Millimeter Wave Systems:\n  Impact of Resolution and Bandwidth on Performance", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01980", "oai:arXiv.org:1502.01980"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The wide bandwidth and large number of antennas used in millimeter wave\nsystems put a heavy burden on the power consumption at the receiver. In this\npaper, using an additive quantization noise model, the effect of analog-digital\nconversion (ADC) resolution and bandwidth on the achievable rate is\ninvestigated for a multi-antenna system under a receiver power constraint. Two\nreceiver architectures, analog and digital combining, are compared in terms of\nperformance. Results demonstrate that: (i) For both analog and digital\ncombining, there is a maximum bandwidth beyond which the achievable rate\ndecreases; (ii) Depending on the operating regime of the system, analog\ncombiner may have higher rate but digital combining uses less bandwidth when\nonly ADC power consumption is considered, (iii) digital combining may have\nhigher rate when power consumption of all the components in the receiver\nfront-end are taken into account.\n", "Comment: 8 pages, 6 figures, in Proc. of IEEE Information Theory and\n  Applications Workshop, Feb. 2015"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01980"}}, {"publisher": {"name": ""}, "description": "  In this paper, we examine the evolution of the impact of non-elite journals.\nWe attempt to answer two questions. First, what fraction of the top-cited\narticles are published in non-elite journals and how has this changed over\ntime. Second, what fraction of the total citations are to non-elite journals\nand how has this changed over time.\n  We studied citations to articles published in 1995-2013. We computed the 10\nmost-cited journals and the 1000 most-cited articles each year for all 261\nsubject categories in Scholar Metrics. We marked the 10 most-cited journals in\na category as the elite journals for the category and the rest as non-elite.\n  There are two conclusions from our study. First, the fraction of top-cited\narticles published in non-elite journals increased steadily over 1995-2013.\nWhile the elite journals still publish a substantial fraction of high-impact\narticles, many more authors of well-regarded papers in diverse research fields\nare choosing other venues.\n  The number of top-1000 papers published in non-elite journals for the\nrepresentative subject category went from 149 in 1995 to 245 in 2013, a growth\nof 64%. Looking at broad research areas, 4 out of 9 areas saw at least\none-third of the top-cited articles published in non-elite journals in 2013.\nFor 6 out of 9 areas, the fraction of top-cited papers published in non-elite\njournals for the representative subject category grew by 45% or more.\n  Second, now that finding and reading relevant articles in non-elite journals\nis about as easy as finding and reading articles in elite journals, researchers\nare increasingly building on and citing work published everywhere. Considering\ncitations to all articles, the percentage of citations to articles in non-elite\njournals went from 27% in 1995 to 47% in 2013. Six out of nine broad areas had\nat least 50% of citations going to articles published in non-elite journals in\n2013.\n", "contributors": [{"name": "Acharya, Anurag", "sameAs": [], "familyName": "Acharya", "additionalName": "", "givenName": "Anurag", "email": ""}, {"name": "Verstak, Alex", "sameAs": [], "familyName": "Verstak", "additionalName": "", "givenName": "Alex", "email": ""}, {"name": "Suzuki, Helder", "sameAs": [], "familyName": "Suzuki", "additionalName": "", "givenName": "Helder", "email": ""}, {"name": "Henderson, Sean", "sameAs": [], "familyName": "Henderson", "additionalName": "", "givenName": "Sean", "email": ""}, {"name": "Iakhiaev, Mikhail", "sameAs": [], "familyName": "Iakhiaev", "additionalName": "", "givenName": "Mikhail", "email": ""}, {"name": "Lin, Cliff Chiung Yu", "sameAs": [], "familyName": "Lin", "additionalName": "Chiung Yu", "givenName": "Cliff", "email": ""}, {"name": "Shetty, Namit", "sameAs": [], "familyName": "Shetty", "additionalName": "", "givenName": "Namit", "email": ""}], "title": "Rise of the Rest: The Growing Impact of Non-Elite Journals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-08"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2217", "oai:arXiv.org:1410.2217"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this paper, we examine the evolution of the impact of non-elite journals.\nWe attempt to answer two questions. First, what fraction of the top-cited\narticles are published in non-elite journals and how has this changed over\ntime. Second, what fraction of the total citations are to non-elite journals\nand how has this changed over time.\n  We studied citations to articles published in 1995-2013. We computed the 10\nmost-cited journals and the 1000 most-cited articles each year for all 261\nsubject categories in Scholar Metrics. We marked the 10 most-cited journals in\na category as the elite journals for the category and the rest as non-elite.\n  There are two conclusions from our study. First, the fraction of top-cited\narticles published in non-elite journals increased steadily over 1995-2013.\nWhile the elite journals still publish a substantial fraction of high-impact\narticles, many more authors of well-regarded papers in diverse research fields\nare choosing other venues.\n  The number of top-1000 papers published in non-elite journals for the\nrepresentative subject category went from 149 in 1995 to 245 in 2013, a growth\nof 64%. Looking at broad research areas, 4 out of 9 areas saw at least\none-third of the top-cited articles published in non-elite journals in 2013.\nFor 6 out of 9 areas, the fraction of top-cited papers published in non-elite\njournals for the representative subject category grew by 45% or more.\n  Second, now that finding and reading relevant articles in non-elite journals\nis about as easy as finding and reading articles in elite journals, researchers\nare increasingly building on and citing work published everywhere. Considering\ncitations to all articles, the percentage of citations to articles in non-elite\njournals went from 27% in 1995 to 47% in 2013. Six out of nine broad areas had\nat least 50% of citations going to articles published in non-elite journals in\n2013.\n"}}], "languages": [null], "subjects": ["computer science - digital libraries"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2217"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Developing and implementing measurable methodologies for improving the security and resilience of a national postal sector directly contribute to protecting public and postal personnel, assets, and revenues. Such methodologies also contribute to the security and resilience of the mode of transport used to carry mail and the protection of the global mail supply chain. Since 2011, the U.S. Postal Inspection Service (USPIS) has collaborated with the CERT Division at Carnegie Mellon University\u2019s Software Engineering Institute to improve the resilience of selected U.S. Postal Service (USPS) products and services. The CERT Resilience Management Model (CERT-RMM) and its companion diagnostic methods served as the foundational tool for this collaboration.\nThis report includes one result of the USPIS/CERT collaboration. It is an extension of CERT-RMM to include a new mail-specific process area for the transportation of international mail. The purpose is to ensure that all international mail is transported in accordance with the standards established by the Universal Postal Union (UPU), which is the governing body that regulates the transportation of international mail.", "contributors": [{"name": "Allen, Julia H.", "sameAs": [], "familyName": "Allen", "additionalName": "H.", "givenName": "Julia", "email": ""}, {"name": "Crabb, Greg", "sameAs": [], "familyName": "Crabb", "additionalName": "", "givenName": "Greg", "email": ""}, {"name": "Curtis, Pamela D", "sameAs": [], "familyName": "Curtis", "additionalName": "D", "givenName": "Pamela", "email": ""}, {"name": "Lin, Sam", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Sam", "email": ""}, {"name": "Mehravari, Nader", "sameAs": [], "familyName": "Mehravari", "additionalName": "", "givenName": "Nader", "email": ""}, {"name": "Wilkes, Dawn", "sameAs": [], "familyName": "Wilkes", "additionalName": "", "givenName": "Dawn", "email": ""}], "title": "CERT Resilience Management Model\u2014Mail-Specific Process Areas: International Mail Transportation (Version 1.0)", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2014-08-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/sei/795", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1807&amp;context=sei", "oai:repository.cmu.edu:sei-1807"]}}, {"name": "setSpec", "properties": {"setSpec": "publication:sei"}}, {"name": "description", "properties": {"description": "Developing and implementing measurable methodologies for improving the security and resilience of a national postal sector directly contribute to protecting public and postal personnel, assets, and revenues. Such methodologies also contribute to the security and resilience of the mode of transport used to carry mail and the protection of the global mail supply chain. Since 2011, the U.S. Postal Inspection Service (USPIS) has collaborated with the CERT Division at Carnegie Mellon University\u2019s Software Engineering Institute to improve the resilience of selected U.S. Postal Service (USPS) products and services. The CERT Resilience Management Model (CERT-RMM) and its companion diagnostic methods served as the foundational tool for this collaboration.\nThis report includes one result of the USPIS/CERT collaboration. It is an extension of CERT-RMM to include a new mail-specific process area for the transportation of international mail. The purpose is to ensure that all international mail is transported in accordance with the standards established by the Universal Postal Union (UPU), which is the governing body that regulates the transportation of international mail."}}], "languages": [null], "subjects": ["software engineering", "uspis", "usps", "international mail transportation", "computer sciences", "universal postal union", "cert-rmm", "upu", "resilience", "mail specific"], "providerUpdatedDateTime": "2014-11-04T16:15:19", "uris": {"canonicalUri": "http://repository.cmu.edu/sei/795"}}, {"publisher": {"name": ""}, "description": "  Ubiquitous sensing is tightly coupled with activity recognition. This survey\nreviews recent advances in Ubiquitous sensing and looks ahead on promising\nfuture directions. In particular, Ubiquitous sensing crosses new barriers\ngiving us new ways to interact with the environment or to inspect our psyche.\nThrough sensing paradigms that parasitically utilise stimuli from the noise of\nenvironmental, third-party pre-installed systems, sensing leaves the boundaries\nof the personal domain. Compared to previous environmental sensing approaches,\nthese new systems mitigate high installation and placement cost by providing a\nrobustness towards process noise. On the other hand, sensing focuses inward and\nattempts to capture mental activities such as cognitive load, fatigue or\nemotion through advances in, for instance, eye-gaze sensing systems or\ninterpretation of body gesture or pose. This survey summarises these\ndevelopments and discusses current research questions and promising future\ndirections.\n", "contributors": [{"name": "Sigg, Stephan", "sameAs": [], "familyName": "Sigg", "additionalName": "", "givenName": "Stephan", "email": ""}, {"name": "Kunze, Kai", "sameAs": [], "familyName": "Kunze", "additionalName": "", "givenName": "Kai", "email": ""}, {"name": "Fu, Xiaoming", "sameAs": [], "familyName": "Fu", "additionalName": "", "givenName": "Xiaoming", "email": ""}], "title": "Recent Advances and Challenges in Ubiquitous Sensing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04973", "oai:arXiv.org:1503.04973"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Ubiquitous sensing is tightly coupled with activity recognition. This survey\nreviews recent advances in Ubiquitous sensing and looks ahead on promising\nfuture directions. In particular, Ubiquitous sensing crosses new barriers\ngiving us new ways to interact with the environment or to inspect our psyche.\nThrough sensing paradigms that parasitically utilise stimuli from the noise of\nenvironmental, third-party pre-installed systems, sensing leaves the boundaries\nof the personal domain. Compared to previous environmental sensing approaches,\nthese new systems mitigate high installation and placement cost by providing a\nrobustness towards process noise. On the other hand, sensing focuses inward and\nattempts to capture mental activities such as cognitive load, fatigue or\nemotion through advances in, for instance, eye-gaze sensing systems or\ninterpretation of body gesture or pose. This survey summarises these\ndevelopments and discusses current research questions and promising future\ndirections.\n", "Comment: Submitted to PIEEE"]}}], "languages": [null], "subjects": ["computer science - human-computer interaction"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04973"}}, {"publisher": {"name": ""}, "description": "abstract: The Game As Life - Life As Game (GALLAG) project investigates how people might change their lives if they think of and/or experience their life as a game. The GALLAG system aims to help people reach their personal goals through the use of context-aware computing, and tailored games and applications. To accomplish this, the GALLAG system uses a combination of sensing technologies, remote audio/video feedback, mobile devices and an application programming interface (API) to empower users to create their own context-aware applications. However, the API requires programming through source code, a task that is too complicated and abstract for many users. This thesis presents GALLAG Strip, a novel approach to programming sensor-based context-aware applications that combines the Programming With Demonstration technique and a mobile device to enable users to experience their applications as they program them. GALLAG Strip lets users create sensor-based context-aware applications in an intuitive and appealing way without the need of computer programming skills; instead, they program their applications by physically demonstrating their envisioned interactions within a space using the same interface that they will later use to interact with the system, that is, using GALLAG-compatible sensors and mobile devices. GALLAG Strip was evaluated through a study with end users in a real world setting, measuring their ability to program simple and complex applications accurately and in a timely manner. The evaluation also comprises a benchmark with expert GALLAG system programmers in creating the same applications. Data and feedback collected from the study show that GALLAG Strip successfully allows users to create sensor-based context-aware applications easily and accurately without the need of prior programming skills currently required by the GALLAG system and enables them to create almost all of their envisioned applications.", "contributors": [{"name": "Garduno Massieu, Luis  (Author)", "sameAs": [], "familyName": "Garduno Massieu", "additionalName": "", "givenName": "Luis", "email": ""}, {"name": "Burleson, Winslow  (Advisor)", "sameAs": [], "familyName": "Burleson", "additionalName": "", "givenName": "Winslow", "email": ""}, {"name": "Hekler, Eric  (Committee member)", "sameAs": [], "familyName": "Hekler", "additionalName": "", "givenName": "Eric", "email": ""}, {"name": "Gupta, Sandeep  (Committee member)", "sameAs": [], "familyName": "Gupta", "additionalName": "", "givenName": "Sandeep", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "GALLAG Strip: A Mobile, Programming With Demonstration Environment for Sensor-Based Context-Aware Application Programming", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Masters Thesis"}}, {"name": "format", "properties": {"format": "90 pages"}}, {"name": "date", "properties": {"date": "2012"}}, {"name": "description", "properties": {"description": ["abstract: The Game As Life - Life As Game (GALLAG) project investigates how people might change their lives if they think of and/or experience their life as a game. The GALLAG system aims to help people reach their personal goals through the use of context-aware computing, and tailored games and applications. To accomplish this, the GALLAG system uses a combination of sensing technologies, remote audio/video feedback, mobile devices and an application programming interface (API) to empower users to create their own context-aware applications. However, the API requires programming through source code, a task that is too complicated and abstract for many users. This thesis presents GALLAG Strip, a novel approach to programming sensor-based context-aware applications that combines the Programming With Demonstration technique and a mobile device to enable users to experience their applications as they program them. GALLAG Strip lets users create sensor-based context-aware applications in an intuitive and appealing way without the need of computer programming skills; instead, they program their applications by physically demonstrating their envisioned interactions within a space using the same interface that they will later use to interact with the system, that is, using GALLAG-compatible sensors and mobile devices. GALLAG Strip was evaluated through a study with end users in a real world setting, measuring their ability to program simple and complex applications accurately and in a timely manner. The evaluation also comprises a benchmark with expert GALLAG system programmers in creating the same applications. Data and feedback collected from the study show that GALLAG Strip successfully allows users to create sensor-based context-aware applications easily and accurately without the need of prior programming skills currently required by the GALLAG system and enables them to create almost all of their envisioned applications.", "Dissertation/Thesis", "M.S. Computer Science 2012"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.14871", "item:14871"]}}], "languages": [null], "subjects": ["human computer interaction", "arts", "ame", "pwd", "computer science", "hci", "media and engineering"], "providerUpdatedDateTime": "2015-02-12T01:13:31", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.14871"}}, {"publisher": {"name": ""}, "description": "  Schelling's model of segregation is one of the first and most influential\nmodels in the field of social simulation. There are many variations of the\nmodel which have been proposed and simulated over the last forty years, though\nthe present state of the literature on the subject is somewhat fragmented and\nlacking comprehensive analytical treatments. In this article a unified\nmathematical framework for Schelling's model and its many variants is\ndeveloped. This methodology is useful in two regards: firstly, it provides a\ntool with which to understand the differences observed between models;\nsecondly, phenomena which appear in several model variations may be understood\nin more depth through analytic studies of simpler versions.\n", "contributors": [{"name": "Rogers, Tim", "sameAs": [], "familyName": "Rogers", "additionalName": "", "givenName": "Tim", "email": ""}, {"name": "McKane, Alan J.", "sameAs": [], "familyName": "McKane", "additionalName": "J.", "givenName": "Alan", "email": ""}], "title": "A unified framework for Schelling's model of segregation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-11", "2011-05-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.1971", "J. Stat. Mech. (2011) P07006", "doi:10.1088/1742-5468/2011/07/P07006", "oai:arXiv.org:1104.1971"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Schelling's model of segregation is one of the first and most influential\nmodels in the field of social simulation. There are many variations of the\nmodel which have been proposed and simulated over the last forty years, though\nthe present state of the literature on the subject is somewhat fragmented and\nlacking comprehensive analytical treatments. In this article a unified\nmathematical framework for Schelling's model and its many variants is\ndeveloped. This methodology is useful in two regards: firstly, it provides a\ntool with which to understand the differences observed between models;\nsecondly, phenomena which appear in several model variations may be understood\nin more depth through analytic studies of simpler versions.\n", "Comment: 21 pages, 3 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "condensed matter - statistical mechanics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.1971"}}, {"publisher": {"name": ""}, "description": "  In computational biology and bioinformatics, the manner to understand\nevolution processes within various related organisms paid a lot of attention\nthese last decades. However, accurate methodologies are still needed to\ndiscover genes content evolution. In a previous work, two novel approaches\nbased on sequence similarities and genes features have been proposed. More\nprecisely, we proposed to use genes names, sequence similarities, or both,\ninsured either from NCBI or from DOGMA annotation tools. Dogma has the\nadvantage to be an up-to-date accurate automatic tool specifically designed for\nchloroplasts, whereas NCBI possesses high quality human curated genes (together\nwith wrongly annotated ones). The key idea of the former proposal was to take\nthe best from these two tools. However, the first proposal was limited by name\nvariations and spelling errors on the NCBI side, leading to core trees of low\nquality. In this paper, these flaws are fixed by improving the comparison of\nNCBI and DOGMA results, and by relaxing constraints on gene names while adding\na stage of post-validation on gene sequences. The two stages of similarity\nmeasures, on names and sequences, are thus proposed for sequence clustering.\nThis improves results that can be obtained using either NCBI or DOGMA alone.\nResults obtained with this quality control test are further investigated and\ncompared with previously released ones, on both computational and biological\naspects, considering a set of 99 chloroplastic genomes.\n", "contributors": [{"name": "AlKindy, Bassam", "sameAs": [], "familyName": "AlKindy", "additionalName": "", "givenName": "Bassam", "email": ""}, {"name": "Guyeux, Christophe", "sameAs": [], "familyName": "Guyeux", "additionalName": "", "givenName": "Christophe", "email": ""}, {"name": "Couchot, Jean-Fran\u00e7ois", "sameAs": [], "familyName": "Couchot", "additionalName": "", "givenName": "Jean-Fran\u00e7ois", "email": ""}, {"name": "Salomon, Michel", "sameAs": [], "familyName": "Salomon", "additionalName": "", "givenName": "Michel", "email": ""}, {"name": "Bahi, Jacques M.", "sameAs": [], "familyName": "Bahi", "additionalName": "M.", "givenName": "Jacques", "email": ""}], "title": "Gene Similarity-based Approaches for Determining Core-Genes of\n  Chloroplasts", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5323", "oai:arXiv.org:1412.5323"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": ["  In computational biology and bioinformatics, the manner to understand\nevolution processes within various related organisms paid a lot of attention\nthese last decades. However, accurate methodologies are still needed to\ndiscover genes content evolution. In a previous work, two novel approaches\nbased on sequence similarities and genes features have been proposed. More\nprecisely, we proposed to use genes names, sequence similarities, or both,\ninsured either from NCBI or from DOGMA annotation tools. Dogma has the\nadvantage to be an up-to-date accurate automatic tool specifically designed for\nchloroplasts, whereas NCBI possesses high quality human curated genes (together\nwith wrongly annotated ones). The key idea of the former proposal was to take\nthe best from these two tools. However, the first proposal was limited by name\nvariations and spelling errors on the NCBI side, leading to core trees of low\nquality. In this paper, these flaws are fixed by improving the comparison of\nNCBI and DOGMA results, and by relaxing constraints on gene names while adding\na stage of post-validation on gene sequences. The two stages of similarity\nmeasures, on names and sequences, are thus proposed for sequence clustering.\nThis improves results that can be obtained using either NCBI or DOGMA alone.\nResults obtained with this quality control test are further investigated and\ncompared with previously released ones, on both computational and biological\naspects, considering a set of 99 chloroplastic genomes.\n", "Comment: 4 pages, IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM 2014)"]}}], "languages": [null], "subjects": ["quantitative biology - genomics", "computer science - neural and evolutionary computing"], "providerUpdatedDateTime": "2014-12-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5323"}}, {"publisher": {"name": ""}, "description": "  The aim of rendezvous in a graph is meeting of two mobile agents at some node\nof an unknown anonymous connected graph. In this paper, we focus on rendezvous\nin trees, and, analogously to the efforts that have been made for solving the\nexploration problem with compact automata, we study the size of memory of\nmobile agents that permits to solve the rendezvous problem deterministically.\nWe assume that the agents are identical, and move in synchronous rounds.\n  We first show that if the delay between the starting times of the agents is\narbitrary, then the lower bound on memory required for rendezvous is Omega(log\nn) bits, even for the line of length n. This lower bound meets a previously\nknown upper bound of O(log n) bits for rendezvous in arbitrary graphs of size\nat most n. Our main result is a proof that the amount of memory needed for\nrendezvous with simultaneous start depends essentially on the number L of\nleaves of the tree, and is exponentially less impacted by the number n of\nnodes. Indeed, we present two identical agents with O(log L + loglog n) bits of\nmemory that solve the rendezvous problem in all trees with at most n nodes and\nat most L leaves. Hence, for the class of trees with polylogarithmically many\nleaves, there is an exponential gap in minimum memory size needed for\nrendezvous between the scenario with arbitrary delay and the scenario with\ndelay zero. Moreover, we show that our upper bound is optimal by proving that\nOmega(log L + loglog n)$ bits of memory are required for rendezvous, even in\nthe class of trees with degrees bounded by 3.\n", "contributors": [{"name": "Fraigniaud, Pierre", "sameAs": [], "familyName": "Fraigniaud", "additionalName": "", "givenName": "Pierre", "email": ""}, {"name": "Pelc, Andrzej", "sameAs": [], "familyName": "Pelc", "additionalName": "", "givenName": "Andrzej", "email": ""}], "title": "Delays Induce an Exponential Memory Gap for Rendezvous in Trees", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-02-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1102.0467", "oai:arXiv.org:1102.0467"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The aim of rendezvous in a graph is meeting of two mobile agents at some node\nof an unknown anonymous connected graph. In this paper, we focus on rendezvous\nin trees, and, analogously to the efforts that have been made for solving the\nexploration problem with compact automata, we study the size of memory of\nmobile agents that permits to solve the rendezvous problem deterministically.\nWe assume that the agents are identical, and move in synchronous rounds.\n  We first show that if the delay between the starting times of the agents is\narbitrary, then the lower bound on memory required for rendezvous is Omega(log\nn) bits, even for the line of length n. This lower bound meets a previously\nknown upper bound of O(log n) bits for rendezvous in arbitrary graphs of size\nat most n. Our main result is a proof that the amount of memory needed for\nrendezvous with simultaneous start depends essentially on the number L of\nleaves of the tree, and is exponentially less impacted by the number n of\nnodes. Indeed, we present two identical agents with O(log L + loglog n) bits of\nmemory that solve the rendezvous problem in all trees with at most n nodes and\nat most L leaves. Hence, for the class of trees with polylogarithmically many\nleaves, there is an exponential gap in minimum memory size needed for\nrendezvous between the scenario with arbitrary delay and the scenario with\ndelay zero. Moreover, we show that our upper bound is optimal by proving that\nOmega(log L + loglog n)$ bits of memory are required for rendezvous, even in\nthe class of trees with degrees bounded by 3.\n"}}], "languages": [null], "subjects": ["computer science - robotics", "computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1102.0467"}}, {"publisher": {"name": ""}, "description": "  Software model checking, as an undecidable problem, has three possible\noutcomes: (1) the program satisfies the specification, (2) the program does not\nsatisfy the specification, and (3) the model checker fails. The third outcome\nusually manifests itself in a space-out, time-out, or one component of the\nverification tool giving up; in all of these failing cases, significant\ncomputation is performed by the verification tool before the failure, but no\nresult is reported. We propose to reformulate the model-checking problem as\nfollows, in order to have the verification tool report a summary of the\nperformed work even in case of failure: given a program and a specification,\nthe model checker returns a condition P ---usually a state predicate--- such\nthat the program satisfies the specification under the condition P ---that is,\nas long as the program does not leave states in which P is satisfied. We are of\ncourse interested in model checkers that return conditions P that are as weak\nas possible. Instead of outcome (1), the model checker will return P = true;\ninstead of (2), the condition P will return the part of the state space that\nsatisfies the specification; and in case (3), the condition P can summarize the\nwork that has been performed by the model checker before space-out, time-out,\nor giving up. If complete verification is necessary, then a different\nverification method or tool may be used to focus on the states that violate the\ncondition. We give such conditions as input to a conditional model checker,\nsuch that the verification problem is restricted to the part of the state space\nthat satisfies the condition. Our experiments show that repeated application of\nconditional model checkers, using different conditions, can significantly\nimprove the verification results, state-space coverage, and performance.\n", "contributors": [{"name": "Beyer, Dirk", "sameAs": [], "familyName": "Beyer", "additionalName": "", "givenName": "Dirk", "email": ""}, {"name": "Henzinger, Thomas A.", "sameAs": [], "familyName": "Henzinger", "additionalName": "A.", "givenName": "Thomas", "email": ""}, {"name": "Keremoglu, M. Erkan", "sameAs": [], "familyName": "Keremoglu", "additionalName": "Erkan", "givenName": "M.", "email": ""}, {"name": "Wendler, Philipp", "sameAs": [], "familyName": "Wendler", "additionalName": "", "givenName": "Philipp", "email": ""}], "title": "Conditional Model Checking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-09-30"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.6926", "oai:arXiv.org:1109.6926"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Software model checking, as an undecidable problem, has three possible\noutcomes: (1) the program satisfies the specification, (2) the program does not\nsatisfy the specification, and (3) the model checker fails. The third outcome\nusually manifests itself in a space-out, time-out, or one component of the\nverification tool giving up; in all of these failing cases, significant\ncomputation is performed by the verification tool before the failure, but no\nresult is reported. We propose to reformulate the model-checking problem as\nfollows, in order to have the verification tool report a summary of the\nperformed work even in case of failure: given a program and a specification,\nthe model checker returns a condition P ---usually a state predicate--- such\nthat the program satisfies the specification under the condition P ---that is,\nas long as the program does not leave states in which P is satisfied. We are of\ncourse interested in model checkers that return conditions P that are as weak\nas possible. Instead of outcome (1), the model checker will return P = true;\ninstead of (2), the condition P will return the part of the state space that\nsatisfies the specification; and in case (3), the condition P can summarize the\nwork that has been performed by the model checker before space-out, time-out,\nor giving up. If complete verification is necessary, then a different\nverification method or tool may be used to focus on the states that violate the\ncondition. We give such conditions as input to a conditional model checker,\nsuch that the verification problem is restricted to the part of the state space\nthat satisfies the condition. Our experiments show that repeated application of\nconditional model checkers, using different conditions, can significantly\nimprove the verification results, state-space coverage, and performance.\n", "Comment: 14 pages, 8 figures, 3 tables"]}}], "languages": [null], "subjects": ["computer science - programming languages", "computer science - software engineering"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.6926"}}, {"publisher": {"name": ""}, "description": "  Motifs are a fundamental building block and distinguishing feature of\nnetworks. While characteristic motif distribution have been found in many\nnetworks, very little is known today about the evolution of network motifs.\nThis paper studies the most important motifs in social networks, triangles, and\nhow directed triangle motifs change over time. Our chosen subject is one of the\nlargest Online Social Networks, Google+. Google+ has two distinguishing\nfeatures that make it particularly interesting: (1) it is a directed network,\nwhich yields a rich set of triangle motifs, and (2) it is a young and fast\nevolving network, whose role in the OSN space is still not fully understood.\nFor the purpose of this study, we crawled the network over a time period of six\nweeks, collecting several snapshots. We find that some triangle types display\nsignificant dynamics, e.g., for some specific initial types, up to 20% of the\ninstances evolve to other types. Due to the fast growth of the OSN in the\nobserved time period, many new triangles emerge. We also observe that many\ntriangles evolve into less-connected motifs (with less edges), suggesting that\ngrowth also comes with pruning. We complement the topological study by also\nconsidering publicly available user profile data (mostly geographic locations).\nThe corresponding results shed some light on the semantics of the triangle\nmotifs. Indeed, we find that users in more symmetric triangle motifs live\ncloser together, indicating more personal relationships. In contrast,\nasymmetric links in motifs often point to faraway users with a high in-degree\n(celebrities).\n", "contributors": [{"name": "Schi\u00f6berg, Doris", "sameAs": [], "familyName": "Schi\u00f6berg", "additionalName": "", "givenName": "Doris", "email": ""}, {"name": "Schneidery, Fabian", "sameAs": [], "familyName": "Schneidery", "additionalName": "", "givenName": "Fabian", "email": ""}, {"name": "Schmid, Stefan", "sameAs": [], "familyName": "Schmid", "additionalName": "", "givenName": "Stefan", "email": ""}, {"name": "Uhlig, Steve", "sameAs": [], "familyName": "Uhlig", "additionalName": "", "givenName": "Steve", "email": ""}, {"name": "Feldmann, Anja", "sameAs": [], "familyName": "Feldmann", "additionalName": "", "givenName": "Anja", "email": ""}], "title": "Evolution of Directed Triangle Motifs in the Google+ OSN", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-15"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04321", "oai:arXiv.org:1502.04321"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Motifs are a fundamental building block and distinguishing feature of\nnetworks. While characteristic motif distribution have been found in many\nnetworks, very little is known today about the evolution of network motifs.\nThis paper studies the most important motifs in social networks, triangles, and\nhow directed triangle motifs change over time. Our chosen subject is one of the\nlargest Online Social Networks, Google+. Google+ has two distinguishing\nfeatures that make it particularly interesting: (1) it is a directed network,\nwhich yields a rich set of triangle motifs, and (2) it is a young and fast\nevolving network, whose role in the OSN space is still not fully understood.\nFor the purpose of this study, we crawled the network over a time period of six\nweeks, collecting several snapshots. We find that some triangle types display\nsignificant dynamics, e.g., for some specific initial types, up to 20% of the\ninstances evolve to other types. Due to the fast growth of the OSN in the\nobserved time period, many new triangles emerge. We also observe that many\ntriangles evolve into less-connected motifs (with less edges), suggesting that\ngrowth also comes with pruning. We complement the topological study by also\nconsidering publicly available user profile data (mostly geographic locations).\nThe corresponding results shed some light on the semantics of the triangle\nmotifs. Indeed, we find that users in more symmetric triangle motifs live\ncloser together, indicating more personal relationships. In contrast,\nasymmetric links in motifs often point to faraway users with a high in-degree\n(celebrities).\n"}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04321"}}, {"publisher": {"name": ""}, "description": "  In this paper, we study the impact of different channel output feedback\narchitectures on the capacity of the two-user interference channel. For a\ntwo-user interference channel, a feedback link can exist between receivers and\ntransmitters in 9 canonical architectures (see Fig. 2), ranging from only one\nfeedback link to four feedback links. We derive the exact capacity region for\nthe symmetric deterministic interference channel and the constant-gap capacity\nregion for the symmetric Gaussian interference channel for all of the 9\narchitectures. We show that for a linear deterministic symmetric interference\nchannel, in the weak interference regime, all models of feedback, except the\none, which has only one of the receivers feeding back to its own transmitter,\nhave the identical capacity region. When only one of the receivers feeds back\nto its own transmitter, the capacity region is a strict subset of the capacity\nregion of the rest of the feedback models in the weak interference regime.\nHowever, the sum-capacity of all feedback models is identical in the weak\ninterference regime. Moreover, in the strong interference regime all models of\nfeedback with at least one of the receivers feeding back to its own transmitter\nhave the identical sum-capacity. For the Gaussian interference channel, the\nresults of the linear deterministic model follow, where capacity is replaced\nwith approximate capacity.\n", "contributors": [{"name": "Sahai, Achaleshwar", "sameAs": [], "familyName": "Sahai", "additionalName": "", "givenName": "Achaleshwar", "email": ""}, {"name": "Aggarwal, Vaneet", "sameAs": [], "familyName": "Aggarwal", "additionalName": "", "givenName": "Vaneet", "email": ""}, {"name": "Yuksel, Melda", "sameAs": [], "familyName": "Yuksel", "additionalName": "", "givenName": "Melda", "email": ""}, {"name": "Sabharwal, Ashutosh", "sameAs": [], "familyName": "Sabharwal", "additionalName": "", "givenName": "Ashutosh", "email": ""}], "title": "Capacity of All Nine Models of Channel Output Feedback for the Two-user\n  Interference Channel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-25", "2013-01-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.4805", "IEEE Transactions on Information Theory, vol.59, no.11,\n  pp.6957,6979, Nov. 2013", "doi:10.1109/TIT.2013.2278691", "oai:arXiv.org:1104.4805"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we study the impact of different channel output feedback\narchitectures on the capacity of the two-user interference channel. For a\ntwo-user interference channel, a feedback link can exist between receivers and\ntransmitters in 9 canonical architectures (see Fig. 2), ranging from only one\nfeedback link to four feedback links. We derive the exact capacity region for\nthe symmetric deterministic interference channel and the constant-gap capacity\nregion for the symmetric Gaussian interference channel for all of the 9\narchitectures. We show that for a linear deterministic symmetric interference\nchannel, in the weak interference regime, all models of feedback, except the\none, which has only one of the receivers feeding back to its own transmitter,\nhave the identical capacity region. When only one of the receivers feeds back\nto its own transmitter, the capacity region is a strict subset of the capacity\nregion of the rest of the feedback models in the weak interference regime.\nHowever, the sum-capacity of all feedback models is identical in the weak\ninterference regime. Moreover, in the strong interference regime all models of\nfeedback with at least one of the receivers feeding back to its own transmitter\nhave the identical sum-capacity. For the Gaussian interference channel, the\nresults of the linear deterministic model follow, where capacity is replaced\nwith approximate capacity.\n", "Comment: submitted to IEEE Transactions on Information Theory, results\n  improved by deriving capacity region of all 9 canonical feedback models in\n  two-user interference channel"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.4805"}}, {"publisher": {"name": ""}, "description": "abstract: Mobile ad hoc networks (MANETs) have attracted attention for mission critical applications. This dissertation investigates techniques of statistical monitoring and control for overhead reduction in a proactive MANET routing protocol. Proactive protocols transmit overhead periodically. Instead, we propose that the local conditions of a node should determine this transmission decision. While the goal is to minimize overhead, a balance in the amount of overhead transmitted and the performance achieved is required. Statistical monitoring consists of techniques to determine if a characteristic has shifted away from an in-control state. A basic tool for monitoring is a control chart, a time-oriented representation of the characteristic. When a sample deviates outside control limits, a significant change has occurred and corrective actions are required to return to the in-control state. We investigate the use of statistical monitoring of local conditions in the Optimized Link State Routing (OLSR) protocol. Three versions are developed. In A-OLSR, each node uses a Shewhart chart to monitor betweenness of its two-hop neighbourhood. Betweenness is a social network metric that measures a node's influence; betweenness is larger when a node has more influence. Changes in topology are associated with changes in betweenness. We incorporate additional local node conditions including speed, density, packet arrival rate, and number of flows it forwards in A+-OLSR. Response Surface Methodology (RSM) is used to optimize timer values. As well, the Shewhart chart is replaced by an Exponentially Weighted Moving Average (EWMA) chart, which is more sensitive to small changes in the characteristic. It is known that control charts do not work as well in the presence of correlation. Hence, in A*-OLSR the autocorrelation in the time series is removed and an Auto-Regressive Integrated Moving Average (ARIMA) model found; this removes the dependence on node speed. A*-OLSR also extends monitoring to two characteristics concurrently using multivariate cumulative sum (MCUSUM) charts. The protocols are evaluated in simulation, and compared to OLSR and its variants. The techniques for statistical monitoring and control are general and have great potential to be applied to the adaptive control of many network protocols.", "contributors": [{"name": "Shaukat, Kahkashan  (Author)", "sameAs": [], "familyName": "Shaukat", "additionalName": "", "givenName": "Kahkashan", "email": ""}, {"name": "Syrotiuk, Violet R (Advisor)", "sameAs": [], "familyName": "Syrotiuk", "additionalName": "R", "givenName": "Violet", "email": ""}, {"name": "Colbourn, Charles J (Committee member)", "sameAs": [], "familyName": "Colbourn", "additionalName": "J", "givenName": "Charles", "email": ""}, {"name": "Montgomery, Douglas C (Committee member)", "sameAs": [], "familyName": "Montgomery", "additionalName": "C", "givenName": "Douglas", "email": ""}, {"name": "Sarjoughian, Hessam S (Committee member)", "sameAs": [], "familyName": "Sarjoughian", "additionalName": "S", "givenName": "Hessam", "email": ""}, {"name": "Sen, Arunabha  (Committee member)", "sameAs": [], "familyName": "Sen", "additionalName": "", "givenName": "Arunabha", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Statistical Monitoring and Control of Locally Proactive Routing Protocols in MANETs", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "168 pages"}}, {"name": "date", "properties": {"date": "2012"}}, {"name": "description", "properties": {"description": ["abstract: Mobile ad hoc networks (MANETs) have attracted attention for mission critical applications. This dissertation investigates techniques of statistical monitoring and control for overhead reduction in a proactive MANET routing protocol. Proactive protocols transmit overhead periodically. Instead, we propose that the local conditions of a node should determine this transmission decision. While the goal is to minimize overhead, a balance in the amount of overhead transmitted and the performance achieved is required. Statistical monitoring consists of techniques to determine if a characteristic has shifted away from an in-control state. A basic tool for monitoring is a control chart, a time-oriented representation of the characteristic. When a sample deviates outside control limits, a significant change has occurred and corrective actions are required to return to the in-control state. We investigate the use of statistical monitoring of local conditions in the Optimized Link State Routing (OLSR) protocol. Three versions are developed. In A-OLSR, each node uses a Shewhart chart to monitor betweenness of its two-hop neighbourhood. Betweenness is a social network metric that measures a node's influence; betweenness is larger when a node has more influence. Changes in topology are associated with changes in betweenness. We incorporate additional local node conditions including speed, density, packet arrival rate, and number of flows it forwards in A+-OLSR. Response Surface Methodology (RSM) is used to optimize timer values. As well, the Shewhart chart is replaced by an Exponentially Weighted Moving Average (EWMA) chart, which is more sensitive to small changes in the characteristic. It is known that control charts do not work as well in the presence of correlation. Hence, in A*-OLSR the autocorrelation in the time series is removed and an Auto-Regressive Integrated Moving Average (ARIMA) model found; this removes the dependence on node speed. A*-OLSR also extends monitoring to two characteristics concurrently using multivariate cumulative sum (MCUSUM) charts. The protocols are evaluated in simulation, and compared to OLSR and its variants. The techniques for statistical monitoring and control are general and have great potential to be applied to the adaptive control of many network protocols.", "Dissertation/Thesis", "Ph.D. Computer Science 2012"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.14511", "item:14511"]}}], "languages": [null], "subjects": ["control charts", "multivariate control charts", "ewma charts", "statistical monitoring", "cusum charts", "computer science", "locally proactive protocols"], "providerUpdatedDateTime": "2015-02-12T01:13:14", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.14511"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Transmission of information from DNA to RNA to protein underlies the core of modem life forms. The advance in sequencing and genetic technologies has revolutionized the study of molecular biology, genetics and developmental biology enabling delineation of biological processes in unprecedented details. Through the study of epigenetics and posttranscriptional regulation of gene expression by high-throughput sequencing technologies in several biological processes, namely embryonic stem cells, somatic reprogramming, erythroid differentiation, epithelial-mesenchymal transition and cancer metastasis, this thesis work has identified novel players and regulatory mechanisms underlying these developmental processes and diseases. Furthermore, an attempt to engineer CRISPRzymes - protein fusions of RNA-guided DNA binding dCas9 - will enable experiments to directly test biological processes at defined genomic loci and expands the toolbox for synthetic biology and potentially opens up opportunities for novel therapeutics.", "contributors": [{"name": "Cheng, Wu Albert", "sameAs": [], "familyName": "Cheng", "additionalName": "Albert", "givenName": "Wu", "email": ""}, {"name": "Massachusetts Institute of Technology. Computational and Systems Biology Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computational and Systems Biology", "givenName": "Massachusetts", "email": ""}, {"name": "Rudolf Jaenisch.", "sameAs": [], "familyName": "Jaenisch.", "additionalName": "", "givenName": "Rudolf", "email": ""}], "title": "Epigenetic and post-transcriptional regulation of gene expression in pluripotent stem cells, differentiation and metastasis", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "309 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/91122", "892972629", "oai:dspace.mit.edu:1721.1/91122"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2014-10-21T17:27:36Z", "2014-10-21T17:27:36Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["Transmission of information from DNA to RNA to protein underlies the core of modem life forms. The advance in sequencing and genetic technologies has revolutionized the study of molecular biology, genetics and developmental biology enabling delineation of biological processes in unprecedented details. Through the study of epigenetics and posttranscriptional regulation of gene expression by high-throughput sequencing technologies in several biological processes, namely embryonic stem cells, somatic reprogramming, erythroid differentiation, epithelial-mesenchymal transition and cancer metastasis, this thesis work has identified novel players and regulatory mechanisms underlying these developmental processes and diseases. Furthermore, an attempt to engineer CRISPRzymes - protein fusions of RNA-guided DNA binding dCas9 - will enable experiments to directly test biological processes at defined genomic loci and expands the toolbox for synthetic biology and potentially opens up opportunities for novel therapeutics.", "by Wu Albert Cheng.", "Thesis: Ph. D., Massachusetts Institute of Technology, Computational and Systems Biology Program, 2014.", "Cataloged from PDF version of thesis.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_54828", "hdl_1721.1_54823"]}}], "languages": [null], "subjects": ["computational and systems biology program."], "providerUpdatedDateTime": "2015-04-27T14:53:07", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/91122"}}, {"publisher": {"name": ""}, "description": "  This paper introduces constrained mixtures for continuous distributions,\ncharacterized by a mixture of distributions where each distribution has a shape\nsimilar to the base distribution and disjoint domains. This new concept is used\nto create generalized asymmetric versions of the Laplace and normal\ndistributions, which are shown to define exponential families, with known\nconjugate priors, and to have maximum likelihood estimates for the original\nparameters, with known closed-form expressions. The asymmetric and symmetric\nnormal distributions are compared in a linear regression example, showing that\nthe asymmetric version performs at least as well as the symmetric one, and in a\nreal world time-series problem, where a hidden Markov model is used to fit a\nstock index, indicating that the asymmetric version provides higher likelihood\nand may learn distribution models over states and transition distributions with\nconsiderably less entropy.\n", "contributors": [{"name": "Miranda, Conrado S.", "sameAs": [], "familyName": "Miranda", "additionalName": "S.", "givenName": "Conrado", "email": ""}, {"name": "Von Zuben, Fernando J.", "sameAs": [], "familyName": "Von Zuben", "additionalName": "J.", "givenName": "Fernando", "email": ""}], "title": "Asymmetric Distributions from Constrained Mixtures", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06429", "oai:arXiv.org:1503.06429"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  This paper introduces constrained mixtures for continuous distributions,\ncharacterized by a mixture of distributions where each distribution has a shape\nsimilar to the base distribution and disjoint domains. This new concept is used\nto create generalized asymmetric versions of the Laplace and normal\ndistributions, which are shown to define exponential families, with known\nconjugate priors, and to have maximum likelihood estimates for the original\nparameters, with known closed-form expressions. The asymmetric and symmetric\nnormal distributions are compared in a linear regression example, showing that\nthe asymmetric version performs at least as well as the symmetric one, and in a\nreal world time-series problem, where a hidden Markov model is used to fit a\nstock index, indicating that the asymmetric version provides higher likelihood\nand may learn distribution models over states and transition distributions with\nconsiderably less entropy.\n"}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-29T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06429"}}, {"publisher": {"name": ""}, "description": "  We illustrate the use of tools (asymptotic theories of standard error\nquantification using appropriate statistical models, bootstrapping, model\ncomparison techniques) in addition to sensitivity that may be employed to\ndetermine the information content in data sets. We do this in the context of\nrecent models [23] for nucleated polymerization in proteins, about which very\nlittle is known regarding the underlying mechanisms; thus the methodology we\ndevelop here may be of great help to experimentalists.\n", "contributors": [{"name": "Banks, H. T.", "sameAs": [], "familyName": "Banks", "additionalName": "T.", "givenName": "H.", "email": ""}, {"name": "Doumic, M", "sameAs": [], "familyName": "Doumic", "additionalName": "", "givenName": "M", "email": ""}, {"name": "Kruse, C", "sameAs": [], "familyName": "Kruse", "additionalName": "", "givenName": "C", "email": ""}, {"name": "Prigent, S", "sameAs": [], "familyName": "Prigent", "additionalName": "", "givenName": "S", "email": ""}, {"name": "Rezaei, H", "sameAs": [], "familyName": "Rezaei", "additionalName": "", "givenName": "H", "email": ""}], "title": "Information Content in Data Sets for a Nucleated-Polymerization Model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04682", "oai:arXiv.org:1503.04682"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": "  We illustrate the use of tools (asymptotic theories of standard error\nquantification using appropriate statistical models, bootstrapping, model\ncomparison techniques) in addition to sensitivity that may be employed to\ndetermine the information content in data sets. We do this in the context of\nrecent models [23] for nucleated polymerization in proteins, about which very\nlittle is known regarding the underlying mechanisms; thus the methodology we\ndevelop here may be of great help to experimentalists.\n"}}], "languages": [null], "subjects": ["statistics - applications", "computer science - computational engineering", "mathematics - analysis of pdes", "finance", "and science"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04682"}}, {"publisher": {"name": ""}, "description": "  Marcus, Spielman, and Srivastava in their seminal work [MSS13] resolved the\nKadison-Singer conjecture by proving that the sum of any set of finitely\nsupported independently distributed random vectors with \"small\" expected\nsquared norm that are in isotropic position (in expectation) attains a \"small\"\nspectral norm with a nonzero probability. Their proof crucially employs real\nstability of polynomials which is the natural generalization of real-rootedness\nto multivariate polynomials.\n  Strongly Rayleigh distributions are families of probability distributions\nwhose generating polynomials are real stable [BBL09]. As independent\ndistributions are just special cases of strongly Rayleigh measures, it is a\nnatural question to see if the main theorem of [MSS13] can be extended to\nfamilies of vectors assigned to the elements of a strongly Rayleigh\ndistribution.\n  In this paper we answer this question affirmatively; we show that for any\nhomogeneous strongly Rayleigh distribution where the marginal probabilities are\nupper bounded by $\\epsilon_1$ and any isotropic set of vectors assigned to the\nunderlying elements whose norms are at most $\\sqrt{\\epsilon_2}$, there is a set\nin the support of the distribution such that the spectral norm of the sum of\nthe vectors assigned to the elements of the set is at most\n$O(\\epsilon_1+\\epsilon_2)$. We employ our theorem to provide a sufficient\ncondition for the existence of spectrally thin trees. This, together with a\nrecent work of the authors, provide an improved upper bound on the integrality\ngap of the natural LP relaxation of the Asymmetric Traveling Salesman Problem.\n", "contributors": [{"name": "Anari, Nima", "sameAs": [], "familyName": "Anari", "additionalName": "", "givenName": "Nima", "email": ""}, {"name": "Gharan, Shayan Oveis", "sameAs": [], "familyName": "Gharan", "additionalName": "Oveis", "givenName": "Shayan", "email": ""}], "title": "The Kadison-Singer Problem for Strongly Rayleigh Measures and\n  Applications to Asymmetric TSP", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1143", "oai:arXiv.org:1412.1143"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  Marcus, Spielman, and Srivastava in their seminal work [MSS13] resolved the\nKadison-Singer conjecture by proving that the sum of any set of finitely\nsupported independently distributed random vectors with \"small\" expected\nsquared norm that are in isotropic position (in expectation) attains a \"small\"\nspectral norm with a nonzero probability. Their proof crucially employs real\nstability of polynomials which is the natural generalization of real-rootedness\nto multivariate polynomials.\n  Strongly Rayleigh distributions are families of probability distributions\nwhose generating polynomials are real stable [BBL09]. As independent\ndistributions are just special cases of strongly Rayleigh measures, it is a\nnatural question to see if the main theorem of [MSS13] can be extended to\nfamilies of vectors assigned to the elements of a strongly Rayleigh\ndistribution.\n  In this paper we answer this question affirmatively; we show that for any\nhomogeneous strongly Rayleigh distribution where the marginal probabilities are\nupper bounded by $\\epsilon_1$ and any isotropic set of vectors assigned to the\nunderlying elements whose norms are at most $\\sqrt{\\epsilon_2}$, there is a set\nin the support of the distribution such that the spectral norm of the sum of\nthe vectors assigned to the elements of the set is at most\n$O(\\epsilon_1+\\epsilon_2)$. We employ our theorem to provide a sufficient\ncondition for the existence of spectrally thin trees. This, together with a\nrecent work of the authors, provide an improved upper bound on the integrality\ngap of the natural LP relaxation of the Asymmetric Traveling Salesman Problem.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - combinatorics", "mathematics - probability"], "providerUpdatedDateTime": "2014-12-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1143"}}, {"publisher": {"name": ""}, "description": "  A stochastic combinatorial semi-bandit is an online learning problem where at\neach step a learning agent chooses a subset of ground items subject to\nconstraints, and then observes stochastic weights of these items and receives\ntheir sum as a payoff. In this paper, we close the problem of computationally\nand sample efficient learning in stochastic combinatorial semi-bandits. In\nparticular, we analyze a UCB-like algorithm for solving the problem, which is\nknown to be computationally efficient; and prove $O(K L (1 / \\Delta) \\log n)$\nand $O(\\sqrt{K L n \\log n})$ upper bounds on its $n$-step regret, where $L$ is\nthe number of ground items, $K$ is the maximum number of chosen items, and\n$\\Delta$ is the gap between the expected returns of the optimal and best\nsuboptimal solutions. The gap-dependent bound is tight up to a constant factor\nand the gap-free bound is tight up to a polylogarithmic factor.\n", "contributors": [{"name": "Kveton, Branislav", "sameAs": [], "familyName": "Kveton", "additionalName": "", "givenName": "Branislav", "email": ""}, {"name": "Wen, Zheng", "sameAs": [], "familyName": "Wen", "additionalName": "", "givenName": "Zheng", "email": ""}, {"name": "Ashkan, Azin", "sameAs": [], "familyName": "Ashkan", "additionalName": "", "givenName": "Azin", "email": ""}, {"name": "Szepesvari, Csaba", "sameAs": [], "familyName": "Szepesvari", "additionalName": "", "givenName": "Csaba", "email": ""}], "title": "Tight Regret Bounds for Stochastic Combinatorial Semi-Bandits", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-03", "2015-01-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.0949", "oai:arXiv.org:1410.0949"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  A stochastic combinatorial semi-bandit is an online learning problem where at\neach step a learning agent chooses a subset of ground items subject to\nconstraints, and then observes stochastic weights of these items and receives\ntheir sum as a payoff. In this paper, we close the problem of computationally\nand sample efficient learning in stochastic combinatorial semi-bandits. In\nparticular, we analyze a UCB-like algorithm for solving the problem, which is\nknown to be computationally efficient; and prove $O(K L (1 / \\Delta) \\log n)$\nand $O(\\sqrt{K L n \\log n})$ upper bounds on its $n$-step regret, where $L$ is\nthe number of ground items, $K$ is the maximum number of chosen items, and\n$\\Delta$ is the gap between the expected returns of the optimal and best\nsuboptimal solutions. The gap-dependent bound is tight up to a constant factor\nand the gap-free bound is tight up to a polylogarithmic factor.\n", "Comment: Proceedings of the 18th International Conference on Artificial\n  Intelligence and Statistics"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.0949"}}, {"publisher": {"name": ""}, "description": "  Exchangeable random partition processes are the basis for Bayesian approaches\nto statistical inference in large alphabet settings. On the other hand, the\nnotion of the pattern of a sequence provides an information-theoretic framework\nfor data compression in large alphabet scenarios. Because data compression and\nparameter estimation are intimately related, we study the redundancy of Bayes\nestimators coming from Poisson-Dirichlet priors (or \"Chinese restaurant\nprocesses\") and the Pitman-Yor prior. This provides an understanding of these\nestimators in the setting of unknown discrete alphabets from the perspective of\nuniversal compression. In particular, we identify relations between alphabet\nsizes and sample sizes where the redundancy is small, thereby characterizing\nuseful regimes for these estimators.\n", "contributors": [{"name": "Santhanam, Narayana P.", "sameAs": [], "familyName": "Santhanam", "additionalName": "P.", "givenName": "Narayana", "email": ""}, {"name": "Sarwate, Anand D.", "sameAs": [], "familyName": "Sarwate", "additionalName": "D.", "givenName": "Anand", "email": ""}, {"name": "Woo, Jae Oh", "sameAs": [], "familyName": "Woo", "additionalName": "Oh", "givenName": "Jae", "email": ""}], "title": "Redundancy of Exchangeable Estimators", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-21", "2014-10-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.5383", "oai:arXiv.org:1407.5383"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Exchangeable random partition processes are the basis for Bayesian approaches\nto statistical inference in large alphabet settings. On the other hand, the\nnotion of the pattern of a sequence provides an information-theoretic framework\nfor data compression in large alphabet scenarios. Because data compression and\nparameter estimation are intimately related, we study the redundancy of Bayes\nestimators coming from Poisson-Dirichlet priors (or \"Chinese restaurant\nprocesses\") and the Pitman-Yor prior. This provides an understanding of these\nestimators in the setting of unknown discrete alphabets from the perspective of\nuniversal compression. In particular, we identify relations between alphabet\nsizes and sample sizes where the redundancy is small, thereby characterizing\nuseful regimes for these estimators.\n", "Comment: 18 pages"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.5383"}}, {"publisher": {"name": ""}, "description": "  In the Red-Blue Dominating Set problem, we are given a bipartite graph $G =\n(V_B \\cup V_R,E)$ and an integer $k$, and asked whether $G$ has a subset $D\n\\subseteq V_B$ of at most $k$ \"blue\" vertices such that each \"red\" vertex from\n$V_R$ is adjacent to a vertex in $D$. We provide the first explicit linear\nkernel for this problem on planar graphs, of size at most $46k$.\n", "contributors": [{"name": "Garnero, Valentin", "sameAs": [], "familyName": "Garnero", "additionalName": "", "givenName": "Valentin", "email": ""}, {"name": "Sau, Ignasi", "sameAs": [], "familyName": "Sau", "additionalName": "", "givenName": "Ignasi", "email": ""}, {"name": "Thilikos, Dimitrios M.", "sameAs": [], "familyName": "Thilikos", "additionalName": "M.", "givenName": "Dimitrios", "email": ""}], "title": "A linear kernel for planar red-blue dominating set", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-27", "2015-01-14"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6388", "oai:arXiv.org:1408.6388"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In the Red-Blue Dominating Set problem, we are given a bipartite graph $G =\n(V_B \\cup V_R,E)$ and an integer $k$, and asked whether $G$ has a subset $D\n\\subseteq V_B$ of at most $k$ \"blue\" vertices such that each \"red\" vertex from\n$V_R$ is adjacent to a vertex in $D$. We provide the first explicit linear\nkernel for this problem on planar graphs, of size at most $46k$.\n", "Comment: 15 pages, 4 figures"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "05c10", "05c85", "g.2.2"], "providerUpdatedDateTime": "2015-01-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6388"}}, {"publisher": {"name": ""}, "description": "  A topological constraint on the possible values of the universal quantization\nparameter is revealed in the case of geometric quantization on (boundary)\ncurves diffeomorphic to $S^1$, analytically extended on a bounded domain in\n$\\mathbb{C}$, with $n \\ge 2$ boundary components. Unlike the case of one\nboundary component (such as the canonical Berezin quantization of the\nPoincar\\'e upper-half plane or the case of conformally-invariant 2D systems),\nthe more general case considered here leads to a strictly positive minimum\nvalue for the quantization parameter, which depends on the geometrical data of\nthe domain (specifically, the total area and total perimeter in the smooth\ncase). It is proven that if the lower bound is attained, then $n=2$ and the\ndomain must be annular, with a direct interpretation in terms of the global\nmonodromy.\n", "contributors": [{"name": "Teodorescu, Razvan", "sameAs": [], "familyName": "Teodorescu", "additionalName": "", "givenName": "Razvan", "email": ""}], "title": "Topological constraints in geometric deformation quantization on domains\n  with multiple boundary components", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7716", "oai:arXiv.org:1412.7716"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "physics:hep-th", "physics:math-ph"]}}, {"name": "description", "properties": {"description": "  A topological constraint on the possible values of the universal quantization\nparameter is revealed in the case of geometric quantization on (boundary)\ncurves diffeomorphic to $S^1$, analytically extended on a bounded domain in\n$\\mathbb{C}$, with $n \\ge 2$ boundary components. Unlike the case of one\nboundary component (such as the canonical Berezin quantization of the\nPoincar\\'e upper-half plane or the case of conformally-invariant 2D systems),\nthe more general case considered here leads to a strictly positive minimum\nvalue for the quantization parameter, which depends on the geometrical data of\nthe domain (specifically, the total area and total perimeter in the smooth\ncase). It is proven that if the lower bound is attained, then $n=2$ and the\ndomain must be annular, with a direct interpretation in terms of the global\nmonodromy.\n"}}], "languages": [null], "subjects": ["high energy physics - theory", "11f99", "81s99", "mathematical physics", "mathematics - complex variables", "mathematics - operator algebras", "46l37", "46l35"], "providerUpdatedDateTime": "2014-12-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7716"}}, {"publisher": {"name": ""}, "description": "  This paper presents generalized probabilistic models for high-order\nprojective dependency parsing and an algorithmic framework for learning these\nstatistical models involving dependency trees. Partition functions and\nmarginals for high-order dependency trees can be computed efficiently, by\nadapting our algorithms which extend the inside-outside algorithm to\nhigher-order cases. To show the effectiveness of our algorithms, we perform\nexperiments on three languages---English, Chinese and Czech, using maximum\nconditional likelihood estimation for model training and L-BFGS for parameter\nestimation. Our methods achieve competitive performance for English, and\noutperform all previously reported dependency parsers for Chinese and Czech.\n", "contributors": [{"name": "Ma, Xuezhe", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Xuezhe", "email": ""}, {"name": "Zhao, Hai", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Hai", "email": ""}], "title": "Probabilistic Models for High-Order Projective Dependency Parsing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-14"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04174", "oai:arXiv.org:1502.04174"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper presents generalized probabilistic models for high-order\nprojective dependency parsing and an algorithmic framework for learning these\nstatistical models involving dependency trees. Partition functions and\nmarginals for high-order dependency trees can be computed efficiently, by\nadapting our algorithms which extend the inside-outside algorithm to\nhigher-order cases. To show the effectiveness of our algorithms, we perform\nexperiments on three languages---English, Chinese and Czech, using maximum\nconditional likelihood estimation for model training and L-BFGS for parameter\nestimation. Our methods achieve competitive performance for English, and\noutperform all previously reported dependency parsers for Chinese and Czech.\n"}}], "languages": [null], "subjects": ["computer science - computation and language"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04174"}}, {"publisher": {"name": ""}, "description": "  Microcanonical thermostatistics analysis has become an important tool to\nreveal essential aspects of phase transitions in complex systems. An efficient\nway to estimate the microcanonical inverse temperature $\\beta(E)$ and the\nmicrocanonical entropy $S(E)$ is achieved with the statistical temperature\nweighted histogram analysis method (ST-WHAM). The strength of this method lies\non its flexibility, as it can be used to analyse data produced by algorithms\nwith generalised sampling weights. However, for any sampling weight, ST-WHAM\nrequires the calculation of derivatives of energy histograms $H(E)$, which\nleads to non-trivial and tedious binning tasks for models with continuous\nenergy spectrum such as those for biomolecular and colloidal systems. Here, we\ndiscuss two alternative methods that avoid the need for such energy binning to\nobtain continuous estimates for $H(E)$ in order to evaluate $\\beta(E)$ by using\nST-WHAM: (i) a series expansion to estimate probability densities from the\nempirical cumulative distribution function (CDF), and (ii) a Bayesian approach\nto model this CDF. Comparison with a simple linear regression method is also\ncarried out. The performance of these approaches is evaluated considering\ncoarse-grained protein models for folding and peptide aggregation.\n", "contributors": [{"name": "Alves, Nelson A.", "sameAs": [], "familyName": "Alves", "additionalName": "A.", "givenName": "Nelson", "email": ""}, {"name": "Morero, Lucas D.", "sameAs": [], "familyName": "Morero", "additionalName": "D.", "givenName": "Lucas", "email": ""}, {"name": "Rizzi, Leandro G.", "sameAs": [], "familyName": "Rizzi", "additionalName": "G.", "givenName": "Leandro", "email": ""}], "title": "Microcanonical thermostatistics analysis without histograms: cumulative\n  distribution and Bayesian approaches", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07964", "doi:10.1016/j.cpc.2015.02.010", "oai:arXiv.org:1502.07964"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Microcanonical thermostatistics analysis has become an important tool to\nreveal essential aspects of phase transitions in complex systems. An efficient\nway to estimate the microcanonical inverse temperature $\\beta(E)$ and the\nmicrocanonical entropy $S(E)$ is achieved with the statistical temperature\nweighted histogram analysis method (ST-WHAM). The strength of this method lies\non its flexibility, as it can be used to analyse data produced by algorithms\nwith generalised sampling weights. However, for any sampling weight, ST-WHAM\nrequires the calculation of derivatives of energy histograms $H(E)$, which\nleads to non-trivial and tedious binning tasks for models with continuous\nenergy spectrum such as those for biomolecular and colloidal systems. Here, we\ndiscuss two alternative methods that avoid the need for such energy binning to\nobtain continuous estimates for $H(E)$ in order to evaluate $\\beta(E)$ by using\nST-WHAM: (i) a series expansion to estimate probability densities from the\nempirical cumulative distribution function (CDF), and (ii) a Bayesian approach\nto model this CDF. Comparison with a simple linear regression method is also\ncarried out. The performance of these approaches is evaluated considering\ncoarse-grained protein models for folding and peptide aggregation.\n", "Comment: 9 pages, 11 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "condensed matter - statistical mechanics", "physics - biological physics"], "providerUpdatedDateTime": "2015-03-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07964"}}, {"publisher": {"name": ""}, "description": "  We study asymptotic distribution of zeros of random holomorphic sections of\nhigh powers of positive line bundles defined over projective homogenous\nmanifolds. We work with a wide class of distributions that includes real and\ncomplex Gaussians. As a special case, we obtain asymptotic zero distribution of\nensembles of orthogonal polynomials. Namely, we prove that normalized zero\nmeasures of m i.i.d random polynomials, orthonormalized on a regular compact\nset $K\\subset \\Bbb{C}^m,$ are almost surely asymptotic to the equilibrium\nmeasure of $K$.\n", "contributors": [{"name": "Bayraktar, Turgay", "sameAs": [], "familyName": "Bayraktar", "additionalName": "", "givenName": "Turgay", "email": ""}], "title": "Equidistribution of zeros of random holomorphic sections", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-03", "2015-02-23"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.0933", "oai:arXiv.org:1312.0933"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We study asymptotic distribution of zeros of random holomorphic sections of\nhigh powers of positive line bundles defined over projective homogenous\nmanifolds. We work with a wide class of distributions that includes real and\ncomplex Gaussians. As a special case, we obtain asymptotic zero distribution of\nensembles of orthogonal polynomials. Namely, we prove that normalized zero\nmeasures of m i.i.d random polynomials, orthonormalized on a regular compact\nset $K\\subset \\Bbb{C}^m,$ are almost surely asymptotic to the equilibrium\nmeasure of $K$.\n", "Comment: Minor revisions and corrections. Some examples and references added.\n  26 pages"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - probability", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.0933"}}, {"publisher": {"name": ""}, "description": "  This study investigates the significance of Rogers Diffusion of Innovations\n(DOI) theory with regard to the use of a Virtual Learning Environment (VLE) at\nthe Royal University of Bhutan (RUB). The focus is on different adoption types\nand characteristics of users. Rogers DOI theory is applied to investigate the\ninfluence of five predictors (relative advantage, complexity, compatibility,\ntrialability and observability) and their significance in the perception of\nacademic staff at the RUB in relation to the probability of VLE adoption. These\npredictors are attributes of the VLE that determine the rate of adoption by\nvarious adopter group memberships (Innovators, Early Adopters, Early Majority,\nLate Majority, Laggards). Descriptive statistics and regression analysis were\ndeployed to analyse adopter group memberships and predictor significance in VLE\nadoption and use. The results reveal varying attitudes towards VLE adoption by\nacademic staff at RUB. Few predictors are consistent with previous research on\nVLE adoption. There are also significant differences from previous research on\npredictors such as the deviation in adopter frequency from that predicted by\nRogers DOI theory. Therefore, it can be concluded that it is misleading to rely\non the DOI theory in the way it is currently operationalised for predicting VLE\nuse.\n", "contributors": [{"name": "Penjor, Sonam", "sameAs": [], "familyName": "Penjor", "additionalName": "", "givenName": "Sonam", "email": ""}, {"name": "Zander, Par-Ola", "sameAs": [], "familyName": "Zander", "additionalName": "", "givenName": "Par-Ola", "email": ""}], "title": "Predictors for the Adoption of Virtual Learning Environments - a Case\n  Study from Bhutan", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02408", "oai:arXiv.org:1503.02408"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This study investigates the significance of Rogers Diffusion of Innovations\n(DOI) theory with regard to the use of a Virtual Learning Environment (VLE) at\nthe Royal University of Bhutan (RUB). The focus is on different adoption types\nand characteristics of users. Rogers DOI theory is applied to investigate the\ninfluence of five predictors (relative advantage, complexity, compatibility,\ntrialability and observability) and their significance in the perception of\nacademic staff at the RUB in relation to the probability of VLE adoption. These\npredictors are attributes of the VLE that determine the rate of adoption by\nvarious adopter group memberships (Innovators, Early Adopters, Early Majority,\nLate Majority, Laggards). Descriptive statistics and regression analysis were\ndeployed to analyse adopter group memberships and predictor significance in VLE\nadoption and use. The results reveal varying attitudes towards VLE adoption by\nacademic staff at RUB. Few predictors are consistent with previous research on\nVLE adoption. There are also significant differences from previous research on\npredictors such as the deviation in adopter frequency from that predicted by\nRogers DOI theory. Therefore, it can be concluded that it is misleading to rely\non the DOI theory in the way it is currently operationalised for predicting VLE\nuse.\n", "Comment: In review - comments welcome also from other colleagues!"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02408"}}, {"publisher": {"name": ""}, "description": "  Bloom filters are probabilistic data structures commonly used for approximate\nmembership problems in many areas of Computer Science (networking, distributed\nsystems, databases, etc.). With the increase in data size and distribution of\ndata, problems arise where a large number of Bloom filters are available, and\nall them need to be searched for potential matches. As an example, in a\nfederated cloud environment, each cloud provider could encode the information\nusing Bloom filters and share the Bloom filters with a central coordinator. The\nproblem of interest is not only whether a given element is in any of the sets\nrepresented by the Bloom filters, but which of the existing sets contain the\ngiven element. This problem cannot be solved by just constructing a Bloom\nfilter on the union of all the sets. Instead, we effectively have a\nmultidimensional Bloom filter problem: given an element, we wish to receive a\nlist of candidate sets where the element might be.\n  To solve this problem, we consider 3 alternatives. Firstly, we can naively\ncheck many Bloom filters. Secondly, we propose to organize the Bloom filters in\na hierarchical index structure akin to a B+ tree, that we call Bloofi. Finally,\nwe propose another data structure that packs the Bloom filters in such a way as\nto exploit bit-level parallelism, which we call Flat-Bloofi.\n  Our theoretical and experimental results show that Bloofi and Flat-Bloofi\nprovide scalable and efficient solutions alternatives to search through a large\nnumber of Bloom filters.\n", "contributors": [{"name": "Crainiceanu, Adina", "sameAs": [], "familyName": "Crainiceanu", "additionalName": "", "givenName": "Adina", "email": ""}, {"name": "Lemire, Daniel", "sameAs": [], "familyName": "Lemire", "additionalName": "", "givenName": "Daniel", "email": ""}], "title": "Bloofi: Multidimensional Bloom Filters", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-08", "2015-02-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.01941", "doi:10.1016/j.is.2015.01.002", "oai:arXiv.org:1501.01941"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Bloom filters are probabilistic data structures commonly used for approximate\nmembership problems in many areas of Computer Science (networking, distributed\nsystems, databases, etc.). With the increase in data size and distribution of\ndata, problems arise where a large number of Bloom filters are available, and\nall them need to be searched for potential matches. As an example, in a\nfederated cloud environment, each cloud provider could encode the information\nusing Bloom filters and share the Bloom filters with a central coordinator. The\nproblem of interest is not only whether a given element is in any of the sets\nrepresented by the Bloom filters, but which of the existing sets contain the\ngiven element. This problem cannot be solved by just constructing a Bloom\nfilter on the union of all the sets. Instead, we effectively have a\nmultidimensional Bloom filter problem: given an element, we wish to receive a\nlist of candidate sets where the element might be.\n  To solve this problem, we consider 3 alternatives. Firstly, we can naively\ncheck many Bloom filters. Secondly, we propose to organize the Bloom filters in\na hierarchical index structure akin to a B+ tree, that we call Bloofi. Finally,\nwe propose another data structure that packs the Bloom filters in such a way as\nto exploit bit-level parallelism, which we call Flat-Bloofi.\n  Our theoretical and experimental results show that Bloofi and Flat-Bloofi\nprovide scalable and efficient solutions alternatives to search through a large\nnumber of Bloom filters.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - databases"], "providerUpdatedDateTime": "2015-02-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.01941"}}, {"publisher": {"name": ""}, "description": "  We show that if $(X_t,\\mathcal{F}_t)_t$ is a family of foliations with\nreduced singularities on a smooth family of surfaces, then invariance of\nplurigenera holds for sufficiently large $m$. On the other hand, we provide\nexamples on which the result fails, for small values of $m$.\n", "contributors": [{"name": "Cascini, Paolo", "sameAs": [], "familyName": "Cascini", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Floris, Enrica", "sameAs": [], "familyName": "Floris", "additionalName": "", "givenName": "Enrica", "email": ""}], "title": "On invariance of plurigenera for foliations on surfaces", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.00817", "oai:arXiv.org:1502.00817"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We show that if $(X_t,\\mathcal{F}_t)_t$ is a family of foliations with\nreduced singularities on a smooth family of surfaces, then invariance of\nplurigenera holds for sufficiently large $m$. On the other hand, we provide\nexamples on which the result fails, for small values of $m$.\n", "Comment: 33 pages"]}}], "languages": [null], "subjects": ["37f75", "mathematics - complex variables", "14j99", "32l10", "mathematics - algebraic geometry", "14d06", "32g10"], "providerUpdatedDateTime": "2015-02-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.00817"}}, {"publisher": {"name": ""}, "description": "  The analysis of astronomical images is a non-trivial task. The D3PO algorithm\naddresses the inference problem of denoising, deconvolving, and decomposing\nphoton observations. Its primary goal is the simultaneous but individual\nreconstruction of the diffuse and point-like photon flux given a single photon\ncount image, where the fluxes are superimposed. In order to discriminate\nbetween these morphologically different signal components, a probabilistic\nalgorithm is derived in the language of information field theory based on a\nhierarchical Bayesian parameter model. The signal inference exploits prior\ninformation on the spatial correlation structure of the diffuse component and\nthe brightness distribution of the spatially uncorrelated point-like sources. A\nmaximum a posteriori solution and a solution minimizing the Gibbs free energy\nof the inference problem using variational Bayesian methods are discussed.\nSince the derivation of the solution is not dependent on the underlying\nposition space, the implementation of the D3PO algorithm uses the NIFTY package\nto ensure applicability to various spatial grids and at any resolution. The\nfidelity of the algorithm is validated by the analysis of simulated data,\nincluding a realistic high energy photon count image showing a 32 x 32 arcmin^2\nobservation with a spatial resolution of 0.1 arcmin. In all tests the D3PO\nalgorithm successfully denoised, deconvolved, and decomposed the data into a\ndiffuse and a point-like signal estimate for the respective photon flux\ncomponents.\n", "contributors": [{"name": "Selig, Marco", "sameAs": [], "familyName": "Selig", "additionalName": "", "givenName": "Marco", "email": ""}, {"name": "En\u00dflin, Torsten", "sameAs": [], "familyName": "En\u00dflin", "additionalName": "", "givenName": "Torsten", "email": ""}], "title": "D$^3$PO - Denoising, Deconvolving, and Decomposing Photon Observations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-11-08", "2015-01-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1311.1888", "A&A 574, A74 (2015)", "doi:10.1051/0004-6361/201323006", "oai:arXiv.org:1311.1888"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:astro-ph", "physics:physics", "stat"]}}, {"name": "description", "properties": {"description": ["  The analysis of astronomical images is a non-trivial task. The D3PO algorithm\naddresses the inference problem of denoising, deconvolving, and decomposing\nphoton observations. Its primary goal is the simultaneous but individual\nreconstruction of the diffuse and point-like photon flux given a single photon\ncount image, where the fluxes are superimposed. In order to discriminate\nbetween these morphologically different signal components, a probabilistic\nalgorithm is derived in the language of information field theory based on a\nhierarchical Bayesian parameter model. The signal inference exploits prior\ninformation on the spatial correlation structure of the diffuse component and\nthe brightness distribution of the spatially uncorrelated point-like sources. A\nmaximum a posteriori solution and a solution minimizing the Gibbs free energy\nof the inference problem using variational Bayesian methods are discussed.\nSince the derivation of the solution is not dependent on the underlying\nposition space, the implementation of the D3PO algorithm uses the NIFTY package\nto ensure applicability to various spatial grids and at any resolution. The\nfidelity of the algorithm is validated by the analysis of simulated data,\nincluding a realistic high energy photon count image showing a 32 x 32 arcmin^2\nobservation with a spatial resolution of 0.1 arcmin. In all tests the D3PO\nalgorithm successfully denoised, deconvolved, and decomposed the data into a\ndiffuse and a point-like signal estimate for the respective photon flux\ncomponents.\n", "Comment: 22 pages, 8 figures, 2 tables, accepted by Astronomy & Astrophysics;\n  refereed version, 1 figure added, results unchanged, software available at\n  http://www.mpa-garching.mpg.de/ift/d3po/"]}}], "languages": [null], "subjects": ["statistics and probability", "statistics - computation", "computer science - information theory", "astrophysics - instrumentation and methods for astrophysics", "physics - data analysis"], "providerUpdatedDateTime": "2015-01-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1311.1888"}}, {"publisher": {"name": ""}, "description": "  Inspired by the chemical metaphor, this paper proposes an extension of\nLinda-like languages in the aim of modeling the coordination of complex\ndistributed systems. The new language manipulates finite sets of tuples and\ndistributes a density among them. This new concept adds to the non-determinism\ninherent in the selection of matched tuples a non-determinism to the tell, ask\nand get primitives on the consideration of different tuples. Furthermore,\nthanks to de Boer and Palamidessi's notion of modular embedding, we establish\nthat this new language strictly increases the expressiveness of the Dense Bach\nlanguage introduced earlier and, consequently, Linda-like languages.\n", "contributors": [{"name": "Darquennes, Denis", "sameAs": [], "familyName": "Darquennes", "additionalName": "", "givenName": "Denis", "email": ""}, {"name": "Jacquet, Jean-Marie", "sameAs": [], "familyName": "Jacquet", "additionalName": "", "givenName": "Jean-Marie", "email": ""}, {"name": "Linden, Isabelle", "sameAs": [], "familyName": "Linden", "additionalName": "", "givenName": "Isabelle", "email": ""}], "title": "On Distributed Density in Tuple-based Coordination Languages", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.03513", "EPTCS 175, 2015, pp. 36-53", "doi:10.4204/EPTCS.175.3", "oai:arXiv.org:1502.03513"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Inspired by the chemical metaphor, this paper proposes an extension of\nLinda-like languages in the aim of modeling the coordination of complex\ndistributed systems. The new language manipulates finite sets of tuples and\ndistributes a density among them. This new concept adds to the non-determinism\ninherent in the selection of matched tuples a non-determinism to the tell, ask\nand get primitives on the consideration of different tuples. Furthermore,\nthanks to de Boer and Palamidessi's notion of modular embedding, we establish\nthat this new language strictly increases the expressiveness of the Dense Bach\nlanguage introduced earlier and, consequently, Linda-like languages.\n", "Comment: In Proceedings FOCLASA 2014, arXiv:1502.03157"]}}], "languages": [null], "subjects": ["d.3.2", "computer science - multiagent systems", "f.1.2", "and cluster computing", "d.1.3", "computer science - distributed", "computer science - programming languages", "parallel"], "providerUpdatedDateTime": "2015-02-13T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.03513"}}, {"publisher": {"name": ""}, "description": "  We show that unconverged stochastic gradient descent can be interpreted as a\nprocedure that samples from a nonparametric variational approximate posterior\ndistribution. This distribution is implicitly defined as the transformation of\nan initial distribution by a sequence of optimization updates. By tracking the\nchange in entropy over this sequence of transformations during optimization, we\nform a scalable, unbiased estimate of the variational lower bound on the log\nmarginal likelihood. We can use this bound to optimize hyperparameters instead\nof using cross-validation. This Bayesian interpretation of SGD suggests\nimproved, overfitting-resistant optimization procedures, and gives a\ntheoretical foundation for popular tricks such as early stopping and\nensembling. We investigate the properties of this marginal likelihood estimator\non neural network models.\n", "contributors": [{"name": "Maclaurin, Dougal", "sameAs": [], "familyName": "Maclaurin", "additionalName": "", "givenName": "Dougal", "email": ""}, {"name": "Duvenaud, David", "sameAs": [], "familyName": "Duvenaud", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Adams, Ryan P.", "sameAs": [], "familyName": "Adams", "additionalName": "P.", "givenName": "Ryan", "email": ""}], "title": "Early Stopping is Nonparametric Variational Inference", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01344", "oai:arXiv.org:1504.01344"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  We show that unconverged stochastic gradient descent can be interpreted as a\nprocedure that samples from a nonparametric variational approximate posterior\ndistribution. This distribution is implicitly defined as the transformation of\nan initial distribution by a sequence of optimization updates. By tracking the\nchange in entropy over this sequence of transformations during optimization, we\nform a scalable, unbiased estimate of the variational lower bound on the log\nmarginal likelihood. We can use this bound to optimize hyperparameters instead\nof using cross-validation. This Bayesian interpretation of SGD suggests\nimproved, overfitting-resistant optimization procedures, and gives a\ntheoretical foundation for popular tricks such as early stopping and\nensembling. We investigate the properties of this marginal likelihood estimator\non neural network models.\n", "Comment: 8 pages, 5 figures"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01344"}}, {"publisher": {"name": ""}, "description": "  This paper divide some complexity class by using fixpoint of Decidable\nUniversal Turing Machine (UTM). Decidable Deterministic Turing Machine (DTM)\nhave fixpointless combinator that add no extra resources (like Negation), but\nUTM makes some fixpoint in the combinator if UTM Target DTM set close under the\ncombinator. This means that we can jump out of the fixpointless combinator\nsystem by making more complex problem with UTM and diagonal method.\n  We proof that L is not P as concrete example. We can make Polynomial time UTM\nthat emulate all Logarithm space DTM (LDTM). LDTM set close under Negation,\ntherefore UTM does not close under LDTM set. We can proof this theorem like\nhalting problem and time/space hierarchy theorem. We can extend this proof to\ndivide time/space limited DTM set. These are new hierarchy that use UTM and\nNegation.\n  As appendix, We proof P is not NP by using P is not L.\n", "contributors": [{"name": "Kobayashi, Koji", "sameAs": [], "familyName": "Kobayashi", "additionalName": "", "givenName": "Koji", "email": ""}], "title": "Small Jump with Negation-UTM Trampoline", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-12-05", "2014-10-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1112.0987", "oai:arXiv.org:1112.0987"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper divide some complexity class by using fixpoint of Decidable\nUniversal Turing Machine (UTM). Decidable Deterministic Turing Machine (DTM)\nhave fixpointless combinator that add no extra resources (like Negation), but\nUTM makes some fixpoint in the combinator if UTM Target DTM set close under the\ncombinator. This means that we can jump out of the fixpointless combinator\nsystem by making more complex problem with UTM and diagonal method.\n  We proof that L is not P as concrete example. We can make Polynomial time UTM\nthat emulate all Logarithm space DTM (LDTM). LDTM set close under Negation,\ntherefore UTM does not close under LDTM set. We can proof this theorem like\nhalting problem and time/space hierarchy theorem. We can extend this proof to\ndivide time/space limited DTM set. These are new hierarchy that use UTM and\nNegation.\n  As appendix, We proof P is not NP by using P is not L.\n", "Comment: 3 pages"]}}], "languages": [null], "subjects": ["computer science - computational complexity"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1112.0987"}}, {"publisher": {"name": ""}, "description": "  We consider the problem of tracking with small relative error an integer\nfunction $f(n)$ defined by a distributed update stream $f'(n)$. Existing\nstreaming algorithms with worst-case guarantees for this problem assume $f(n)$\nto be monotone; there are very large lower bounds on the space requirements for\nsummarizing a distributed non-monotonic stream, often linear in the size $n$ of\nthe stream.\n  Input streams that give rise to large space requirements are highly variable,\nmaking relatively large jumps from one timestep to the next. However, streams\noften vary slowly in practice. What has heretofore been lacking is a framework\nfor non-monotonic streams that admits algorithms whose worst-case performance\nis as good as existing algorithms for monotone streams and degrades gracefully\nfor non-monotonic streams as those streams vary more quickly.\n  In this paper we propose such a framework. We introduce a new stream\nparameter, the \"variability\" $v$, deriving its definition in a way that shows\nit to be a natural parameter to consider for non-monotonic streams. It is also\na useful parameter. From a theoretical perspective, we can adapt existing\nalgorithms for monotone streams to work for non-monotonic streams, with only\nminor modifications, in such a way that they reduce to the monotone case when\nthe stream happens to be monotone, and in such a way that we can refine the\nworst-case communication bounds from $\\Theta(n)$ to $\\tilde{O}(v)$. From a\npractical perspective, we demonstrate that $v$ can be small in practice by\nproving that $v$ is $O(\\log f(n))$ for monotone streams and $o(n)$ for streams\nthat are \"nearly\" monotone or that are generated by random walks. We expect $v$\nto be $o(n)$ for many other interesting input classes as well.\n", "contributors": [{"name": "Felber, David", "sameAs": [], "familyName": "Felber", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Ostrovsky, Rafail", "sameAs": [], "familyName": "Ostrovsky", "additionalName": "", "givenName": "Rafail", "email": ""}], "title": "Variability in data streams", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07027", "oai:arXiv.org:1502.07027"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We consider the problem of tracking with small relative error an integer\nfunction $f(n)$ defined by a distributed update stream $f'(n)$. Existing\nstreaming algorithms with worst-case guarantees for this problem assume $f(n)$\nto be monotone; there are very large lower bounds on the space requirements for\nsummarizing a distributed non-monotonic stream, often linear in the size $n$ of\nthe stream.\n  Input streams that give rise to large space requirements are highly variable,\nmaking relatively large jumps from one timestep to the next. However, streams\noften vary slowly in practice. What has heretofore been lacking is a framework\nfor non-monotonic streams that admits algorithms whose worst-case performance\nis as good as existing algorithms for monotone streams and degrades gracefully\nfor non-monotonic streams as those streams vary more quickly.\n  In this paper we propose such a framework. We introduce a new stream\nparameter, the \"variability\" $v$, deriving its definition in a way that shows\nit to be a natural parameter to consider for non-monotonic streams. It is also\na useful parameter. From a theoretical perspective, we can adapt existing\nalgorithms for monotone streams to work for non-monotonic streams, with only\nminor modifications, in such a way that they reduce to the monotone case when\nthe stream happens to be monotone, and in such a way that we can refine the\nworst-case communication bounds from $\\Theta(n)$ to $\\tilde{O}(v)$. From a\npractical perspective, we demonstrate that $v$ can be small in practice by\nproving that $v$ is $O(\\log f(n))$ for monotone streams and $o(n)$ for streams\nthat are \"nearly\" monotone or that are generated by random walks. We expect $v$\nto be $o(n)$ for many other interesting input classes as well.\n", "Comment: submitted to ICALP 2015 (here, fullpage formatting)"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07027"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "This thesis explores the evolving nature of independent music practices in the context of offline and online social networks. The pivotal role of social networks in the cultural production of music is first examined by treating an independent record label of the post-punk era as an offline social network. This develops a useful framework for then considering the similar and distinctive ways in which contemporary independent practices are enabled and/or shaped by online social networks. Analysis is based on close, comparative readings of the structures and affordances of two case studies: the UK-based Rough Trade record label (1978 - 1991) and MySpace (2003 - present). Numerous examples of artists and their practices are drawn upon to illustrate how discursive meanings of independence are negotiated within each network. Investigated are potentials for realizing not only autonomy from the mainstream music industry, but also a range of other post-punk ideals tied to a broader independent ethos concerned with issues of access and participation, artistic control and freedom, as well as desires to engender more diverse music cultures. The intersection of offline and online networks in the context of today's dynamic, transitional music industry further provides new opportunities for more meaningful artist-to-artist, artist-to-fan, and artist-to-company/label interactions. By emphasizing the centrality of social networks, conceptions of autonomous, \"do-it-yourself\" music making are problematized in favor of \"do-it-together\" understandings that foreground cooperation.", "contributors": [{"name": "Wendel, Evan Landon", "sameAs": [], "familyName": "Wendel", "additionalName": "Landon", "givenName": "Evan", "email": ""}, {"name": "Massachusetts Institute of Technology. Dept. of Comparative Media Studies.", "sameAs": [], "familyName": "Studies.", "additionalName": "Institute of Technology. Dept. of Comparative Media", "givenName": "Massachusetts", "email": ""}, {"name": "William Uricchio.", "sameAs": [], "familyName": "Uricchio.", "additionalName": "", "givenName": "William", "email": ""}], "title": "New potentials for \"independent\" music : social networks, old and new, and the ongoing struggles to reshape the music industry", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "112 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/43197", "256929823", "oai:dspace.mit.edu:1721.1/43197"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2008-11-07T19:14:35Z", "2008-11-07T19:14:35Z", "2008", "2008"]}}, {"name": "description", "properties": {"description": ["This thesis explores the evolving nature of independent music practices in the context of offline and online social networks. The pivotal role of social networks in the cultural production of music is first examined by treating an independent record label of the post-punk era as an offline social network. This develops a useful framework for then considering the similar and distinctive ways in which contemporary independent practices are enabled and/or shaped by online social networks. Analysis is based on close, comparative readings of the structures and affordances of two case studies: the UK-based Rough Trade record label (1978 - 1991) and MySpace (2003 - present). Numerous examples of artists and their practices are drawn upon to illustrate how discursive meanings of independence are negotiated within each network. Investigated are potentials for realizing not only autonomy from the mainstream music industry, but also a range of other post-punk ideals tied to a broader independent ethos concerned with issues of access and participation, artistic control and freedom, as well as desires to engender more diverse music cultures. The intersection of offline and online networks in the context of today's dynamic, transitional music industry further provides new opportunities for more meaningful artist-to-artist, artist-to-fan, and artist-to-company/label interactions. By emphasizing the centrality of social networks, conceptions of autonomous, \"do-it-yourself\" music making are problematized in favor of \"do-it-together\" understandings that foreground cooperation.", "by Evan Landon Wendel.", "Thesis (S.M.)--Massachusetts Institute of Technology, Dept. of Comparative Media Studies, 2008.", "Includes bibliographical references (p. 105-111)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39100", "hdl_1721.1_39097"]}}], "languages": [null], "subjects": ["comparative media studies."], "providerUpdatedDateTime": "2015-04-27T14:44:36", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/43197"}}, {"publisher": {"name": ""}, "description": "  Many inference problems involve inferring the number $N$ of objects in some\nregion, along with their properties $\\{\\mathbf{x}_i\\}_{i=1}^N$, from a dataset\n$\\mathcal{D}$. A common statistical example is finite mixture modelling. In the\nBayesian framework, these problems are typically solved using one of the\nfollowing two methods: i) by executing a Monte Carlo algorithm (such as Nested\nSampling) once for each possible value of $N$, and calculating the marginal\nlikelihood or evidence as a function of $N$; or ii) by doing a single run that\nallows the model dimension $N$ to change (such as Markov Chain Monte Carlo with\nbirth/death moves), and obtaining the posterior for $N$ directly. In this paper\nwe present a general approach to this problem that uses trans-dimensional MCMC\nembedded {\\it within} a Nested Sampling algorithm, allowing us to explore the\nposterior distribution and calculate the marginal likelihood (summed over $N$)\neven if the problem contains a phase transition or other difficult features\nsuch as multimodality. We present two example problems, finding sinusoidal\nsignals in noisy data, and finding and measuring galaxies in a noisy\nastronomical image. Both of the examples demonstrate phase transitions in the\nrelationship between the likelihood and the cumulative prior mass.\n", "contributors": [{"name": "Brewer, Brendon J.", "sameAs": [], "familyName": "Brewer", "additionalName": "J.", "givenName": "Brendon", "email": ""}], "title": "Inference for Trans-dimensional Bayesian Models with Diffusive Nested\n  Sampling", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-14", "2014-11-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3921", "oai:arXiv.org:1411.3921"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:astro-ph", "physics:physics", "stat"]}}, {"name": "description", "properties": {"description": ["  Many inference problems involve inferring the number $N$ of objects in some\nregion, along with their properties $\\{\\mathbf{x}_i\\}_{i=1}^N$, from a dataset\n$\\mathcal{D}$. A common statistical example is finite mixture modelling. In the\nBayesian framework, these problems are typically solved using one of the\nfollowing two methods: i) by executing a Monte Carlo algorithm (such as Nested\nSampling) once for each possible value of $N$, and calculating the marginal\nlikelihood or evidence as a function of $N$; or ii) by doing a single run that\nallows the model dimension $N$ to change (such as Markov Chain Monte Carlo with\nbirth/death moves), and obtaining the posterior for $N$ directly. In this paper\nwe present a general approach to this problem that uses trans-dimensional MCMC\nembedded {\\it within} a Nested Sampling algorithm, allowing us to explore the\nposterior distribution and calculate the marginal likelihood (summed over $N$)\neven if the problem contains a phase transition or other difficult features\nsuch as multimodality. We present two example problems, finding sinusoidal\nsignals in noisy data, and finding and measuring galaxies in a noisy\nastronomical image. Both of the examples demonstrate phase transitions in the\nrelationship between the likelihood and the cumulative prior mass.\n", "Comment: Submitted. Comments welcome. 14 pages, 7 figures. Software available\n  at https://github.com/eggplantbren/RJObject"]}}], "languages": [null], "subjects": ["statistics - computation", "statistics and probability", "astrophysics - instrumentation and methods for astrophysics", "physics - data analysis"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3921"}}, {"publisher": {"name": ""}, "description": "  Estimating the difficulty level of math word problems is an important task\nfor many educational applications. Identification of relevant and irrelevant\nsentences in math word problems is an important step for calculating the\ndifficulty levels of such problems. This paper addresses a novel application of\ntext categorization to identify two types of sentences in mathematical word\nproblems, namely relevant and irrelevant sentences. A novel joint probabilistic\nclassification model is proposed to estimate the joint probability of\nclassification decisions for all sentences of a math word problem by utilizing\nthe correlation among all sentences along with the correlation between the\nquestion sentence and other sentences, and sentence text. The proposed model is\ncompared with i) a SVM classifier which makes independent classification\ndecisions for individual sentences by only using the sentence text and ii) a\nnovel SVM classifier that considers the correlation between the question\nsentence and other sentences along with the sentence text. An extensive set of\nexperiments demonstrates the effectiveness of the joint probabilistic\nclassification model for identifying relevant and irrelevant sentences as well\nas the novel SVM classifier that utilizes the correlation between the question\nsentence and other sentences. Furthermore, empirical results and analysis show\nthat i) it is highly beneficial not to remove stopwords and ii) utilizing part\nof speech tagging does not make a significant improvement although it has been\nshown to be effective for the related task of math word problem type\nclassification.\n", "contributors": [{"name": "Cetintas, Suleyman", "sameAs": [], "familyName": "Cetintas", "additionalName": "", "givenName": "Suleyman", "email": ""}, {"name": "Si, Luo", "sameAs": [], "familyName": "Si", "additionalName": "", "givenName": "Luo", "email": ""}, {"name": "Xin, Yan Ping", "sameAs": [], "familyName": "Xin", "additionalName": "Ping", "givenName": "Yan", "email": ""}, {"name": "Zhang, Dake", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Dake", "email": ""}, {"name": "Park, Joo Young", "sameAs": [], "familyName": "Park", "additionalName": "Young", "givenName": "Joo", "email": ""}, {"name": "Tzur, Ron", "sameAs": [], "familyName": "Tzur", "additionalName": "", "givenName": "Ron", "email": ""}], "title": "A Joint Probabilistic Classification Model of Relevant and Irrelevant\n  Sentences in Mathematical Word Problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5732", "oai:arXiv.org:1411.5732"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Estimating the difficulty level of math word problems is an important task\nfor many educational applications. Identification of relevant and irrelevant\nsentences in math word problems is an important step for calculating the\ndifficulty levels of such problems. This paper addresses a novel application of\ntext categorization to identify two types of sentences in mathematical word\nproblems, namely relevant and irrelevant sentences. A novel joint probabilistic\nclassification model is proposed to estimate the joint probability of\nclassification decisions for all sentences of a math word problem by utilizing\nthe correlation among all sentences along with the correlation between the\nquestion sentence and other sentences, and sentence text. The proposed model is\ncompared with i) a SVM classifier which makes independent classification\ndecisions for individual sentences by only using the sentence text and ii) a\nnovel SVM classifier that considers the correlation between the question\nsentence and other sentences along with the sentence text. An extensive set of\nexperiments demonstrates the effectiveness of the joint probabilistic\nclassification model for identifying relevant and irrelevant sentences as well\nas the novel SVM classifier that utilizes the correlation between the question\nsentence and other sentences. Furthermore, empirical results and analysis show\nthat i) it is highly beneficial not to remove stopwords and ii) utilizing part\nof speech tagging does not make a significant improvement although it has been\nshown to be effective for the related task of math word problem type\nclassification.\n", "Comment: appears in Journal of Educational Data Mining (JEDM, 2010)"]}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - computation and language", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-11-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5732"}}, {"publisher": {"name": ""}, "description": "  The development and evolution of malware including computer viruses, worms,\nand trojan horses, is shown to be closely analogous to the process of community\nsuccession long recognized in ecology. In particular, both changes in the\noverall environment by external disturbances, as well as, feedback effects from\nmalware competition and antivirus coevolution have driven community succession\nand the development of different types of malware with varying modes of\ntransmission and adaptability.\n", "contributors": [{"name": "Smith, Reginald D.", "sameAs": [], "familyName": "Smith", "additionalName": "D.", "givenName": "Reginald", "email": ""}], "title": "Malware \"Ecology\" Viewed as Ecological Succession: Historical Trends and\n  Future Prospects", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-09-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.8082", "oai:arXiv.org:1410.8082"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-bio"]}}, {"name": "description", "properties": {"description": ["  The development and evolution of malware including computer viruses, worms,\nand trojan horses, is shown to be closely analogous to the process of community\nsuccession long recognized in ecology. In particular, both changes in the\noverall environment by external disturbances, as well as, feedback effects from\nmalware competition and antivirus coevolution have driven community succession\nand the development of different types of malware with varying modes of\ntransmission and adaptability.\n", "Comment: 13 pages, 3 figures"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "quantitative biology - populations and evolution"], "providerUpdatedDateTime": "2014-10-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.8082"}}, {"publisher": {"name": ""}, "description": "  String diagrams are a powerful tool for reasoning about composite structures\nin symmetric monoidal categories. By representing string diagrams as graphs,\nequational reasoning can be done automatically by double-pushout rewriting.\n!-graphs give us the means of expressing and proving properties about whole\nfamilies of these graphs simultaneously. While !-graphs provide elegant proofs\nof surprisingly powerful theorems, little is known about the formal properties\nof the graph languages they define. This paper takes the first step in\ncharacterising these languages by showing that an important subclass of\n!-graphs\u00c3\u00a2\u00c2\u0080\u00c2\u0094those whose repeated structures only overlap trivially\u00c3\u00a2\u00c2\u0080\u00c2\u0094can be encoded\nusing a (context-free) vertex replacement grammar.\n", "contributors": [{"name": "Kissinger, Aleks", "sameAs": [], "familyName": "Kissinger", "additionalName": "", "givenName": "Aleks", "email": ""}, {"name": "Zamdzhiev, Vladimir", "sameAs": [], "familyName": "Zamdzhiev", "additionalName": "", "givenName": "Vladimir", "email": ""}], "title": "!-Graphs with Trivial Overlap are Context-Free", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-24", "2015-04-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06059", "EPTCS 181, 2015, pp. 16-31", "doi:10.4204/EPTCS.181.2", "oai:arXiv.org:1501.06059"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  String diagrams are a powerful tool for reasoning about composite structures\nin symmetric monoidal categories. By representing string diagrams as graphs,\nequational reasoning can be done automatically by double-pushout rewriting.\n!-graphs give us the means of expressing and proving properties about whole\nfamilies of these graphs simultaneously. While !-graphs provide elegant proofs\nof surprisingly powerful theorems, little is known about the formal properties\nof the graph languages they define. This paper takes the first step in\ncharacterising these languages by showing that an important subclass of\n!-graphs\u00c3\u00a2\u00c2\u0080\u00c2\u0094those whose repeated structures only overlap trivially\u00c3\u00a2\u00c2\u0080\u00c2\u0094can be encoded\nusing a (context-free) vertex replacement grammar.\n", "Comment: In Proceedings GaM 2015, arXiv:1504.02448"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory", "computer science - logic in computer science", "mathematics - category theory"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06059"}}, {"publisher": {"name": ""}, "description": "  Considering congestion games with uncertain delays, we compute the\ninefficiency introduced in network routing by risk-averse agents. At\nequilibrium, agents may select paths that do not minimize the expected latency\nto obtain lower variability. A social planner, who is likely to be more risk\nneutral than agents because it operates at a longer time-scale, quantifies\nsocial cost with the total expected delay along routes. From that perspective,\nagents may make suboptimal decisions that degrade long-term quality. We define\nthe price of risk aversion (PRA) as the worst-case ratio of the social cost at\na risk-averse Wardrop equilibrium to that where agents are risk-neutral. For\nnetworks with arbitrary delays and a single source-sink pair, we show that the\nPRA depends linearly on the agents' risk tolerance and on the degree of\nvariability present in the network. In contrast to the price of anarchy, in\ngeneral the PRA increases when the network gets larger but does not depend on\nthe shape of the delay functions. To get this result we rely on a combinatorial\nproof that employs alternating paths that are reminiscent of those used in\nmax-flow algorithms. Restricting topologies to the class of series-parallel\n(SP) graphs, the PRA is independent of the network topology and its size. As a\npartial result of independent interest, we prove that for SP networks with\ndeterministic delays, among all feasible flows, Wardrop equilibria maximize the\nshortest path objective.\n", "contributors": [{"name": "Nikolova, E.", "sameAs": [], "familyName": "Nikolova", "additionalName": "", "givenName": "E.", "email": ""}, {"name": "Stier-Moses, N.", "sameAs": [], "familyName": "Stier-Moses", "additionalName": "", "givenName": "N.", "email": ""}], "title": "The Burden of Risk Aversion in Mean-Risk Selfish Routing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-31"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0059", "oai:arXiv.org:1411.0059"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Considering congestion games with uncertain delays, we compute the\ninefficiency introduced in network routing by risk-averse agents. At\nequilibrium, agents may select paths that do not minimize the expected latency\nto obtain lower variability. A social planner, who is likely to be more risk\nneutral than agents because it operates at a longer time-scale, quantifies\nsocial cost with the total expected delay along routes. From that perspective,\nagents may make suboptimal decisions that degrade long-term quality. We define\nthe price of risk aversion (PRA) as the worst-case ratio of the social cost at\na risk-averse Wardrop equilibrium to that where agents are risk-neutral. For\nnetworks with arbitrary delays and a single source-sink pair, we show that the\nPRA depends linearly on the agents' risk tolerance and on the degree of\nvariability present in the network. In contrast to the price of anarchy, in\ngeneral the PRA increases when the network gets larger but does not depend on\nthe shape of the delay functions. To get this result we rely on a combinatorial\nproof that employs alternating paths that are reminiscent of those used in\nmax-flow algorithms. Restricting topologies to the class of series-parallel\n(SP) graphs, the PRA is independent of the network topology and its size. As a\npartial result of independent interest, we prove that for SP networks with\ndeterministic delays, among all feasible flows, Wardrop equilibria maximize the\nshortest path objective.\n", "Comment: 21 pages, 4 figures"]}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2014-11-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0059"}}, {"publisher": {"name": ""}, "description": "  Inference in general Ising models is difficult, due to high treewidth making\ntree-based algorithms intractable. Moreover, when interactions are strong,\nGibbs sampling may take exponential time to converge to the stationary\ndistribution. We present an algorithm to project Ising model parameters onto a\nparameter set that is guaranteed to be fast mixing, under several divergences.\nWe find that Gibbs sampling using the projected parameters is more accurate\nthan with the original parameters when interaction strengths are strong and\nwhen limited time is available for sampling.\n", "contributors": [{"name": "Domke, Justin", "sameAs": [], "familyName": "Domke", "additionalName": "", "givenName": "Justin", "email": ""}, {"name": "Liu, Xianghang", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Xianghang", "email": ""}], "title": "Projecting Ising Model Parameters for Fast Mixing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-02", "2014-10-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.0749", "oai:arXiv.org:1407.0749"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Inference in general Ising models is difficult, due to high treewidth making\ntree-based algorithms intractable. Moreover, when interactions are strong,\nGibbs sampling may take exponential time to converge to the stationary\ndistribution. We present an algorithm to project Ising model parameters onto a\nparameter set that is guaranteed to be fast mixing, under several divergences.\nWe find that Gibbs sampling using the projected parameters is more accurate\nthan with the original parameters when interaction strengths are strong and\nwhen limited time is available for sampling.\n", "Comment: Advances in Neural Information Processing Systems 2013"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.0749"}}, {"publisher": {"name": ""}, "description": "  We present a new type of polyominoes that can have transparent squares\n(holes). We show how these polyominoes can tile rectangles and we categorise\nthem according to their tiling ability. We were able to categorise all but 7\npolyominoes with 5 or fewer visible squares.\n", "contributors": [{"name": "Kamenetsky, Dmitry", "sameAs": [], "familyName": "Kamenetsky", "additionalName": "", "givenName": "Dmitry", "email": ""}, {"name": "Cooke, Tristrom", "sameAs": [], "familyName": "Cooke", "additionalName": "", "givenName": "Tristrom", "email": ""}], "title": "Tiling rectangles with holey polyominoes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-10"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2699", "oai:arXiv.org:1411.2699"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We present a new type of polyominoes that can have transparent squares\n(holes). We show how these polyominoes can tile rectangles and we categorise\nthem according to their tiling ability. We were able to categorise all but 7\npolyominoes with 5 or fewer visible squares.\n", "Comment: 23 pages"]}}], "languages": [null], "subjects": ["g.2.1", "05-02", "computer science - computational geometry"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2699"}}, {"publisher": {"name": ""}, "description": "  The reproduction and replication of novel results has become a major issue\nfor a number of scientific disciplines. In computer science and related\ncomputational disciplines such as systems biology, the issues closely revolve\naround the ability to implement novel algorithms and models. Taking an approach\nfrom the literature and applying it to a new codebase frequently requires local\nknowledge missing from the published manuscripts and project websites.\nAlongside this issue, benchmarking, and the development of fair -- and publicly\navailable -- benchmark sets present another barrier.\n  In this paper, we outline several suggestions to address these issues, driven\nby specific examples from a range of scientific domains. Finally, based on\nthese suggestions, we propose a new open automated platform for scientific\nsoftware development which effectively abstracts specific dependencies from the\nindividual researcher and their workstation, allowing easy sharing and\nreproduction of results. This new cyberinfrastructure for computational science\noffers the potential to incentivise a culture change and drive the adoption of\nnew techniques to improve the efficiency of scientific exploration.\n", "contributors": [{"name": "Crick, Tom", "sameAs": [], "familyName": "Crick", "additionalName": "", "givenName": "Tom", "email": ""}, {"name": "Ishtiaq, Samin", "sameAs": [], "familyName": "Ishtiaq", "additionalName": "", "givenName": "Samin", "email": ""}, {"name": "Hall, Benjamin A.", "sameAs": [], "familyName": "Hall", "additionalName": "A.", "givenName": "Benjamin", "email": ""}], "title": "Towards \"Reproducibility-as-a-Service\"", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02388", "oai:arXiv.org:1503.02388"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The reproduction and replication of novel results has become a major issue\nfor a number of scientific disciplines. In computer science and related\ncomputational disciplines such as systems biology, the issues closely revolve\naround the ability to implement novel algorithms and models. Taking an approach\nfrom the literature and applying it to a new codebase frequently requires local\nknowledge missing from the published manuscripts and project websites.\nAlongside this issue, benchmarking, and the development of fair -- and publicly\navailable -- benchmark sets present another barrier.\n  In this paper, we outline several suggestions to address these issues, driven\nby specific examples from a range of scientific domains. Finally, based on\nthese suggestions, we propose a new open automated platform for scientific\nsoftware development which effectively abstracts specific dependencies from the\nindividual researcher and their workstation, allowing easy sharing and\nreproduction of results. This new cyberinfrastructure for computational science\noffers the potential to incentivise a culture change and drive the adoption of\nnew techniques to improve the efficiency of scientific exploration.\n", "Comment: Invited submission to Journal of Open Research Software; 10 pages,\n  LaTeX"]}}], "languages": [null], "subjects": ["computer science - computers and society", "computer science - computational engineering", "computer science - software engineering", "and science", "finance"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02388"}}, {"publisher": {"name": ""}, "description": "  We prove that two algebraic embeddings of a smooth variety $X$ in\n$\\mathbb{C}^m$ are the same up to a holomorphic coordinate change, provided\nthat $2 \\dim X + 1$ is smaller than or equal to $m$. This improves an algebraic\nresult of Nori and Srinivas. For the proof we extend a technique of Kaliman\nusing generic linear projections of $\\mathbb{C}^m$.\n", "contributors": [{"name": "Feller, Peter", "sameAs": [], "familyName": "Feller", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Stampfli, Immanuel", "sameAs": [], "familyName": "Stampfli", "additionalName": "", "givenName": "Immanuel", "email": ""}], "title": "Holomorphically Equivalent Algebraic Embeddings", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-25", "2014-10-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.7319", "oai:arXiv.org:1409.7319"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  We prove that two algebraic embeddings of a smooth variety $X$ in\n$\\mathbb{C}^m$ are the same up to a holomorphic coordinate change, provided\nthat $2 \\dim X + 1$ is smaller than or equal to $m$. This improves an algebraic\nresult of Nori and Srinivas. For the proof we extend a technique of Kaliman\nusing generic linear projections of $\\mathbb{C}^m$.\n", "Comment: 17 pages. Version 2 acknowledges the fact that the main result of\n  this paper was previously established by Kaliman, see\n  http://arxiv.org/abs/1309.3791"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.7319"}}, {"publisher": {"name": ""}, "description": "  Advertisement (abbreviated ad) options are a recent development in online\nadvertising. Simply, an ad option is a contract in which a publisher or search\nengine grants an advertiser a right but not obligation to enter into\ntransactions to purchase impressions or clicks from a specific ad slot at a\npre-specified price on a specific delivery date. Such a structure provides\nadvertisers with more flexibility of their guaranteed deliveries. The valuation\nof ad options is an important topic and previous studies on ad options pricing\nhave been mostly restricted to the situations where the underlying prices\nfollow a geometric Brownian motion (GBM). This assumption is reasonable for\nsponsored search; however, some studies have also indicated that it is not\nvalid for display advertising. In this paper, we address this issue by\nemploying a stochastic volatility (SV) model and discuss a lattice framework to\napproximate the proposed SV model in option pricing. Our developments are\nvalidated by experiments with real advertising data: (i) we find that the SV\nmodel has a better fitness over the GBM model; (ii) we validate the proposed\nlattice model via two sequential Monte Carlo simulation methods; (iii) we\ndemonstrate that advertisers are able to flexibly manage their guaranteed\ndeliveries by using the proposed options, and publishers can have an increased\nrevenue when some of their inventories are sold via ad options.\n", "contributors": [{"name": "Chen, Bowei", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Bowei", "email": ""}, {"name": "Wang, Jun", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Jun", "email": ""}], "title": "A Lattice Framework for Pricing Display Ad Options with the Stochastic\n  Volatility Underlying Model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-02", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.0697", "oai:arXiv.org:1409.0697"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "q-fin"]}}, {"name": "description", "properties": {"description": ["  Advertisement (abbreviated ad) options are a recent development in online\nadvertising. Simply, an ad option is a contract in which a publisher or search\nengine grants an advertiser a right but not obligation to enter into\ntransactions to purchase impressions or clicks from a specific ad slot at a\npre-specified price on a specific delivery date. Such a structure provides\nadvertisers with more flexibility of their guaranteed deliveries. The valuation\nof ad options is an important topic and previous studies on ad options pricing\nhave been mostly restricted to the situations where the underlying prices\nfollow a geometric Brownian motion (GBM). This assumption is reasonable for\nsponsored search; however, some studies have also indicated that it is not\nvalid for display advertising. In this paper, we address this issue by\nemploying a stochastic volatility (SV) model and discuss a lattice framework to\napproximate the proposed SV model in option pricing. Our developments are\nvalidated by experiments with real advertising data: (i) we find that the SV\nmodel has a better fitness over the GBM model; (ii) we validate the proposed\nlattice model via two sequential Monte Carlo simulation methods; (iii) we\ndemonstrate that advertisers are able to flexibly manage their guaranteed\ndeliveries by using the proposed options, and publishers can have an increased\nrevenue when some of their inventories are sold via ad options.\n", "Comment: 23 pages, working paper"]}}], "languages": [null], "subjects": ["computer science - computer science and game theory", "quantitative finance - computational finance"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.0697"}}, {"publisher": {"name": ""}, "description": "  Existing document filtering systems learn user profiles based on user\nrelevance feedback on documents. In some cases, users may have prior knowledge\nabout what features are important. For example, a Spanish speaker may only want\nnews written in Spanish, and thus a relevant document should contain the\nfeature \"Language: Spanish\"; a researcher focusing on HIV knows an article with\nthe medical subject \"Subject: AIDS\" is very likely to be relevant to him/her.\n  Semi-structured documents with rich metadata are increasingly prevalent on\nthe Internet. Motivated by the well-adopted faceted search interface in\ne-commerce, we study the exploitation of user prior knowledge on faceted\nfeatures for semi-structured document filtering. We envision two faceted\nfeedback mechanisms, and propose a novel user profile learning algorithm that\ncan incorporate user feedback on features. To evaluate the proposed work, we\nuse two data sets from the TREC filtering track, and conduct a user study on\nAmazon Mechanical Turk. Our experiment results show that user feedback on\nfaceted features is useful for filtering. The proposed user profile learning\nalgorithm can effectively learn from user feedback on both documents and\nfeatures, and performs better than several existing methods.\n", "contributors": [{"name": "Zhang, Lanbo", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Lanbo", "email": ""}, {"name": "Zhang, Yi", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Yi", "email": ""}, {"name": "Xing, Qianli", "sameAs": [], "familyName": "Xing", "additionalName": "", "givenName": "Qianli", "email": ""}], "title": "Learning from Labeled Features for Document Filtering", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-28"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.8125", "oai:arXiv.org:1412.8125"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Existing document filtering systems learn user profiles based on user\nrelevance feedback on documents. In some cases, users may have prior knowledge\nabout what features are important. For example, a Spanish speaker may only want\nnews written in Spanish, and thus a relevant document should contain the\nfeature \"Language: Spanish\"; a researcher focusing on HIV knows an article with\nthe medical subject \"Subject: AIDS\" is very likely to be relevant to him/her.\n  Semi-structured documents with rich metadata are increasingly prevalent on\nthe Internet. Motivated by the well-adopted faceted search interface in\ne-commerce, we study the exploitation of user prior knowledge on faceted\nfeatures for semi-structured document filtering. We envision two faceted\nfeedback mechanisms, and propose a novel user profile learning algorithm that\ncan incorporate user feedback on features. To evaluate the proposed work, we\nuse two data sets from the TREC filtering track, and conduct a user study on\nAmazon Mechanical Turk. Our experiment results show that user feedback on\nfaceted features is useful for filtering. The proposed user profile learning\nalgorithm can effectively learn from user feedback on both documents and\nfeatures, and performs better than several existing methods.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.8125"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "The mammalian accessory olfactory system is specialized for the detection of chemicals that identify kin and conspecifics. Vomeronasal sensory neurons (VSNs) residing in the vomeronasal organ project axons to the accessory olfactory bulb (AOB), where they form synapses with principal neurons known as mitral cells. The organization of this projection is quite precise and is believed to be essential for appropriate function of this system. However, how this precise connectivity is established is unknown. We show here that in mice the vomeronasal duct is open at birth, allowing external chemical stimuli access to sensory neurons, and that these sensory neurons are capable of releasing neurotransmitter to downstream neurons as early as the first postnatal day (P). Using major histocompatibility complex class I peptides to activate a selective subset of VSNs during the first few postnatal days of development, we show that increased activity results in exuberant VSN axonal projections and a delay in axonal coalescence into well defined glomeruli in the AOB. Finally, we show that mitral cell dendritic refinement occurs just after the coalescence of presynaptic axons. Such a mechanism may allow the formation of precise connectivity with specific glomeruli that receive input from sensory neurons expressing the same receptor type.", "contributors": [{"name": "Hovis, Kenneth R.", "sameAs": [], "familyName": "Hovis", "additionalName": "R.", "givenName": "Kenneth", "email": ""}, {"name": "Ramnath, Rohit", "sameAs": [], "familyName": "Ramnath", "additionalName": "", "givenName": "Rohit", "email": ""}, {"name": "Dahlen, Jeffrey E.", "sameAs": [], "familyName": "Dahlen", "additionalName": "E.", "givenName": "Jeffrey", "email": ""}, {"name": "Romanova, Anna L.", "sameAs": [], "familyName": "Romanova", "additionalName": "L.", "givenName": "Anna", "email": ""}, {"name": "LaRocca, Greg", "sameAs": [], "familyName": "LaRocca", "additionalName": "", "givenName": "Greg", "email": ""}, {"name": "Bier, Mark E.", "sameAs": [], "familyName": "Bier", "additionalName": "E.", "givenName": "Mark", "email": ""}, {"name": "Urban, Nathaniel N.", "sameAs": [], "familyName": "Urban", "additionalName": "N.", "givenName": "Nathaniel", "email": ""}], "title": "Activity regulates functional connectivity from the vomeronasal organ to the accessory olfactory bulb.", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2012-06-06T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/biology/461", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1468&amp;context=biology", "oai:repository.cmu.edu:biology-1468"]}}, {"name": "setSpec", "properties": {"setSpec": "publication:biology"}}, {"name": "description", "properties": {"description": "The mammalian accessory olfactory system is specialized for the detection of chemicals that identify kin and conspecifics. Vomeronasal sensory neurons (VSNs) residing in the vomeronasal organ project axons to the accessory olfactory bulb (AOB), where they form synapses with principal neurons known as mitral cells. The organization of this projection is quite precise and is believed to be essential for appropriate function of this system. However, how this precise connectivity is established is unknown. We show here that in mice the vomeronasal duct is open at birth, allowing external chemical stimuli access to sensory neurons, and that these sensory neurons are capable of releasing neurotransmitter to downstream neurons as early as the first postnatal day (P). Using major histocompatibility complex class I peptides to activate a selective subset of VSNs during the first few postnatal days of development, we show that increased activity results in exuberant VSN axonal projections and a delay in axonal coalescence into well defined glomeruli in the AOB. Finally, we show that mitral cell dendritic refinement occurs just after the coalescence of presynaptic axons. Such a mechanism may allow the formation of precise connectivity with specific glomeruli that receive input from sensory neurons expressing the same receptor type."}}], "languages": [null], "subjects": ["olfactory bulb", "mhc class i", "biology", "receptors", "female", "patch-clamp techniques", "image processing", "vomeronasal organ", "neuropeptides", "olfactory receptor neurons", "computer-assisted", "gene expression", "electroporation", "immunohistochemistry", "presynaptic", "axons", "genes", "proto-oncogene proteins c-fos", "freeze drying", "mice", "animals", "smell", "transgenic", "microscopy", "confocal", "dendrites", "neural pathways", "male"], "providerUpdatedDateTime": "2014-10-28T19:52:16", "uris": {"canonicalUri": "http://repository.cmu.edu/biology/461"}}, {"publisher": {"name": ""}, "description": "  The Multiple Depot Ring-Star Problem (MDRSP) is an important combinatorial\noptimization problem that arises in the context of optical fiber network\ndesign, and in applications pertaining to collecting data using stationary\nsensing devices and autonomous vehicles. Given the locations of a set of\ncustomers and a set of depots, the goal is to (i) find a set of simple cycles\nsuch that each cycle (ring) passes through a subset of customers and exactly\none depot, (ii) assign each non-visited customer to a visited customer or a\ndepot, and (iii) minimize the sum of the routing costs, i.e., the cost of the\ncycles and the assignment costs. We present a mixed integer linear programming\nformulation for the MDRSP and propose valid inequalities to strengthen the\nlinear programming relaxation. Furthermore, we present a polyhedral analysis\nand derive facet-inducing results for the MDRSP. All these results are then\nused to develop a branch-and-cut algorithm to obtain optimal solutions to the\nMDRSP. The performance of the branch-and-cut algorithm is evaluated through\nextensive computational experiments on several classes of test instances.\n", "contributors": [{"name": "Sundar, Kaarthik", "sameAs": [], "familyName": "Sundar", "additionalName": "", "givenName": "Kaarthik", "email": ""}, {"name": "Rathinam, Sivakumar", "sameAs": [], "familyName": "Rathinam", "additionalName": "", "givenName": "Sivakumar", "email": ""}], "title": "Multiple Depot Ring Star Problem: A polyhedral study and exact algorithm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-07-18", "2014-10-15"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.5080", "oai:arXiv.org:1407.5080"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The Multiple Depot Ring-Star Problem (MDRSP) is an important combinatorial\noptimization problem that arises in the context of optical fiber network\ndesign, and in applications pertaining to collecting data using stationary\nsensing devices and autonomous vehicles. Given the locations of a set of\ncustomers and a set of depots, the goal is to (i) find a set of simple cycles\nsuch that each cycle (ring) passes through a subset of customers and exactly\none depot, (ii) assign each non-visited customer to a visited customer or a\ndepot, and (iii) minimize the sum of the routing costs, i.e., the cost of the\ncycles and the assignment costs. We present a mixed integer linear programming\nformulation for the MDRSP and propose valid inequalities to strengthen the\nlinear programming relaxation. Furthermore, we present a polyhedral analysis\nand derive facet-inducing results for the MDRSP. All these results are then\nused to develop a branch-and-cut algorithm to obtain optimal solutions to the\nMDRSP. The performance of the branch-and-cut algorithm is evaluated through\nextensive computational experiments on several classes of test instances.\n", "Comment: Submitted to Optimization Letters"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - systems and control"], "providerUpdatedDateTime": "2014-10-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.5080"}}, {"publisher": {"name": ""}, "description": "  There has been rapidly growing interest in studying and designing online\ndeliberative processes and technologies. This SIG aims at providing a venue for\ncontinuous and constructive dialogue between social, political and cognitive\nsciences as well as computer science, HCI, and CSCW. Through an online\ncommunity and a modified version of world cafe discussions, we contribute to\nthe definition of the theoretical building blocks, the identification of a\nresearch agenda for the CHI community, and the network of individuals from\nacademia, industry, and the public sector who share interests in different\naspects of online deliberation.\n", "contributors": [{"name": "Xiao, Lu", "sameAs": [], "familyName": "Xiao", "additionalName": "", "givenName": "Lu", "email": ""}, {"name": "Zhang, Weiyu", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Weiyu", "email": ""}, {"name": "Przybylska, Anna", "sameAs": [], "familyName": "Przybylska", "additionalName": "", "givenName": "Anna", "email": ""}, {"name": "De Liddo, Anna", "sameAs": [], "familyName": "De Liddo", "additionalName": "", "givenName": "Anna", "email": ""}, {"name": "Convertino, Gregorio", "sameAs": [], "familyName": "Convertino", "additionalName": "", "givenName": "Gregorio", "email": ""}, {"name": "Davies, Todd", "sameAs": [], "familyName": "Davies", "additionalName": "", "givenName": "Todd", "email": ""}, {"name": "Klein, Mark", "sameAs": [], "familyName": "Klein", "additionalName": "", "givenName": "Mark", "email": ""}], "title": "Design for Online Deliberative Processes and Technologies: Towards a\n  Multidisciplinary Research Agenda", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-03", "2015-03-04"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01145", "doi:10.1145/2702613.2727687", "oai:arXiv.org:1503.01145"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  There has been rapidly growing interest in studying and designing online\ndeliberative processes and technologies. This SIG aims at providing a venue for\ncontinuous and constructive dialogue between social, political and cognitive\nsciences as well as computer science, HCI, and CSCW. Through an online\ncommunity and a modified version of world cafe discussions, we contribute to\nthe definition of the theoretical building blocks, the identification of a\nresearch agenda for the CHI community, and the network of individuals from\nacademia, industry, and the public sector who share interests in different\naspects of online deliberation.\n", "Comment: CHI'15 Extended Abstracts, Apr 18-23, 2015, Seoul, Republic of Korea,\n  ACM 978-1-4503-3146-3/15/04, 4 pages"]}}], "languages": [null], "subjects": ["k.4.3", "computer science - human-computer interaction", "k.4.1", "h.5.3"], "providerUpdatedDateTime": "2015-03-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01145"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "We propose a new fast algorithm for approximate MAP inference on factor graphs, which combines augmented Lagrangian optimization with the dual decomposition method. Each slave subproblem is given a quadratic penalty, which pushes toward faster consensus than in previous subgradient approaches. Our algorithm is provably convergent, parallelizable, and suitable for fine decompositions of the graph. We show how it can efficiently handle problems with (possibly global) structural constraints via simple sort operations. Experiments on synthetic and real-world data show that our approach compares favorably with the state-of-the-art.", "contributors": [{"name": "Martins, Andre F.T.", "sameAs": [], "familyName": "Martins", "additionalName": "F.T.", "givenName": "Andre", "email": ""}, {"name": "Figeuiredo, Mario A. T.", "sameAs": [], "familyName": "Figeuiredo", "additionalName": "A. T.", "givenName": "Mario", "email": ""}, {"name": "Aguiar, Pedro M.Q.", "sameAs": [], "familyName": "Aguiar", "additionalName": "M.Q.", "givenName": "Pedro", "email": ""}, {"name": "Smith, Noah A.", "sameAs": [], "familyName": "Smith", "additionalName": "A.", "givenName": "Noah", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "An Augmented Lagrangian Approach to Constrained MAP Inference", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2011-06-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/213", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1211&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1211"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "We propose a new fast algorithm for approximate MAP inference on factor graphs, which combines augmented Lagrangian optimization with the dual decomposition method. Each slave subproblem is given a quadratic penalty, which pushes toward faster consensus than in previous subgradient approaches. Our algorithm is provably convergent, parallelizable, and suitable for fine decompositions of the graph. We show how it can efficiently handle problems with (possibly global) structural constraints via simple sort operations. Experiments on synthetic and real-world data show that our approach compares favorably with the state-of-the-art."}}], "languages": [null], "subjects": ["computer sciences", "theory and algorithms"], "providerUpdatedDateTime": "2015-04-08T21:48:26", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/213"}}, {"publisher": {"name": ""}, "description": "abstract: In many classication problems data samples cannot be collected easily, example in drug trials, biological experiments and study on cancer patients. In many situations the data set size is small and there are many outliers. When classifying such data, example cancer vs normal patients the consequences of mis-classication are probably more important than any other data type, because the data point could be a cancer patient or the classication decision could help determine what gene might be over expressed and perhaps a cause of cancer. These mis-classications are typically higher in the presence of outlier data points. The aim of this thesis is to develop a maximum margin classier that is suited to address the lack of robustness of discriminant based classiers (like the Support Vector Machine (SVM)) to noise and outliers. The underlying notion is to adopt and develop a natural loss function that is more robust to outliers and more representative of the true loss function of the data. It is demonstrated experimentally that SVM's are indeed susceptible to outliers and that the new classier developed, here coined as Robust-SVM (RSVM), is superior to all studied classier on the synthetic datasets. It is superior to the SVM in both the synthetic and experimental data from biomedical studies and is competent to a classier derived on similar lines when real life data examples are considered.", "contributors": [{"name": "Gupta, Sidharth  (Author)", "sameAs": [], "familyName": "Gupta", "additionalName": "", "givenName": "Sidharth", "email": ""}, {"name": "Kim, Seungchan  (Advisor)", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Seungchan", "email": ""}, {"name": "Welfert, Bruno  (Committee member)", "sameAs": [], "familyName": "Welfert", "additionalName": "", "givenName": "Bruno", "email": ""}, {"name": "Li, Baoxin  (Committee member)", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Baoxin", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Robust Margin Based Classifiers For Small Sample Data", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Masters Thesis"}}, {"name": "format", "properties": {"format": "46 pages"}}, {"name": "date", "properties": {"date": "2011"}}, {"name": "description", "properties": {"description": ["abstract: In many classication problems data samples cannot be collected easily, example in drug trials, biological experiments and study on cancer patients. In many situations the data set size is small and there are many outliers. When classifying such data, example cancer vs normal patients the consequences of mis-classication are probably more important than any other data type, because the data point could be a cancer patient or the classication decision could help determine what gene might be over expressed and perhaps a cause of cancer. These mis-classications are typically higher in the presence of outlier data points. The aim of this thesis is to develop a maximum margin classier that is suited to address the lack of robustness of discriminant based classiers (like the Support Vector Machine (SVM)) to noise and outliers. The underlying notion is to adopt and develop a natural loss function that is more robust to outliers and more representative of the true loss function of the data. It is demonstrated experimentally that SVM's are indeed susceptible to outliers and that the new classier developed, here coined as Robust-SVM (RSVM), is superior to all studied classier on the synthetic datasets. It is superior to the SVM in both the synthetic and experimental data from biomedical studies and is competent to a classier derived on similar lines when real life data examples are considered.", "Dissertation/Thesis", "Source Code for RSVM(MATLAB)", "Presentation on RSVM", "M.S. Computer Science 2011"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.9162", "item:9162"]}}], "languages": [null], "subjects": ["overfitting", "small sample", "rsvm", "statistics", "svm", "computer science", "bioinformatics", "classifier"], "providerUpdatedDateTime": "2015-02-12T01:08:46", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.9162"}}, {"publisher": {"name": ""}, "description": "  We study the problem of the transmission of currently observed time variable\nsignals via a channel that is capable of sending a single binary signal only\nfor each measurement of the underlying process. For encoding and decoding, we\nsuggest a modification othe adaptive delta modulation algorithm. This\nmodification ensures tracking of time variable signals. We obtained upper\nestimates for the error for the case of noiseless transmission.\n", "contributors": [{"name": "Dokuchaev, Nikolai", "sameAs": [], "familyName": "Dokuchaev", "additionalName": "", "givenName": "Nikolai", "email": ""}], "title": "Transmission of a continuous signal via one-bit capacity channel", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-12", "2014-12-29"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.3507", "oai:arXiv.org:1312.3507"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We study the problem of the transmission of currently observed time variable\nsignals via a channel that is capable of sending a single binary signal only\nfor each measurement of the underlying process. For encoding and decoding, we\nsuggest a modification othe adaptive delta modulation algorithm. This\nmodification ensures tracking of time variable signals. We obtained upper\nestimates for the error for the case of noiseless transmission.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "94a12", "computer science - information theory", "94a40"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.3507"}}, {"publisher": {"name": ""}, "description": "  This note establishes smooth approximation from above for J-plurisubharmonic\nfunctions on an almost complex manifold (X,J). The following theorem is proved.\nSuppose X is J-pseudoconvex, i.e., X admits a smooth strictly\nJ-plurisubharmonic exhaustion function. Let u be an (upper semi-continuous)\nJ-plurisubharmonic function on X. Then there exists a sequence {u_j} of smooth,\nstrictly J-plurisubharmonic functions point-wise decreasing down to u.\n  On any almost complex manifold (X,J) each point has a fundamental\nneighborhood system of J-pseudoconvex domains, and so the theorem above\nestablishes local smooth approximation on X.\n  This result was proved in complex dimension 2 by the third author, who also\nshowed that the result would hold in general dimensions if a parallel result\nfor continuous approximation were known. This paper establishes the required\nstep by solving the obstacle problem.\n", "contributors": [{"name": "Harvey, F. Reese", "sameAs": [], "familyName": "Harvey", "additionalName": "Reese", "givenName": "F.", "email": ""}, {"name": "Lawson, Jr., H. Blaine", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Lawson", "email": ""}, {"name": "Pli\u015b, Szymon", "sameAs": [], "familyName": "Pli\u015b", "additionalName": "", "givenName": "Szymon", "email": ""}], "title": "Smooth Approximation of Plurisubharmonic Functions on Almost Complex\n  Manifolds", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-26"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7137", "oai:arXiv.org:1411.7137"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": "  This note establishes smooth approximation from above for J-plurisubharmonic\nfunctions on an almost complex manifold (X,J). The following theorem is proved.\nSuppose X is J-pseudoconvex, i.e., X admits a smooth strictly\nJ-plurisubharmonic exhaustion function. Let u be an (upper semi-continuous)\nJ-plurisubharmonic function on X. Then there exists a sequence {u_j} of smooth,\nstrictly J-plurisubharmonic functions point-wise decreasing down to u.\n  On any almost complex manifold (X,J) each point has a fundamental\nneighborhood system of J-pseudoconvex domains, and so the theorem above\nestablishes local smooth approximation on X.\n  This result was proved in complex dimension 2 by the third author, who also\nshowed that the result would hold in general dimensions if a parallel result\nfor continuous approximation were known. This paper establishes the required\nstep by solving the obstacle problem.\n"}}], "languages": [null], "subjects": ["32e99", "32q60", "mathematics - complex variables", "mathematics - symplectic geometry", "53d99", "32u05", "31c10", "32u15", "mathematics - differential geometry"], "providerUpdatedDateTime": "2014-11-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7137"}}, {"publisher": {"name": ""}, "description": "  Devaney and Krych showed that for $0<\\lambda<1/e$ the Julia set of $\\lambda\ne^z$ consists of pairwise disjoint curves, called hairs, which connect finite\npoints, called the endpoints of the hairs, with $\\infty$. McMullen showed that\nthe Julia set has Hausdorff dimension $2$ and Karpi\\'nska showed that the set\nof hairs without endpoints has Hausdorff dimension $1$. We study for which\ngauge functions the Hausdorff measure of the set of hairs without endpoints is\nfinite.\n", "contributors": [{"name": "Bergweiler, Walter", "sameAs": [], "familyName": "Bergweiler", "additionalName": "", "givenName": "Walter", "email": ""}, {"name": "Wang, Jun", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Jun", "email": ""}], "title": "Hausdorff measure of hairs without endpoints in the exponential family", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01961", "oai:arXiv.org:1502.01961"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  Devaney and Krych showed that for $0<\\lambda<1/e$ the Julia set of $\\lambda\ne^z$ consists of pairwise disjoint curves, called hairs, which connect finite\npoints, called the endpoints of the hairs, with $\\infty$. McMullen showed that\nthe Julia set has Hausdorff dimension $2$ and Karpi\\'nska showed that the set\nof hairs without endpoints has Hausdorff dimension $1$. We study for which\ngauge functions the Hausdorff measure of the set of hairs without endpoints is\nfinite.\n", "Comment: 18 pages"]}}], "languages": [null], "subjects": ["37f10", "30d05", "mathematics - dynamical systems", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01961"}}, {"publisher": {"name": ""}, "description": "  One long-standing question in epidemiological research is how best to\nallocate limited amounts of vaccine or similar preventative measures in order\nto minimize the severity of an epidemic. Much of the literature on the problem\nof vaccine allocation has focused on influenza epidemics and used mathematical\nmodels of epidemic spread to determine the effectiveness of proposed methods.\nOur work applies computational models of epidemics to the problem of\ngeographically allocating a limited number of vaccines within several Texas\ncounties. We developed a graph-based, stochastic model for epidemics that is\nbased on the SEIR model, and tested vaccine allocation methods based on\nmultiple centrality measures. This approach provides an alternative method for\naddressing the vaccine allocation problem, which can be combined with more\nconventional approaches to yield more effective epidemic suppression\nstrategies. We found that allocation methods based on in-degree and inverse\nbetweenness centralities tended to be the most effective at containing\nepidemics.\n", "contributors": [{"name": "Drewniak, Krzysztof", "sameAs": [], "familyName": "Drewniak", "additionalName": "", "givenName": "Krzysztof", "email": ""}, {"name": "Helsing, Joseph", "sameAs": [], "familyName": "Helsing", "additionalName": "", "givenName": "Joseph", "email": ""}, {"name": "Mikler, Armin R.", "sameAs": [], "familyName": "Mikler", "additionalName": "R.", "givenName": "Armin", "email": ""}], "title": "A Method for Reducing the Severity of Epidemics by Allocating Vaccines\n  According to Centrality", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-07-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.7288", "doi:10.1145/2649387.2649409", "oai:arXiv.org:1407.7288"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  One long-standing question in epidemiological research is how best to\nallocate limited amounts of vaccine or similar preventative measures in order\nto minimize the severity of an epidemic. Much of the literature on the problem\nof vaccine allocation has focused on influenza epidemics and used mathematical\nmodels of epidemic spread to determine the effectiveness of proposed methods.\nOur work applies computational models of epidemics to the problem of\ngeographically allocating a limited number of vaccines within several Texas\ncounties. We developed a graph-based, stochastic model for epidemics that is\nbased on the SEIR model, and tested vaccine allocation methods based on\nmultiple centrality measures. This approach provides an alternative method for\naddressing the vaccine allocation problem, which can be combined with more\nconventional approaches to yield more effective epidemic suppression\nstrategies. We found that allocation methods based on in-degree and inverse\nbetweenness centralities tended to be the most effective at containing\nepidemics.\n", "Comment: 10 pages, accepted to ACM BCB 2014"]}}], "languages": [null], "subjects": ["j.3", "g.2.2", "finance", "and science", "computer science - social and information networks", "physics - physics and society", "computer science - computational engineering"], "providerUpdatedDateTime": "2014-12-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.7288"}}, {"publisher": {"name": ""}, "description": "  For every Gaussian network, there exists a corresponding deterministic\nnetwork called the discrete superposition network. We show that this discrete\nsuperposition network provides a near-optimal digital interface for operating a\nclass consisting of many Gaussian networks in the sense that any code for the\ndiscrete superposition network can be naturally lifted to a corresponding code\nfor the Gaussian network, while achieving a rate that is no more than a\nconstant number of bits lesser than the rate it achieves for the discrete\nsuperposition network. This constant depends only on the number of nodes in the\nnetwork and not on the channel gains or SNR. Moreover the capacities of the two\nnetworks are within a constant of each other, again independent of channel\ngains and SNR. We show that the class of Gaussian networks for which this\ninterface property holds includes relay networks with a single\nsource-destination pair, interference networks, multicast networks, and the\ncounterparts of these networks with multiple transmit and receive antennas.\n  The code for the Gaussian relay network can be obtained from any code for the\ndiscrete superposition network simply by pruning it. This lifting scheme\nestablishes that the superposition model can indeed potentially serve as a\nstrong surrogate for designing codes for Gaussian relay networks.\n  We present similar results for the K x K Gaussian interference network, MIMO\nGaussian interference networks, MIMO Gaussian relay networks, and multicast\nnetworks, with the constant gap depending additionally on the number of\nantennas in case of MIMO networks.\n", "contributors": [{"name": "Anand, M.", "sameAs": [], "familyName": "Anand", "additionalName": "", "givenName": "M.", "email": ""}, {"name": "Kumar, P. R.", "sameAs": [], "familyName": "Kumar", "additionalName": "R.", "givenName": "P.", "email": ""}], "title": "A digital interface for Gaussian relay and interference networks:\n  Lifting codes from the discrete superposition model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-05-02", "2011-05-20"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.0167", "Special issue on interference Networks, IEEE Trans. Info. Theory,\n  vol. 57, no. 5, pp. 2548 - 2564, May 2011", "doi:10.1109/TIT.2011.2120070", "oai:arXiv.org:1005.0167"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  For every Gaussian network, there exists a corresponding deterministic\nnetwork called the discrete superposition network. We show that this discrete\nsuperposition network provides a near-optimal digital interface for operating a\nclass consisting of many Gaussian networks in the sense that any code for the\ndiscrete superposition network can be naturally lifted to a corresponding code\nfor the Gaussian network, while achieving a rate that is no more than a\nconstant number of bits lesser than the rate it achieves for the discrete\nsuperposition network. This constant depends only on the number of nodes in the\nnetwork and not on the channel gains or SNR. Moreover the capacities of the two\nnetworks are within a constant of each other, again independent of channel\ngains and SNR. We show that the class of Gaussian networks for which this\ninterface property holds includes relay networks with a single\nsource-destination pair, interference networks, multicast networks, and the\ncounterparts of these networks with multiple transmit and receive antennas.\n  The code for the Gaussian relay network can be obtained from any code for the\ndiscrete superposition network simply by pruning it. This lifting scheme\nestablishes that the superposition model can indeed potentially serve as a\nstrong surrogate for designing codes for Gaussian relay networks.\n  We present similar results for the K x K Gaussian interference network, MIMO\nGaussian interference networks, MIMO Gaussian relay networks, and multicast\nnetworks, with the constant gap depending additionally on the number of\nantennas in case of MIMO networks.\n", "Comment: Final version"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.0167"}}, {"publisher": {"name": ""}, "description": "  Vehicular communication channels are characterized by a non-stationary time-\nand frequency-selective fading process due to fast changes in the environment.\nWe characterize the distribution of the envelope of the first delay bin in\nvehicle-to-vehicle channels by means of its Rician $K$-factor. We analyze the\ntime-frequency variability of this channel parameter using vehicular channel\nmeasurements at 5.6 GHz with a bandwidth of 240 MHz for safety-relevant\nscenarios in intelligent transportation systems (ITS). This data enables a\nfrequency-variability analysis from an IEEE 802.11p system point of view, which\nuses 10 MHz channels. We show that the small-scale fading of the envelope of\nthe first delay bin is Ricean distributed with a varying $K$-factor. The later\ndelay bins are Rayleigh distributed. We demonstrate that the $K$-factor cannot\nbe assumed to be constant in time and frequency. The causes of these variations\nare the frequency-varying antenna radiation patterns as well as the\ntime-varying number of active scatterers, and the effects of vegetation. We\nalso present a simple but accurate bi-modal Gaussian mixture model, that allows\nto capture the $K$-factor variability in time for safety-relevant ITS\nscenarios.\n", "contributors": [{"name": "Bernad\u00f3, Laura", "sameAs": [], "familyName": "Bernad\u00f3", "additionalName": "", "givenName": "Laura", "email": ""}, {"name": "Zemen, Thomas", "sameAs": [], "familyName": "Zemen", "additionalName": "", "givenName": "Thomas", "email": ""}, {"name": "Tufvesson, Fredrik", "sameAs": [], "familyName": "Tufvesson", "additionalName": "", "givenName": "Fredrik", "email": ""}, {"name": "Molisch, Andreas F.", "sameAs": [], "familyName": "Molisch", "additionalName": "F.", "givenName": "Andreas", "email": ""}, {"name": "Mecklenbr\u00e4uker, Christoph F.", "sameAs": [], "familyName": "Mecklenbr\u00e4uker", "additionalName": "F.", "givenName": "Christoph", "email": ""}], "title": "Time- and Frequency-Varying $K$-Factor of Non-Stationary Vehicular\n  Channels for Safety Relevant Scenarios", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-17", "2014-04-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.3914", "IEEE Transactions on Intelligent Transportation Systems, vol. 16,\n  no. 2, April 2015", "doi:10.1109/TITS.2014.2349364", "oai:arXiv.org:1306.3914"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Vehicular communication channels are characterized by a non-stationary time-\nand frequency-selective fading process due to fast changes in the environment.\nWe characterize the distribution of the envelope of the first delay bin in\nvehicle-to-vehicle channels by means of its Rician $K$-factor. We analyze the\ntime-frequency variability of this channel parameter using vehicular channel\nmeasurements at 5.6 GHz with a bandwidth of 240 MHz for safety-relevant\nscenarios in intelligent transportation systems (ITS). This data enables a\nfrequency-variability analysis from an IEEE 802.11p system point of view, which\nuses 10 MHz channels. We show that the small-scale fading of the envelope of\nthe first delay bin is Ricean distributed with a varying $K$-factor. The later\ndelay bins are Rayleigh distributed. We demonstrate that the $K$-factor cannot\nbe assumed to be constant in time and frequency. The causes of these variations\nare the frequency-varying antenna radiation patterns as well as the\ntime-varying number of active scatterers, and the effects of vegetation. We\nalso present a simple but accurate bi-modal Gaussian mixture model, that allows\nto capture the $K$-factor variability in time for safety-relevant ITS\nscenarios.\n", "Comment: 26 pages, 12 figures, submitted to IEEE Transactions on Intelligent\n  Transportation Systems for possible publication"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-04-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.3914"}}, {"publisher": {"name": ""}, "description": "  This paper compares the Value--at--Risk (VaR) forecasts delivered by\nalternative model specifications using the Model Confidence Set (MCS) procedure\nrecently developed by Hansen et al. (2011). The direct VaR estimate provided by\nthe Conditional Autoregressive Value--at--Risk (CAViaR) models of Eengle and\nManganelli (2004) are compared to those obtained by the popular Autoregressive\nConditional Heteroskedasticity (ARCH) models of Engle (1982) and to the\nrecently introduced Generalised Autoregressive Score (GAS) models of Creal et\nal. (2013) and Harvey (2013). The Hansen's procedure consists on a sequence of\ntests which permits to construct a set of \"superior\" models, where the null\nhypothesis of Equal Predictive Ability (EPA) is not rejected at a certain\nconfidence level. Our empirical results, suggest that, after the Global\nFinancial Crisis (GFC) of 2007-2008, highly non-linear volatility models\ndeliver better VaR forecasts for the European countries as opposed to other\nregions. The R package MCS is introduced for performing the model comparisons\nwhose main features are discussed throughout the paper.\n", "contributors": [{"name": "Bernardi, Mauro", "sameAs": [], "familyName": "Bernardi", "additionalName": "", "givenName": "Mauro", "email": ""}, {"name": "Catania, Leopoldo", "sameAs": [], "familyName": "Catania", "additionalName": "", "givenName": "Leopoldo", "email": ""}], "title": "Comparison of Value-at-Risk models: the MCS package", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04472", "oai:arXiv.org:1502.04472"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": ["  This paper compares the Value--at--Risk (VaR) forecasts delivered by\nalternative model specifications using the Model Confidence Set (MCS) procedure\nrecently developed by Hansen et al. (2011). The direct VaR estimate provided by\nthe Conditional Autoregressive Value--at--Risk (CAViaR) models of Eengle and\nManganelli (2004) are compared to those obtained by the popular Autoregressive\nConditional Heteroskedasticity (ARCH) models of Engle (1982) and to the\nrecently introduced Generalised Autoregressive Score (GAS) models of Creal et\nal. (2013) and Harvey (2013). The Hansen's procedure consists on a sequence of\ntests which permits to construct a set of \"superior\" models, where the null\nhypothesis of Equal Predictive Ability (EPA) is not rejected at a certain\nconfidence level. Our empirical results, suggest that, after the Global\nFinancial Crisis (GFC) of 2007-2008, highly non-linear volatility models\ndeliver better VaR forecasts for the European countries as opposed to other\nregions. The R package MCS is introduced for performing the model comparisons\nwhose main features are discussed throughout the paper.\n", "Comment: 25 pages. arXiv admin note: substantial text overlap with\n  arXiv:1410.8504"]}}], "languages": [null], "subjects": ["statistics - computation"], "providerUpdatedDateTime": "2015-02-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04472"}}, {"publisher": {"name": ""}, "description": "  The achievable and converse regions for sparse representation of white\nGaussian noise based on an overcomplete dictionary are derived in the limit of\nlarge systems. Furthermore, the marginal distribution of such sparse\nrepresentations is also inferred. The results are obtained via the Replica\nmethod which stems from statistical mechanics. A direct outcome of these\nresults is the introduction of sharp threshold for $\\ell_{0}$-norm decoding in\nnoisy compressed sensing, and its mean-square error for underdetermined\nGaussian vector channels.\n", "contributors": [{"name": "Shental, Ori", "sameAs": [], "familyName": "Shental", "additionalName": "", "givenName": "Ori", "email": ""}], "title": "Sparse Representation of White Gaussian Noise with Application to\n  L0-Norm Decoding in Noisy Compressed Sensing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-12", "2011-12-20"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.2215", "oai:arXiv.org:1104.2215"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The achievable and converse regions for sparse representation of white\nGaussian noise based on an overcomplete dictionary are derived in the limit of\nlarge systems. Furthermore, the marginal distribution of such sparse\nrepresentations is also inferred. The results are obtained via the Replica\nmethod which stems from statistical mechanics. A direct outcome of these\nresults is the introduction of sharp threshold for $\\ell_{0}$-norm decoding in\nnoisy compressed sensing, and its mean-square error for underdetermined\nGaussian vector channels.\n", "Comment: VER1"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.2215"}}, {"publisher": {"name": "Virginia Tech"}, "description": "Reticulitermids were significantly more likely to discover subterranean baits connected by physical guidelines than freestanding baits under both laboratory and field conditions.  In the laboratory, subterranean termites built significantly longer tunnels adjacent to cellulosic guidelines than plastic guidelines.   In the field, all guideline materials were equally effective at directing tunneling activity.   Reticulitermes spp. workers were tested to determine their preferred substrate temperature.  The preferred range for Reticulitermes spp. workers was found to be 18 to 27 degrees C.   A laboratory bioassay was performed to determine if Reticulitermes spp. aggregates within thermal shadows.  Significantly more Reticulitermes spp. workers aggregated within cool thermal shadows than control areas.   In a multiple choice bioassay, mean consumption was higher for paper baits treated with fructose, galactose, glucose, raffinose, sucrose, trehalose and uric acid than for control baits.  In a multiple choice bioassay, mean consumption was significantly lower for baits treated with arbutin, and most amino acids than for control baits.  In the no-choice bioassay, the amount of paper bait consumed did not differ significantly for any of the treated baits tested and control baits.", "contributors": [{"name": "Swoboda, Lois Elizabeth", "sameAs": [], "familyName": "Swoboda", "additionalName": "Elizabeth", "givenName": "Lois", "email": ""}, {"name": "Fell, Richard D.", "sameAs": [], "familyName": "Fell", "additionalName": "D.", "givenName": "Richard", "email": ""}, {"name": "Weaver, Michael J.", "sameAs": [], "familyName": "Weaver", "additionalName": "J.", "givenName": "Michael", "email": ""}, {"name": "Mullins, Donald E.", "sameAs": [], "familyName": "Mullins", "additionalName": "E.", "givenName": "Donald", "email": ""}, {"name": "Miller, Dini M.", "sameAs": [], "familyName": "Miller", "additionalName": "M.", "givenName": "Dini", "email": ""}, {"name": "Schabenberger, Oliver", "sameAs": [], "familyName": "Schabenberger", "additionalName": "", "givenName": "Oliver", "email": ""}, {"name": "Entomology", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Entomology", "email": ""}], "title": "Environmental Influences on Subterranean Termite Foraging Behavior and Bait Acceptance", "shareProperties": {"source": "vtech"}, "otherProperties": [{"name": "type", "properties": {"type": "Other - Dissertation"}}, {"name": "source", "properties": {"source": "http://scholar.lib.vt.edu/theses/available/etd-05262004-184108"}}, {"name": "format", "properties": {"format": "ETD"}}, {"name": "date", "properties": {"date": ["2011-08-22T19:02:28Z", "2011-08-22T19:02:28Z", "2004-07-06"]}}, {"name": "identifier", "properties": {"identifier": ["etd-05262004-184108", "http://hdl.handle.net/10919/11205", "oai:vtechworks.lib.vt.edu:10919/11205"]}}, {"name": "setSpec", "properties": {"setSpec": ["com_10919_5534", "col_10919_11041"]}}, {"name": "rights", "properties": {"rights": "The authors of the theses and dissertations are the copyright owners.  Virginia Tech's Digital Library and Archives has their permission to store and provide access to these works."}}, {"name": "relation", "properties": {"relation": "Onefilegood.pdf"}}], "languages": [null], "subjects": ["foraging", "temperature", "nutrients", "subterranean termites", "wood thermoplastic composites", "physical guidelines"], "providerUpdatedDateTime": "2015-03-24T12:02:47", "uris": {"canonicalUri": "http://hdl.handle.net/10919/11205"}}, {"publisher": {"name": ""}, "description": "  Often, when analyzing the behaviour of systems modelled as context-free\nlanguages, we wish to know if two languages overlap. To this end, we present an\neffective semi-decision procedure for regular separability of context-free\nlanguages, based on counter-example guided abstraction refinement. We propose\ntwo refinement methods, one inexpensive but incomplete, and the other complete\nbut more expensive. We provide an experimental evaluation of this procedure,\nand demonstrate its practicality on a range of verification and\nlanguage-theoretic instances.\n", "contributors": [{"name": "Gange, Graeme", "sameAs": [], "familyName": "Gange", "additionalName": "", "givenName": "Graeme", "email": ""}, {"name": "Navas, Jorge A.", "sameAs": [], "familyName": "Navas", "additionalName": "A.", "givenName": "Jorge", "email": ""}, {"name": "Schachte, Peter", "sameAs": [], "familyName": "Schachte", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Sondergaard, Harald", "sameAs": [], "familyName": "Sondergaard", "additionalName": "", "givenName": "Harald", "email": ""}, {"name": "Stuckey, Peter J.", "sameAs": [], "familyName": "Stuckey", "additionalName": "J.", "givenName": "Peter", "email": ""}], "title": "A Complete Refinement Procedure for Regular Separability of Context-Free\n  Languages", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5131", "oai:arXiv.org:1411.5131"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Often, when analyzing the behaviour of systems modelled as context-free\nlanguages, we wish to know if two languages overlap. To this end, we present an\neffective semi-decision procedure for regular separability of context-free\nlanguages, based on counter-example guided abstraction refinement. We propose\ntwo refinement methods, one inexpensive but incomplete, and the other complete\nbut more expensive. We provide an experimental evaluation of this procedure,\nand demonstrate its practicality on a range of verification and\nlanguage-theoretic instances.\n"}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2014-11-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5131"}}, {"publisher": {"name": ""}, "description": "  We formalize and analyze a new automata-theoretic problem termed control\nimprovisation. Given an automaton, the problem is to produce an improviser, a\nprobabilistic algorithm that randomly generates words in its language, subject\nto two additional constraints: the satisfaction of an admissibility predicate,\nand exhibition of a specified amount of randomness. This problem has proved\nuseful, for example, in generating musical improvisations that satisfy rhythmic\nand melodic constraints, where admissibility was determined by some bounded\ndivergence from a reference melody. We analyze the complexity of the control\nimprovisation problem, giving cases where it is efficiently solvable and cases\nwhere it is #P-hard or undecidable. We also show how symbolic techniques based\non SAT solvers can be used to approximately solve some of the intractable\ncases.\n", "contributors": [{"name": "Fremont, Daniel J.", "sameAs": [], "familyName": "Fremont", "additionalName": "J.", "givenName": "Daniel", "email": ""}, {"name": "Donz\u00e9, Alexandre", "sameAs": [], "familyName": "Donz\u00e9", "additionalName": "", "givenName": "Alexandre", "email": ""}, {"name": "Seshia, Sanjit A.", "sameAs": [], "familyName": "Seshia", "additionalName": "A.", "givenName": "Sanjit", "email": ""}, {"name": "Wessel, David", "sameAs": [], "familyName": "Wessel", "additionalName": "", "givenName": "David", "email": ""}], "title": "Control Improvisation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-11-03", "2015-03-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0698", "oai:arXiv.org:1411.0698"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We formalize and analyze a new automata-theoretic problem termed control\nimprovisation. Given an automaton, the problem is to produce an improviser, a\nprobabilistic algorithm that randomly generates words in its language, subject\nto two additional constraints: the satisfaction of an admissibility predicate,\nand exhibition of a specified amount of randomness. This problem has proved\nuseful, for example, in generating musical improvisations that satisfy rhythmic\nand melodic constraints, where admissibility was determined by some bounded\ndivergence from a reference melody. We analyze the complexity of the control\nimprovisation problem, giving cases where it is efficiently solvable and cases\nwhere it is #P-hard or undecidable. We also show how symbolic techniques based\non SAT solvers can be used to approximately solve some of the intractable\ncases.\n", "Comment: 16 pages"]}}], "languages": [null], "subjects": ["computer science - formal languages and automata theory"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0698"}}, {"publisher": {"name": ""}, "description": "  We consider planning with uncertainty in the initial state as a case study of\nincremental quantified Boolean formula (QBF) solving. We report on experiments\nwith a workflow to incrementally encode a planning instance into a sequence of\nQBFs. To solve this sequence of incrementally constructed QBFs, we use our\ngeneral-purpose incremental QBF solver DepQBF. Since the generated QBFs have\nmany clauses and variables in common, our approach avoids redundancy both in\nthe encoding phase and in the solving phase. Experimental results show that\nincremental QBF solving outperforms non-incremental QBF solving. Our results\nare the first empirical study of incremental QBF solving in the context of\nplanning and motivate its use in other application domains.\n", "contributors": [{"name": "Egly, Uwe", "sameAs": [], "familyName": "Egly", "additionalName": "", "givenName": "Uwe", "email": ""}, {"name": "Kronegger, Martin", "sameAs": [], "familyName": "Kronegger", "additionalName": "", "givenName": "Martin", "email": ""}, {"name": "Lonsing, Florian", "sameAs": [], "familyName": "Lonsing", "additionalName": "", "givenName": "Florian", "email": ""}, {"name": "Pfandler, Andreas", "sameAs": [], "familyName": "Pfandler", "additionalName": "", "givenName": "Andreas", "email": ""}], "title": "Conformant Planning as a Case Study of Incremental QBF Solving", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-28", "2014-10-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.7253", "doi:10.1007/978-3-319-13770-4_11", "oai:arXiv.org:1405.7253"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We consider planning with uncertainty in the initial state as a case study of\nincremental quantified Boolean formula (QBF) solving. We report on experiments\nwith a workflow to incrementally encode a planning instance into a sequence of\nQBFs. To solve this sequence of incrementally constructed QBFs, we use our\ngeneral-purpose incremental QBF solver DepQBF. Since the generated QBFs have\nmany clauses and variables in common, our approach avoids redundancy both in\nthe encoding phase and in the solving phase. Experimental results show that\nincremental QBF solving outperforms non-incremental QBF solving. Our results\nare the first empirical study of incremental QBF solving in the context of\nplanning and motivate its use in other application domains.\n", "Comment: revision (camera-ready, to appear in the proceedings of AISC 2014,\n  volume 8884 of LNAI, Springer)"]}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - logic in computer science"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.7253"}}, {"publisher": {"name": ""}, "description": "  Although the many forms of modern social media have become major channels for\nthe dissemination of information, they are becoming overloaded because of the\nrapidly-expanding number of information feeds. We analyze the expanding\nuser-generated content in Sina Weibo, the largest micro-blog site in China, and\nfind evidence that popular messages often follow a mechanism that differs from\nthat found in the spread of disease, in contrast to common believe. In this\nmechanism, an individual with more friends needs more repeated exposures to\nspread further the information. Moreover, our data suggest that in contrast to\nepidemics, for certain messages the chance of an individual to share the\nmessage is proportional to the fraction of its neighbours who shared it with\nhim/her. Thus the greater the number of friends an individual has the greater\nthe number of repeated contacts needed to spread the message, which is a result\nof competition for attention. We model this process using a fractional\nsusceptible infected recovered (FSIR) model, where the infection probability of\na node is proportional to its fraction of infected neighbors. Our findings have\ndramatic implications for information contagion. For example, using the FSIR\nmodel we find that real-world social networks have a finite epidemic threshold.\nThis is in contrast to the zero threshold that conventional wisdom derives from\ndisease epidemic models. This means that when individuals are overloaded with\nexcess information feeds, the information either reaches out the population if\nit is above the critical epidemic threshold, or it would never be well\nreceived, leading to only a handful of information contents that can be widely\nspread throughout the population.\n", "contributors": [{"name": "Feng, Ling", "sameAs": [], "familyName": "Feng", "additionalName": "", "givenName": "Ling", "email": ""}, {"name": "Hu, Yanqing", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Yanqing", "email": ""}, {"name": "Li, Baowen", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Baowen", "email": ""}, {"name": "Stanley, H. Eugene", "sameAs": [], "familyName": "Stanley", "additionalName": "Eugene", "givenName": "H.", "email": ""}, {"name": "Havlin, Shlomo", "sameAs": [], "familyName": "Havlin", "additionalName": "", "givenName": "Shlomo", "email": ""}, {"name": "Braunstein, Lidia A.", "sameAs": [], "familyName": "Braunstein", "additionalName": "A.", "givenName": "Lidia", "email": ""}], "title": "Competing for Attention in Social Media under Information Overload\n  Conditions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.1668", "oai:arXiv.org:1410.1668"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Although the many forms of modern social media have become major channels for\nthe dissemination of information, they are becoming overloaded because of the\nrapidly-expanding number of information feeds. We analyze the expanding\nuser-generated content in Sina Weibo, the largest micro-blog site in China, and\nfind evidence that popular messages often follow a mechanism that differs from\nthat found in the spread of disease, in contrast to common believe. In this\nmechanism, an individual with more friends needs more repeated exposures to\nspread further the information. Moreover, our data suggest that in contrast to\nepidemics, for certain messages the chance of an individual to share the\nmessage is proportional to the fraction of its neighbours who shared it with\nhim/her. Thus the greater the number of friends an individual has the greater\nthe number of repeated contacts needed to spread the message, which is a result\nof competition for attention. We model this process using a fractional\nsusceptible infected recovered (FSIR) model, where the infection probability of\na node is proportional to its fraction of infected neighbors. Our findings have\ndramatic implications for information contagion. For example, using the FSIR\nmodel we find that real-world social networks have a finite epidemic threshold.\nThis is in contrast to the zero threshold that conventional wisdom derives from\ndisease epidemic models. This means that when individuals are overloaded with\nexcess information feeds, the information either reaches out the population if\nit is above the critical epidemic threshold, or it would never be well\nreceived, leading to only a handful of information contents that can be widely\nspread throughout the population.\n", "Comment: 11 pages, 5 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-10-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.1668"}}, {"publisher": {"name": "Research Showcase @ CMU"}, "description": "Association mapping studies promise to link DNA mutations to gene expression data, possibly leading to innovative treatments for diseases. One challenge in large-scale association mapping studies is exploring the results of the computational analysis to find relevant and interesting associations. Although many association mapping studies find associations from a genome-wide collection of genomic data to hundreds or thousands of traits, current visualization software only allow these associations to be explored one trait at a time. The inability to explore the association of a genomic location to multiple traits hides the inherent interaction between traits in the analysis. Additionally, researchers must rely on collections of in-house scripts and multiple tools to perform an analysis, adding time and effort to find interesting associations. In this paper, we present a novel visual analytics system called GenAMap. GenAMap replaces the time-consuming analysis of large-scale association mapping studies with exploratory visualization tools that give geneticists an overview of the data and lead them to relevant information. We present the results of a preliminary evaluation that validated our basic approach.", "contributors": [{"name": "Curtis, Ross E.", "sameAs": [], "familyName": "Curtis", "additionalName": "E.", "givenName": "Ross", "email": ""}, {"name": "Kinnaird, Peter", "sameAs": [], "familyName": "Kinnaird", "additionalName": "", "givenName": "Peter", "email": ""}, {"name": "Xing, Eric P", "sameAs": [], "familyName": "Xing", "additionalName": "P", "givenName": "Eric", "email": ""}], "title": "GenAMap: Visualization Strategies for Structured Association Mapping", "shareProperties": {"source": "cmu"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": "application/pdf"}}, {"name": "date", "properties": {"date": "2011-10-01T07:00:00Z"}}, {"name": "identifier", "properties": {"identifier": ["http://repository.cmu.edu/machine_learning/215", "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1209&amp;context=machine_learning", "oai:repository.cmu.edu:machine_learning-1209"]}}, {"name": "setSpec", "properties": {"setSpec": ["publication:machine_learning", "publication:scs"]}}, {"name": "description", "properties": {"description": "Association mapping studies promise to link DNA mutations to gene expression data, possibly leading to innovative treatments for diseases. One challenge in large-scale association mapping studies is exploring the results of the computational analysis to find relevant and interesting associations. Although many association mapping studies find associations from a genome-wide collection of genomic data to hundreds or thousands of traits, current visualization software only allow these associations to be explored one trait at a time. The inability to explore the association of a genomic location to multiple traits hides the inherent interaction between traits in the analysis. Additionally, researchers must rely on collections of in-house scripts and multiple tools to perform an analysis, adding time and effort to find interesting associations. In this paper, we present a novel visual analytics system called GenAMap. GenAMap replaces the time-consuming analysis of large-scale association mapping studies with exploratory visualization tools that give geneticists an overview of the data and lead them to relevant information. We present the results of a preliminary evaluation that validated our basic approach."}}], "languages": [null], "subjects": ["visual analytics", "theory and algorithms", "structured association mapping", "computer sciences", "eqtl analysis", "genome-wide association studies"], "providerUpdatedDateTime": "2015-04-08T21:48:31", "uris": {"canonicalUri": "http://repository.cmu.edu/machine_learning/215"}}, {"publisher": {"name": ""}, "description": "  Bayesian Networks (BNs) are popular graphical models for the representation\nof statistical problems embodying dependence relationships between a number of\nvariables. Much of this popularity is due to the d-separation theorem of Pearl\nand Lauritzen, which allows an analyst to identify the conditional independence\nstatements that a model of the problem embodies using only the topology of the\ngraph. However for many problems the complete model dependence structure cannot\nbe depicted by a BN. The Chain Event Graph (CEG) was introduced for these types\nof problem. In this paper we introduce a separation theorem for CEGs, analogous\nto the d-separation theorem for BNs, which likewise allows an analyst to\nidentify the conditional independence structure of their model from the\ntopology of the graph.\n", "contributors": [{"name": "Thwaites, Peter A.", "sameAs": [], "familyName": "Thwaites", "additionalName": "A.", "givenName": "Peter", "email": ""}, {"name": "Smith, Jim Q.", "sameAs": [], "familyName": "Smith", "additionalName": "Q.", "givenName": "Jim", "email": ""}], "title": "A Separation Theorem for Chain Event Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05215", "oai:arXiv.org:1501.05215"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Bayesian Networks (BNs) are popular graphical models for the representation\nof statistical problems embodying dependence relationships between a number of\nvariables. Much of this popularity is due to the d-separation theorem of Pearl\nand Lauritzen, which allows an analyst to identify the conditional independence\nstatements that a model of the problem embodies using only the topology of the\ngraph. However for many problems the complete model dependence structure cannot\nbe depicted by a BN. The Chain Event Graph (CEG) was introduced for these types\nof problem. In this paper we introduce a separation theorem for CEGs, analogous\nto the d-separation theorem for BNs, which likewise allows an analyst to\nidentify the conditional independence structure of their model from the\ntopology of the graph.\n", "Comment: 39 pages, 10 figures. Submitted to Electronic Journal of Statistics"]}}], "languages": [null], "subjects": ["68t37 (secondary)", "computer science - artificial intelligence", "62f15 (primary)", "statistics - methodology"], "providerUpdatedDateTime": "2015-01-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05215"}}, {"publisher": {"name": ""}, "description": "  Stencil computations on low dimensional grids are kernels of many scientific\napplications including finite difference methods used to solve partial\ndifferential equations. On typical modern computer architectures, such stencil\ncomputations are limited by the performance of the memory subsystem, namely by\nthe bandwidth between main memory and the cache. This work considers the\ncomputation of star stencils, like the 5-point and 7-point stencil, in the\nexternal memory model and parallel external memory model and analyses the\nconstant of the leading term of the non-compulsory I/Os. While optimizing\nstencil computations is an active field of research, there has been a\nsignificant gap between the lower bounds and the performance of the algorithms\nso far. In two dimensions, this work provides matching constants for lower and\nupper bounds closing a multiplicative gap of 4. In three dimensions, the bounds\nmatch up to a factor of $\\sqrt{2}$ improving the known results by a factor of\n$2 \\sqrt{3}\\sqrt{B}$, where $B$ is the block (cache line) size of the external\nmemory model. For dimensions $d\\geq 4$, the lower bound is improved between a\nfactor of $4$ and $6$. For arbitrary dimension~$d$, the first analysis of the\nconstant of the leading term of the non-compulsory I/Os is presented. For\n$d\\geq 3$ the lower and upper bound match up to a factor of\n$\\sqrt[d-1]{d!}\\approx \\frac{d}{e}$.\n", "contributors": [{"name": "Hupp, Philipp", "sameAs": [], "familyName": "Hupp", "additionalName": "", "givenName": "Philipp", "email": ""}, {"name": "Jacob, Riko", "sameAs": [], "familyName": "Jacob", "additionalName": "", "givenName": "Riko", "email": ""}], "title": "Tight Bounds for Low Dimensional Star Stencils in the Parallel External\n  Memory Model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-05-02", "2015-01-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.0606", "WADS 2013, LNCS 8037, pp. 415-426, 2013", "doi:10.1007/978-3-642-40104-6_36", "oai:arXiv.org:1205.0606"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Stencil computations on low dimensional grids are kernels of many scientific\napplications including finite difference methods used to solve partial\ndifferential equations. On typical modern computer architectures, such stencil\ncomputations are limited by the performance of the memory subsystem, namely by\nthe bandwidth between main memory and the cache. This work considers the\ncomputation of star stencils, like the 5-point and 7-point stencil, in the\nexternal memory model and parallel external memory model and analyses the\nconstant of the leading term of the non-compulsory I/Os. While optimizing\nstencil computations is an active field of research, there has been a\nsignificant gap between the lower bounds and the performance of the algorithms\nso far. In two dimensions, this work provides matching constants for lower and\nupper bounds closing a multiplicative gap of 4. In three dimensions, the bounds\nmatch up to a factor of $\\sqrt{2}$ improving the known results by a factor of\n$2 \\sqrt{3}\\sqrt{B}$, where $B$ is the block (cache line) size of the external\nmemory model. For dimensions $d\\geq 4$, the lower bound is improved between a\nfactor of $4$ and $6$. For arbitrary dimension~$d$, the first analysis of the\nconstant of the leading term of the non-compulsory I/Os is presented. For\n$d\\geq 3$ the lower and upper bound match up to a factor of\n$\\sqrt[d-1]{d!}\\approx \\frac{d}{e}$.\n", "Comment: 64 pages, 8 figures, 4 tables"]}}], "languages": [null], "subjects": ["computer science - computational complexity"], "providerUpdatedDateTime": "2015-01-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.0606"}}, {"publisher": {"name": ""}, "description": "  Sensitivity, certificate complexity and block sensitivity are widely used\nBoolean function complexity measures. A longstanding open problem, proposed by\nNisan and Szegedy, is whether sensitivity and block sensitivity are\npolynomially related. Motivated by the constructions of functions which achieve\nthe largest known separations, we study the relation between 1-certificate\ncomplexity and 0-sensitivity and 0-block sensitivity.\n  Previously the best known lower bound was $C_1(f)\\geq \\frac{bs_0(f)}{2\ns_0(f)}$, achieved by Kenyon and Kutin. We improve this to $C_1(f)\\geq \\frac{3\nbs_0(f)}{2 s_0(f)}$. While this improvement is only by a constant factor, this\nis quite important, as it precludes achieving a superquadratic separation\nbetween $bs(f)$ and $s(f)$ by iterating functions which reach this bound. In\naddition, this bound is tight, as it matches the construction of Ambainis and\nSun up to an additive constant.\n", "contributors": [{"name": "Ambainis, Andris", "sameAs": [], "familyName": "Ambainis", "additionalName": "", "givenName": "Andris", "email": ""}, {"name": "Pr\u016bsis, Kri\u0161j\u0101nis", "sameAs": [], "familyName": "Pr\u016bsis", "additionalName": "", "givenName": "Kri\u0161j\u0101nis", "email": ""}], "title": "A Tight Lower Bound on Certificate Complexity in Terms of Block\n  Sensitivity and Sensitivity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-20", "2014-07-31"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.5078", "doi:10.1007/978-3-662-44465-8_4", "oai:arXiv.org:1402.5078"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Sensitivity, certificate complexity and block sensitivity are widely used\nBoolean function complexity measures. A longstanding open problem, proposed by\nNisan and Szegedy, is whether sensitivity and block sensitivity are\npolynomially related. Motivated by the constructions of functions which achieve\nthe largest known separations, we study the relation between 1-certificate\ncomplexity and 0-sensitivity and 0-block sensitivity.\n  Previously the best known lower bound was $C_1(f)\\geq \\frac{bs_0(f)}{2\ns_0(f)}$, achieved by Kenyon and Kutin. We improve this to $C_1(f)\\geq \\frac{3\nbs_0(f)}{2 s_0(f)}$. While this improvement is only by a constant factor, this\nis quite important, as it precludes achieving a superquadratic separation\nbetween $bs(f)$ and $s(f)$ by iterating functions which reach this bound. In\naddition, this bound is tight, as it matches the construction of Ambainis and\nSun up to an additive constant.\n", "Comment: 12 pages"]}}], "languages": [null], "subjects": ["computer science - computational complexity"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.5078"}}, {"publisher": {"name": ""}, "description": "  This work is about the use of regularized optimal-transport distances for\nconvex, histogram-based image segmentation. In the considered framework, fixed\nexemplar histograms define a prior on the statistical features of the two\nregions in competition. In this paper, we investigate the use of various\ntransport-based cost functions as discrepancy measures and rely on a\nprimal-dual algorithm to solve the obtained convex optimization problem.\n", "contributors": [{"name": "Rabin, Julien", "sameAs": [], "familyName": "Rabin", "additionalName": "", "givenName": "Julien", "email": ""}, {"name": "Papadakis, Nicolas", "sameAs": [], "familyName": "Papadakis", "additionalName": "", "givenName": "Nicolas", "email": ""}], "title": "Convex Color Image Segmentation with Optimal Transport Distances", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-03-06", "2015-03-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.01986", "oai:arXiv.org:1503.01986"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This work is about the use of regularized optimal-transport distances for\nconvex, histogram-based image segmentation. In the considered framework, fixed\nexemplar histograms define a prior on the statistical features of the two\nregions in competition. In this paper, we investigate the use of various\ntransport-based cost functions as discrepancy measures and rely on a\nprimal-dual algorithm to solve the obtained convex optimization problem.\n", "Comment: A short version of this report has been submitted to the Fifth\n  International Conference on Scale Space and Variational Methods in Computer\n  Vision (SSVM) 2015"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.01986"}}, {"publisher": {"name": ""}, "description": "  A classical result of Conway and Pless is that a natural projection of the\nfixed code of an automorphism of odd prime order of a self-dual binary linear\ncode is self-dual. In this paper we prove that the same holds for involutions\nunder some (quite strong) conditions on the codes. In order to prove it, we\nintroduce a new family of binary codes: the semi self-dual codes. A binary\nself-orthogonal code is called semi self-dual if it contains the all-ones\nvector and is of codimension 2 in its dual code. We prove upper bounds on the\ndual distance of semi self-dual codes. As an application we get the following:\nlet C be an extremal self-dual binary linear code of length 24m and s in Aut(C)\nbe a fixed point free automorphism of order 2. If m is odd or if m=2k with\nbinom{5k-1}{k-1} odd then C is a free F_2<s>-module. This result has quite\nstrong consequences on the structure of the automorphism group of such codes.\n", "contributors": [{"name": "Borello, Martino", "sameAs": [], "familyName": "Borello", "additionalName": "", "givenName": "Martino", "email": ""}, {"name": "Nebe, Gabriele", "sameAs": [], "familyName": "Nebe", "additionalName": "", "givenName": "Gabriele", "email": ""}], "title": "On involutions in extremal self-dual codes and the dual distance of semi\n  self-dual codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-01-23", "2014-11-24"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1401.6036", "oai:arXiv.org:1401.6036"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  A classical result of Conway and Pless is that a natural projection of the\nfixed code of an automorphism of odd prime order of a self-dual binary linear\ncode is self-dual. In this paper we prove that the same holds for involutions\nunder some (quite strong) conditions on the codes. In order to prove it, we\nintroduce a new family of binary codes: the semi self-dual codes. A binary\nself-orthogonal code is called semi self-dual if it contains the all-ones\nvector and is of codimension 2 in its dual code. We prove upper bounds on the\ndual distance of semi self-dual codes. As an application we get the following:\nlet C be an extremal self-dual binary linear code of length 24m and s in Aut(C)\nbe a fixed point free automorphism of order 2. If m is odd or if m=2k with\nbinom{5k-1}{k-1} odd then C is a free F_2<s>-module. This result has quite\nstrong consequences on the structure of the automorphism group of such codes.\n", "Comment: 12 pages"]}}], "languages": [null], "subjects": ["computer science - information theory", "mathematics - combinatorics"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1401.6036"}}, {"publisher": {"name": ""}, "description": "  This paper presents a theoretical analysis of multi-view embedding -- feature\nembedding that can be learned from unlabeled data through the task of\npredicting one view from another. We prove its usefulness in supervised\nlearning under certain conditions. The result explains the effectiveness of\nsome existing methods such as word embedding. Based on this theory, we propose\na new semi-supervised learning framework that learns a multi-view embedding of\nsmall text regions with convolutional neural networks. The method derived from\nthis framework outperforms state-of-the-art methods on sentiment classification\nand topic categorization.\n", "contributors": [{"name": "Johnson, Rie", "sameAs": [], "familyName": "Johnson", "additionalName": "", "givenName": "Rie", "email": ""}, {"name": "Zhang, Tong", "sameAs": [], "familyName": "Zhang", "additionalName": "", "givenName": "Tong", "email": ""}], "title": "Semi-Supervised Learning with Multi-View Embedding: Theory and\n  Application with Convolutional Neural Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01255", "oai:arXiv.org:1504.01255"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  This paper presents a theoretical analysis of multi-view embedding -- feature\nembedding that can be learned from unlabeled data through the task of\npredicting one view from another. We prove its usefulness in supervised\nlearning under certain conditions. The result explains the effectiveness of\nsome existing methods such as word embedding. Based on this theory, we propose\na new semi-supervised learning framework that learns a multi-view embedding of\nsmall text regions with convolutional neural networks. The method derived from\nthis framework outperforms state-of-the-art methods on sentiment classification\nand topic categorization.\n"}}], "languages": [null], "subjects": ["computer science - computation and language", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01255"}}, {"publisher": {"name": ""}, "description": "  We consider the problem of optimal multi-modes switching in finite horizon,\nwhen the state of the system, including the switching cost functions are\narbitrary ($g_{ij}(t,x)\\geq 0$). We show existence of the optimal strategy, and\ngive when the optimal strategy is finite via a verification theorem. Finally,\nwhen the state of the system is a markov process, we show that the vector of\nvalue functions of the optimal problem is the unique viscosity solution to the\nsystem of $m$ variational partial differential inequalities with\ninter-connected obstacles.\n", "contributors": [{"name": "Asri, Brahim El", "sameAs": [], "familyName": "Asri", "additionalName": "El", "givenName": "Brahim", "email": ""}], "title": "Stochastic Optimal Multi-Modes Switching with a Viscosity Solution\n  Approach", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-02-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1102.1256", "oai:arXiv.org:1102.1256"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider the problem of optimal multi-modes switching in finite horizon,\nwhen the state of the system, including the switching cost functions are\narbitrary ($g_{ij}(t,x)\\geq 0$). We show existence of the optimal strategy, and\ngive when the optimal strategy is finite via a verification theorem. Finally,\nwhen the state of the system is a markov process, we show that the vector of\nvalue functions of the optimal problem is the unique viscosity solution to the\nsystem of $m$ variational partial differential inequalities with\ninter-connected obstacles.\n", "Comment: 2 figures"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - systems and control", "real options", "viscosity solution of pdes", "snell\n  envelope", "variational\n  inequalities", "stopping times", "switching", "backward stochastic differential equations", "mathematics - probability"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1102.1256"}}, {"publisher": {"name": ""}, "description": "  In this work we derive fundamental limits for many linear and non-linear\nsparse signal processing models including linear and non-linear sparse\nregression, group testing, multivariate regression and problems with missing\nfeatures. In general, sparse signal processing problems can be characterized in\nterms of the following Markovian property. We are given a set of $N$ variables\n$X_1,X_2,\\ldots,X_N$, and there is an unknown subset of variables $S \\subset\n\\{1,2,\\ldots, N\\}$ that are \\emph{relevant} for predicting outcomes/outputs\n$Y$. More specifically, when $Y$ is conditioned on $\\{X_n\\}_{n\\in S}$ it is\nconditionally independent of the other variables, $\\{X_n\\}_{n \\not \\in S}$. Our\ngoal is to identify the set $S$ from samples of the variables $X$ and the\nassociated outcomes $Y$. We characterize this problem as a version of the noisy\nchannel coding problem. Using asymptotic information theoretic analyses, we\nestablish mutual information formulas that provide sufficient and necessary\nconditions on the number of samples required to successfully recover the\nsalient variables. These mutual information expressions unify conditions for\nboth linear and non-linear observations. We then compute sample complexity\nbounds for the aforementioned models, based on the mutual information\nexpressions in order to demonstrate the applicability and flexibility of our\nresults in general sparse signal processing models.\n", "contributors": [{"name": "Aksoylar, Cem", "sameAs": [], "familyName": "Aksoylar", "additionalName": "", "givenName": "Cem", "email": ""}, {"name": "Atia, George", "sameAs": [], "familyName": "Atia", "additionalName": "", "givenName": "George", "email": ""}, {"name": "Saligrama, Venkatesh", "sameAs": [], "familyName": "Saligrama", "additionalName": "", "givenName": "Venkatesh", "email": ""}], "title": "Sparse Signal Processing with Linear and Non-Linear Observations: A\n  Unified Shannon Theoretic Approach", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-04-02", "2015-01-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1304.0682", "oai:arXiv.org:1304.0682"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "stat"]}}, {"name": "description", "properties": {"description": ["  In this work we derive fundamental limits for many linear and non-linear\nsparse signal processing models including linear and non-linear sparse\nregression, group testing, multivariate regression and problems with missing\nfeatures. In general, sparse signal processing problems can be characterized in\nterms of the following Markovian property. We are given a set of $N$ variables\n$X_1,X_2,\\ldots,X_N$, and there is an unknown subset of variables $S \\subset\n\\{1,2,\\ldots, N\\}$ that are \\emph{relevant} for predicting outcomes/outputs\n$Y$. More specifically, when $Y$ is conditioned on $\\{X_n\\}_{n\\in S}$ it is\nconditionally independent of the other variables, $\\{X_n\\}_{n \\not \\in S}$. Our\ngoal is to identify the set $S$ from samples of the variables $X$ and the\nassociated outcomes $Y$. We characterize this problem as a version of the noisy\nchannel coding problem. Using asymptotic information theoretic analyses, we\nestablish mutual information formulas that provide sufficient and necessary\nconditions on the number of samples required to successfully recover the\nsalient variables. These mutual information expressions unify conditions for\nboth linear and non-linear observations. We then compute sample complexity\nbounds for the aforementioned models, based on the mutual information\nexpressions in order to demonstrate the applicability and flexibility of our\nresults in general sparse signal processing models.\n", "Comment: Major rewrite of the technical part, errors in notation, theorem\n  statements and proofs are corrected"]}}], "languages": [null], "subjects": ["mathematics - statistics theory", "computer science - information theory", "computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-01-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1304.0682"}}, {"publisher": {"name": ""}, "description": "  Human-Robot Social Interaction became one of active research fields in which\nresearchers from different areas propose solutions and directives leading\nrobots to improve their interactions with humans. In this paper we propose to\nintroduce works in both human robot interaction and human computer interaction\nand to make a bridge between them, i.e. to integrate emotions and capabilities\nconcepts of the robot in human computer model to become adequate for human\nrobot interaction and discuss challenges related to the proposed model. Finally\nan illustration through real case of this model will be presented.\n", "contributors": [{"name": "Toumi, Tarek", "sameAs": [], "familyName": "Toumi", "additionalName": "", "givenName": "Tarek", "email": ""}, {"name": "Zidani, Abdelmadjid", "sameAs": [], "familyName": "Zidani", "additionalName": "", "givenName": "Abdelmadjid", "email": ""}], "title": "From Human-Computer Interaction to Human-Robot Social Interaction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1251", "IJCSI International Journal of Computer Science Issues, Vol. 11,\n  Issue 1, No 1, 2014 1694-0814", "oai:arXiv.org:1412.1251"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Human-Robot Social Interaction became one of active research fields in which\nresearchers from different areas propose solutions and directives leading\nrobots to improve their interactions with humans. In this paper we propose to\nintroduce works in both human robot interaction and human computer interaction\nand to make a bridge between them, i.e. to integrate emotions and capabilities\nconcepts of the robot in human computer model to become adequate for human\nrobot interaction and discuss challenges related to the proposed model. Finally\nan illustration through real case of this model will be presented.\n"}}], "languages": [null], "subjects": ["computer science - robotics", "computer science - systems and control", "computer science - human-computer interaction"], "providerUpdatedDateTime": "2014-12-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1251"}}, {"publisher": {"name": ""}, "description": "  We study the dynamics of the normal implied volatility in a local volatility\nmodel, using a small-time expansion in powers of maturity T. At leading order\nin this expansion, the asymptotics of the normal implied volatility is similar,\nup to a different definition of the moneyness, to that of the log-normal\nvolatility. This relation is preserved also to order O(T) in the small-time\nexpansion, and differences with the log-normal case appear first at O(T^2). The\nresults are illustrated on a few examples of local volatility models with\nanalytical local volatility, finding generally good agreement with exact or\nnumerical solutions. We point out that the asymptotic expansion can fail if\napplied naively for models with nonanalytical local volatility, for example\nwhich have discontinuous derivatives. Using perturbation theory methods, we\nshow that the ATM normal implied volatility for such a model contains a term ~\n\\sqrt{T}, with a coefficient which is proportional with the jump of the\nderivative.\n", "contributors": [{"name": "Costeanu, Viorel", "sameAs": [], "familyName": "Costeanu", "additionalName": "", "givenName": "Viorel", "email": ""}, {"name": "Pirjol, Dan", "sameAs": [], "familyName": "Pirjol", "additionalName": "", "givenName": "Dan", "email": ""}], "title": "Asymptotic Expansion for the Normal Implied Volatility in Local\n  Volatility Models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.3359", "oai:arXiv.org:1105.3359"]}}, {"name": "setSpec", "properties": {"setSpec": "q-fin"}}, {"name": "description", "properties": {"description": ["  We study the dynamics of the normal implied volatility in a local volatility\nmodel, using a small-time expansion in powers of maturity T. At leading order\nin this expansion, the asymptotics of the normal implied volatility is similar,\nup to a different definition of the moneyness, to that of the log-normal\nvolatility. This relation is preserved also to order O(T) in the small-time\nexpansion, and differences with the log-normal case appear first at O(T^2). The\nresults are illustrated on a few examples of local volatility models with\nanalytical local volatility, finding generally good agreement with exact or\nnumerical solutions. We point out that the asymptotic expansion can fail if\napplied naively for models with nonanalytical local volatility, for example\nwhich have discontinuous derivatives. Using perturbation theory methods, we\nshow that the ATM normal implied volatility for such a model contains a term ~\n\\sqrt{T}, with a coefficient which is proportional with the jump of the\nderivative.\n", "Comment: 29 pages, 5 figures"]}}], "languages": [null], "subjects": ["quantitative finance - pricing of securities", "quantitative finance - computational finance"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.3359"}}, {"publisher": {"name": ""}, "description": "  High-order harmonic generation is investigated for H$_2^+$ and D$_2^+$ with\nand without Born-Oppenheimer approximation by numerical solution of full\ndimensional electronic time-dependent Schr\\\"{o}dinger equation under 4-cycle\nintense laser pulses of 800 nm wavelength and $I$=4, 5, 7, 10 $\\times 10^{14}$\nW$/$cm$^2$ intensities. For most harmonic orders, the intensity obtained for\nD$_2^+$ is higher than that for H$_2^+$, and the yield difference increases as\nthe harmonic order increases. Only at some low harmonic orders, H$_2^+$\ngenerates more intense harmonics compared to D$_2^+$. The results show that\nnuclear motion, ionization probability and system dimensionality must be\nsimultaneously taken into account to properly explain the isotopic effects on\nhigh-order harmonic generation and to justify experimental observations.\n", "contributors": [{"name": "Ahmadi, Hamed", "sameAs": [], "familyName": "Ahmadi", "additionalName": "", "givenName": "Hamed", "email": ""}, {"name": "Maghari, Ali", "sameAs": [], "familyName": "Maghari", "additionalName": "", "givenName": "Ali", "email": ""}, {"name": "Sabzyan, Hassan", "sameAs": [], "familyName": "Sabzyan", "additionalName": "", "givenName": "Hassan", "email": ""}, {"name": "Niknam, Ali Reza", "sameAs": [], "familyName": "Niknam", "additionalName": "Reza", "givenName": "Ali", "email": ""}, {"name": "Vafaee, Mohsen", "sameAs": [], "familyName": "Vafaee", "additionalName": "", "givenName": "Mohsen", "email": ""}], "title": "Effect of nuclear motion on high-order harmonic generation of H$_2^+$ in\n  intense ultrashort laser pulses", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-07-21"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1407.5458", "Phys. Rev. A 90, 043411 (2014)", "doi:10.1103/PhysRevA.90.043411", "oai:arXiv.org:1407.5458"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": ["  High-order harmonic generation is investigated for H$_2^+$ and D$_2^+$ with\nand without Born-Oppenheimer approximation by numerical solution of full\ndimensional electronic time-dependent Schr\\\"{o}dinger equation under 4-cycle\nintense laser pulses of 800 nm wavelength and $I$=4, 5, 7, 10 $\\times 10^{14}$\nW$/$cm$^2$ intensities. For most harmonic orders, the intensity obtained for\nD$_2^+$ is higher than that for H$_2^+$, and the yield difference increases as\nthe harmonic order increases. Only at some low harmonic orders, H$_2^+$\ngenerates more intense harmonics compared to D$_2^+$. The results show that\nnuclear motion, ionization probability and system dimensionality must be\nsimultaneously taken into account to properly explain the isotopic effects on\nhigh-order harmonic generation and to justify experimental observations.\n", "Comment: 7 pages, 5 figures"]}}], "languages": [null], "subjects": ["physics - computational physics", "physics - chemical physics", "physics - atomic physics"], "providerUpdatedDateTime": "2014-10-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1407.5458"}}], "time": 0.13}